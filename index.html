<!DOCTYPE html>
<html>
<head>
<title>Paper collected by Wang</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">


/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

span#pid {
  color:red;
  
}
span#filename{
  font-style: oblique;
}

span#title{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: italic;
  font-size: 20px;
  border:1px solid #B50;
}
span#abs{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: oblique;
  font-size: 18px;
}
</style>
</head>
<body>

</p></br></br><div id='section'>Paperid: <span id='pid'>1, <a href='https://arxiv.org/pdf/2510.05351.pdf' target='_blank'>https://arxiv.org/pdf/2510.05351.pdf</a></span>   <span><a href='https://github.com/Autumnstar-cjh/PIANO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinghao Cao, Qin Li, Mengnan Du, Haimin Wang, Bo Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05351">Physics-informed Attention-enhanced Fourier Neural Operator for Solar Magnetic Field Extrapolations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose Physics-informed Attention-enhanced Fourier Neural Operator (PIANO) to solve the Nonlinear Force-Free Field (NLFFF) problem in solar physics. Unlike conventional approaches that rely on iterative numerical methods, our proposed PIANO directly learns the 3D magnetic field structure from 2D boundary conditions. Specifically, PIANO integrates Efficient Channel Attention (ECA) mechanisms with Dilated Convolutions (DC), which enhances the model's ability to capture multimodal input by prioritizing critical channels relevant to the magnetic field's variations. Furthermore, we apply physics-informed loss by enforcing the force-free and divergence-free conditions in the training process so that our prediction is consistent with underlying physics with high accuracy. Experimental results on the ISEE NLFFF dataset show that our PIANO not only outperforms state-of-the-art neural operators in terms of accuracy but also shows strong consistency with the physical characteristics of NLFFF data across magnetic fields reconstructed from various solar active regions. The GitHub of this project is available https://github.com/Autumnstar-cjh/PIANO
<div id='section'>Paperid: <span id='pid'>2, <a href='https://arxiv.org/pdf/2509.24517.pdf' target='_blank'>https://arxiv.org/pdf/2509.24517.pdf</a></span>   <span><a href='https://github.com/sophiawilson18/FlowMatching' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sophia N. Wilson, Jens Hesselbjerg Christensen, Raghavendra Selvan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24517">Trading Carbon for Physics: On the Resource Efficiency of Machine Learning for Spatio-Temporal Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Development of modern deep learning methods has been driven primarily by the push for improving model efficacy (accuracy metrics). This sole focus on efficacy has steered development of large-scale models that require massive resources, and results in considerable carbon footprint across the model life-cycle. In this work, we explore how physics inductive biases can offer useful trade-offs between model efficacy and model efficiency (compute, energy, and carbon). We study a variety of models for spatio-temporal forecasting, a task governed by physical laws and well-suited for exploring different levels of physics inductive bias. We show that embedding physics inductive biases into the model design can yield substantial efficiency gains while retaining or even improving efficacy for the tasks under consideration. In addition to using standard physics-informed spatio-temporal models, we demonstrate the usefulness of more recent models like flow matching as a general purpose method for spatio-temporal forecasting. Our experiments show that incorporating physics inductive biases offer a principled way to improve the efficiency and reduce the carbon footprint of machine learning models. We argue that model efficiency, along with model efficacy, should become a core consideration driving machine learning model development and deployment.
<div id='section'>Paperid: <span id='pid'>3, <a href='https://arxiv.org/pdf/2509.22458.pdf' target='_blank'>https://arxiv.org/pdf/2509.22458.pdf</a></span>   <span><a href='https://github.com/Kimchangheon/PIGNN-Attn-LS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Changhun Kim, Timon Conrad, Redwanul Karim, Julian Oelhaf, David Riebesel, Tomás Arias-Vergara, Andreas Maier, Johann Jäger, Siming Bayer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.22458">Physics-informed GNN for medium-high voltage AC power flow with edge-aware attention and line search correction operator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed graph neural networks (PIGNNs) have emerged as fast AC power-flow solvers that can replace classic Newton--Raphson (NR) solvers, especially when thousands of scenarios must be evaluated. However, current PIGNNs still need accuracy improvements at parity speed; in particular, the physics loss is inoperative at inference, which can deter operational adoption. We address this with PIGNN-Attn-LS, combining an edge-aware attention mechanism that explicitly encodes line physics via per-edge biases, capturing the grid's anisotropy, with a backtracking line-search-based globalized correction operator that restores an operative decrease criterion at inference. Training and testing use a realistic High-/Medium-Voltage scenario generator, with NR used only to construct reference states. On held-out HV cases consisting of 4--32-bus grids, PIGNN-Attn-LS achieves a test RMSE of 0.00033 p.u. in voltage and 0.08$^\circ$ in angle, outperforming the PIGNN-MLP baseline by 99.5\% and 87.1\%, respectively. With streaming micro-batches, it delivers 2--5$\times$ faster batched inference than NR on 4--1024-bus grids.
<div id='section'>Paperid: <span id='pid'>4, <a href='https://arxiv.org/pdf/2509.19985.pdf' target='_blank'>https://arxiv.org/pdf/2509.19985.pdf</a></span>   <span><a href='https://github.com/sepehr-m/Pi-Transformer' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sepehr Maleki, Negar Pourmoazemi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.19985">Pi-Transformer: A Physics-informed Attention Mechanism for Time Series Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anomalies in multivariate time series often arise from temporal context and cross-channel coordination rather than isolated outliers. We present Pi-Transformer, a physics-informed transformer with two attention pathways: a data-driven series attention and a smoothly evolving prior attention that encodes temporal invariants such as scale-related self-similarity and phase synchrony. The prior acts as a stable reference that calibrates reconstruction error. During training, we pair a reconstruction objective with a divergence term that encourages agreement between the two attentions while keeping them meaningfully distinct; the prior is regularised to evolve smoothly and is lightly distilled towards dataset-level statistics. At inference, the model combines an alignment-weighted reconstruction signal (Energy) with a mismatch signal that highlights timing and phase disruptions, and fuses them into a single score for detection. Across five benchmarks (SMD, MSL, SMAP, SWaT, and PSM), Pi-Transformer achieves state-of-the-art or highly competitive F1, with particular strength on timing and phase-breaking anomalies. Case analyses show complementary behaviour of the two streams and interpretable detections around regime changes. Embedding physics-informed priors into attention yields a calibrated and robust approach to anomaly detection in complex multivariate systems. Code is publicly available at this GitHub repository\footnote{https://github.com/sepehr-m/Pi-Transformer}.
<div id='section'>Paperid: <span id='pid'>5, <a href='https://arxiv.org/pdf/2509.05117.pdf' target='_blank'>https://arxiv.org/pdf/2509.05117.pdf</a></span>   <span><a href='https://github.com/rbischof/hypino' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Rafael Bischof, Michal Piovarči, Michael A. Kraus, Siddhartha Mishra, Bernd Bickel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05117">HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present HyPINO, a multi-physics neural operator designed for zero-shot generalization across a broad class of parametric PDEs without requiring task-specific fine-tuning. Our approach combines a Swin Transformer-based hypernetwork with mixed supervision: (i) labeled data from analytical solutions generated via the Method of Manufactured Solutions (MMS), and (ii) unlabeled samples optimized using physics-informed objectives. The model maps PDE parametrizations to target Physics-Informed Neural Networks (PINNs) and can handle linear elliptic, hyperbolic, and parabolic equations in two dimensions with varying source terms, geometries, and mixed Dirichlet/Neumann boundary conditions, including interior boundaries. HyPINO achieves strong zero-shot accuracy on seven benchmark problems from PINN literature, outperforming U-Nets, Poseidon, and Physics-Informed Neural Operators (PINO). Further, we introduce an iterative refinement procedure that compares the physics of the generated PINN to the requested PDE and uses the discrepancy to generate a "delta" PINN. Summing their contributions and repeating this process forms an ensemble whose combined solution progressively reduces the error on six benchmarks and achieves over 100x gain in average $L_2$ loss in the best case, while retaining forward-only inference. Additionally, we evaluate the fine-tuning behavior of PINNs initialized by HyPINO and show that they converge faster and to lower final error than both randomly initialized and Reptile-meta-learned PINNs on five benchmarks, performing on par on the remaining two. Our results highlight the potential of this scalable approach as a foundation for extending neural operators toward solving increasingly complex, nonlinear, and high-dimensional PDE problems. The code and model weights are publicly available at https://github.com/rbischof/hypino.
<div id='section'>Paperid: <span id='pid'>6, <a href='https://arxiv.org/pdf/2509.02343.pdf' target='_blank'>https://arxiv.org/pdf/2509.02343.pdf</a></span>   <span><a href='https://github.com/LannWei/CBS2025' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lan Wei, Lou Genoud, Dandan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02343">Physics-Informed Machine Learning with Adaptive Grids for Optical Microrobot Depth Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optical microrobots actuated by optical tweezers (OT) offer great potential for biomedical applications such as cell manipulation and microscale assembly. These tasks demand accurate three-dimensional perception to ensure precise control in complex and dynamic biological environments. However, the transparent nature of microrobots and low-contrast microscopic imaging challenge conventional deep learning methods, which also require large annotated datasets that are costly to obtain. To address these challenges, we propose a physics-informed, data-efficient framework for depth estimation of optical microrobots. Our method augments convolutional feature extraction with physics-based focus metrics, such as entropy, Laplacian of Gaussian, and gradient sharpness, calculated using an adaptive grid strategy. This approach allocates finer grids over microrobot regions and coarser grids over background areas, enhancing depth sensitivity while reducing computational complexity. We evaluate our framework on multiple microrobot types and demonstrate significant improvements over baseline models. Specifically, our approach reduces mean squared error (MSE) by over 60% and improves the coefficient of determination (R^2) across all test cases. Notably, even when trained on only 20% of the available data, our model outperforms ResNet50 trained on the full dataset, highlighting its robustness under limited data conditions. Our code is available at: https://github.com/LannWei/CBS2025.
<div id='section'>Paperid: <span id='pid'>7, <a href='https://arxiv.org/pdf/2508.19847.pdf' target='_blank'>https://arxiv.org/pdf/2508.19847.pdf</a></span>   <span><a href='https://github.com/erkara/fem-pi-deeponet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Erdi Kara, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19847">Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a hybrid framework that couples finite element methods (FEM) with physics-informed DeepONet to model fluid transport in porous media from sharp, localized Gaussian sources. The governing system consists of a steady-state Darcy flow equation and a time-dependent convection-diffusion equation. Our approach solves the Darcy system using FEM and transfers the resulting velocity field to a physics-informed DeepONet, which learns the mapping from source functions to solute concentration profiles. This modular strategy preserves FEM-level accuracy in the flow field while enabling fast inference for transport dynamics. To handle steep gradients induced by sharp sources, we introduce an adaptive sampling strategy for trunk collocation points. Numerical experiments demonstrate that our method is in good agreement with the reference solutions while offering orders of magnitude speedups over traditional solvers, making it suitable for practical applications in relevant scenarios. Implementation of our proposed method is available at https://github.com/erkara/fem-pi-deeponet.
<div id='section'>Paperid: <span id='pid'>8, <a href='https://arxiv.org/pdf/2508.19561.pdf' target='_blank'>https://arxiv.org/pdf/2508.19561.pdf</a></span>   <span><a href='https://github.com/sufe-Ran-Zhang/EMMPDE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qinjiao Gao, Longzhe Xu, Dongjiang Wang, Ran Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19561">Energy-Equidistributed Moving Sampling Physics-informed Neural Networks for Solving Conservative Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel Energy-Equidistributed adaptive sampling framework for multi-dimensional conservative PDEs, introducing both location-based and velocity-based formulations of Energy-Equidistributed moving mesh PDEs (EMMPDEs). The framework utilizes the energy density function as the monitor function, ensuring that mesh adaptation dynamically tracks energy evolution during temporal integration. These theoretical developments are integrated with deep neural networks to establish the Energy-Equidistributed Moving Sampling Physics-Informed Neural Networks (EEMS-PINNs), which integrate physics-informed learning with energy-adaptive mesh optimization. Extensive numerical experiments demonstrate that EEMS-PINNs effectively maintain solution accuracy in long-time simulations while preserving conserved energy. The framework's robustness is further evidenced by its stable performance in non-conservative systems. The code for this paper can be found at https://github.com/sufe-Ran-Zhang/EMMPDE.
<div id='section'>Paperid: <span id='pid'>9, <a href='https://arxiv.org/pdf/2508.19249.pdf' target='_blank'>https://arxiv.org/pdf/2508.19249.pdf</a></span>   <span><a href='https://github.com/MarcusGalea/PhysicsInformedRegression.jl' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas SÃ¸eborg Nielsen, Marcus Galea Jacobsen, Albert Brincker Olson, Mads Peter SÃ¸rensen, Allan Peter Engsig-Karup
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19249">Physics-Informed Regression: Parameter Estimation in Parameter-Linear Nonlinear Dynamic Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a new efficient hybrid parameter estimation method based on the idea, that if nonlinear dynamic models are stated in terms of a system of equations that is linear in terms of the parameters, then regularized ordinary least squares can be used to estimate these parameters from time series data. We introduce the term "Physics-Informed Regression" (PIR) to describe the proposed data-driven hybrid technique as a way to bridge theory and data by use of ordinary least squares to efficiently perform parameter estimation of the model coefficients of different parameter-linear models; providing examples of models based on nonlinear ordinary equations (ODE) and partial differential equations (PDE). The focus is on parameter estimation on a selection of ODE and PDE models, each illustrating performance in different model characteristics. For two relevant epidemic models of different complexity and number of parameters, PIR is tested and compared against the related technique, physics-informed neural networks (PINN), both on synthetic data generated from known target parameters and on real public Danish time series data collected during the COVID-19 pandemic in Denmark. Both methods were able to estimate the target parameters, while PIR showed to perform noticeably better, especially on a compartment model with higher complexity. Given the difference in computational speed, it is concluded that the PIR method is superior to PINN for the models considered. It is also demonstrated how PIR can be applied to estimate the time-varying parameters of a compartment model that is fitted using real Danish data from the COVID-19 pandemic obtained during a period from 2020 to 2021. The study shows how data-driven and physics-informed techniques may support reliable and fast -- possibly real-time -- parameter estimation in parameter-linear nonlinear dynamic models.
<div id='section'>Paperid: <span id='pid'>10, <a href='https://arxiv.org/pdf/2508.16999.pdf' target='_blank'>https://arxiv.org/pdf/2508.16999.pdf</a></span>   <span><a href='https://github.com/yanpeng-gong/PIKAN-MultiMaterial' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanpeng Gong, Yida He, Yue Mei, Xiaoying Zhuang, Fei Qin, Timon Rabczuk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16999">Physics-Informed Kolmogorov-Arnold Networks for multi-material elasticity problems in electronic packaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a Physics-Informed Kolmogorov-Arnold Network (PIKAN) method for analyzing elasticity problems in electronic packaging multi-material structures. The core innovation lies in replacing Multi-Layer Perceptrons (MLPs) with Kolmogorov-Arnold Networks (KANs) within the energy-based Physics-Informed Neural Networks (PINNs) framework. The method constructs admissible displacement fields that automatically satisfy essential boundary conditions and employs various numerical integration schemes to compute loss functions for network optimization. Unlike traditional PINNs that require domain decomposition and penalty terms for multi-material problems, KANs' trainable B-spline activation functions provide inherent piecewise function characteristics that naturally accommodate material property discontinuities. Consequently, this approach requires only a single KAN to achieve accurate approximation across the entire computational domain without subdomain partitioning and interface continuity constraints. Numerical validation demonstrates PIKAN's accuracy and robustness for multi-material elasticity problems. The method maintains high accuracy while significantly reducing computational complexity compared to domain decomposition approaches. Results confirm PIKAN's unique advantages in solving multi-material problems and its significant potential for electronic packaging structure analysis. Source codes are available at https://github.com/yanpeng-gong/PIKAN-MultiMaterial.
<div id='section'>Paperid: <span id='pid'>11, <a href='https://arxiv.org/pdf/2508.12213.pdf' target='_blank'>https://arxiv.org/pdf/2508.12213.pdf</a></span>   <span><a href='https://github.com/rh20624/Awesome-IMU-Sensing,' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yize Cai, Baoshen Guo, Flora Salim, Zhiqing Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12213">Towards Generalizable Human Activity Recognition: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a critical component of Wearable AI, IMU-based Human Activity Recognition (HAR) has attracted increasing attention from both academia and industry in recent years. Although HAR performance has improved considerably in specific scenarios, its generalization capability remains a key barrier to widespread real-world adoption. For example, domain shifts caused by variations in users, sensor positions, or environments can significantly decrease the performance in practice. As a result, in this survey, we explore the rapidly evolving field of IMU-based generalizable HAR, reviewing 229 research papers alongside 25 publicly available datasets to provide a broad and insightful overview. We first present the background and overall framework of IMU-based HAR tasks, as well as the generalization-oriented training settings. Then, we categorize representative methodologies from two perspectives: (i) model-centric approaches, including pre-training method, end-to-end method, and large language model (LLM)-based learning method; and (ii) data-centric approaches, including multi-modal learning and data augmentation techniques. In addition, we summarize widely used datasets in this field, as well as relevant tools and benchmarks. Building on these methodological advances, the broad applicability of IMU-based HAR is also reviewed and discussed. Finally, we discuss persistent challenges (e.g., data scarcity, efficient training, and reliable evaluation) and also outline future directions for HAR, including the adoption of foundation and large language models, physics-informed and context-aware reasoning, generative modeling, and resource-efficient training and inference. The complete list of this survey is available at https://github.com/rh20624/Awesome-IMU-Sensing, which will be updated continuously.
<div id='section'>Paperid: <span id='pid'>12, <a href='https://arxiv.org/pdf/2508.09811.pdf' target='_blank'>https://arxiv.org/pdf/2508.09811.pdf</a></span>   <span><a href='https://github.com/vLAR-group/TRACE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinxi Li, Ziyang Song, Bo Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.09811">TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we aim to model 3D scene geometry, appearance, and physical information just from dynamic multi-view videos in the absence of any human labels. By leveraging physics-informed losses as soft constraints or integrating simple physics models into neural nets, existing works often fail to learn complex motion physics, or doing so requires additional labels such as object types or masks. We propose a new framework named TRACE to model the motion physics of complex dynamic 3D scenes. The key novelty of our method is that, by formulating each 3D point as a rigid particle with size and orientation in space, we directly learn a translation rotation dynamics system for each particle, explicitly estimating a complete set of physical parameters to govern the particle's motion over time. Extensive experiments on three existing dynamic datasets and one newly created challenging synthetic datasets demonstrate the extraordinary performance of our method over baselines in the task of future frame extrapolation. A nice property of our framework is that multiple objects or parts can be easily segmented just by clustering the learned physical parameters.
<div id='section'>Paperid: <span id='pid'>13, <a href='https://arxiv.org/pdf/2508.03776.pdf' target='_blank'>https://arxiv.org/pdf/2508.03776.pdf</a></span>   <span><a href='https://github.com/Event-AHU/OpenFusion' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Wang, Zikang Yan, Hao Si, Zhendong Yang, Qingquan Yang, Dengdi Sun, Wanli Lyu, Jin Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03776">Revisiting Heat Flux Analysis of Tungsten Monoblock Divertor on EAST using Physics-Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating heat flux in the nuclear fusion device EAST is a critically important task. Traditional scientific computing methods typically model this process using the Finite Element Method (FEM). However, FEM relies on grid-based sampling for computation, which is computationally inefficient and hard to perform real-time simulations during actual experiments. Inspired by artificial intelligence-powered scientific computing, this paper proposes a novel Physics-Informed Neural Network (PINN) to address this challenge, significantly accelerating the heat conduction estimation process while maintaining high accuracy. Specifically, given inputs of different materials, we first feed spatial coordinates and time stamps into the neural network, and compute boundary loss, initial condition loss, and physical loss based on the heat conduction equation. Additionally, we sample a small number of data points in a data-driven manner to better fit the specific heat conduction scenario, further enhancing the model's predictive capability. We conduct experiments under both uniform and non-uniform heating conditions on the top surface. Experimental results show that the proposed thermal conduction physics-informed neural network achieves accuracy comparable to the finite element method, while achieving $\times$40 times acceleration in computational efficiency. The dataset and source code will be released on https://github.com/Event-AHU/OpenFusion.
<div id='section'>Paperid: <span id='pid'>14, <a href='https://arxiv.org/pdf/2508.00628.pdf' target='_blank'>https://arxiv.org/pdf/2508.00628.pdf</a></span>   <span><a href='https://github.com/xgxgnpu/SV-SNN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiong Xiong, Zhuo Zhang, Rongchun Hu, Chen Gao, Zichen Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00628">Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving high-frequency oscillatory partial differential equations (PDEs) is a critical challenge in scientific computing, with applications in fluid mechanics, quantum mechanics, and electromagnetic wave propagation. Traditional physics-informed neural networks (PINNs) suffer from spectral bias, limiting their ability to capture high-frequency solution components.  We introduce Separated-Variable Spectral Neural Networks (SV-SNN), a novel framework that addresses these limitations by integrating separation of variables with adaptive spectral methods. Our approach features three key innovations: (1) decomposition of multivariate functions into univariate function products, enabling independent spatial and temporal networks; (2) adaptive Fourier spectral features with learnable frequency parameters for high-frequency capture; and (3) theoretical framework based on singular value decomposition to quantify spectral bias. Comprehensive evaluation on benchmark problems including Heat equation, Helmholtz equation, Poisson equations and Navier-Stokes equations demonstrates that SV-SNN achieves 1-3 orders of magnitude improvement in accuracy while reducing parameter count by over 90\% and training time by 60\%. These results establish SV-SNN as an effective solution to the spectral bias problem in neural PDE solving. The implementation will be made publicly available upon acceptance at https://github.com/xgxgnpu/SV-SNN.
<div id='section'>Paperid: <span id='pid'>15, <a href='https://arxiv.org/pdf/2507.18150.pdf' target='_blank'>https://arxiv.org/pdf/2507.18150.pdf</a></span>   <span><a href='https://github.com/shinychoudhury/physics-informed-nuclear-reactor-unit-commitment-algorithm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiny Choudhury, Michael Davidson, George Tynan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18150">Physics-Informed Unit Commitment Framework for Nuclear Reactors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nuclear reactors are often modeled as inflexible baseload generators with fixed downtimes and restrictive ramping constraints. In practice, however, a reactor's operational flexibility is closely tied to its fuel cycle and associated reactivity margin. A key physical constraint for power maneuverability is xenon poisoning, caused from the transient buildup of neutron-absorbing xenon following a power reduction. This transient can delay or prevent subsequent power ramp-up due to suppressed core reactivity. Additionally, if a reactor is shutdown during periods of low reactivity, restart times can vary significantly, leading to prolonged downtimes. This work introduces a physics-informed modeling framework that embeds fuel cycle dynamics within a unit commitment (UC) formulation. The framework tracks reactivity margin, dynamically enforces xenon induced constraints, and endogenously schedules refueling outages based on core conditions. By capturing intracycle reactivity evolution, the model enables operation dependent nuclear dispatch that reflects both techno-economic requirements and irreducible nuclear physics limits. Application to a representative reactor fleet shows that flexible operation can slow reactivity degradation and extend fuel cycles. Results further demonstrate that different operational modes substantially affect VRE utilization, curtailment, and nuclear fleet capacity factors. These findings highlight the importance of fuel cycle aware flexibility modeling for accurate reactor scheduling and integration of nuclear power into energy system models.
<div id='section'>Paperid: <span id='pid'>16, <a href='https://arxiv.org/pdf/2507.17151.pdf' target='_blank'>https://arxiv.org/pdf/2507.17151.pdf</a></span>   <span><a href='https://github.com/Asatheesh6561/PICore' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Anirudh Satheesh, Anant Khandelwal, Mucong Ding, Radu Balan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.17151">PICore: Physics-Informed Unsupervised Coreset Selection for Data Efficient Neural Operator Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural operators offer a powerful paradigm for solving partial differential equations (PDEs) that cannot be solved analytically by learning mappings between function spaces. However, there are two main bottlenecks in training neural operators: they require a significant amount of training data to learn these mappings, and this data needs to be labeled, which can only be accessed via expensive simulations with numerical solvers. To alleviate both of these issues simultaneously, we propose PICore, an unsupervised coreset selection framework that identifies the most informative training samples without requiring access to ground-truth PDE solutions. PICore leverages a physics-informed loss to select unlabeled inputs by their potential contribution to operator learning. After selecting a compact subset of inputs, only those samples are simulated using numerical solvers to generate labels, reducing annotation costs. We then train the neural operator on the reduced labeled dataset, significantly decreasing training time as well. Across four diverse PDE benchmarks and multiple coreset selection strategies, PICore achieves up to 78% average increase in training efficiency relative to supervised coreset selection methods with minimal changes in accuracy. We provide code at https://github.com/Asatheesh6561/PICore.
<div id='section'>Paperid: <span id='pid'>17, <a href='https://arxiv.org/pdf/2507.12659.pdf' target='_blank'>https://arxiv.org/pdf/2507.12659.pdf</a></span>   <span><a href='https://github.com/LiuzLab/PINN-extrapolation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Athanasios Papastathopoulos-Katsaros, Alexandra Stavrianidi, Zhandong Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.12659">Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are deep learning models that incorporate the governing physical laws of a system into the learning process, making them well-suited for solving complex scientific and engineering problems. Recently, PINNs have gained widespread attention as a powerful framework for combining physical principles with data-driven modeling to improve prediction accuracy. Despite their successes, however, PINNs often exhibit poor extrapolation performance outside the training domain and are highly sensitive to the choice of activation functions (AFs). In this paper, we introduce a transfer learning (TL) method to improve the extrapolation capability of PINNs. Our approach applies transfer learning (TL) within an extended training domain, using only a small number of carefully selected collocation points. Additionally, we propose an adaptive AF that takes the form of a linear combination of standard AFs, which improves both the robustness and accuracy of the model. Through a series of experiments, we demonstrate that our method achieves an average of 40% reduction in relative L2 error and an average of 50% reduction in mean absolute error in the extrapolation domain, all without a significant increase in computational cost. The code is available at https://github.com/LiuzLab/PINN-extrapolation .
<div id='section'>Paperid: <span id='pid'>18, <a href='https://arxiv.org/pdf/2507.09330.pdf' target='_blank'>https://arxiv.org/pdf/2507.09330.pdf</a></span>   <span><a href='https://github.com/linuswalter/WellPINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Linus Walter, Qingkai Kong, Sara Hanson-Hedgecock, VÃ­ctor Vilarrasa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09330">WellPINN: Accurate Well Representation for Transient Fluid Pressure Diffusion in Subsurface Reservoirs with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate representation of wells is essential for reliable reservoir characterization and simulation of operational scenarios in subsurface flow models. Physics-informed neural networks (PINNs) have recently emerged as a promising method for reservoir modeling, offering seamless integration of monitoring data and governing physical equations. However, existing PINN-based studies face major challenges in capturing fluid pressure near wells, particularly during the early stage after injection begins. To address this, we propose WellPINN, a modeling workflow that combines the outputs of multiple sequentially trained PINN models to accurately represent wells. This workflow iteratively approximates the radius of the equivalent well to match the actual well dimensions by decomposing the domain into stepwise shrinking subdomains with a simultaneously reducing equivalent well radius. Our results demonstrate that sequential training of superimposing networks around the pumping well is the first workflow that focuses on accurate inference of fluid pressure from pumping rates throughout the entire injection period, significantly advancing the potential of PINNs for inverse modeling and operational scenario simulations. All data and code for this paper will be made openly available at https://github.com/linuswalter/WellPINN.
<div id='section'>Paperid: <span id='pid'>19, <a href='https://arxiv.org/pdf/2507.01340.pdf' target='_blank'>https://arxiv.org/pdf/2507.01340.pdf</a></span>   <span><a href='https://github.com/cuongle1206/Phys-GRD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Cuong Le, Huy-Phuong Le, Duc Le, Minh-Thien Duong, Van-Binh Nguyen, My-Ha Le
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01340">Physics-informed Ground Reaction Dynamics from Human Motion Capture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Body dynamics are crucial information for the analysis of human motions in important research fields, ranging from biomechanics, sports science to computer vision and graphics. Modern approaches collect the body dynamics, external reactive force specifically, via force plates, synchronizing with human motion capture data, and learn to estimate the dynamics from a black-box deep learning model. Being specialized devices, force plates can only be installed in laboratory setups, imposing a significant limitation on the learning of human dynamics. To this end, we propose a novel method for estimating human ground reaction dynamics directly from the more reliable motion capture data with physics laws and computational simulation as constrains. We introduce a highly accurate and robust method for computing ground reaction forces from motion capture data using Euler's integration scheme and PD algorithm. The physics-based reactive forces are used to inform the learning model about the physics-informed motion dynamics thus improving the estimation accuracy. The proposed approach was tested on the GroundLink dataset, outperforming the baseline model on: 1) the ground reaction force estimation accuracy compared to the force plates measurement; and 2) our simulated root trajectory precision. The implementation code is available at https://github.com/cuongle1206/Phys-GRD
<div id='section'>Paperid: <span id='pid'>20, <a href='https://arxiv.org/pdf/2506.23135.pdf' target='_blank'>https://arxiv.org/pdf/2506.23135.pdf</a></span>   <span><a href='https://github.com/tsinghua-fib-lab/RoboScape' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Shang, Xin Zhang, Yinzhou Tang, Lei Jin, Chen Gao, Wei Wu, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23135">RoboScape: Physics-informed Embodied World Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>World models have become indispensable tools for embodied intelligence, serving as powerful simulators capable of generating realistic robotic videos while addressing critical data scarcity challenges. However, current embodied world models exhibit limited physical awareness, particularly in modeling 3D geometry and motion dynamics, resulting in unrealistic video generation for contact-rich robotic scenarios. In this paper, we present RoboScape, a unified physics-informed world model that jointly learns RGB video generation and physics knowledge within an integrated framework. We introduce two key physics-informed joint training tasks: temporal depth prediction that enhances 3D geometric consistency in video rendering, and keypoint dynamics learning that implicitly encodes physical properties (e.g., object shape and material characteristics) while improving complex motion modeling. Extensive experiments demonstrate that RoboScape generates videos with superior visual fidelity and physical plausibility across diverse robotic scenarios. We further validate its practical utility through downstream applications including robotic policy training with generated data and policy evaluation. Our work provides new insights for building efficient physics-informed world models to advance embodied intelligence research. The code is available at: https://github.com/tsinghua-fib-lab/RoboScape.
<div id='section'>Paperid: <span id='pid'>21, <a href='https://arxiv.org/pdf/2506.07902.pdf' target='_blank'>https://arxiv.org/pdf/2506.07902.pdf</a></span>   <span><a href='https://github.com/sifanexisted/fundiff' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sifan Wang, Zehao Dou, Tong-Rui Liu, Lu Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.07902">FunDiff: Diffusion Models over Function Spaces for Physics-Informed Generative Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in generative modeling -- particularly diffusion models and flow matching -- have achieved remarkable success in synthesizing discrete data such as images and videos. However, adapting these models to physical applications remains challenging, as the quantities of interest are continuous functions governed by complex physical laws. Here, we introduce $\textbf{FunDiff}$, a novel framework for generative modeling in function spaces. FunDiff combines a latent diffusion process with a function autoencoder architecture to handle input functions with varying discretizations, generate continuous functions evaluable at arbitrary locations, and seamlessly incorporate physical priors. These priors are enforced through architectural constraints or physics-informed loss functions, ensuring that generated samples satisfy fundamental physical laws. We theoretically establish minimax optimality guarantees for density estimation in function spaces, showing that diffusion-based estimators achieve optimal convergence rates under suitable regularity conditions. We demonstrate the practical effectiveness of FunDiff across diverse applications in fluid dynamics and solid mechanics. Empirical results show that our method generates physically consistent samples with high fidelity to the target distribution and exhibits robustness to noisy and low-resolution data. Code and datasets are publicly available at https://github.com/sifanexisted/fundiff.
<div id='section'>Paperid: <span id='pid'>22, <a href='https://arxiv.org/pdf/2506.06999.pdf' target='_blank'>https://arxiv.org/pdf/2506.06999.pdf</a></span>   <span><a href='https://github.com/arunshar/Physics-Informed-Diffusion-Probabilistic-Model' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Arun Sharma, Mingzhou Yang, Majid Farhadloo, Subhankar Ghosh, Bharat Jayaprakash, Shashi Shekhar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06999">Towards Physics-informed Diffusion for Anomaly Detection in Trajectories</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given trajectory data, a domain-specific study area, and a user-defined threshold, we aim to find anomalous trajectories indicative of possible GPS spoofing (e.g., fake trajectory). The problem is societally important to curb illegal activities in international waters, such as unauthorized fishing and illicit oil transfers. The problem is challenging due to advances in AI generated in deep fakes generation (e.g., additive noise, fake trajectories) and lack of adequate amount of labeled samples for ground-truth verification. Recent literature shows promising results for anomalous trajectory detection using generative models despite data sparsity. However, they do not consider fine-scale spatiotemporal dependencies and prior physical knowledge, resulting in higher false-positive rates. To address these limitations, we propose a physics-informed diffusion model that integrates kinematic constraints to identify trajectories that do not adhere to physical laws. Experimental results on real-world datasets in the maritime and urban domains show that the proposed framework results in higher prediction accuracy and lower estimation error rate for anomaly detection and trajectory generation methods, respectively. Our implementation is available at https://github.com/arunshar/Physics-Informed-Diffusion-Probabilistic-Model.
<div id='section'>Paperid: <span id='pid'>23, <a href='https://arxiv.org/pdf/2506.04753.pdf' target='_blank'>https://arxiv.org/pdf/2506.04753.pdf</a></span>   <span><a href='https://github.com/iN1k1/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Niki Martinel, Rita Pucci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.04753">Physics Informed Capsule Enhanced Variational AutoEncoder for Underwater Image Enhancement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel dual-stream architecture that achieves state-of-the-art underwater image enhancement by explicitly integrating the Jaffe-McGlamery physical model with capsule clustering-based feature representation learning. Our method simultaneously estimates transmission maps and spatially-varying background light through a dedicated physics estimator while extracting entity-level features via capsule clustering in a parallel stream. This physics-guided approach enables parameter-free enhancement that respects underwater formation constraints while preserving semantic structures and fine-grained details. Our approach also features a novel optimization objective ensuring both physical adherence and perceptual quality across multiple spatial frequencies. To validate our approach, we conducted extensive experiments across six challenging benchmarks. Results demonstrate consistent improvements of $+0.5$dB PSNR over the best existing methods while requiring only one-third of their computational complexity (FLOPs), or alternatively, more than $+1$dB PSNR improvement when compared to methods with similar computational budgets. Code and data \textit{will} be available at https://github.com/iN1k1/.
<div id='section'>Paperid: <span id='pid'>24, <a href='https://arxiv.org/pdf/2505.23863.pdf' target='_blank'>https://arxiv.org/pdf/2505.23863.pdf</a></span>   <span><a href='https://github.com/tsinghua-fib-lab/PhyxMamba' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chang Liu, Bohao Zhao, Jingtao Ding, Huandong Wang, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23863">Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Long-term forecasting of chaotic systems from short-term observations remains a fundamental and underexplored challenge due to the intrinsic sensitivity to initial conditions and the complex geometry of strange attractors. Existing approaches often rely on long-term training data or focus on short-term sequence correlations, struggling to maintain predictive stability and dynamical coherence over extended horizons. We propose PhyxMamba, a novel framework that integrates a Mamba-based state-space model with physics-informed principles to capture the underlying dynamics of chaotic systems. By reconstructing the attractor manifold from brief observations using time-delay embeddings, PhyxMamba extracts global dynamical features essential for accurate forecasting. Our generative training scheme enables Mamba to replicate the physical process, augmented by multi-token prediction and attractor geometry regularization for physical constraints, enhancing prediction accuracy and preserving key statistical invariants. Extensive evaluations on diverse simulated and real-world chaotic systems demonstrate that PhyxMamba delivers superior long-term forecasting and faithfully captures essential dynamical invariants from short-term data. This framework opens new avenues for reliably predicting chaotic systems under observation-scarce conditions, with broad implications across climate science, neuroscience, epidemiology, and beyond. Our code is open-source at https://github.com/tsinghua-fib-lab/PhyxMamba.
<div id='section'>Paperid: <span id='pid'>25, <a href='https://arxiv.org/pdf/2505.13921.pdf' target='_blank'>https://arxiv.org/pdf/2505.13921.pdf</a></span>   <span><a href='https://github.com/hwj20/APEX_EXP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wanjing Huang, Weixiang Yan, Zhen Zhang, Ambuj Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13921">APEX: Empowering LLMs with Physics-Based Task Planning for Real-time Insight</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) demonstrate strong reasoning and task planning capabilities but remain fundamentally limited in physical interaction modeling. Existing approaches integrate perception via Vision-Language Models (VLMs) or adaptive decision-making through Reinforcement Learning (RL), but they fail to capture dynamic object interactions or require task-specific training, limiting their real-world applicability. We introduce APEX (Anticipatory Physics-Enhanced Execution), a framework that equips LLMs with physics-driven foresight for real-time task planning. APEX constructs structured graphs to identify and model the most relevant dynamic interactions in the environment, providing LLMs with explicit physical state updates. Simultaneously, APEX provides low-latency forward simulations of physically feasible actions, allowing LLMs to select optimal strategies based on predictive outcomes rather than static observations. We evaluate APEX on three benchmarks designed to assess perception, prediction, and decision-making: (1) Physics Reasoning Benchmark, testing causal inference and object motion prediction; (2) Tetris, evaluating whether physics-informed prediction enhances decision-making performance in long-horizon planning tasks; (3) Dynamic Obstacle Avoidance, assessing the immediate integration of perception and action feasibility analysis. APEX significantly outperforms standard LLMs and VLM-based models, demonstrating the necessity of explicit physics reasoning for bridging the gap between language-based intelligence and real-world task execution. The source code and experiment setup are publicly available at https://github.com/hwj20/APEX_EXP .
<div id='section'>Paperid: <span id='pid'>26, <a href='https://arxiv.org/pdf/2505.11117.pdf' target='_blank'>https://arxiv.org/pdf/2505.11117.pdf</a></span>   <span><a href='https://github.com/chenhong-zhou/DualBalanced-PINNs' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhong Zhou, Jie Chen, Zaifeng Yang, Ching Eng Png
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11117">Dual-Balancing for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a new learning paradigm for solving partial differential equations (PDEs) by enforcing the constraints of physical equations, boundary conditions (BCs), and initial conditions (ICs) into the loss function. Despite their successes, vanilla PINNs still suffer from poor accuracy and slow convergence due to the intractable multi-objective optimization issue. In this paper, we propose a novel Dual-Balanced PINN (DB-PINN), which dynamically adjusts loss weights by integrating inter-balancing and intra-balancing to alleviate two imbalance issues in PINNs. Inter-balancing aims to mitigate the gradient imbalance between PDE residual loss and condition-fitting losses by determining an aggregated weight that offsets their gradient distribution discrepancies. Intra-balancing acts on condition-fitting losses to tackle the imbalance in fitting difficulty across diverse conditions. By evaluating the fitting difficulty based on the loss records, intra-balancing can allocate the aggregated weight proportionally to each condition loss according to its fitting difficulty level. We further introduce a robust weight update strategy to prevent abrupt spikes and arithmetic overflow in instantaneous weight values caused by large loss variances, enabling smooth weight updating and stable training. Extensive experiments demonstrate that DB-PINN achieves significantly superior performance than those popular gradient-based weighting methods in terms of convergence speed and prediction accuracy. Our code and supplementary material are available at https://github.com/chenhong-zhou/DualBalanced-PINNs.
<div id='section'>Paperid: <span id='pid'>27, <a href='https://arxiv.org/pdf/2505.10930.pdf' target='_blank'>https://arxiv.org/pdf/2505.10930.pdf</a></span>   <span><a href='https://github.com/SCAILab-USTC/PITA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Congcong Zhu, Xiaoyan Xu, Jiayue Han, Jingrun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.10930">Physics-informed Temporal Alignment for Auto-regressive PDE Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Auto-regressive partial differential equation (PDE) foundation models have shown great potential in handling time-dependent data. However, these models suffer from the shortcut problem deeply rooted in auto-regressive prediction, causing error accumulation. The challenge becomes particularly evident for out-of-distribution data, as the pretraining performance may approach random model initialization for downstream tasks with long-term dynamics. To deal with this problem, we propose physics-informed temporal alignment (PITA), a self-supervised learning framework inspired by inverse problem solving. Specifically, PITA aligns the physical dynamics discovered at different time steps on each given PDE trajectory by integrating physics-informed constraints into the self-supervision signal. The alignment is derived from observation data without relying on known physics priors, indicating strong generalization ability to the out-of-distribution data. Extensive experiments show that PITA significantly enhances the accuracy and robustness of existing foundation models on diverse time-dependent PDE data. The code is available at https://github.com/SCAILab-USTC/PITA.
<div id='section'>Paperid: <span id='pid'>28, <a href='https://arxiv.org/pdf/2505.08740.pdf' target='_blank'>https://arxiv.org/pdf/2505.08740.pdf</a></span>   <span><a href='https://github.com/AMBehroozi/SC_Neural_Operators' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdolmehdi Behroozi, Chaopeng Shen and, Daniel Kifer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08740">Sensitivity-Constrained Fourier Neural Operators for Forward and Inverse Problems in Parametric Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Parametric differential equations of the form du/dt = f(u, x, t, p) are fundamental in science and engineering. While deep learning frameworks such as the Fourier Neural Operator (FNO) can efficiently approximate solutions, they struggle with inverse problems, sensitivity estimation (du/dp), and concept drift. We address these limitations by introducing a sensitivity-based regularization strategy, called Sensitivity-Constrained Fourier Neural Operators (SC-FNO). SC-FNO achieves high accuracy in predicting solution paths and consistently outperforms standard FNO and FNO with physics-informed regularization. It improves performance in parameter inversion tasks, scales to high-dimensional parameter spaces (tested with up to 82 parameters), and reduces both data and training requirements. These gains are achieved with a modest increase in training time (30% to 130% per epoch) and generalize across various types of differential equations and neural operators. Code and selected experiments are available at: https://github.com/AMBehroozi/SC_Neural_Operators
<div id='section'>Paperid: <span id='pid'>29, <a href='https://arxiv.org/pdf/2504.16172.pdf' target='_blank'>https://arxiv.org/pdf/2504.16172.pdf</a></span>   <span><a href='https://github.com/Francis-Fan-create/SCaSML' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zexi Fan, Yan Sun, Shihao Yang, Yiping Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16172">Physics-Informed Inference Time Scaling via Simulation-Calibrated Scientific Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-dimensional partial differential equations (PDEs) pose significant computational challenges across fields ranging from quantum chemistry to economics and finance. Although scientific machine learning (SciML) techniques offer approximate solutions, they often suffer from bias and neglect crucial physical insights. Inspired by inference-time scaling strategies in language models, we propose Simulation-Calibrated Scientific Machine Learning (SCaSML), a physics-informed framework that dynamically refines and debiases the SCiML predictions during inference by enforcing the physical laws. SCaSML leverages derived new physical laws that quantifies systematic errors and employs Monte Carlo solvers based on the Feynman-Kac and Elworthy-Bismut-Li formulas to dynamically correct the prediction. Both numerical and theoretical analysis confirms enhanced convergence rates via compute-optimal inference methods. Our numerical experiments demonstrate that SCaSML reduces errors by 20-50% compared to the base surrogate model, establishing it as the first algorithm to refine approximated solutions to high-dimensional PDE during inference. Code of SCaSML is available at https://github.com/Francis-Fan-create/SCaSML.
<div id='section'>Paperid: <span id='pid'>30, <a href='https://arxiv.org/pdf/2504.12675.pdf' target='_blank'>https://arxiv.org/pdf/2504.12675.pdf</a></span>   <span><a href='https://github.com/ptdang1001/MPOCtrL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pengtao Dang, Tingbo Guo, Melissa Fishel, Guang Lin, Wenzhuo Wu, Sha Cao, Chi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.12675">Physics Informed Constrained Learning of Dynamics from Static Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A physics-informed neural network (PINN) models the dynamics of a system by integrating the governing physical laws into the architecture of a neural network. By enforcing physical laws as constraints, PINN overcomes challenges with data scarsity and potentially high dimensionality. Existing PINN frameworks rely on fully observed time-course data, the acquisition of which could be prohibitive for many systems. In this study, we developed a new PINN learning paradigm, namely Constrained Learning, that enables the approximation of first-order derivatives or motions using non-time course or partially observed data. Computational principles and a general mathematical formulation of Constrained Learning were developed. We further introduced MPOCtrL (Message Passing Optimization-based Constrained Learning) an optimization approach tailored for the Constrained Learning framework that strives to balance the fitting of physical models and observed data. Its code is available at github link: https://github.com/ptdang1001/MPOCtrL Experiments on synthetic and real-world data demonstrated that MPOCtrL can effectively detect the nonlinear dependency between observed data and the underlying physical properties of the system. In particular, on the task of metabolic flux analysis, MPOCtrL outperforms all existing data-driven flux estimators.
<div id='section'>Paperid: <span id='pid'>31, <a href='https://arxiv.org/pdf/2504.07976.pdf' target='_blank'>https://arxiv.org/pdf/2504.07976.pdf</a></span>   <span><a href='https://github.com/HamidrezaEiv/EquiNO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hamidreza Eivazi, Jendrik-Alexander TrÃ¶ger, Stefan Wittek, Stefan Hartmann, Andreas Rausch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07976">EquiNO: A Physics-Informed Neural Operator for Multiscale Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiscale problems are ubiquitous in physics. Numerical simulations of such problems by solving partial differential equations (PDEs) at high resolution are computationally too expensive for many-query scenarios, e.g., uncertainty quantification, remeshing applications, topology optimization, and so forth. This limitation has motivated the application of data-driven surrogate models, where the microscale computations are $\textit{substituted}$ with a surrogate, usually acting as a black-box mapping between macroscale quantities. These models offer significant speedups but struggle with incorporating microscale physical constraints, such as the balance of linear momentum and constitutive models. In this contribution, we propose Equilibrium Neural Operator (EquiNO) as a $\textit{complementary}$ physics-informed PDE surrogate for predicting microscale physics and compare it with variational physics-informed neural and operator networks. Our framework, applicable to the so-called multiscale FE$^{\,2}\,$ computations, introduces the FE-OL approach by integrating the finite element (FE) method with operator learning (OL). We apply the proposed FE-OL approach to quasi-static problems of solid mechanics. The results demonstrate that FE-OL can yield accurate solutions even when confronted with a restricted dataset during model development. Our results show that EquiNO achieves speedup factors exceeding 8000-fold compared to traditional methods and offers an optimal balance between data-driven and physics-based strategies.
<div id='section'>Paperid: <span id='pid'>32, <a href='https://arxiv.org/pdf/2504.05830.pdf' target='_blank'>https://arxiv.org/pdf/2504.05830.pdf</a></span>   <span><a href='https://github.com/Event-AHU/HARDVS/tree/HARDVSv2' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiao Wang, Xiao Wang, Bo Jiang, Lin Zhu, Guoqi Li, Yaowei Wang, Yonghong Tian, Jin Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.05830">Human Activity Recognition using RGB-Event based Sensors: A Multi-modal Heat Conduction Model and A Benchmark Dataset</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human Activity Recognition (HAR) primarily relied on traditional RGB cameras to achieve high-performance activity recognition. However, the challenging factors in real-world scenarios, such as insufficient lighting and rapid movements, inevitably degrade the performance of RGB cameras. To address these challenges, biologically inspired event cameras offer a promising solution to overcome the limitations of traditional RGB cameras. In this work, we rethink human activity recognition by combining the RGB and event cameras. The first contribution is the proposed large-scale multi-modal RGB-Event human activity recognition benchmark dataset, termed HARDVS 2.0, which bridges the dataset gaps. It contains 300 categories of everyday real-world actions with a total of 107,646 paired videos covering various challenging scenarios. Inspired by the physics-informed heat conduction model, we propose a novel multi-modal heat conduction operation framework for effective activity recognition, termed MMHCO-HAR. More in detail, given the RGB frames and event streams, we first extract the feature embeddings using a stem network. Then, multi-modal Heat Conduction blocks are designed to fuse the dual features, the key module of which is the multi-modal Heat Conduction Operation layer. We integrate RGB and event embeddings through a multi-modal DCT-IDCT layer while adaptively incorporating the thermal conductivity coefficient via FVEs into this module. After that, we propose an adaptive fusion module based on a policy routing strategy for high-performance classification. Comprehensive experiments demonstrate that our method consistently performs well, validating its effectiveness and robustness. The source code and benchmark dataset will be released on https://github.com/Event-AHU/HARDVS/tree/HARDVSv2
<div id='section'>Paperid: <span id='pid'>33, <a href='https://arxiv.org/pdf/2503.23167.pdf' target='_blank'>https://arxiv.org/pdf/2503.23167.pdf</a></span>   <span><a href='https://github.com/Emory-Melody/Awesome-Graph-NDEs' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zewen Liu, Xiaoda Wang, Bohan Wang, Zijie Huang, Carl Yang, Wei Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.23167">Graph ODEs and Beyond: A Comprehensive Survey on Integrating Differential Equations with Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) and differential equations (DEs) are two rapidly advancing areas of research that have shown remarkable synergy in recent years. GNNs have emerged as powerful tools for learning on graph-structured data, while differential equations provide a principled framework for modeling continuous dynamics across time and space. The intersection of these fields has led to innovative approaches that leverage the strengths of both, enabling applications in physics-informed learning, spatiotemporal modeling, and scientific computing. This survey aims to provide a comprehensive overview of the burgeoning research at the intersection of GNNs and DEs. We will categorize existing methods, discuss their underlying principles, and highlight their applications across domains such as molecular modeling, traffic prediction, and epidemic spreading. Furthermore, we identify open challenges and outline future research directions to advance this interdisciplinary field. A comprehensive paper list is provided at https://github.com/Emory-Melody/Awesome-Graph-NDEs. This survey serves as a resource for researchers and practitioners seeking to understand and contribute to the fusion of GNNs and DEs
<div id='section'>Paperid: <span id='pid'>34, <a href='https://arxiv.org/pdf/2503.08929.pdf' target='_blank'>https://arxiv.org/pdf/2503.08929.pdf</a></span>   <span><a href='https://github.com/HrishikeshVish/HessianForge/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hrishikesh Viswanath, Md Ashiqur Rahman, Chi Lin, Damon Conover, Aniket Bera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08929">HessianForge: Scalable LiDAR reconstruction with Physics-Informed Neural Representation and Smoothness Energy Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and efficient 3D mapping of large-scale outdoor environments from LiDAR measurements is a fundamental challenge in robotics, particularly towards ensuring smooth and artifact-free surface reconstructions. Although the state-of-the-art methods focus on memory-efficient neural representations for high-fidelity surface generation, they often fail to produce artifact-free manifolds, with artifacts arising due to noisy and sparse inputs. To address this issue, we frame surface mapping as a physics-informed energy optimization problem, enforcing surface smoothness by optimizing an energy functional that penalizes sharp surface ridges. Specifically, we propose a deep learning based approach that learns the signed distance field (SDF) of the surface manifold from raw LiDAR point clouds using a physics-informed loss function that optimizes the $L_2$-Hessian energy of the surface. Our learning framework includes a hierarchical octree based input feature encoding and a multi-scale neural network to iteratively refine the signed distance field at different scales of resolution. Lastly, we introduce a test-time refinement strategy to correct topological inconsistencies and edge distortions that can arise in the generated mesh. We propose a \texttt{CUDA}-accelerated least-squares optimization that locally adjusts vertex positions to enforce feature-preserving smoothing. We evaluate our approach on large-scale outdoor datasets and demonstrate that our approach outperforms current state-of-the-art methods in terms of improved accuracy and smoothness. Our code is available at \href{https://github.com/HrishikeshVish/HessianForge/}{https://github.com/HrishikeshVish/HessianForge/}
<div id='section'>Paperid: <span id='pid'>35, <a href='https://arxiv.org/pdf/2503.08121.pdf' target='_blank'>https://arxiv.org/pdf/2503.08121.pdf</a></span>   <span><a href='https://github.com/agvpreid25/AG-VPReID-Net' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Huy Nguyen, Kien Nguyen, Akila Pemasiri, Feng Liu, Sridha Sridharan, Clinton Fookes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08121">AG-VPReID: A Challenging Large-Scale Benchmark for Aerial-Ground Video-based Person Re-Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce AG-VPReID, a new large-scale dataset for aerial-ground video-based person re-identification (ReID) that comprises 6,632 subjects, 32,321 tracklets and over 9.6 million frames captured by drones (altitudes ranging from 15-120m), CCTV, and wearable cameras. This dataset offers a real-world benchmark for evaluating the robustness to significant viewpoint changes, scale variations, and resolution differences in cross-platform aerial-ground settings. In addition, to address these challenges, we propose AG-VPReID-Net, an end-to-end framework composed of three complementary streams: (1) an Adapted Temporal-Spatial Stream addressing motion pattern inconsistencies and facilitating temporal feature learning, (2) a Normalized Appearance Stream leveraging physics-informed techniques to tackle resolution and appearance changes, and (3) a Multi-Scale Attention Stream handling scale variations across drone altitudes. We integrate visual-semantic cues from all streams to form a robust, viewpoint-invariant whole-body representation. Extensive experiments demonstrate that AG-VPReID-Net outperforms state-of-the-art approaches on both our new dataset and existing video-based ReID benchmarks, showcasing its effectiveness and generalizability. Nevertheless, the performance gap observed on AG-VPReID across all methods underscores the dataset's challenging nature. The dataset, code and trained models are available at https://github.com/agvpreid25/AG-VPReID-Net.
<div id='section'>Paperid: <span id='pid'>36, <a href='https://arxiv.org/pdf/2502.19290.pdf' target='_blank'>https://arxiv.org/pdf/2502.19290.pdf</a></span>   <span><a href='https://github.com/PhysicsSolver/PhysicsSolver' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenyi Zhu, Yuchen Huang, Liu Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19290">PhysicsSolver: Transformer-Enhanced Physics-Informed Neural Networks for Forward and Forecasting Problems in Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time-dependent partial differential equations are a significant class of equations that describe the evolution of various physical phenomena over time. One of the open problems in scientific computing is predicting the behaviour of the solution outside the given temporal region. Most traditional numerical methods are applied to a given time-space region and can only accurately approximate the solution of the given region. To address this problem, many deep learning-based methods, basically data-driven and data-free approaches, have been developed to solve these problems. However, most data-driven methods require a large amount of data, which consumes significant computational resources and fails to utilize all the necessary information embedded underlying the partial differential equations (PDEs). Moreover, data-free approaches such as Physics-Informed Neural Networks (PINNs) may not be that ideal in practice, as traditional PINNs, which primarily rely on multilayer perceptrons (MLPs) and convolutional neural networks (CNNs), tend to overlook the crucial temporal dependencies inherent in real-world physical systems. We propose a method denoted as \textbf{PhysicsSolver} that merges the strengths of two approaches: data-free methods that can learn the intrinsic properties of physical systems without using data, and data-driven methods, which are effective at making predictions. Extensive numerical experiments have demonstrated the efficiency and robustness of our proposed method. We provide the code at \href{https://github.com/PhysicsSolver/PhysicsSolver}{https://github.com/PhysicsSolver}.
<div id='section'>Paperid: <span id='pid'>37, <a href='https://arxiv.org/pdf/2502.17497.pdf' target='_blank'>https://arxiv.org/pdf/2502.17497.pdf</a></span>   <span><a href='https://github.com/zhizhi4452/HCS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yushi Zhang, Shuai Su, Yong Wang, Yanzhong Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.17497">Hard constraint learning approaches with trainable influence functions for evolutionary equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper develops a novel deep learning approach for solving evolutionary equations, which integrates sequential learning strategies with an enhanced hard constraint strategy featuring trainable parameters, addressing the low computational accuracy of standard Physics-Informed Neural Networks (PINNs) in large temporal domains.Sequential learning strategies divide a large temporal domain into multiple subintervals and solve them one by one in a chronological order, which naturally respects the principle of causality and improves the stability of the PINN solution. The improved hard constraint strategy strictly ensures the continuity and smoothness of the PINN solution at time interval nodes, and at the same time passes the information from the previous interval to the next interval, which avoids the incorrect/trivial solution at the position far from the initial time. Furthermore, by investigating the requirements of different types of equations on hard constraints, we design a novel influence function with trainable parameters for hard constraints, which provides theoretical and technical support for the effective implementations of hard constraint strategies, and significantly improves the universality and computational accuracy of our method. In addition, an adaptive time-domain partitioning algorithm is proposed, which plays an important role in the application of the proposed method as well as in the improvement of computational efficiency and accuracy. Numerical experiments verify the performance of the method. The data and code accompanying this paper are available at https://github.com/zhizhi4452/HCS.
<div id='section'>Paperid: <span id='pid'>38, <a href='https://arxiv.org/pdf/2502.09296.pdf' target='_blank'>https://arxiv.org/pdf/2502.09296.pdf</a></span>   <span><a href='https://github.com/mosaf/PI-MoCoNet.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mojtaba Safari, Shansong Wang, Zach Eidex, Richard Qiu, Chih-Wei Chang, David S. Yu, Xiaofeng Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09296">A Physics-Informed Deep Learning Model for MRI Brain Motion Correction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: MRI is crucial for brain imaging but is highly susceptible to motion artifacts due to long acquisition times. This study introduces PI-MoCoNet, a physics-informed motion correction network that integrates spatial and k-space information to remove motion artifacts without explicit motion parameter estimation, enhancing image fidelity and diagnostic reliability. Materials and Methods: PI-MoCoNet consists of a motion detection network (U-net with spatial averaging) to identify corrupted k-space lines and a motion correction network (U-net with Swin Transformer blocks) to reconstruct motion-free images. The correction is guided by three loss functions: reconstruction (L1), perceptual (LPIPS), and data consistency (Ldc). Motion artifacts were simulated via rigid phase encoding perturbations and evaluated on IXI and MR-ART datasets against Pix2Pix, CycleGAN, and U-net using PSNR, SSIM, and NMSE. Results: PI-MoCoNet significantly improved image quality. On IXI, for minor artifacts, PSNR increased from 34.15 dB to 45.95 dB, SSIM from 0.87 to 1.00, and NMSE reduced from 0.55% to 0.04%. For moderate artifacts, PSNR improved from 30.23 dB to 42.16 dB, SSIM from 0.80 to 0.99, and NMSE from 1.32% to 0.09%. For heavy artifacts, PSNR rose from 27.99 dB to 36.01 dB, SSIM from 0.75 to 0.97, and NMSE decreased from 2.21% to 0.36%. On MR-ART, PI-MoCoNet achieved PSNR gains of ~10 dB and SSIM improvements of up to 0.20, with NMSE reductions of ~6%. Ablation studies confirmed the importance of data consistency and perceptual losses, yielding a 1 dB PSNR gain and 0.17% NMSE reduction. Conclusions: PI-MoCoNet effectively mitigates motion artifacts in brain MRI, outperforming existing methods. Its ability to integrate spatial and k-space information makes it a promising tool for clinical use in motion-prone settings. Code: https://github.com/mosaf/PI-MoCoNet.git.
<div id='section'>Paperid: <span id='pid'>39, <a href='https://arxiv.org/pdf/2502.04018.pdf' target='_blank'>https://arxiv.org/pdf/2502.04018.pdf</a></span>   <span><a href='https://github.com/KV-Park' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Keonvin Park, Jisu Kim, Jaemin Seo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04018">PINT: Physics-Informed Neural Time Series Models with Applications to Long-term Inference on WeatherBench 2m-Temperature Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces PINT (Physics-Informed Neural Time Series Models), a framework that integrates physical constraints into neural time series models to improve their ability to capture complex dynamics. We apply PINT to the ERA5 WeatherBench dataset, focusing on long-term forecasting of 2m-temperature data. PINT incorporates the Simple Harmonic Oscillator Equation as a physics-informed prior, embedding its periodic dynamics into RNN, LSTM, and GRU architectures. This equation's analytical solutions (sine and cosine functions) facilitate rigorous evaluation of the benefits of incorporating physics-informed constraints. By benchmarking against a linear regression baseline derived from its exact solutions, we quantify the impact of embedding physical principles in data-driven models. Unlike traditional time series models that rely on future observations, PINT is designed for practical forecasting. Using only the first 90 days of observed data, it iteratively predicts the next two years, addressing challenges posed by limited real-time updates. Experiments on the WeatherBench dataset demonstrate PINT's ability to generalize, capture periodic trends, and align with physical principles. This study highlights the potential of physics-informed neural models in bridging machine learning and interpretable climate applications.
  Our models and datasets are publicly available on GitHub: https://github.com/KV-Park.
<div id='section'>Paperid: <span id='pid'>40, <a href='https://arxiv.org/pdf/2502.00318.pdf' target='_blank'>https://arxiv.org/pdf/2502.00318.pdf</a></span>   <span><a href='https://github.com/miniHuiHui/PINNMamba' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhui Xu, Dancheng Liu, Yuting Hu, Jiajie Li, Ruiyang Qin, Qingxiao Zheng, Jinjun Xiong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00318">Sub-Sequential Physics-Informed Learning with State Space Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are a kind of deep-learning-based numerical solvers for partial differential equations (PDEs). Existing PINNs often suffer from failure modes of being unable to propagate patterns of initial conditions. We discover that these failure modes are caused by the simplicity bias of neural networks and the mismatch between PDE's continuity and PINN's discrete sampling. We reveal that the State Space Model (SSM) can be a continuous-discrete articulation allowing initial condition propagation, and that simplicity bias can be eliminated by aligning a sequence of moderate granularity. Accordingly, we propose PINNMamba, a novel framework that introduces sub-sequence modeling with SSM. Experimental results show that PINNMamba can reduce errors by up to 86.3\% compared with state-of-the-art architecture. Our code is available at https://github.com/miniHuiHui/PINNMamba.
<div id='section'>Paperid: <span id='pid'>41, <a href='https://arxiv.org/pdf/2501.18582.pdf' target='_blank'>https://arxiv.org/pdf/2501.18582.pdf</a></span>   <span><a href='https://github.com/haoming-SHEN/Accuracy-and-Robustness-of-Weight-Balancing-Methods-for-Training-PINNs.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthieu Barreau, Haoming Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18582">Accuracy and Robustness of Weight-Balancing Methods for Training PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as powerful tools for integrating physics-based models with data by minimizing both data and physics losses. However, this multi-objective optimization problem is notoriously challenging, with some benchmark problems leading to unfeasible solutions. To address these issues, various strategies have been proposed, including adaptive weight adjustments in the loss function. In this work, we introduce clear definitions of accuracy and robustness in the context of PINNs and propose a novel training algorithm based on the Primal-Dual (PD) optimization framework. Our approach enhances the robustness of PINNs while maintaining comparable performance to existing weight-balancing methods. Numerical experiments demonstrate that the PD method consistently achieves reliable solutions across all investigated cases, even in the low-data regime, and can be easily implemented, facilitating its practical adoption. The code is available at https://github.com/haoming-SHEN/Accuracy-and-Robustness-of-Weight-Balancing-Methods-for-Training-PINNs.git.
<div id='section'>Paperid: <span id='pid'>42, <a href='https://arxiv.org/pdf/2501.06081.pdf' target='_blank'>https://arxiv.org/pdf/2501.06081.pdf</a></span>   <span><a href='https://github.com/deeplearningmethods/averaged-adam' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Steffen Dereich, Arnulf Jentzen, Adrian Riekert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06081">Averaged Adam accelerates stochastic optimization in the training of deep neural network approximations for partial differential equation and optimal control problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning methods - usually consisting of a class of deep neural networks (DNNs) trained by a stochastic gradient descent (SGD) optimization method - are nowadays omnipresent in data-driven learning problems as well as in scientific computing tasks such as optimal control (OC) and partial differential equation (PDE) problems. In practically relevant learning tasks, often not the plain-vanilla standard SGD optimization method is employed to train the considered class of DNNs but instead more sophisticated adaptive and accelerated variants of the standard SGD method such as the popular Adam optimizer are used. Inspired by the classical Polyak-Ruppert averaging approach, in this work we apply averaged variants of the Adam optimizer to train DNNs to approximately solve exemplary scientific computing problems in the form of PDEs and OC problems. We test the averaged variants of Adam in a series of learning problems including physics-informed neural network (PINN), deep backward stochastic differential equation (deep BSDE), and deep Kolmogorov approximations for PDEs (such as heat, Black-Scholes, Burgers, and Allen-Cahn PDEs), including DNN approximations for OC problems, and including DNN approximations for image classification problems (ResNet for CIFAR-10). In each of the numerical examples the employed averaged variants of Adam outperform the standard Adam and the standard SGD optimizers, particularly, in the situation of the scientific machine learning problems. The Python source codes for the numerical experiments associated to this work can be found on GitHub at https://github.com/deeplearningmethods/averaged-adam.
<div id='section'>Paperid: <span id='pid'>43, <a href='https://arxiv.org/pdf/2501.04366.pdf' target='_blank'>https://arxiv.org/pdf/2501.04366.pdf</a></span>   <span><a href='https://github.com/liufeng2317/DispFormer' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Feng Liu, Bao Deng, Rui Su, Lei Bai, Wanli Ouyang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.04366">DispFormer: A Pretrained Transformer Incorporating Physical Constraints for Dispersion Curve Inversion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Surface wave dispersion curve inversion is crucial for estimating subsurface shear-wave velocity (vs), yet traditional methods often face challenges related to computational cost, non-uniqueness, and sensitivity to initial models. While deep learning approaches show promise, many require large labeled datasets and struggle with real-world datasets, which often exhibit varying period ranges, missing values, and low signal-to-noise ratios. To address these limitations, this study introduces DispFormer, a transformer-based neural network for $v_s$ profile inversion from Rayleigh-wave phase and group dispersion curves. DispFormer processes dispersion data independently at each period, allowing it to handle varying lengths without requiring network modifications or strict alignment between training and testing datasets. A depth-aware training strategy is also introduced, incorporating physical constraints derived from the depth sensitivity of dispersion data. DispFormer is pre-trained on a global synthetic dataset and evaluated on two regional synthetic datasets using zero-shot and few-shot strategies. Results show that even without labeled data, the zero-shot DispFormer generates inversion profiles that outperform the interpolated reference model used as the pretraining target, providing a deployable initial model generator to assist traditional workflows. When partial labeled data available, the few-shot trained DispFormer surpasses traditional global search methods. Real-world tests further confirm that DispFormer generalizes well to dispersion data with varying lengths and achieves lower data residuals than reference models. These findings underscore the potential of DispFormer as a foundation model for dispersion curve inversion and demonstrate the advantages of integrating physics-informed deep learning into geophysical applications.
<div id='section'>Paperid: <span id='pid'>44, <a href='https://arxiv.org/pdf/2412.09752.pdf' target='_blank'>https://arxiv.org/pdf/2412.09752.pdf</a></span>   <span><a href='https://github.com/kyrochi/n\_tangentprop' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kyle R. Chickering
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09752">A Quasilinear Algorithm for Computing Higher-Order Derivatives of Deep Feed-Forward Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The use of neural networks for solving differential equations is practically difficult due to the exponentially increasing runtime of autodifferentiation when computing high-order derivatives. We propose $n$-TangentProp, the natural extension of the TangentProp formalism \cite{simard1991tangent} to arbitrarily many derivatives. $n$-TangentProp computes the exact derivative $d^n/dx^n f(x)$ in quasilinear, instead of exponential time, for a densely connected, feed-forward neural network $f$ with a smooth, parameter-free activation function. We validate our algorithm empirically across a range of depths, widths, and number of derivatives. We demonstrate that our method is particularly beneficial in the context of physics-informed neural networks where \ntp allows for significantly faster training times than previous methods and has favorable scaling with respect to both model size and loss-function complexity as measured by the number of required derivatives. The code for this paper can be found at https://github.com/kyrochi/n\_tangentprop.
<div id='section'>Paperid: <span id='pid'>45, <a href='https://arxiv.org/pdf/2412.09009.pdf' target='_blank'>https://arxiv.org/pdf/2412.09009.pdf</a></span>   <span><a href='https://github.com/quest-lab-iisc/PINTO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sumanth Kumar Boya, Deepak Subramani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09009">A physics-informed transformer neural operator for learning generalized solutions of initial boundary value problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Initial boundary value problems arise commonly in applications with engineering and natural systems governed by nonlinear partial differential equations (PDEs). Operator learning is an emerging field for solving these equations by using a neural network to learn a map between infinite dimensional input and output function spaces. These neural operators are trained using a combination of data (observations or simulations) and PDE-residuals (physics-loss). A major drawback of existing neural approaches is the requirement to retrain with new initial/boundary conditions, and the necessity for a large amount of simulation data for training. We develop a physics-informed transformer neural operator (named PINTO) that efficiently generalizes to unseen initial and boundary conditions, trained in a simulation-free setting using only physics loss. The main innovation lies in our new iterative kernel integral operator units, implemented using cross-attention, to transform the PDE solution's domain points into an initial/boundary condition-aware representation vector, enabling efficient learning of the solution function for new scenarios. The PINTO architecture is applied to simulate the solutions of important equations used in engineering applications: advection, Burgers, and steady and unsteady Navier-Stokes equations (three flow scenarios). For these five test cases, we show that the relative errors during testing under challenging conditions of unseen initial/boundary conditions are only one-fifth to one-third of other leading physics informed operator learning methods. Moreover, our PINTO model is able to accurately solve the advection and Burgers equations at time steps that are not included in the training collocation points. The code is available at https://github.com/quest-lab-iisc/PINTO
<div id='section'>Paperid: <span id='pid'>46, <a href='https://arxiv.org/pdf/2412.00994.pdf' target='_blank'>https://arxiv.org/pdf/2412.00994.pdf</a></span>   <span><a href='https://github.com/ahmad-shirazi/DSSRNN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmad Mohammadshirazi, Pinaki Prasad Guha Neogi, Rajiv Ramnath
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00994">PIAD-SRNN: Physics-Informed Adaptive Decomposition in State-Space RNN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time series forecasting often demands a trade-off between accuracy and efficiency. While recent Transformer models have improved forecasting capabilities, they come with high computational costs. Linear-based models have shown better accuracy than Transformers but still fall short of ideal performance. We propose PIAD-SRNN, a physics-informed adaptive decomposition state-space RNN, that separates seasonal and trend components and embeds domain equations in a recurrent framework. We evaluate PIAD-SRNN's performance on indoor air quality datasets, focusing on CO2 concentration prediction across various forecasting horizons, and results demonstrate that it consistently outperforms SoTA models in both long-term and short-term time series forecasting, including transformer-based architectures, in terms of both MSE and MAE. Besides proposing PIAD-SRNN which balances accuracy with efficiency, this paper also provides four curated datasets. Code and data: https://github.com/ahmad-shirazi/DSSRNN
<div id='section'>Paperid: <span id='pid'>47, <a href='https://arxiv.org/pdf/2411.19632.pdf' target='_blank'>https://arxiv.org/pdf/2411.19632.pdf</a></span>   <span><a href='https://github.com/CoenVisser/PACMANN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Coen Visser, Alexander Heinlein, Bianca Giovanardi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.19632">PACMANN: Point Adaptive Collocation Method for Artificial Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a tool for approximating the solution of Partial Differential Equations (PDEs) in both forward and inverse problems. PINNs minimize a loss function which includes the PDE residual determined for a set of collocation points. Previous work has shown that the number and distribution of these collocation points have a significant influence on the accuracy of the PINN solution. Therefore, the effective placement of these collocation points is an active area of research. Specifically, available adaptive collocation point sampling methods have been reported to scale poorly in terms of computational cost when applied to high-dimensional problems. In this work, we address this issue and present the Point Adaptive Collocation Method for Artificial Neural Networks (PACMANN). PACMANN incrementally moves collocation points toward regions of higher residuals using gradient-based optimization algorithms guided by the gradient of the PINN loss function, that is, the squared PDE residual. We apply PACMANN for forward and inverse problems, and demonstrate that this method matches the performance of state-of-the-art methods in terms of the accuracy/efficiency tradeoff for the low-dimensional problems, while outperforming available approaches for high-dimensional problems. Key features of the method include its low computational cost and simplicity of integration into existing physics-informed neural network pipelines. The code is available at https://github.com/CoenVisser/PACMANN.
<div id='section'>Paperid: <span id='pid'>48, <a href='https://arxiv.org/pdf/2411.16663.pdf' target='_blank'>https://arxiv.org/pdf/2411.16663.pdf</a></span>   <span><a href='https://github.com/Jimmy000207/Boundary-EPGP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianlei Huang, Marc HÃ¤rkÃ¶nen, Markus Lange-Hegermann, Bogdan RaiÅ£Ä
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16663">Gaussian Process Priors for Boundary Value Problems of Linear Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving systems of partial differential equations (PDEs) is a fundamental task in computational science, traditionally addressed by numerical solvers. Recent advancements have introduced neural operators and physics-informed neural networks (PINNs) to tackle PDEs, achieving reduced computational costs at the expense of solution quality and accuracy. Gaussian processes (GPs) have also been applied to linear PDEs, with the advantage of always yielding precise solutions. In this work, we propose Boundary Ehrenpreis-Palamodov Gaussian Processes (B-EPGPs), a novel framework for constructing GP priors that satisfy both general systems of linear PDEs with constant coefficients and linear boundary conditions. We explicitly construct GP priors for representative PDE systems with practical boundary conditions. Formal proofs of correctness are provided and empirical results demonstrating significant accuracy improvements over state-of-the-art neural operator approaches.
<div id='section'>Paperid: <span id='pid'>49, <a href='https://arxiv.org/pdf/2411.08378.pdf' target='_blank'>https://arxiv.org/pdf/2411.08378.pdf</a></span>   <span><a href='https://github.com/pantheon5100/pid_diffusion.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Joshua Tian Jin Tee, Kang Zhang, Hee Suk Yoon, Dhananjaya Nagaraja Gowda, Chanwoo Kim, Chang D. Yoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08378">Physics Informed Distillation for Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have recently emerged as a potent tool in generative modeling. However, their inherent iterative nature often results in sluggish image generation due to the requirement for multiple model evaluations. Recent progress has unveiled the intrinsic link between diffusion models and Probability Flow Ordinary Differential Equations (ODEs), thus enabling us to conceptualize diffusion models as ODE systems. Simultaneously, Physics Informed Neural Networks (PINNs) have substantiated their effectiveness in solving intricate differential equations through implicit modeling of their solutions. Building upon these foundational insights, we introduce Physics Informed Distillation (PID), which employs a student model to represent the solution of the ODE system corresponding to the teacher diffusion model, akin to the principles employed in PINNs. Through experiments on CIFAR 10 and ImageNet 64x64, we observe that PID achieves performance comparable to recent distillation methods. Notably, it demonstrates predictable trends concerning method-specific hyperparameters and eliminates the need for synthetic dataset generation during the distillation process. Both of which contribute to its easy-to-use nature as a distillation approach for Diffusion Models. Our code and pre-trained checkpoint are publicly available at: https://github.com/pantheon5100/pid_diffusion.git.
<div id='section'>Paperid: <span id='pid'>50, <a href='https://arxiv.org/pdf/2411.05867.pdf' target='_blank'>https://arxiv.org/pdf/2411.05867.pdf</a></span>   <span><a href='https://github.com/AJS50/Hybrid_RC_for_NLONS_paper_code' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Shannon, Conor Houghton, David Barton, Martin Homer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05867">Modeling Nonlinear Oscillator Networks Using Physics-Informed Hybrid Reservoir Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Surrogate modeling of non-linear oscillator networks remains challenging due to discrepancies between simplified analytical models and real-world complexity. To bridge this gap, we investigate hybrid reservoir computing, combining reservoir computing with "expert" analytical models. Simulating the absence of an exact model, we first test the surrogate models with parameter errors in their expert model. Second, in a residual physics task, we assess their performance when their expert model lacks key non-linear coupling terms present in an extended ground-truth model. We focus on short-term forecasting across diverse dynamical regimes, evaluating the use of these surrogates for control applications. We show that hybrid reservoir computers generally outperform standard reservoir computers and exhibit greater robustness to parameter tuning. This advantage is less pronounced in the residual physics task. Notably, unlike standard reservoir computers, the performance of the hybrid does not degrade when crossing an observed spectral radius threshold. Furthermore, there is good performance for dynamical regimes not accessible to the expert model, demonstrating the contribution of the reservoir.
<div id='section'>Paperid: <span id='pid'>51, <a href='https://arxiv.org/pdf/2411.03671.pdf' target='_blank'>https://arxiv.org/pdf/2411.03671.pdf</a></span>   <span><a href='https://github.com/JinshuaiBai/energy_PINN_Contact.(The' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinshuai Bai, Zhongya Lin, Yizheng Wang, Jiancong Wen, Yinghua Liu, Timon Rabczuk, YuanTong Gu, Xi-Qiao Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.03671">Energy-based physics-informed neural network for frictionless contact problems under large deformation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Numerical methods for contact mechanics are of great importance in engineering applications, enabling the prediction and analysis of complex surface interactions under various conditions. In this work, we propose an energy-based physics-informed neural network (PINNs) framework for solving frictionless contact problems under large deformation. Inspired by microscopic Lennard-Jones potential, a surface contact energy is used to describe the contact phenomena. To ensure the robustness of the proposed PINN framework, relaxation, gradual loading and output scaling techniques are introduced. In the numerical examples, the well-known Hertz contact benchmark problem is conducted, demonstrating the effectiveness and robustness of the proposed PINNs framework. Moreover, challenging contact problems with the consideration of geometrical and material nonlinearities are tested. It has been shown that the proposed PINNs framework provides a reliable and powerful tool for nonlinear contact mechanics. More importantly, the proposed PINNs framework exhibits competitive computational efficiency to the commercial FEM software when dealing with those complex contact problems. The codes used in this manuscript are available at https://github.com/JinshuaiBai/energy_PINN_Contact.(The code will be available after acceptance)
<div id='section'>Paperid: <span id='pid'>52, <a href='https://arxiv.org/pdf/2410.19759.pdf' target='_blank'>https://arxiv.org/pdf/2410.19759.pdf</a></span>   <span><a href='https://github.com/cgalaz01/supinn' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Christoforos Galazis, Ching-En Chiu, Tomoki Arichi, Anil A. Bharath, Marta Varela
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19759">PINNing Cerebral Blood Flow: Analysis of Perfusion MRI in Infants using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Arterial spin labeling (ASL) magnetic resonance imaging (MRI) enables cerebral perfusion measurement, which is crucial in detecting and managing neurological issues in infants born prematurely or after perinatal complications. However, cerebral blood flow (CBF) estimation in infants using ASL remains challenging due to the complex interplay of network physiology, involving dynamic interactions between cardiac output and cerebral perfusion, as well as issues with parameter uncertainty and data noise. We propose a new spatial uncertainty-based physics-informed neural network (PINN), SUPINN, to estimate CBF and other parameters from infant ASL data. SUPINN employs a multi-branch architecture to concurrently estimate regional and global model parameters across multiple voxels. It computes regional spatial uncertainties to weigh the signal. SUPINN can reliably estimate CBF (relative error $-0.3 \pm 71.7$), bolus arrival time (AT) ($30.5 \pm 257.8$), and blood longitudinal relaxation time ($T_{1b}$) ($-4.4 \pm 28.9$), surpassing parameter estimates performed using least squares or standard PINNs. Furthermore, SUPINN produces physiologically plausible spatially smooth CBF and AT maps. Our study demonstrates the successful modification of PINNs for accurate multi-parameter perfusion estimation from noisy and limited ASL data in infants. Frameworks like SUPINN have the potential to advance our understanding of the complex cardio-brain network physiology, aiding in the detection and management of diseases. Source code is provided at: https://github.com/cgalaz01/supinn.
<div id='section'>Paperid: <span id='pid'>53, <a href='https://arxiv.org/pdf/2410.18153.pdf' target='_blank'>https://arxiv.org/pdf/2410.18153.pdf</a></span>   <span><a href='https://github.com/TaikiMiyagawa/FunctionalPINN' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/TaikiMiyagawa/FunctionalPINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taiki Miyagawa, Takeru Yokota
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.18153">Physics-informed Neural Networks for Functional Differential Equations: Cylindrical Approximation and Its Convergence Guarantees</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the first learning scheme for functional differential equations (FDEs). FDEs play a fundamental role in physics, mathematics, and optimal control. However, the numerical analysis of FDEs has faced challenges due to its unrealistic computational costs and has been a long standing problem over decades. Thus, numerical approximations of FDEs have been developed, but they often oversimplify the solutions. To tackle these two issues, we propose a hybrid approach combining physics-informed neural networks (PINNs) with the \textit{cylindrical approximation}. The cylindrical approximation expands functions and functional derivatives with an orthonormal basis and transforms FDEs into high-dimensional PDEs. To validate the reliability of the cylindrical approximation for FDE applications, we prove the convergence theorems of approximated functional derivatives and solutions. Then, the derived high-dimensional PDEs are numerically solved with PINNs. Through the capabilities of PINNs, our approach can handle a broader class of functional derivatives more efficiently than conventional discretization-based methods, improving the scalability of the cylindrical approximation. As a proof of concept, we conduct experiments on two FDEs and demonstrate that our model can successfully achieve typical $L^1$ relative error orders of PINNs $\sim 10^{-3}$. Overall, our work provides a strong backbone for physicists, mathematicians, and machine learning experts to analyze previously challenging FDEs, thereby democratizing their numerical analysis, which has received limited attention. Code is available at \url{https://github.com/TaikiMiyagawa/FunctionalPINN}.
<div id='section'>Paperid: <span id='pid'>54, <a href='https://arxiv.org/pdf/2410.09883.pdf' target='_blank'>https://arxiv.org/pdf/2410.09883.pdf</a></span>   <span><a href='https://github.com/Rtlyc/antfields-demo' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuchen Liu, Ruiqi Ni, Ahmed H. Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.09883">Physics-informed Neural Mapping and Motion Planning in Unknown Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mapping and motion planning are two essential elements of robot intelligence that are interdependent in generating environment maps and navigating around obstacles. The existing mapping methods create maps that require computationally expensive motion planning tools to find a path solution. In this paper, we propose a new mapping feature called arrival time fields, which is a solution to the Eikonal equation. The arrival time fields can directly guide the robot in navigating the given environments. Therefore, this paper introduces a new approach called Active Neural Time Fields (Active NTFields), which is a physics-informed neural framework that actively explores the unknown environment and maps its arrival time field on the fly for robot motion planning. Our method does not require any expert data for learning and uses neural networks to directly solve the Eikonal equation for arrival time field mapping and motion planning. We benchmark our approach against state-of-the-art mapping and motion planning methods and demonstrate its superior performance in both simulated and real-world environments with a differential drive robot and a 6 degrees-of-freedom (DOF) robot manipulator. The supplementary videos can be found at https://youtu.be/qTPL5a6pRKk, and the implementation code repository is available at https://github.com/Rtlyc/antfields-demo.
<div id='section'>Paperid: <span id='pid'>55, <a href='https://arxiv.org/pdf/2410.06820.pdf' target='_blank'>https://arxiv.org/pdf/2410.06820.pdf</a></span>   <span><a href='https://github.com/2ailesB/neural-parametric-solver' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lise Le Boudec, Emmanuel de Bezenac, Louis Serrano, Ramon Daniel Regueiro-Espino, Yuan Yin, Patrick Gallinari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06820">Learning a Neural Solver for Parametric PDE to Enhance Physics-Informed Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed deep learning often faces optimization challenges due to the complexity of solving partial differential equations (PDEs), which involve exploring large solution spaces, require numerous iterations, and can lead to unstable training. These challenges arise particularly from the ill-conditioning of the optimization problem caused by the differential terms in the loss function. To address these issues, we propose learning a solver, i.e., solving PDEs using a physics-informed iterative algorithm trained on data. Our method learns to condition a gradient descent algorithm that automatically adapts to each PDE instance, significantly accelerating and stabilizing the optimization process and enabling faster convergence of physics-aware models. Furthermore, while traditional physics-informed methods solve for a single PDE instance, our approach extends to parametric PDEs. Specifically, we integrate the physical loss gradient with PDE parameters, allowing our method to solve over a distribution of PDE parameters, including coefficients, initial conditions, and boundary conditions. We demonstrate the effectiveness of our approach through empirical experiments on multiple datasets, comparing both training and test-time optimization performance. The code is available at https://github.com/2ailesB/neural-parametric-solver.
<div id='section'>Paperid: <span id='pid'>56, <a href='https://arxiv.org/pdf/2410.02242.pdf' target='_blank'>https://arxiv.org/pdf/2410.02242.pdf</a></span>   <span><a href='https://github.com/1HyunwooLee/Tanh-Init' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunwoo Lee, Hayoung Choi, Hyunju Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.02242">Robust Weight Initialization for Tanh Neural Networks with Fixed Point Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a neural network's depth increases, it can improve generalization performance. However, training deep networks is challenging due to gradient and signal propagation issues. To address these challenges, extensive theoretical research and various methods have been introduced. Despite these advances, effective weight initialization methods for tanh neural networks remain insufficiently investigated. This paper presents a novel weight initialization method for neural networks with tanh activation function. Based on an analysis of the fixed points of the function $\tanh(ax)$, the proposed method aims to determine values of $a$ that mitigate activation saturation. A series of experiments on various classification datasets and physics-informed neural networks demonstrates that the proposed method outperforms Xavier initialization methods~(with or without normalization) in terms of robustness across different network sizes, data efficiency, and convergence speed. Code is available at https://github.com/1HyunwooLee/Tanh-Init
<div id='section'>Paperid: <span id='pid'>57, <a href='https://arxiv.org/pdf/2409.14248.pdf' target='_blank'>https://arxiv.org/pdf/2409.14248.pdf</a></span>   <span><a href='https://github.com/kelvinhkcs/HRKAN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chi Chiu So, Siu Pang Yung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.14248">Higher-order-ReLU-KANs (HRKANs) for solving physics-informed neural networks (PINNs) more accurately, robustly and faster</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Finding solutions to partial differential equations (PDEs) is an important and essential component in many scientific and engineering discoveries. One of the common approaches empowered by deep learning is Physics-informed Neural Networks (PINNs). Recently, a new type of fundamental neural network model, Kolmogorov-Arnold Networks (KANs), has been proposed as a substitute of Multilayer Perceptions (MLPs), and possesses trainable activation functions. To enhance KANs in fitting accuracy, a modification of KANs, so called ReLU-KANs, using "square of ReLU" as the basis of its activation functions, has been suggested. In this work, we propose another basis of activation functions, namely, Higherorder-ReLU (HR), which is simpler than the basis of activation functions used in KANs, namely, Bsplines; allows efficient KAN matrix operations; and possesses smooth and non-zero higher-order derivatives, essential to physicsinformed neural networks. We name such KANs with Higher-order-ReLU (HR) as their activations, HRKANs. Our detailed experiments on two famous and representative PDEs, namely, the linear Poisson equation and nonlinear Burgers' equation with viscosity, reveal that our proposed Higher-order-ReLU-KANs (HRKANs) achieve the highest fitting accuracy and training robustness and lowest training time significantly among KANs, ReLU-KANs and HRKANs. The codes to replicate our experiments are available at https://github.com/kelvinhkcs/HRKAN.
<div id='section'>Paperid: <span id='pid'>58, <a href='https://arxiv.org/pdf/2409.08958.pdf' target='_blank'>https://arxiv.org/pdf/2409.08958.pdf</a></span>   <span><a href='https://github.com/aleks-krasowski/PINNfluence' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas R. Naujoks, Aleksander Krasowski, Moritz Weckbecker, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek, RenÃ© P. Klausen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08958">PINNfluence: Influence Functions for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, physics-informed neural networks (PINNs) have emerged as a flexible and promising application of deep learning to partial differential equations in the physical sciences. While offering strong performance and competitive inference speeds on forward and inverse problems, their black-box nature limits interpretability, particularly regarding alignment with expected physical behavior. In the present work, we explore the application of influence functions (IFs) to validate and debug PINNs post-hoc. Specifically, we apply variations of IF-based indicators to gauge the influence of different types of collocation points on the prediction of PINNs applied to a 2D Navier-Stokes fluid flow problem. Our results demonstrate how IFs can be adapted to PINNs to reveal the potential for further studies. The code is publicly available at https://github.com/aleks-krasowski/PINNfluence.
<div id='section'>Paperid: <span id='pid'>59, <a href='https://arxiv.org/pdf/2409.03231.pdf' target='_blank'>https://arxiv.org/pdf/2409.03231.pdf</a></span>   <span><a href='https://github.com/zheyuanhu01/State_Space_Model_Neural_Operator' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheyuan Hu, Nazanin Ahmadi Daryakenari, Qianli Shen, Kenji Kawaguchi, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03231">State-space models are accurate and efficient neural operators for dynamical systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning (PIML) has emerged as a promising alternative to classical methods for predicting dynamical systems, offering faster and more generalizable solutions. However, existing models, including recurrent neural networks (RNNs), transformers, and neural operators, face challenges such as long-time integration, long-range dependencies, chaotic dynamics, and extrapolation, to name a few. To this end, this paper introduces state-space models implemented in Mamba for accurate and efficient dynamical system operator learning. Mamba addresses the limitations of existing architectures by dynamically capturing long-range dependencies and enhancing computational efficiency through reparameterization techniques. To extensively test Mamba and compare against another 11 baselines, we introduce several strict extrapolation testbeds that go beyond the standard interpolation benchmarks. We demonstrate Mamba's superior performance in both interpolation and challenging extrapolation tasks. Mamba consistently ranks among the top models while maintaining the lowest computational cost and exceptional extrapolation capabilities. Moreover, we demonstrate the good performance of Mamba for a real-world application in quantitative systems pharmacology for assessing the efficacy of drugs in tumor growth under limited data scenarios. Taken together, our findings highlight Mamba's potential as a powerful tool for advancing scientific machine learning in dynamical systems modeling. (The code will be available at https://github.com/zheyuanhu01/State_Space_Model_Neural_Operator upon acceptance.)
<div id='section'>Paperid: <span id='pid'>60, <a href='https://arxiv.org/pdf/2409.01899.pdf' target='_blank'>https://arxiv.org/pdf/2409.01899.pdf</a></span>   <span><a href='https://github.com/alirezaafzalaghaei/pinnies' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Afzal Aghaei, Mahdi Movahedian Moghaddam, Kourosh Parand
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01899">PINNIES: An Efficient Physics-Informed Neural Network Framework to Integral Operator Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces an efficient tensor-vector product technique for the rapid and accurate approximation of integral operators within physics-informed deep learning frameworks. Our approach leverages neural network architectures to evaluate problem dynamics at specific points, while employing Gaussian quadrature formulas to approximate the integral components, even in the presence of infinite domains or singularities. We demonstrate the applicability of this method to both Fredholm and Volterra integral operators, as well as to optimal control problems involving continuous time. Additionally, we outline how this approach can be extended to approximate fractional derivatives and integrals and propose a fast matrix-vector product algorithm for efficiently computing the fractional Caputo derivative. In the numerical section, we conduct comprehensive experiments on forward and inverse problems. For forward problems, we evaluate the performance of our method on over 50 diverse mathematical problems, including multi-dimensional integral equations, systems of integral equations, partial and fractional integro-differential equations, and various optimal control problems in delay, fractional, multi-dimensional, and nonlinear configurations. For inverse problems, we test our approach on several integral equations and fractional integro-differential problems. Finally, we introduce the pinnies Python package to facilitate the implementation and usability of the proposed method.
<div id='section'>Paperid: <span id='pid'>61, <a href='https://arxiv.org/pdf/2408.12171.pdf' target='_blank'>https://arxiv.org/pdf/2408.12171.pdf</a></span>   <span><a href='https://github.com/WillDreamer/Awesome-AI4CFD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haixin Wang, Yadi Cao, Zijie Huang, Yuxuan Liu, Peiyan Hu, Xiao Luo, Zezheng Song, Wanjia Zhao, Jilin Liu, Jinan Sun, Shikun Zhang, Long Wei, Yue Wang, Tailin Wu, Zhi-Ming Ma, Yizhou Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12171">Recent Advances on Machine Learning for Computational Fluid Dynamics: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper explores the recent advancements in enhancing Computational Fluid Dynamics (CFD) tasks through Machine Learning (ML) techniques. We begin by introducing fundamental concepts, traditional methods, and benchmark datasets, then examine the various roles ML plays in improving CFD. The literature systematically reviews papers in recent five years and introduces a novel classification for forward modeling: Data-driven Surrogates, Physics-Informed Surrogates, and ML-assisted Numerical Solutions. Furthermore, we also review the latest ML methods in inverse design and control, offering a novel classification and providing an in-depth discussion. Then we highlight real-world applications of ML for CFD in critical scientific and engineering disciplines, including aerodynamics, combustion, atmosphere & ocean science, biology fluid, plasma, symbolic regression, and reduced order modeling. Besides, we identify key challenges and advocate for future research directions to address these challenges, such as multi-scale representation, physical knowledge encoding, scientific foundation model and automatic scientific discovery. This review serves as a guide for the rapidly expanding ML for CFD community, aiming to inspire insights for future advancements. We draw the conclusion that ML is poised to significantly transform CFD research by enhancing simulation accuracy, reducing computational time, and enabling more complex analyses of fluid dynamics. The paper resources can be viewed at https://github.com/WillDreamer/Awesome-AI4CFD.
<div id='section'>Paperid: <span id='pid'>62, <a href='https://arxiv.org/pdf/2408.09845.pdf' target='_blank'>https://arxiv.org/pdf/2408.09845.pdf</a></span>   <span><a href='https://github.com/tsinghua-fib-lab/DiskNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruikun Li, Huandong Wang, Jinghua Piao, Qingmin Liao, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09845">Predicting Long-term Dynamics of Complex Networks via Identifying Skeleton in Hyperbolic Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning complex network dynamics is fundamental for understanding, modeling, and controlling real-world complex systems. Though great efforts have been made to predict the future states of nodes on networks, the capability of capturing long-term dynamics remains largely limited. This is because they overlook the fact that long-term dynamics in complex network are predominantly governed by their inherent low-dimensional manifolds, i.e., skeletons. Therefore, we propose the Dynamics-Invariant Skeleton Neural Net}work (DiskNet), which identifies skeletons of complex networks based on the renormalization group structure in hyperbolic space to preserve both topological and dynamics properties. Specifically, we first condense complex networks with various dynamics into simple skeletons through physics-informed hyperbolic embeddings. Further, we design graph neural ordinary differential equations to capture the condensed dynamics on the skeletons. Finally, we recover the skeleton networks and dynamics to the original ones using a degree-based super-resolution module. Extensive experiments across three representative dynamics as well as five real-world and two synthetic networks demonstrate the superior performances of the proposed DiskNet, which outperforms the state-of-the-art baselines by an average of 10.18\% in terms of long-term prediction accuracy. Code for reproduction is available at: https://github.com/tsinghua-fib-lab/DiskNet.
<div id='section'>Paperid: <span id='pid'>63, <a href='https://arxiv.org/pdf/2408.08488.pdf' target='_blank'>https://arxiv.org/pdf/2408.08488.pdf</a></span>   <span><a href='https://github.com/Zest86/ACL-PITN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Wang, Mengshi Qi, Yingxia Shao, Anfu Zhou, Huadong Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.08488">PITN: Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monitoring blood pressure with non-invasive sensors has gained popularity for providing comfortable user experiences, one of which is a significant function of smart wearables. Although providing a comfortable user experience, such methods are suffering from the demand for a significant amount of realistic data to train an individual model for each subject, especially considering the invasive or obtrusive BP ground-truth measurements. To tackle this challenge, we introduce a novel physics-informed temporal network~(PITN) with adversarial contrastive learning to enable precise BP estimation with very limited data. Specifically, we first enhance the physics-informed neural network~(PINN) with the temporal block for investigating BP dynamics' multi-periodicity for personal cardiovascular cycle modeling and temporal variation. We then employ adversarial training to generate extra physiological time series data, improving PITN's robustness in the face of sparse subject-specific training data. Furthermore, we utilize contrastive learning to capture the discriminative variations of cardiovascular physiologic phenomena. This approach aggregates physiological signals with similar blood pressure values in latent space while separating clusters of samples with dissimilar blood pressure values. Experiments on three widely-adopted datasets with different modailties (\emph{i.e.,} bioimpedance, PPG, millimeter-wave) demonstrate the superiority and effectiveness of the proposed methods over previous state-of-the-art approaches. The code is available at~\url{https://github.com/Zest86/ACL-PITN}.
<div id='section'>Paperid: <span id='pid'>64, <a href='https://arxiv.org/pdf/2408.05215.pdf' target='_blank'>https://arxiv.org/pdf/2408.05215.pdf</a></span>   <span><a href='https://github.com/nec-research/PICPS-ML4Sci' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Makoto Takamoto, Viktor Zaverkin, Mathias Niepert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.05215">Physics-Informed Weakly Supervised Learning for Interatomic Potentials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning plays an increasingly important role in computational chemistry and materials science, complementing computationally intensive ab initio and first-principles methods. Despite their utility, machine-learning models often lack generalization capability and robustness during atomistic simulations, yielding unphysical energy and force predictions that hinder their real-world applications. We address this challenge by introducing a physics-informed, weakly supervised approach for training machine-learned interatomic potentials (MLIPs). We introduce two novel loss functions, extrapolating the potential energy via a Taylor expansion and using the concept of conservative forces. Our approach improves the accuracy of MLIPs applied to training tasks with sparse training data sets and reduces the need for pre-training computationally demanding models with large data sets. Particularly, we perform extensive experiments demonstrating reduced energy and force errors -- often lower by a factor of two -- for various baseline models and benchmark data sets. Moreover, we demonstrate improved robustness during MD simulations of the MLIP models trained with the proposed weakly supervised loss. Finally, our approach improves the fine-tuning of foundation models on sparse, highly accurate ab initio data. An implementation of our method and scripts for executing experiments are available at https://github.com/nec-research/PICPS-ML4Sci.
<div id='section'>Paperid: <span id='pid'>65, <a href='https://arxiv.org/pdf/2408.02698.pdf' target='_blank'>https://arxiv.org/pdf/2408.02698.pdf</a></span>   <span><a href='https://github.com/eshaghi-ms/DeepNetBeam' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Sadegh Eshaghi, Mostafa Bamdad, Cosmin Anitescu, Yizheng Wang, Xiaoying Zhuang, Timon Rabczuk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02698">Applications of Scientific Machine Learning for the Analysis of Functionally Graded Porous Beams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates different Scientific Machine Learning (SciML) approaches for the analysis of functionally graded (FG) porous beams and compares them under a new framework. The beam material properties are assumed to vary as an arbitrary continuous function. The methods consider the output of a neural network/operator as an approximation to the displacement fields and derive the equations governing beam behavior based on the continuum formulation. The methods are implemented in the framework and formulated by three approaches: (a) the vector approach leads to a Physics-Informed Neural Network (PINN), (b) the energy approach brings about the Deep Energy Method (DEM), and (c) the data-driven approach, which results in a class of Neural Operator methods. Finally, a neural operator has been trained to predict the response of the porous beam with functionally graded material under any porosity distribution pattern and any arbitrary traction condition. The results are validated with analytical and numerical reference solutions. The data and code accompanying this manuscript will be publicly available at https://github.com/eshaghi-ms/DeepNetBeam.
<div id='section'>Paperid: <span id='pid'>66, <a href='https://arxiv.org/pdf/2408.01600.pdf' target='_blank'>https://arxiv.org/pdf/2408.01600.pdf</a></span>   <span><a href='https://github.com/WeihengZ/Physics-informed-Neural-Foundation-Operator' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Weiheng Zhong, Hadi Meidani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.01600">Physics-Informed Geometry-Aware Neural Operator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Engineering design problems often involve solving parametric Partial Differential Equations (PDEs) under variable PDE parameters and domain geometry. Recently, neural operators have shown promise in learning PDE operators and quickly predicting the PDE solutions. However, training these neural operators typically requires large datasets, the acquisition of which can be prohibitively expensive. To overcome this, physics-informed training offers an alternative way of building neural operators, eliminating the high computational costs associated with Finite Element generation of training data. Nevertheless, current physics-informed neural operators struggle with limitations, either in handling varying domain geometries or varying PDE parameters. In this research, we introduce a novel method, the Physics-Informed Geometry-Aware Neural Operator (PI-GANO), designed to simultaneously generalize across both PDE parameters and domain geometries. We adopt a geometry encoder to capture the domain geometry features, and design a novel pipeline to integrate this component within the existing DCON architecture. Numerical results demonstrate the accuracy and efficiency of the proposed method. All the codes and data related to this work are available on GitHub: https://github.com/WeihengZ/Physics-informed-Neural-Foundation-Operator.
<div id='section'>Paperid: <span id='pid'>67, <a href='https://arxiv.org/pdf/2407.20741.pdf' target='_blank'>https://arxiv.org/pdf/2407.20741.pdf</a></span>   <span><a href='https://github.com/MorganREN/Improving-PINNs-By-Algebraic-Inclusion-of-Boundary-and-Initial-Conditions' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohan Ren, Zhihao Fang, Keren Li, Anirbit Mukherjee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.20741">Improving PINNs By Algebraic Inclusion of Boundary and Initial Conditions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>"AI for Science" aims to solve fundamental scientific problems using AI techniques. As most physical phenomena can be described as Partial Differential Equations (PDEs) , approximating their solutions using neural networks has evolved as a central component of scientific-ML. Physics-Informed Neural Networks (PINNs) is the general method that has evolved for this task but its training is well-known to be very unstable. In this work we explore the possibility of changing the model being trained from being just a neural network to being a non-linear transformation of it - one that algebraically includes the boundary/initial conditions. This reduces the number of terms in the loss function than the standard PINN losses. We demonstrate that our modification leads to significant performance gains across a range of benchmark tasks, in various dimensions and without having to tweak the training algorithm. Our conclusions are based on conducting hundreds of experiments, in the fully unsupervised setting, over multiple linear and non-linear PDEs set to exactly solvable scenarios, which lends to a concrete measurement of our performance gains in terms of order(s) of magnitude lower fractional errors being achieved, than by standard PINNs. The code accompanying this manuscript is publicly available at, https://github.com/MorganREN/Improving-PINNs-By-Algebraic-Inclusion-of-Boundary-and-Initial-Conditions
<div id='section'>Paperid: <span id='pid'>68, <a href='https://arxiv.org/pdf/2407.19421.pdf' target='_blank'>https://arxiv.org/pdf/2407.19421.pdf</a></span>   <span><a href='https://github.com/PanChengN/I-PINN.git,' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pancheng Niu, Yongming Chen, Jun Guo, Yuqian Zhou, Minfu Feng, Yanchao Shi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.19421">Improved physics-informed neural network in mitigating gradient related failures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) integrate fundamental physical principles with advanced data-driven techniques, driving significant advancements in scientific computing. However, PINNs face persistent challenges with stiffness in gradient flow, which limits their predictive capabilities. This paper presents an improved PINN (I-PINN) to mitigate gradient-related failures. The core of I-PINN is to combine the respective strengths of neural networks with an improved architecture and adaptive weights containingupper bounds. The capability to enhance accuracy by at least one order of magnitude and accelerate convergence, without introducing extra computational complexity relative to the baseline model, is achieved by I-PINN. Numerical experiments with a variety of benchmarks illustrate the improved accuracy and generalization of I-PINN. The supporting data and code are accessible at https://github.com/PanChengN/I-PINN.git, enabling broader research engagement.
<div id='section'>Paperid: <span id='pid'>69, <a href='https://arxiv.org/pdf/2407.11253.pdf' target='_blank'>https://arxiv.org/pdf/2407.11253.pdf</a></span>   <span><a href='https://github.com/HewlettPackard/separable-operator-networks' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinling Yu, Sean Hooten, Ziyue Liu, Yequan Zhao, Marco Fiorentino, Thomas Van Vaerenbergh, Zheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11253">Separable Operator Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Operator learning has become a powerful tool in machine learning for modeling complex physical systems governed by partial differential equations (PDEs). Although Deep Operator Networks (DeepONet) show promise, they require extensive data acquisition. Physics-informed DeepONets (PI-DeepONet) mitigate data scarcity but suffer from inefficient training processes. We introduce Separable Operator Networks (SepONet), a novel framework that significantly enhances the efficiency of physics-informed operator learning. SepONet uses independent trunk networks to learn basis functions separately for different coordinate axes, enabling faster and more memory-efficient training via forward-mode automatic differentiation. We provide a universal approximation theorem for SepONet proving the existence of a separable approximation to any nonlinear continuous operator. Then, we comprehensively benchmark its representational capacity and computational performance against PI-DeepONet. Our results demonstrate SepONet's superior performance across various nonlinear and inseparable PDEs, with SepONet's advantages increasing with problem complexity, dimension, and scale. For 1D time-dependent PDEs, SepONet achieves up to 112x faster training and 82x reduction in GPU memory usage compared to PI-DeepONet, while maintaining comparable accuracy. For the 2D time-dependent nonlinear diffusion equation, SepONet efficiently handles the complexity, achieving a 6.44% mean relative $\ell_{2}$ test error, while PI-DeepONet fails due to memory constraints. This work paves the way for extreme-scale learning of continuous mappings between infinite-dimensional function spaces. Open source code is available at \url{https://github.com/HewlettPackard/separable-operator-networks}.
<div id='section'>Paperid: <span id='pid'>70, <a href='https://arxiv.org/pdf/2407.09679.pdf' target='_blank'>https://arxiv.org/pdf/2407.09679.pdf</a></span>   <span><a href='https://github.com/19reborn/PICT_smoke' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiming Wang, Siyu Tang, Mengyu Chu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.09679">Physics-Informed Learning of Characteristic Trajectories for Smoke Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We delve into the physics-informed neural reconstruction of smoke and obstacles through sparse-view RGB videos, tackling challenges arising from limited observation of complex dynamics. Existing physics-informed neural networks often emphasize short-term physics constraints, leaving the proper preservation of long-term conservation less explored. We introduce Neural Characteristic Trajectory Fields, a novel representation utilizing Eulerian neural fields to implicitly model Lagrangian fluid trajectories. This topology-free, auto-differentiable representation facilitates efficient flow map calculations between arbitrary frames as well as efficient velocity extraction via auto-differentiation. Consequently, it enables end-to-end supervision covering long-term conservation and short-term physics priors. Building on the representation, we propose physics-informed trajectory learning and integration into NeRF-based scene reconstruction. We enable advanced obstacle handling through self-supervised scene decomposition and seamless integrated boundary constraints. Our results showcase the ability to overcome challenges like occlusion uncertainty, density-color ambiguity, and static-dynamic entanglements. Code and sample tests are at \url{https://github.com/19reborn/PICT_smoke}.
<div id='section'>Paperid: <span id='pid'>71, <a href='https://arxiv.org/pdf/2407.09299.pdf' target='_blank'>https://arxiv.org/pdf/2407.09299.pdf</a></span>   <span><a href='https://github.com/fangyuanmao/PID' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Fangyuan Mao, Jilin Mei, Shun Lu, Fuyang Liu, Liang Chen, Fangzhou Zhao, Yu Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.09299">PID: Physics-Informed Diffusion Model for Infrared Image Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Infrared imaging technology has gained significant attention for its reliable sensing ability in low visibility conditions, prompting many studies to convert the abundant RGB images to infrared images. However, most existing image translation methods treat infrared images as a stylistic variation, neglecting the underlying physical laws, which limits their practical application. To address these issues, we propose a Physics-Informed Diffusion (PID) model for translating RGB images to infrared images that adhere to physical laws. Our method leverages the iterative optimization of the diffusion model and incorporates strong physical constraints based on prior knowledge of infrared laws during training. This approach enhances the similarity between translated infrared images and the real infrared domain without increasing extra training parameters. Experimental results demonstrate that PID significantly outperforms existing state-of-the-art methods. Our code is available at https://github.com/fangyuanmao/PID.
<div id='section'>Paperid: <span id='pid'>72, <a href='https://arxiv.org/pdf/2407.08664.pdf' target='_blank'>https://arxiv.org/pdf/2407.08664.pdf</a></span>   <span><a href='https://github.com/uwsbel/sbel-reproducibility/tree/master/2024/MNODE-code' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingquan Wang, Shu Wang, Huzaifa Mustafa Unjhawala, Jinlong Wu, Dan Negrut
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08664">MBD-NODE: Physics-informed data-driven modeling and simulation of constrained multibody systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We describe a framework that can integrate prior physical information, e.g., the presence of kinematic constraints, to support data-driven simulation in multi-body dynamics. Unlike other approaches, e.g., Fully-connected Neural Network (FCNN) or Recurrent Neural Network (RNN)-based methods that are used to model the system states directly, the proposed approach embraces a Neural Ordinary Differential Equation (NODE) paradigm that models the derivatives of the system states. A central part of the proposed methodology is its capacity to learn the multibody system dynamics from prior physical knowledge and constraints combined with data inputs. This learning process is facilitated by a constrained optimization approach, which ensures that physical laws and system constraints are accounted for in the simulation process. The models, data, and code for this work are publicly available as open source at https://github.com/uwsbel/sbel-reproducibility/tree/master/2024/MNODE-code.
<div id='section'>Paperid: <span id='pid'>73, <a href='https://arxiv.org/pdf/2406.14495.pdf' target='_blank'>https://arxiv.org/pdf/2406.14495.pdf</a></span>   <span><a href='https://github.com/alirezaafzalaghaei/rKAN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Afzal Aghaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14495">rKAN: Rational Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The development of Kolmogorov-Arnold networks (KANs) marks a significant shift from traditional multi-layer perceptrons in deep learning. Initially, KANs employed B-spline curves as their primary basis function, but their inherent complexity posed implementation challenges. Consequently, researchers have explored alternative basis functions such as Wavelets, Polynomials, and Fractional functions. In this research, we explore the use of rational functions as a novel basis function for KANs. We propose two different approaches based on Pade approximation and rational Jacobi functions as trainable basis functions, establishing the rational KAN (rKAN). We then evaluate rKAN's performance in various deep learning and physics-informed tasks to demonstrate its practicality and effectiveness in function approximation.
<div id='section'>Paperid: <span id='pid'>74, <a href='https://arxiv.org/pdf/2406.09071.pdf' target='_blank'>https://arxiv.org/pdf/2406.09071.pdf</a></span>   <span><a href='https://github.com/CAME-THU/FlamePINN-1D' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahao Wu, Su Zhang, Yuxin Wu, Guihua Zhang, Xin Li, Hai Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09071">FlamePINN-1D: Physics-informed neural networks to solve forward and inverse problems of 1D laminar flames</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the existence of various forward and inverse problems in combustion studies and applications that necessitate distinct methods for resolution, a framework to solve them in a unified way is critically needed. A promising approach is the integration of machine learning methods with governing equations of combustion systems, which exhibits superior generality and few-shot learning ability compared to purely data-driven methods. In this work, the FlamePINN-1D framework is proposed to solve the forward and inverse problems of 1D laminar flames based on physics-informed neural networks. Three cases with increasing complexity have been tested: Case 1 are freely-propagating premixed (FPP) flames with simplified physical models, while Case 2 and Case 3 are FPP and counterflow premixed (CFP) flames with detailed models, respectively. For forward problems, FlamePINN-1D aims to solve the flame fields and infer the unknown eigenvalues (such as laminar flame speeds) under the constraints of governing equations and boundary conditions. For inverse problems, FlamePINN-1D aims to reconstruct the continuous fields and infer the unknown parameters (such as transport and chemical kinetics parameters) from noisy sparse observations of the flame. Our results strongly validate these capabilities of FlamePINN-1D across various flames and working conditions. Compared to traditional methods, FlamePINN-1D is differentiable and mesh-free, exhibits no discretization errors, and is easier to implement for inverse problems. The inverse problem results also indicate the possibility of optimizing chemical mechanisms from measurements of laboratory 1D flames. Furthermore, some proposed strategies, such as hard constraints and thin-layer normalization, are proven to be essential for the robust learning of FlamePINN-1D. The code for this paper is partially available at https://github.com/CAME-THU/FlamePINN-1D.
<div id='section'>Paperid: <span id='pid'>75, <a href='https://arxiv.org/pdf/2405.17527.pdf' target='_blank'>https://arxiv.org/pdf/2405.17527.pdf</a></span>   <span><a href='https://github.com/thuml/Unisolver' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Zhou, Yuezhou Ma, Haixu Wu, Haowen Wang, Mingsheng Long
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17527">Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE Solvers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep models have recently emerged as promising tools to solve partial differential equations (PDEs), known as neural PDE solvers. While neural solvers trained from either simulation data or physics-informed loss can solve PDEs reasonably well, they are mainly restricted to a few instances of PDEs, e.g. a certain equation with a limited set of coefficients. This limits their generalization to diverse PDEs, preventing them from being practical surrogate models of numerical solvers. In this paper, we present Unisolver, a novel Transformer model trained on diverse data and conditioned on diverse PDEs, aiming towards a universal neural PDE solver capable of solving a wide scope of PDEs. Instead of purely scaling up data and parameters, Unisolver stems from the theoretical analysis of the PDE-solving process. Inspired by the mathematical structure of PDEs that a PDE solution is fundamentally governed by a series of PDE components such as equation symbols and boundary conditions, we define a complete set of PDE components and flexibly embed them as domain-wise and point-wise deep conditions for Transformer PDE solvers. Integrating physical insights with recent Transformer advances, Unisolver achieves consistent state-of-the-art on three challenging large-scale benchmarks, showing impressive performance and generalizability. Code is available at https://github.com/thuml/Unisolver.
<div id='section'>Paperid: <span id='pid'>76, <a href='https://arxiv.org/pdf/2405.14369.pdf' target='_blank'>https://arxiv.org/pdf/2405.14369.pdf</a></span>   <span><a href='https://github.com/thuml/RoPINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haixu Wu, Huakun Luo, Yuezhou Ma, Jianmin Wang, Mingsheng Long
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14369">RoPINN: Region Optimized Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have been widely applied to solve partial differential equations (PDEs) by enforcing outputs and gradients of deep models to satisfy target equations. Due to the limitation of numerical computation, PINNs are conventionally optimized on finite selected points. However, since PDEs are usually defined on continuous domains, solely optimizing models on scattered points may be insufficient to obtain an accurate solution for the whole domain. To mitigate this inherent deficiency of the default scatter-point optimization, this paper proposes and theoretically studies a new training paradigm as region optimization. Concretely, we propose to extend the optimization process of PINNs from isolated points to their continuous neighborhood regions, which can theoretically decrease the generalization error, especially for hidden high-order constraints of PDEs. A practical training algorithm, Region Optimized PINN (RoPINN), is seamlessly derived from this new paradigm, which is implemented by a straightforward but effective Monte Carlo sampling method. By calibrating the sampling process into trust regions, RoPINN finely balances optimization and generalization error. Experimentally, RoPINN consistently boosts the performance of diverse PINNs on a wide range of PDEs without extra backpropagation or gradient calculation. Code is available at this repository: https://github.com/thuml/RoPINN.
<div id='section'>Paperid: <span id='pid'>77, <a href='https://arxiv.org/pdf/2405.11752.pdf' target='_blank'>https://arxiv.org/pdf/2405.11752.pdf</a></span>   <span><a href='https://github.com/killingbear999/chemical-reactor-foundation-model' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihao Wang, Zhe Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11752">Towards Foundation Model for Chemical Reactor Modeling: Meta-Learning with Physics-Informed Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing accurate models for chemical reactors is often challenging due to the complexity of reaction kinetics and process dynamics. Traditional approaches require retraining models for each new system, limiting generalizability and efficiency. In this work, we take a step toward foundation models for chemical reactor modeling by introducing a neural network framework that generalizes across diverse reactor types and rapidly adapts to new chemical processes. Our approach leverages meta-learning to pretrain the model on a broad set of reactor dynamics, enabling efficient adaptation to unseen reactions with minimal data. To further enhance generalizability, we incorporate physics-informed fine-tuning, ensuring physically consistent adaptation to new reactor conditions. Our framework is evaluated across three integer-order fundamental reactor types - continuous stirred tank reactors, batch reactors, and plug flow reactors - demonstrating superior few-shot adaptation compared to conventional data-driven, physics-informed, and transfer learning approaches. By combining meta-learning with physics-informed adaptation, this work lays the foundation for a generalizable modeling framework, advancing the development of foundation models for chemical engineering applications. Source code is available at https://github.com/killingbear999/chemical-reactor-foundation-model.
<div id='section'>Paperid: <span id='pid'>78, <a href='https://arxiv.org/pdf/2405.11208.pdf' target='_blank'>https://arxiv.org/pdf/2405.11208.pdf</a></span>   <span><a href='https://github.com/MathBon/Discover-PINNs-Model' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Zhang, Chao Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11208">Discovering Physics-Informed Neural Networks Model for Solving Partial Differential Equations through Evolutionary Computation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, the researches about solving partial differential equations (PDEs) based on artificial neural network have attracted considerable attention. In these researches, the neural network models are usually designed depend on human experience or trial and error. Despite the emergence of several model searching methods, these methods primarily concentrate on optimizing the hyperparameters of fully connected neural network model based on the framework of physics-informed neural networks (PINNs), and the corresponding search spaces are relatively restricted, thereby limiting the exploration of superior models. This article proposes an evolutionary computation method aimed at discovering the PINNs model with higher approximation accuracy and faster convergence rate. In addition to searching the numbers of layers and neurons per hidden layer, this method concurrently explores the optimal shortcut connections between the layers and the novel parametric activation functions expressed by the binary trees. In evolution, the strategy about dynamic population size and training epochs (DPSTE) is adopted, which significantly increases the number of models to be explored and facilitates the discovery of models with fast convergence rate. In experiments, the performance of different models that are searched through Bayesian optimization, random search and evolution is compared in solving Klein-Gordon, Burgers, and LamÃ© equations. The experimental results affirm that the models discovered by the proposed evolutionary computation method generally exhibit superior approximation accuracy and convergence rate, and these models also show commendable generalization performance with respect to the source term, initial and boundary conditions, equation coefficient and computational domain. The corresponding code is available at https://github.com/MathBon/Discover-PINNs-Model.
<div id='section'>Paperid: <span id='pid'>79, <a href='https://arxiv.org/pdf/2405.01680.pdf' target='_blank'>https://arxiv.org/pdf/2405.01680.pdf</a></span>   <span><a href='https://github.com/nimahsn/pinns_tf2' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nima Hosseini Dashtbayaz, Ghazal Farhani, Boyu Wang, Charles X. Ling
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01680">Physics-Informed Neural Networks: Minimizing Residual Loss with Wide Networks and Effective Activations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The residual loss in Physics-Informed Neural Networks (PINNs) alters the simple recursive relation of layers in a feed-forward neural network by applying a differential operator, resulting in a loss landscape that is inherently different from those of common supervised problems. Therefore, relying on the existing theory leads to unjustified design choices and suboptimal performance. In this work, we analyze the residual loss by studying its characteristics at critical points to find the conditions that result in effective training of PINNs. Specifically, we first show that under certain conditions, the residual loss of PINNs can be globally minimized by a wide neural network. Furthermore, our analysis also reveals that an activation function with well-behaved high-order derivatives plays a crucial role in minimizing the residual loss. In particular, to solve a $k$-th order PDE, the $k$-th derivative of the activation function should be bijective. The established theory paves the way for designing and choosing effective activation functions for PINNs and explains why periodic activations have shown promising performance in certain cases. Finally, we verify our findings by conducting a set of experiments on several PDEs. Our code is publicly available at https://github.com/nimahsn/pinns_tf2.
<div id='section'>Paperid: <span id='pid'>80, <a href='https://arxiv.org/pdf/2404.13646.pdf' target='_blank'>https://arxiv.org/pdf/2404.13646.pdf</a></span>   <span><a href='https://github.com/WeihengZ/PI-DCON' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Weiheng Zhong, Hadi Meidani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.13646">Physics-informed Discretization-independent Deep Compositional Operator Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving parametric Partial Differential Equations (PDEs) for a broad range of parameters is a critical challenge in scientific computing. To this end, neural operators, which \textcolor{black}{predicts the PDE solution with variable PDE parameter inputs}, have been successfully used. However, the training of neural operators typically demands large training datasets, the acquisition of which can be prohibitively expensive. To address this challenge, physics-informed training can offer a cost-effective strategy. However, current physics-informed neural operators face limitations, either in handling irregular domain shapes or in in generalizing to various discrete representations of PDE parameters. In this research, we introduce a novel physics-informed model architecture which can generalize to various discrete representations of PDE parameters and irregular domain shapes. Particularly, inspired by deep operator neural networks, our model involves a discretization-independent learning of parameter embedding repeatedly, and this parameter embedding is integrated with the response embeddings through multiple compositional layers, for more expressivity. Numerical results demonstrate the accuracy and efficiency of the proposed method. All the codes and data related to this work are available on GitHub: https://github.com/WeihengZ/PI-DCON.
<div id='section'>Paperid: <span id='pid'>81, <a href='https://arxiv.org/pdf/2404.11811.pdf' target='_blank'>https://arxiv.org/pdf/2404.11811.pdf</a></span>   <span><a href='https://github.com/dralgroup/mlatom' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi-Fan Hou, Lina Zhang, Quanhao Zhang, Fuchun Ge, Pavlo O. Dral
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.11811">Physics-informed active learning for accelerating quantum chemical simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantum chemical simulations can be greatly accelerated by constructing machine learning potentials, which is often done using active learning (AL). The usefulness of the constructed potentials is often limited by the high effort required and their insufficient robustness in the simulations. Here we introduce the end-to-end AL for constructing robust data-efficient potentials with affordable investment of time and resources and minimum human interference. Our AL protocol is based on the physics-informed sampling of training points, automatic selection of initial data, uncertainty quantification, and convergence monitoring. The versatility of this protocol is shown in our implementation of quasi-classical molecular dynamics for simulating vibrational spectra, conformer search of a key biochemical molecule, and time-resolved mechanism of the Diels-Alder reactions. These investigations took us days instead of weeks of pure quantum chemical calculations on a high-performance computing cluster. The code in MLatom and tutorials are available at https://github.com/dralgroup/mlatom.
<div id='section'>Paperid: <span id='pid'>82, <a href='https://arxiv.org/pdf/2403.17607.pdf' target='_blank'>https://arxiv.org/pdf/2403.17607.pdf</a></span>   <span><a href='https://github.com/intel/tiny-dpcpp-nn' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai Yuan, Christoph Bauinger, Xiangyi Zhang, Pascal Baehr, Matthias Kirchhart, Darius Dabert, Adrien Tousnakhoff, Pierre Boudier, Michael Paulitsch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17607">Fully-fused Multi-Layer Perceptrons on Intel Data Center GPUs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a SYCL implementation of Multi-Layer Perceptrons (MLPs), which targets and is optimized for the Intel Data Center GPU Max 1550. To increase the performance, our implementation minimizes the slow global memory accesses by maximizing the data reuse within the general register file and the shared local memory by fusing the operations in each layer of the MLP. We show with a simple roofline model that this results in a significant increase in the arithmetic intensity, leading to improved performance, especially for inference. We compare our approach to a similar CUDA implementation for MLPs and show that our implementation on the Intel Data Center GPU outperforms the CUDA implementation on Nvidia's H100 GPU by a factor up to 2.84 in inference and 1.75 in training. The paper also showcases the efficiency of our SYCL implementation in three significant areas: Image Compression, Neural Radiance Fields, and Physics-Informed Machine Learning. In all cases, our implementation outperforms the off-the-shelf Intel Extension for PyTorch (IPEX) implementation on the same Intel GPU by up to a factor of 30 and the CUDA PyTorch version on Nvidia's H100 GPU by up to a factor 19. The code can be found at https://github.com/intel/tiny-dpcpp-nn.
<div id='section'>Paperid: <span id='pid'>83, <a href='https://arxiv.org/pdf/2402.06680.pdf' target='_blank'>https://arxiv.org/pdf/2402.06680.pdf</a></span>   <span><a href='https://github.com/tsinghua-fib-lab/SPDiff' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongyi Chen, Jingtao Ding, Yong Li, Yue Wang, Xiao-Ping Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06680">Social Physics Informed Diffusion Model for Crowd Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Crowd simulation holds crucial applications in various domains, such as urban planning, architectural design, and traffic arrangement. In recent years, physics-informed machine learning methods have achieved state-of-the-art performance in crowd simulation but fail to model the heterogeneity and multi-modality of human movement comprehensively. In this paper, we propose a social physics-informed diffusion model named SPDiff to mitigate the above gap. SPDiff takes both the interactive and historical information of crowds in the current timeframe to reverse the diffusion process, thereby generating the distribution of pedestrian movement in the subsequent timeframe. Inspired by the well-known social physics model, i.e., Social Force, regarding crowd dynamics, we design a crowd interaction module to guide the denoising process and further enhance this module with the equivariant properties of crowd interactions. To mitigate error accumulation in long-term simulations, we propose a multi-frame rollout training algorithm for diffusion modeling. Experiments conducted on two real-world datasets demonstrate the superior performance of SPDiff in terms of macroscopic and microscopic evaluation metrics. Code and appendix are available at https://github.com/tsinghua-fib-lab/SPDiff.
<div id='section'>Paperid: <span id='pid'>84, <a href='https://arxiv.org/pdf/2402.00326.pdf' target='_blank'>https://arxiv.org/pdf/2402.00326.pdf</a></span>   <span><a href='https://github.com/PredictiveIntelligenceLab/jaxpi' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sifan Wang, Bowen Li, Yuhan Chen, Paris Perdikaris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00326">PirateNets: Physics-informed Deep Learning with Residual Adaptive Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While physics-informed neural networks (PINNs) have become a popular deep learning framework for tackling forward and inverse problems governed by partial differential equations (PDEs), their performance is known to degrade when larger and deeper neural network architectures are employed. Our study identifies that the root of this counter-intuitive behavior lies in the use of multi-layer perceptron (MLP) architectures with non-suitable initialization schemes, which result in poor trainablity for the network derivatives, and ultimately lead to an unstable minimization of the PDE residual loss. To address this, we introduce Physics-informed Residual Adaptive Networks (PirateNets), a novel architecture that is designed to facilitate stable and efficient training of deep PINN models. PirateNets leverage a novel adaptive residual connection, which allows the networks to be initialized as shallow networks that progressively deepen during training. We also show that the proposed initialization scheme allows us to encode appropriate inductive biases corresponding to a given PDE system into the network architecture. We provide comprehensive empirical evidence showing that PirateNets are easier to optimize and can gain accuracy from considerably increased depth, ultimately achieving state-of-the-art results across various benchmarks. All code and data accompanying this manuscript will be made publicly available at \url{https://github.com/PredictiveIntelligenceLab/jaxpi}.
<div id='section'>Paperid: <span id='pid'>85, <a href='https://arxiv.org/pdf/2401.09631.pdf' target='_blank'>https://arxiv.org/pdf/2401.09631.pdf</a></span>   <span><a href='https://github.com/fnerrise/LNNs_MagNav/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Favour Nerrise, Andrew Sosa Sosanya, Patrick Neary
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.09631">Physics-Informed Calibration of Aeromagnetic Compensation in Magnetic Navigation Systems using Liquid Time-Constant Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Magnetic navigation (MagNav) is a rising alternative to the Global Positioning System (GPS) and has proven useful for aircraft navigation. Traditional aircraft navigation systems, while effective, face limitations in precision and reliability in certain environments and against attacks. Airborne MagNav leverages the Earth's magnetic field to provide accurate positional information. However, external magnetic fields induced by aircraft electronics and Earth's large-scale magnetic fields disrupt the weaker signal of interest. We introduce a physics-informed approach using Tolles-Lawson coefficients for compensation and Liquid Time-Constant Networks (LTCs) to remove complex, noisy signals derived from the aircraft's magnetic sources. Using real flight data with magnetometer measurements and aircraft measurements, we observe up to a 64% reduction in aeromagnetic compensation error (RMSE nT), outperforming conventional models. This significant improvement underscores the potential of a physics-informed, machine learning approach for extracting clean, reliable, and accurate magnetic signals for MagNav positional estimation.
<div id='section'>Paperid: <span id='pid'>86, <a href='https://arxiv.org/pdf/2312.17329.pdf' target='_blank'>https://arxiv.org/pdf/2312.17329.pdf</a></span>   <span><a href='https://github.com/NREL/pinnstripes' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Malik Hassanaly, Peter J. Weddle, Ryan N. King, Subhayan De, Alireza Doostan, Corey R. Randall, Eric J. Dufek, Andrew M. Colclasure, Kandler Smith
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.17329">PINN surrogate of Li-ion battery models for parameter inference. Part I: Implementation and multi-fidelity hierarchies for the single-particle model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To plan and optimize energy storage demands that account for Li-ion battery aging dynamics, techniques need to be developed to diagnose battery internal states accurately and rapidly. This study seeks to reduce the computational resources needed to determine a battery's internal states by replacing physics-based Li-ion battery models -- such as the single-particle model (SPM) and the pseudo-2D (P2D) model -- with a physics-informed neural network (PINN) surrogate. The surrogate model makes high-throughput techniques, such as Bayesian calibration, tractable to determine battery internal parameters from voltage responses. This manuscript is the first of a two-part series that introduces PINN surrogates of Li-ion battery models for parameter inference (i.e., state-of-health diagnostics). In this first part, a method is presented for constructing a PINN surrogate of the SPM. A multi-fidelity hierarchical training, where several neural nets are trained with multiple physics-loss fidelities is shown to significantly improve the surrogate accuracy when only training on the governing equation residuals. The implementation is made available in a companion repository (https://github.com/NREL/pinnstripes). The techniques used to develop a PINN surrogate of the SPM are extended in Part II for the PINN surrogate for the P2D battery model, and explore the Bayesian calibration capabilities of both surrogates.
<div id='section'>Paperid: <span id='pid'>87, <a href='https://arxiv.org/pdf/2312.10594.pdf' target='_blank'>https://arxiv.org/pdf/2312.10594.pdf</a></span>   <span><a href='https://github.com/jacobwang925/path-integral-PINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoyuan Wang, Reece Keller, Xiyu Deng, Kenta Hoshino, Takashi Tanaka, Yorie Nakahira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10594">Physics-Informed Representation and Learning: Control and Risk Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optimal and safety-critical control are fundamental problems for stochastic systems, and are widely considered in real-world scenarios such as robotic manipulation and autonomous driving. In this paper, we consider the problem of efficiently finding optimal and safe control for high-dimensional systems. Specifically, we propose to use dimensionality reduction techniques from a comparison theorem for stochastic differential equations together with a generalizable physics-informed neural network to estimate the optimal value function and the safety probability of the system. The proposed framework results in substantial sample efficiency improvement compared to existing methods. We further develop an autoencoder-like neural network to automatically identify the low-dimensional features of the system to enhance the ease of design for system integration. We also provide experiments and quantitative analysis to validate the efficacy of the proposed method. Source code is available at https://github.com/jacobwang925/path-integral-PINN.
<div id='section'>Paperid: <span id='pid'>88, <a href='https://arxiv.org/pdf/2312.05063.pdf' target='_blank'>https://arxiv.org/pdf/2312.05063.pdf</a></span>   <span><a href='https://github.com/m1balcerak/GliODIL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Michal Balcerak, Jonas Weidner, Petr Karnakov, Ivan Ezhov, Sergey Litvinov, Petros Koumoutsakos, Ray Zirui Zhang, John S. Lowengrub, Bene Wiestler, Bjoern Menze
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.05063">Individualizing Glioma Radiotherapy Planning by Optimization of Data and Physics-Informed Discrete Loss</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Brain tumor growth is unique to each glioma patient and extends beyond what is visible in imaging scans, infiltrating surrounding brain tissue. Understanding these hidden patient-specific progressions is essential for effective therapies. Current treatment plans for brain tumors, such as radiotherapy, typically involve delineating a uniform margin around the visible tumor on pre-treatment scans to target this invisible tumor growth. This "one size fits all" approach is derived from population studies and often fails to account for the nuances of individual patient conditions. We present the GliODIL framework, which infers the full spatial distribution of tumor cell concentration from available multi-modal imaging, leveraging a Fisher-Kolmogorov type physics model to describe tumor growth. This is achieved through the newly introduced method of Optimizing the Discrete Loss (ODIL), where both data and physics-based constraints are softly assimilated into the solution. Our test dataset comprises 152 glioblastoma patients with pre-treatment imaging and post-treatment follow-ups for tumor recurrence monitoring. By blending data-driven techniques with physics-based constraints, GliODIL enhances recurrence prediction in radiotherapy planning, challenging traditional uniform margins and strict adherence to the Fisher-Kolmogorov partial differential equation (PDE) model, which is adapted for complex cases.
<div id='section'>Paperid: <span id='pid'>89, <a href='https://arxiv.org/pdf/2312.03243.pdf' target='_blank'>https://arxiv.org/pdf/2312.03243.pdf</a></span>   <span><a href='https://github.com/chiuph/Baldwinian-PINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Cheng Wong, Chin Chun Ooi, Abhishek Gupta, Pao-Hsiung Chiu, Joshua Shao Zheng Low, My Ha Dao, Yew-Soon Ong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.03243">Evolutionary Optimization of Physics-Informed Neural Networks: Advancing Generalizability by the Baldwin Effect</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are at the forefront of scientific machine learning, making possible the creation of machine intelligence that is cognizant of physical laws and able to accurately simulate them. However, today's PINNs are often trained for a single physics task and require computationally expensive re-training for each new task, even for tasks from similar physics domains. To address this limitation, this paper proposes a pioneering approach to advance the generalizability of PINNs through the framework of Baldwinian evolution. Drawing inspiration from the neurodevelopment of precocial species that have evolved to learn, predict and react quickly to their environment, we envision PINNs that are pre-wired with connection strengths inducing strong biases towards efficient learning of physics. A novel two-stage stochastic programming formulation coupling evolutionary selection pressure (based on proficiency over a distribution of physics tasks) with lifetime learning (to specialize on a sampled subset of those tasks) is proposed to instantiate the Baldwin effect. The evolved Baldwinian-PINNs demonstrate fast and physics-compliant prediction capabilities across a range of empirically challenging problem instances with more than an order of magnitude improvement in prediction accuracy at a fraction of the computation cost compared to state-of-the-art gradient-based meta-learning methods. For example, when solving the diffusion-reaction equation, a 70x improvement in accuracy was obtained while taking 700x less computational time. This paper thus marks a leap forward in the meta-learning of PINNs as generalizable physics solvers. Sample codes are available at https://github.com/chiuph/Baldwinian-PINN.
<div id='section'>Paperid: <span id='pid'>90, <a href='https://arxiv.org/pdf/2311.04465.pdf' target='_blank'>https://arxiv.org/pdf/2311.04465.pdf</a></span>   <span><a href='https://github.com/xuangu-fang/Gaussian-Process-Slover-for-High-Freq-PDE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shikai Fang, Madison Cooley, Da Long, Shibo Li, Robert Kirby, Shandian Zhe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.04465">Solving High Frequency and Multi-Scale PDEs with Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning based solvers have garnered much attention in physical simulation and scientific computing, with a prominent example, physics-informed neural networks (PINNs). However, PINNs often struggle to solve high-frequency and multi-scale PDEs, which can be due to spectral bias during neural network training. To address this problem, we resort to the Gaussian process (GP) framework. To flexibly capture the dominant frequencies, we model the power spectrum of the PDE solution with a student $t$ mixture or Gaussian mixture. We apply the inverse Fourier transform to obtain the covariance function (by Wiener-Khinchin theorem). The covariance derived from the Gaussian mixture spectrum corresponds to the known spectral mixture kernel. Next, we estimate the mixture weights in the log domain, which we show is equivalent to placing a Jeffreys prior. It automatically induces sparsity, prunes excessive frequencies, and adjusts the remaining toward the ground truth. Third, to enable efficient and scalable computation on massive collocation points, which are critical to capture high frequencies, we place the collocation points on a grid, and multiply our covariance function at each input dimension. We use the GP conditional mean to predict the solution and its derivatives so as to fit the boundary condition and the equation itself. As a result, we can derive a Kronecker product structure in the covariance matrix. We use Kronecker product properties and multilinear algebra to promote computational efficiency and scalability, without low-rank approximations. We show the advantage of our method in systematic experiments. The code is released at \url{https://github.com/xuangu-fang/Gaussian-Process-Slover-for-High-Freq-PDE}.
<div id='section'>Paperid: <span id='pid'>91, <a href='https://arxiv.org/pdf/2311.03626.pdf' target='_blank'>https://arxiv.org/pdf/2311.03626.pdf</a></span>   <span><a href='https://github.com/rezaakb/pinns-tf2' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Reza Akbarian Bafghi, Maziar Raissi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.03626">PINNs-TF2: Fast and User-Friendly Physics-Informed Neural Networks in TensorFlow V2</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have gained prominence for their capability to tackle supervised learning tasks that conform to physical laws, notably nonlinear partial differential equations (PDEs). This paper presents "PINNs-TF2", a Python package built on the TensorFlow V2 framework. It not only accelerates PINNs implementation but also simplifies user interactions by abstracting complex PDE challenges. We underscore the pivotal role of compilers in PINNs, highlighting their ability to boost performance by up to 119x. Across eight diverse examples, our package, integrated with XLA compilers, demonstrated its flexibility and achieved an average speed-up of 18.12 times over TensorFlow V1. Moreover, a real-world case study is implemented to underscore the compilers' potential to handle many trainable parameters and large batch sizes. For community engagement and future enhancements, our package's source code is openly available at: https://github.com/rezaakb/pinns-tf2.
<div id='section'>Paperid: <span id='pid'>92, <a href='https://arxiv.org/pdf/2311.02495.pdf' target='_blank'>https://arxiv.org/pdf/2311.02495.pdf</a></span>   <span><a href='https://github.com/avakanski/Creep-uncertainty-quantification' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Longze Li, Jiang Chang, Aleksandar Vakanski, Yachun Wang, Tiankai Yao, Min Xian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.02495">Uncertainty Quantification in Multivariable Regression for Material Property Prediction with Bayesian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the increased use of data-driven approaches and machine learning-based methods in material science, the importance of reliable uncertainty quantification (UQ) of the predicted variables for informed decision-making cannot be overstated. UQ in material property prediction poses unique challenges, including the multi-scale and multi-physics nature of advanced materials, intricate interactions between numerous factors, limited availability of large curated datasets for model training, etc. Recently, Bayesian Neural Networks (BNNs) have emerged as a promising approach for UQ, offering a probabilistic framework for capturing uncertainties within neural networks. In this work, we introduce an approach for UQ within physics-informed BNNs, which integrates knowledge from governing laws in material modeling to guide the models toward physically consistent predictions. To evaluate the effectiveness of this approach, we present case studies for predicting the creep rupture life of steel alloys. Experimental validation with three datasets of collected measurements from creep tests demonstrates the ability of BNNs to produce accurate point and uncertainty estimates that are competitive or exceed the performance of the conventional method of Gaussian Process Regression. Similarly, we evaluated the suitability of BNNs for UQ in an active learning application and reported competitive performance. The most promising framework for creep life prediction is BNNs based on Markov Chain Monte Carlo approximation of the posterior distribution of network parameters, as it provided more reliable results in comparison to BNNs based on variational inference approximation or related NNs with probabilistic outputs. The codes are available at: https://github.com/avakanski/Creep-uncertainty-quantification.
<div id='section'>Paperid: <span id='pid'>93, <a href='https://arxiv.org/pdf/2310.15690.pdf' target='_blank'>https://arxiv.org/pdf/2310.15690.pdf</a></span>   <span><a href='https://github.com/CMMAi/ResNet_for_PINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Amir Noorizadegan, D. L. Young, Y. C. Hon, C. S. Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.15690">Power-Enhanced Residual Network for Function Approximation and Physics-Informed Inverse Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we investigate how the updating of weights during forward operation and the computation of gradients during backpropagation impact the optimization process, training procedure, and overall performance of the neural network, particularly the multi-layer perceptrons (MLPs). This paper introduces a novel neural network structure called the Power-Enhancing residual network, inspired by highway network and residual network, designed to improve the network's capabilities for both smooth and non-smooth functions approximation in 2D and 3D settings. By incorporating power terms into residual elements, the architecture enhances the stability of weight updating, thereby facilitating better convergence and accuracy. The study explores network depth, width, and optimization methods, showing the architecture's adaptability and performance advantages. Consistently, the results emphasize the exceptional accuracy of the proposed Power-Enhancing residual network, particularly for non-smooth functions. Real-world examples also confirm its superiority over plain neural network in terms of accuracy, convergence, and efficiency. Moreover, the proposed architecture is also applied to solving the inverse Burgers' equation, demonstrating superior performance. In conclusion, the Power-Enhancing residual network offers a versatile solution that significantly enhances neural network capabilities by emphasizing the importance of stable weight updates for effective training in deep neural networks. The codes implemented are available at: \url{https://github.com/CMMAi/ResNet_for_PINN}.
<div id='section'>Paperid: <span id='pid'>94, <a href='https://arxiv.org/pdf/2310.06923.pdf' target='_blank'>https://arxiv.org/pdf/2310.06923.pdf</a></span>   <span><a href='https://github.com/ShenQianli/PICProp' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qianli Shen, Wai Hoh Tang, Zhun Deng, Apostolos Psaros, Kenji Kawaguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06923">PICProp: Physics-Informed Confidence Propagation for Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Standard approaches for uncertainty quantification in deep learning and physics-informed learning have persistent limitations. Indicatively, strong assumptions regarding the data likelihood are required, the performance highly depends on the selection of priors, and the posterior can be sampled only approximately, which leads to poor approximations because of the associated computational cost. This paper introduces and studies confidence interval (CI) estimation for deterministic partial differential equations as a novel problem. That is, to propagate confidence, in the form of CIs, from data locations to the entire domain with probabilistic guarantees. We propose a method, termed Physics-Informed Confidence Propagation (PICProp), based on bi-level optimization to compute a valid CI without making heavy assumptions. We provide a theorem regarding the validity of our method, and computational experiments, where the focus is on physics-informed learning.
<div id='section'>Paperid: <span id='pid'>95, <a href='https://arxiv.org/pdf/2308.10283.pdf' target='_blank'>https://arxiv.org/pdf/2308.10283.pdf</a></span>   <span><a href='https://github.com/Pongpisit-Thanasutives/UBIC' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pongpisit Thanasutives, Takashi Morita, Masayuki Numao, Ken-ichi Fukui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10283">Adaptive Uncertainty-Guided Model Selection for Data-Driven PDE Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a new parameter-adaptive uncertainty-penalized Bayesian information criterion (UBIC) to prioritize the parsimonious partial differential equation (PDE) that sufficiently governs noisy spatial-temporal observed data with few reliable terms. Since the naive use of the BIC for model selection has been known to yield an undesirable overfitted PDE, the UBIC penalizes the found PDE not only by its complexity but also the quantified uncertainty, derived from the model supports' coefficient of variation in a probabilistic view. We also introduce physics-informed neural network learning as a simulation-based approach to further validate the selected PDE flexibly against the other discovered PDE. Numerical results affirm the successful application of the UBIC in identifying the true governing PDE. Additionally, we reveal an interesting effect of denoising the observed data on improving the trade-off between the BIC score and model complexity. Code is available at https://github.com/Pongpisit-Thanasutives/UBIC.
<div id='section'>Paperid: <span id='pid'>96, <a href='https://arxiv.org/pdf/2308.04073.pdf' target='_blank'>https://arxiv.org/pdf/2308.04073.pdf</a></span>   <span><a href='https://github.com/LeapLabTHU/AdaAFforPINNs' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Honghui Wang, Lu Lu, Shiji Song, Gao Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04073">Learning Specialized Activation Functions for Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are known to suffer from optimization difficulty. In this work, we reveal the connection between the optimization difficulty of PINNs and activation functions. Specifically, we show that PINNs exhibit high sensitivity to activation functions when solving PDEs with distinct properties. Existing works usually choose activation functions by inefficient trial-and-error. To avoid the inefficient manual selection and to alleviate the optimization difficulty of PINNs, we introduce adaptive activation functions to search for the optimal function when solving different problems. We compare different adaptive activation functions and discuss their limitations in the context of PINNs. Furthermore, we propose to tailor the idea of learning combinations of candidate activation functions to the PINNs optimization, which has a higher requirement for the smoothness and diversity on learned functions. This is achieved by removing activation functions which cannot provide higher-order derivatives from the candidate set and incorporating elementary functions with different properties according to our prior knowledge about the PDE at hand. We further enhance the search space with adaptive slopes. The proposed adaptive activation function can be used to solve different PDE systems in an interpretable way. Its effectiveness is demonstrated on a series of benchmarks. Code is available at https://github.com/LeapLabTHU/AdaAFforPINNs.
<div id='section'>Paperid: <span id='pid'>97, <a href='https://arxiv.org/pdf/2307.12306.pdf' target='_blank'>https://arxiv.org/pdf/2307.12306.pdf</a></span>   <span><a href='https://github.com/zheyuanhu01/SDGD_PINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheyuan Hu, Khemraj Shukla, George Em Karniadakis, Kenji Kawaguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.12306">Tackling the Curse of Dimensionality with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The curse-of-dimensionality taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs, as Richard E. Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. We develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and randomly samples a subset of these dimensional pieces in each iteration of training PINNs. We prove theoretically the convergence and other desired properties of the proposed method. We demonstrate in various diverse tests that the proposed method can solve many notoriously hard high-dimensional PDEs, including the Hamilton-Jacobi-Bellman (HJB) and the SchrÃ¶dinger equations in tens of thousands of dimensions very fast on a single GPU using the PINNs mesh-free approach. Notably, we solve nonlinear PDEs with nontrivial, anisotropic, and inseparable solutions in 100,000 effective dimensions in 12 hours on a single GPU using SDGD with PINNs. Since SDGD is a general training methodology of PINNs, it can be applied to any current and future variants of PINNs to scale them up for arbitrary high-dimensional PDEs.
<div id='section'>Paperid: <span id='pid'>98, <a href='https://arxiv.org/pdf/2307.06167.pdf' target='_blank'>https://arxiv.org/pdf/2307.06167.pdf</a></span>   <span><a href='https://github.com/junjun-yan/ATL-PINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Junjun Yan, Xinhai Chen, Zhichao Wang, Enqiang Zhou, Jie Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.06167">Auxiliary-Tasks Learning for Physics-Informed Neural Network-Based Partial Differential Equations Solving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as promising surrogate modes for solving partial differential equations (PDEs). Their effectiveness lies in the ability to capture solution-related features through neural networks. However, original PINNs often suffer from bottlenecks, such as low accuracy and non-convergence, limiting their applicability in complex physical contexts. To alleviate these issues, we proposed auxiliary-task learning-based physics-informed neural networks (ATL-PINNs), which provide four different auxiliary-task learning modes and investigate their performance compared with original PINNs. We also employ the gradient cosine similarity algorithm to integrate auxiliary problem loss with the primary problem loss in ATL-PINNs, which aims to enhance the effectiveness of the auxiliary-task learning modes. To the best of our knowledge, this is the first study to introduce auxiliary-task learning modes in the context of physics-informed learning. We conduct experiments on three PDE problems across different fields and scenarios. Our findings demonstrate that the proposed auxiliary-task learning modes can significantly improve solution accuracy, achieving a maximum performance boost of 96.62% (averaging 28.23%) compared to the original single-task PINNs. The code and dataset are open source at https://github.com/junjun-yan/ATL-PINN.
<div id='section'>Paperid: <span id='pid'>99, <a href='https://arxiv.org/pdf/2306.13385.pdf' target='_blank'>https://arxiv.org/pdf/2306.13385.pdf</a></span>   <span><a href='https://github.com/Blue-Giant/FMPINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xi'an Li, Jinran Wu, You-Gan Wang, Xin Tai, Jianhua Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13385">Solving a class of multi-scale elliptic PDEs by means of Fourier-based mixed physics informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have garnered widespread attention due to their simplicity and flexibility in the fields of engineering and scientific calculation. In this study, we probe into solving a class of elliptic partial differential equations(PDEs) with multiple scales by utilizing Fourier-based mixed physics informed neural networks(dubbed FMPINN), its solver is configured as a multi-scale deep neural network. In contrast to the classical PINN method, a dual (flux) variable about the rough coefficient of PDEs is introduced to avoid the ill-condition of neural tangent kernel matrix caused by the oscillating coefficient of multi-scale PDEs. Therefore, apart from the physical conservation laws, the discrepancy between the auxiliary variables and the gradients of multi-scale coefficients is incorporated into the cost function, then obtaining a satisfactory solution of PDEs by minimizing the defined loss through some optimization methods. Additionally, a trigonometric activation function is introduced for FMPINN, which is suited for representing the derivatives of complex target functions. Handling the input data by Fourier feature mapping will effectively improve the capacity of deep neural networks to solve high-frequency problems. Finally, to validate the efficiency and robustness of the proposed FMPINN algorithm, we present several numerical examples of multi-scale problems in various dimensional Euclidean spaces. These examples cover both low-frequency and high-frequency oscillation cases, demonstrating the effectiveness of our approach. All code and data accompanying this manuscript will be made publicly available at \href{https://github.com/Blue-Giant/FMPINN}{https://github.com/Blue-Giant/FMPINN}.
<div id='section'>Paperid: <span id='pid'>100, <a href='https://arxiv.org/pdf/2306.09389.pdf' target='_blank'>https://arxiv.org/pdf/2306.09389.pdf</a></span>   <span><a href='https://github.com/junjun-yan/ST-PINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Junjun Yan, Xinhai Chen, Zhichao Wang, Enqiang Zhoui, Jie Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09389">ST-PINN: A Self-Training Physics-Informed Neural Network for Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial differential equations (PDEs) are an essential computational kernel in physics and engineering. With the advance of deep learning, physics-informed neural networks (PINNs), as a mesh-free method, have shown great potential for fast PDE solving in various applications. To address the issue of low accuracy and convergence problems of existing PINNs, we propose a self-training physics-informed neural network, ST-PINN. Specifically, ST-PINN introduces a pseudo label based self-learning algorithm during training. It employs governing equation as the pseudo-labeled evaluation index and selects the highest confidence examples from the sample points to attach the pseudo labels. To our best knowledge, we are the first to incorporate a self-training mechanism into physics-informed learning. We conduct experiments on five PDE problems in different fields and scenarios. The results demonstrate that the proposed method allows the network to learn more physical information and benefit convergence. The ST-PINN outperforms existing physics-informed neural network methods and improves the accuracy by a factor of 1.33x-2.54x. The code of ST-PINN is available at GitHub: https://github.com/junjun-yan/ST-PINN.
<div id='section'>Paperid: <span id='pid'>101, <a href='https://arxiv.org/pdf/2306.05014.pdf' target='_blank'>https://arxiv.org/pdf/2306.05014.pdf</a></span>   <span><a href='https://github.com/envfluids/py2d' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/jakharkaran/EqsDiscovery_2D-FHIT_RBC' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Karan Jakhar, Yifei Guan, Rambod Mojgani, Ashesh Chattopadhyay, Pedram Hassanzadeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.05014">Learning Closed-form Equations for Subgrid-scale Closures from High-fidelity Data: Promises and Challenges</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There is growing interest in discovering interpretable, closed-form equations for subgrid-scale (SGS) closures/parameterizations of complex processes in Earth systems. Here, we apply a common equation-discovery technique with expansive libraries to learn closures from filtered direct numerical simulations of 2D turbulence and Rayleigh-BÃ©nard convection (RBC). Across common filters (e.g., Gaussian, box), we robustly discover closures of the same form for momentum and heat fluxes. These closures depend on nonlinear combinations of gradients of filtered variables, with constants that are independent of the fluid/flow properties and only depend on filter type/size. We show that these closures are the nonlinear gradient model (NGM), which is derivable analytically using Taylor-series. Indeed, we suggest that with common (physics-free) equation-discovery algorithms, for many common systems/physics, discovered closures are consistent with the leading term of the Taylor-series (except when cutoff filters are used). Like previous studies, we find that large-eddy simulations with NGM closures are unstable, despite significant similarities between the true and NGM-predicted fluxes (correlations $> 0.95$). We identify two shortcomings as reasons for these instabilities: in 2D, NGM produces zero kinetic energy transfer between resolved and subgrid scales, lacking both diffusion and backscattering. In RBC, potential energy backscattering is poorly predicted. Moreover, we show that SGS fluxes diagnosed from data, presumed the ''truth'' for discovery, depend on filtering procedures and are not unique. Accordingly, to learn accurate, stable closures in future work, we propose several ideas around using physics-informed libraries, loss functions, and metrics. These findings are relevant to closure modeling of any multi-scale system.
<div id='section'>Paperid: <span id='pid'>102, <a href='https://arxiv.org/pdf/2306.03105.pdf' target='_blank'>https://arxiv.org/pdf/2306.03105.pdf</a></span>   <span><a href='https://github.com/gautamksaharia/Fokas-Lenells' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Gautam Kumar Saharia, Sagardeep Talukdar, Riki Dutta, Sudipta Nandy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03105">Data driven localized wave solution of the Fokas-Lenells equation using modified PINN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate data driven localized wave solutions of the Fokas-Lenells equation by using physics informed neural network(PINN). We improve basic PINN by incorporating control parameters into the residual loss function. We also add conserve quantity as another loss term to modify the PINN. Using modified PINN we obtain the data driven bright soliton and dark soliton solutions of Fokas-Lenells equation. Conserved quantities informed loss function achieve more accuracy in terms of relative L2 error between predicted and exact soliton solutions. We hope that the present investigation would be useful to study the applications of deep learning in nonlinear optics and other branches of nonlinear physics. Source codes are available at https://github.com/gautamksaharia/Fokas-Lenells
<div id='section'>Paperid: <span id='pid'>103, <a href='https://arxiv.org/pdf/2306.00616.pdf' target='_blank'>https://arxiv.org/pdf/2306.00616.pdf</a></span>   <span><a href='https://github.com/ruiqini/P-NTFields' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiqi Ni, Ahmed H. Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.00616">Progressive Learning for Physics-informed Neural Motion Planning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motion planning (MP) is one of the core robotics problems requiring fast methods for finding a collision-free robot motion path connecting the given start and goal states. Neural motion planners (NMPs) demonstrate fast computational speed in finding path solutions but require a huge amount of expert trajectories for learning, thus adding a significant training computational load. In contrast, recent advancements have also led to a physics-informed NMP approach that directly solves the Eikonal equation for motion planning and does not require expert demonstrations for learning. However, experiments show that the physics-informed NMP approach performs poorly in complex environments and lacks scalability in multiple scenarios and high-dimensional real robot settings. To overcome these limitations, this paper presents a novel and tractable Eikonal equation formulation and introduces a new progressive learning strategy to train neural networks without expert data in complex, cluttered, multiple high-dimensional robot motion planning scenarios. The results demonstrate that our method outperforms state-of-the-art traditional MP, data-driven NMP, and physics-informed NMP methods by a significant margin in terms of computational planning speed, path quality, and success rates. We also show that our approach scales to multiple complex, cluttered scenarios and the real robot set up in a narrow passage environment. The proposed method's videos and code implementations are available at https://github.com/ruiqini/P-NTFields.
<div id='section'>Paperid: <span id='pid'>104, <a href='https://arxiv.org/pdf/2306.00230.pdf' target='_blank'>https://arxiv.org/pdf/2306.00230.pdf</a></span>   <span><a href='https://github.com/barbagroup/jcs_paper_pinn},' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pi-Yueh Chuang, Lorena A. Barba
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.00230">Predictive Limitations of Physics-Informed Neural Networks in Vortex Shedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent surge of interest in physics-informed neural network (PINN) methods has led to a wave of studies that attest to their potential for solving partial differential equations (PDEs) and predicting the dynamics of physical systems. However, the predictive limitations of PINNs have not been thoroughly investigated. We look at the flow around a 2D cylinder and find that data-free PINNs are unable to predict vortex shedding. Data-driven PINN exhibits vortex shedding only while the training data (from a traditional CFD solver) is available, but reverts to the steady state solution when the data flow stops. We conducted dynamic mode decomposition and analyze the Koopman modes in the solutions obtained with PINNs versus a traditional fluid solver (PetIBM). The distribution of the Koopman eigenvalues on the complex plane suggests that PINN is numerically dispersive and diffusive. The PINN method reverts to the steady solution possibly as a consequence of spectral bias. This case study reaises concerns about the ability of PINNs to predict flows with instabilities, specifically vortex shedding. Our computational study supports the need for more theoretical work to analyze the numerical properties of PINN methods. The results in this paper are transparent and reproducible, with all data and code available in public repositories and persistent archives; links are provided in the paper repository at \url{https://github.com/barbagroup/jcs_paper_pinn}, and a Reproducibility Statement within the paper.
<div id='section'>Paperid: <span id='pid'>105, <a href='https://arxiv.org/pdf/2305.17387.pdf' target='_blank'>https://arxiv.org/pdf/2305.17387.pdf</a></span>   <span><a href='https://github.com/ehsansaleh/btspinn' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ehsan Saleh, Saba Ghaffari, Timothy Bretl, Luke Olson, Matthew West
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.17387">Learning from Integral Losses in Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work proposes a solution for the problem of training physics-informed networks under partial integro-differential equations. These equations require an infinite or a large number of neural evaluations to construct a single residual for training. As a result, accurate evaluation may be impractical, and we show that naive approximations at replacing these integrals with unbiased estimates lead to biased loss functions and solutions. To overcome this bias, we investigate three types of potential solutions: the deterministic sampling approaches, the double-sampling trick, and the delayed target method. We consider three classes of PDEs for benchmarking; one defining Poisson problems with singular charges and weak solutions of up to 10 dimensions, another involving weak solutions on electro-magnetic fields and a Maxwell equation, and a third one defining a Smoluchowski coagulation problem. Our numerical results confirm the existence of the aforementioned bias in practice and also show that our proposed delayed target approach can lead to accurate solutions with comparable quality to ones estimated with a large sample size integral. Our implementation is open-source and available at https://github.com/ehsansaleh/btspinn.
<div id='section'>Paperid: <span id='pid'>106, <a href='https://arxiv.org/pdf/2305.13650.pdf' target='_blank'>https://arxiv.org/pdf/2305.13650.pdf</a></span>   <span><a href='https://github.com/sabagh1994/PGVAE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saba Ghaffari, Ehsan Saleh, Alexander G. Schwing, Yu-Xiong Wang, Martin D. Burke, Saurabh Sinha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.13650">Robust Model-Based Optimization for Challenging Fitness Landscapes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protein design, a grand challenge of the day, involves optimization on a fitness landscape, and leading methods adopt a model-based approach where a model is trained on a training set (protein sequences and fitness) and proposes candidates to explore next. These methods are challenged by sparsity of high-fitness samples in the training set, a problem that has been in the literature. A less recognized but equally important problem stems from the distribution of training samples in the design space: leading methods are not designed for scenarios where the desired optimum is in a region that is not only poorly represented in training data, but also relatively far from the highly represented low-fitness regions. We show that this problem of "separation" in the design space is a significant bottleneck in existing model-based optimization tools and propose a new approach that uses a novel VAE as its search model to overcome the problem. We demonstrate its advantage over prior methods in robustly finding improved samples, regardless of the imbalance and separation between low- and high-fitness samples. Our comprehensive benchmark on real and semi-synthetic protein datasets as well as solution design for physics-informed neural networks, showcases the generality of our approach in discrete and continuous design spaces. Our implementation is available at https://github.com/sabagh1994/PGVAE.
<div id='section'>Paperid: <span id='pid'>107, <a href='https://arxiv.org/pdf/2305.06863.pdf' target='_blank'>https://arxiv.org/pdf/2305.06863.pdf</a></span>   <span><a href='https://github.com/Sysuzqs/DFVM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianhuan Cen, Qingsong Zou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.06863">Deep Finite Volume Method for Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce the Deep Finite Volume Method (DFVM), an innovative deep learning framework tailored for solving high-order (order \(\geq 2\)) partial differential equations (PDEs). Our approach centers on a novel loss function crafted from local conservation laws derived from the original PDE, distinguishing DFVM from traditional deep learning methods. By formulating DFVM in the weak form of the PDE rather than the strong form, we enhance accuracy, particularly beneficial for PDEs with less smooth solutions compared to strong-form-based methods like Physics-Informed Neural Networks (PINNs). A key technique of DFVM lies in its transformation of all second-order or higher derivatives of neural networks into first-order derivatives which can be comupted directly using Automatic Differentiation (AD). This adaptation significantly reduces computational overhead, particularly advantageous for solving high-dimensional PDEs. Numerical experiments demonstrate that DFVM achieves equal or superior solution accuracy compared to existing deep learning methods such as PINN, Deep Ritz Method (DRM), and Weak Adversarial Networks (WAN), while drastically reducing computational costs. Notably, for PDEs with nonsmooth solutions, DFVM yields approximate solutions with relative errors up to two orders of magnitude lower than those obtained by PINN. The implementation of DFVM is available on GitHub at \href{https://github.com/Sysuzqs/DFVM}{https://github.com/Sysuzqs/DFVM}.
<div id='section'>Paperid: <span id='pid'>108, <a href='https://arxiv.org/pdf/2305.03868.pdf' target='_blank'>https://arxiv.org/pdf/2305.03868.pdf</a></span>   <span><a href='https://github.com/sriram-2502/KoopmanMPC_Quadrotor' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sriram S. K. S. Narayanan, Duvan Tellez-Castro, Sarang Sutavani, Umesh Vaidya
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.03868">SE(3) Koopman-MPC: Data-driven Learning and Control of Quadrotor UAVs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a novel data-driven approach for learning and control of quadrotor UAVs based on the Koopman operator and extended dynamic mode decomposition (EDMD). Building observables for EDMD based on conventional methods like Euler angles (to represent orientation) is known to involve singularities. To address this issue, we employ a set of physics-informed observables based on the underlying topology of the nonlinear system. We use rotation matrices to directly represent the orientation dynamics and obtain a lifted linear representation of the nonlinear quadrotor dynamics in the SE(3) manifold. This EDMD model leads to accurate prediction and can be generalized to several validation sets. Further, we design a linear model predictive controller (MPC) based on the proposed EDMD model to track agile reference trajectories. Simulation results show that the proposed MPC controller can run as fast as 100 Hz and is able to track arbitrary reference trajectories with good accuracy. Implementation details can be found in \url{https://github.com/sriram-2502/KoopmanMPC_Quadrotor}.
<div id='section'>Paperid: <span id='pid'>109, <a href='https://arxiv.org/pdf/2304.06234.pdf' target='_blank'>https://arxiv.org/pdf/2304.06234.pdf</a></span>   <span><a href='https://github.com/JinshuaiBai/PIRBN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinshuai Bai, Gui-Rong Liu, Ashish Gupta, Laith Alzubaidi, Xi-Qiao Feng, YuanTong Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06234">Physics-informed radial basis network (PIRBN): A local approximating neural network for solving nonlinear PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Our recent intensive study has found that physics-informed neural networks (PINN) tend to be local approximators after training. This observation leads to this novel physics-informed radial basis network (PIRBN), which can maintain the local property throughout the entire training process. Compared to deep neural networks, a PIRBN comprises of only one hidden layer and a radial basis "activation" function. Under appropriate conditions, we demonstrated that the training of PIRBNs using gradient descendent methods can converge to Gaussian processes. Besides, we studied the training dynamics of PIRBN via the neural tangent kernel (NTK) theory. In addition, comprehensive investigations regarding the initialisation strategies of PIRBN were conducted. Based on numerical examples, PIRBN has been demonstrated to be more effective and efficient than PINN in solving PDEs with high-frequency features and ill-posed computational domains. Moreover, the existing PINN numerical techniques, such as adaptive learning, decomposition and different types of loss functions, are applicable to PIRBN. The programs that can regenerate all numerical results can be found at https://github.com/JinshuaiBai/PIRBN.
<div id='section'>Paperid: <span id='pid'>110, <a href='https://arxiv.org/pdf/2302.05968.pdf' target='_blank'>https://arxiv.org/pdf/2302.05968.pdf</a></span>   <span><a href='https://github.com/roydenwa/pseudo-colorize-masked-cells' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Royden Wagner, Carlos Fernandez Lopez, Christoph Stiller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05968">Self-supervised pseudo-colorizing of masked cells</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised learning, which is strikingly referred to as the dark matter of intelligence, is gaining more attention in biomedical applications of deep learning. In this work, we introduce a novel self-supervision objective for the analysis of cells in biomedical microscopy images. We propose training deep learning models to pseudo-colorize masked cells. We use a physics-informed pseudo-spectral colormap that is well suited for colorizing cell topology. Our experiments reveal that approximating semantic segmentation by pseudo-colorization is beneficial for subsequent fine-tuning on cell detection. Inspired by the recent success of masked image modeling, we additionally mask out cell parts and train to reconstruct these parts to further enrich the learned representations. We compare our pre-training method with self-supervised frameworks including contrastive learning (SimCLR), masked autoencoders (MAEs), and edge-based self-supervision. We build upon our previous work and train hybrid models for cell detection, which contain both convolutional and vision transformer modules. Our pre-training method can outperform SimCLR, MAE-like masked image modeling, and edge-based self-supervision when pre-training on a diverse set of six fluorescence microscopy datasets. Code is available at: https://github.com/roydenwa/pseudo-colorize-masked-cells
<div id='section'>Paperid: <span id='pid'>111, <a href='https://arxiv.org/pdf/2301.10343.pdf' target='_blank'>https://arxiv.org/pdf/2301.10343.pdf</a></span>   <span><a href='https://github.com/microsoft/ClimaX' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tung Nguyen, Johannes Brandstetter, Ashish Kapoor, Jayesh K. Gupta, Aditya Grover
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.10343">ClimaX: A foundation model for weather and climate</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most state-of-the-art approaches for weather and climate modeling are based on physics-informed numerical models of the atmosphere. These approaches aim to model the non-linear dynamics and complex interactions between multiple variables, which are challenging to approximate. Additionally, many such numerical models are computationally intensive, especially when modeling the atmospheric phenomenon at a fine-grained spatial and temporal resolution. Recent data-driven approaches based on machine learning instead aim to directly solve a downstream forecasting or projection task by learning a data-driven functional mapping using deep neural networks. However, these networks are trained using curated and homogeneous climate datasets for specific spatiotemporal tasks, and thus lack the generality of numerical models. We develop and demonstrate ClimaX, a flexible and generalizable deep learning model for weather and climate science that can be trained using heterogeneous datasets spanning different variables, spatio-temporal coverage, and physical groundings. ClimaX extends the Transformer architecture with novel encoding and aggregation blocks that allow effective use of available compute while maintaining general utility. ClimaX is pre-trained with a self-supervised learning objective on climate datasets derived from CMIP6. The pre-trained ClimaX can then be fine-tuned to address a breadth of climate and weather tasks, including those that involve atmospheric variables and spatio-temporal scales unseen during pretraining. Compared to existing data-driven baselines, we show that this generality in ClimaX results in superior performance on benchmarks for weather forecasting and climate projections, even when pretrained at lower resolutions and compute budgets. The source code is available at https://github.com/microsoft/ClimaX.
<div id='section'>Paperid: <span id='pid'>112, <a href='https://arxiv.org/pdf/2211.13944.pdf' target='_blank'>https://arxiv.org/pdf/2211.13944.pdf</a></span>   <span><a href='https://github.com/MatrixBrain/DMIS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zijiang Yang, Zhongwei Qiu, Dongmei Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.13944">DMIS: Dynamic Mesh-based Importance Sampling for Training Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling dynamics in the form of partial differential equations (PDEs) is an effectual way to understand real-world physics processes. For complex physics systems, analytical solutions are not available and numerical solutions are widely-used. However, traditional numerical algorithms are computationally expensive and challenging in handling multiphysics systems. Recently, using neural networks to solve PDEs has made significant progress, called physics-informed neural networks (PINNs). PINNs encode physical laws into neural networks and learn the continuous solutions of PDEs. For the training of PINNs, existing methods suffer from the problems of inefficiency and unstable convergence, since the PDE residuals require calculating automatic differentiation. In this paper, we propose Dynamic Mesh-based Importance Sampling (DMIS) to tackle these problems. DMIS is a novel sampling scheme based on importance sampling, which constructs a dynamic triangular mesh to estimate sample weights efficiently. DMIS has broad applicability and can be easily integrated into existing methods. The evaluation of DMIS on three widely-used benchmarks shows that DMIS improves the convergence speed and accuracy in the meantime. Especially in solving the highly nonlinear SchrÃ¶dinger Equation, compared with state-of-the-art methods, DMIS shows up to 46% smaller root mean square error and five times faster convergence speed. Code are available at https://github.com/MatrixBrain/DMIS.
<div id='section'>Paperid: <span id='pid'>113, <a href='https://arxiv.org/pdf/2211.12549.pdf' target='_blank'>https://arxiv.org/pdf/2211.12549.pdf</a></span>   <span><a href='https://github.com/fsahli/WarpPINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pablo Arratia LÃ³pez, HernÃ¡n Mella, Sergio Uribe, Daniel E. Hurtado, Francisco Sahli Costabal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.12549">WarpPINN: Cine-MR image registration with physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Heart failure is typically diagnosed with a global function assessment, such as ejection fraction. However, these metrics have low discriminate power, failing to distinguish different types of this disease. Quantifying local deformations in the form of cardiac strain can provide helpful information, but it remains a challenge. In this work, we introduce WarpPINN, a physics-informed neural network to perform image registration to obtain local metrics of the heart deformation. We apply this method to cine magnetic resonance images to estimate the motion during the cardiac cycle. We inform our neural network of near-incompressibility of cardiac tissue by penalizing the jacobian of the deformation field. The loss function has two components: an intensity-based similarity term between the reference and the warped template images, and a regularizer that represents the hyperelastic behavior of the tissue. The architecture of the neural network allows us to easily compute the strain via automatic differentiation to assess cardiac activity. We use Fourier feature mappings to overcome the spectral bias of neural networks, allowing us to capture discontinuities in the strain field. We test our algorithm on a synthetic example and on a cine-MRI benchmark of 15 healthy volunteers. We outperform current methodologies both landmark tracking and strain estimation. We expect that WarpPINN will enable more precise diagnostics of heart failure based on local deformation information. Source code is available at https://github.com/fsahli/WarpPINN.
<div id='section'>Paperid: <span id='pid'>114, <a href='https://arxiv.org/pdf/2210.10418.pdf' target='_blank'>https://arxiv.org/pdf/2210.10418.pdf</a></span>   <span><a href='https://github.com/Romain3Ch216/p3VAE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Romain Thoreau, Laurent Risser, VÃ©ronique Achard, BÃ©atrice Berthelot, Xavier Briottet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.10418">Physics-informed Variational Autoencoders for Improved Robustness to Environmental Factors of Variation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The combination of machine learning models with physical models is a recent research path to learn robust data representations. In this paper, we introduce p$^3$VAE, a variational autoencoder that integrates prior physical knowledge about the latent factors of variation that are related to the data acquisition conditions. p$^3$VAE combines standard neural network layers with non-trainable physics layers in order to partially ground the latent space to physical variables. We introduce a semi-supervised learning algorithm that strikes a balance between the machine learning part and the physics part. Experiments on simulated and real data sets demonstrate the benefits of our framework against competing physics-informed and conventional machine learning models, in terms of extrapolation capabilities and interpretability. In particular, we show that p$^3$VAE naturally has interesting disentanglement capabilities. Our code and data have been made publicly available at https://github.com/Romain3Ch216/p3VAE.
<div id='section'>Paperid: <span id='pid'>115, <a href='https://arxiv.org/pdf/2210.09060.pdf' target='_blank'>https://arxiv.org/pdf/2210.09060.pdf</a></span>   <span><a href='https://github.com/JinshuaiBai/PINN_Comp_Mech' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinshuai Bai, Hyogu Jeong, C. P. Batuwatta-Gamage, Shusheng Xiao, Qingxia Wang, C. M. Rathnayaka, Laith Alzubaidi, Gui-Rong Liu, Yuantong Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.09060">An introduction to programming Physics-Informed Neural Network-based computational solid mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural network (PINN) has recently gained increasing interest in computational mechanics. In this work, we present a detailed introduction to programming PINN-based computational solid mechanics. Besides, two prevailingly used physics-informed loss functions for PINN-based computational solid mechanics are summarised. Moreover, numerical examples ranging from 1D to 3D solid problems are presented to show the performance of PINN-based computational solid mechanics. The programs are built via Python coding language and TensorFlow library with step-by-step explanations. It is worth highlighting that PINN-based computational mechanics is easy to implement and can be extended for more challenging applications. This work aims to help the researchers who are interested in the PINN-based solid mechanics solver to have a clear insight into this emerging area. The programs for all the numerical examples presented in this work are available on https://github.com/JinshuaiBai/PINN_Comp_Mech.
<div id='section'>Paperid: <span id='pid'>116, <a href='https://arxiv.org/pdf/2207.12800.pdf' target='_blank'>https://arxiv.org/pdf/2207.12800.pdf</a></span>   <span><a href='https://github.com/NamGyuKang/CosineSampler' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Namgyu Kang, Byeonghyeon Lee, Youngjoon Hong, Seok-Bae Yun, Eunbyung Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.12800">PIXEL: Physics-Informed Cell Representations for Fast and Accurate PDE Solvers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the increases in computational power and advances in machine learning, data-driven learning-based methods have gained significant attention in solving PDEs. Physics-informed neural networks (PINNs) have recently emerged and succeeded in various forward and inverse PDE problems thanks to their excellent properties, such as flexibility, mesh-free solutions, and unsupervised training. However, their slower convergence speed and relatively inaccurate solutions often limit their broader applicability in many science and engineering domains. This paper proposes a new kind of data-driven PDEs solver, physics-informed cell representations (PIXEL), elegantly combining classical numerical methods and learning-based approaches. We adopt a grid structure from the numerical methods to improve accuracy and convergence speed and overcome the spectral bias presented in PINNs. Moreover, the proposed method enjoys the same benefits in PINNs, e.g., using the same optimization frameworks to solve both forward and inverse PDE problems and readily enforcing PDE constraints with modern automatic differentiation techniques. We provide experimental results on various challenging PDEs that the original PINNs have struggled with and show that PIXEL achieves fast convergence speed and high accuracy. Project page: https://namgyukang.github.io/PIXEL/
<div id='section'>Paperid: <span id='pid'>117, <a href='https://arxiv.org/pdf/2206.06070.pdf' target='_blank'>https://arxiv.org/pdf/2206.06070.pdf</a></span>   <span><a href='https://github.com/zju-jiangqi/ACI-PI2RNet' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/zju-jiangqi/ACI-PI2RNet' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Jiang, Hao Shi, Lei Sun, Shaohua Gao, Kailun Yang, Kaiwei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.06070">Annular Computational Imaging: Capture Clear Panoramic Images through Simple Lens</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Panoramic Annular Lens (PAL) composed of few lenses has great potential in panoramic surrounding sensing tasks for mobile and wearable devices because of its tiny size and large Field of View (FoV). However, the image quality of tiny-volume PAL confines to optical limit due to the lack of lenses for aberration correction. In this paper, we propose an Annular Computational Imaging (ACI) framework to break the optical limit of light-weight PAL design. To facilitate learning-based image restoration, we introduce a wave-based simulation pipeline for panoramic imaging and tackle the synthetic-to-real gap through multiple data distributions. The proposed pipeline can be easily adapted to any PAL with design parameters and is suitable for loose-tolerance designs. Furthermore, we design the Physics Informed Image Restoration Network (PI2RNet) considering the physical priors of panoramic imaging and single-pass physics-informed engine. At the dataset level, we create the DIVPano dataset and the extensive experiments on it illustrate that our proposed network sets the new state of the art in the panoramic image restoration under spatially-variant degradation. In addition, the evaluation of the proposed ACI on a simple PAL with only 3 spherical lenses reveals the delicate balance between high-quality panoramic imaging and compact design. To the best of our knowledge, we are the first to explore Computational Imaging (CI) in PAL. Code and datasets are publicly available at https://github.com/zju-jiangqi/ACI-PI2RNet.
<div id='section'>Paperid: <span id='pid'>118, <a href='https://arxiv.org/pdf/2206.02016.pdf' target='_blank'>https://arxiv.org/pdf/2206.02016.pdf</a></span>   <span><a href='https://github.com/LithiumDA/L_inf-PINN' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuwei Wang, Shanda Li, Di He, Liwei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.02016">Is $L^2$ Physics-Informed Loss Always Suitable for Training Physics-Informed Neural Network?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Physics-Informed Neural Network (PINN) approach is a new and promising way to solve partial differential equations using deep learning. The $L^2$ Physics-Informed Loss is the de-facto standard in training Physics-Informed Neural Networks. In this paper, we challenge this common practice by investigating the relationship between the loss function and the approximation quality of the learned solution. In particular, we leverage the concept of stability in the literature of partial differential equation to study the asymptotic behavior of the learned solution as the loss approaches zero. With this concept, we study an important class of high-dimensional non-linear PDEs in optimal control, the Hamilton-Jacobi-Bellman(HJB) Equation, and prove that for general $L^p$ Physics-Informed Loss, a wide class of HJB equation is stable only if $p$ is sufficiently large. Therefore, the commonly used $L^2$ loss is not suitable for training PINN on those equations, while $L^{\infty}$ loss is a better choice. Based on the theoretical insight, we develop a novel PINN training algorithm to minimize the $L^{\infty}$ loss for HJB equations which is in a similar spirit to adversarial training. The effectiveness of the proposed algorithm is empirically demonstrated through experiments. Our code is released at https://github.com/LithiumDA/L_inf-PINN.
<div id='section'>Paperid: <span id='pid'>119, <a href='https://arxiv.org/pdf/2203.15038.pdf' target='_blank'>https://arxiv.org/pdf/2203.15038.pdf</a></span>   <span><a href='https://github.com/slimgroup' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mathias Louboutin, Philipp A. Witte, Ali Siahkoohi, Gabrio Rizzuti, Ziyi Yin, Rafael Orozco, Felix J. Herrmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.15038">Accelerating innovation with software abstractions for scalable computational geophysics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present the SLIM (https://github.com/slimgroup) open-source software framework for computational geophysics, and more generally, inverse problems based on the wave-equation (e.g., medical ultrasound). We developed a software environment aimed at scalable research and development by designing multiple layers of abstractions. This environment allows the researchers to easily formulate their problem in an abstract fashion, while still being able to exploit the latest developments in high-performance computing. We illustrate and demonstrate the benefits of our software design on many geophysical applications, including seismic inversion and physics-informed machine learning for geophysics (e.g., loop unrolled imaging, uncertainty quantification), all while facilitating the integration of external software.
<div id='section'>Paperid: <span id='pid'>120, <a href='https://arxiv.org/pdf/2202.09340.pdf' target='_blank'>https://arxiv.org/pdf/2202.09340.pdf</a></span>   <span><a href='https://github.com/LithiumDA/PINN-without-Stacked-BP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Di He, Shanda Li, Wenlei Shi, Xiaotian Gao, Jia Zhang, Jiang Bian, Liwei Wang, Tie-Yan Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.09340">Learning Physics-Informed Neural Networks without Stacked Back-propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Network (PINN) has become a commonly used machine learning approach to solve partial differential equations (PDE). But, facing high-dimensional secondorder PDE problems, PINN will suffer from severe scalability issues since its loss includes second-order derivatives, the computational cost of which will grow along with the dimension during stacked back-propagation. In this work, we develop a novel approach that can significantly accelerate the training of Physics-Informed Neural Networks. In particular, we parameterize the PDE solution by the Gaussian smoothed model and show that, derived from Stein's Identity, the second-order derivatives can be efficiently calculated without back-propagation. We further discuss the model capacity and provide variance reduction methods to address key limitations in the derivative estimation. Experimental results show that our proposed method can achieve competitive error compared to standard PINN training but is significantly faster. Our code is released at https://github.com/LithiumDA/PINN-without-Stacked-BP.
<div id='section'>Paperid: <span id='pid'>121, <a href='https://arxiv.org/pdf/2107.14229.pdf' target='_blank'>https://arxiv.org/pdf/2107.14229.pdf</a></span>   <span><a href='https://github.com/astra-vision/GuidedDisent' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabio Pizzati, Pietro Cerri, Raoul de Charette
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2107.14229">Physics-informed Guided Disentanglement in Generative Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image-to-image translation (i2i) networks suffer from entanglement effects in presence of physics-related phenomena in target domain (such as occlusions, fog, etc), lowering altogether the translation quality, controllability and variability. In this paper, we propose a general framework to disentangle visual traits in target images. Primarily, we build upon collection of simple physics models, guiding the disentanglement with a physical model that renders some of the target traits, and learning the remaining ones. Because physics allows explicit and interpretable outputs, our physical models (optimally regressed on target) allows generating unseen scenarios in a controllable manner. Secondarily, we show the versatility of our framework to neural-guided disentanglement where a generative network is used in place of a physical model in case the latter is not directly accessible. Altogether, we introduce three strategies of disentanglement being guided from either a fully differentiable physics model, a (partially) non-differentiable physics model, or a neural network. The results show our disentanglement strategies dramatically increase performances qualitatively and quantitatively in several challenging scenarios for image translation.
<div id='section'>Paperid: <span id='pid'>122, <a href='https://arxiv.org/pdf/2506.20343.pdf' target='_blank'>https://arxiv.org/pdf/2506.20343.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kento Kawaharazuka, Takahiro Hattori, Keita Yoneda, Kei Okada
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.20343">PIMBS: Efficient Body Schema Learning for Musculoskeletal Humanoids with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Musculoskeletal humanoids are robots that closely mimic the human musculoskeletal system, offering various advantages such as variable stiffness control, redundancy, and flexibility. However, their body structure is complex, and muscle paths often significantly deviate from geometric models. To address this, numerous studies have been conducted to learn body schema, particularly the relationships among joint angles, muscle tension, and muscle length. These studies typically rely solely on data collected from the actual robot, but this data collection process is labor-intensive, and learning becomes difficult when the amount of data is limited. Therefore, in this study, we propose a method that applies the concept of Physics-Informed Neural Networks (PINNs) to the learning of body schema in musculoskeletal humanoids, enabling high-accuracy learning even with a small amount of data. By utilizing not only data obtained from the actual robot but also the physical laws governing the relationship between torque and muscle tension under the assumption of correct joint structure, more efficient learning becomes possible. We apply the proposed method to both simulation and an actual musculoskeletal humanoid and discuss its effectiveness and characteristics.
<div id='section'>Paperid: <span id='pid'>123, <a href='https://arxiv.org/pdf/2402.00531.pdf' target='_blank'>https://arxiv.org/pdf/2402.00531.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Songming Liu, Chang Su, Jiachen Yao, Zhongkai Hao, Hang Su, Youjia Wu, Jun Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00531">Preconditioning for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have shown promise in solving various partial differential equations (PDEs). However, training pathologies have negatively affected the convergence and prediction accuracy of PINNs, which further limits their practical applications. In this paper, we propose to use condition number as a metric to diagnose and mitigate the pathologies in PINNs. Inspired by classical numerical analysis, where the condition number measures sensitivity and stability, we highlight its pivotal role in the training dynamics of PINNs. We prove theorems to reveal how condition number is related to both the error control and convergence of PINNs. Subsequently, we present an algorithm that leverages preconditioning to improve the condition number. Evaluations of 18 PDE problems showcase the superior performance of our method. Significantly, in 7 of these problems, our method reduces errors by an order of magnitude. These empirical findings verify the critical role of the condition number in PINNs' training.
<div id='section'>Paperid: <span id='pid'>124, <a href='https://arxiv.org/pdf/2306.08827.pdf' target='_blank'>https://arxiv.org/pdf/2306.08827.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongkai Hao, Jiachen Yao, Chang Su, Hang Su, Ziao Wang, Fanzhi Lu, Zeyu Xia, Yichi Zhang, Songming Liu, Lu Lu, Jun Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.08827">PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While significant progress has been made on Physics-Informed Neural Networks (PINNs), a comprehensive comparison of these methods across a wide range of Partial Differential Equations (PDEs) is still lacking. This study introduces PINNacle, a benchmarking tool designed to fill this gap. PINNacle provides a diverse dataset, comprising over 20 distinct PDEs from various domains, including heat conduction, fluid dynamics, biology, and electromagnetics. These PDEs encapsulate key challenges inherent to real-world problems, such as complex geometry, multi-scale phenomena, nonlinearity, and high dimensionality. PINNacle also offers a user-friendly toolbox, incorporating about 10 state-of-the-art PINN methods for systematic evaluation and comparison. We have conducted extensive experiments with these methods, offering insights into their strengths and weaknesses. In addition to providing a standardized means of assessing performance, PINNacle also offers an in-depth analysis to guide future research, particularly in areas such as domain decomposition methods and loss reweighting for handling multi-scale problems and complex geometry. To the best of our knowledge, it is the largest benchmark with a diverse and comprehensive evaluation that will undoubtedly foster further research in PINNs.
<div id='section'>Paperid: <span id='pid'>125, <a href='https://arxiv.org/pdf/2306.02816.pdf' target='_blank'>https://arxiv.org/pdf/2306.02816.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiachen Yao, Chang Su, Zhongkai Hao, Songming Liu, Hang Su, Jun Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02816">MultiAdam: Parameter-wise Scale-invariant Optimizer for Multiscale Training of Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Neural Networks (PINNs) have recently achieved remarkable progress in solving Partial Differential Equations (PDEs) in various fields by minimizing a weighted sum of PDE loss and boundary loss. However, there are several critical challenges in the training of PINNs, including the lack of theoretical frameworks and the imbalance between PDE loss and boundary loss. In this paper, we present an analysis of second-order non-homogeneous PDEs, which are classified into three categories and applicable to various common problems. We also characterize the connections between the training loss and actual error, guaranteeing convergence under mild conditions. The theoretical analysis inspires us to further propose MultiAdam, a scale-invariant optimizer that leverages gradient momentum to parameter-wisely balance the loss terms. Extensive experiment results on multiple problems from different physical domains demonstrate that our MultiAdam solver can improve the predictive accuracy by 1-2 orders of magnitude compared with strong baselines.
<div id='section'>Paperid: <span id='pid'>126, <a href='https://arxiv.org/pdf/2211.08064.pdf' target='_blank'>https://arxiv.org/pdf/2211.08064.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongkai Hao, Songming Liu, Yichi Zhang, Chengyang Ying, Yao Feng, Hang Su, Jun Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.08064">Physics-Informed Machine Learning: A Survey on Problems, Methods and Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances of data-driven machine learning have revolutionized fields like computer vision, reinforcement learning, and many scientific and engineering domains. In many real-world and scientific problems, systems that generate data are governed by physical laws. Recent work shows that it provides potential benefits for machine learning models by incorporating the physical prior and collected data, which makes the intersection of machine learning and physics become a prevailing paradigm. By integrating the data and mathematical physics models seamlessly, it can guide the machine learning model towards solutions that are physically plausible, improving accuracy and efficiency even in uncertain and high-dimensional contexts. In this survey, we present this learning paradigm called Physics-Informed Machine Learning (PIML) which is to build a model that leverages empirical data and available physical prior knowledge to improve performance on a set of tasks that involve a physical mechanism. We systematically review the recent development of physics-informed machine learning from three perspectives of machine learning tasks, representation of physical prior, and methods for incorporating physical prior. We also propose several important open research problems based on the current trends in the field. We argue that encoding different forms of physical prior into model architectures, optimizers, inference algorithms, and significant domain-specific applications like inverse engineering design and robotic control is far from being fully explored in the field of physics-informed machine learning. We believe that the interdisciplinary research of physics-informed machine learning will significantly propel research progress, foster the creation of more effective machine learning models, and also offer invaluable assistance in addressing long-standing problems in related disciplines.
<div id='section'>Paperid: <span id='pid'>127, <a href='https://arxiv.org/pdf/2209.07075.pdf' target='_blank'>https://arxiv.org/pdf/2209.07075.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongkai Hao, Chengyang Ying, Hang Su, Jun Zhu, Jian Song, Ze Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.07075">Bi-level Physics-Informed Neural Networks for PDE Constrained Optimization using Broyden's Hypergradients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning based approaches like Physics-informed neural networks (PINNs) and DeepONets have shown promise on solving PDE constrained optimization (PDECO) problems. However, existing methods are insufficient to handle those PDE constraints that have a complicated or nonlinear dependency on optimization targets. In this paper, we present a novel bi-level optimization framework to resolve the challenge by decoupling the optimization of the targets and constraints. For the inner loop optimization, we adopt PINNs to solve the PDE constraints only. For the outer loop, we design a novel method by using Broyden's method based on the Implicit Function Theorem (IFT), which is efficient and accurate for approximating hypergradients. We further present theoretical explanations and error analysis of the hypergradients computation. Extensive experiments on multiple large-scale and nonlinear PDE constrained optimization problems demonstrate that our method achieves state-of-the-art results compared with strong baselines.
<div id='section'>Paperid: <span id='pid'>128, <a href='https://arxiv.org/pdf/2402.16836.pdf' target='_blank'>https://arxiv.org/pdf/2402.16836.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dingkun Guo, Yuqi Xiang, Shuqi Zhao, Xinghao Zhu, Masayoshi Tomizuka, Mingyu Ding, Wei Zhan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16836">PhyGrasp: Generalizing Robotic Grasping with Physics-informed Large Multimodal Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robotic grasping is a fundamental aspect of robot functionality, defining how robots interact with objects. Despite substantial progress, its generalizability to counter-intuitive or long-tailed scenarios, such as objects with uncommon materials or shapes, remains a challenge. In contrast, humans can easily apply their intuitive physics to grasp skillfully and change grasps efficiently, even for objects they have never seen before.
  This work delves into infusing such physical commonsense reasoning into robotic manipulation. We introduce PhyGrasp, a multimodal large model that leverages inputs from two modalities: natural language and 3D point clouds, seamlessly integrated through a bridge module. The language modality exhibits robust reasoning capabilities concerning the impacts of diverse physical properties on grasping, while the 3D modality comprehends object shapes and parts. With these two capabilities, PhyGrasp is able to accurately assess the physical properties of object parts and determine optimal grasping poses. Additionally, the model's language comprehension enables human instruction interpretation, generating grasping poses that align with human preferences. To train PhyGrasp, we construct a dataset PhyPartNet with 195K object instances with varying physical properties and human preferences, alongside their corresponding language descriptions. Extensive experiments conducted in the simulation and on the real robots demonstrate that PhyGrasp achieves state-of-the-art performance, particularly in long-tailed cases, e.g., about 10% improvement in success rate over GraspNet. Project page: https://sites.google.com/view/phygrasp
<div id='section'>Paperid: <span id='pid'>129, <a href='https://arxiv.org/pdf/2506.13777.pdf' target='_blank'>https://arxiv.org/pdf/2506.13777.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>En Xu, Huandong Wang, Yunke Zhang, Sibo Li, Yinzhou Tang, Zhilun Zhou, Yuming Lin, Yuan Yuan, Xiaochen Fan, Jingtao Ding, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13777">A Survey of Physics-Informed AI for Complex Urban Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Urban systems are typical examples of complex systems, where the integration of physics-based modeling with artificial intelligence (AI) presents a promising paradigm for enhancing predictive accuracy, interpretability, and decision-making. In this context, AI excels at capturing complex, nonlinear relationships, while physics-based models ensure consistency with real-world laws and provide interpretable insights. We provide a comprehensive review of physics-informed AI methods in urban applications. The proposed taxonomy categorizes existing approaches into three paradigms - Physics-Integrated AI, Physics-AI Hybrid Ensemble, and AI-Integrated Physics - and further details seven representative methods. This classification clarifies the varying degrees and directions of physics-AI integration, guiding the selection and development of appropriate methods based on application needs and data availability. We systematically examine their applications across eight key urban domains: energy, environment, economy, transportation, information, public services, emergency management, and the urban system as a whole. Our analysis highlights how these methodologies leverage physical laws and data-driven models to address urban challenges, enhancing system reliability, efficiency, and adaptability. By synthesizing existing methodologies and their urban applications, we identify critical gaps and outline future research directions, paving the way toward next-generation intelligent urban system modeling.
<div id='section'>Paperid: <span id='pid'>130, <a href='https://arxiv.org/pdf/2505.23863.pdf' target='_blank'>https://arxiv.org/pdf/2505.23863.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chang Liu, Bohao Zhao, Jingtao Ding, Huandong Wang, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23863">Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Long-term forecasting of chaotic systems remains a fundamental challenge due to the intrinsic sensitivity to initial conditions and the complex geometry of strange attractors. Conventional approaches, such as reservoir computing, typically require training data that incorporates long-term continuous dynamical behavior to comprehensively capture system dynamics. While advanced deep sequence models can capture transient dynamics within the training data, they often struggle to maintain predictive stability and dynamical coherence over extended horizons. Here, we propose PhyxMamba, a framework that integrates a Mamba-based state-space model with physics-informed principles to forecast long-term behavior of chaotic systems given short-term historical observations on their state evolution. We first reconstruct the attractor manifold with time-delay embeddings to extract global dynamical features. After that, we introduce a generative training scheme that enables Mamba to replicate the physical process. It is further augmented by multi-patch prediction and attractor geometry regularization for physical constraints, enhancing predictive accuracy and preserving key statistical properties of systems. Extensive experiments on simulated and real-world chaotic systems demonstrate that PhyxMamba delivers superior forecasting accuracy and faithfully captures essential statistics from short-term historical observations.
<div id='section'>Paperid: <span id='pid'>131, <a href='https://arxiv.org/pdf/2505.13919.pdf' target='_blank'>https://arxiv.org/pdf/2505.13919.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruikun Li, Huandong Wang, Jingtao Ding, Yuan Yuan, Qingmin Liao, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13919">Predicting Dynamical Systems across Environments via Diffusive Model Weight Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven methods offer an effective equation-free solution for predicting physical dynamics. However, the same physical system can exhibit significantly different dynamic behaviors in various environments. This causes prediction functions trained for specific environments to fail when transferred to unseen environments. Therefore, cross-environment prediction requires modeling the dynamic functions of different environments. In this work, we propose a model weight generation method, \texttt{EnvAd-Diff}. \texttt{EnvAd-Diff} operates in the weight space of the dynamic function, generating suitable weights from scratch based on environmental condition for zero-shot prediction. Specifically, we first train expert prediction functions on dynamic trajectories from a limited set of visible environments to create a model zoo, thereby constructing sample pairs of prediction function weights and their corresponding environments. Subsequently, we train a latent space diffusion model conditioned on the environment to model the joint distribution of weights and environments. Considering the lack of environmental prior knowledge in real-world scenarios, we propose a physics-informed surrogate label to distinguish different environments. Generalization experiments across multiple systems demonstrate that a 1M parameter prediction function generated by \texttt{EnvAd-Diff} outperforms a pre-trained 500M parameter foundation model.
<div id='section'>Paperid: <span id='pid'>132, <a href='https://arxiv.org/pdf/2506.22843.pdf' target='_blank'>https://arxiv.org/pdf/2506.22843.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kien Nguyen, Clinton Fookes, Sridha Sridharan, Huy Nguyen, Feng Liu, Xiaoming Liu, Arun Ross, Dana Michalski, TamÃ¡s Endrei, Ivan DeAndres-Tame, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez, Javier Ortega-Garcia, Zijing Gong, Yuhao Wang, Xuehu Liu, Pingping Zhang, Md Rashidunnabi, Hugo ProenÃ§a, Kailash A. Hambarde, Saeid Rezaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22843">AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Person re-identification (ReID) across aerial and ground vantage points has become crucial for large-scale surveillance and public safety applications. Although significant progress has been made in ground-only scenarios, bridging the aerial-ground domain gap remains a formidable challenge due to extreme viewpoint differences, scale variations, and occlusions. Building upon the achievements of the AG-ReID 2023 Challenge, this paper introduces the AG-VPReID 2025 Challenge - the first large-scale video-based competition focused on high-altitude (80-120m) aerial-ground ReID. Constructed on the new AG-VPReID dataset with 3,027 identities, over 13,500 tracklets, and approximately 3.7 million frames captured from UAVs, CCTV, and wearable cameras, the challenge featured four international teams. These teams developed solutions ranging from multi-stream architectures to transformer-based temporal reasoning and physics-informed modeling. The leading approach, X-TFCLIP from UAM, attained 72.28% Rank-1 accuracy in the aerial-to-ground ReID setting and 70.77% in the ground-to-aerial ReID setting, surpassing existing baselines while highlighting the dataset's complexity. For additional details, please refer to the official website at https://agvpreid25.github.io.
<div id='section'>Paperid: <span id='pid'>133, <a href='https://arxiv.org/pdf/2411.19125.pdf' target='_blank'>https://arxiv.org/pdf/2411.19125.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Honghui Wang, Yifan Pu, Shiji Song, Gao Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.19125">Advancing Generalization in PINNs through Latent-Space Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have made significant strides in modeling dynamical systems governed by partial differential equations (PDEs). However, their generalization capabilities across varying scenarios remain limited. To overcome this limitation, we propose PIDO, a novel physics-informed neural PDE solver designed to generalize effectively across diverse PDE configurations, including varying initial conditions, PDE coefficients, and training time horizons. PIDO exploits the shared underlying structure of dynamical systems with different properties by projecting PDE solutions into a latent space using auto-decoding. It then learns the dynamics of these latent representations, conditioned on the PDE coefficients. Despite its promise, integrating latent dynamics models within a physics-informed framework poses challenges due to the optimization difficulties associated with physics-informed losses. To address these challenges, we introduce a novel approach that diagnoses and mitigates these issues within the latent space. This strategy employs straightforward yet effective regularization techniques, enhancing both the temporal extrapolation performance and the training stability of PIDO. We validate PIDO on a range of benchmarks, including 1D combined equations and 2D Navier-Stokes equations. Additionally, we demonstrate the transferability of its learned representations to downstream applications such as long-term integration and inverse problems.
<div id='section'>Paperid: <span id='pid'>134, <a href='https://arxiv.org/pdf/2505.17434.pdf' target='_blank'>https://arxiv.org/pdf/2505.17434.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guanzhou Lan, Yuqi Yang, Anup Teejo Mathew, Feiping Nie, Rong Wang, Xuelong Li, Federico Renda, Bin Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17434">Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Goal-conditioned dynamic manipulation is inherently challenging due to complex system dynamics and stringent task constraints, particularly in deformable object scenarios characterized by high degrees of freedom and underactuation. Prior methods often simplify the problem to low-speed or 2D settings, limiting their applicability to real-world 3D tasks. In this work, we explore 3D goal-conditioned rope manipulation as a representative challenge. To mitigate data scarcity, we introduce a novel simulation framework and benchmark grounded in reduced-order dynamics, which enables compact state representation and facilitates efficient policy learning. Building on this, we propose Dynamics Informed Diffusion Policy (DIDP), a framework that integrates imitation pretraining with physics-informed test-time adaptation. First, we design a diffusion policy that learns inverse dynamics within the reduced-order space, enabling imitation learning to move beyond naÃ¯ve data fitting and capture the underlying physical structure. Second, we propose a physics-informed test-time adaptation scheme that imposes kinematic boundary conditions and structured dynamics priors on the diffusion process, ensuring consistency and reliability in manipulation execution. Extensive experiments validate the proposed approach, demonstrating strong performance in terms of accuracy and robustness in the learned policy.
<div id='section'>Paperid: <span id='pid'>135, <a href='https://arxiv.org/pdf/2506.16443.pdf' target='_blank'>https://arxiv.org/pdf/2506.16443.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas R. Naujoks, Aleksander Krasowski, Moritz Weckbecker, Galip Ãmit Yolcu, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek, RenÃ© P. Klausen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.16443">Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) offer a powerful approach to solving partial differential equations (PDEs), which are ubiquitous in the quantitative sciences. Applied to both forward and inverse problems across various scientific domains, PINNs have recently emerged as a valuable tool in the field of scientific machine learning. A key aspect of their training is that the data -- spatio-temporal points sampled from the PDE's input domain -- are readily available. Influence functions, a tool from the field of explainable AI (XAI), approximate the effect of individual training points on the model, enhancing interpretability. In the present work, we explore the application of influence function-based sampling approaches for the training data. Our results indicate that such targeted resampling based on data attribution methods has the potential to enhance prediction accuracy in physics-informed neural networks, demonstrating a practical application of an XAI method in PINN training.
<div id='section'>Paperid: <span id='pid'>136, <a href='https://arxiv.org/pdf/2503.17978.pdf' target='_blank'>https://arxiv.org/pdf/2503.17978.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dominique Nshimyimana, Vitor Fortes Rey, Sungho Suh, Bo Zhou, Paul Lukowicz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17978">PIM: Physics-Informed Multi-task Pre-training for Improving Inertial Sensor-Based Human Activity Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human activity recognition (HAR) with deep learning models relies on large amounts of labeled data, often challenging to obtain due to associated cost, time, and labor. Self-supervised learning (SSL) has emerged as an effective approach to leverage unlabeled data through pretext tasks, such as masked reconstruction and multitask learning with signal processing-based data augmentations, to pre-train encoder models. However, such methods are often derived from computer vision approaches that disregard physical mechanisms and constraints that govern wearable sensor data and the phenomena they reflect. In this paper, we propose a physics-informed multi-task pre-training (PIM) framework for IMU-based HAR. PIM generates pre-text tasks based on the understanding of basic physical aspects of human motion: including movement speed, angles of movement, and symmetry between sensor placements. Given a sensor signal, we calculate corresponding features using physics-based equations and use them as pretext tasks for SSL. This enables the model to capture fundamental physical characteristics of human activities, which is especially relevant for multi-sensor systems. Experimental evaluations on four HAR benchmark datasets demonstrate that the proposed method outperforms existing state-of-the-art methods, including data augmentation and masked reconstruction, in terms of accuracy and F1 score. We have observed gains of almost 10\% in macro f1 score and accuracy with only 2 to 8 labeled examples per class and up to 3% when there is no reduction in the amount of training data.
<div id='section'>Paperid: <span id='pid'>137, <a href='https://arxiv.org/pdf/2502.03236.pdf' target='_blank'>https://arxiv.org/pdf/2502.03236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Li Sun, Ziheng Zhang, Zixi Wang, Yujie Wang, Qiqi Wan, Hao Li, Hao Peng, Philip S. Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03236">Pioneer: Physics-informed Riemannian Graph ODE for Entropy-increasing Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamic interacting system modeling is important for understanding and simulating real world systems. The system is typically described as a graph, where multiple objects dynamically interact with each other and evolve over time. In recent years, graph Ordinary Differential Equations (ODE) receive increasing research attentions. While achieving encouraging results, existing solutions prioritize the traditional Euclidean space, and neglect the intrinsic geometry of the system and physics laws, e.g., the principle of entropy increasing. The limitations above motivate us to rethink the system dynamics from a fresh perspective of Riemannian geometry, and pose a more realistic problem of physics-informed dynamic system modeling, considering the underlying geometry and physics law for the first time. In this paper, we present a novel physics-informed Riemannian graph ODE for a wide range of entropy-increasing dynamic systems (termed as Pioneer). In particular, we formulate a differential system on the Riemannian manifold, where a manifold-valued graph ODE is governed by the proposed constrained Ricci flow, and a manifold preserving Gyro-transform aware of system geometry. Theoretically, we report the provable entropy non-decreasing of our formulation, obeying the physics laws. Empirical results show the superiority of Pioneer on real datasets.
<div id='section'>Paperid: <span id='pid'>138, <a href='https://arxiv.org/pdf/2504.12169.pdf' target='_blank'>https://arxiv.org/pdf/2504.12169.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joanne Lin, Crispian Morris, Ruirui Lin, Fan Zhang, David Bull, Nantheera Anantrasirichai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.12169">Towards a General-Purpose Zero-Shot Synthetic Low-Light Image and Video Pipeline</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Low-light conditions pose significant challenges for both human and machine annotation. This in turn has led to a lack of research into machine understanding for low-light images and (in particular) videos. A common approach is to apply annotations obtained from high quality datasets to synthetically created low light versions. In addition, these approaches are often limited through the use of unrealistic noise models. In this paper, we propose a new Degradation Estimation Network (DEN), which synthetically generates realistic standard RGB (sRGB) noise without the requirement for camera metadata. This is achieved by estimating the parameters of physics-informed noise distributions, trained in a self-supervised manner. This zero-shot approach allows our method to generate synthetic noisy content with a diverse range of realistic noise characteristics, unlike other methods which focus on recreating the noise characteristics of the training data. We evaluate our proposed synthetic pipeline using various methods trained on its synthetic data for typical low-light tasks including synthetic noise replication, video enhancement, and object detection, showing improvements of up to 24\% KLD, 21\% LPIPS, and 62\% AP$_{50-95}$, respectively.
<div id='section'>Paperid: <span id='pid'>139, <a href='https://arxiv.org/pdf/2502.16828.pdf' target='_blank'>https://arxiv.org/pdf/2502.16828.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruikun Li, Huandong Wang, Qingmin Liao, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16828">Predicting the Energy Landscape of Stochastic Dynamical System via Physics-informed Self-supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Energy landscapes play a crucial role in shaping dynamics of many real-world complex systems. System evolution is often modeled as particles moving on a landscape under the combined effect of energy-driven drift and noise-induced diffusion, where the energy governs the long-term motion of the particles. Estimating the energy landscape of a system has been a longstanding interdisciplinary challenge, hindered by the high operational costs or the difficulty of obtaining supervisory signals. Therefore, the question of how to infer the energy landscape in the absence of true energy values is critical. In this paper, we propose a physics-informed self-supervised learning method to learn the energy landscape from the evolution trajectories of the system. It first maps the system state from the observation space to a discrete landscape space by an adaptive codebook, and then explicitly integrates energy into the graph neural Fokker-Planck equation, enabling the joint learning of energy estimation and evolution prediction. Experimental results across interdisciplinary systems demonstrate that our estimated energy has a correlation coefficient above 0.9 with the ground truth, and evolution prediction accuracy exceeds the baseline by an average of 17.65\%. The code is available at github.com/tsinghua-fib-lab/PESLA.
<div id='section'>Paperid: <span id='pid'>140, <a href='https://arxiv.org/pdf/2306.03390.pdf' target='_blank'>https://arxiv.org/pdf/2306.03390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Can Rong, Huandong Wang, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03390">Origin-Destination Network Generation via Gravity-Guided GAN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Origin-destination (OD) flow, which contains valuable population mobility information including direction and volume, is critical in many urban applications, such as urban planning, transportation management, etc. However, OD data is not always easy to access due to high costs or privacy concerns. Therefore, we must consider generating OD through mathematical models. Existing works utilize physics laws or machine learning (ML) models to build the association between urban structures and OD flows while these two kinds of methods suffer from the limitation of over-simplicity and poor generalization ability, respectively. In this paper, we propose to adopt physics-informed ML paradigm, which couple the physics scientific knowledge and data-driven ML methods, to construct a model named Origin-Destination Generation Networks (ODGN) for better population mobility modeling by leveraging the complementary strengths of combining physics and ML methods. Specifically, we first build a Multi-view Graph Attention Networks (MGAT) to capture the urban features of every region and then use a gravity-guided predictor to obtain OD flow between every two regions. Furthermore, we use a conditional GAN training strategy and design a sequence-based discriminator to consider the overall topological features of OD as a network. Extensive experiments on real-world datasets have been done to demonstrate the superiority of our proposed method compared with baselines.
<div id='section'>Paperid: <span id='pid'>141, <a href='https://arxiv.org/pdf/2506.21765.pdf' target='_blank'>https://arxiv.org/pdf/2506.21765.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Li, Shaheer U. Saeed, Yuliang Huang, Mingyuan Luo, Zhongnuo Yan, Jiongquan Chen, Xin Yang, Dong Ni, Nektarios Winter, Phuc Nguyen, Lucas Steinberger, Caelan Haney, Yuan Zhao, Mingjie Jiang, Bowen Ren, SiYeoul Lee, Seonho Kim, MinKyung Seo, MinWoo Kim, Yimeng Dou, Zhiwei Zhang, Yin Li, Tomy Varghese, Dean C. Barratt, Matthew J. Clarkson, Tom Vercauteren, Yipeng Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.21765">TUS-REC2024: A Challenge to Reconstruct 3D Freehand Ultrasound Without External Tracker</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Trackerless freehand ultrasound reconstruction aims to reconstruct 3D volumes from sequences of 2D ultrasound images without relying on external tracking systems, offering a low-cost, portable, and widely deployable alternative for volumetric imaging. However, it presents significant challenges, including accurate inter-frame motion estimation, minimisation of drift accumulation over long sequences, and generalisability across scanning protocols. The TUS-REC2024 Challenge was established to benchmark and accelerate progress in trackerless 3D ultrasound reconstruction by providing a publicly available dataset for the first time, along with a baseline model and evaluation framework. The Challenge attracted over 43 registered teams, of which 6 teams submitted 21 valid dockerized solutions. Submitted methods spanned a wide range of algorithmic approaches, including recurrent models, registration-driven volume refinement, attention, and physics-informed models. This paper presents an overview of the Challenge design, summarises the key characteristics of the dataset, provides a concise literature review, introduces the technical details of the underlying methodology working with tracked freehand ultrasound data, and offers a comparative analysis of submitted methods across multiple evaluation metrics. The results highlight both the progress and current limitations of state-of-the-art approaches in this domain, and inform directions for future research. The data, evaluation code, and baseline are publicly available to facilitate ongoing development and reproducibility. As a live and evolving benchmark, this Challenge is designed to be continuously developed and improved. The Challenge was held at MICCAI 2024 and will be organised again at MICCAI 2025, reflecting its growing impact and the sustained commitment to advancing this field.
<div id='section'>Paperid: <span id='pid'>142, <a href='https://arxiv.org/pdf/2412.16724.pdf' target='_blank'>https://arxiv.org/pdf/2412.16724.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giovanni Pollo, Alessio Burrello, Enrico Macii, Massimo Poncino, Sara Vinco, Daniele Jahier Pagliari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.16724">Coupling Neural Networks and Physics Equations For Li-Ion Battery State-of-Charge Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating the evolution of the battery's State of Charge (SoC) in response to its usage is critical for implementing effective power management policies and for ultimately improving the system's lifetime. Most existing estimation methods are either physics-based digital twins of the battery or data-driven models such as Neural Networks (NNs). In this work, we propose two new contributions in this domain. First, we introduce a novel NN architecture formed by two cascaded branches: one to predict the current SoC based on sensor readings, and one to estimate the SoC at a future time as a function of the load behavior. Second, we integrate battery dynamics equations into the training of our NN, merging the physics-based and data-driven approaches, to improve the models' generalization over variable prediction horizons. We validate our approach on two publicly accessible datasets, showing that our Physics-Informed Neural Networks (PINNs) outperform purely data-driven ones while also obtaining superior prediction accuracy with a smaller architecture with respect to the state-of-the-art.
<div id='section'>Paperid: <span id='pid'>143, <a href='https://arxiv.org/pdf/2403.12226.pdf' target='_blank'>https://arxiv.org/pdf/2403.12226.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingsong Xu, Yilei Shi, Jonathan Bamber, Chaojun Ouyang, Xiao Xiang Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.12226">Large-scale flood modeling and forecasting with FloodCast</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large-scale hydrodynamic models generally rely on fixed-resolution spatial grids and model parameters as well as incurring a high computational cost. This limits their ability to accurately forecast flood crests and issue time-critical hazard warnings. In this work, we build a fast, stable, accurate, resolution-invariant, and geometry-adaptative flood modeling and forecasting framework that can perform at large scales, namely FloodCast. The framework comprises two main modules: multi-satellite observation and hydrodynamic modeling. In the multi-satellite observation module, a real-time unsupervised change detection method and a rainfall processing and analysis tool are proposed to harness the full potential of multi-satellite observations in large-scale flood prediction. In the hydrodynamic modeling module, a geometry-adaptive physics-informed neural solver (GeoPINS) is introduced, benefiting from the absence of a requirement for training data in physics-informed neural networks and featuring a fast, accurate, and resolution-invariant architecture with Fourier neural operators. GeoPINS demonstrates impressive performance on popular PDEs across regular and irregular domains. Building upon GeoPINS, we propose a sequence-to-sequence GeoPINS model to handle long-term temporal series and extensive spatial domains in large-scale flood modeling. Next, we establish a benchmark dataset in the 2022 Pakistan flood to assess various flood prediction methods. Finally, we validate the model in three dimensions - flood inundation range, depth, and transferability of spatiotemporal downscaling. Traditional hydrodynamics and sequence-to-sequence GeoPINS exhibit exceptional agreement during high water levels, while comparative assessments with SAR-based flood depth data show that sequence-to-sequence GeoPINS outperforms traditional hydrodynamics, with smaller prediction errors.
<div id='section'>Paperid: <span id='pid'>144, <a href='https://arxiv.org/pdf/2310.05227.pdf' target='_blank'>https://arxiv.org/pdf/2310.05227.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingsong Xu, Yilei Shi, Jonathan Bamber, Ye Tuo, Ralf Ludwig, Xiao Xiang Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05227">Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate hydrological understanding and water cycle prediction are crucial for addressing scientific and societal challenges associated with the management of water resources, particularly under the dynamic influence of anthropogenic climate change. Existing reviews predominantly concentrate on the development of machine learning (ML) in this field, yet there is a clear distinction between hydrology and ML as separate paradigms. Here, we introduce physics-aware ML as a transformative approach to overcome the perceived barrier and revolutionize both fields. Specifically, we present a comprehensive review of the physics-aware ML methods, building a structured community (PaML) of existing methodologies that integrate prior physical knowledge or physics-based modeling into ML. We systematically analyze these PaML methodologies with respect to four aspects: physical data-guided ML, physics-informed ML, physics-embedded ML, and physics-aware hybrid learning. PaML facilitates ML-aided hypotheses, accelerating insights from big data and fostering scientific discoveries. We first conduct a systematic review of hydrology in PaML, including rainfall-runoff hydrological processes and hydrodynamic processes, and highlight the most promising and challenging directions for different objectives and PaML methods. Finally, a new PaML-based hydrology platform, termed HydroPML, is released as a foundation for hydrological applications. HydroPML enhances the explainability and causality of ML and lays the groundwork for the digital water cycle's realization. The HydroPML platform is publicly available at https://hydropml.github.io/.
<div id='section'>Paperid: <span id='pid'>145, <a href='https://arxiv.org/pdf/2509.24615.pdf' target='_blank'>https://arxiv.org/pdf/2509.24615.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahul Halder, Giovanni Stabile, Gianluigi Rozza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24615">Coupling Physics Informed Neural Networks with External Solvers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The current work aims to incorporate physics-based loss in Physics Informed Neural Network (PINN) directly using the numerical residual obtained from the governing equation in any dicretized forward solver. PINN's major difficulties in coupling with external forward solvers arise from the inability to access the discretized form (Finite difference, finite volume, finite element, etc.) of the governing equation directly through the network and to include them in its computational graph. This poses a significant challenge to conventional automatic-differentiation-based derivative computation of physics-based loss terms concerning the neural network hyperparameters if gradient-based optimization techniques are adopted. Therefore, we propose modifying the physics-based loss term to account for the residual arising from the external solver and to compute the derivative required for the optimization machinery. The proposed methodologies are demonstrated on benchmark full-order and reduced-order systems.
<div id='section'>Paperid: <span id='pid'>146, <a href='https://arxiv.org/pdf/2311.14045.pdf' target='_blank'>https://arxiv.org/pdf/2311.14045.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahul Halder, Giovanni Stabile, Gianluigi Rozza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.14045">Physics Informed Neural Network Framework for Unsteady Discretized Reduced Order System</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work addresses the development of a physics-informed neural network (PINN) with a loss term derived from a discretized time-dependent reduced-order system. In this work, first, the governing equations are discretized using a finite difference scheme (whereas, any other discretization technique can be adopted), then projected on a reduced or latent space using the Proper Orthogonal Decomposition (POD)-Galerkin approach and next, the residual arising from discretized reduced order equation is considered as an additional loss penalty term alongside the data-driven loss term using different variants of deep learning method such as Artificial neural network (ANN), Long Short-Term Memory based neural network (LSTM). The LSTM neural network has been proven to be very effective for time-dependent problems in a purely data-driven environment. The current work demonstrates the LSTM network's potential over ANN networks in physics-informed neural networks (PINN) as well. The potential of using discretized governing equations instead of continuous form lies in the flexibility of input to the PINN. Different sizes of data ranging from small, medium to big datasets are used to assess the potential of discretized-physics-informed neural networks when there is very sparse or no data available. The proposed methods are applied to a pitch-plunge airfoil motion governed by rigid-body dynamics and a one-dimensional viscous Burgers' equation. The current work also demonstrates the prediction capability of various discretized-physics-informed neural networks outside the domain where the data is available or governing equation-based residuals are minimized.
<div id='section'>Paperid: <span id='pid'>147, <a href='https://arxiv.org/pdf/2502.09346.pdf' target='_blank'>https://arxiv.org/pdf/2502.09346.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sibo Cheng, Marc Bocquet, Weiping Ding, Tobias Sebastian Finn, Rui Fu, Jinlong Fu, Yike Guo, Eleda Johnson, Siyi Li, Che Liu, Eric Newton Moro, Jie Pan, Matthew Piggott, Cesar Quilodran, Prakhar Sharma, Kun Wang, Dunhui Xiao, Xiao Xue, Yong Zeng, Mingrui Zhang, Hao Zhou, Kewei Zhu, Rossella Arcucci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09346">Machine learning for modelling unstructured grid data in computational physics: a review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unstructured grid data are essential for modelling complex geometries and dynamics in computational physics. Yet, their inherent irregularity presents significant challenges for conventional machine learning (ML) techniques. This paper provides a comprehensive review of advanced ML methodologies designed to handle unstructured grid data in high-dimensional dynamical systems. Key approaches discussed include graph neural networks, transformer models with spatial attention mechanisms, interpolation-integrated ML methods, and meshless techniques such as physics-informed neural networks. These methodologies have proven effective across diverse fields, including fluid dynamics and environmental simulations. This review is intended as a guidebook for computational scientists seeking to apply ML approaches to unstructured grid data in their domains, as well as for ML researchers looking to address challenges in computational physics. It places special focus on how ML methods can overcome the inherent limitations of traditional numerical techniques and, conversely, how insights from computational physics can inform ML development. To support benchmarking, this review also provides a summary of open-access datasets of unstructured grid data in computational physics. Finally, emerging directions such as generative models with unstructured data, reinforcement learning for mesh generation, and hybrid physics-data-driven paradigms are discussed to inspire future advancements in this evolving field.
<div id='section'>Paperid: <span id='pid'>148, <a href='https://arxiv.org/pdf/2502.00803.pdf' target='_blank'>https://arxiv.org/pdf/2502.00803.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haixu Wu, Yuezhou Ma, Hang Zhou, Huikun Weng, Jianmin Wang, Mingsheng Long
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00803">ProPINN: Demystifying Propagation Failures in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have earned high expectations in solving partial differential equations (PDEs), but their optimization usually faces thorny challenges due to the unique derivative-dependent loss function. By analyzing the loss distribution, previous research observed the propagation failure phenomenon of PINNs, intuitively described as the correct supervision for model outputs cannot ''propagate'' from initial states or boundaries to the interior domain. Going beyond intuitive understanding, this paper provides a formal and in-depth study of propagation failure and its root cause. Based on a detailed comparison with classical finite element methods, we ascribe the failure to the conventional single-point-processing architecture of PINNs and further prove that propagation failure is essentially caused by the lower gradient correlation of PINN models on nearby collocation points. Compared to superficial loss maps, this new perspective provides a more precise quantitative criterion to identify where and why PINN fails. The theoretical finding also inspires us to present a new PINN architecture, named ProPINN, which can effectively unite the gradients of region points for better propagation. ProPINN can reliably resolve PINN failure modes and significantly surpass advanced Transformer-based models with 46% relative promotion.
<div id='section'>Paperid: <span id='pid'>149, <a href='https://arxiv.org/pdf/2409.20409.pdf' target='_blank'>https://arxiv.org/pdf/2409.20409.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michal Balcerak, Tamaz Amiranashvili, Andreas Wagner, Jonas Weidner, Petr Karnakov, Johannes C. Paetzold, Ivan Ezhov, Petros Koumoutsakos, Benedikt Wiestler, Bjoern Menze
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.20409">Physics-Regularized Multi-Modal Image Assimilation for Brain Tumor Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physical models in the form of partial differential equations serve as important priors for many under-constrained problems. One such application is tumor treatment planning, which relies on accurately estimating the spatial distribution of tumor cells within a patient's anatomy. While medical imaging can detect the bulk of a tumor, it cannot capture the full extent of its spread, as low-concentration tumor cells often remain undetectable, particularly in glioblastoma, the most common primary brain tumor. Machine learning approaches struggle to estimate the complete tumor cell distribution due to a lack of appropriate training data. Consequently, most existing methods rely on physics-based simulations to generate anatomically and physiologically plausible estimations. However, these approaches face challenges with complex and unknown initial conditions and are constrained by overly rigid physical models. In this work, we introduce a novel method that integrates data-driven and physics-based cost functions, akin to Physics-Informed Neural Networks (PINNs). However, our approach parametrizes the solution directly on a dynamic discrete mesh, allowing for the effective modeling of complex biomechanical behaviors. Specifically, we propose a unique discretization scheme that quantifies how well the learned spatiotemporal distributions of tumor and brain tissues adhere to their respective growth and elasticity equations. This quantification acts as a regularization term, offering greater flexibility and improved integration of patient data compared to existing models. We demonstrate enhanced coverage of tumor recurrence areas using real-world data from a patient cohort, highlighting the potential of our method to improve model-driven treatment planning for glioblastoma in clinical practice.
<div id='section'>Paperid: <span id='pid'>150, <a href='https://arxiv.org/pdf/2405.04662.pdf' target='_blank'>https://arxiv.org/pdf/2405.04662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Borts, Erich Liang, Tim BrÃ¶dermann, Andrea Ramazzina, Stefanie Walz, Edoardo Palladin, Jipeng Sun, David Bruggemann, Christos Sakaridis, Luc Van Gool, Mario Bijelic, Felix Heide
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.04662">Radar Fields: Frequency-Space Neural Scene Representations for FMCW Radar</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural fields have been broadly investigated as scene representations for the reproduction and novel generation of diverse outdoor scenes, including those autonomous vehicles and robots must handle. While successful approaches for RGB and LiDAR data exist, neural reconstruction methods for radar as a sensing modality have been largely unexplored. Operating at millimeter wavelengths, radar sensors are robust to scattering in fog and rain, and, as such, offer a complementary modality to active and passive optical sensing techniques. Moreover, existing radar sensors are highly cost-effective and deployed broadly in robots and vehicles that operate outdoors. We introduce Radar Fields - a neural scene reconstruction method designed for active radar imagers. Our approach unites an explicit, physics-informed sensor model with an implicit neural geometry and reflectance model to directly synthesize raw radar measurements and extract scene occupancy. The proposed method does not rely on volume rendering. Instead, we learn fields in Fourier frequency space, supervised with raw radar data. We validate the effectiveness of the method across diverse outdoor scenarios, including urban scenes with dense vehicles and infrastructure, and in harsh weather scenarios, where mm-wavelength sensing is especially favorable.
<div id='section'>Paperid: <span id='pid'>151, <a href='https://arxiv.org/pdf/2311.16536.pdf' target='_blank'>https://arxiv.org/pdf/2311.16536.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ray Zirui Zhang, Ivan Ezhov, Michal Balcerak, Andy Zhu, Benedikt Wiestler, Bjoern Menze, John S. Lowengrub
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16536">Personalized Predictions of Glioblastoma Infiltration: Mathematical Models, Physics-Informed Neural Networks and Multimodal Scans</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the infiltration of Glioblastoma (GBM) from medical MRI scans is crucial for understanding tumor growth dynamics and designing personalized radiotherapy treatment plans.Mathematical models of GBM growth can complement the data in the prediction of spatial distributions of tumor cells. However, this requires estimating patient-specific parameters of the model from clinical data, which is a challenging inverse problem due to limited temporal data and the limited time between imaging and diagnosis. This work proposes a method that uses Physics-Informed Neural Networks (PINNs) to estimate patient-specific parameters of a reaction-diffusion PDE model of GBM growth from a single 3D structural MRI snapshot. PINNs embed both the data and the PDE into a loss function, thus integrating theory and data. Key innovations include the identification and estimation of characteristic non-dimensional parameters, a pre-training step that utilizes the non-dimensional parameters and a fine-tuning step to determine the patient specific parameters. Additionally, the diffuse domain method is employed to handle the complex brain geometry within the PINN framework. Our method is validated both on synthetic and patient datasets, and shows promise for real-time parametric inference in the clinical setting for personalized GBM treatment.
<div id='section'>Paperid: <span id='pid'>152, <a href='https://arxiv.org/pdf/2507.19205.pdf' target='_blank'>https://arxiv.org/pdf/2507.19205.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Md Abrar Jahin, Shahriar Soudeep, M. F. Mridha, Muhammad Mostafa Monowar, Md. Abdul Hamid
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19205">Physics-Informed Graph Neural Networks for Transverse Momentum Estimation in CMS Trigger Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-time particle transverse momentum ($p_T$) estimation in high-energy physics demands algorithms that are both efficient and accurate under strict hardware constraints. Static machine learning models degrade under high pileup and lack physics-aware optimization, while generic graph neural networks (GNNs) often neglect domain structure critical for robust $p_T$ regression. We propose a physics-informed GNN framework that systematically encodes detector geometry and physical observables through four distinct graph construction strategies that systematically encode detector geometry and physical observables: station-as-node, feature-as-node, bending angle-centric, and pseudorapidity ($Î·$)-centric representations. This framework integrates these tailored graph structures with a novel Message Passing Layer (MPL), featuring intra-message attention and gated updates, and domain-specific loss functions incorporating $p_{T}$-distribution priors. Our co-design methodology yields superior accuracy-efficiency trade-offs compared to existing baselines. Extensive experiments on the CMS Trigger Dataset validate the approach: a station-informed EdgeConv model achieves a state-of-the-art MAE of 0.8525 with $\ge55\%$ fewer parameters than deep learning baselines, especially TabNet, while an $Î·$-centric MPL configuration also demonstrates improved accuracy with comparable efficiency. These results establish the promise of physics-guided GNNs for deployment in resource-constrained trigger systems.
<div id='section'>Paperid: <span id='pid'>153, <a href='https://arxiv.org/pdf/2412.13811.pdf' target='_blank'>https://arxiv.org/pdf/2412.13811.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas Weidner, Michal Balcerak, Ivan Ezhov, AndrÃ© Datchev, Laurin Lux, Lucas Zimmer, Daniel Rueckert, BjÃ¶rn Menze, Benedikt Wiestler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13811">A Lightweight Optimization Framework for Estimating 3D Brain Tumor Infiltration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Glioblastoma, the most aggressive primary brain tumor, poses a severe clinical challenge due to its diffuse microscopic infiltration, which remains largely undetected on standard MRI. As a result, current radiotherapy planning employs a uniform 15 mm margin around the resection cavity, failing to capture patient-specific tumor spread. Tumor growth modeling offers a promising approach to reveal this hidden infiltration. However, methods based on partial differential equations or physics-informed neural networks tend to be computationally intensive or overly constrained, limiting their clinical adaptability to individual patients. In this work, we propose a lightweight, rapid, and robust optimization framework that estimates the 3D tumor concentration by fitting it to MRI tumor segmentations while enforcing a smooth concentration landscape. This approach achieves superior tumor recurrence prediction on 192 brain tumor patients across two public datasets, outperforming state-of-the-art baselines while reducing runtime from 30 minutes to less than one minute. Furthermore, we demonstrate the framework's versatility and adaptability by showing its ability to seamlessly integrate additional imaging modalities or physical constraints.
<div id='section'>Paperid: <span id='pid'>154, <a href='https://arxiv.org/pdf/2409.18438.pdf' target='_blank'>https://arxiv.org/pdf/2409.18438.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chinthaka Ranasingha, Harshala Gammulle, Tharindu Fernando, Sridha Sridharan, Clinton Fookes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.18438">Physics Augmented Tuple Transformer for Autism Severity Level Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Early diagnosis of Autism Spectrum Disorder (ASD) is an effective and favorable step towards enhancing the health and well-being of children with ASD. Manual ASD diagnosis testing is labor-intensive, complex, and prone to human error due to several factors contaminating the results. This paper proposes a novel framework that exploits the laws of physics for ASD severity recognition. The proposed physics-informed neural network architecture encodes the behaviour of the subject extracted by observing a part of the skeleton-based motion trajectory in a higher dimensional latent space. Two decoders, namely physics-based and non-physics-based decoder, use this latent embedding and predict the future motion patterns. The physics branch leverages the laws of physics that apply to a skeleton sequence in the prediction process while the non-physics-based branch is optimised to minimise the difference between the predicted and actual motion of the subject. A classifier also leverages the same latent space embeddings to recognise the ASD severity. This dual generative objective explicitly forces the network to compare the actual behaviour of the subject with the general normal behaviour of children that are governed by the laws of physics, aiding the ASD recognition task. The proposed method attains state-of-the-art performance on multiple ASD diagnosis benchmarks. To illustrate the utility of the proposed framework beyond the task ASD diagnosis, we conduct a third experiment using a publicly available benchmark for the task of fall prediction and demonstrate the superiority of our model.
<div id='section'>Paperid: <span id='pid'>155, <a href='https://arxiv.org/pdf/2510.03360.pdf' target='_blank'>https://arxiv.org/pdf/2510.03360.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zelin Zhao, Zongyi Li, Kimia Hassibi, Kamyar Azizzadenesheli, Junchi Yan, H. Jane Bae, Di Zhou, Anima Anandkumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03360">Physics-informed Neural-operator Predictive Control for Drag Reduction in Turbulent Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Assessing turbulence control effects for wall friction numerically is a significant challenge since it requires expensive simulations of turbulent fluid dynamics. We instead propose an efficient deep reinforcement learning (RL) framework for modeling and control of turbulent flows. It is model-based RL for predictive control (PC), where both the policy and the observer models for turbulence control are learned jointly using Physics Informed Neural Operators (PINO), which are discretization invariant and can capture fine scales in turbulent flows accurately. Our PINO-PC outperforms prior model-free reinforcement learning methods in various challenging scenarios where the flows are of high Reynolds numbers and unseen, i.e., not provided during model training. We find that PINO-PC achieves a drag reduction of 39.0\% under a bulk-velocity Reynolds number of 15,000, outperforming previous fluid control methods by more than 32\%.
<div id='section'>Paperid: <span id='pid'>156, <a href='https://arxiv.org/pdf/2504.08277.pdf' target='_blank'>https://arxiv.org/pdf/2504.08277.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ryan Y. Lin, Julius Berner, Valentin Duruisseaux, David Pitt, Daniel Leibovici, Jean Kossaifi, Kamyar Azizzadenesheli, Anima Anandkumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08277">Enabling Automatic Differentiation with Mollified Graph Neural Operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural operators offer a powerful framework for learning solution operators of partial differential equations (PDEs) by combining data and physics losses. However, these physics losses rely on derivatives. Computing these derivatives remains challenging, with spectral and finite difference methods introducing approximation errors due to finite resolution. Here, we propose the mollified graph neural operator (mGNO), the first method to leverage automatic differentiation and compute \emph{exact} gradients on arbitrary geometries. This enhancement enables efficient training on irregular grids and varying geometries while allowing seamless evaluation of physics losses at randomly sampled points for improved generalization. For a PDE example on regular grids, mGNO paired with autograd reduced the L2 relative data error by 20x compared to finite differences, although training was slower. It can also solve PDEs on unstructured point clouds seamlessly, using physics losses only, at resolutions vastly lower than those needed for finite differences to be accurate enough. On these unstructured point clouds, mGNO leads to errors that are consistently 2 orders of magnitude lower than machine learning baselines (Meta-PDE) for comparable runtimes, and also delivers speedups from 1 to 3 orders of magnitude compared to the numerical solver for similar accuracy. mGNOs can also be used to solve inverse design and shape optimization problems on complex geometries.
<div id='section'>Paperid: <span id='pid'>157, <a href='https://arxiv.org/pdf/2410.12805.pdf' target='_blank'>https://arxiv.org/pdf/2410.12805.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xujie Shen, Haocheng Peng, Zesong Yang, Juzhan Xu, Hujun Bao, Ruizhen Hu, Zhaopeng Cui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12805">PC-Planner: Physics-Constrained Self-Supervised Learning for Robust Neural Motion Planning with Shape-Aware Distance Function</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motion Planning (MP) is a critical challenge in robotics, especially pertinent with the burgeoning interest in embodied artificial intelligence. Traditional MP methods often struggle with high-dimensional complexities. Recently neural motion planners, particularly physics-informed neural planners based on the Eikonal equation, have been proposed to overcome the curse of dimensionality. However, these methods perform poorly in complex scenarios with shaped robots due to multiple solutions inherent in the Eikonal equation. To address these issues, this paper presents PC-Planner, a novel physics-constrained self-supervised learning framework for robot motion planning with various shapes in complex environments. To this end, we propose several physical constraints, including monotonic and optimal constraints, to stabilize the training process of the neural network with the Eikonal equation. Additionally, we introduce a novel shape-aware distance field that considers the robot's shape for efficient collision checking and Ground Truth (GT) speed computation. This field reduces the computational intensity, and facilitates adaptive motion planning at test time. Experiments in diverse scenarios with different robots demonstrate the superiority of the proposed method in efficiency and robustness for robot motion planning, particularly in complex environments.
<div id='section'>Paperid: <span id='pid'>158, <a href='https://arxiv.org/pdf/2407.07873.pdf' target='_blank'>https://arxiv.org/pdf/2407.07873.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingtong Sun, Julius Berner, Lorenz Richter, Marius Zeinhofer, Johannes MÃ¼ller, Kamyar Azizzadenesheli, Anima Anandkumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.07873">Dynamical Measure Transport and Neural PDE Solvers for Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The task of sampling from a probability density can be approached as transporting a tractable density function to the target, known as dynamical measure transport. In this work, we tackle it through a principled unified framework using deterministic or stochastic evolutions described by partial differential equations (PDEs). This framework incorporates prior trajectory-based sampling methods, such as diffusion models or SchrÃ¶dinger bridges, without relying on the concept of time-reversals. Moreover, it allows us to propose novel numerical methods for solving the transport task and thus sampling from complicated targets without the need for the normalization constant or data samples. We employ physics-informed neural networks (PINNs) to approximate the respective PDE solutions, implying both conceptional and computational advantages. In particular, PINNs allow for simulation- and discretization-free optimization and can be trained very efficiently, leading to significantly better mode coverage in the sampling task compared to alternative methods. Moreover, they can readily be fine-tuned with Gauss-Newton methods to achieve high accuracy in sampling.
<div id='section'>Paperid: <span id='pid'>159, <a href='https://arxiv.org/pdf/2111.03794.pdf' target='_blank'>https://arxiv.org/pdf/2111.03794.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zongyi Li, Hongkai Zheng, Nikola Kovachki, David Jin, Haoxuan Chen, Burigede Liu, Kamyar Azizzadenesheli, Anima Anandkumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2111.03794">Physics-Informed Neural Operator for Learning Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose physics-informed neural operators (PINO) that combine training data and physics constraints to learn the solution operator of a given family of parametric Partial Differential Equations (PDE). PINO is the first hybrid approach incorporating data and PDE constraints at different resolutions to learn the operator. Specifically, in PINO, we combine coarse-resolution training data with PDE constraints imposed at a higher resolution. The resulting PINO model can accurately approximate the ground-truth solution operator for many popular PDE families and shows no degradation in accuracy even under zero-shot super-resolution, i.e., being able to predict beyond the resolution of training data. PINO uses the Fourier neural operator (FNO) framework that is guaranteed to be a universal approximator for any continuous operator and discretization-convergent in the limit of mesh refinement. By adding PDE constraints to FNO at a higher resolution, we obtain a high-fidelity reconstruction of the ground-truth operator. Moreover, PINO succeeds in settings where no training data is available and only PDE constraints are imposed, while previous approaches, such as the Physics-Informed Neural Network (PINN), fail due to optimization challenges, e.g., in multi-scale dynamic systems such as Kolmogorov flows.
<div id='section'>Paperid: <span id='pid'>160, <a href='https://arxiv.org/pdf/2410.16132.pdf' target='_blank'>https://arxiv.org/pdf/2410.16132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Runkang Guo, Bin Chen, Qi Zhang, Yong Zhao, Xiao Wang, Zhengqiu Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.16132">A Data-driven Crowd Simulation Framework Integrating Physics-informed Machine Learning with Navigation Potential Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional rule-based physical models are limited by their reliance on singular physical formulas and parameters, making it difficult to effectively tackle the intricate tasks associated with crowd simulation. Recent research has introduced deep learning methods to tackle these issues, but most current approaches focus primarily on generating pedestrian trajectories, often lacking interpretability and failing to provide real-time dynamic simulations.To address the aforementioned issues, we propose a novel data-driven crowd simulation framework that integrates Physics-informed Machine Learning (PIML) with navigation potential fields. Our approach leverages the strengths of both physical models and PIML. Specifically, we design an innovative Physics-informed Spatio-temporal Graph Convolutional Network (PI-STGCN) as a data-driven module to predict pedestrian movement trends based on crowd spatio-temporal data. Additionally, we construct a physical model of navigation potential fields based on flow field theory to guide pedestrian movements, thereby reinforcing physical constraints during the simulation. In our framework, navigation potential fields are dynamically computed and updated based on the movement trends predicted by the PI-STGCN, while the updated crowd dynamics, guided by these fields, subsequently feed back into the PI-STGCN. Comparative experiments on two publicly available large-scale real-world datasets across five scenes demonstrate that our proposed framework outperforms existing rule-based methods in accuracy and fidelity. The similarity between simulated and actual pedestrian trajectories increases by 10.8%, while the average error is reduced by 4%. Moreover, our framework exhibits greater adaptability and better interpretability compared to methods that rely solely on deep learning for trajectory generation.
<div id='section'>Paperid: <span id='pid'>161, <a href='https://arxiv.org/pdf/2410.06366.pdf' target='_blank'>https://arxiv.org/pdf/2410.06366.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zijie Huang, Wanjia Zhao, Jingdong Gao, Ziniu Hu, Xiao Luo, Yadi Cao, Yuanzhou Chen, Yizhou Sun, Wei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06366">Physics-Informed Regularization for Domain-Agnostic Dynamical System Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning complex physical dynamics purely from data is challenging due to the intrinsic properties of systems to be satisfied. Incorporating physics-informed priors, such as in Hamiltonian Neural Networks (HNNs), achieves high-precision modeling for energy-conservative systems. However, real-world systems often deviate from strict energy conservation and follow different physical priors. To address this, we present a framework that achieves high-precision modeling for a wide range of dynamical systems from the numerical aspect, by enforcing Time-Reversal Symmetry (TRS) via a novel regularization term. It helps preserve energies for conservative systems while serving as a strong inductive bias for non-conservative, reversible systems. While TRS is a domain-specific physical prior, we present the first theoretical proof that TRS loss can universally improve modeling accuracy by minimizing higher-order Taylor terms in ODE integration, which is numerically beneficial to various systems regardless of their properties, even for irreversible systems. By integrating the TRS loss within neural ordinary differential equation models, the proposed model TREAT demonstrates superior performance on diverse physical systems. It achieves a significant 11.5% MSE improvement in a challenging chaotic triple-pendulum scenario, underscoring TREAT's broad applicability and effectiveness.
<div id='section'>Paperid: <span id='pid'>162, <a href='https://arxiv.org/pdf/2402.09730.pdf' target='_blank'>https://arxiv.org/pdf/2402.09730.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruichen Li, Chuwei Wang, Haotian Ye, Di He, Liwei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.09730">DOF: Accelerating High-order Differential Operators with Forward Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving partial differential equations (PDEs) efficiently is essential for analyzing complex physical systems. Recent advancements in leveraging deep learning for solving PDE have shown significant promise. However, machine learning methods, such as Physics-Informed Neural Networks (PINN), face challenges in handling high-order derivatives of neural network-parameterized functions. Inspired by Forward Laplacian, a recent method of accelerating Laplacian computation, we propose an efficient computational framework, Differential Operator with Forward-propagation (DOF), for calculating general second-order differential operators without losing any precision. We provide rigorous proof of the advantages of our method over existing methods, demonstrating two times improvement in efficiency and reduced memory consumption on any architectures. Empirical results illustrate that our method surpasses traditional automatic differentiation (AutoDiff) techniques, achieving 2x improvement on the MLP structure and nearly 20x improvement on the MLP with Jacobian sparsity.
<div id='section'>Paperid: <span id='pid'>163, <a href='https://arxiv.org/pdf/2310.06427.pdf' target='_blank'>https://arxiv.org/pdf/2310.06427.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zijie Huang, Wanjia Zhao, Jingdong Gao, Ziniu Hu, Xiao Luo, Yadi Cao, Yuanzhou Chen, Yizhou Sun, Wei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06427">TANGO: Time-Reversal Latent GraphODE for Multi-Agent Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning complex multi-agent system dynamics from data is crucial across many domains, such as in physical simulations and material modeling. Extended from purely data-driven approaches, existing physics-informed approaches such as Hamiltonian Neural Network strictly follow energy conservation law to introduce inductive bias, making their learning more sample efficiently. However, many real-world systems do not strictly conserve energy, such as spring systems with frictions. Recognizing this, we turn our attention to a broader physical principle: Time-Reversal Symmetry, which depicts that the dynamics of a system shall remain invariant when traversed back over time. It still helps to preserve energies for conservative systems and in the meanwhile, serves as a strong inductive bias for non-conservative, reversible systems. To inject such inductive bias, in this paper, we propose a simple-yet-effective self-supervised regularization term as a soft constraint that aligns the forward and backward trajectories predicted by a continuous graph neural network-based ordinary differential equation (GraphODE). It effectively imposes time-reversal symmetry to enable more accurate model predictions across a wider range of dynamical systems under classical mechanics. In addition, we further provide theoretical analysis to show that our regularization essentially minimizes higher-order Taylor expansion terms during the ODE integration steps, which enables our model to be more noise-tolerant and even applicable to irreversible systems. Experimental results on a variety of physical systems demonstrate the effectiveness of our proposed method. Particularly, it achieves an MSE improvement of 11.5 % on a challenging chaotic triple-pendulum systems.
<div id='section'>Paperid: <span id='pid'>164, <a href='https://arxiv.org/pdf/2507.06826.pdf' target='_blank'>https://arxiv.org/pdf/2507.06826.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yoshiki Masuyama, FranÃ§ois G. Germain, Gordon Wichern, Christopher Ick, Jonathan Le Roux
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06826">Physics-Informed Direction-Aware Neural Acoustic Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a physics-informed neural network (PINN) for modeling first-order Ambisonic (FOA) room impulse responses (RIRs). PINNs have demonstrated promising performance in sound field interpolation by combining the powerful modeling capability of neural networks and the physical principles of sound propagation. In room acoustics, PINNs have typically been trained to represent the sound pressure measured by omnidirectional microphones where the wave equation or its frequency-domain counterpart, i.e., the Helmholtz equation, is leveraged. Meanwhile, FOA RIRs additionally provide spatial characteristics and are useful for immersive audio generation with a wide range of applications. In this paper, we extend the PINN framework to model FOA RIRs. We derive two physics-informed priors for FOA RIRs based on the correspondence between the particle velocity and the (X, Y, Z)-channels of FOA. These priors associate the predicted W-channel and other channels through their partial derivatives and impose the physically feasible relationship on the four channels. Our experiments confirm the effectiveness of the proposed method compared with a neural network without the physics-informed prior.
<div id='section'>Paperid: <span id='pid'>165, <a href='https://arxiv.org/pdf/2504.15623.pdf' target='_blank'>https://arxiv.org/pdf/2504.15623.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiucheng Wang, Qiming Zhang, Nan Cheng, Ruijin Sun, Zan Li, Shuguang Cui, Xuemin Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15623">RadioDiff-$k^2$: Helmholtz Equation Informed Generative Diffusion Model for Multi-Path Aware Radio Map Construction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a novel physics-informed generative learning approach, termed RadioDiff-$\bm{k^2}$, for accurate and efficient multipath-aware radio map (RM) construction. As wireless communication evolves towards environment-aware paradigms, driven by the increasing demand for intelligent and proactive optimization in sixth-generation (6G) networks, accurate construction of RMs becomes crucial yet highly challenging. Conventional electromagnetic (EM)-based methods, such as full-wave solvers and ray-tracing approaches, exhibit substantial computational overhead and limited adaptability to dynamic scenarios. Although, existing neural network (NN) approaches have efficient inferencing speed, they lack sufficient consideration of the underlying physics of EM wave propagation, limiting their effectiveness in accurately modeling critical EM singularities induced by complex multipath environments. To address these fundamental limitations, we propose a novel physics-inspired RM construction method guided explicitly by the Helmholtz equation, which inherently governs EM wave propagation. Specifically, we theoretically establish a direct correspondence between EM singularities, which correspond to the critical spatial features influencing wireless propagation, and regions defined by negative wave numbers in the Helmholtz equation. Based on this insight, we design an innovative dual generative diffusion model (DM) framework comprising one DM dedicated to accurately inferring EM singularities and another DM responsible for reconstructing the complete RM using these singularities along with environmental contextual information. Our physics-informed approach uniquely combines the efficiency advantages of data-driven methods with rigorous physics-based EM modeling, significantly enhancing RM accuracy, particularly in complex propagation environments dominated by multipath effects.
<div id='section'>Paperid: <span id='pid'>166, <a href='https://arxiv.org/pdf/2505.23444.pdf' target='_blank'>https://arxiv.org/pdf/2505.23444.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Runmin Jiang, Genpei Zhang, Yuntian Yang, Siqi Wu, Yuheng Zhang, Wanyue Feng, Yizhou Zhao, Xi Xiao, Xiao Wang, Tianyang Wang, Xingjian Li, Min Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23444">CryoCCD: Conditional Cycle-consistent Diffusion with Biophysical Modeling for Cryo-EM Synthesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryo-electron microscopy (cryo-EM) offers near-atomic resolution imaging of macromolecules, but developing robust models for downstream analysis is hindered by the scarcity of high-quality annotated data. While synthetic data generation has emerged as a potential solution, existing methods often fail to capture both the structural diversity of biological specimens and the complex, spatially varying noise inherent in cryo-EM imaging. To overcome these limitations, we propose CryoCCD, a synthesis framework that integrates biophysical modeling with generative techniques. Specifically, CryoCCD produces multi-scale cryo-EM micrographs that reflect realistic biophysical variability through compositional heterogeneity, cellular context, and physics-informed imaging. To generate realistic noise, we employ a conditional diffusion model, enhanced by cycle consistency to preserve structural fidelity and mask-aware contrastive learning to capture spatially adaptive noise patterns. Extensive experiments show that CryoCCD generates structurally accurate micrographs and enhances performance in downstream tasks, outperforming state-of-the-art baselines in both particle picking and reconstruction.
<div id='section'>Paperid: <span id='pid'>167, <a href='https://arxiv.org/pdf/2306.06766.pdf' target='_blank'>https://arxiv.org/pdf/2306.06766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Li, Haozhe Lei, Hao Guo, Mingsheng Yin, Yaqi Hu, Quanyan Zhu, Sundeep Rangan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06766">Digital Twin-Enhanced Wireless Indoor Navigation: Achieving Efficient Environment Sensing with Zero-Shot Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Millimeter-wave (mmWave) communication is a vital component of future generations of mobile networks, offering not only high data rates but also precise beams, making it ideal for indoor navigation in complex environments. However, the challenges of multipath propagation and noisy signal measurements in indoor spaces complicate the use of mmWave signals for navigation tasks. Traditional physics-based methods, such as following the angle of arrival (AoA), often fall short in complex scenarios, highlighting the need for more sophisticated approaches. Digital twins, as virtual replicas of physical environments, offer a powerful tool for simulating and optimizing mmWave signal propagation in such settings. By creating detailed, physics-based models of real-world spaces, digital twins enable the training of machine learning algorithms in virtual environments, reducing the costs and limitations of physical testing. Despite their advantages, current machine learning models trained in digital twins often overfit specific virtual environments and require costly retraining when applied to new scenarios. In this paper, we propose a Physics-Informed Reinforcement Learning (PIRL) approach that leverages the physical insights provided by digital twins to shape the reinforcement learning (RL) reward function. By integrating physics-based metrics such as signal strength, AoA, and path reflections into the learning process, PIRL enables efficient learning and improved generalization to new environments without retraining. Our experiments demonstrate that the proposed PIRL, supported by digital twin simulations, outperforms traditional heuristics and standard RL models, achieving zero-shot generalization in unseen environments and offering a cost-effective, scalable solution for wireless indoor navigation.
<div id='section'>Paperid: <span id='pid'>168, <a href='https://arxiv.org/pdf/2505.03140.pdf' target='_blank'>https://arxiv.org/pdf/2505.03140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03140">HMAE: Self-Supervised Few-Shot Learning for Quantum Spin Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantum machine learning for spin and molecular systems faces critical challenges of scarce labeled data and computationally expensive simulations. To address these limitations, we introduce Hamiltonian-Masked Autoencoding (HMAE), a novel self-supervised framework that pre-trains transformers on unlabeled quantum Hamiltonians, enabling efficient few-shot transfer learning. Unlike random masking approaches, HMAE employs a physics-informed strategy based on quantum information theory to selectively mask Hamiltonian terms based on their physical significance. Experiments on 12,500 quantum Hamiltonians (60% real-world, 40% synthetic) demonstrate that HMAE achieves 85.3% $\pm$ 1.5% accuracy in phase classification and 0.15 $\pm$ 0.02 eV MAE in ground state energy prediction with merely 10 labeled examples - a statistically significant improvement (p < 0.01) over classical graph neural networks (78.1% $\pm$ 2.1%) and quantum neural networks (76.8% $\pm$ 2.3%). Our method's primary advantage is exceptional sample efficiency - reducing required labeled examples by 3-5x compared to baseline methods - though we emphasize that ground truth values for fine-tuning and evaluation still require exact diagonalization or tensor networks. We explicitly acknowledge that our current approach is limited to small quantum systems (specifically limited to 12 qubits during training, with limited extension to 16-20 qubits in testing) and that, while promising within this regime, this size restriction prevents immediate application to larger systems of practical interest in materials science and quantum chemistry.
<div id='section'>Paperid: <span id='pid'>169, <a href='https://arxiv.org/pdf/2505.03140.pdf' target='_blank'>https://arxiv.org/pdf/2505.03140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03140">HMAE: Self-Supervised Few-Shot Learning for Quantum Spin Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantum machine learning for spin and molecular systems faces critical challenges of scarce labeled data and computationally expensive simulations. To address these limitations, we introduce Hamiltonian-Masked Autoencoding (HMAE), a novel self-supervised framework that pre-trains transformers on unlabeled quantum Hamiltonians, enabling efficient few-shot transfer learning. Unlike random masking approaches, HMAE employs a physics-informed strategy based on quantum information theory to selectively mask Hamiltonian terms based on their physical significance. Experiments on 12,500 quantum Hamiltonians (60% real-world, 40% synthetic) demonstrate that HMAE achieves 85.3% $\pm$ 1.5% accuracy in phase classification and 0.15 $\pm$ 0.02 eV MAE in ground state energy prediction with merely 10 labeled examples - a statistically significant improvement (p < 0.01) over classical graph neural networks (78.1% $\pm$ 2.1%) and quantum neural networks (76.8% $\pm$ 2.3%). Our method's primary advantage is exceptional sample efficiency - reducing required labeled examples by 3-5x compared to baseline methods - though we emphasize that ground truth values for fine-tuning and evaluation still require exact diagonalization or tensor networks. We explicitly acknowledge that our current approach is limited to small quantum systems (specifically limited to 12 qubits during training, with limited extension to 16-20 qubits in testing) and that, while promising within this regime, this size restriction prevents immediate application to larger systems of practical interest in materials science and quantum chemistry.
<div id='section'>Paperid: <span id='pid'>170, <a href='https://arxiv.org/pdf/2309.07672.pdf' target='_blank'>https://arxiv.org/pdf/2309.07672.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengge Du, Yuntian Chen, Longfeng Nie, Siyu Lou, Dongxiao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.07672">Physics-constrained robust learning of open-form partial differential equations from limited and noisy data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unveiling the underlying governing equations of nonlinear dynamic systems remains a significant challenge. Insufficient prior knowledge hinders the determination of an accurate candidate library, while noisy observations lead to imprecise evaluations, which in turn result in redundant function terms or erroneous equations. This study proposes a framework to robustly uncover open-form partial differential equations (PDEs) from limited and noisy data. The framework operates through two alternating update processes: discovering and embedding. The discovering phase employs symbolic representation and a novel reinforcement learning (RL)-guided hybrid PDE generator to efficiently produce diverse open-form PDEs with tree structures. A neural network-based predictive model fits the system response and serves as the reward evaluator for the generated PDEs. PDEs with higher rewards are utilized to iteratively optimize the generator via the RL strategy and the best-performing PDE is selected by a parameter-free stability metric. The embedding phase integrates the initially identified PDE from the discovering process as a physical constraint into the predictive model for robust training. The traversal of PDE trees automates the construction of the computational graph and the embedding process without human intervention. Numerical experiments demonstrate our framework's capability to uncover governing equations from nonlinear dynamic systems with limited and highly noisy data and outperform other physics-informed neural network-based discovery methods. This work opens new potential for exploring real-world systems with limited understanding.
<div id='section'>Paperid: <span id='pid'>171, <a href='https://arxiv.org/pdf/2508.07841.pdf' target='_blank'>https://arxiv.org/pdf/2508.07841.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlo Cena, Mauro Martini, Marcello Chiaberge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07841">Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Attitude control is a fundamental aspect of spacecraft operations. Model Predictive Control (MPC) has emerged as a powerful strategy for these tasks, relying on accurate models of the system dynamics to optimize control actions over a prediction horizon. In scenarios where physics models are incomplete, difficult to derive, or computationally expensive, machine learning offers a flexible alternative by learning the system behavior directly from data. However, purely data-driven models often struggle with generalization and stability, especially when applied to inputs outside their training domain. To address these limitations, we investigate the benefits of incorporating Physics-Informed Neural Networks (PINNs) into the learning of spacecraft attitude dynamics, comparing their performance with that of purely data-driven approaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network architecture with a self-attention mechanism, we trained several models on simulated data generated with the Basilisk simulator. Two training strategies were considered: a purely data-driven baseline and a physics-informed variant to improve robustness and stability. Our results demonstrate that the inclusion of physics-based information significantly enhances the performance in terms of the mean relative error of the best architectures found by 27.08%. These advantages are particularly evident when the learned models are integrated into an MPC framework, where PINN-based models consistently outperform their purely data-driven counterparts in terms of control accuracy and robustness, yielding improvements of up to 42.86% in performance stability error and increased robustness-to-noise.
<div id='section'>Paperid: <span id='pid'>172, <a href='https://arxiv.org/pdf/2504.02015.pdf' target='_blank'>https://arxiv.org/pdf/2504.02015.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriele Greco, Carlo Cena, Umberto Albertin, Mauro Martini, Marcello Chiaberge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02015">Fault injection analysis of Real NVP normalising flow model for satellite anomaly detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Satellites are used for a multitude of applications, including communications, Earth observation, and space science. Neural networks and deep learning-based approaches now represent the state-of-the-art to enhance the performance and efficiency of these tasks. Given that satellites are susceptible to various faults, one critical application of Artificial Intelligence (AI) is fault detection. However, despite the advantages of neural networks, these systems are vulnerable to radiation errors, which can significantly impact their reliability. Ensuring the dependability of these solutions requires extensive testing and validation, particularly using fault injection methods. This study analyses a physics-informed (PI) real-valued non-volume preserving (Real NVP) normalizing flow model for fault detection in space systems, with a focus on resilience to Single-Event Upsets (SEUs). We present a customized fault injection framework in TensorFlow to assess neural network resilience. Fault injections are applied through two primary methods: Layer State injection, targeting internal network components such as weights and biases, and Layer Output injection, which modifies layer outputs across various activations. Fault types include zeros, random values, and bit-flip operations, applied at varying levels and across different network layers. Our findings reveal several critical insights, such as the significance of bit-flip errors in critical bits, that can lead to substantial performance degradation or even system failure. With this work, we aim to exhaustively study the resilience of Real NVP models against errors due to radiation, providing a means to guide the implementation of fault tolerance measures.
<div id='section'>Paperid: <span id='pid'>173, <a href='https://arxiv.org/pdf/2501.19160.pdf' target='_blank'>https://arxiv.org/pdf/2501.19160.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haozhe Jia, Wenshuo Chen, Zhihui Huang, Lei Wang, Hongru Xiao, Nanqian Jia, Keming Wu, Songning Lai, Bowen Tian, Yutao Yue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.19160">Physics-Informed Representation Alignment for Sparse Radio-Map Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Radio map reconstruction is essential for enabling advanced applications, yet challenges such as complex signal propagation and sparse observational data hinder accurate reconstruction in practical scenarios. Existing methods often fail to align physical constraints with data-driven features, particularly under sparse measurement conditions. To address these issues, we propose **Phy**sics-Aligned **R**adio **M**ap **D**iffusion **M**odel (**PhyRMDM**), a novel framework that establishes cross-domain representation alignment between physical principles and neural network features through dual learning pathways. The proposed model integrates **Physics-Informed Neural Networks (PINNs)** with a **representation alignment mechanism** that explicitly enforces consistency between Helmholtz equation constraints and environmental propagation patterns. Experimental results demonstrate significant improvements over state-of-the-art methods, achieving **NMSE of 0.0031** under *Static Radio Map (SRM)* conditions, and **NMSE of 0.0047** with **Dynamic Radio Map (DRM)** scenarios. The proposed representation alignment paradigm provides **37.2%** accuracy enhancement in ultra-sparse cases (**1%** sampling rate), confirming its effectiveness in bridging physics-based modeling and deep learning for radio map reconstruction.
<div id='section'>Paperid: <span id='pid'>174, <a href='https://arxiv.org/pdf/2406.00559.pdf' target='_blank'>https://arxiv.org/pdf/2406.00559.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guglielmo Padula, Michele Girfoglio, Gianluigi Rozza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00559">A brief review of Reduced Order Models using intrusive and non-intrusive techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reduced Order Models (ROMs) have gained a great attention by the scientific community in the last years thanks to their capabilities of significantly reducing the computational cost of the numerical simulations, which is a crucial objective in applications like real time control and shape optimization. This contribution aims to provide a brief overview about such a topic. We discuss both an intrusive framework based on a Galerkin projection technique and non-intrusive approaches, including Physics Informed Neural Networks (PINN), purely Data-Driven Neural Networks (DDNN), Radial Basis Functions (RBF), Dynamic Mode Decomposition (DMD) and Gaussian Process Regression (GPR). We also briefly mention geometrical parametrization and dimensionality reduction methods like Active Subspaces (AS). Then we present some results related to academic test cases as well as a preliminary investigation related to an industrial application.
<div id='section'>Paperid: <span id='pid'>175, <a href='https://arxiv.org/pdf/2405.17339.pdf' target='_blank'>https://arxiv.org/pdf/2405.17339.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlo Cena, Umberto Albertin, Mauro Martini, Silvia Bucci, Marcello Chiaberge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17339">Physics-Informed Real NVP for Satellite Power System Fault Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The unique challenges posed by the space environment, characterized by extreme conditions and limited accessibility, raise the need for robust and reliable techniques to identify and prevent satellite faults. Fault detection methods in the space sector are required to ensure mission success and to protect valuable assets. In this context, this paper proposes an Artificial Intelligence (AI) based fault detection methodology and evaluates its performance on ADAPT (Advanced Diagnostics and Prognostics Testbed), an Electrical Power System (EPS) dataset, crafted in laboratory by NASA. Our study focuses on the application of a physics-informed (PI) real-valued non-volume preserving (Real NVP) model for fault detection in space systems. The efficacy of this method is systematically compared against other AI approaches such as Gated Recurrent Unit (GRU) and Autoencoder-based techniques. Results show that our physics-informed approach outperforms existing methods of fault detection, demonstrating its suitability for addressing the unique challenges of satellite EPS sub-system faults. Furthermore, we unveil the competitive advantage of physics-informed loss in AI models to address specific space needs, namely robustness, reliability, and power constraints, crucial for space exploration and satellite missions.
<div id='section'>Paperid: <span id='pid'>176, <a href='https://arxiv.org/pdf/2409.01626.pdf' target='_blank'>https://arxiv.org/pdf/2409.01626.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddhant Dutta, Nouhaila Innan, Sadok Ben Yahia, Muhammad Shafique
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01626">AQ-PINNs: Attention-Enhanced Quantum Physics-Informed Neural Networks for Carbon-Efficient Climate Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing computational demands of artificial intelligence (AI) in addressing climate change raise significant concerns about inefficiencies and environmental impact, as highlighted by the Jevons paradox. We propose an attention-enhanced quantum physics-informed neural networks model (AQ-PINNs) to tackle these challenges. This approach integrates quantum computing techniques into physics-informed neural networks (PINNs) for climate modeling, aiming to enhance predictive accuracy in fluid dynamics governed by the Navier-Stokes equations while reducing the computational burden and carbon footprint. By harnessing variational quantum multi-head self-attention mechanisms, our AQ-PINNs achieve a 51.51% reduction in model parameters compared to classical multi-head self-attention methods while maintaining comparable convergence and loss. It also employs quantum tensor networks to enhance representational capacity, which can lead to more efficient gradient computations and reduced susceptibility to barren plateaus. Our AQ-PINNs represent a crucial step towards more sustainable and effective climate modeling solutions.
<div id='section'>Paperid: <span id='pid'>177, <a href='https://arxiv.org/pdf/2402.02711.pdf' target='_blank'>https://arxiv.org/pdf/2402.02711.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hemanth Saratchandran, Shin-Fang Chng, Simon Lucey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.02711">Architectural Strategies for the optimization of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) offer a promising avenue for tackling both forward and inverse problems in partial differential equations (PDEs) by incorporating deep learning with fundamental physics principles. Despite their remarkable empirical success, PINNs have garnered a reputation for their notorious training challenges across a spectrum of PDEs. In this work, we delve into the intricacies of PINN optimization from a neural architecture perspective. Leveraging the Neural Tangent Kernel (NTK), our study reveals that Gaussian activations surpass several alternate activations when it comes to effectively training PINNs. Building on insights from numerical linear algebra, we introduce a preconditioned neural architecture, showcasing how such tailored architectures enhance the optimization process. Our theoretical findings are substantiated through rigorous validation against established PDEs within the scientific literature.
<div id='section'>Paperid: <span id='pid'>178, <a href='https://arxiv.org/pdf/2509.09936.pdf' target='_blank'>https://arxiv.org/pdf/2509.09936.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saarth Gaonkar, Xiang Zheng, Haocheng Xi, Rishabh Tiwari, Kurt Keutzer, Dmitriy Morozov, Michael W. Mahoney, Amir Gholami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.09936">SciML Agents: Write the Solver, Not the Solution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent work in scientific machine learning aims to tackle scientific tasks directly by predicting target values with neural networks (e.g., physics-informed neural networks, neural ODEs, neural operators, etc.), but attaining high accuracy and robustness has been challenging. We explore an alternative view: use LLMs to write code that leverages decades of numerical algorithms. This shifts the burden from learning a solution function to making domain-aware numerical choices. We ask whether LLMs can act as SciML agents that, given a natural-language ODE description, generate runnable code that is scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff), and enforcing stability checks. There is currently no benchmark to measure this kind of capability for scientific computing tasks. As such, we first introduce two new datasets: a diagnostic dataset of adversarial "misleading" problems; and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set contains problems whose superficial appearance suggests stiffness, and that require algebraic simplification to demonstrate non-stiffness; and the large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open- and closed-source LLM models along two axes: (i) unguided versus guided prompting with domain-specific knowledge; and (ii) off-the-shelf versus fine-tuned variants. Our evaluation measures both executability and numerical validity against reference solutions. We find that with sufficient context and guided prompts, newer instruction-following models achieve high accuracy on both criteria. In many cases, recent open-source systems perform strongly without fine-tuning, while older or smaller models still benefit from fine-tuning. Overall, our preliminary results indicate that careful prompting and fine-tuning can yield a specialized LLM agent capable of reliably solving simple ODE problems.
<div id='section'>Paperid: <span id='pid'>179, <a href='https://arxiv.org/pdf/2504.06070.pdf' target='_blank'>https://arxiv.org/pdf/2504.06070.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huaguan Chen, Yang Liu, Hao Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.06070">PINP: Physics-Informed Neural Predictor with latent estimation of fluid flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting fluid dynamics and evolution has been a long-standing challenge in physical sciences. Conventional deep learning methods often rely on the nonlinear modeling capabilities of neural networks to establish mappings between past and future states, overlooking the fluid dynamics, or only modeling the velocity field, neglecting the coupling of multiple physical quantities. In this paper, we propose a new physics-informed learning approach that incorporates coupled physical quantities into the prediction process to assist with forecasting. Central to our method lies in the discretization of physical equations, which are directly integrated into the model architecture and loss function. This integration enables the model to provide robust, long-term future predictions. By incorporating physical equations, our model demonstrates temporal extrapolation and spatial generalization capabilities. Experimental results show that our approach achieves the state-of-the-art performance in spatiotemporal prediction across both numerical simulations and real-world extreme-precipitation nowcasting benchmarks.
<div id='section'>Paperid: <span id='pid'>180, <a href='https://arxiv.org/pdf/2410.22371.pdf' target='_blank'>https://arxiv.org/pdf/2410.22371.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chun-Wei Kong, Luca Laurenti, Jay McMahon, Morteza Lahijanian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.22371">Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Stochastic differential equations are commonly used to describe the evolution of stochastic processes. The state uncertainty of such processes is best represented by the probability density function (PDF), whose evolution is governed by the Fokker-Planck partial differential equation (FP-PDE). However, it is generally infeasible to solve the FP-PDE in closed form. In this work, we show that physics-informed neural networks (PINNs) can be trained to approximate the solution PDF. Our main contribution is the analysis of PINN approximation error: we develop a theoretical framework to construct tight error bounds using PINNs. In addition, we derive a practical error bound that can be efficiently constructed with standard training methods. We discuss that this error-bound framework generalizes to approximate solutions of other linear PDEs. Empirical results on nonlinear, high-dimensional, and chaotic systems validate the correctness of our error bounds while demonstrating the scalability of PINNs and their significant computational speedup in obtaining accurate PDF solutions compared to the Monte Carlo approach.
<div id='section'>Paperid: <span id='pid'>181, <a href='https://arxiv.org/pdf/2410.22371.pdf' target='_blank'>https://arxiv.org/pdf/2410.22371.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chun-Wei Kong, Luca Laurenti, Jay McMahon, Morteza Lahijanian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.22371">Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Stochastic differential equations are commonly used to describe the evolution of stochastic processes. The state uncertainty of such processes is best represented by the probability density function (PDF), whose evolution is governed by the Fokker-Planck partial differential equation (FP-PDE). However, it is generally infeasible to solve the FP-PDE in closed form. In this work, we show that physics-informed neural networks (PINNs) can be trained to approximate the solution PDF. Our main contribution is the analysis of PINN approximation error: we develop a theoretical framework to construct tight error bounds using PINNs. In addition, we derive a practical error bound that can be efficiently constructed with standard training methods. We discuss that this error-bound framework generalizes to approximate solutions of other linear PDEs. Empirical results on nonlinear, high-dimensional, and chaotic systems validate the correctness of our error bounds while demonstrating the scalability of PINNs and their significant computational speedup in obtaining accurate PDF solutions compared to the Monte Carlo approach.
<div id='section'>Paperid: <span id='pid'>182, <a href='https://arxiv.org/pdf/2308.16372.pdf' target='_blank'>https://arxiv.org/pdf/2308.16372.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qian Zhang, Chenxi Wu, Adar Kahana, Youngeun Kim, Yuhang Li, George Em Karniadakis, Priyadarshini Panda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16372">Artificial to Spiking Neural Networks Conversion for Scientific Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a method to convert Physics-Informed Neural Networks (PINNs), commonly used in scientific machine learning, to Spiking Neural Networks (SNNs), which are expected to have higher energy efficiency compared to traditional Artificial Neural Networks (ANNs). We first extend the calibration technique of SNNs to arbitrary activation functions beyond ReLU, making it more versatile, and we prove a theorem that ensures the effectiveness of the calibration. We successfully convert PINNs to SNNs, enabling computational efficiency for diverse regression tasks in solving multiple differential equations, including the unsteady Navier-Stokes equations. We demonstrate great gains in terms of overall efficiency, including Separable PINNs (SPINNs), which accelerate the training process. Overall, this is the first work of this kind and the proposed method achieves relatively good accuracy with low spike rates.
<div id='section'>Paperid: <span id='pid'>183, <a href='https://arxiv.org/pdf/2305.10157.pdf' target='_blank'>https://arxiv.org/pdf/2305.10157.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francisco Eiras, Adel Bibi, Rudy Bunel, Krishnamurthy Dj Dvijotham, Philip Torr, M. Pawan Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.10157">Efficient Error Certification for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent work provides promising evidence that Physics-Informed Neural Networks (PINN) can efficiently solve partial differential equations (PDE). However, previous works have failed to provide guarantees on the worst-case residual error of a PINN across the spatio-temporal domain - a measure akin to the tolerance of numerical solvers - focusing instead on point-wise comparisons between their solution and the ones obtained by a solver on a set of inputs. In real-world applications, one cannot consider tests on a finite set of points to be sufficient grounds for deployment, as the performance could be substantially worse on a different set. To alleviate this issue, we establish guaranteed error-based conditions for PINNs over their continuous applicability domain. To verify the extent to which they hold, we introduce $\partial$-CROWN: a general, efficient and scalable post-training framework to bound PINN residual errors. We demonstrate its effectiveness in obtaining tight certificates by applying it to two classically studied PINNs - Burgers' and SchrÃ¶dinger's equations -, and two more challenging ones with real-world applications - the Allan-Cahn and Diffusion-Sorption equations.
<div id='section'>Paperid: <span id='pid'>184, <a href='https://arxiv.org/pdf/2305.05150.pdf' target='_blank'>https://arxiv.org/pdf/2305.05150.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pu Ren, Chengping Rao, Hao Sun, Yang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.05150">Physics-informed neural network for seismic wave inversion in layered semi-infinite domain</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating the material distribution of Earth's subsurface is a challenging task in seismology and earthquake engineering. The recent development of physics-informed neural network (PINN) has shed new light on seismic inversion. In this paper, we present a PINN framework for seismic wave inversion in layered (1D) semi-infinite domain. The absorbing boundary condition is incorporated into the network as a soft regularizer for avoiding excessive computation. In specific, we design a lightweight network to learn the unknown material distribution and a deep neural network to approximate solution variables. The entire network is end-to-end and constrained by both sparse measurement data and the underlying physical laws (i.e., governing equations and initial/boundary conditions). Various experiments have been conducted to validate the effectiveness of our proposed approach for inverse modeling of seismic wave propagation in 1D semi-infinite domain.
<div id='section'>Paperid: <span id='pid'>185, <a href='https://arxiv.org/pdf/2106.04781.pdf' target='_blank'>https://arxiv.org/pdf/2106.04781.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chengping Rao, Pu Ren, Qi Wang, Oral Buyukozturk, Hao Sun, Yang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2106.04781">Encoding physics to learn reaction-diffusion processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling complex spatiotemporal dynamical systems, such as the reaction-diffusion processes, have largely relied on partial differential equations (PDEs). However, due to insufficient prior knowledge on some under-explored dynamical systems, such as those in chemistry, biology, geology, physics and ecology, and the lack of explicit PDE formulation used for describing the nonlinear process of the system variables, to predict the evolution of such a system remains a challenging task. Unifying measurement data and our limited prior physics knowledge via machine learning provides us with a new path to solving this problem. Existing physics-informed learning paradigms impose physics laws through soft penalty constraints, whose solution quality largely depends on a trial-and-error proper setting of hyperparameters. Since the core of such methods is still rooted in black-box neural networks, the resulting model generally lacks interpretability and suffers from critical issues of extrapolation and generalization. To this end, we propose a deep learning framework that forcibly encodes given physics structure to facilitate the learning of the spatiotemporal dynamics in sparse data regimes. We show how the proposed approach can be applied to a variety of problems regarding the PDE system, including forward and inverse analysis, data-driven modeling, and discovery of PDEs. The resultant learning paradigm that encodes physics shows high accuracy, robustness, interpretability and generalizability demonstrated via extensive numerical experiments.
<div id='section'>Paperid: <span id='pid'>186, <a href='https://arxiv.org/pdf/2105.00557.pdf' target='_blank'>https://arxiv.org/pdf/2105.00557.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chengping Rao, Hao Sun, Yang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2105.00557">Hard Encoding of Physics for Learning Spatiotemporal Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling nonlinear spatiotemporal dynamical systems has primarily relied on partial differential equations (PDEs). However, the explicit formulation of PDEs for many underexplored processes, such as climate systems, biochemical reaction and epidemiology, remains uncertain or partially unknown, where very limited measurement data is yet available. To tackle this challenge, we propose a novel deep learning architecture that forcibly encodes known physics knowledge to facilitate learning in a data-driven manner. The coercive encoding mechanism of physics, which is fundamentally different from the penalty-based physics-informed learning, ensures the network to rigorously obey given physics. Instead of using nonlinear activation functions, we propose a novel elementwise product operation to achieve the nonlinearity of the model. Numerical experiment demonstrates that the resulting physics-encoded learning paradigm possesses remarkable robustness against data noise/scarcity and generalizability compared with some state-of-the-art models for data-driven modeling.
<div id='section'>Paperid: <span id='pid'>187, <a href='https://arxiv.org/pdf/2506.19243.pdf' target='_blank'>https://arxiv.org/pdf/2506.19243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yixuan Wang, Ziming Liu, Zongyi Li, Anima Anandkumar, Thomas Y. Hou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19243">High precision PINNs in unbounded domains: application to singularity formulation in PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate the high-precision training of Physics-Informed Neural Networks (PINNs) in unbounded domains, with a special focus on applications to singularity formulation in PDEs. We propose a modularized approach and study the choices of neural network ansatz, sampling strategy, and optimization algorithm. When combined with rigorous computer-assisted proofs and PDE analysis, the numerical solutions identified by PINNs, provided they are of high precision, can serve as a powerful tool for studying singularities in PDEs. For 1D Burgers equation, our framework can lead to a solution with very high precision, and for the 2D Boussinesq equation, which is directly related to the singularity formulation in 3D Euler and Navier-Stokes equations, we obtain a solution whose loss is $4$ digits smaller than that obtained in \cite{wang2023asymptotic} with fewer training steps. We also discuss potential directions for pushing towards machine precision for higher-dimensional problems.
<div id='section'>Paperid: <span id='pid'>188, <a href='https://arxiv.org/pdf/2506.00478.pdf' target='_blank'>https://arxiv.org/pdf/2506.00478.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongjie Zhu, Zezheng Zhang, Zeyu Zhang, Yu Bai, Shimin Wen, Huazhang Wang, Daji Ergu, Ying Cai, Yang Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00478">Dynamic Domain Adaptation-Driven Physics-Informed Graph Representation Learning for AC-OPF</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Alternating Current Optimal Power Flow (AC-OPF) aims to optimize generator power outputs by utilizing the non-linear relationships between voltage magnitudes and phase angles in a power system. However, current AC-OPF solvers struggle to effectively represent the complex relationship between variable distributions in the constraint space and their corresponding optimal solutions. This limitation in constraint modeling restricts the system's ability to develop diverse knowledge representations. Additionally, modeling the power grid solely based on spatial topology further limits the integration of additional prior knowledge, such as temporal information. To overcome these challenges, we propose DDA-PIGCN (Dynamic Domain Adaptation-Driven Physics-Informed Graph Convolutional Network), a new method designed to address constraint-related issues and build a graph-based learning framework that incorporates spatiotemporal features. DDA-PIGCN improves consistency optimization for features with varying long-range dependencies by applying multi-layer, hard physics-informed constraints. It also uses a dynamic domain adaptation learning mechanism that iteratively updates and refines key state variables under predefined constraints, enabling precise constraint verification. Moreover, it captures spatiotemporal dependencies between generators and loads by leveraging the physical structure of the power grid, allowing for deep integration of topological information across time and space. Extensive comparative and ablation studies show that DDA-PIGCN delivers strong performance across several IEEE standard test cases (such as case9, case30, and case300), achieving mean absolute errors (MAE) from 0.0011 to 0.0624 and constraint satisfaction rates between 99.6% and 100%, establishing it as a reliable and efficient AC-OPF solver.
<div id='section'>Paperid: <span id='pid'>189, <a href='https://arxiv.org/pdf/2502.14432.pdf' target='_blank'>https://arxiv.org/pdf/2502.14432.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarvin Moradi, Gerben I. Beintema, Nick Jaensson, Roland TÃ³th, Maarten Schoukens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14432">Port-Hamiltonian Neural Networks with Output Error Noise Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hamiltonian neural networks (HNNs) represent a promising class of physics-informed deep learning methods that utilize Hamiltonian theory as foundational knowledge within neural networks. However, their direct application to engineering systems is often challenged by practical issues, including the presence of external inputs, dissipation, and noisy measurements. This paper introduces a novel framework that enhances the capabilities of HNNs to address these real-life factors. We integrate port-Hamiltonian theory into the neural network structure, allowing for the inclusion of external inputs and dissipation, while mitigating the impact of measurement noise through an output-error (OE) model structure. The resulting output error port-Hamiltonian neural networks (OE-pHNNs) can be adapted to tackle modeling complex engineering systems with noisy measurements. Furthermore, we propose the identification of OE-pHNNs based on the subspace encoder approach (SUBNET), which efficiently approximates the complete simulation loss using subsections of the data and uses an encoder function to predict initial states. By integrating SUBNET with OE-pHNNs, we achieve consistent models of complex engineering systems under noisy measurements. In addition, we perform a consistency analysis to ensure the reliability of the proposed data-driven model learning method. We demonstrate the effectiveness of our approach on system identification benchmarks, showing its potential as a powerful tool for modeling dynamic systems in real-world applications.
<div id='section'>Paperid: <span id='pid'>190, <a href='https://arxiv.org/pdf/2412.00527.pdf' target='_blank'>https://arxiv.org/pdf/2412.00527.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyu Cen, Bangti Jin, Xiyao Li, Zhi Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00527">Imaging Anisotropic Conductivity from Internal Measurements with Mixed Least-Squares Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work we develop a novel algorithm, termed as mixed least-squares deep neural network (MLS-DNN), to recover an anisotropic conductivity tensor from the internal measurements of the solutions. It is based on applying the least-squares formulation to the mixed form of the elliptic problem, and approximating the internal flux and conductivity tensor simultaneously using deep neural networks. We provide error bounds on the approximations obtained via both population and empirical losses. The analysis relies on the canonical source condition, approximation theory of deep neural networks and statistical learning theory. We also present multiple numerical experiments to illustrate the performance of the method, and conduct a comparative study with the standard Galerkin finite element method and physics informed neural network. The results indicate that the method can accurately recover the anisotropic conductivity in both two- and three-dimensional cases, up to 10\% noise in the data.
<div id='section'>Paperid: <span id='pid'>191, <a href='https://arxiv.org/pdf/2408.05177.pdf' target='_blank'>https://arxiv.org/pdf/2408.05177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuwei Wang, Julius Berner, Zongyi Li, Di Zhou, Jiayun Wang, Jane Bae, Anima Anandkumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.05177">Coarse Graining with Neural Operators for Simulating Chaotic Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting the long-term behavior of chaotic systems is crucial for various applications such as climate modeling. However, achieving such predictions typically requires iterative computations over a dense spatiotemporal grid to account for the unstable nature of chaotic systems, which is expensive and impractical in many real-world situations. An alternative approach to such a full-resolved simulation is using a coarse grid and then correcting its errors through a \textit{closure model}, which approximates the overall information from fine scales not captured in the coarse-grid simulation. Recently, ML approaches have been used for closure modeling, but they typically require a large number of training samples from expensive fully-resolved simulations (FRS). In this work, we prove an even more fundamental limitation, i.e., the standard approach to learning closure models suffers from a large approximation error for generic problems, no matter how large the model is, and it stems from the non-uniqueness of the mapping. We propose an alternative end-to-end learning approach using a physics-informed neural operator (PINO) that overcomes this limitation by not using a closure model or a coarse-grid solver. We first train the PINO model on data from a coarse-grid solver and then fine-tune it with (a small amount of) FRS and physics-based losses on a fine grid. The discretization-free nature of neural operators means that they do not suffer from the restriction of a coarse grid that closure models face, and they can provably approximate the long-term statistics of chaotic systems. In our experiments, our PINO model achieves a 330x speedup compared to FRS with a relative error $\sim 10\%$. In contrast, the closure model coupled with a coarse-grid solver is $60$x slower than PINO while having a much higher error $\sim186\%$ when the closure model is trained on the same FRS dataset.
<div id='section'>Paperid: <span id='pid'>192, <a href='https://arxiv.org/pdf/2403.01993.pdf' target='_blank'>https://arxiv.org/pdf/2403.01993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Noah Maul, Annette Birkhold, Fabian Wagner, Mareike Thies, Maximilian Rohleder, Philipp Berg, Markus Kowarschik, Andreas Maier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01993">Physics-Informed Learning for Time-Resolved Angiographic Contrast Agent Concentration Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Three-dimensional Digital Subtraction Angiography (3D-DSA) is a well-established X-ray-based technique for visualizing vascular anatomy. Recently, four-dimensional DSA (4D-DSA) reconstruction algorithms have been developed to enable the visualization of volumetric contrast flow dynamics through time-series of volumes. . This reconstruction problem is ill-posed mainly due to vessel overlap in the projection direction and geometric vessel foreshortening, which leads to information loss in the recorded projection images. However, knowledge about the underlying fluid dynamics can be leveraged to constrain the solution space. In our work, we implicitly include this information in a neural network-based model that is trained on a dataset of image-based blood flow simulations. The model predicts the spatially averaged contrast agent concentration for each centerline point of the vasculature over time, lowering the overall computational demand. The trained network enables the reconstruction of relative contrast agent concentrations with a mean absolute error of 0.02 $\pm$ 0.02 and a mean absolute percentage error of 5.31 % $\pm$ 9.25 %. Moreover, the network is robust to varying degrees of vessel overlap and vessel foreshortening. Our approach demonstrates the potential of the integration of machine learning and blood flow simulations in time-resolved angiographic flow reconstruction.
<div id='section'>Paperid: <span id='pid'>193, <a href='https://arxiv.org/pdf/2403.01993.pdf' target='_blank'>https://arxiv.org/pdf/2403.01993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Noah Maul, Annette Birkhold, Fabian Wagner, Mareike Thies, Maximilian Rohleder, Philipp Berg, Markus Kowarschik, Andreas Maier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01993">Physics-Informed Learning for Time-Resolved Angiographic Contrast Agent Concentration Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Three-dimensional Digital Subtraction Angiography (3D-DSA) is a well-established X-ray-based technique for visualizing vascular anatomy. Recently, four-dimensional DSA (4D-DSA) reconstruction algorithms have been developed to enable the visualization of volumetric contrast flow dynamics through time-series of volumes. . This reconstruction problem is ill-posed mainly due to vessel overlap in the projection direction and geometric vessel foreshortening, which leads to information loss in the recorded projection images. However, knowledge about the underlying fluid dynamics can be leveraged to constrain the solution space. In our work, we implicitly include this information in a neural network-based model that is trained on a dataset of image-based blood flow simulations. The model predicts the spatially averaged contrast agent concentration for each centerline point of the vasculature over time, lowering the overall computational demand. The trained network enables the reconstruction of relative contrast agent concentrations with a mean absolute error of 0.02 $\pm$ 0.02 and a mean absolute percentage error of 5.31 % $\pm$ 9.25 %. Moreover, the network is robust to varying degrees of vessel overlap and vessel foreshortening. Our approach demonstrates the potential of the integration of machine learning and blood flow simulations in time-resolved angiographic flow reconstruction.
<div id='section'>Paperid: <span id='pid'>194, <a href='https://arxiv.org/pdf/2308.16905.pdf' target='_blank'>https://arxiv.org/pdf/2308.16905.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sirui Xu, Zhengyuan Li, Yu-Xiong Wang, Liang-Yan Gui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16905">InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses a novel task of anticipating 3D human-object interactions (HOIs). Most existing research on HOI synthesis lacks comprehensive whole-body interactions with dynamic objects, e.g., often limited to manipulating small or static objects. Our task is significantly more challenging, as it requires modeling dynamic objects with various shapes, capturing whole-body motion, and ensuring physically valid interactions. To this end, we propose InterDiff, a framework comprising two key steps: (i) interaction diffusion, where we leverage a diffusion model to encode the distribution of future human-object interactions; (ii) interaction correction, where we introduce a physics-informed predictor to correct denoised HOIs in a diffusion step. Our key insight is to inject prior knowledge that the interactions under reference with respect to contact points follow a simple pattern and are easily predictable. Experiments on multiple human-object interaction datasets demonstrate the effectiveness of our method for this task, capable of producing realistic, vivid, and remarkably long-term 3D HOI predictions.
<div id='section'>Paperid: <span id='pid'>195, <a href='https://arxiv.org/pdf/2308.16429.pdf' target='_blank'>https://arxiv.org/pdf/2308.16429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianhao Hu, Bangti Jin, Zhi Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16429">Solving Poisson Problems in Polygonal Domains with Singularity Enriched Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are a powerful class of numerical solvers for partial differential equations, employing deep neural networks with successful applications across a diverse set of problems. However, their effectiveness is somewhat diminished when addressing issues involving singularities, such as point sources or geometric irregularities, where the approximations they provide often suffer from reduced accuracy due to the limited regularity of the exact solution. In this work, we investigate PINNs for solving Poisson equations in polygonal domains with geometric singularities and mixed boundary conditions. We propose a novel singularity enriched PINN (SEPINN), by explicitly incorporating the singularity behavior of the analytic solution, e.g., corner singularity, mixed boundary condition and edge singularities, into the ansatz space, and present a convergence analysis of the scheme. We present extensive numerical simulations in two and three-dimensions to illustrate the efficiency of the method, and also a comparative study with several existing neural network based approaches.
<div id='section'>Paperid: <span id='pid'>196, <a href='https://arxiv.org/pdf/2305.01338.pdf' target='_blank'>https://arxiv.org/pdf/2305.01338.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarvin Moradi, Nick Jaensson, Roland TÃ³th, Maarten Schoukens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.01338">Physics-Informed Learning Using Hamiltonian Neural Networks with Output Error Noise Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In order to make data-driven models of physical systems interpretable and reliable, it is essential to include prior physical knowledge in the modeling framework. Hamiltonian Neural Networks (HNNs) implement Hamiltonian theory in deep learning and form a comprehensive framework for modeling autonomous energy-conservative systems. Despite being suitable to estimate a wide range of physical system behavior from data, classical HNNs are restricted to systems without inputs and require noiseless state measurements and information on the derivative of the state to be available. To address these challenges, this paper introduces an Output Error Hamiltonian Neural Network (OE-HNN) modeling approach to address the modeling of physical systems with inputs and noisy state measurements. Furthermore, it does not require the state derivatives to be known. Instead, the OE-HNN utilizes an ODE-solver embedded in the training process, which enables the OE-HNN to learn the dynamics from noisy state measurements. In addition, extending HNNs based on the generalized Hamiltonian theory enables to include external inputs into the framework which are important for engineering applications. We demonstrate via simulation examples that the proposed OE-HNNs results in superior modeling performance compared to classical HNNs.
<div id='section'>Paperid: <span id='pid'>197, <a href='https://arxiv.org/pdf/2211.15960.pdf' target='_blank'>https://arxiv.org/pdf/2211.15960.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adarsh Ganeshram, Haydn Maust, Valentin Duruisseaux, Zongyi Li, Yixuan Wang, Daniel Leibovici, Oscar Bruno, Thomas Hou, Anima Anandkumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.15960">FC-PINO: High Precision Physics-Informed Neural Operators via Fourier Continuation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The physics-informed neural operator (PINO) is a machine learning paradigm that has demonstrated promising results for learning solutions to partial differential equations (PDEs). It leverages the Fourier Neural Operator to learn solution operators in function spaces and leverages physics losses during training to penalize deviations from known physics laws. Spectral differentiation provides an efficient way to compute derivatives for the physics losses, but it inherently assumes periodicity. When applied to non-periodic functions, this assumption of periodicity can lead to significant errors, including Gibbs phenomena near domain boundaries which degrade the accuracy of both function representations and derivative computations, especially for higher order derivatives. To overcome this limitation, we introduce the FC-PINO (Fourier-Continuation-based PINO) architecture which extends the accuracy and efficiency of PINO and spectral differentiation to non-periodic and non-smooth PDEs. In FC-PINO, we propose integrating Fourier continuation into the PINO framework, and test two different continuation approaches: FC-Legendre and FC-Gram. By transforming non-periodic signals into periodic functions on extended domains in a well-conditioned manner, Fourier continuation enables fast and accurate derivative computations. This approach avoids the discretization sensitivity of finite differences and the memory overhead of automatic differentiation. We demonstrate that standard PINO struggles to solve non-periodic and non-smooth PDEs with high precision, across challenging benchmarks. In contrast, the proposed FC-PINO provides accurate, robust, and scalable solutions, substantially outperforming PINO alternatives, and demonstrating that Fourier continuation is critical for extending PINO to a wider range of PDE problems when high-precision solutions are needed.
<div id='section'>Paperid: <span id='pid'>198, <a href='https://arxiv.org/pdf/2509.18105.pdf' target='_blank'>https://arxiv.org/pdf/2509.18105.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nachiket N. Naik, Prathamesh Dinesh Joshi, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18105">BULL-ODE: Bullwhip Learning with Neural ODEs and Universal Differential Equations under Stochastic Demand</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study learning of continuous-time inventory dynamics under stochastic demand and quantify when structure helps or hurts forecasting of the bullwhip effect. BULL-ODE compares a fully learned Neural ODE (NODE) that models the entire right-hand side against a physics-informed Universal Differential Equation (UDE) that preserves conservation and order-up-to structure while learning a small residual policy term. Classical supply chain models explain the bullwhip through control/forecasting choices and information sharing, while recent physics-informed and neural differential equation methods blend domain constraints with learned components. It is unclear whether structural bias helps or hinders forecasting under different demand regimes. We address this by using a single-echelon testbed with three demand regimes - AR(1) (autocorrelated), i.i.d. Gaussian, and heavy-tailed lognormal. Training is done on varying fractions of each trajectory, followed by evaluation of multi-step forecasts for inventory I, order rate O, and demand D. Across the structured regimes, UDE consistently generalizes better: with 90% of the training horizon, inventory RMSE drops from 4.92 (NODE) to 0.26 (UDE) under AR(1) and from 5.96 to 0.95 under Gaussian demand. Under heavy-tailed lognormal shocks, the flexibility of NODE is better. These trends persist as train18 ing data shrinks, with NODE exhibiting phase drift in extrapolation while UDE remains stable but underreacts to rare spikes. Our results provide concrete guidance: enforce structure when noise is light-tailed or temporally correlated; relax structure when extreme events dominate. Beyond inventory control, the results offer guidance for hybrid modeling in scientific and engineering systems: enforce known structure when conservation laws and modest noise dominate, and relax structure to capture extremes in settings where rare events drive dynamics.
<div id='section'>Paperid: <span id='pid'>199, <a href='https://arxiv.org/pdf/2508.20414.pdf' target='_blank'>https://arxiv.org/pdf/2508.20414.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengyu Sun, Ziyuan Yang, Yongqiang Huang, Hui Yu, Yingyu Chen, Shuren Qi, Andrew Beng Jin Teoh, Yi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20414">Federated Learning for Large Models in Medical Imaging: A Comprehensive Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence (AI) has demonstrated considerable potential in the realm of medical imaging. However, the development of high-performance AI models typically necessitates training on large-scale, centralized datasets. This approach is confronted with significant challenges due to strict patient privacy regulations and legal restrictions on data sharing and utilization. These limitations hinder the development of large-scale models in medical domains and impede continuous updates and training with new data. Federated Learning (FL), a privacy-preserving distributed training framework, offers a new solution by enabling collaborative model development across fragmented medical datasets. In this survey, we review FL's contributions at two stages of the full-stack medical analysis pipeline. First, in upstream tasks such as CT or MRI reconstruction, FL enables joint training of robust reconstruction networks on diverse, multi-institutional datasets, alleviating data scarcity while preserving confidentiality. Second, in downstream clinical tasks like tumor diagnosis and segmentation, FL supports continuous model updating by allowing local fine-tuning on new data without centralizing sensitive images. We comprehensively analyze FL implementations across the medical imaging pipeline, from physics-informed reconstruction networks to diagnostic AI systems, highlighting innovations that improve communication efficiency, align heterogeneous data, and ensure secure parameter aggregation. Meanwhile, this paper provides an outlook on future research directions, aiming to serve as a valuable reference for the field's development.
<div id='section'>Paperid: <span id='pid'>200, <a href='https://arxiv.org/pdf/2507.08834.pdf' target='_blank'>https://arxiv.org/pdf/2507.08834.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karishma Battina, Prathamesh Dinesh Joshi, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08834">Physical Informed Neural Networks for modeling ocean pollutant</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional numerical methods often struggle with the complexity and scale of modeling pollutant transport across vast and dynamic oceanic domains. This paper introduces a Physics-Informed Neural Network (PINN) framework to simulate the dispersion of pollutants governed by the 2D advection-diffusion equation. The model achieves physically consistent predictions by embedding physical laws and fitting to noisy synthetic data, generated via a finite difference method (FDM), directly into the neural network training process. This approach addresses challenges such as non-linear dynamics and the enforcement of boundary and initial conditions. Synthetic data sets, augmented with varying noise levels, are used to capture real-world variability. The training incorporates a hybrid loss function including PDE residuals, boundary/initial condition conformity, and a weighted data fit term. The approach takes advantage of the Julia language scientific computing ecosystem for high-performance simulations, offering a scalable and flexible alternative to traditional solvers
<div id='section'>Paperid: <span id='pid'>201, <a href='https://arxiv.org/pdf/2507.07143.pdf' target='_blank'>https://arxiv.org/pdf/2507.07143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karthik Pappu, Prathamesh Dinesh Joshi, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07143">Understanding Malware Propagation Dynamics through Scientific Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately modeling malware propagation is essential for designing effective cybersecurity defenses, particularly against adaptive threats that evolve in real time. While traditional epidemiological models and recent neural approaches offer useful foundations, they often fail to fully capture the nonlinear feedback mechanisms present in real-world networks. In this work, we apply scientific machine learning to malware modeling by evaluating three approaches: classical Ordinary Differential Equations (ODEs), Universal Differential Equations (UDEs), and Neural ODEs. Using data from the Code Red worm outbreak, we show that the UDE approach substantially reduces prediction error compared to both traditional and neural baselines by 44%, while preserving interpretability. We introduce a symbolic recovery method that transforms the learned neural feedback into explicit mathematical expressions, revealing suppression mechanisms such as network saturation, security response, and malware variant evolution. Our results demonstrate that hybrid physics-informed models can outperform both purely analytical and purely neural approaches, offering improved predictive accuracy and deeper insight into the dynamics of malware spread. These findings support the development of early warning systems, efficient outbreak response strategies, and targeted cyber defense interventions.
<div id='section'>Paperid: <span id='pid'>202, <a href='https://arxiv.org/pdf/2503.00908.pdf' target='_blank'>https://arxiv.org/pdf/2503.00908.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyuan Yang, Yingyu Chen, Zhiwen Wang, Hongming Shan, Yang Chen, Yi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00908">Patient-Level Anatomy Meets Scanning-Level Physics: Personalized Federated Low-Dose CT Denoising Empowered by Large Language Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reducing radiation doses benefits patients, however, the resultant low-dose computed tomography (LDCT) images often suffer from clinically unacceptable noise and artifacts. While deep learning (DL) shows promise in LDCT reconstruction, it requires large-scale data collection from multiple clients, raising privacy concerns. Federated learning (FL) has been introduced to address these privacy concerns; however, current methods are typically tailored to specific scanning protocols, which limits their generalizability and makes them less effective for unseen protocols. To address these issues, we propose SCAN-PhysFed, a novel SCanning- and ANatomy-level personalized Physics-Driven Federated learning paradigm for LDCT reconstruction. Since the noise distribution in LDCT data is closely tied to scanning protocols and anatomical structures being scanned, we design a dual-level physics-informed way to address these challenges. Specifically, we incorporate physical and anatomical prompts into our physics-informed hypernetworks to capture scanning- and anatomy-specific information, enabling dual-level physics-driven personalization of imaging features. These prompts are derived from the scanning protocol and the radiology report generated by a medical large language model (MLLM), respectively. Subsequently, client-specific decoders project these dual-level personalized imaging features back into the image domain. Besides, to tackle the challenge of unseen data, we introduce a novel protocol vector-quantization strategy (PVQS), which ensures consistent performance across new clients by quantifying the unseen scanning code as one of the codes in the scanning codebook. Extensive experimental results demonstrate the superior performance of SCAN-PhysFed on public datasets.
<div id='section'>Paperid: <span id='pid'>203, <a href='https://arxiv.org/pdf/2410.06452.pdf' target='_blank'>https://arxiv.org/pdf/2410.06452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sameera S Kashyap, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06452">Modeling chaotic Lorenz ODE System using Scientific Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In climate science, models for global warming and weather prediction face significant challenges due to the limited availability of high-quality data and the difficulty in obtaining it, making data efficiency crucial. In the past few years, Scientific Machine Learning (SciML) models have gained tremendous traction as they can be trained in a data-efficient manner, making them highly suitable for real-world climate applications. Despite this, very little attention has been paid to chaotic climate system modeling utilizing SciML methods. In this paper, we have integrated SciML methods into foundational weather models, where we have enhanced large-scale climate predictions with a physics-informed approach that achieves high accuracy with reduced data. We successfully demonstrate that by combining the interpretability of physical climate models with the computational power of neural networks, SciML models can prove to be a reliable tool for modeling climate. This indicates a shift from the traditional black box-based machine learning modeling of climate systems to physics-informed decision-making, leading to effective climate policy implementation.
<div id='section'>Paperid: <span id='pid'>204, <a href='https://arxiv.org/pdf/2408.15408.pdf' target='_blank'>https://arxiv.org/pdf/2408.15408.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad S. Khorrami, Pawan Goyal, Jaber R. Mianroodi, Bob Svendsen, Peter Benner, Dierk Raabe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15408">A physics-encoded Fourier neural operator approach for surrogate modeling of divergence-free stress fields in solids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The purpose of the current work is the development of a so-called physics-encoded Fourier neural operator (PeFNO) for surrogate modeling of the quasi-static equilibrium stress field in solids. Rather than accounting for constraints from physics in the loss function as done in the (now standard) physics-informed approach, the physics-encoded approach incorporates or "encodes" such constraints directly into the network or operator architecture. As a result, in contrast to the physics-informed approach in which only training is physically constrained, both training and output are physically constrained in the physics-encoded approach. For the current constraint of divergence-free stress, a novel encoding approach based on a stress potential is proposed.
  As a "proof-of-concept" example application of the proposed PeFNO, a heterogeneous polycrystalline material consisting of isotropic elastic grains subject to uniaxial extension is considered. Stress field data for training are obtained from the numerical solution of a corresponding boundary-value problem for quasi-static mechanical equilibrium. This data is also employed to train an analogous physics-guided FNO (PgFNO) and physics-informed FNO (PiFNO) for comparison. As confirmed by this comparison and as expected on the basis of their differences, the output of the trained PeFNO is significantly more accurate in satisfying mechanical equilibrium than the output of either the trained PgFNO or the trained PiFNO.
<div id='section'>Paperid: <span id='pid'>205, <a href='https://arxiv.org/pdf/2407.03292.pdf' target='_blank'>https://arxiv.org/pdf/2407.03292.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Min, Zachary M. C. Baum, Shaheer U. Saeed, Mark Emberton, Dean C. Barratt, Zeike A. Taylor, Yipeng Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03292">Biomechanics-informed Non-rigid Medical Image Registration and its Inverse Material Property Estimation with Linear and Nonlinear Elasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates both biomechanical-constrained non-rigid medical image registrations and accurate identifications of material properties for soft tissues, using physics-informed neural networks (PINNs). The complex nonlinear elasticity theory is leveraged to formally establish the partial differential equations (PDEs) representing physics laws of biomechanical constraints that need to be satisfied, with which registration and identification tasks are treated as forward (i.e., data-driven solutions of PDEs) and inverse (i.e., parameter estimation) problems under PINNs respectively. Two net configurations (i.e., Cfg1 and Cfg2) have also been compared for both linear and nonlinear physics model. Two sets of experiments have been conducted, using pairs of undeformed and deformed MR images from clinical cases of prostate cancer biopsy.
  Our contributions are summarised as follows. 1) We developed a learning-based biomechanical-constrained non-rigid registration algorithm using PINNs, where linear elasticity is generalised to the nonlinear version. 2) We demonstrated extensively that nonlinear elasticity shows no statistical significance against linear models in computing point-wise displacement vectors but their respective benefits may depend on specific patients, with finite-element (FE) computed ground-truth. 3) We formulated and solved the inverse parameter estimation problem, under the joint optimisation scheme of registration and parameter identification using PINNs, whose solutions can be accurately found by locating saddle points.
<div id='section'>Paperid: <span id='pid'>206, <a href='https://arxiv.org/pdf/2401.14580.pdf' target='_blank'>https://arxiv.org/pdf/2401.14580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dai Shi, Andi Han, Lequan Lin, Yi Guo, Zhiyong Wang, Junbin Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.14580">Design Your Own Universe: A Physics-Informed Agnostic Method for Enhancing Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Graph Neural Networks have achieved remarkable performance in learning through graph-structured data by mitigating common GNN challenges such as over-smoothing, over-squashing, and heterophily adaption. Despite these advancements, the development of a simple yet effective paradigm that appropriately integrates previous methods for handling all these challenges is still underway. In this paper, we draw an analogy between the propagation of GNNs and particle systems in physics, proposing a model-agnostic enhancement framework. This framework enriches the graph structure by introducing additional nodes and rewiring connections with both positive and negative weights, guided by node labeling information. We theoretically verify that GNNs enhanced through our approach can effectively circumvent the over-smoothing issue and exhibit robustness against over-squashing. Moreover, we conduct a spectral analysis on the rewired graph to demonstrate that the corresponding GNNs can fit both homophilic and heterophilic graphs. Empirical validations on benchmarks for homophilic, heterophilic graphs, and long-term graph datasets show that GNNs enhanced by our method significantly outperform their original counterparts.
<div id='section'>Paperid: <span id='pid'>207, <a href='https://arxiv.org/pdf/2309.02769.pdf' target='_blank'>https://arxiv.org/pdf/2309.02769.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiqi Shao, Dai Shi, Andi Han, Yi Guo, Qibin Zhao, Junbin Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02769">Unifying over-smoothing and over-squashing in graph neural networks: A physics informed approach and beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) have emerged as one of the leading approaches for machine learning on graph-structured data. Despite their great success, critical computational challenges such as over-smoothing, over-squashing, and limited expressive power continue to impact the performance of GNNs. In this study, inspired from the time-reversal principle commonly utilized in classical and quantum physics, we reverse the time direction of the graph heat equation. The resulted reversing process yields a class of high pass filtering functions that enhance the sharpness of graph node features. Leveraging this concept, we introduce the Multi-Scaled Heat Kernel based GNN (MHKG) by amalgamating diverse filtering functions' effects on node features. To explore more flexible filtering conditions, we further generalize MHKG into a model termed G-MHKG and thoroughly show the roles of each element in controlling over-smoothing, over-squashing and expressive power. Notably, we illustrate that all aforementioned issues can be characterized and analyzed via the properties of the filtering functions, and uncover a trade-off between over-smoothing and over-squashing: enhancing node feature sharpness will make model suffer more from over-squashing, and vice versa. Furthermore, we manipulate the time again to show how G-MHKG can handle both two issues under mild conditions. Our conclusive experiments highlight the effectiveness of proposed models. It surpasses several GNN baseline models in performance across graph datasets characterized by both homophily and heterophily.
<div id='section'>Paperid: <span id='pid'>208, <a href='https://arxiv.org/pdf/2302.10343.pdf' target='_blank'>https://arxiv.org/pdf/2302.10343.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Min, Zachary M. C. Baum, Shaheer U. Saeed, Mark Emberton, Dean C. Barratt, Zeike A. Taylor, Yipeng Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10343">Non-rigid Medical Image Registration using Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biomechanical modelling of soft tissue provides a non-data-driven method for constraining medical image registration, such that the estimated spatial transformation is considered biophysically plausible. This has not only been adopted in real-world clinical applications, such as the MR-to-ultrasound registration for prostate intervention of interest in this work, but also provides an explainable means of understanding the organ motion and spatial correspondence establishment. This work instantiates the recently-proposed physics-informed neural networks (PINNs) to a 3D linear elastic model for modelling prostate motion commonly encountered during transrectal ultrasound guided procedures. To overcome a widely-recognised challenge in generalising PINNs to different subjects, we propose to use PointNet as the nodal-permutation-invariant feature extractor, together with a registration algorithm that aligns point sets and simultaneously takes into account the PINN-imposed biomechanics. The proposed method has been both developed and validated in both patient-specific and multi-patient manner.
<div id='section'>Paperid: <span id='pid'>209, <a href='https://arxiv.org/pdf/2509.23960.pdf' target='_blank'>https://arxiv.org/pdf/2509.23960.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manan Tayal, Aditya Singh, Shishir Kolathaya, Somil Bansal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.23960">MAD-PINN: A Decentralized Physics-Informed Machine Learning Framework for Safe and Optimal Multi-Agent Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Co-optimizing safety and performance in large-scale multi-agent systems remains a fundamental challenge. Existing approaches based on multi-agent reinforcement learning (MARL), safety filtering, or Model Predictive Control (MPC) either lack strict safety guarantees, suffer from conservatism, or fail to scale effectively. We propose MAD-PINN, a decentralized physics-informed machine learning framework for solving the multi-agent state-constrained optimal control problem (MASC-OCP). Our method leverages an epigraph-based reformulation of SC-OCP to simultaneously capture performance and safety, and approximates its solution via a physics-informed neural network. Scalability is achieved by training the SC-OCP value function on reduced-agent systems and deploying them in a decentralized fashion, where each agent relies only on local observations of its neighbours for decision-making. To further enhance safety and efficiency, we introduce an Hamilton-Jacobi (HJ) reachability-based neighbour selection strategy to prioritize safety-critical interactions, and a receding-horizon policy execution scheme that adapts to dynamic interactions while reducing computational burden. Experiments on multi-agent navigation tasks demonstrate that MAD-PINN achieves superior safety-performance trade-offs, maintains scalability as the number of agents grows, and consistently outperforms state-of-the-art baselines.
<div id='section'>Paperid: <span id='pid'>210, <a href='https://arxiv.org/pdf/2506.18295.pdf' target='_blank'>https://arxiv.org/pdf/2506.18295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kejia Bian, Meixia Tao, Shu Sun, Jun Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18295">GeNeRT: A Physics-Informed Approach to Intelligent Wireless Channel Modeling via Generalizable Neural Ray Tracing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural ray tracing (RT) has emerged as a promising paradigm for channel modeling by combining physical propagation principles with neural networks. It enables high modeling accuracy and efficiency. However, current neural RT methods face two key limitations: constrained generalization capability due to strong spatial dependence, and weak adherence to electromagnetic laws. In this paper, we propose GeNeRT, a Generalizable Neural RT framework with enhanced generalization, accuracy and efficiency. GeNeRT supports both intra-scenario spatial transferability and inter-scenario zero-shot generalization. By incorporating Fresnel-inspired neural network design, it also achieves higher accuracy in multipath component (MPC) prediction. Furthermore, a GPU-tensorized acceleration strategy is introduced to improve runtime efficiency. Extensive experiments conducted in outdoor scenarios demonstrate that GeNeRT generalizes well across untrained regions within a scenario and entirely unseen environments, and achieves superior accuracy in MPC prediction compared to baselines. Moreover, it outperforms Wireless Insite in runtime efficiency, particularly in multi-transmitter settings. Ablation experiments validate the effectiveness of the network architecture and training strategy in capturing physical principles of ray-surface interactions.
<div id='section'>Paperid: <span id='pid'>211, <a href='https://arxiv.org/pdf/2506.09100.pdf' target='_blank'>https://arxiv.org/pdf/2506.09100.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haonan Zhang, Guoyan Lao, Yuyao Zhang, Hongjiang Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09100">Low-Rank Augmented Implicit Neural Representation for Unsupervised High-Dimensional Quantitative MRI Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantitative magnetic resonance imaging (qMRI) provides tissue-specific parameters vital for clinical diagnosis. Although simultaneous multi-parametric qMRI (MP-qMRI) technologies enhance imaging efficiency, robustly reconstructing qMRI from highly undersampled, high-dimensional measurements remains a significant challenge. This difficulty arises primarily because current reconstruction methods that rely solely on a single prior or physics-informed model to solve the highly ill-posed inverse problem, which often leads to suboptimal results. To overcome this limitation, we propose LoREIN, a novel unsupervised and dual-prior-integrated framework for accelerated 3D MP-qMRI reconstruction. Technically, LoREIN incorporates both low-rank prior and continuity prior via low-rank representation (LRR) and implicit neural representation (INR), respectively, to enhance reconstruction fidelity. The powerful continuous representation of INR enables the estimation of optimal spatial bases within the low-rank subspace, facilitating high-fidelity reconstruction of weighted images. Simultaneously, the predicted multi-contrast weighted images provide essential structural and quantitative guidance, further enhancing the reconstruction accuracy of quantitative parameter maps. Furthermore, our work introduces a zero-shot learning paradigm with broad potential in complex spatiotemporal and high-dimensional image reconstruction tasks, further advancing the field of medical imaging.
<div id='section'>Paperid: <span id='pid'>212, <a href='https://arxiv.org/pdf/2505.14555.pdf' target='_blank'>https://arxiv.org/pdf/2505.14555.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingtao Luo, Shikai Fang, Binqing Wu, Qingsong Wen, Liang Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14555">Physics-Guided Learning of Meteorological Dynamics for Weather Downscaling and Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Weather forecasting is essential but remains computationally intensive and physically incomplete in traditional numerical weather prediction (NWP) methods. Deep learning (DL) models offer efficiency and accuracy but often ignore physical laws, limiting interpretability and generalization. We propose PhyDL-NWP, a physics-guided deep learning framework that integrates physical equations with latent force parameterization into data-driven models. It predicts weather variables from arbitrary spatiotemporal coordinates, computes physical terms via automatic differentiation, and uses a physics-informed loss to align predictions with governing dynamics. PhyDL-NWP enables resolution-free downscaling by modeling weather as a continuous function and fine-tunes pre-trained models with minimal overhead, achieving up to 170x faster inference with only 55K parameters. Experiments show that PhyDL-NWP improves both forecasting performance and physical consistency.
<div id='section'>Paperid: <span id='pid'>213, <a href='https://arxiv.org/pdf/2505.10949.pdf' target='_blank'>https://arxiv.org/pdf/2505.10949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhui Xu, Dancheng Liu, Amir Nassereldine, Jinjun Xiong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.10949">FP64 is All You Need: Rethinking Failure Modes in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics Informed Neural Networks (PINNs) often exhibit failure modes in which the PDE residual loss converges while the solution error stays large, a phenomenon traditionally blamed on local optima separated from the true solution by steep loss barriers. We challenge this understanding by demonstrate that the real culprit is insufficient arithmetic precision: with standard FP32, the LBFGS optimizer prematurely satisfies its convergence test, freezing the network in a spurious failure phase. Simply upgrading to FP64 rescues optimization, enabling vanilla PINNs to solve PDEs without any failure modes. These results reframe PINN failure modes as precision induced stalls rather than inescapable local minima and expose a three stage training dynamic unconverged, failure, success whose boundaries shift with numerical precision. Our findings emphasize that rigorous arithmetic precision is the key to dependable PDE solving with neural networks.
<div id='section'>Paperid: <span id='pid'>214, <a href='https://arxiv.org/pdf/2505.08123.pdf' target='_blank'>https://arxiv.org/pdf/2505.08123.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qing Wu, Hongjiang Wei, Jingyi Yu, S. Kevin Zhou, Yuyao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08123">JSover: Joint Spectrum Estimation and Multi-Material Decomposition from Single-Energy CT Projections</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-material decomposition (MMD) enables quantitative reconstruction of tissue compositions in the human body, supporting a wide range of clinical applications. However, traditional MMD typically requires spectral CT scanners and pre-measured X-ray energy spectra, significantly limiting clinical applicability. To this end, various methods have been developed to perform MMD using conventional (i.e., single-energy, SE) CT systems, commonly referred to as SEMMD. Despite promising progress, most SEMMD methods follow a two-step image decomposition pipeline, which first reconstructs monochromatic CT images using algorithms such as FBP, and then performs decomposition on these images. The initial reconstruction step, however, neglects the energy-dependent attenuation of human tissues, introducing severe nonlinear beam hardening artifacts and noise into the subsequent decomposition. This paper proposes JSover, a fundamentally reformulated one-step SEMMD framework that jointly reconstructs multi-material compositions and estimates the energy spectrum directly from SECT projections. By explicitly incorporating physics-informed spectral priors into the SEMMD process, JSover accurately simulates a virtual spectral CT system from SE acquisitions, thereby improving the reliability and accuracy of decomposition. Furthermore, we introduce implicit neural representation (INR) as an unsupervised deep learning solver for representing the underlying material maps. The inductive bias of INR toward continuous image patterns constrains the solution space and further enhances estimation quality. Extensive experiments on both simulated and real CT datasets show that JSover outperforms state-of-the-art SEMMD methods in accuracy and computational efficiency.
<div id='section'>Paperid: <span id='pid'>215, <a href='https://arxiv.org/pdf/2504.11045.pdf' target='_blank'>https://arxiv.org/pdf/2504.11045.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shreenabh Agrawal, Manan Tayal, Aditya Singh, Shishir Kolathaya
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11045">Neural Control Barrier Functions from Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As autonomous systems become increasingly prevalent in daily life, ensuring their safety is paramount. Control Barrier Functions (CBFs) have emerged as an effective tool for guaranteeing safety; however, manually designing them for specific applications remains a significant challenge. With the advent of deep learning techniques, recent research has explored synthesizing CBFs using neural networks-commonly referred to as neural CBFs. This paper introduces a novel class of neural CBFs that leverages a physics-inspired neural network framework by incorporating Zubov's Partial Differential Equation (PDE) within the context of safety. This approach provides a scalable methodology for synthesizing neural CBFs applicable to high-dimensional systems. Furthermore, by utilizing reciprocal CBFs instead of zeroing CBFs, the proposed framework allows for the specification of flexible, user-defined safe regions. To validate the effectiveness of the approach, we present case studies on three different systems: an inverted pendulum, autonomous ground navigation, and aerial navigation in obstacle-laden environments.
<div id='section'>Paperid: <span id='pid'>216, <a href='https://arxiv.org/pdf/2504.04052.pdf' target='_blank'>https://arxiv.org/pdf/2504.04052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youn-Yeol Yu, Jeongwhan Choi, Jaehyeon Park, Kookjin Lee, Noseong Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04052">PIORF: Physics-Informed Ollivier-Ricci Flow for Long-Range Interactions in Mesh Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, data-driven simulators based on graph neural networks have gained attention in modeling physical systems on unstructured meshes. However, they struggle with long-range dependencies in fluid flows, particularly in refined mesh regions. This challenge, known as the 'over-squashing' problem, hinders information propagation. While existing graph rewiring methods address this issue to some extent, they only consider graph topology, overlooking the underlying physical phenomena. We propose Physics-Informed Ollivier-Ricci Flow (PIORF), a novel rewiring method that combines physical correlations with graph topology. PIORF uses Ollivier-Ricci curvature (ORC) to identify bottleneck regions and connects these areas with nodes in high-velocity gradient nodes, enabling long-range interactions and mitigating over-squashing. Our approach is computationally efficient in rewiring edges and can scale to larger simulations. Experimental results on 3 fluid dynamics benchmark datasets show that PIORF consistently outperforms baseline models and existing rewiring methods, achieving up to 26.2 improvement.
<div id='section'>Paperid: <span id='pid'>217, <a href='https://arxiv.org/pdf/2503.11029.pdf' target='_blank'>https://arxiv.org/pdf/2503.11029.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weiye Gan, Yicheng Li, Qian Lin, Zuoqiang Shi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.11029">Neural Tangent Kernel of Neural Networks with Loss Informed by Differential Operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spectral bias is a significant phenomenon in neural network training and can be explained by neural tangent kernel (NTK) theory. In this work, we develop the NTK theory for deep neural networks with physics-informed loss, providing insights into the convergence of NTK during initialization and training, and revealing its explicit structure. We find that, in most cases, the differential operators in the loss function do not induce a faster eigenvalue decay rate and stronger spectral bias. Some experimental results are also presented to verify the theory.
<div id='section'>Paperid: <span id='pid'>218, <a href='https://arxiv.org/pdf/2502.11057.pdf' target='_blank'>https://arxiv.org/pdf/2502.11057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manan Tayal, Aditya Singh, Shishir Kolathaya, Somil Bansal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11057">A Physics-Informed Machine Learning Framework for Safe and Optimal Control of Autonomous Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As autonomous systems become more ubiquitous in daily life, ensuring high performance with guaranteed safety is crucial. However, safety and performance could be competing objectives, which makes their co-optimization difficult. Learning-based methods, such as Constrained Reinforcement Learning (CRL), achieve strong performance but lack formal safety guarantees due to safety being enforced as soft constraints, limiting their use in safety-critical settings. Conversely, formal methods such as Hamilton-Jacobi (HJ) Reachability Analysis and Control Barrier Functions (CBFs) provide rigorous safety assurances but often neglect performance, resulting in overly conservative controllers. To bridge this gap, we formulate the co-optimization of safety and performance as a state-constrained optimal control problem, where performance objectives are encoded via a cost function and safety requirements are imposed as state constraints. We demonstrate that the resultant value function satisfies a Hamilton-Jacobi-Bellman (HJB) equation, which we approximate efficiently using a novel physics-informed machine learning framework. In addition, we introduce a conformal prediction-based verification strategy to quantify the learning errors, recovering a high-confidence safety value function, along with a probabilistic error bound on performance degradation. Through several case studies, we demonstrate the efficacy of the proposed framework in enabling scalable learning of safe and performant controllers for complex, high-dimensional autonomous systems.
<div id='section'>Paperid: <span id='pid'>219, <a href='https://arxiv.org/pdf/2411.06651.pdf' target='_blank'>https://arxiv.org/pdf/2411.06651.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rafael Orozco, Huseyin Tuna Erdinc, Yunlin Zeng, Mathias Louboutin, Felix J. Herrmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.06651">Machine learning-enabled velocity model building with uncertainty quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately characterizing migration velocity models is crucial for a wide range of geophysical applications, from hydrocarbon exploration to monitoring of CO2 sequestration projects. Traditional velocity model building methods such as Full-Waveform Inversion (FWI) are powerful but often struggle with the inherent complexities of the inverse problem, including noise, limited bandwidth, receiver aperture and computational constraints. To address these challenges, we propose a scalable methodology that integrates generative modeling, in the form of Diffusion networks, with physics-informed summary statistics, making it suitable for complicated imaging problems including field datasets. By defining these summary statistics in terms of subsurface-offset image volumes for poor initial velocity models, our approach allows for computationally efficient generation of Bayesian posterior samples for migration velocity models that offer a useful assessment of uncertainty. To validate our approach, we introduce a battery of tests that measure the quality of the inferred velocity models, as well as the quality of the inferred uncertainties. With modern synthetic datasets, we reconfirm gains from using subsurface-image gathers as the conditioning observable. For complex velocity model building involving salt, we propose a new iterative workflow that refines amortized posterior approximations with salt flooding and demonstrate how the uncertainty in the velocity model can be propagated to the final product reverse time migrated images. Finally, we present a proof of concept on field datasets to show that our method can scale to industry-sized problems.
<div id='section'>Paperid: <span id='pid'>220, <a href='https://arxiv.org/pdf/2405.00316.pdf' target='_blank'>https://arxiv.org/pdf/2405.00316.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Zhou, Haichao Liu, Hongliang Lu, Dan Xu, Jun Ma, Yiding Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.00316">Enhance Planning with Physics-informed Safety Controller for End-to-end Autonomous Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent years have seen a growing research interest in applications of Deep Neural Networks (DNN) on autonomous vehicle technology. The trend started with perception and prediction a few years ago and it is gradually being applied to motion planning tasks. Despite the performance of networks improve over time, DNN planners inherit the natural drawbacks of Deep Learning. Learning-based planners have limitations in achieving perfect accuracy on the training dataset and network performance can be affected by out-of-distribution problem. In this paper, we propose FusionAssurance, a novel trajectory-based end-to-end driving fusion framework which combines physics-informed control for safety assurance. By incorporating Potential Field into Model Predictive Control, FusionAssurance is capable of navigating through scenarios that are not included in the training dataset and scenarios where neural network fail to generalize. The effectiveness of the approach is demonstrated by extensive experiments under various scenarios on the CARLA benchmark.
<div id='section'>Paperid: <span id='pid'>221, <a href='https://arxiv.org/pdf/2401.06230.pdf' target='_blank'>https://arxiv.org/pdf/2401.06230.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyi Yin, Rafael Orozco, Mathias Louboutin, Felix J. Herrmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.06230">WISE: full-Waveform variational Inference via Subsurface Extensions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a probabilistic technique for full-waveform inversion, employing variational inference and conditional normalizing flows to quantify uncertainty in migration-velocity models and its impact on imaging. Our approach integrates generative artificial intelligence with physics-informed common-image gathers, reducing reliance on accurate initial velocity models. Considered case studies demonstrate its efficacy producing realizations of migration-velocity models conditioned by the data. These models are used to quantify amplitude and positioning effects during subsequent imaging.
<div id='section'>Paperid: <span id='pid'>222, <a href='https://arxiv.org/pdf/2311.02124.pdf' target='_blank'>https://arxiv.org/pdf/2311.02124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuyan Ni, Shikun Feng, Wei-Ying Ma, Zhi-Ming Ma, Yanyan Lan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.02124">Sliced Denoising: A Physics-Informed Molecular Pre-Training Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While molecular pre-training has shown great potential in enhancing drug discovery, the lack of a solid physical interpretation in current methods raises concerns about whether the learned representation truly captures the underlying explanatory factors in observed data, ultimately resulting in limited generalization and robustness. Although denoising methods offer a physical interpretation, their accuracy is often compromised by ad-hoc noise design, leading to inaccurate learned force fields. To address this limitation, this paper proposes a new method for molecular pre-training, called sliced denoising (SliDe), which is based on the classical mechanical intramolecular potential theory. SliDe utilizes a novel noise strategy that perturbs bond lengths, angles, and torsion angles to achieve better sampling over conformations. Additionally, it introduces a random slicing approach that circumvents the computationally expensive calculation of the Jacobian matrix, which is otherwise essential for estimating the force field. By aligning with physical principles, SliDe shows a 42\% improvement in the accuracy of estimated force fields compared to current state-of-the-art denoising methods, and thus outperforms traditional baselines on various molecular property prediction tasks.
<div id='section'>Paperid: <span id='pid'>223, <a href='https://arxiv.org/pdf/2306.13867.pdf' target='_blank'>https://arxiv.org/pdf/2306.13867.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Truong X. Nghiem, JÃ¡n DrgoÅa, Colin Jones, Zoltan Nagy, Roland Schwan, Biswadip Dey, Ankush Chakrabarty, Stefano Di Cairano, Joel A. Paulson, Andrea Carron, Melanie N. Zeilinger, Wenceslao Shaw Cortez, Draguna L. Vrabie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13867">Physics-Informed Machine Learning for Modeling and Control of Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning (PIML) is a set of methods and tools that systematically integrate machine learning (ML) algorithms with physical constraints and abstract mathematical models developed in scientific and engineering domains. As opposed to purely data-driven methods, PIML models can be trained from additional information obtained by enforcing physical laws such as energy and mass conservation. More broadly, PIML models can include abstract properties and conditions such as stability, convexity, or invariance. The basic premise of PIML is that the integration of ML and physics can yield more effective, physically consistent, and data-efficient models. This paper aims to provide a tutorial-like overview of the recent advances in PIML for dynamical system modeling and control. Specifically, the paper covers an overview of the theory, fundamental concepts and methods, tools, and applications on topics of: 1) physics-informed learning for system identification; 2) physics-informed learning for control; 3) analysis and verification of PIML models; and 4) physics-informed digital twins. The paper is concluded with a perspective on open challenges and future research opportunities.
<div id='section'>Paperid: <span id='pid'>224, <a href='https://arxiv.org/pdf/2206.06577.pdf' target='_blank'>https://arxiv.org/pdf/2206.06577.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengyu Chu, Lingjie Liu, Quan Zheng, Aleksandra Franz, Hans-Peter Seidel, Christian Theobalt, Rhaleb Zayer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.06577">Physics Informed Neural Fields for Smoke Reconstruction with Sparse Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-fidelity reconstruction of fluids from sparse multiview RGB videos remains a formidable challenge due to the complexity of the underlying physics as well as complex occlusion and lighting in captures. Existing solutions either assume knowledge of obstacles and lighting, or only focus on simple fluid scenes without obstacles or complex lighting, and thus are unsuitable for real-world scenes with unknown lighting or arbitrary obstacles. We present the first method to reconstruct dynamic fluid by leveraging the governing physics (ie, Navier -Stokes equations) in an end-to-end optimization from sparse videos without taking lighting conditions, geometry information, or boundary conditions as input. We provide a continuous spatio-temporal scene representation using neural networks as the ansatz of density and velocity solution functions for fluids as well as the radiance field for static objects. With a hybrid architecture that separates static and dynamic contents, fluid interactions with static obstacles are reconstructed for the first time without additional geometry input or human labeling. By augmenting time-varying neural radiance fields with physics-informed deep learning, our method benefits from the supervision of images and physical priors. To achieve robust optimization from sparse views, we introduced a layer-by-layer growing strategy to progressively increase the network capacity. Using progressively growing models with a new regularization term, we manage to disentangle density-color ambiguity in radiance fields without overfitting. A pretrained density-to-velocity fluid model is leveraged in addition as the data prior to avoid suboptimal velocity which underestimates vorticity but trivially fulfills physical equations. Our method exhibits high-quality results with relaxed constraints and strong flexibility on a representative set of synthetic and real flow captures.
<div id='section'>Paperid: <span id='pid'>225, <a href='https://arxiv.org/pdf/2110.13530.pdf' target='_blank'>https://arxiv.org/pdf/2110.13530.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicola Demo, Maria Strazzullo, Gianluigi Rozza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.13530">An extended physics informed neural network for preliminary analysis of parametric optimal control problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work we propose an extension of physics informed supervised learning strategies to parametric partial differential equations. Indeed, even if the latter are indisputably useful in many applications, they can be computationally expensive most of all in a real-time and many-query setting. Thus, our main goal is to provide a physics informed learning paradigm to simulate parametrized phenomena in a small amount of time. The physics information will be exploited in many ways, in the loss function (standard physics informed neural networks), as an augmented input (extra feature employment) and as a guideline to build an effective structure for the neural network (physics informed architecture). These three aspects, combined together, will lead to a faster training phase and to a more accurate parametric prediction. The methodology has been tested for several equations and also in an optimal control framework.
<div id='section'>Paperid: <span id='pid'>226, <a href='https://arxiv.org/pdf/2509.20570.pdf' target='_blank'>https://arxiv.org/pdf/2509.20570.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingze Yuan, Pengfei Jin, Na Li, Quanzheng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.20570">PIRF: Physics-Informed Reward Fine-Tuning for Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have demonstrated strong generative capabilities across scientific domains, but often produce outputs that violate physical laws. We propose a new perspective by framing physics-informed generation as a sparse reward optimization problem, where adherence to physical constraints is treated as a reward signal. This formulation unifies prior approaches under a reward-based paradigm and reveals a shared bottleneck: reliance on diffusion posterior sampling (DPS)-style value function approximations, which introduce non-negligible errors and lead to training instability and inference inefficiency. To overcome this, we introduce Physics-Informed Reward Fine-tuning (PIRF), a method that bypasses value approximation by computing trajectory-level rewards and backpropagating their gradients directly. However, a naive implementation suffers from low sample efficiency and compromised data fidelity. PIRF mitigates these issues through two key strategies: (1) a layer-wise truncated backpropagation method that leverages the spatiotemporally localized nature of physics-based rewards, and (2) a weight-based regularization scheme that improves efficiency over traditional distillation-based methods. Across five PDE benchmarks, PIRF consistently achieves superior physical enforcement under efficient sampling regimes, highlighting the potential of reward fine-tuning for advancing scientific generative modeling.
<div id='section'>Paperid: <span id='pid'>227, <a href='https://arxiv.org/pdf/2509.17293.pdf' target='_blank'>https://arxiv.org/pdf/2509.17293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ryan Chappell, Chayan Banerjee, Kien Nguyen, Clinton Fookes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17293">Physics-Informed Operator Learning for Hemodynamic Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate modeling of personalized cardiovascular dynamics is crucial for non-invasive monitoring and therapy planning. State-of-the-art physics-informed neural network (PINN) approaches employ deep, multi-branch architectures with adversarial or contrastive objectives to enforce partial differential equation constraints. While effective, these enhancements introduce significant training and implementation complexity, limiting scalability and practical deployment. We investigate physics-informed neural operator learning models as efficient supervisory signals for training simplified architectures through knowledge distillation. Our approach pre-trains a physics-informed DeepONet (PI-DeepONet) on high-fidelity cuffless blood pressure recordings to learn operator mappings from raw wearable waveforms to beat-to-beat pressure signals under embedded physics constraints. This pre-trained operator serves as a frozen supervisor in a lightweight knowledge-distillation pipeline, guiding streamlined base models that eliminate complex adversarial and contrastive learning components while maintaining performance. We characterize the role of physics-informed regularization in operator learning and demonstrate its effectiveness for supervisory guidance. Through extensive experiments, our operator-supervised approach achieves performance parity with complex baselines (correlation: 0.766 vs. 0.770, RMSE: 4.452 vs. 4.501), while dramatically reducing architectural complexity from eight critical hyperparameters to a single regularization coefficient and decreasing training overhead by 4%. Our results demonstrate that operator-based supervision effectively replaces intricate multi-component training strategies, offering a more scalable and interpretable approach to physiological modeling with reduced implementation burden.
<div id='section'>Paperid: <span id='pid'>228, <a href='https://arxiv.org/pdf/2504.06242.pdf' target='_blank'>https://arxiv.org/pdf/2504.06242.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Brunke, Siqi Zhou, Francesco D'Orazio, Angela P. Schoellig
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.06242">Addressing Relative Degree Issues in Control Barrier Function Synthesis with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In robotics, control barrier function (CBF)-based safety filters are commonly used to enforce state constraints. A critical challenge arises when the relative degree of the CBF varies across the state space. This variability can create regions within the safe set where the control input becomes unconstrained. When implemented as a safety filter, this may result in chattering near the safety boundary and ultimately compromise system safety. To address this issue, we propose a novel approach for CBF synthesis by formulating it as solving a set of boundary value problems. The solutions to the boundary value problems are determined using physics-informed neural networks (PINNs). Our approach ensures that the synthesized CBFs maintain a constant relative degree across the set of admissible states, thereby preventing unconstrained control scenarios. We illustrate the approach in simulation and further verify it through real-world quadrotor experiments, demonstrating its effectiveness in preserving desired system safety properties.
<div id='section'>Paperid: <span id='pid'>229, <a href='https://arxiv.org/pdf/2503.07070.pdf' target='_blank'>https://arxiv.org/pdf/2503.07070.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Apivich Hemachandra, Gregory Kang Ruey Lau, See-Kiong Ng, Bryan Kian Hsiang Low
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07070">PIED: Physics-Informed Experimental Design for Inverse Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many science and engineering settings, system dynamics are characterized by governing PDEs, and a major challenge is to solve inverse problems (IPs) where unknown PDE parameters are inferred based on observational data gathered under limited budget. Due to the high costs of setting up and running experiments, experimental design (ED) is often done with the help of PDE simulations to optimize for the most informative design parameters to solve such IPs, prior to actual data collection. This process of optimizing design parameters is especially critical when the budget and other practical constraints make it infeasible to adjust the design parameters between trials during the experiments. However, existing experimental design (ED) methods tend to require sequential and frequent design parameter adjustments between trials. Furthermore, they also have significant computational bottlenecks due to the need for complex numerical simulations for PDEs, and do not exploit the advantages provided by physics informed neural networks (PINNs), such as its meshless solutions, differentiability, and amortized training. This work presents PIED, the first ED framework that makes use of PINNs in a fully differentiable architecture to perform continuous optimization of design parameters for IPs for one-shot deployments. PIED overcomes existing methods' computational bottlenecks through parallelized computation and meta-learning of PINN parameter initialization, and proposes novel methods to effectively take into account PINN training dynamics in optimizing the ED parameters. Through experiments based on noisy simulated data and even real world experimental data, we empirically show that given limited observation budget, PIED significantly outperforms existing ED methods in solving IPs, including challenging settings where the inverse parameters are unknown functions rather than just finite-dimensional.
<div id='section'>Paperid: <span id='pid'>230, <a href='https://arxiv.org/pdf/2503.06320.pdf' target='_blank'>https://arxiv.org/pdf/2503.06320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zongren Zou, Zhicheng Wang, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.06320">Learning and discovering multiple solutions using physics-informed neural networks with random initialization and deep ensemble</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We explore the capability of physics-informed neural networks (PINNs) to discover multiple solutions. Many real-world phenomena governed by nonlinear differential equations (DEs), such as fluid flow, exhibit multiple solutions under the same conditions, yet capturing this solution multiplicity remains a significant challenge. A key difficulty is giving appropriate initial conditions or initial guesses, to which the widely used time-marching schemes and Newton's iteration method are very sensitive in finding solutions for complex computational problems. While machine learning models, particularly PINNs, have shown promise in solving DEs, their ability to capture multiple solutions remains underexplored. In this work, we propose a simple and practical approach using PINNs to learn and discover multiple solutions. We first reveal that PINNs, when combined with random initialization and deep ensemble method -- originally developed for uncertainty quantification -- can effectively uncover multiple solutions to nonlinear ordinary and partial differential equations (ODEs/PDEs). Our approach highlights the critical role of initialization in shaping solution diversity, addressing an often-overlooked aspect of machine learning for scientific computing. Furthermore, we propose utilizing PINN-generated solutions as initial conditions or initial guesses for conventional numerical solvers to enhance accuracy and efficiency in capturing multiple solutions. Extensive numerical experiments, including the Allen-Cahn equation and cavity flow, where our approach successfully identifies both stable and unstable solutions, validate the effectiveness of our method. These findings establish a general and efficient framework for addressing solution multiplicity in nonlinear differential equations.
<div id='section'>Paperid: <span id='pid'>231, <a href='https://arxiv.org/pdf/2502.11382.pdf' target='_blank'>https://arxiv.org/pdf/2502.11382.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liqun Chen, Yuxuan Li, Jun Dai, Jinwei Gu, Tianfan Xue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11382">A Physics-Informed Blur Learning Framework for Imaging Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate blur estimation is essential for high-performance imaging across various applications. Blur is typically represented by the point spread function (PSF). In this paper, we propose a physics-informed PSF learning framework for imaging systems, consisting of a simple calibration followed by a learning process. Our framework could achieve both high accuracy and universal applicability. Inspired by the Seidel PSF model for representing spatially varying PSF, we identify its limitations in optimization and introduce a novel wavefront-based PSF model accompanied by an optimization strategy, both reducing optimization complexity and improving estimation accuracy. Moreover, our wavefront-based PSF model is independent of lens parameters, eliminate the need for prior knowledge of the lens. To validate our approach, we compare it with recent PSF estimation methods (Degradation Transfer and Fast Two-step) through a deblurring task, where all the estimated PSFs are used to train state-of-the-art deblurring algorithms. Our approach demonstrates improvements in image quality in simulation and also showcases noticeable visual quality improvements on real captured images.
<div id='section'>Paperid: <span id='pid'>232, <a href='https://arxiv.org/pdf/2502.04719.pdf' target='_blank'>https://arxiv.org/pdf/2502.04719.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Dai, Liqun Chen, Xinge Yang, Yuyao Hu, Jinwei Gu, Tianfan Xue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04719">Tolerance-Aware Deep Optics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep optics has emerged as a promising approach by co-designing optical elements with deep learning algorithms. However, current research typically overlooks the analysis and optimization of manufacturing and assembly tolerances. This oversight creates a significant performance gap between designed and fabricated optical systems. To address this challenge, we present the first end-to-end tolerance-aware optimization framework that incorporates multiple tolerance types into the deep optics design pipeline. Our method combines physics-informed modelling with data-driven training to enhance optical design by accounting for and compensating for structural deviations in manufacturing and assembly. We validate our approach through computational imaging applications, demonstrating results in both simulations and real-world experiments. We further examine how our proposed solution improves the robustness of optical systems and vision algorithms against tolerances through qualitative and quantitative analyses. Code and additional visual results are available at openimaginglab.github.io/LensTolerance.
<div id='section'>Paperid: <span id='pid'>233, <a href='https://arxiv.org/pdf/2410.13228.pdf' target='_blank'>https://arxiv.org/pdf/2410.13228.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan Diego Toscano, Vivek Oommen, Alan John Varghese, Zongren Zou, Nazanin Ahmadi Daryakenari, Chenxi Wu, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13228">From PINNs to PIKANs: Recent Advances in Physics-Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a key tool in Scientific Machine Learning since their introduction in 2017, enabling the efficient solution of ordinary and partial differential equations using sparse measurements. Over the past few years, significant advancements have been made in the training and optimization of PINNs, covering aspects such as network architectures, adaptive refinement, domain decomposition, and the use of adaptive weights and activation functions. A notable recent development is the Physics-Informed Kolmogorov-Arnold Networks (PIKANS), which leverage a representation model originally proposed by Kolmogorov in 1957, offering a promising alternative to traditional PINNs. In this review, we provide a comprehensive overview of the latest advancements in PINNs, focusing on improvements in network design, feature expansion, optimization techniques, uncertainty quantification, and theoretical insights. We also survey key applications across a range of fields, including biomedicine, fluid and solid mechanics, geophysics, dynamical systems, heat transfer, chemical engineering, and beyond. Finally, we review computational frameworks and software tools developed by both academia and industry to support PINN research and applications.
<div id='section'>Paperid: <span id='pid'>234, <a href='https://arxiv.org/pdf/2409.18423.pdf' target='_blank'>https://arxiv.org/pdf/2409.18423.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xu Liu, Wen Yao, Wei Peng, Zhuojia Fu, Zixue Xiang, Xiaoqian Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.18423">A physics-driven sensor placement optimization methodology for temperature field reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Perceiving the global field from sparse sensors has been a grand challenge in the monitoring, analysis, and design of physical systems. In this context, sensor placement optimization is a crucial issue. Most existing works require large and sufficient data to construct data-based criteria, which are intractable in data-free scenarios without numerical and experimental data. To this end, we propose a novel physics-driven sensor placement optimization (PSPO) method for temperature field reconstruction using a physics-based criterion to optimize sensor locations. In our methodological framework, we firstly derive the theoretical upper and lower bounds of the reconstruction error under noise scenarios by analyzing the optimal solution, proving that error bounds correlate with the condition number determined by sensor locations. Furthermore, the condition number, as the physics-based criterion, is used to optimize sensor locations by the genetic algorithm. Finally, the best sensors are validated by reconstruction models, including non-invasive end-to-end models, non-invasive reduced-order models, and physics-informed models. Experimental results, both on a numerical and an application case, demonstrate that the PSPO method significantly outperforms random and uniform selection methods, improving the reconstruction accuracy by nearly an order of magnitude. Moreover, the PSPO method can achieve comparable reconstruction accuracy to the existing data-driven placement optimization methods.
<div id='section'>Paperid: <span id='pid'>235, <a href='https://arxiv.org/pdf/2408.07201.pdf' target='_blank'>https://arxiv.org/pdf/2408.07201.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mario De Florio, Zongren Zou, Daniele E. Schiavazzi, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.07201">Quantification of total uncertainty in the physics-informed reconstruction of CVSim-6 physiology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When predicting physical phenomena through simulation, quantification of the total uncertainty due to multiple sources is as crucial as making sure the underlying numerical model is accurate. Possible sources include irreducible aleatoric uncertainty due to noise in the data, epistemic uncertainty induced by insufficient data or inadequate parameterization, and model-form uncertainty related to the use of misspecified model equations. Physics-based regularization interacts in nontrivial ways with aleatoric, epistemic and model-form uncertainty and their combination, and a better understanding of this interaction is needed to improve the predictive performance of physics-informed digital twins that operate under real conditions. With a specific focus on biological and physiological models, this study investigates the decomposition of total uncertainty in the estimation of states and parameters of a differential system simulated with MC X-TFC, a new physics-informed approach for uncertainty quantification based on random projections and Monte-Carlo sampling. MC X-TFC is applied to a six-compartment stiff ODE system, the CVSim-6 model, developed in the context of human physiology. The system is analyzed by progressively removing data while estimating an increasing number of parameters and by investigating total uncertainty under model-form misspecification of non-linear resistance in the pulmonary compartment. In particular, we focus on the interaction between the formulation of the discrepancy term and quantification of model-form uncertainty, and show how additional physics can help in the estimation process. The method demonstrates robustness and efficiency in estimating unknown states and parameters, even with limited, sparse, and noisy data. It also offers great flexibility in integrating data with physics for improved estimation, even in cases of model misspecification.
<div id='section'>Paperid: <span id='pid'>236, <a href='https://arxiv.org/pdf/2408.01026.pdf' target='_blank'>https://arxiv.org/pdf/2408.01026.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chayan Banerjee, Kien Nguyen, Olivier Salvado, Truyen Tran, Clinton Fookes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.01026">PINNs for Medical Image Analysis: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The incorporation of physical information in machine learning frameworks is transforming medical image analysis (MIA). By integrating fundamental knowledge and governing physical laws, these models achieve enhanced robustness and interpretability. In this work, we explore the utility of physics-informed approaches for MIA (PIMIA) tasks such as registration, generation, classification, and reconstruction. We present a systematic literature review of over 80 papers on physics-informed methods dedicated to MIA. We propose a unified taxonomy to investigate what physics knowledge and processes are modelled, how they are represented, and the strategies to incorporate them into MIA models. We delve deep into a wide range of image analysis tasks, from imaging, generation, prediction, inverse imaging (super-resolution and reconstruction), registration, and image analysis (segmentation and classification). For each task, we thoroughly examine and present in a tabular format the central physics-guided operation, the region of interest (with respect to human anatomy), the corresponding imaging modality, the dataset used for model training, the deep network architecture employed, and the primary physical process, equation, or principle utilized. Additionally, we also introduce a novel metric to compare the performance of PIMIA methods across different tasks and datasets. Based on this review, we summarize and distil our perspectives on the challenges, open research questions, and directions for future research. We highlight key open challenges in PIMIA, including selecting suitable physics priors and establishing a standardized benchmarking platform.
<div id='section'>Paperid: <span id='pid'>237, <a href='https://arxiv.org/pdf/2407.21217.pdf' target='_blank'>https://arxiv.org/pdf/2407.21217.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Khemraj Shukla, Zongren Zou, Chi Hin Chan, Additi Pandey, Zhicheng Wang, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21217">NeuroSEM: A hybrid framework for simulating multiphysics problems by coupling PINNs and spectral elements</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiphysics problems that are characterized by complex interactions among fluid dynamics, heat transfer, structural mechanics, and electromagnetics, are inherently challenging due to their coupled nature. While experimental data on certain state variables may be available, integrating these data with numerical solvers remains a significant challenge. Physics-informed neural networks (PINNs) have shown promising results in various engineering disciplines, particularly in handling noisy data and solving inverse problems in partial differential equations (PDEs). However, their effectiveness in forecasting nonlinear phenomena in multiphysics regimes, particularly involving turbulence, is yet to be fully established. This study introduces NeuroSEM, a hybrid framework integrating PINNs with the high-fidelity Spectral Element Method (SEM) solver, Nektar++. NeuroSEM leverages the strengths of both PINNs and SEM, providing robust solutions for multiphysics problems. PINNs are trained to assimilate data and model physical phenomena in specific subdomains, which are then integrated into the Nektar++ solver. We demonstrate the efficiency and accuracy of NeuroSEM for thermal convection in cavity flow and flow past a cylinder. We applied NeuroSEM to the Rayleigh-BÃ©nard convection system, including cases with missing thermal boundary conditions and noisy datasets, and to real particle image velocimetry (PIV) data to capture flow patterns characterized by horseshoe vortical structures. The framework's plug-and-play nature facilitates its extension to other multiphysics or multiscale problems. Furthermore, NeuroSEM is optimized for efficient execution on emerging integrated GPU-CPU architectures. This hybrid approach enhances the accuracy and efficiency of simulations, making it a powerful tool for tackling complex engineering challenges in various scientific domains.
<div id='section'>Paperid: <span id='pid'>238, <a href='https://arxiv.org/pdf/2406.02917.pdf' target='_blank'>https://arxiv.org/pdf/2406.02917.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Khemraj Shukla, Juan Diego Toscano, Zhicheng Wang, Zongren Zou, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02917">A comprehensive and FAIR comparison between MLP and KAN representations for differential equations and operator networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kolmogorov-Arnold Networks (KANs) were recently introduced as an alternative representation model to MLP. Herein, we employ KANs to construct physics-informed machine learning models (PIKANs) and deep operator models (DeepOKANs) for solving differential equations for forward and inverse problems. In particular, we compare them with physics-informed neural networks (PINNs) and deep operator networks (DeepONets), which are based on the standard MLP representation. We find that although the original KANs based on the B-splines parameterization lack accuracy and efficiency, modified versions based on low-order orthogonal polynomials have comparable performance to PINNs and DeepONet although they still lack robustness as they may diverge for different random seeds or higher order orthogonal polynomials. We visualize their corresponding loss landscapes and analyze their learning dynamics using information bottleneck theory. Our study follows the FAIR principles so that other researchers can use our benchmarks to further advance this emerging topic.
<div id='section'>Paperid: <span id='pid'>239, <a href='https://arxiv.org/pdf/2404.07662.pdf' target='_blank'>https://arxiv.org/pdf/2404.07662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gregory Kang Ruey Lau, Apivich Hemachandra, See-Kiong Ng, Bryan Kian Hsiang Low
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.07662">PINNACLE: PINN Adaptive ColLocation and Experimental points selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs), which incorporate PDEs as soft constraints, train with a composite loss function that contains multiple training point types: different types of collocation points chosen during training to enforce each PDE and initial/boundary conditions, and experimental points which are usually costly to obtain via experiments or simulations. Training PINNs using this loss function is challenging as it typically requires selecting large numbers of points of different types, each with different training dynamics. Unlike past works that focused on the selection of either collocation or experimental points, this work introduces PINN Adaptive ColLocation and Experimental points selection (PINNACLE), the first algorithm that jointly optimizes the selection of all training point types, while automatically adjusting the proportion of collocation point types as training progresses. PINNACLE uses information on the interaction among training point types, which had not been considered before, based on an analysis of PINN training dynamics via the Neural Tangent Kernel (NTK). We theoretically show that the criterion used by PINNACLE is related to the PINN generalization error, and empirically demonstrate that PINNACLE is able to outperform existing point selection methods for forward, inverse, and transfer learning problems.
<div id='section'>Paperid: <span id='pid'>240, <a href='https://arxiv.org/pdf/2311.11262.pdf' target='_blank'>https://arxiv.org/pdf/2311.11262.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zongren Zou, Xuhui Meng, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.11262">Uncertainty quantification for noisy inputs-outputs in physics-informed neural networks and neural operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification (UQ) in scientific machine learning (SciML) becomes increasingly critical as neural networks (NNs) are being widely adopted in addressing complex problems across various scientific disciplines. Representative SciML models are physics-informed neural networks (PINNs) and neural operators (NOs). While UQ in SciML has been increasingly investigated in recent years, very few works have focused on addressing the uncertainty caused by the noisy inputs, such as spatial-temporal coordinates in PINNs and input functions in NOs. The presence of noise in the inputs of the models can pose significantly more challenges compared to noise in the outputs of the models, primarily due to the inherent nonlinearity of most SciML algorithms. As a result, UQ for noisy inputs becomes a crucial factor for reliable and trustworthy deployment of these models in applications involving physical knowledge. To this end, we introduce a Bayesian approach to quantify uncertainty arising from noisy inputs-outputs in PINNs and NOs. We show that this approach can be seamlessly integrated into PINNs and NOs, when they are employed to encode the physical information. PINNs incorporate physics by including physics-informed terms via automatic differentiation, either in the loss function or the likelihood, and often take as input the spatial-temporal coordinate. Therefore, the present method equips PINNs with the capability to address problems where the observed coordinate is subject to noise. On the other hand, pretrained NOs are also commonly employed as equation-free surrogates in solving differential equations and Bayesian inverse problems, in which they take functions as inputs. The proposed approach enables them to handle noisy measurements for both input and output functions with UQ.
<div id='section'>Paperid: <span id='pid'>241, <a href='https://arxiv.org/pdf/2310.10776.pdf' target='_blank'>https://arxiv.org/pdf/2310.10776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zongren Zou, Xuhui Meng, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.10776">Correcting model misspecification in physics-informed neural networks (PINNs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven discovery of governing equations in computational science has emerged as a new paradigm for obtaining accurate physical models and as a possible alternative to theoretical derivations. The recently developed physics-informed neural networks (PINNs) have also been employed to learn governing equations given data across diverse scientific disciplines. Despite the effectiveness of PINNs for discovering governing equations, the physical models encoded in PINNs may be misspecified in complex systems as some of the physical processes may not be fully understood, leading to the poor accuracy of PINN predictions. In this work, we present a general approach to correct the misspecified physical models in PINNs for discovering governing equations, given some sparse and/or noisy data. Specifically, we first encode the assumed physical models, which may be misspecified, then employ other deep neural networks (DNNs) to model the discrepancy between the imperfect models and the observational data. Due to the expressivity of DNNs, the proposed method is capable of reducing the computational errors caused by the model misspecification and thus enables the applications of PINNs in complex systems where the physical processes are not exactly known. Furthermore, we utilize the Bayesian PINNs (B-PINNs) and/or ensemble PINNs to quantify uncertainties arising from noisy and/or gappy data in the discovered governing equations. A series of numerical examples including non-Newtonian channel and cavity flows demonstrate that the added DNNs are capable of correcting the model misspecification in PINNs and thus reduce the discrepancy between the physical models and the observational data. We envision that the proposed approach will extend the applications of PINNs for discovering governing equations in problems where the physico-chemical or biological processes are not well understood.
<div id='section'>Paperid: <span id='pid'>242, <a href='https://arxiv.org/pdf/2309.16189.pdf' target='_blank'>https://arxiv.org/pdf/2309.16189.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lu Dai, Liqian Ma, Shenhan Qian, Hao Liu, Ziwei Liu, Hui Xiong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16189">Cloth2Body: Generating 3D Human Body Mesh from 2D Clothing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we define and study a new Cloth2Body problem which has a goal of generating 3D human body meshes from a 2D clothing image. Unlike the existing human mesh recovery problem, Cloth2Body needs to address new and emerging challenges raised by the partial observation of the input and the high diversity of the output. Indeed, there are three specific challenges. First, how to locate and pose human bodies into the clothes. Second, how to effectively estimate body shapes out of various clothing types. Finally, how to generate diverse and plausible results from a 2D clothing image. To this end, we propose an end-to-end framework that can accurately estimate 3D body mesh parameterized by pose and shape from a 2D clothing image. Along this line, we first utilize Kinematics-aware Pose Estimation to estimate body pose parameters. 3D skeleton is employed as a proxy followed by an inverse kinematics module to boost the estimation accuracy. We additionally design an adaptive depth trick to align the re-projected 3D mesh better with 2D clothing image by disentangling the effects of object size and camera extrinsic. Next, we propose Physics-informed Shape Estimation to estimate body shape parameters. 3D shape parameters are predicted based on partial body measurements estimated from RGB image, which not only improves pixel-wise human-cloth alignment, but also enables flexible user editing. Finally, we design Evolution-based pose generation method, a skeleton transplanting method inspired by genetic algorithms to generate diverse reasonable poses during inference. As shown by experimental results on both synthetic and real-world data, the proposed framework achieves state-of-the-art performance and can effectively recover natural and diverse 3D body meshes from 2D images that align well with clothing.
<div id='section'>Paperid: <span id='pid'>243, <a href='https://arxiv.org/pdf/2309.01909.pdf' target='_blank'>https://arxiv.org/pdf/2309.01909.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chayan Banerjee, Kien Nguyen, Clinton Fookes, Maziar Raissi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.01909">A Survey on Physics Informed Reinforcement Learning: Review and Open Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The inclusion of physical information in machine learning frameworks has revolutionized many application areas. This involves enhancing the learning process by incorporating physical constraints and adhering to physical laws. In this work we explore their utility for reinforcement learning applications. We present a thorough review of the literature on incorporating physics information, as known as physics priors, in reinforcement learning approaches, commonly referred to as physics-informed reinforcement learning (PIRL). We introduce a novel taxonomy with the reinforcement learning pipeline as the backbone to classify existing works, compare and contrast them, and derive crucial insights. Existing works are analyzed with regard to the representation/ form of the governing physics modeled for integration, their specific contribution to the typical reinforcement learning architecture, and their connection to the underlying reinforcement learning pipeline stages. We also identify core learning architectures and physics incorporation biases (i.e., observational, inductive and learning) of existing PIRL approaches and use them to further categorize the works for better understanding and adaptation. By providing a comprehensive perspective on the implementation of the physics-informed capability, the taxonomy presents a cohesive approach to PIRL. It identifies the areas where this approach has been applied, as well as the gaps and opportunities that exist. Additionally, the taxonomy sheds light on unresolved issues and challenges, which can guide future research. This nascent field holds great potential for enhancing reinforcement learning algorithms by increasing their physical plausibility, precision, data efficiency, and applicability in real-world scenarios.
<div id='section'>Paperid: <span id='pid'>244, <a href='https://arxiv.org/pdf/2307.08107.pdf' target='_blank'>https://arxiv.org/pdf/2307.08107.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Zhang, Zongren Zou, Ellen Kuhl, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.08107">Discovering a reaction-diffusion model for Alzheimer's disease by combining PINNs with symbolic regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Misfolded tau proteins play a critical role in the progression and pathology of Alzheimer's disease. Recent studies suggest that the spatio-temporal pattern of misfolded tau follows a reaction-diffusion type equation. However, the precise mathematical model and parameters that characterize the progression of misfolded protein across the brain remain incompletely understood. Here, we use deep learning and artificial intelligence to discover a mathematical model for the progression of Alzheimer's disease using longitudinal tau positron emission tomography from the Alzheimer's Disease Neuroimaging Initiative database. Specifically, we integrate physics informed neural networks (PINNs) and symbolic regression to discover a reaction-diffusion type partial differential equation for tau protein misfolding and spreading. First, we demonstrate the potential of our model and parameter discovery on synthetic data. Then, we apply our method to discover the best model and parameters to explain tau imaging data from 46 individuals who are likely to develop Alzheimer's disease and 30 healthy controls. Our symbolic regression discovers different misfolding models $f(c)$ for two groups, with a faster misfolding for the Alzheimer's group, $f(c) = 0.23c^3 - 1.34c^2 + 1.11c$, than for the healthy control group, $f(c) = -c^3 +0.62c^2 + 0.39c$. Our results suggest that PINNs, supplemented by symbolic regression, can discover a reaction-diffusion type model to explain misfolded tau protein concentrations in Alzheimer's disease. We expect our study to be the starting point for a more holistic analysis to provide image-based technologies for early diagnosis, and ideally early treatment of neurodegeneration in Alzheimer's disease and possibly other misfolding-protein based neurodegenerative disorders.
<div id='section'>Paperid: <span id='pid'>245, <a href='https://arxiv.org/pdf/2305.18035.pdf' target='_blank'>https://arxiv.org/pdf/2305.18035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chayan Banerjee, Kien Nguyen, Clinton Fookes, George Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.18035">Physics-Informed Computer Vision: A Review and Perspectives</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The incorporation of physical information in machine learning frameworks is opening and transforming many application domains. Here the learning process is augmented through the induction of fundamental knowledge and governing physical laws. In this work, we explore their utility for computer vision tasks in interpreting and understanding visual data. We present a systematic literature review of more than 250 papers on formulation and approaches to computer vision tasks guided by physical laws. We begin by decomposing the popular computer vision pipeline into a taxonomy of stages and investigate approaches to incorporate governing physical equations in each stage. Existing approaches in computer vision tasks are analyzed with regard to what governing physical processes are modeled and formulated, and how they are incorporated, i.e. modification of input data (observation bias), modification of network architectures (inductive bias), and modification of training losses (learning bias). The taxonomy offers a unified view of the application of the physics-informed capability, highlighting where physics-informed learning has been conducted and where the gaps and opportunities are. Finally, we highlight open problems and challenges to inform future research. While still in its early days, the study of physics-informed computer vision has the promise to develop better computer vision models that can improve physical plausibility, accuracy, data efficiency, and generalization in increasingly realistic applications.
<div id='section'>Paperid: <span id='pid'>246, <a href='https://arxiv.org/pdf/2301.02152.pdf' target='_blank'>https://arxiv.org/pdf/2301.02152.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zongren Zou, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.02152">L-HYDRA: Multi-Head Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce multi-head neural networks (MH-NNs) to physics-informed machine learning, which is a type of neural networks (NNs) with all nonlinear hidden layers as the body and multiple linear output layers as multi-head. Hence, we construct multi-head physics-informed neural networks (MH-PINNs) as a potent tool for multi-task learning (MTL), generative modeling, and few-shot learning for diverse problems in scientific machine learning (SciML). MH-PINNs connect multiple functions/tasks via a shared body as the basis functions as well as a shared distribution for the head. The former is accomplished by solving multiple tasks with MH-PINNs with each head independently corresponding to each task, while the latter by employing normalizing flows (NFs) for density estimate and generative modeling. To this end, our method is a two-stage method, and both stages can be tackled with standard deep learning tools of NNs, enabling easy implementation in practice. MH-PINNs can be used for various purposes, such as approximating stochastic processes, solving multiple tasks synergistically, providing informative prior knowledge for downstream few-shot learning tasks such as meta-learning and transfer learning, learning representative basis functions, and uncertainty quantification. We demonstrate the effectiveness of MH-PINNs in five benchmarks, investigating also the possibility of synergistic learning in regression analysis. We name the open-source code "Lernaean Hydra" (L-HYDRA), since this mythical creature possessed many heads for performing important multiple tasks, as in the proposed method.
<div id='section'>Paperid: <span id='pid'>247, <a href='https://arxiv.org/pdf/2508.20527.pdf' target='_blank'>https://arxiv.org/pdf/2508.20527.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan G. Rittig, Manuel Dahmen, Martin Grohe, Philippe Schwaller, Alexander Mitsos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20527">Molecular Machine Learning in Chemical Process Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a perspective on molecular machine learning (ML) in the field of chemical process engineering. Recently, molecular ML has demonstrated great potential in (i) providing highly accurate predictions for properties of pure components and their mixtures, and (ii) exploring the chemical space for new molecular structures. We review current state-of-the-art molecular ML models and discuss research directions that promise further advancements. This includes ML methods, such as graph neural networks and transformers, which can be further advanced through the incorporation of physicochemical knowledge in a hybrid or physics-informed fashion. Then, we consider leveraging molecular ML at the chemical process scale, which is highly desirable yet rather unexplored. We discuss how molecular ML can be integrated into process design and optimization formulations, promising to accelerate the identification of novel molecules and processes. To this end, it will be essential to create molecule and process design benchmarks and practically validate proposed candidates, possibly in collaboration with the chemical industry.
<div id='section'>Paperid: <span id='pid'>248, <a href='https://arxiv.org/pdf/2508.20527.pdf' target='_blank'>https://arxiv.org/pdf/2508.20527.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan G. Rittig, Manuel Dahmen, Martin Grohe, Philippe Schwaller, Alexander Mitsos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20527">Molecular Machine Learning in Chemical Process Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a perspective on molecular machine learning (ML) in the field of chemical process engineering. Recently, molecular ML has demonstrated great potential in (i) providing highly accurate predictions for properties of pure components and their mixtures, and (ii) exploring the chemical space for new molecular structures. We review current state-of-the-art molecular ML models and discuss research directions that promise further advancements. This includes ML methods, such as graph neural networks and transformers, which can be further advanced through the incorporation of physicochemical knowledge in a hybrid or physics-informed fashion. Then, we consider leveraging molecular ML at the chemical process scale, which is highly desirable yet rather unexplored. We discuss how molecular ML can be integrated into process design and optimization formulations, promising to accelerate the identification of novel molecules and processes. To this end, it will be essential to create molecule and process design benchmarks and practically validate proposed candidates, possibly in collaboration with the chemical industry.
<div id='section'>Paperid: <span id='pid'>249, <a href='https://arxiv.org/pdf/2508.16235.pdf' target='_blank'>https://arxiv.org/pdf/2508.16235.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mayank Nagda, Jephte Abijuru, Phil Ostheimer, Marius Kloft, Sophie Fellenz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16235">PIANO: Physics Informed Autoregressive Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving time-dependent partial differential equations (PDEs) is fundamental to modeling critical phenomena across science and engineering. Physics-Informed Neural Networks (PINNs) solve PDEs using deep learning. However, PINNs perform pointwise predictions that neglect the autoregressive property of dynamical systems, leading to instabilities and inaccurate predictions. We introduce Physics-Informed Autoregressive Networks (PIANO) -- a framework that redesigns PINNs to model dynamical systems. PIANO operates autoregressively, explicitly conditioning future predictions on the past. It is trained through a self-supervised rollout mechanism while enforcing physical constraints. We present a rigorous theoretical analysis demonstrating that PINNs suffer from temporal instability, while PIANO achieves stability through autoregressive modeling. Extensive experiments on challenging time-dependent PDEs demonstrate that PIANO achieves state-of-the-art performance, significantly improving accuracy and stability over existing methods. We further show that PIANO outperforms existing methods in weather forecasting.
<div id='section'>Paperid: <span id='pid'>250, <a href='https://arxiv.org/pdf/2505.18365.pdf' target='_blank'>https://arxiv.org/pdf/2505.18365.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhangxing Bian, Shuwen Wei, Xiao Liang, Yuan-Chiao Lu, Samuel W. Remedios, Fangxu Xing, Jonghye Woo, Dzung L. Pham, Aaron Carass, Philip V. Bayly, Jiachen Zhuo, Ahmed Alshareef, Jerry L. Prince
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18365">Brightness-Invariant Tracking Estimation in Tagged MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Magnetic resonance (MR) tagging is an imaging technique for noninvasively tracking tissue motion in vivo by creating a visible pattern of magnetization saturation (tags) that deforms with the tissue. Due to longitudinal relaxation and progression to steady-state, the tags and tissue brightnesses change over time, which makes tracking with optical flow methods error-prone. Although Fourier methods can alleviate these problems, they are also sensitive to brightness changes as well as spectral spreading due to motion. To address these problems, we introduce the brightness-invariant tracking estimation (BRITE) technique for tagged MRI. BRITE disentangles the anatomy from the tag pattern in the observed tagged image sequence and simultaneously estimates the Lagrangian motion. The inherent ill-posedness of this problem is addressed by leveraging the expressive power of denoising diffusion probabilistic models to represent the probabilistic distribution of the underlying anatomy and the flexibility of physics-informed neural networks to estimate biologically-plausible motion. A set of tagged MR images of a gel phantom was acquired with various tag periods and imaging flip angles to demonstrate the impact of brightness variations and to validate our method. The results show that BRITE achieves more accurate motion and strain estimates as compared to other state of the art methods, while also being resistant to tag fading.
<div id='section'>Paperid: <span id='pid'>251, <a href='https://arxiv.org/pdf/2503.18787.pdf' target='_blank'>https://arxiv.org/pdf/2503.18787.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Mayfrank, Mehmet Velioglu, Alexander Mitsos, Manuel Dahmen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18787">Sample-Efficient Reinforcement Learning of Koopman eNMPC</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement learning (RL) can be used to tune data-driven (economic) nonlinear model predictive controllers ((e)NMPCs) for optimal performance in a specific control task by optimizing the dynamic model or parameters in the policy's objective function or constraints, such as state bounds. However, the sample efficiency of RL is crucial, and to improve it, we combine a model-based RL algorithm with our published method that turns Koopman (e)NMPCs into automatically differentiable policies. We apply our approach to an eNMPC case study of a continuous stirred-tank reactor (CSTR) model from the literature. The approach outperforms benchmark methods, i.e., data-driven eNMPCs using models based on system identification without further RL tuning of the resulting policy, and neural network controllers trained with model-based RL, by achieving superior control performance and higher sample efficiency. Furthermore, utilizing partial prior knowledge about the system dynamics via physics-informed learning further increases sample efficiency.
<div id='section'>Paperid: <span id='pid'>252, <a href='https://arxiv.org/pdf/2411.06278.pdf' target='_blank'>https://arxiv.org/pdf/2411.06278.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shu Liu, Stanley Osher, Wuchen Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.06278">A Natural Primal-Dual Hybrid Gradient Method for Adversarial Neural Network Training on Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a scalable preconditioned primal-dual hybrid gradient algorithm for solving partial differential equations (PDEs). We multiply the PDE with a dual test function to obtain an inf-sup problem whose loss functional involves lower-order differential operators. The Primal-Dual Hybrid Gradient (PDHG) algorithm is then leveraged for this saddle point problem. By introducing suitable precondition operators to the proximal steps in the PDHG algorithm, we obtain an alternative natural gradient ascent-descent optimization scheme for updating the neural network parameters. We apply the Krylov subspace method (MINRES) to evaluate the natural gradients efficiently. Such treatment readily handles the inversion of precondition matrices via matrix-vector multiplication. A posterior convergence analysis is established for the time-continuous version of the proposed method. The algorithm is tested on various types of PDEs with dimensions ranging from $1$ to $50$, including linear and nonlinear elliptic equations, reaction-diffusion equations, and Monge-AmpÃ¨re equations stemming from the $L^2$ optimal transport problems. We compare the performance of the proposed method with several commonly used deep learning algorithms such as physics-informed neural networks (PINNs), the DeepRitz method, weak adversarial networks (WANs), etc, for solving PDEs using the Adam and L-BFGS optimizers. The numerical results suggest that the proposed method performs efficiently and robustly and converges more stably.
<div id='section'>Paperid: <span id='pid'>253, <a href='https://arxiv.org/pdf/2409.20206.pdf' target='_blank'>https://arxiv.org/pdf/2409.20206.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mayank Nagda, Phil Ostheimer, Thomas Specht, Frank Rhein, Fabian Jirasek, Stephan Mandt, Marius Kloft, Sophie Fellenz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.20206">SetPINNs: Set-based Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) solve partial differential equations using deep learning. However, conventional PINNs perform pointwise predictions that neglect dependencies within a domain, which may result in suboptimal solutions. We introduce SetPINNs, a framework that effectively captures local dependencies. With a finite element-inspired sampling scheme, we partition the domain into sets to model local dependencies while simultaneously enforcing physical laws. We provide a rigorous theoretical analysis showing that SetPINNs yield unbiased, lower-variance estimates of residual energy and its gradients, ensuring improved domain coverage and reduced residual error. Extensive experiments on synthetic and real-world tasks show improved accuracy, efficiency, and robustness.
<div id='section'>Paperid: <span id='pid'>254, <a href='https://arxiv.org/pdf/2409.13532.pdf' target='_blank'>https://arxiv.org/pdf/2409.13532.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sven LÃ¼pke, Yousef Yeganeh, Ehsan Adeli, Nassir Navab, Azade Farshad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13532">Physics-Informed Latent Diffusion for Multimodal Brain MRI Synthesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in generative models for medical imaging have shown promise in representing multiple modalities. However, the variability in modality availability across datasets limits the general applicability of the synthetic data they produce. To address this, we present a novel physics-informed generative model capable of synthesizing a variable number of brain MRI modalities, including those not present in the original dataset. Our approach utilizes latent diffusion models and a two-step generative process: first, unobserved physical tissue property maps are synthesized using a latent diffusion model, and then these maps are combined with a physical signal model to generate the final MRI scan. Our experiments demonstrate the efficacy of this approach in generating unseen MR contrasts and preserving physical plausibility. Furthermore, we validate the distributions of generated tissue properties by comparing them to those measured in real brain tissue.
<div id='section'>Paperid: <span id='pid'>255, <a href='https://arxiv.org/pdf/2406.01528.pdf' target='_blank'>https://arxiv.org/pdf/2406.01528.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehmet Velioglu, Song Zhai, Sophia Rupprecht, Alexander Mitsos, Andreas Jupke, Manuel Dahmen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01528">Physics-Informed Neural Networks for Dynamic Process Operations with Limited Physical Knowledge and Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In chemical engineering, process data are expensive to acquire, and complex phenomena are difficult to fully model. We explore the use of physics-informed neural networks (PINNs) for modeling dynamic processes with incomplete mechanistic semi-explicit differential-algebraic equation systems and scarce process data. In particular, we focus on estimating states for which neither direct observational data nor constitutive equations are available. We propose an easy-to-apply heuristic to assess whether estimation of such states may be possible. As numerical examples, we consider a continuously stirred tank reactor and a liquid-liquid separator. We find that PINNs can infer immeasurable states with reasonable accuracy, even if respective constitutive equations are unknown. We thus show that PINNs are capable of modeling processes when relatively few experimental data and only partially known mechanistic descriptions are available, and conclude that they constitute a promising avenue that warrants further investigation.
<div id='section'>Paperid: <span id='pid'>256, <a href='https://arxiv.org/pdf/2402.15552.pdf' target='_blank'>https://arxiv.org/pdf/2402.15552.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel OrdoÃ±ez-Apraez, Giulio Turrisi, Vladimir Kostic, Mario Martin, Antonio Agudo, Francesc Moreno-Noguer, Massimiliano Pontil, Claudio Semini, Carlos Mastalli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.15552">Morphological Symmetries in Robotics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a comprehensive framework for studying and leveraging morphological symmetries in robotic systems. These are intrinsic properties of the robot's morphology, frequently observed in animal biology and robotics, which stem from the replication of kinematic structures and the symmetrical distribution of mass. We illustrate how these symmetries extend to the robot's state space and both proprioceptive and exteroceptive sensor measurements, resulting in the equivariance of the robot's equations of motion and optimal control policies. Thus, we recognize morphological symmetries as a relevant and previously unexplored physics-informed geometric prior, with significant implications for both data-driven and analytical methods used in modeling, control, estimation and design in robotics. For data-driven methods, we demonstrate that morphological symmetries can enhance the sample efficiency and generalization of machine learning models through data augmentation, or by applying equivariant/invariant constraints on the model's architecture. In the context of analytical methods, we employ abstract harmonic analysis to decompose the robot's dynamics into a superposition of lower-dimensional, independent dynamics. We substantiate our claims with both synthetic and real-world experiments conducted on bipedal and quadrupedal robots. Lastly, we introduce the repository MorphoSymm to facilitate the practical use of the theory and applications outlined in this work.
<div id='section'>Paperid: <span id='pid'>257, <a href='https://arxiv.org/pdf/2312.09787.pdf' target='_blank'>https://arxiv.org/pdf/2312.09787.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Federica Caforio, Francesco Regazzoni, Stefano Pagani, Elias Karabelas, Christoph Augustin, Gundolf Haase, Gernot Plank, Alfio Quarteroni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.09787">Physics-informed Neural Network Estimation of Material Properties in Soft Tissue Nonlinear Biomechanical Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The development of biophysical models for clinical applications is rapidly advancing in the research community, thanks to their predictive nature and their ability to assist the interpretation of clinical data. However, high-resolution and accurate multi-physics computational models are computationally expensive and their personalisation involves fine calibration of a large number of parameters, which may be space-dependent, challenging their clinical translation. In this work, we propose a new approach which relies on the combination of physics-informed neural networks (PINNs) with three-dimensional soft tissue nonlinear biomechanical models, capable of reconstructing displacement fields and estimating heterogeneous patient-specific biophysical properties. The proposed learning algorithm encodes information from a limited amount of displacement and, in some cases, strain data, that can be routinely acquired in the clinical setting, and combines it with the physics of the problem, represented by a mathematical model based on partial differential equations, to regularise the problem and improve its convergence properties. Several benchmarks are presented to show the accuracy and robustness of the proposed method and its great potential to enable the robust and effective identification of patient-specific, heterogeneous physical properties, s.a. tissue stiffness properties. In particular, we demonstrate the capability of the PINN to detect the presence, location and severity of scar tissue, which is beneficial to develop personalised simulation models for disease diagnosis, especially for cardiac applications.
<div id='section'>Paperid: <span id='pid'>258, <a href='https://arxiv.org/pdf/2311.00815.pdf' target='_blank'>https://arxiv.org/pdf/2311.00815.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Parv Maheshwari, Wenshan Wang, Samuel Triest, Matthew Sivaprakasam, Shubhra Aich, John G. Rogers, Jason M. Gregory, Sebastian Scherer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.00815">PIAug -- Physics Informed Augmentation for Learning Vehicle Dynamics for Off-Road Navigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling the precise dynamics of off-road vehicles is a complex yet essential task due to the challenging terrain they encounter and the need for optimal performance and safety. Recently, there has been a focus on integrating nominal physics-based models alongside data-driven neural networks using Physics Informed Neural Networks. These approaches often assume the availability of a well-distributed dataset; however, this assumption may not hold due to regions in the physical distribution that are hard to collect, such as high-speed motions and rare terrains. Therefore, we introduce a physics-informed data augmentation methodology called PIAug. We show an example use case of the same by modeling high-speed and aggressive motion predictions, given a dataset with only low-speed data. During the training phase, we leverage the nominal model for generating target domain (medium and high velocity) data using the available source data (low velocity). Subsequently, we employ a physics-inspired loss function with this augmented dataset to incorporate prior knowledge of physics into the neural network. Our methodology results in up to 67% less mean error in trajectory prediction in comparison to a standalone nominal model, especially during aggressive maneuvers at speeds outside the training domain. In real-life navigation experiments, our model succeeds in 4x tighter waypoint tracking constraints than the Kinematic Bicycle Model (KBM) at out-of-domain velocities.
<div id='section'>Paperid: <span id='pid'>259, <a href='https://arxiv.org/pdf/2306.14916.pdf' target='_blank'>https://arxiv.org/pdf/2306.14916.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tom WollschlÃ¤ger, Nicholas Gao, Bertrand Charpentier, Mohamed Amine Ketata, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.14916">Uncertainty Estimation for Molecules: Desiderata and Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) are promising surrogates for quantum mechanical calculations as they establish unprecedented low errors on collections of molecular dynamics (MD) trajectories. Thanks to their fast inference times they promise to accelerate computational chemistry applications. Unfortunately, despite low in-distribution (ID) errors, such GNNs might be horribly wrong for out-of-distribution (OOD) samples. Uncertainty estimation (UE) may aid in such situations by communicating the model's certainty about its prediction. Here, we take a closer look at the problem and identify six key desiderata for UE in molecular force fields, three 'physics-informed' and three 'application-focused' ones. To overview the field, we survey existing methods from the field of UE and analyze how they fit to the set desiderata. By our analysis, we conclude that none of the previous works satisfies all criteria. To fill this gap, we propose Localized Neural Kernel (LNK) a Gaussian Process (GP)-based extension to existing GNNs satisfying the desiderata. In our extensive experimental evaluation, we test four different UE with three different backbones and two datasets. In out-of-equilibrium detection, we find LNK yielding up to 2.5 and 2.1 times lower errors in terms of AUC-ROC score than dropout or evidential regression-based methods while maintaining high predictive performance.
<div id='section'>Paperid: <span id='pid'>260, <a href='https://arxiv.org/pdf/2306.02925.pdf' target='_blank'>https://arxiv.org/pdf/2306.02925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rixi Peng, Juncheng Dong, Jordan Malof, Willie J. Padilla, Vahid Tarokh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02925">Deep Generalized Green's Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we address the challenge of obtaining a Green's function operator for linear partial differential equations (PDEs). The Green's function is well-sought after due to its ability to directly map inputs to solutions, bypassing the need for common numerical methods such as finite difference and finite elements methods. However, obtaining an explicit form of the Green's function kernel for most PDEs has been a challenge due to the Dirac delta function singularity present. To address this issue, we propose the Deep Generalized Green's Function (DGGF) as an alternative, which can be solved for in an efficient and accurate manner using neural network models. The DGGF provides a more efficient and precise approach to solving linear PDEs while inheriting the reusability of the Green's function, and possessing additional desirable properties such as mesh-free operation and a small memory footprint. The DGGF is compared against a variety of state-of-the-art (SOTA) PDE solvers, including direct methods, namely physics-informed neural networks (PINNs), Green's function approaches such as networks for Gaussian approximation of the Dirac delta functions (GADD), and numerical Green's functions (NGFs). The performance of all methods is compared on four representative PDE categories, each with different combinations of dimensionality and domain shape. The results confirm the advantages of DGGFs, and benefits of Generalized Greens Functions as an novel alternative approach to solve PDEs without suffering from singularities.
<div id='section'>Paperid: <span id='pid'>261, <a href='https://arxiv.org/pdf/2304.00092.pdf' target='_blank'>https://arxiv.org/pdf/2304.00092.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Divyanshi Dwivedi, Pradeep Kumar Yemula, Mayukha Pal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.00092">DynamoPMU: A Physics Informed Anomaly Detection and Prediction Methodology using non-linear dynamics from $Î¼$PMU Measurement Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The expansion in technology and attainability of a large number of sensors has led to a huge amount of real-time streaming data. The real-time data in the electrical distribution system is collected through distribution-level phasor measurement units referred to as $Î¼$PMU which report high-resolution phasor measurements comprising various event signatures which provide situational awareness and enable a level of visibility into the distribution system. These events are infrequent, unschedule, and uncertain; it is a challenge to scrutinize, detect and predict the occurrence of such events. For electrical distribution systems, it is challenging to explicitly identify evolution functions that describe the complex, non-linear, and non-stationary signature patterns of events. In this paper, we seek to address this problem by developing a physics dynamics-based approach to detect anomalies in the $Î¼$PMU streaming data and simultaneously predict the events using governing equations. We propose a data-driven approach based on the Hankel alternative view of the Koopman (HAVOK) operator, called DynamoPMU, to analyze the underlying dynamics of the distribution system by representing them in a linear intrinsic space. The key technical idea is that the proposed method separates out the linear dynamical behaviour pattern and intermittent forcing (anomalous events) in sequential data which turns out to be very useful for anomaly detection and simultaneous data prediction. We demonstrate the efficacy of our proposed framework through analysis of real $Î¼$PMU data taken from the LBNL distribution grid. DynamoPMU is suitable for real-time event detection as well as prediction in an unsupervised way and adapts to varying statistics.
<div id='section'>Paperid: <span id='pid'>262, <a href='https://arxiv.org/pdf/2209.06467.pdf' target='_blank'>https://arxiv.org/pdf/2209.06467.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junyan He, Diab Abueidda, Rashid Abu Al-Rub, Seid Koric, Iwona Jasiuk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.06467">A deep learning energy-based method for classical elastoplasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The deep energy method (DEM) has been used to solve the elastic deformation of structures with linear elasticity, hyperelasticity, and strain-gradient elasticity material models based on the principle of minimum potential energy. In this work, we extend DEM to elastoplasticity problems involving path dependence and irreversibility. A loss function inspired by the discrete variational formulation of plasticity is proposed. The radial return algorithm is coupled with DEM to update the plastic internal state variables without violating the Kuhn-Tucker consistency conditions. Finite element shape functions and their gradients are used to approximate the spatial gradients of the DEM-predicted displacements, and Gauss quadrature is used to integrate the loss function. Four numerical examples are presented to demonstrate the use of the framework, such as generating stress-strain curves in cyclic loading, material heterogeneity, performance comparison with other physics-informed methods, and simulation/inference on unstructured meshes. In all cases, the DEM solution shows decent accuracy compared to the reference solution obtained from the finite element method. The current DEM model marks the first time that energy-based physics-informed neural networks are extended to plasticity, and offers promising potential to effectively solve elastoplasticity problems from scratch using deep neural networks.
<div id='section'>Paperid: <span id='pid'>263, <a href='https://arxiv.org/pdf/2205.13748.pdf' target='_blank'>https://arxiv.org/pdf/2205.13748.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yicheng Wang, Xiaotian Han, Chia-Yuan Chang, Daochen Zha, Ulisses Braga-Neto, Xia Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.13748">Auto-PINN: Understanding and Optimizing Physics-Informed Neural Architecture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are revolutionizing science and engineering practice by bringing together the power of deep learning to bear on scientific computation. In forward modeling problems, PINNs are meshless partial differential equation (PDE) solvers that can handle irregular, high-dimensional physical domains. Naturally, the neural architecture hyperparameters have a large impact on the efficiency and accuracy of the PINN solver. However, this remains an open and challenging problem because of the large search space and the difficulty of identifying a proper search objective for PDEs. Here, we propose Auto-PINN, the first systematic, automated hyperparameter optimization approach for PINNs, which employs Neural Architecture Search (NAS) techniques to PINN design. Auto-PINN avoids manually or exhaustively searching the hyperparameter space associated with PINNs. A comprehensive set of pre-experiments using standard PDE benchmarks allows us to probe the structure-performance relationship in PINNs. We find that the different hyperparameters can be decoupled, and that the training loss function of PINNs is a good search objective. Comparison experiments with baseline methods demonstrate that Auto-PINN produces neural architectures with superior stability and accuracy over alternative baselines.
<div id='section'>Paperid: <span id='pid'>264, <a href='https://arxiv.org/pdf/2509.25704.pdf' target='_blank'>https://arxiv.org/pdf/2509.25704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng Guo, Giuseppe L'Erario, Giulio Romualdi, Mattia Leonori, Marta Lorenzini, Arash Ajoudani, Daniele Pucci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25704">Physics-Informed Learning for Human Whole-Body Kinematics Prediction via Sparse IMUs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and physically feasible human motion prediction is crucial for safe and seamless human-robot collaboration. While recent advancements in human motion capture enable real-time pose estimation, the practical value of many existing approaches is limited by the lack of future predictions and consideration of physical constraints. Conventional motion prediction schemes rely heavily on past poses, which are not always available in real-world scenarios. To address these limitations, we present a physics-informed learning framework that integrates domain knowledge into both training and inference to predict human motion using inertial measurements from only 5 IMUs. We propose a network that accounts for the spatial characteristics of human movements. During training, we incorporate forward and differential kinematics functions as additional loss components to regularize the learned joint predictions. At the inference stage, we refine the prediction from the previous iteration to update a joint state buffer, which is used as extra inputs to the network. Experimental results demonstrate that our approach achieves high accuracy, smooth transitions between motions, and generalizes well to unseen subjects
<div id='section'>Paperid: <span id='pid'>265, <a href='https://arxiv.org/pdf/2509.21207.pdf' target='_blank'>https://arxiv.org/pdf/2509.21207.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Olga Fink, Ismail Nejjar, Vinay Sharma, Keivan Faghih Niresi, Han Sun, Hao Dong, Chenghao Xu, Amaury Wei, Arthur Bizzi, Raffael Theiler, Yuan Tian, Leandro Von Krannichfeldt, Zhan Ma, Sergei Garmaev, Zepeng Zhang, Mengjie Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21207">From Physics to Machine Learning and Back: Part II - Learning and Observational Bias in PHM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prognostics and Health Management ensures the reliability, safety, and efficiency of complex engineered systems by enabling fault detection, anticipating equipment failures, and optimizing maintenance activities throughout an asset lifecycle. However, real-world PHM presents persistent challenges: sensor data is often noisy or incomplete, available labels are limited, and degradation behaviors and system interdependencies can be highly complex and nonlinear. Physics-informed machine learning has emerged as a promising approach to address these limitations by embedding physical knowledge into data-driven models. This review examines how incorporating learning and observational biases through physics-informed modeling and data strategies can guide models toward physically consistent and reliable predictions. Learning biases embed physical constraints into model training through physics-informed loss functions and governing equations, or by incorporating properties like monotonicity. Observational biases influence data selection and synthesis to ensure models capture realistic system behavior through virtual sensing for estimating unmeasured states, physics-based simulation for data augmentation, and multi-sensor fusion strategies. The review then examines how these approaches enable the transition from passive prediction to active decision-making through reinforcement learning, which allows agents to learn maintenance policies that respect physical constraints while optimizing operational objectives. This closes the loop between model-based predictions, simulation, and actual system operation, empowering adaptive decision-making. Finally, the review addresses the critical challenge of scaling PHM solutions from individual assets to fleet-wide deployment. Fast adaptation methods including meta-learning and few-shot learning are reviewed alongside domain generalization techniques ...
<div id='section'>Paperid: <span id='pid'>266, <a href='https://arxiv.org/pdf/2506.21349.pdf' target='_blank'>https://arxiv.org/pdf/2506.21349.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizhe Cheng, Chunxun Tian, Haoru Wang, Wentao Zhu, Xiaoxuan Ma, Yizhou Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.21349">Generalizable Neural Electromagnetic Inverse Scattering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving Electromagnetic Inverse Scattering Problems (EISP) is fundamental in applications such as medical imaging, where the goal is to reconstruct the relative permittivity from scattered electromagnetic field. This inverse process is inherently ill-posed and highly nonlinear, making it particularly challenging. A recent machine learning-based approach, Img-Interiors, shows promising results by leveraging continuous implicit functions. However, it requires case-specific optimization, lacks generalization to unseen data, and fails under sparse transmitter setups (e.g., with only one transmitter). To address these limitations, we revisit EISP from a physics-informed perspective, reformulating it as a two stage inverse transmission-scattering process. This formulation reveals the induced current as a generalizable intermediate representation, effectively decoupling the nonlinear scattering process from the ill-posed inverse problem. Built on this insight, we propose the first generalizable physics-driven framework for EISP, comprising a current estimator and a permittivity solver, working in an end-to-end manner. The current estimator explicitly learns the induced current as a physical bridge between the incident and scattered field, while the permittivity solver computes the relative permittivity directly from the estimated induced current. This design enables data-driven training and generalizable feed-forward prediction of relative permittivity on unseen data while maintaining strong robustness to transmitter sparsity. Extensive experiments show that our method outperforms state-of-the-art approaches in reconstruction accuracy, generalization, and robustness. This work offers a fundamentally new perspective on electromagnetic inverse scattering and represents a major step toward cost-effective practical solutions for electromagnetic imaging.
<div id='section'>Paperid: <span id='pid'>267, <a href='https://arxiv.org/pdf/2506.08049.pdf' target='_blank'>https://arxiv.org/pdf/2506.08049.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tengfei Lyu, Weijia Zhang, Hao Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08049">Physics-Informed Teleconnection-Aware Transformer for Global Subseasonal-to-Seasonal Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Subseasonal-to-seasonal (S2S) forecasting, which predicts climate conditions from several weeks to months in advance, represents a critical frontier for agricultural planning, energy management, and disaster preparedness. However, it remains one of the most challenging problems in atmospheric science, due to the chaotic dynamics of atmospheric systems and complex interactions across multiple scales. Current approaches often fail to explicitly model underlying physical processes and teleconnections that are crucial at S2S timescales. We introduce \textbf{TelePiT}, a novel deep learning architecture that enhances global S2S forecasting through integrated multi-scale physics and teleconnection awareness. Our approach consists of three key components: (1) Spherical Harmonic Embedding, which accurately encodes global atmospheric variables onto spherical geometry; (2) Multi-Scale Physics-Informed Neural ODE, which explicitly captures atmospheric physical processes across multiple learnable frequency bands; (3) Teleconnection-Aware Transformer, which models critical global climate interactions through explicitly modeling teleconnection patterns into the self-attention. Extensive experiments demonstrate that \textbf{TelePiT} significantly outperforms state-of-the-art data-driven baselines and operational numerical weather prediction systems across all forecast horizons, marking a significant advance toward reliable S2S forecasting.
<div id='section'>Paperid: <span id='pid'>268, <a href='https://arxiv.org/pdf/2409.03005.pdf' target='_blank'>https://arxiv.org/pdf/2409.03005.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoyi Cai, James Queeney, Tong Xu, Aniket Datar, Chenhui Pan, Max Miller, Ashton Flather, Philip R. Osteen, Nicholas Roy, Xuesu Xiao, Jonathan P. How
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03005">PIETRA: Physics-Informed Evidential Learning for Traversing Out-of-Distribution Terrain</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised learning is a powerful approach for developing traversability models for off-road navigation, but these models often struggle with inputs unseen during training. Existing methods utilize techniques like evidential deep learning to quantify model uncertainty, helping to identify and avoid out-of-distribution terrain. However, always avoiding out-of-distribution terrain can be overly conservative, e.g., when novel terrain can be effectively analyzed using a physics-based model. To overcome this challenge, we introduce Physics-Informed Evidential Traversability (PIETRA), a self-supervised learning framework that integrates physics priors directly into the mathematical formulation of evidential neural networks and introduces physics knowledge implicitly through an uncertainty-aware, physics-informed training loss. Our evidential network seamlessly transitions between learned and physics-based predictions for out-of-distribution inputs. Additionally, the physics-informed loss regularizes the learned model, ensuring better alignment with the physics model. Extensive simulations and hardware experiments demonstrate that PIETRA improves both learning accuracy and navigation performance in environments with significant distribution shifts.
<div id='section'>Paperid: <span id='pid'>269, <a href='https://arxiv.org/pdf/2408.09840.pdf' target='_blank'>https://arxiv.org/pdf/2408.09840.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joe Watson, Chen Song, Oliver Weeger, Theo Gruner, An T. Le, Kay Pompetzki, Ahmed Hendawy, Oleg Arenz, Will Trojak, Miles Cranmer, Carlo D'Eramo, Fabian BÃ¼low, Tanmay Goyal, Jan Peters, Martin W. Hoffman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09840">Machine Learning with Physics Knowledge for Prediction: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This survey examines the broad suite of methods and models for combining machine learning with physics knowledge for prediction and forecast, with a focus on partial differential equations. These methods have attracted significant interest due to their potential impact on advancing scientific research and industrial practices by improving predictive models with small- or large-scale datasets and expressive predictive models with useful inductive biases. The survey has two parts. The first considers incorporating physics knowledge on an architectural level through objective functions, structured predictive models, and data augmentation. The second considers data as physics knowledge, which motivates looking at multi-task, meta, and contextual learning as an alternative approach to incorporating physics knowledge in a data-driven fashion. Finally, we also provide an industrial perspective on the application of these methods and a survey of the open-source ecosystem for physics-informed machine learning.
<div id='section'>Paperid: <span id='pid'>270, <a href='https://arxiv.org/pdf/2403.19090.pdf' target='_blank'>https://arxiv.org/pdf/2403.19090.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuling Jiao, Yuhui Liu, Jerry Zhijian Yang, Cheng Yuan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.19090">A Stabilized Physics Informed Neural Networks Method for Wave Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this article, we propose a novel Stabilized Physics Informed Neural Networks method (SPINNs) for solving wave equations. In general, this method not only demonstrates theoretical convergence but also exhibits higher efficiency compared to the original PINNs. By replacing the $L^2$ norm with $H^1$ norm in the learning of initial condition and boundary condition, we theoretically proved that the error of solution can be upper bounded by the risk in SPINNs. Based on this, we decompose the error of SPINNs into approximation error, statistical error and optimization error. Furthermore, by applying the approximating theory of $ReLU^3$ networks and the learning theory on Rademacher complexity, covering number and pseudo-dimension of neural networks, we present a systematical non-asymptotic convergence analysis on our method, which shows that the error of SPINNs can be well controlled if the number of training samples, depth and width of the deep neural networks have been appropriately chosen. Two illustrative numerical examples on 1-dimensional and 2-dimensional wave equations demonstrate that SPINNs can achieve a faster and better convergence than classical PINNs method.
<div id='section'>Paperid: <span id='pid'>271, <a href='https://arxiv.org/pdf/2403.11591.pdf' target='_blank'>https://arxiv.org/pdf/2403.11591.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dimitrios G. Patsatzis, Lucia Russo, Constantinos Siettos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11591">A physics-informed neural network method for the approximation of slow invariant manifolds for the general class of stiff systems of ODEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a physics-informed neural network (PINN) approach for the discovery of slow invariant manifolds (SIMs), for the most general class of fast/slow dynamical systems of ODEs. In contrast to other machine learning (ML) approaches that construct reduced order black box surrogate models using simple regression, and/or require a priori knowledge of the fast and slow variables, our approach, simultaneously decomposes the vector field into fast and slow components and provides a functional of the underlying SIM in a closed form. The decomposition is achieved by finding a transformation of the state variables to the fast and slow ones, which enables the derivation of an explicit, in terms of fast variables, SIM functional. The latter is obtained by solving a PDE corresponding to the invariance equation within the Geometric Singular Perturbation Theory (GSPT) using a single-layer feedforward neural network with symbolic differentiation. The performance of the proposed physics-informed ML framework is assessed via three benchmark problems: the Michaelis-Menten, the target mediated drug disposition (TMDD) reaction model and a fully competitive substrate-inhibitor(fCSI) mechanism. We also provide a comparison with other GPST methods, namely the quasi steady state approximation (QSSA), the partial equilibrium approximation (PEA) and CSP with one and two iterations. We show that the proposed PINN scheme provides SIM approximations, of equivalent or even higher accuracy, than those provided by QSSA, PEA and CSP, especially close to the boundaries of the underlying SIMs.
<div id='section'>Paperid: <span id='pid'>272, <a href='https://arxiv.org/pdf/2402.10681.pdf' target='_blank'>https://arxiv.org/pdf/2402.10681.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tobias WÃ¼rth, Niklas Freymuth, Clemens Zimmerling, Gerhard Neumann, Luise KÃ¤rger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10681">Physics-informed MeshGraphNets (PI-MGNs): Neural finite element solvers for non-stationary and nonlinear simulations on arbitrary meshes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Engineering components must meet increasing technological demands in ever shorter development cycles. To face these challenges, a holistic approach is essential that allows for the concurrent development of part design, material system and manufacturing process. Current approaches employ numerical simulations, which however quickly becomes computation-intensive, especially for iterative optimization. Data-driven machine learning methods can be used to replace time- and resource-intensive numerical simulations. In particular, MeshGraphNets (MGNs) have shown promising results. They enable fast and accurate predictions on unseen mesh geometries while being fully differentiable for optimization. However, these models rely on large amounts of expensive training data, such as numerical simulations. Physics-informed neural networks (PINNs) offer an opportunity to train neural networks with partial differential equations instead of labeled data, but have not been extended yet to handle time-dependent simulations of arbitrary meshes. This work introduces PI-MGNs, a hybrid approach that combines PINNs and MGNs to quickly and accurately solve non-stationary and nonlinear partial differential equations (PDEs) on arbitrary meshes. The method is exemplified for thermal process simulations of unseen parts with inhomogeneous material distribution. Further results show that the model scales well to large and complex meshes, although it is trained on small generic meshes only.
<div id='section'>Paperid: <span id='pid'>273, <a href='https://arxiv.org/pdf/2311.06968.pdf' target='_blank'>https://arxiv.org/pdf/2311.06968.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiyuan Zhang, Xiaohan Fu, Diyan Teng, Chengyu Dong, Keerthivasan Vijayakumar, Jiayun Zhang, Ranak Roy Chowdhury, Junsheng Han, Dezhi Hong, Rashmi Kulkarni, Jingbo Shang, Rajesh Gupta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.06968">Physics-Informed Data Denoising for Real-Life Sensing Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sensors measuring real-life physical processes are ubiquitous in today's interconnected world. These sensors inherently bear noise that often adversely affects performance and reliability of the systems they support. Classic filtering-based approaches introduce strong assumptions on the time or frequency characteristics of sensory measurements, while learning-based denoising approaches typically rely on using ground truth clean data to train a denoising model, which is often challenging or prohibitive to obtain for many real-world applications. We observe that in many scenarios, the relationships between different sensor measurements (e.g., location and acceleration) are analytically described by laws of physics (e.g., second-order differential equation). By incorporating such physics constraints, we can guide the denoising process to improve even in the absence of ground truth data. In light of this, we design a physics-informed denoising model that leverages the inherent algebraic relationships between different measurements governed by the underlying physics. By obviating the need for ground truth clean data, our method offers a practical denoising solution for real-world applications. We conducted experiments in various domains, including inertial navigation, CO2 monitoring, and HVAC control, and achieved state-of-the-art performance compared with existing denoising methods. Our method can denoise data in real time (4ms for a sequence of 1s) for low-cost noisy sensors and produces results that closely align with those from high-precision, high-cost alternatives, leading to an efficient, cost-effective approach for more accurate sensor-based systems.
<div id='section'>Paperid: <span id='pid'>274, <a href='https://arxiv.org/pdf/2309.07946.pdf' target='_blank'>https://arxiv.org/pdf/2309.07946.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dimitrios G. Patsatzis, Gianluca Fabiani, Lucia Russo, Constantinos Siettos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.07946">Slow Invariant Manifolds of Singularly Perturbed Systems via Physics-Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a physics-informed machine-learning (PIML) approach for the approximation of slow invariant manifolds (SIMs) of singularly perturbed systems, providing functionals in an explicit form that facilitate the construction and numerical integration of reduced order models (ROMs). The proposed scheme solves a partial differential equation corresponding to the invariance equation (IE) within the Geometric Singular Perturbation Theory (GSPT) framework. For the solution of the IE, we used two neural network structures, namely feedforward neural networks (FNNs), and random projection neural networks (RPNNs), with symbolic differentiation for the computation of the gradients required for the learning process. The efficiency of our PIML method is assessed via three benchmark problems, namely the Michaelis-Menten, the target mediated drug disposition reaction mechanism, and the 3D Sel'kov model. We show that the proposed PIML scheme provides approximations, of equivalent or even higher accuracy, than those provided by other traditional GSPT-based methods, and importantly, for any practical purposes, it is not affected by the magnitude of the perturbation parameter. This is of particular importance, as there are many systems for which the gap between the fast and slow timescales is not that big, but still ROMs can be constructed. A comparison of the computational costs between symbolic, automatic and numerical approximation of the required derivatives in the learning process is also provided.
<div id='section'>Paperid: <span id='pid'>275, <a href='https://arxiv.org/pdf/2306.13881.pdf' target='_blank'>https://arxiv.org/pdf/2306.13881.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenguang Duan, Yuling Jiao, Xiliang Lu, Jerry Zhijian Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13881">Current density impedance imaging with PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce CDII-PINNs, a computationally efficient method for solving CDII using PINNs in the framework of Tikhonov regularization. This method constructs a physics-informed loss function by merging the regularized least-squares output functional with an underlying differential equation, which describes the relationship between the conductivity and voltage. A pair of neural networks representing the conductivity and voltage, respectively, are coupled by this loss function. Then, minimizing the loss function provides a reconstruction. A rigorous theoretical guarantee is provided. We give an error analysis for CDII-PINNs and establish a convergence rate, based on prior selected neural network parameters in terms of the number of samples. The numerical simulations demonstrate that CDII-PINNs are efficient, accurate and robust to noise levels ranging from $1\%$ to $20\%$.
<div id='section'>Paperid: <span id='pid'>276, <a href='https://arxiv.org/pdf/2305.08757.pdf' target='_blank'>https://arxiv.org/pdf/2305.08757.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cooper Lorsung, Zijie Li, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.08757">Physics Informed Token Transformer for Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving Partial Differential Equations (PDEs) is the core of many fields of science and engineering. While classical approaches are often prohibitively slow, machine learning models often fail to incorporate complete system information. Over the past few years, transformers have had a significant impact on the field of Artificial Intelligence and have seen increased usage in PDE applications. However, despite their success, transformers currently lack integration with physics and reasoning. This study aims to address this issue by introducing PITT: Physics Informed Token Transformer. The purpose of PITT is to incorporate the knowledge of physics by embedding partial differential equations (PDEs) into the learning process. PITT uses an equation tokenization method to learn an analytically-driven numerical update operator. By tokenizing PDEs and embedding partial derivatives, the transformer models become aware of the underlying knowledge behind physical processes. To demonstrate this, PITT is tested on challenging 1D and 2D PDE neural operator prediction tasks. The results show that PITT outperforms popular neural operator models and has the ability to extract physically relevant information from governing equations.
<div id='section'>Paperid: <span id='pid'>277, <a href='https://arxiv.org/pdf/2303.15849.pdf' target='_blank'>https://arxiv.org/pdf/2303.15849.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuling Jiao, Di Li, Xiliang Lu, Jerry Zhijian Yang, Cheng Yuan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.15849">GAS: A Gaussian Mixture Distribution-Based Adaptive Sampling Method for PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the recent study of deep learning in scientific computation, the Physics-Informed Neural Networks (PINNs) method has drawn widespread attention for solving Partial Differential Equations (PDEs). Compared to traditional methods, PINNs can efficiently handle high-dimensional problems, but the accuracy is relatively low, especially for highly irregular problems. Inspired by the idea of adaptive finite element methods and incremental learning, we propose GAS, a Gaussian mixture distribution-based adaptive sampling method for PINNs. During the training procedure, GAS uses the current residual information to generate a Gaussian mixture distribution for the sampling of additional points, which are then trained together with historical data to speed up the convergence of the loss and achieve higher accuracy. Several numerical simulations on 2D and 10D problems show that GAS is a promising method that achieves state-of-the-art accuracy among deep solvers, while being comparable with traditional numerical solvers.
<div id='section'>Paperid: <span id='pid'>278, <a href='https://arxiv.org/pdf/2211.14680.pdf' target='_blank'>https://arxiv.org/pdf/2211.14680.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dule Shu, Zijie Li, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.14680">A Physics-informed Diffusion Model for High-fidelity Flow Field Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models are gaining increasing popularity in the domain of fluid dynamics for their potential to accelerate the production of high-fidelity computational fluid dynamics data. However, many recently proposed machine learning models for high-fidelity data reconstruction require low-fidelity data for model training. Such requirement restrains the application performance of these models, since their data reconstruction accuracy would drop significantly if the low-fidelity input data used in model test has a large deviation from the training data. To overcome this restraint, we propose a diffusion model which only uses high-fidelity data at training. With different configurations, our model is able to reconstruct high-fidelity data from either a regular low-fidelity sample or a sparsely measured sample, and is also able to gain an accuracy increase by using physics-informed conditioning information from a known partial differential equation when that is available. Experimental results demonstrate that our model can produce accurate reconstruction results for 2d turbulent flows based on different input sources without retraining.
<div id='section'>Paperid: <span id='pid'>279, <a href='https://arxiv.org/pdf/2203.05337.pdf' target='_blank'>https://arxiv.org/pdf/2203.05337.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gianluca Fabiani, Evangelos Galaris, Lucia Russo, Constantinos Siettos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.05337">Parsimonious Physics-Informed Random Projection Neural Networks for Initial-Value Problems of ODEs and index-1 DAEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We address a physics-informed neural network based on the concept of random projections for the numerical solution of IVPs of nonlinear ODEs in linear-implicit form and index-1 DAEs, which may also arise from the spatial discretization of PDEs. The scheme has a single hidden layer with appropriately randomly parametrized Gaussian kernels and a linear output layer, while the internal weights are fixed to ones. The unknown weights between the hidden and output layer are computed by Newton's iterations, using the Moore-Penrose pseudoinverse for low to medium, and sparse QR decomposition with regularization for medium to large scale systems. To deal with stiffness and sharp gradients, we propose a variable step size scheme for adjusting the interval of integration and address a continuation method for providing good initial guesses for the Newton iterations. Based on previous works on random projections, we prove the approximation capability of the scheme for ODEs in the canonical form and index-1 DAEs in the semiexplicit form. The optimal bounds of the uniform distribution are parsimoniously chosen based on the bias-variance trade-off. The performance of the scheme is assessed through seven benchmark problems: four index-1 DAEs, the Robertson model, a model of five DAEs describing the motion of a bead, a model of six DAEs describing a power discharge control problem, the chemical Akzo Nobel problem and three stiff problems, the Belousov-Zhabotinsky, the Allen-Cahn PDE and the Kuramoto-Sivashinsky PDE. The efficiency of the scheme is compared with three solvers ode23t, ode23s, ode15s of the MATLAB ODE suite. Our results show that the proposed scheme outperforms the stiff solvers in several cases, especially in regimes where high stiffness or sharp gradients arise in terms of numerical accuracy, while the computational costs are for any practical purposes comparable.
<div id='section'>Paperid: <span id='pid'>280, <a href='https://arxiv.org/pdf/2509.24697.pdf' target='_blank'>https://arxiv.org/pdf/2509.24697.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Evelyn D'Elia, Paolo Maria Viceconte, Lorenzo Rapetti, Diego Ferigo, Giulio Romualdi, Giuseppe L'Erario, Raffaello Camoriano, Daniele Pucci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24697">Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent trends in humanoid robot control have successfully employed imitation learning to enable the learned generation of smooth, human-like trajectories from human data. While these approaches make more realistic motions possible, they are limited by the amount of available motion data, and do not incorporate prior knowledge about the physical laws governing the system and its interactions with the environment. Thus they may violate such laws, leading to divergent trajectories and sliding contacts which limit real-world stability. We address such limitations via a two-pronged learning strategy which leverages the known physics of the system and fundamental control principles. First, we encode physics priors during supervised imitation learning to promote trajectory feasibility. Second, we minimize drift at inference time by applying a proportional-integral controller directly to the generated output state. We validate our method on various locomotion behaviors for the ergoCub humanoid robot, where a physics-informed loss encourages zero contact foot velocity. Our experiments demonstrate that the proposed approach is compatible with multiple controllers on a real robot and significantly improves the accuracy and physical constraint conformity of generated trajectories.
<div id='section'>Paperid: <span id='pid'>281, <a href='https://arxiv.org/pdf/2508.07536.pdf' target='_blank'>https://arxiv.org/pdf/2508.07536.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tasfiq E. Alam, Md Manjurul Ahsan, Shivakumar Raman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07536">Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and interpretable bearing fault classification is critical for ensuring the reliability of rotating machinery, particularly under variable operating conditions where domain shifts can significantly degrade model performance. This study proposes a physics-informed multimodal convolutional neural network (CNN) with a late fusion architecture, integrating vibration and motor current signals alongside a dedicated physics-based feature extraction branch. The model incorporates a novel physics-informed loss function that penalizes physically implausible predictions based on characteristic bearing fault frequencies - Ball Pass Frequency Outer (BPFO) and Ball Pass Frequency Inner (BPFI) - derived from bearing geometry and shaft speed. Comprehensive experiments on the Paderborn University dataset demonstrate that the proposed physics-informed approach consistently outperforms a non-physics-informed baseline, achieving higher accuracy, reduced false classifications, and improved robustness across multiple data splits. To address performance degradation under unseen operating conditions, three transfer learning (TL) strategies - Target-Specific Fine-Tuning (TSFT), Layer-Wise Adaptation Strategy (LAS), and Hybrid Feature Reuse (HFR) - are evaluated. Results show that LAS yields the best generalization, with additional performance gains when combined with physics-informed modeling. Validation on the KAIST bearing dataset confirms the framework's cross-dataset applicability, achieving up to 98 percent accuracy. Statistical hypothesis testing further verifies significant improvements (p < 0.01) in classification performance. The proposed framework demonstrates the potential of integrating domain knowledge with data-driven learning to achieve robust, interpretable, and generalizable fault diagnosis for real-world industrial applications.
<div id='section'>Paperid: <span id='pid'>282, <a href='https://arxiv.org/pdf/2507.10105.pdf' target='_blank'>https://arxiv.org/pdf/2507.10105.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ines Sorrentino, Giulio Romualdi, Lorenzo Moretti, Silvio Traversaro, Daniele Pucci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10105">Physics-Informed Neural Networks with Unscented Kalman Filter for Sensorless Joint Torque Estimation in Humanoid Robots</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel framework for whole-body torque control of humanoid robots without joint torque sensors, designed for systems with electric motors and high-ratio harmonic drives. The approach integrates Physics-Informed Neural Networks (PINNs) for friction modeling and Unscented Kalman Filtering (UKF) for joint torque estimation, within a real-time torque control architecture. PINNs estimate nonlinear static and dynamic friction from joint and motor velocity readings, capturing effects like motor actuation without joint movement. The UKF utilizes PINN-based friction estimates as direct measurement inputs, improving torque estimation robustness. Experimental validation on the ergoCub humanoid robot demonstrates improved torque tracking accuracy, enhanced energy efficiency, and superior disturbance rejection compared to the state-of-the-art Recursive Newton-Euler Algorithm (RNEA), using a dynamic balancing experiment. The framework's scalability is shown by consistent performance across robots with similar hardware but different friction characteristics, without re-identification. Furthermore, a comparative analysis with position control highlights the advantages of the proposed torque control approach. The results establish the method as a scalable and practical solution for sensorless torque control in humanoid robots, ensuring torque tracking, adaptability, and stability in dynamic environments.
<div id='section'>Paperid: <span id='pid'>283, <a href='https://arxiv.org/pdf/2505.22861.pdf' target='_blank'>https://arxiv.org/pdf/2505.22861.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlota ParÃ©s-Morlans, Michelle Yi, Claire Chen, Sarah A. Wu, Rika Antonova, Tobias Gerstenberg, Jeannette Bohg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22861">Causal-PIK: Causality-based Physical Reasoning with a Physics-Informed Kernel</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tasks that involve complex interactions between objects with unknown dynamics make planning before execution difficult. These tasks require agents to iteratively improve their actions after actively exploring causes and effects in the environment. For these type of tasks, we propose Causal-PIK, a method that leverages Bayesian optimization to reason about causal interactions via a Physics-Informed Kernel to help guide efficient search for the best next action. Experimental results on Virtual Tools and PHYRE physical reasoning benchmarks show that Causal-PIK outperforms state-of-the-art results, requiring fewer actions to reach the goal. We also compare Causal-PIK to human studies, including results from a new user study we conducted on the PHYRE benchmark. We find that Causal-PIK remains competitive on tasks that are very challenging, even for human problem-solvers.
<div id='section'>Paperid: <span id='pid'>284, <a href='https://arxiv.org/pdf/2505.20300.pdf' target='_blank'>https://arxiv.org/pdf/2505.20300.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenxi Wu, Juan Diego Toscano, Khemraj Shukla, Yingjie Chen, Ali Shahmohammadi, Edward Raymond, Thomas Toupy, Neda Nazemifard, Charles Papageorgiou, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20300">FMEnets: Flow, Material, and Energy networks for non-ideal plug flow reactor design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose FMEnets, a physics-informed machine learning framework for the design and analysis of non-ideal plug flow reactors. FMEnets integrates the fundamental governing equations (Navier-Stokes for fluid flow, material balance for reactive species transport, and energy balance for temperature distribution) into a unified multi-scale network model. The framework is composed of three interconnected sub-networks with independent optimizers that enable both forward and inverse problem-solving. In the forward mode, FMEnets predicts velocity, pressure, species concentrations, and temperature profiles using only inlet and outlet information. In the inverse mode, FMEnets utilizes sparse multi-residence-time measurements to simultaneously infer unknown kinetic parameters and states. FMEnets can be implemented either as FME-PINNs, which employ conventional multilayer perceptrons, or as FME-KANs, based on Kolmogorov-Arnold Networks. Comprehensive ablation studies highlight the critical role of the FMEnets architecture in achieving accurate predictions. Specifically, FME-KANs are more robust to noise than FME-PINNs, although both representations are comparable in accuracy and speed in noise-free conditions. The proposed framework is applied to three different sets of reaction scenarios and is compared with finite element simulations. FMEnets effectively captures the complex interactions, achieving relative errors less than 2.5% for the unknown kinetic parameters. The new network framework not only provides a computationally efficient alternative for reactor design and optimization, but also opens new avenues for integrating empirical correlations, limited and noisy experimental data, and fundamental physical equations to guide reactor design.
<div id='section'>Paperid: <span id='pid'>285, <a href='https://arxiv.org/pdf/2505.16373.pdf' target='_blank'>https://arxiv.org/pdf/2505.16373.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ge Meng, Zhongnan Cai, Jingyan Tu, Yingying Wang, Chenxin Li, Yue Huang, Xinghao Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16373">PCMamba: Physics-Informed Cross-Modal State Space Model for Dual-Camera Compressive Hyperspectral Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Panchromatic (PAN) -assisted Dual-Camera Compressive Hyperspectral Imaging (DCCHI) is a key technology in snapshot hyperspectral imaging. Existing research primarily focuses on exploring spectral information from 2D compressive measurements and spatial information from PAN images in an explicit manner, leading to a bottleneck in HSI reconstruction. Various physical factors, such as temperature, emissivity, and multiple reflections between objects, play a critical role in the process of a sensor acquiring hyperspectral thermal signals. Inspired by this, we attempt to investigate the interrelationships between physical properties to provide deeper theoretical insights for HSI reconstruction. In this paper, we propose a Physics-Informed Cross-Modal State Space Model Network (PCMamba) for DCCHI, which incorporates the forward physical imaging process of HSI into the linear complexity of Mamba to facilitate lightweight and high-quality HSI reconstruction. Specifically, we analyze the imaging process of hyperspectral thermal signals to enable the network to disentangle the three key physical properties-temperature, emissivity, and texture. By fully exploiting the potential information embedded in 2D measurements and PAN images, the HSIs are reconstructed through a physics-driven synthesis process. Furthermore, we design a Cross-Modal Scanning Mamba Block (CSMB) that introduces inter-modal pixel-wise interaction with positional inductive bias by cross-scanning the backbone features and PAN features. Extensive experiments conducted on both real and simulated datasets demonstrate that our method significantly outperforms SOTA methods in both quantitative and qualitative metrics.
<div id='section'>Paperid: <span id='pid'>286, <a href='https://arxiv.org/pdf/2504.09069.pdf' target='_blank'>https://arxiv.org/pdf/2504.09069.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuning Sun, Yu Zhang, Chen Wu, Dianjie Lu, Dianjie Lu, Guijuan Zhan, Yang Weng, Zhuoran Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.09069">UniFlowRestore: A General Video Restoration Framework via Flow Matching and Prompt Guidance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Video imaging is often affected by complex degradations such as blur, noise, and compression artifacts. Traditional restoration methods follow a "single-task single-model" paradigm, resulting in poor generalization and high computational cost, limiting their applicability in real-world scenarios with diverse degradation types. We propose UniFlowRestore, a general video restoration framework that models restoration as a time-continuous evolution under a prompt-guided and physics-informed vector field. A physics-aware backbone PhysicsUNet encodes degradation priors as potential energy, while PromptGenerator produces task-relevant prompts as momentum. These components define a Hamiltonian system whose vector field integrates inertial dynamics, decaying physical gradients, and prompt-based guidance. The system is optimized via a fixed-step ODE solver to achieve efficient and unified restoration across tasks. Experiments show that UniFlowRestore delivers stateof-the-art performance with strong generalization and efficiency. Quantitative results demonstrate that UniFlowRestore achieves state-of-the-art performance, attaining the highest PSNR (33.89 dB) and SSIM (0.97) on the video denoising task, while maintaining top or second-best scores across all evaluated tasks.
<div id='section'>Paperid: <span id='pid'>287, <a href='https://arxiv.org/pdf/2504.07379.pdf' target='_blank'>https://arxiv.org/pdf/2504.07379.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nazanin Ahmadi Daryakenari, Khemraj Shukla, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07379">Representation Meets Optimization: Training PINNs and PIKANs for Gray-Box Discovery in Systems Pharmacology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Kolmogorov-Arnold Networks (PIKANs) are gaining attention as an effective counterpart to the original multilayer perceptron-based Physics-Informed Neural Networks (PINNs). Both representation models can address inverse problems and facilitate gray-box system identification. However, a comprehensive understanding of their performance in terms of accuracy and speed remains underexplored. In particular, we introduce a modified PIKAN architecture, tanh-cPIKAN, which is based on Chebyshev polynomials for parametrization of the univariate functions with an extra nonlinearity for enhanced performance. We then present a systematic investigation of how choices of the optimizer, representation, and training configuration influence the performance of PINNs and PIKANs in the context of systems pharmacology modeling. We benchmark a wide range of first-order, second-order, and hybrid optimizers, including various learning rate schedulers. We use the new Optax library to identify the most effective combinations for learning gray-boxes under ill-posed, non-unique, and data-sparse conditions. We examine the influence of model architecture (MLP vs. KAN), numerical precision (single vs. double), the need for warm-up phases for second-order methods, and sensitivity to the initial learning rate. We also assess the optimizer scalability for larger models and analyze the trade-offs introduced by JAX in terms of computational efficiency and numerical accuracy. Using two representative systems pharmacology case studies - a pharmacokinetics model and a chemotherapy drug-response model - we offer practical guidance on selecting optimizers and representation models/architectures for robust and efficient gray-box discovery. Our findings provide actionable insights for improving the training of physics-informed networks in biomedical applications and beyond.
<div id='section'>Paperid: <span id='pid'>288, <a href='https://arxiv.org/pdf/2504.03955.pdf' target='_blank'>https://arxiv.org/pdf/2504.03955.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinling Yu, Ziyue Liu, Hai Li, Yixing Li, Xin Ai, Zhiyu Zeng, Ian Young, Zheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03955">DeepOHeat-v1: Efficient Operator Learning for Fast and Trustworthy Thermal Simulation and Optimization in 3D-IC Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Thermal analysis is crucial in three-dimensional integrated circuit (3D-IC) design due to increased power density and complex heat dissipation paths. Although operator learning frameworks such as DeepOHeat have demonstrated promising preliminary results in accelerating thermal simulation, they face critical limitations in prediction capability for multi-scale thermal patterns, training efficiency, and trustworthiness of results during design optimization. This paper presents DeepOHeat-v1, an enhanced physics-informed operator learning framework that addresses these challenges through three key innovations. First, we integrate Kolmogorov-Arnold Networks with learnable activation functions as trunk networks, enabling an adaptive representation of multi-scale thermal patterns. This approach achieves a $1.25\times$ and $6.29\times$ reduction in error in two representative test cases. Second, we introduce a separable training method that decomposes the basis function along the coordinate axes, achieving $62\times$ training speedup and $31\times$ GPU memory reduction in our baseline case, and enabling thermal analysis at resolutions previously infeasible due to GPU memory constraints. Third, we propose a confidence score to evaluate the trustworthiness of the predicted results, and further develop a hybrid optimization workflow that combines operator learning with finite difference (FD) using Generalized Minimal Residual (GMRES) method for incremental solution refinement, enabling efficient and trustworthy thermal optimization. Experimental results demonstrate that DeepOHeat-v1 achieves accuracy comparable to optimization using high-fidelity finite difference solvers, while speeding up the entire optimization process by $70.6\times$ in our test cases, effectively minimizing the peak temperature through optimal placement of heat-generating components.
<div id='section'>Paperid: <span id='pid'>289, <a href='https://arxiv.org/pdf/2502.12384.pdf' target='_blank'>https://arxiv.org/pdf/2502.12384.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yequan Zhao, Xinling Yu, Xian Xiao, Zhixiong Chen, Ziyue Liu, Geza Kurczveil, Raymond G. Beausoleil, Sijia Liu, Zheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12384">Scalable Back-Propagation-Free Training of Optical Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have shown promise in solving partial differential equations (PDEs), with growing interest in their energy-efficient, real-time training on edge devices. Photonic computing offers a potential solution to achieve this goal because of its ultra-high operation speed. However, the lack of photonic memory and the large device sizes prevent training real-size PINNs on photonic chips. This paper proposes a completely back-propagation-free (BP-free) and highly salable framework for training real-size PINNs on silicon photonic platforms. Our approach involves three key innovations: (1) a sparse-grid Stein derivative estimator to avoid the BP in the loss evaluation of a PINN, (2) a dimension-reduced zeroth-order optimization via tensor-train decomposition to achieve better scalability and convergence in BP-free training, and (3) a scalable on-chip photonic PINN training accelerator design using photonic tensor cores. We validate our numerical methods on both low- and high-dimensional PDE benchmarks. Through circuit simulation based on real device parameters, we further demonstrate the significant performance benefit (e.g., real-time training, huge chip area reduction) of our photonic accelerator.
<div id='section'>Paperid: <span id='pid'>290, <a href='https://arxiv.org/pdf/2501.16371.pdf' target='_blank'>https://arxiv.org/pdf/2501.16371.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elham Kiyani, Khemraj Shukla, Jorge F. UrbÃ¡n, JÃ©rÃ´me Darbon, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16371">Optimizing the Optimizer for Physics-Informed Neural Networks and Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have revolutionized the computation of PDE solutions by integrating partial differential equations (PDEs) into the neural network's training process as soft constraints, becoming an important component of the scientific machine learning (SciML) ecosystem. More recently, physics-informed Kolmogorv-Arnold networks (PIKANs) have also shown to be effective and comparable in accuracy with PINNs. In their current implementation, both PINNs and PIKANs are mainly optimized using first-order methods like Adam, as well as quasi-Newton methods such as BFGS and its low-memory variant, L-BFGS. However, these optimizers often struggle with highly non-linear and non-convex loss landscapes, leading to challenges such as slow convergence, local minima entrapment, and (non)degenerate saddle points. In this study, we investigate the performance of Self-Scaled BFGS (SSBFGS), Self-Scaled Broyden (SSBroyden) methods and other advanced quasi-Newton schemes, including BFGS and L-BFGS with different line search strategies. These methods dynamically rescale updates based on historical gradient information, thus enhancing training efficiency and accuracy. We systematically compare these optimizers using both PINNs and PIKANs on key challenging PDEs, including the Burgers, Allen-Cahn, Kuramoto-Sivashinsky, Ginzburg-Landau, and Stokes equations. Additionally, we evaluate the performance of SSBFGS and SSBroyden for Deep Operator Network (DeepONet) architectures, demonstrating their effectiveness for data-driven operator learning. Our findings provide state-of-the-art results with orders-of-magnitude accuracy improvements without the use of adaptive weights or any other enhancements typically employed in PINNs.
<div id='section'>Paperid: <span id='pid'>291, <a href='https://arxiv.org/pdf/2410.12685.pdf' target='_blank'>https://arxiv.org/pdf/2410.12685.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ines Sorrentino, Giulio Romualdi, Fabio Bergonti, Giuseppe Ä½Erario, Silvio Traversaro, Daniele Pucci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12685">Physics-Informed Learning for the Friction Modeling of High-Ratio Harmonic Drives</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a scalable method for friction identification in robots equipped with electric motors and high-ratio harmonic drives, utilizing Physics-Informed Neural Networks (PINN). This approach eliminates the need for dedicated setups and joint torque sensors by leveraging the roboÅ¥s intrinsic model and state data. We present a comprehensive pipeline that includes data acquisition, preprocessing, ground truth generation, and model identification. The effectiveness of the PINN-based friction identification is validated through extensive testing on two different joints of the humanoid robot ergoCub, comparing its performance against traditional static friction models like the Coulomb-viscous and Stribeck-Coulomb-viscous models. Integrating the identified PINN-based friction models into a two-layer torque control architecture enhances real-time friction compensation. The results demonstrate significant improvements in control performance and reductions in energy losses, highlighting the scalability and robustness of the proposed method, also for application across a large number of joints as in the case of humanoid robots.
<div id='section'>Paperid: <span id='pid'>292, <a href='https://arxiv.org/pdf/2410.06442.pdf' target='_blank'>https://arxiv.org/pdf/2410.06442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingu Kang, Dongseok Lee, Woojin Cho, Jaehyeon Park, Kookjin Lee, Anthony Gruber, Youngjoon Hong, Noseong Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06442">MaD-Scientist: AI-based Scientist solving Convection-Diffusion-Reaction Equations Using Massive PINN-Based Prior Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs), like ChatGPT, have shown that even trained with noisy prior data, they can generalize effectively to new tasks through in-context learning (ICL) and pre-training techniques. Motivated by this, we explore whether a similar approach can be applied to scientific foundation models (SFMs). Our methodology is structured as follows: (i) we collect low-cost physics-informed neural network (PINN)-based approximated prior data in the form of solutions to partial differential equations (PDEs) constructed through an arbitrary linear combination of mathematical dictionaries; (ii) we utilize Transformer architectures with self and cross-attention mechanisms to predict PDE solutions without knowledge of the governing equations in a zero-shot setting; (iii) we provide experimental evidence on the one-dimensional convection-diffusion-reaction equation, which demonstrate that pre-training remains robust even with approximated prior data, with only marginal impacts on test accuracy. Notably, this finding opens the path to pre-training SFMs with realistic, low-cost data instead of (or in conjunction with) numerical high-cost data. These results support the conjecture that SFMs can improve in a manner similar to LLMs, where fully cleaning the vast set of sentences crawled from the Internet is nearly impossible.
<div id='section'>Paperid: <span id='pid'>293, <a href='https://arxiv.org/pdf/2410.04001.pdf' target='_blank'>https://arxiv.org/pdf/2410.04001.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Woojin Cho, Kookjin Lee, Noseong Park, Donsub Rim, Gerrit Welper
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04001">FastLRNR and Sparse Physics Informed Backpropagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Sparse Physics Informed Backpropagation (SPInProp), a new class of methods for accelerating backpropagation for a specialized neural network architecture called Low Rank Neural Representation (LRNR). The approach exploits the low rank structure within LRNR and constructs a reduced neural network approximation that is much smaller in size. We call the smaller network FastLRNR. We show that backpropagation of FastLRNR can be substituted for that of LRNR, enabling a significant reduction in complexity. We apply SPInProp to a physics informed neural networks framework and demonstrate how the solution of parametrized partial differential equations is accelerated.
<div id='section'>Paperid: <span id='pid'>294, <a href='https://arxiv.org/pdf/2408.09446.pdf' target='_blank'>https://arxiv.org/pdf/2408.09446.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Woojin Cho, Minju Jo, Haksoo Lim, Kookjin Lee, Dongeun Lee, Sanghyun Hong, Noseong Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09446">Parameterized Physics-informed Neural Networks for Parameterized PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Complex physical systems are often described by partial differential equations (PDEs) that depend on parameters such as the Reynolds number in fluid mechanics. In applications such as design optimization or uncertainty quantification, solutions of those PDEs need to be evaluated at numerous points in the parameter space. While physics-informed neural networks (PINNs) have emerged as a new strong competitor as a surrogate, their usage in this scenario remains underexplored due to the inherent need for repetitive and time-consuming training. In this paper, we address this problem by proposing a novel extension, parameterized physics-informed neural networks (P$^2$INNs). P$^2$INNs enable modeling the solutions of parameterized PDEs via explicitly encoding a latent representation of PDE parameters. With the extensive empirical evaluation, we demonstrate that P$^2$INNs outperform the baselines both in accuracy and parameter efficiency on benchmark 1D and 2D parameterized PDEs and are also effective in overcoming the known "failure modes".
<div id='section'>Paperid: <span id='pid'>295, <a href='https://arxiv.org/pdf/2408.07110.pdf' target='_blank'>https://arxiv.org/pdf/2408.07110.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julian Suk, Dieuwertje Alblas, Barbara A. Hutten, Albert Wiegman, Christoph Brune, Pim van Ooij, Jelmer M. Wolterink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.07110">Physics-informed graph neural networks for flow field estimation in carotid arteries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hemodynamic quantities are valuable biomedical risk factors for cardiovascular pathology such as atherosclerosis. Non-invasive, in-vivo measurement of these quantities can only be performed using a select number of modalities that are not widely available, such as 4D flow magnetic resonance imaging (MRI). In this work, we create a surrogate model for hemodynamic flow field estimation, powered by machine learning. We train graph neural networks that include priors about the underlying symmetries and physics, limiting the amount of data required for training. This allows us to train the model using moderately-sized, in-vivo 4D flow MRI datasets, instead of large in-silico datasets obtained by computational fluid dynamics (CFD), as is the current standard. We create an efficient, equivariant neural network by combining the popular PointNet++ architecture with group-steerable layers. To incorporate the physics-informed priors, we derive an efficient discretisation scheme for the involved differential operators. We perform extensive experiments in carotid arteries and show that our model can accurately estimate low-noise hemodynamic flow fields in the carotid artery. Moreover, we show how the learned relation between geometry and hemodynamic quantities transfers to 3D vascular models obtained using a different imaging modality than the training data. This shows that physics-informed graph neural networks can be trained using 4D flow MRI data to estimate blood flow in unseen carotid artery geometries.
<div id='section'>Paperid: <span id='pid'>296, <a href='https://arxiv.org/pdf/2405.17487.pdf' target='_blank'>https://arxiv.org/pdf/2405.17487.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Deepak Bhoriya, Dinshaw S. Balsara, Vladimir Florinski, Harish Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.17487">Going Beyond the MHD Approximation: Physics-Based Numerical Solution of the CGL Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a new numerical model for solving the Chew-Goldberger-Low system of equations describing a bi-Maxwellian plasma in a magnetic field. Heliospheric and geospace environments are often observed to be in an anisotropic state with distinctly different parallel and perpendicular pressure components. The CGL system represents the simplest leading order correction to the common isotropic MHD model that still allows to incorporate the latter's most desirable features. However, the CGL system presents several numerical challenges: the system is not in conservation form, the source terms are stiff, and unlike MHD it is prone to a loss of hyperbolicity if the parallel and perpendicular pressures become too different. The usual cure is to bring the parallel and perpendicular pressures closer to one another; but that has usually been done in an ad hoc manner. We present a physics-informed method of pressure relaxation based on the idea of pitch-angle scattering that keeps the numerical system hyperbolic and naturally leads to zero anisotropy in the limit of very large plasma beta. Numerical codes based on the CGL equations can, therefore, be made to function robustly for any magnetic field strength, including the limit where the magnetic field approaches zero. The capabilities of our new algorithm are demonstrated using several stringent test problems that provide a comparison of the CGL equations in the weakly and strongly collisional limits. This includes a test problem that mimics interaction of a shock with a magnetospheric environment in 2D.
<div id='section'>Paperid: <span id='pid'>297, <a href='https://arxiv.org/pdf/2403.12764.pdf' target='_blank'>https://arxiv.org/pdf/2403.12764.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Konrad Mundinger, Max Zimmer, Sebastian Pokutta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.12764">Neural Parameter Regression for Explicit Representations of PDE Solution Operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Neural Parameter Regression (NPR), a novel framework specifically developed for learning solution operators in Partial Differential Equations (PDEs). Tailored for operator learning, this approach surpasses traditional DeepONets (Lu et al., 2021) by employing Physics-Informed Neural Network (PINN, Raissi et al., 2019) techniques to regress Neural Network (NN) parameters. By parametrizing each solution based on specific initial conditions, it effectively approximates a mapping between function spaces. Our method enhances parameter efficiency by incorporating low-rank matrices, thereby boosting computational efficiency and scalability. The framework shows remarkable adaptability to new initial and boundary conditions, allowing for rapid fine-tuning and inference, even in cases of out-of-distribution examples.
<div id='section'>Paperid: <span id='pid'>298, <a href='https://arxiv.org/pdf/2402.00712.pdf' target='_blank'>https://arxiv.org/pdf/2402.00712.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan Nathaniel, Yongquan Qu, Tung Nguyen, Sungduk Yu, Julius Busecke, Aditya Grover, Pierre Gentine
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00712">ChaosBench: A Multi-Channel, Physics-Based Benchmark for Subseasonal-to-Seasonal Climate Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of climate in the subseasonal-to-seasonal scale is crucial for disaster preparedness and robust decision making amidst climate change. Yet, forecasting beyond the weather timescale is challenging because it deals with problems other than initial condition, including boundary interaction, butterfly effect, and our inherent lack of physical understanding. At present, existing benchmarks tend to have shorter forecasting range of up-to 15 days, do not include a wide range of operational baselines, and lack physics-based constraints for explainability. Thus, we propose ChaosBench, a challenging benchmark to extend the predictability range of data-driven weather emulators to S2S timescale. First, ChaosBench is comprised of variables beyond the typical surface-atmospheric ERA5 to also include ocean, ice, and land reanalysis products that span over 45 years to allow for full Earth system emulation that respects boundary conditions. We also propose physics-based, in addition to deterministic and probabilistic metrics, to ensure a physically-consistent ensemble that accounts for butterfly effect. Furthermore, we evaluate on a diverse set of physics-based forecasts from four national weather agencies as baselines to our data-driven counterpart such as ViT/ClimaX, PanguWeather, GraphCast, and FourCastNetV2. Overall, we find methods originally developed for weather-scale applications fail on S2S task: their performance simply collapse to an unskilled climatology. Nonetheless, we outline and demonstrate several strategies that can extend the predictability range of existing weather emulators, including the use of ensembles, robust control of error propagation, and the use of physics-informed models. Our benchmark, datasets, and instructions are available at https://leap-stc.github.io/ChaosBench.
<div id='section'>Paperid: <span id='pid'>299, <a href='https://arxiv.org/pdf/2401.00413.pdf' target='_blank'>https://arxiv.org/pdf/2401.00413.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yequan Zhao, Xian Xiao, Xinling Yu, Ziyue Liu, Zhixiong Chen, Geza Kurczveil, Raymond G. Beausoleil, Zheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00413">Real-Time FJ/MAC PDE Solvers via Tensorized, Back-Propagation-Free Optical PINN Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving partial differential equations (PDEs) numerically often requires huge computing time, energy cost, and hardware resources in practical applications. This has limited their applications in many scenarios (e.g., autonomous systems, supersonic flows) that have a limited energy budget and require near real-time response. Leveraging optical computing, this paper develops an on-chip training framework for physics-informed neural networks (PINNs), aiming to solve high-dimensional PDEs with fJ/MAC photonic power consumption and ultra-low latency. Despite the ultra-high speed of optical neural networks, training a PINN on an optical chip is hard due to (1) the large size of photonic devices, and (2) the lack of scalable optical memory devices to store the intermediate results of back-propagation (BP). To enable realistic optical PINN training, this paper presents a scalable method to avoid the BP process. We also employ a tensor-compressed approach to improve the convergence and scalability of our optical PINN training. This training framework is designed with tensorized optical neural networks (TONN) for scalable inference acceleration and MZI phase-domain tuning for \textit{in-situ} optimization. Our simulation results of a 20-dim HJB PDE show that our photonic accelerator can reduce the number of MZIs by a factor of $1.17\times 10^3$, with only $1.36$ J and $1.15$ s to solve this equation. This is the first real-size optical PINN training framework that can be applied to solve high-dimensional PDEs.
<div id='section'>Paperid: <span id='pid'>300, <a href='https://arxiv.org/pdf/2310.09528.pdf' target='_blank'>https://arxiv.org/pdf/2310.09528.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Woojin Cho, Kookjin Lee, Donsub Rim, Noseong Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.09528">Hypernetwork-based Meta-Learning for Low-Rank Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In various engineering and applied science applications, repetitive numerical simulations of partial differential equations (PDEs) for varying input parameters are often required (e.g., aircraft shape optimization over many design parameters) and solvers are required to perform rapid execution. In this study, we suggest a path that potentially opens up a possibility for physics-informed neural networks (PINNs), emerging deep-learning-based solvers, to be considered as one such solver. Although PINNs have pioneered a proper integration of deep-learning and scientific computing, they require repetitive time-consuming training of neural networks, which is not suitable for many-query scenarios. To address this issue, we propose a lightweight low-rank PINNs containing only hundreds of model parameters and an associated hypernetwork-based meta-learning algorithm, which allows efficient approximation of solutions of PDEs for varying ranges of PDE input parameters. Moreover, we show that the proposed method is effective in overcoming a challenging issue, known as "failure modes" of PINNs.
<div id='section'>Paperid: <span id='pid'>301, <a href='https://arxiv.org/pdf/2310.01433.pdf' target='_blank'>https://arxiv.org/pdf/2310.01433.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nazanin Ahmadi Daryakenari, Mario De Florio, Khemraj Shukla, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.01433">AI-Aristotle: A Physics-Informed framework for Systems Biology Gray-Box Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discovering mathematical equations that govern physical and biological systems from observed data is a fundamental challenge in scientific research. We present a new physics-informed framework for parameter estimation and missing physics identification (gray-box) in the field of Systems Biology. The proposed framework -- named AI-Aristotle -- combines eXtreme Theory of Functional Connections (X-TFC) domain-decomposition and Physics-Informed Neural Networks (PINNs) with symbolic regression (SR) techniques for parameter discovery and gray-box identification. We test the accuracy, speed, flexibility and robustness of AI-Aristotle based on two benchmark problems in Systems Biology: a pharmacokinetics drug absorption model, and an ultradian endocrine model for glucose-insulin interactions. We compare the two machine learning methods (X-TFC and PINNs), and moreover, we employ two different symbolic regression techniques to cross-verify our results. While the current work focuses on the performance of AI-Aristotle based on synthetic data, it can equally handle noisy experimental data and can even be used for black-box identification in just a few minutes on a laptop. More broadly, our work provides insights into the accuracy, cost, scalability, and robustness of integrating neural networks with symbolic regressors, offering a comprehensive guide for researchers tackling gray-box identification challenges in complex dynamical systems in biomedicine and beyond.
<div id='section'>Paperid: <span id='pid'>302, <a href='https://arxiv.org/pdf/2309.15284.pdf' target='_blank'>https://arxiv.org/pdf/2309.15284.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keke Long, Zihao Sheng, Haotian Shi, Xiaopeng Li, Sikai Chen, Sue Ahn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.15284">A Physics Enhanced Residual Learning (PERL) Framework for Vehicle Trajectory Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In vehicle trajectory prediction, physics models and data-driven models are two predominant methodologies. However, each approach presents its own set of challenges: physics models fall short in predictability, while data-driven models lack interpretability. Addressing these identified shortcomings, this paper proposes a novel framework, the Physics-Enhanced Residual Learning (PERL) model. PERL integrates the strengths of physics-based and data-driven methods for traffic state prediction. PERL contains a physics model and a residual learning model. Its prediction is the sum of the physics model result and a predicted residual as a correction to it. It preserves the interpretability inherent to physics-based models and has reduced data requirements compared to data-driven methods. Experiments were conducted using a real-world vehicle trajectory dataset. We proposed a PERL model, with the Intelligent Driver Model (IDM) as its physics car-following model and Long Short-Term Memory (LSTM) as its residual learning model. We compare this PERL model with the physics car-following model, data-driven model, and other physics-informed neural network (PINN) models. The result reveals that PERL achieves better prediction with a small dataset, compared to the physics model, data-driven model, and PINN model. Second, the PERL model showed faster convergence during training, offering comparable performance with fewer training samples than the data-driven model and PINN model. Sensitivity analysis also proves comparable performance of PERL using another residual learning model and a physics car-following model.
<div id='section'>Paperid: <span id='pid'>303, <a href='https://arxiv.org/pdf/2308.15918.pdf' target='_blank'>https://arxiv.org/pdf/2308.15918.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuo-Xu Cui, Congcong Liu, Xiaohong Fan, Chentao Cao, Jing Cheng, Qingyong Zhu, Yuanyuan Liu, Sen Jia, Yihang Zhou, Haifeng Wang, Yanjie Zhu, Jianping Zhang, Qiegen Liu, Dong Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.15918">Physics-Informed DeepMRI: Bridging the Gap from Heat Diffusion to k-Space Interpolation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of parallel imaging (PI), alongside image-domain regularization methods, substantial research has been dedicated to exploring $k$-space interpolation. However, the interpretability of these methods remains an unresolved issue. Furthermore, these approaches currently face acceleration limitations that are comparable to those experienced by image-domain methods. In order to enhance interpretability and overcome the acceleration limitations, this paper introduces an interpretable framework that unifies both $k$-space interpolation techniques and image-domain methods, grounded in the physical principles of heat diffusion equations. Building upon this foundational framework, a novel $k$-space interpolation method is proposed. Specifically, we model the process of high-frequency information attenuation in $k$-space as a heat diffusion equation, while the effort to reconstruct high-frequency information from low-frequency regions can be conceptualized as a reverse heat equation. However, solving the reverse heat equation poses a challenging inverse problem. To tackle this challenge, we modify the heat equation to align with the principles of magnetic resonance PI physics and employ the score-based generative method to precisely execute the modified reverse heat diffusion. Finally, experimental validation conducted on publicly available datasets demonstrates the superiority of the proposed approach over traditional $k$-space interpolation methods, deep learning-based $k$-space interpolation methods, and conventional diffusion models in terms of reconstruction accuracy, particularly in high-frequency regions.
<div id='section'>Paperid: <span id='pid'>304, <a href='https://arxiv.org/pdf/2308.09858.pdf' target='_blank'>https://arxiv.org/pdf/2308.09858.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yequan Zhao, Xinling Yu, Zhixiong Chen, Ziyue Liu, Sijia Liu, Zheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09858">Tensor-Compressed Back-Propagation-Free Training for (Physics-Informed) Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Backward propagation (BP) is widely used to compute the gradients in neural network training. However, it is hard to implement BP on edge devices due to the lack of hardware and software resources to support automatic differentiation. This has tremendously increased the design complexity and time-to-market of on-device training accelerators. This paper presents a completely BP-free framework that only requires forward propagation to train realistic neural networks. Our technical contributions are three-fold. Firstly, we present a tensor-compressed variance reduction approach to greatly improve the scalability of zeroth-order (ZO) optimization, making it feasible to handle a network size that is beyond the capability of previous ZO approaches. Secondly, we present a hybrid gradient evaluation approach to improve the efficiency of ZO training. Finally, we extend our BP-free training framework to physics-informed neural networks (PINNs) by proposing a sparse-grid approach to estimate the derivatives in the loss function without using BP. Our BP-free training only loses little accuracy on the MNIST dataset compared with standard first-order training. We also demonstrate successful results in training a PINN for solving a 20-dim Hamiltonian-Jacobi-Bellman PDE. This memory-efficient and BP-free approach may serve as a foundation for the near-future on-device training on many resource-constraint platforms (e.g., FPGA, ASIC, micro-controllers, and photonic chips).
<div id='section'>Paperid: <span id='pid'>305, <a href='https://arxiv.org/pdf/2307.09142.pdf' target='_blank'>https://arxiv.org/pdf/2307.09142.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elham Kiyani, Mahdi Kooshkbaghi, Khemraj Shukla, Rahul Babu Koneru, Zhen Li, Luis Bravo, Anindya Ghoshal, George Em Karniadakis, Mikko Karttunen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.09142">Characterization of partial wetting by CMAS droplets using multiphase many-body dissipative particle dynamics and data-driven discovery based on PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The molten sand, a mixture of calcia, magnesia, alumina, and silicate, known as CMAS, is characterized by its high viscosity, density, and surface tension. The unique properties of CMAS make it a challenging material to deal with in high-temperature applications, requiring innovative solutions and materials to prevent its buildup and damage to critical equipment. Here, we use multiphase many-body dissipative particle dynamics (mDPD) simulations to study the wetting dynamics of highly viscous molten CMAS droplets. The simulations are performed in three dimensions, with varying initial droplet sizes and equilibrium contact angles. We propose a coarse parametric ordinary differential equation (ODE) that captures the spreading radius behavior of the CMAS droplets. The ODE parameters are then identified based on the Physics-Informed Neural Network (PINN) framework. Subsequently, the closed form dependency of parameter values found by PINN on the initial radii and contact angles are given using symbolic regression. Finally, we employ Bayesian PINNs (B-PINNs) to assess and quantify the uncertainty associated with the discovered parameters. In brief, this study provides insight into spreading dynamics of CMAS droplets by fusing simple parametric ODE modeling and state-of-the-art machine learning techniques.
<div id='section'>Paperid: <span id='pid'>306, <a href='https://arxiv.org/pdf/2305.10706.pdf' target='_blank'>https://arxiv.org/pdf/2305.10706.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elham Kiyani, Khemraj Shukla, George Em Karniadakis, Mikko Karttunen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.10706">A Framework Based on Symbolic Regression Coupled with eXtended Physics-Informed Neural Networks for Gray-Box Learning of Equations of Motion from Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a framework and an algorithm to uncover the unknown parts of nonlinear equations directly from data. The framework is based on eXtended Physics-Informed Neural Networks (X-PINNs), domain decomposition in space-time, but we augment the original X-PINN method by imposing flux continuity across the domain interfaces. The well-known Allen-Cahn equation is used to demonstrate the approach. The Frobenius matrix norm is used to evaluate the accuracy of the X-PINN predictions and the results show excellent performance. In addition, symbolic regression is employed to determine the closed form of the unknown part of the equation from the data, and the results confirm the accuracy of the X-PINNs based approach. To test the framework in a situation resembling real-world data, random noise is added to the datasets to mimic scenarios such as the presence of thermal noise or instrument errors. The results show that the framework is stable against significant amount of noise. As the final part, we determine the minimal amount of data required for training the neural network. The framework is able to predict the correct form and coefficients of the underlying dynamical equation when at least 50\% data is used for training.
<div id='section'>Paperid: <span id='pid'>307, <a href='https://arxiv.org/pdf/2302.11883.pdf' target='_blank'>https://arxiv.org/pdf/2302.11883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinling Yu, JosÃ© E. C. SerrallÃ©s, Ilias I. Giannakopoulos, Ziyue Liu, Luca Daniel, Riccardo Lattanzi, Zheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.11883">PIFON-EPT: MR-Based Electrical Property Tomography Using Physics-Informed Fourier Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose Physics-Informed Fourier Networks for Electrical Properties (EP) Tomography (PIFON-EPT), a novel deep learning-based method for EP reconstruction using noisy and/or incomplete magnetic resonance (MR) measurements. Our approach leverages the Helmholtz equation to constrain two networks, responsible for the denoising and completion of the transmit fields, and the estimation of the object's EP, respectively. We embed a random Fourier features mapping into our networks to enable efficient learning of high-frequency details encoded in the transmit fields. We demonstrated the efficacy of PIFON-EPT through several simulated experiments at 3 and 7 tesla (T) MR imaging, and showed that our method can reconstruct physically consistent EP and transmit fields. Specifically, when only $20\%$ of the noisy measured fields were used as inputs, PIFON-EPT reconstructed the EP of a phantom with $\leq 5\%$ error, and denoised and completed the measurements with $\leq 1\%$ error. Additionally, we adapted PIFON-EPT to solve the generalized Helmholtz equation that accounts for gradients of EP between inhomogeneities. This yielded improved results at interfaces between different materials without explicit knowledge of boundary conditions. PIFON-EPT is the first method that can simultaneously reconstruct EP and transmit fields from incomplete noisy MR measurements, providing new opportunities for EPT research.
<div id='section'>Paperid: <span id='pid'>308, <a href='https://arxiv.org/pdf/2301.03565.pdf' target='_blank'>https://arxiv.org/pdf/2301.03565.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam J. Thorpe, Cyrus Neary, Franck Djeumou, Meeko M. K. Oishi, Ufuk Topcu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.03565">Physics-Informed Kernel Embeddings: Integrating Prior System Knowledge with Data-Driven Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven control algorithms use observations of system dynamics to construct an implicit model for the purpose of control. However, in practice, data-driven techniques often require excessive sample sizes, which may be infeasible in real-world scenarios where only limited observations of the system are available. Furthermore, purely data-driven methods often neglect useful a priori knowledge, such as approximate models of the system dynamics. We present a method to incorporate such prior knowledge into data-driven control algorithms using kernel embeddings, a nonparametric machine learning technique based in the theory of reproducing kernel Hilbert spaces. Our proposed approach incorporates prior knowledge of the system dynamics as a bias term in the kernel learning problem. We formulate the biased learning problem as a least-squares problem with a regularization term that is informed by the dynamics, that has an efficiently computable, closed-form solution. Through numerical experiments, we empirically demonstrate the improved sample efficiency and out-of-sample generalization of our approach over a purely data-driven baseline. We demonstrate an application of our method to control through a target tracking problem with nonholonomic dynamics, and on spring-mass-damper and F-16 aircraft state prediction tasks.
<div id='section'>Paperid: <span id='pid'>309, <a href='https://arxiv.org/pdf/2212.06764.pdf' target='_blank'>https://arxiv.org/pdf/2212.06764.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Le Cleac'h, Mac Schwager, Zachary Manchester, Vikas Sindhwani, Pete Florence, Sumeet Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.06764">Single-Level Differentiable Contact Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a differentiable formulation of rigid-body contact dynamics for objects and robots represented as compositions of convex primitives. Existing optimization-based approaches simulating contact between convex primitives rely on a bilevel formulation that separates collision detection and contact simulation. These approaches are unreliable in realistic contact simulation scenarios because isolating the collision detection problem introduces contact location non-uniqueness. Our approach combines contact simulation and collision detection into a unified single-level optimization problem. This disambiguates the collision detection problem in a physics-informed manner. Compared to previous differentiable simulation approaches, our formulation features improved simulation robustness and a reduction in computational complexity by more than an order of magnitude. We illustrate the contact and collision differentiability on a robotic manipulation task requiring optimization-through-contact. We provide a numerically efficient implementation of our formulation in the Julia language called Silico.jl.
<div id='section'>Paperid: <span id='pid'>310, <a href='https://arxiv.org/pdf/2212.00893.pdf' target='_blank'>https://arxiv.org/pdf/2212.00893.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cyrus Neary, Ufuk Topcu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.00893">Compositional Learning of Dynamical System Models Using Port-Hamiltonian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many dynamical systems -- from robots interacting with their surroundings to large-scale multiphysics systems -- involve a number of interacting subsystems. Toward the objective of learning composite models of such systems from data, we present i) a framework for compositional neural networks, ii) algorithms to train these models, iii) a method to compose the learned models, iv) theoretical results that bound the error of the resulting composite models, and v) a method to learn the composition itself, when it is not known a priori. The end result is a modular approach to learning: neural network submodels are trained on trajectory data generated by relatively simple subsystems, and the dynamics of more complex composite systems are then predicted without requiring additional data generated by the composite systems themselves. We achieve this compositionality by representing the system of interest, as well as each of its subsystems, as a port-Hamiltonian neural network (PHNN) -- a class of neural ordinary differential equations that uses the port-Hamiltonian systems formulation as inductive bias. We compose collections of PHNNs by using the system's physics-informed interconnection structure, which may be known a priori, or may itself be learned from data. We demonstrate the novel capabilities of the proposed framework through numerical examples involving interacting spring-mass-damper systems. Models of these systems, which include nonlinear energy dissipation and control inputs, are learned independently. Accurate compositions are learned using an amount of training data that is negligible in comparison with that required to train a new model from scratch. Finally, we observe that the composite PHNNs enjoy properties of port-Hamiltonian systems, such as cyclo-passivity -- a property that is useful for control purposes.
<div id='section'>Paperid: <span id='pid'>311, <a href='https://arxiv.org/pdf/2207.01751.pdf' target='_blank'>https://arxiv.org/pdf/2207.01751.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyue Liu, Xinling Yu, Zheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.01751">TT-PINN: A Tensor-Compressed Neural PDE Solver for Edge Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have been increasingly employed due to their capability of modeling complex physics systems. To achieve better expressiveness, increasingly larger network sizes are required in many problems. This has caused challenges when we need to train PINNs on edge devices with limited memory, computing and energy resources. To enable training PINNs on edge devices, this paper proposes an end-to-end compressed PINN based on Tensor-Train decomposition. In solving a Helmholtz equation, our proposed model significantly outperforms the original PINNs with few parameters and achieves satisfactory prediction with up to 15$\times$ overall parameter reduction.
<div id='section'>Paperid: <span id='pid'>312, <a href='https://arxiv.org/pdf/2509.20447.pdf' target='_blank'>https://arxiv.org/pdf/2509.20447.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shunyuan Mao, Weiqi Wang, Sifan Wang, Ruobing Dong, Lu Lu, Kwang Moo Yi, Paris Perdikaris, Andrea Isella, Sébastien Fabbro, Lile Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.20447">Neural Networks as Surrogate Solvers for Time-Dependent Accretion Disk Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accretion disks are ubiquitous in astrophysics, appearing in diverse environments from planet-forming systems to X-ray binaries and active galactic nuclei. Traditionally, modeling their dynamics requires computationally intensive (magneto)hydrodynamic simulations. Recently, Physics-Informed Neural Networks (PINNs) have emerged as a promising alternative. This approach trains neural networks directly on physical laws without requiring data. We for the first time demonstrate PINNs for solving the two-dimensional, time-dependent hydrodynamics of non-self-gravitating accretion disks. Our models provide solutions at arbitrary times and locations within the training domain, and successfully reproduce key physical phenomena, including the excitation and propagation of spiral density waves and gap formation from disk-companion interactions. Notably, the boundary-free approach enabled by PINNs naturally eliminates the spurious wave reflections at disk edges, which are challenging to suppress in numerical simulations. These results highlight how advanced machine learning techniques can enable physics-driven, data-free modeling of complex astrophysical systems, potentially offering an alternative to traditional numerical simulations in the future.
<div id='section'>Paperid: <span id='pid'>313, <a href='https://arxiv.org/pdf/2509.04060.pdf' target='_blank'>https://arxiv.org/pdf/2509.04060.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alejandro Penacho Riveiros, Nicola Bastianello, Karl H. Johansson, Matthieu Barreau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.04060">Physics-Informed Detection of Friction Anomalies in Satellite Reaction Wheels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As the number of satellites in orbit has increased exponentially in recent years, ensuring their correct functionality has started to require automated methods to decrease human workload. In this work, we present an algorithm that analyzes the on-board data related to friction from the Reaction Wheel Assemblies (RWA) of a satellite and determines their operating status, distinguishing between nominal status and several possible anomalies that require preventive measures to be taken. The algorithm first uses a model based on hybrid systems theory to extract the information relevant to the problem. The extraction process combines techniques in changepoint detection, dynamic programming, and maximum likelihood in a structured way. A classifier then uses the extracted information to determine the status of the RWA. This last classifier has been previously trained with a labelled dataset produced by a high-fidelity simulator, comprised for the most part of nominal data. The final algorithm combines model-based and data-based approaches to obtain satisfactory results with an accuracy around 95%.
<div id='section'>Paperid: <span id='pid'>314, <a href='https://arxiv.org/pdf/2507.08972.pdf' target='_blank'>https://arxiv.org/pdf/2507.08972.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sifan Wang, Shyam Sankaran, Panos Stinis, Paris Perdikaris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08972">Simulating Three-dimensional Turbulence with Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Turbulent fluid flows are among the most computationally demanding problems in science, requiring enormous computational resources that become prohibitive at high flow speeds. Physics-informed neural networks (PINNs) represent a radically different approach that trains neural networks directly from physical equations rather than data, offering the potential for continuous, mesh-free solutions. Here we show that appropriately designed PINNs can successfully simulate fully turbulent flows in both two and three dimensions, directly learning solutions to the fundamental fluid equations without traditional computational grids or training data. Our approach combines several algorithmic innovations including adaptive network architectures, causal training, and advanced optimization methods to overcome the inherent challenges of learning chaotic dynamics. Through rigorous validation on challenging turbulence problems, we demonstrate that PINNs accurately reproduce key flow statistics including energy spectra, kinetic energy, enstrophy, and Reynolds stresses. Our results demonstrate that neural equation solvers can handle complex chaotic systems, opening new possibilities for continuous turbulence modeling that transcends traditional computational limitations.
<div id='section'>Paperid: <span id='pid'>315, <a href='https://arxiv.org/pdf/2507.00613.pdf' target='_blank'>https://arxiv.org/pdf/2507.00613.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nuno CapitÃ£o, Yi Zhang, Yidong Zhao, Qian Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00613">Physics-Informed Neural ODEs for Temporal Dynamics Modeling in Cardiac T1 Mapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spin-lattice relaxation time ($T_1$) is an important biomarker in cardiac parametric mapping for characterizing myocardial tissue and diagnosing cardiomyopathies. Conventional Modified Look-Locker Inversion Recovery (MOLLI) acquires 11 breath-hold baseline images with interleaved rest periods to ensure mapping accuracy. However, prolonged scanning can be challenging for patients with poor breathholds, often leading to motion artifacts that degrade image quality. In addition, $T_1$ mapping requires voxel-wise nonlinear fitting to a signal recovery model involving an iterative estimation process. Recent studies have proposed deep-learning approaches for rapid $T_1$ mapping using shortened sequences to reduce acquisition time for patient comfort. Nevertheless, existing methods overlook important physics constraints, limiting interpretability and generalization. In this work, we present an accelerated, end-to-end $T_1$ mapping framework leveraging Physics-Informed Neural Ordinary Differential Equations (ODEs) to model temporal dynamics and address these challenges. Our method achieves high-accuracy $T_1$ estimation from a sparse subset of baseline images and ensures efficient null index estimation at test time. Specifically, we develop a continuous-time LSTM-ODE model to enable selective Look-Locker (LL) data acquisition with arbitrary time lags. Experimental results show superior performance in $T_1$ estimation for both native and post-contrast sequences and demonstrate the strong benefit of our physics-based formulation over direct data-driven $T_1$ priors.
<div id='section'>Paperid: <span id='pid'>316, <a href='https://arxiv.org/pdf/2505.09260.pdf' target='_blank'>https://arxiv.org/pdf/2505.09260.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pratibha Raghupati Hegde, Paolo Marcandelli, Yuanchun He, Luca Pennati, Jeremy J. Williams, Ivy Peng, Stefano Markidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.09260">A Hybrid Quantum-Classical Particle-in-Cell Method for Plasma Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a hybrid quantum-classical electrostatic Particle-in-Cell (PIC) method, where the electrostatic field Poisson solver is implemented on a quantum computer simulator using a hybrid classical-quantum Neural Network (HNN) using data-driven and physics-informed learning approaches. The HNN is trained on classical PIC simulation results and executed via a PennyLane quantum simulator. The remaining computational steps, including particle motion and field interpolation, are performed on a classical system. To evaluate the accuracy and computational cost of this hybrid approach, we test the hybrid quantum-classical electrostatic PIC against the two-stream instability, a standard benchmark in plasma physics. Our results show that the quantum Poisson solver achieves comparable accuracy to classical methods. It also provides insights into the feasibility of using quantum computing and HNNs for plasma simulations. We also discuss the computational overhead associated with current quantum computer simulators, showing the challenges and potential advantages of hybrid quantum-classical numerical methods.
<div id='section'>Paperid: <span id='pid'>317, <a href='https://arxiv.org/pdf/2505.06810.pdf' target='_blank'>https://arxiv.org/pdf/2505.06810.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Jiang, Chi Zhang, Fan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06810">QSeer: A Quantum-Inspired Graph Neural Network for Parameter Initialization in Quantum Approximate Optimization Algorithm Circuits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To mitigate the barren plateau problem, effective parameter initialization is crucial for optimizing the Quantum Approximate Optimization Algorithm (QAOA) in the near-term Noisy Intermediate-Scale Quantum (NISQ) era. Prior physics-driven approaches leveraged the optimal parameter concentration phenomenon, utilizing medium values of previously optimized QAOA parameters stored in databases as initialization for new graphs. However, this medium-value-based strategy lacks generalization capability. Conversely, prior computer-science-based approaches employed graph neural networks (GNNs) trained on previously optimized QAOA parameters to predict initialization values for new graphs. However, these approaches neglect key physics-informed QAOA principles, such as parameter concentration, symmetry, and adiabatic evolution, resulting in suboptimal parameter predictions and limited performance improvements. Furthermore, no existing GNN-based methods support parameter initialization for QAOA circuits with variable depths or for solving weighted Max-Cut problems. This paper introduces QSeer, a quantum-inspired GNN designed for accurate QAOA parameter prediction. Compared to prior physics- and computer-science-driven methods, QSeer improves the initial approximation ratio and convergence speed of QAOA circuits across diverse graphs by 6%-68% and 5x-10x, respectively.
<div id='section'>Paperid: <span id='pid'>318, <a href='https://arxiv.org/pdf/2504.03166.pdf' target='_blank'>https://arxiv.org/pdf/2504.03166.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanbo Bi, Yingchao Feng, Boyuan Tong, Mengyu Wang, Haichen Yu, Yongqiang Mao, Hao Chang, Wenhui Diao, Peijin Wang, Yue Yu, Hanyang Peng, Yehong Zhang, Kun Fu, Xian Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03166">RingMoE: Mixture-of-Modality-Experts Multi-Modal Foundation Models for Universal Remote Sensing Image Interpretation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid advancement of foundation models has revolutionized visual representation learning in a self-supervised manner. However, their application in remote sensing (RS) remains constrained by a fundamental gap: existing models predominantly handle single or limited modalities, overlooking the inherently multi-modal nature of RS observations. Optical, synthetic aperture radar (SAR), and multi-spectral data offer complementary insights that significantly reduce the inherent ambiguity and uncertainty in single-source analysis. To bridge this gap, we introduce RingMoE, a unified multi-modal RS foundation model with 14.7 billion parameters, pre-trained on 400 million multi-modal RS images from nine satellites. RingMoE incorporates three key innovations: (1) A hierarchical Mixture-of-Experts (MoE) architecture comprising modal-specialized, collaborative, and shared experts, effectively modeling intra-modal knowledge while capturing cross-modal dependencies to mitigate conflicts between modal representations; (2) Physics-informed self-supervised learning, explicitly embedding sensor-specific radiometric characteristics into the pre-training objectives; (3) Dynamic expert pruning, enabling adaptive model compression from 14.7B to 1B parameters while maintaining performance, facilitating efficient deployment in Earth observation applications. Evaluated across 23 benchmarks spanning six key RS tasks (i.e., classification, detection, segmentation, tracking, change detection, and depth estimation), RingMoE outperforms existing foundation models and sets new SOTAs, demonstrating remarkable adaptability from single-modal to multi-modal scenarios. Beyond theoretical progress, it has been deployed and trialed in multiple sectors, including emergency response, land management, marine sciences, and urban planning.
<div id='section'>Paperid: <span id='pid'>319, <a href='https://arxiv.org/pdf/2502.12164.pdf' target='_blank'>https://arxiv.org/pdf/2502.12164.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Inaam Ashraf, AndrÃ© Artelt, Barbara Hammer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12164">Scalable and Robust Physics-Informed Graph Neural Networks for Water Distribution Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Water distribution systems (WDSs) are an important part of critical infrastructure becoming increasingly significant in the face of climate change and urban population growth. We propose a robust and scalable surrogate deep learning (DL) model to enable efficient planning, expansion, and rehabilitation of WDSs. Our approach incorporates an improved graph neural network architecture, an adapted physics-informed algorithm, an innovative training scheme, and a physics-preserving data normalization method. Evaluation results on a number of WDSs demonstrate that our model outperforms the current state-of-the-art DL model. Moreover, our method allows us to scale the model to bigger and more realistic WDSs. Furthermore, our approach makes the model more robust to out-of-distribution input features (demands, pipe diameters). Hence, our proposed method constitutes a significant step towards bridging the simulation-to-real gap in the use of artificial intelligence for WDSs.
<div id='section'>Paperid: <span id='pid'>320, <a href='https://arxiv.org/pdf/2502.00604.pdf' target='_blank'>https://arxiv.org/pdf/2502.00604.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sifan Wang, Ananyae Kumar Bhartari, Bowen Li, Paris Perdikaris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00604">Gradient Alignment in Physics-informed Neural Networks: A Second-Order Optimization Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-task learning through composite loss functions is fundamental to modern deep learning, yet optimizing competing objectives remains challenging. We present new theoretical and practical approaches for addressing directional conflicts between loss terms, demonstrating their effectiveness in physics-informed neural networks (PINNs) where such conflicts are particularly challenging to resolve. Through theoretical analysis, we demonstrate how these conflicts limit first-order methods and show that second-order optimization naturally resolves them through implicit gradient alignment. We prove that SOAP, a recently proposed quasi-Newton method, efficiently approximates the Hessian preconditioner, enabling breakthrough performance in PINNs: state-of-the-art results on 10 challenging PDE benchmarks, including the first successful application to turbulent flows with Reynolds numbers up to 10,000, with 2-10x accuracy improvements over existing methods. We also introduce a novel gradient alignment score that generalizes cosine similarity to multiple gradients, providing a practical tool for analyzing optimization dynamics. Our findings establish frameworks for understanding and resolving gradient conflicts, with broad implications for optimization beyond scientific computing.
<div id='section'>Paperid: <span id='pid'>321, <a href='https://arxiv.org/pdf/2501.03432.pdf' target='_blank'>https://arxiv.org/pdf/2501.03432.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Donatella Genovese, Alessandro Sgroi, Alessio Devoto, Samuel Valentine, Lennox Wood, Cristiano Sebastiani, Stefano Giagu, Monica D'Onofrio, Simone Scardapane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.03432">Mixture-of-Experts Graph Transformers for Interpretable Particle Collision Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Large Hadron Collider at CERN produces immense volumes of complex data from high-energy particle collisions, demanding sophisticated analytical techniques for effective interpretation. Neural Networks, including Graph Neural Networks, have shown promise in tasks such as event classification and object identification by representing collisions as graphs. However, while Graph Neural Networks excel in predictive accuracy, their "black box" nature often limits their interpretability, making it difficult to trust their decision-making processes. In this paper, we propose a novel approach that combines a Graph Transformer model with Mixture-of-Expert layers to achieve high predictive performance while embedding interpretability into the architecture. By leveraging attention maps and expert specialization, the model offers insights into its internal decision-making, linking predictions to physics-informed features. We evaluate the model on simulated events from the ATLAS experiment, focusing on distinguishing rare Supersymmetric signal events from Standard Model background. Our results highlight that the model achieves competitive classification accuracy while providing interpretable outputs that align with known physics, demonstrating its potential as a robust and transparent tool for high-energy physics data analysis. This approach underscores the importance of explainability in machine learning methods applied to high energy physics, offering a path toward greater trust in AI-driven discoveries.
<div id='section'>Paperid: <span id='pid'>322, <a href='https://arxiv.org/pdf/2411.07239.pdf' target='_blank'>https://arxiv.org/pdf/2411.07239.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zecheng Zhang, Christian Moya, Lu Lu, Guang Lin, Hayden Schaeffer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.07239">DeepONet as a Multi-Operator Extrapolation Model: Distributed Pretraining with Physics-Informed Fine-Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel fine-tuning method to achieve multi-operator learning through training a distributed neural operator with diverse function data and then zero-shot fine-tuning the neural network using physics-informed losses for downstream tasks. Operator learning effectively approximates solution operators for PDEs and various PDE-related problems, yet it often struggles to generalize to new tasks. To address this, we investigate fine-tuning a pretrained model, while carefully selecting an initialization that enables rapid adaptation to new tasks with minimal data. Our approach combines distributed learning to integrate data from various operators in pre-training, while physics-informed methods enable zero-shot fine-tuning, minimizing the reliance on downstream data. We investigate standard fine-tuning and Low-Rank Adaptation fine-tuning, applying both to train complex nonlinear target operators that are difficult to learn only using random initialization. Through comprehensive numerical examples, we demonstrate the advantages of our approach, showcasing significant improvements in accuracy. Our findings provide a robust framework for advancing multi-operator learning and highlight the potential of transfer learning techniques in this domain.
<div id='section'>Paperid: <span id='pid'>323, <a href='https://arxiv.org/pdf/2410.14477.pdf' target='_blank'>https://arxiv.org/pdf/2410.14477.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vladimir R. Kostic, Karim Lounici, HÃ©lÃ¨ne Halconruy, TimothÃ©e Devergne, Pietro Novelli, Massimiliano Pontil
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14477">Laplace Transform Based Low-Complexity Learning of Continuous Markov Semigroups</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Markov processes serve as a universal model for many real-world random processes. This paper presents a data-driven approach for learning these models through the spectral decomposition of the infinitesimal generator (IG) of the Markov semigroup. The unbounded nature of IGs complicates traditional methods such as vector-valued regression and Hilbert-Schmidt operator analysis. Existing techniques, including physics-informed kernel regression, are computationally expensive and limited in scope, with no recovery guarantees for transfer operator methods when the time-lag is small. We propose a novel method that leverages the IG's resolvent, characterized by the Laplace transform of transfer operators. This approach is robust to time-lag variations, ensuring accurate eigenvalue learning even for small time-lags. Our statistical analysis applies to a broader class of Markov processes than current methods while reducing computational complexity from quadratic to linear in the state dimension. Finally, we illustrate the behaviour of our method in two experiments.
<div id='section'>Paperid: <span id='pid'>324, <a href='https://arxiv.org/pdf/2409.01222.pdf' target='_blank'>https://arxiv.org/pdf/2409.01222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuan Li, Shuai Lu, Wei Gu, Yijun Xu, Ruizhi Yu, Suhan Zhang, Zhikai Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01222">Nonlinear PDE Constrained Optimal Dispatch of Gas and Power: A Global Linearization Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The coordinated dispatch of power and gas in the electricity-gas integrated energy system (EG-IES) is fundamental for ensuring operational security. However, the gas dynamics in the natural gas system (NGS) are governed by the nonlinear partial differential equations (PDE), making the dispatch problem of the EG-IES a complicated optimization model constrained by nonlinear PDE. To address it, we propose a globally linearized gas network model based on the Koopman operator theory, avoiding the commonly used local linearization and spatial discretization. Particularly, we propose a data-driven Koopman operator approximation approach for the globally linearized gas network model based on the extended dynamic mode decomposition, in which a physics-informed stability constraint is derived and embedded to improve the generalization ability and accuracy of the model. Based on this, we develop an optimal dispatch model for the EG-IES that first considers the nonlinear gas dynamics in the NGS. The case study verifies the effectiveness of this work. Simulation results reveal that the commonly used locally linearized gas network model fails to accurately capture the dynamic characteristics of NGS, bringing potential security threats to the system.
<div id='section'>Paperid: <span id='pid'>325, <a href='https://arxiv.org/pdf/2408.15393.pdf' target='_blank'>https://arxiv.org/pdf/2408.15393.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gianluca Fabiani, Erik Bollt, Constantinos Siettos, Athanasios N. Yannacopoulos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15393">Linear Stability Analysis of Physics-Informed Random Projection Neural Networks for ODEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a linear stability analysis of physics-informed random projection neural networks (PI-RPNNs), for the numerical solution of {the initial value problem (IVP)} of (stiff) ODEs. We begin by proving that PI-RPNNs are uniform approximators of the solution to ODEs. We then provide a constructive proof demonstrating that PI-RPNNs offer consistent and asymptotically stable numerical schemes, thus convergent schemes. In particular, we prove that multi-collocation PI-RPNNs guarantee asymptotic stability. Our theoretical results are illustrated via numerical solutions of benchmark examples including indicative comparisons with the backward Euler method, the midpoint method, the trapezoidal rule, the 2-stage Gauss scheme, and the 2- and 3-stage Radau schemes.
<div id='section'>Paperid: <span id='pid'>326, <a href='https://arxiv.org/pdf/2405.12465.pdf' target='_blank'>https://arxiv.org/pdf/2405.12465.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yusuke Yamazaki, Ali Harandi, Mayu Muramatsu, Alexandre Viardin, Markus Apel, Tim Brepols, Stefanie Reese, Shahed Rezaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12465">A finite element-based physics-informed operator learning framework for spatiotemporal partial differential equations on arbitrary domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel finite element-based physics-informed operator learning framework that allows for predicting spatiotemporal dynamics governed by partial differential equations (PDEs). The proposed framework employs a loss function inspired by the finite element method (FEM) with the implicit Euler time integration scheme. A transient thermal conduction problem is considered to benchmark the performance. The proposed operator learning framework takes a temperature field at the current time step as input and predicts a temperature field at the next time step. The Galerkin discretized weak formulation of the heat equation is employed to incorporate physics into the loss function, which is coined finite operator learning (FOL). Upon training, the networks successfully predict the temperature evolution over time for any initial temperature field at high accuracy compared to the FEM solution. The framework is also confirmed to be applicable to a heterogeneous thermal conductivity and arbitrary geometry. The advantages of FOL can be summarized as follows: First, the training is performed in an unsupervised manner, avoiding the need for a large data set prepared from costly simulations or experiments. Instead, random temperature patterns generated by the Gaussian random process and the Fourier series, combined with constant temperature fields, are used as training data to cover possible temperature cases. Second, shape functions and backward difference approximation are exploited for the domain discretization, resulting in a purely algebraic equation. This enhances training efficiency, as one avoids time-consuming automatic differentiation when optimizing weights and biases while accepting possible discretization errors. Finally, thanks to the interpolation power of FEM, any arbitrary geometry can be handled with FOL, which is crucial to addressing various engineering application scenarios.
<div id='section'>Paperid: <span id='pid'>327, <a href='https://arxiv.org/pdf/2402.12360.pdf' target='_blank'>https://arxiv.org/pdf/2402.12360.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hector Vargas Alvarez, Gianluca Fabiani, Ioannis G. Kevrekidis, Nikolaos Kazantzis, Constantinos Siettos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12360">Nonlinear Discrete-Time Observers with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We use Physics-Informed Neural Networks (PINNs) to solve the discrete-time nonlinear observer state estimation problem. Integrated within a single-step exact observer linearization framework, the proposed PINN approach aims at learning a nonlinear state transformation map by solving a system of inhomogeneous functional equations. The performance of the proposed PINN approach is assessed via two illustrative case studies for which the observer linearizing transformation map can be derived analytically. We also perform an uncertainty quantification analysis for the proposed PINN scheme and we compare it with conventional power-series numerical implementations, which rely on the computation of a power series solution.
<div id='section'>Paperid: <span id='pid'>328, <a href='https://arxiv.org/pdf/2308.12939.pdf' target='_blank'>https://arxiv.org/pdf/2308.12939.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Fang, Sifan Wang, Paris Perdikaris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12939">Learning Only On Boundaries: a Physics-Informed Neural operator for Solving Parametric Partial Differential Equations in Complex Geometries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently deep learning surrogates and neural operators have shown promise in solving partial differential equations (PDEs). However, they often require a large amount of training data and are limited to bounded domains. In this work, we present a novel physics-informed neural operator method to solve parametrized boundary value problems without labeled data. By reformulating the PDEs into boundary integral equations (BIEs), we can train the operator network solely on the boundary of the domain. This approach reduces the number of required sample points from $O(N^d)$ to $O(N^{d-1})$, where $d$ is the domain's dimension, leading to a significant acceleration of the training process. Additionally, our method can handle unbounded problems, which are unattainable for existing physics-informed neural networks (PINNs) and neural operators. Our numerical experiments show the effectiveness of parametrized complex geometries and unbounded problems.
<div id='section'>Paperid: <span id='pid'>329, <a href='https://arxiv.org/pdf/2308.10483.pdf' target='_blank'>https://arxiv.org/pdf/2308.10483.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuai Lu, Zihang Gao, Yong Sun, Suhan Zhang, Baoju Li, Chengliang Hao, Yijun Xu, Wei Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10483">Aggregate Model of District Heating Network for Integrated Energy Dispatch: A Physically Informed Data-Driven Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The district heating network (DHN) is essential in enhancing the operational flexibility of integrated energy systems (IES). Yet, it is hard to obtain an accurate and concise DHN model for the operation owing to complicated network features and imperfect measurements. Considering this, this paper proposes a physical-ly informed data-driven aggregate model (AGM) for the DHN, providing a concise description of the source-load relationship of DHN without exposing network details. First, we derive the analytical relationship between the state variables of the source and load nodes of the DHN, offering a physical fundament for the AGM. Second, we propose a physics-informed estimator for the AGM that is robust to low-quality measurements, in which the physical constraints associated with the parameter normalization and sparsity are embedded to improve the accuracy and robustness. Finally, we propose a physics-enhanced algorithm to solve the nonlinear estimator with non-closed constraints efficiently. Simulation results verify the effectiveness of the proposed method.
<div id='section'>Paperid: <span id='pid'>330, <a href='https://arxiv.org/pdf/2308.08468.pdf' target='_blank'>https://arxiv.org/pdf/2308.08468.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sifan Wang, Shyam Sankaran, Hanwen Wang, Paris Perdikaris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08468">An Expert's Guide to Training Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have been popularized as a deep learning framework that can seamlessly synthesize observational data and partial differential equation (PDE) constraints. Their practical effectiveness however can be hampered by training pathologies, but also oftentimes by poor choices made by users who lack deep learning expertise. In this paper we present a series of best practices that can significantly improve the training efficiency and overall accuracy of PINNs. We also put forth a series of challenging benchmark problems that highlight some of the most prominent difficulties in training PINNs, and present comprehensive and fully reproducible ablation studies that demonstrate how different architecture choices and training strategies affect the test accuracy of the resulting models. We show that the methods and guiding principles put forth in this study lead to state-of-the-art results and provide strong baselines that future studies should use for comparison purposes. To this end, we also release a highly optimized library in JAX that can be used to reproduce all results reported in this paper, enable future research studies, as well as facilitate easy adaptation to new use-case scenarios.
<div id='section'>Paperid: <span id='pid'>331, <a href='https://arxiv.org/pdf/2307.11833.pdf' target='_blank'>https://arxiv.org/pdf/2307.11833.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiyuan Zhao, Xueying Ding, B. Aditya Prakash
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.11833">PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a promising deep learning framework for approximating numerical solutions to partial differential equations (PDEs). However, conventional PINNs, relying on multilayer perceptrons (MLP), neglect the crucial temporal dependencies inherent in practical physics systems and thus fail to propagate the initial condition constraints globally and accurately capture the true solutions under various scenarios. In this paper, we introduce a novel Transformer-based framework, termed PINNsFormer, designed to address this limitation. PINNsFormer can accurately approximate PDE solutions by utilizing multi-head attention mechanisms to capture temporal dependencies. PINNsFormer transforms point-wise inputs into pseudo sequences and replaces point-wise PINNs loss with a sequential loss. Additionally, it incorporates a novel activation function, Wavelet, which anticipates Fourier decomposition through deep neural networks. Empirical results demonstrate that PINNsFormer achieves superior generalization ability and accuracy across various scenarios, including PINNs failure modes and high-dimensional PDEs. Moreover, PINNsFormer offers flexibility in integrating existing learning schemes for PINNs, further enhancing its performance.
<div id='section'>Paperid: <span id='pid'>332, <a href='https://arxiv.org/pdf/2304.10717.pdf' target='_blank'>https://arxiv.org/pdf/2304.10717.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuang Hu, Meiqin Liu, Senlin Zhang, Shanling Dong, Ronghao Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10717">Physics-informed Neural Network Combined with Characteristic-Based Split for Solving Navier-Stokes Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, physics-informed neural network (PINN) based on characteristic-based split (CBS) is proposed, which can be used to solve the time-dependent Navier-Stokes equations (N-S equations). In this method, The output parameters and corresponding losses are separated, so the weights between output parameters are not considered. Not all partial derivatives participate in gradient backpropagation, and the remaining terms will be reused.Therefore, compared with traditional PINN, this method is a rapid version. Here, labeled data, physical constraints and network outputs are regarded as priori information, and the residuals of the N-S equations are regarded as posteriori information. So this method can deal with both data-driven and data-free problems. As a result, it can solve the special form of compressible N-S equations -- -Shallow-Water equations, and incompressible N-S equations. As boundary conditions are known, this method only needs the flow field information at a certain time to restore the past and future flow field information. We solve the progress of a solitary wave onto a shelving beach and the dispersion of the hot water in the flow, which show this method's potential in the marine engineering. We also use incompressible equations with exact solutions to prove this method's correctness and universality. We find that PINN needs more strict boundary conditions to solve the N-S equation, because it has no computational boundary compared with the finite element method.
<div id='section'>Paperid: <span id='pid'>333, <a href='https://arxiv.org/pdf/2303.08884.pdf' target='_blank'>https://arxiv.org/pdf/2303.08884.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hector Vargas Alvarez, Gianluca Fabiani, Nikolaos Kazantzis, Constantinos Siettos, Ioannis G. Kevrekidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08884">Discrete-Time Nonlinear Feedback Linearization via Physics-Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a physics-informed machine learning (PIML) scheme for the feedback linearization of nonlinear discrete-time dynamical systems. The PIML finds the nonlinear transformation law, thus ensuring stability via pole placement, in one step. In order to facilitate convergence in the presence of steep gradients in the nonlinear transformation law, we address a greedy-wise training procedure. We assess the performance of the proposed PIML approach via a benchmark nonlinear discrete map for which the feedback linearization transformation law can be derived analytically; the example is characterized by steep gradients, due to the presence of singularities, in the domain of interest. We show that the proposed PIML outperforms, in terms of numerical approximation accuracy, the traditional numerical implementation, which involves the construction--and the solution in terms of the coefficients of a power-series expansion--of a system of homological equations as well as the implementation of the PIML in the entire domain, thus highlighting the importance of continuation techniques in the training procedure of PIML.
<div id='section'>Paperid: <span id='pid'>334, <a href='https://arxiv.org/pdf/2302.13143.pdf' target='_blank'>https://arxiv.org/pdf/2302.13143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Fang, Sifan Wang, Paris Perdikaris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.13143">Ensemble learning for Physics Informed Neural Networks: a Gradient Boosting approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While the popularity of physics-informed neural networks (PINNs) is steadily rising, to this date, PINNs have not been successful in simulating multi-scale and singular perturbation problems. In this work, we present a new training paradigm referred to as "gradient boosting" (GB), which significantly enhances the performance of physics informed neural networks (PINNs). Rather than learning the solution of a given PDE using a single neural network directly, our algorithm employs a sequence of neural networks to achieve a superior outcome. This approach allows us to solve problems presenting great challenges for traditional PINNs. Our numerical experiments demonstrate the effectiveness of our algorithm through various benchmarks, including comparisons with finite element methods and PINNs. Furthermore, this work also unlocks the door to employing ensemble learning techniques in PINNs, providing opportunities for further improvement in solving PDEs.
<div id='section'>Paperid: <span id='pid'>335, <a href='https://arxiv.org/pdf/2207.02338.pdf' target='_blank'>https://arxiv.org/pdf/2207.02338.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arka Daw, Jie Bu, Sifan Wang, Paris Perdikaris, Anuj Karpatne
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.02338">Mitigating Propagation Failures in Physics-informed Neural Networks using Retain-Resample-Release (R3) Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the success of physics-informed neural networks (PINNs) in approximating partial differential equations (PDEs), PINNs can sometimes fail to converge to the correct solution in problems involving complicated PDEs. This is reflected in several recent studies on characterizing the "failure modes" of PINNs, although a thorough understanding of the connection between PINN failure modes and sampling strategies is missing. In this paper, we provide a novel perspective of failure modes of PINNs by hypothesizing that training PINNs relies on successful "propagation" of solution from initial and/or boundary condition points to interior points. We show that PINNs with poor sampling strategies can get stuck at trivial solutions if there are propagation failures, characterized by highly imbalanced PDE residual fields. To mitigate propagation failures, we propose a novel Retain-Resample-Release sampling (R3) algorithm that can incrementally accumulate collocation points in regions of high PDE residuals with little to no computational overhead. We provide an extension of R3 sampling to respect the principle of causality while solving time-dependent PDEs. We theoretically analyze the behavior of R3 sampling and empirically demonstrate its efficacy and efficiency in comparison with baselines on a variety of PDE problems.
<div id='section'>Paperid: <span id='pid'>336, <a href='https://arxiv.org/pdf/2510.01206.pdf' target='_blank'>https://arxiv.org/pdf/2510.01206.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hung Le, Sherif Abbas, Minh Hoang Nguyen, Van Dai Do, Huu Hiep Nguyen, Dung Nguyen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.01206">Accelerating Long-Term Molecular Dynamics with Physics-Informed Time-Series Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficient molecular dynamics (MD) simulation is vital for understanding atomic-scale processes in materials science and biophysics. Traditional density functional theory (DFT) methods are computationally expensive, which limits the feasibility of long-term simulations. We propose a novel approach that formulates MD simulation as a time-series forecasting problem, enabling advanced forecasting models to predict atomic trajectories via displacements rather than absolute positions. We incorporate a physics-informed loss and inference mechanism based on DFT-parametrised pair-wise Morse potential functions that penalize unphysical atomic proximity to enforce physical plausibility. Our method consistently surpasses standard baselines in simulation accuracy across diverse materials. The results highlight the importance of incorporating physics knowledge to enhance the reliability and precision of atomic trajectory forecasting. Remarkably, it enables stable modeling of thousands of MD steps in minutes, offering a scalable alternative to costly DFT simulations.
<div id='section'>Paperid: <span id='pid'>337, <a href='https://arxiv.org/pdf/2509.12437.pdf' target='_blank'>https://arxiv.org/pdf/2509.12437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dingrui Wang, Zhexiao Sun, Zhouheng Li, Cheng Wang, Youlun Peng, Hongyuan Ye, Baha Zarrouki, Wei Li, Mattia Piccinini, Lei Xie, Johannes Betz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12437">Enhancing Physical Consistency in Lightweight World Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A major challenge in deploying world models is the trade-off between size and performance. Large world models can capture rich physical dynamics but require massive computing resources, making them impractical for edge devices. Small world models are easier to deploy but often struggle to learn accurate physics, leading to poor predictions. We propose the Physics-Informed BEV World Model (PIWM), a compact model designed to efficiently capture physical interactions in bird's-eye-view (BEV) representations. PIWM uses Soft Mask during training to improve dynamic object modeling and future prediction. We also introduce a simple yet effective technique, Warm Start, for inference to enhance prediction quality with a zero-shot model. Experiments show that at the same parameter scale (400M), PIWM surpasses the baseline by 60.6% in weighted overall score. Moreover, even when compared with the largest baseline model (400M), the smallest PIWM (130M Soft Mask) achieves a 7.4% higher weighted overall score with a 28% faster inference speed.
<div id='section'>Paperid: <span id='pid'>338, <a href='https://arxiv.org/pdf/2508.08254.pdf' target='_blank'>https://arxiv.org/pdf/2508.08254.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emily Yue-Ting Jia, Jiageng Mao, Zhiyuan Gao, Yajie Zhao, Yue Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.08254">Learning an Implicit Physics Model for Image-based Fluid Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Humans possess an exceptional ability to imagine 4D scenes, encompassing both motion and 3D geometry, from a single still image. This ability is rooted in our accumulated observations of similar scenes and an intuitive understanding of physics. In this paper, we aim to replicate this capacity in neural networks, specifically focusing on natural fluid imagery. Existing methods for this task typically employ simplistic 2D motion estimators to animate the image, leading to motion predictions that often defy physical principles, resulting in unrealistic animations. Our approach introduces a novel method for generating 4D scenes with physics-consistent animation from a single image. We propose the use of a physics-informed neural network that predicts motion for each surface point, guided by a loss term derived from fundamental physical principles, including the Navier-Stokes equations. To capture appearance, we predict feature-based 3D Gaussians from the input image and its estimated depth, which are then animated using the predicted motions and rendered from any desired camera perspective. Experimental results highlight the effectiveness of our method in producing physically plausible animations, showcasing significant performance improvements over existing methods. Our project page is https://physfluid.github.io/ .
<div id='section'>Paperid: <span id='pid'>339, <a href='https://arxiv.org/pdf/2508.08107.pdf' target='_blank'>https://arxiv.org/pdf/2508.08107.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danfeng Hong, Chenyu Li, Naoto Yokoya, Bing Zhang, Xiuping Jia, Antonio Plaza, Paolo Gamba, Jon Atli Benediktsson, Jocelyn Chanussot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.08107">Hyperspectral Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hyperspectral imaging (HSI) is an advanced sensing modality that simultaneously captures spatial and spectral information, enabling non-invasive, label-free analysis of material, chemical, and biological properties. This Primer presents a comprehensive overview of HSI, from the underlying physical principles and sensor architectures to key steps in data acquisition, calibration, and correction. We summarize common data structures and highlight classical and modern analysis methods, including dimensionality reduction, classification, spectral unmixing, and AI-driven techniques such as deep learning. Representative applications across Earth observation, precision agriculture, biomedicine, industrial inspection, cultural heritage, and security are also discussed, emphasizing HSI's ability to uncover sub-visual features for advanced monitoring, diagnostics, and decision-making. Persistent challenges, such as hardware trade-offs, acquisition variability, and the complexity of high-dimensional data, are examined alongside emerging solutions, including computational imaging, physics-informed modeling, cross-modal fusion, and self-supervised learning. Best practices for dataset sharing, reproducibility, and metadata documentation are further highlighted to support transparency and reuse. Looking ahead, we explore future directions toward scalable, real-time, and embedded HSI systems, driven by sensor miniaturization, self-supervised learning, and foundation models. As HSI evolves into a general-purpose, cross-disciplinary platform, it holds promise for transformative applications in science, technology, and society.
<div id='section'>Paperid: <span id='pid'>340, <a href='https://arxiv.org/pdf/2507.05184.pdf' target='_blank'>https://arxiv.org/pdf/2507.05184.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hoang-Quan Nguyen, Xuan Bac Nguyen, Sankalp Pandey, Tim Faltermeier, Nicholas Borys, Hugh Churchill, Khoa Luu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05184">$Ï$-Adapt: A Physics-Informed Adaptation Learning Approach to 2D Quantum Material Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Characterizing quantum flakes is a critical step in quantum hardware engineering because the quality of these flakes directly influences qubit performance. Although computer vision methods for identifying two-dimensional quantum flakes have emerged, they still face significant challenges in estimating flake thickness. These challenges include limited data, poor generalization, sensitivity to domain shifts, and a lack of physical interpretability. In this paper, we introduce one of the first Physics-informed Adaptation Learning approaches to overcome these obstacles. We focus on two main issues, i.e., data scarcity and generalization. First, we propose a new synthetic data generation framework that produces diverse quantum flake samples across various materials and configurations, reducing the need for time-consuming manual collection. Second, we present $Ï$-Adapt, a physics-informed adaptation method that bridges the performance gap between models trained on synthetic data and those deployed in real-world settings. Experimental results show that our approach achieves state-of-the-art performance on multiple benchmarks, outperforming existing methods. Our proposed approach advances the integration of physics-based modeling and domain adaptation. It also addresses a critical gap in leveraging synthesized data for real-world 2D material analysis, offering impactful tools for deep learning and materials science communities.
<div id='section'>Paperid: <span id='pid'>341, <a href='https://arxiv.org/pdf/2507.02078.pdf' target='_blank'>https://arxiv.org/pdf/2507.02078.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shrenik Jadhav, Birva Sevak, Srijita Das, Wencong Su, Van-Hai Bui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02078">Enhancing Power Flow Estimation with Topology-Aware Gated Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and scalable surrogate models for AC power flow are essential for real-time grid monitoring, contingency analysis, and decision support in increasingly dynamic and inverter-dominated power systems. However, most existing surrogates fall short of practical deployment due to their limited capacity to capture long-range nonlinear dependencies in meshed transmission networks and their weak enforcement of physical laws. These models often require extensive hyperparameter tuning, exhibit poor generalization under topology changes or large load swings, and typically do not quantify uncertainty or scale well beyond a few hundred buses. To address these challenges, this paper proposes a \textit{gated graph neural network (GGNN)} surrogate for AC power-flow estimation under topological uncertainty. The model is trained across multiple IEEE benchmark networks of varying size and complexity, each incorporating randomized line contingencies and up to 40\% load variation. To improve robustness and generalization, we explore both conventional supervised learning and physics-informed self-supervised training strategies. Comparative evaluations show that the proposed GGNN consistently outperforms prior GNN-based surrogates, achieving predictions closely aligned with Newton--Raphson solutions. By embedding operational constraints directly into the architecture and loss function, the model ensures physical consistency and delivers a lightweight, accurate, and scalable tool for real-time grid operations.
<div id='section'>Paperid: <span id='pid'>342, <a href='https://arxiv.org/pdf/2506.13961.pdf' target='_blank'>https://arxiv.org/pdf/2506.13961.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamed Serry, Haoyu Li, Ruikun Zhou, Huan Zhang, Jun Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13961">Safe Domains of Attraction for Discrete-Time Nonlinear Systems: Characterization and Verifiable Neural Network Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Analysis of nonlinear autonomous systems typically involves estimating domains of attraction, which have been a topic of extensive research interest for decades. Despite that, accurately estimating domains of attraction for nonlinear systems remains a challenging task, where existing methods are conservative or limited to low-dimensional systems. The estimation becomes even more challenging when accounting for state constraints. In this work, we propose a framework to accurately estimate safe (state-constrained) domains of attraction for discrete-time autonomous nonlinear systems. In establishing this framework, we first derive a new Zubov equation, whose solution corresponds to the exact safe domain of attraction. The solution to the aforementioned Zubov equation is shown to be unique and continuous over the whole state space. We then present a physics-informed approach to approximating the solution of the Zubov equation using neural networks. To obtain certifiable estimates of the domain of attraction from the neural network approximate solutions, we propose a verification framework that can be implemented using standard verification tools (e.g., $Î±,\!Î²$-CROWN and dReal). To illustrate its effectiveness, we demonstrate our approach through numerical examples concerning nonlinear systems with state constraints.
<div id='section'>Paperid: <span id='pid'>343, <a href='https://arxiv.org/pdf/2505.22469.pdf' target='_blank'>https://arxiv.org/pdf/2505.22469.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamed R. Elshamy, Mehdi Elahi, Ahmad Patooghy, Abdel-Hameed A. Badawy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22469">CPINN-ABPI: Physics-Informed Neural Networks for Accurate Power Estimation in MPSoCs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficient thermal and power management in modern multiprocessor systems-on-chip (MPSoCs) demands accurate power consumption estimation. One of the state-of-the-art approaches, Alternative Blind Power Identification (ABPI), theoretically eliminates the dependence on steady-state temperatures, addressing a major shortcoming of previous approaches. However, ABPI performance has remained unverified in actual hardware implementations. In this study, we conduct the first empirical validation of ABPI on commercial hardware using the NVIDIA Jetson Xavier AGX platform. Our findings reveal that, while ABPI provides computational efficiency and independence from steady-state temperature, it exhibits considerable accuracy deficiencies in real-world scenarios. To overcome these limitations, we introduce a novel approach that integrates Custom Physics-Informed Neural Networks (CPINNs) with the underlying thermal model of ABPI. Our approach employs a specialized loss function that harmonizes physical principles with data-driven learning, complemented by multi-objective genetic algorithm optimization to balance estimation accuracy and computational cost. In experimental validation, CPINN-ABPI achieves a reduction of 84.7\% CPU and 73.9\% GPU in the mean absolute error (MAE) relative to ABPI, with the weighted mean absolute percentage error (WMAPE) improving from 47\%--81\% to $\sim$12\%. The method maintains real-time performance with 195.3~$Î¼$s of inference time, with similar 85\%--99\% accuracy gains across heterogeneous SoCs.
<div id='section'>Paperid: <span id='pid'>344, <a href='https://arxiv.org/pdf/2505.22085.pdf' target='_blank'>https://arxiv.org/pdf/2505.22085.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arnulf Jentzen, Julian Kranz, Adrian Riekert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22085">PADAM: Parallel averaged Adam reduces the error for stochastic optimization in scientific machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Averaging techniques such as Ruppert--Polyak averaging and exponential movering averaging (EMA) are powerful approaches to accelerate optimization procedures of stochastic gradient descent (SGD) optimization methods such as the popular ADAM optimizer. However, depending on the specific optimization problem under consideration, the type and the parameters for the averaging need to be adjusted to achieve the smallest optimization error. In this work we propose an averaging approach, which we refer to as parallel averaged ADAM (PADAM), in which we compute parallely different averaged variants of ADAM and during the training process dynamically select the variant with the smallest optimization error. A central feature of this approach is that this procedure requires no more gradient evaluations than the usual ADAM optimizer as each of the averaged trajectories relies on the same underlying ADAM trajectory and thus on the same underlying gradients. We test the proposed PADAM optimizer in 13 stochastic optimization and deep neural network (DNN) learning problems and compare its performance with known optimizers from the literature such as standard SGD, momentum SGD, Adam with and without EMA, and ADAMW. In particular, we apply the compared optimizers to physics-informed neural network, deep Galerkin, deep backward stochastic differential equation and deep Kolmogorov approximations for boundary value partial differential equation problems from scientific machine learning, as well as to DNN approximations for optimal control and optimal stopping problems. In nearly all of the considered examples PADAM achieves, sometimes among others and sometimes exclusively, essentially the smallest optimization error. This work thus strongly suggest to consider PADAM for scientific machine learning problems and also motivates further research for adaptive averaging procedures within the training of DNNs.
<div id='section'>Paperid: <span id='pid'>345, <a href='https://arxiv.org/pdf/2505.12302.pdf' target='_blank'>https://arxiv.org/pdf/2505.12302.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Zhao, Wenqi Huang, Zicheng Wang, Jiaxuan Hou, Peng Li, Lei Bai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12302">SenseFlow: A Physics-Informed and Self-Ensembling Iterative Framework for Power Flow Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Power flow estimation plays a vital role in ensuring the stability and reliability of electrical power systems, particularly in the context of growing network complexities and renewable energy integration. However, existing studies often fail to adequately address the unique characteristics of power systems, such as the sparsity of network connections and the critical importance of the unique Slack node, which poses significant challenges in achieving high-accuracy estimations. In this paper, we present SenseFlow, a novel physics-informed and self-ensembling iterative framework that integrates two main designs, the Physics-Informed Power Flow Network (FlowNet) and Self-Ensembling Iterative Estimation (SeIter), to carefully address the unique properties of the power system and thereby enhance the power flow estimation. Specifically, SenseFlow enforces the FlowNet to gradually predict high-precision voltage magnitudes and phase angles through the iterative SeIter process. On the one hand, FlowNet employs the Virtual Node Attention and Slack-Gated Feed-Forward modules to facilitate efficient global-local communication in the face of network sparsity and amplify the influence of the Slack node on angle predictions, respectively. On the other hand, SeIter maintains an exponential moving average of FlowNet's parameters to create a robust ensemble model that refines power state predictions throughout the iterative fitting process. Experimental results demonstrate that SenseFlow outperforms existing methods, providing a promising solution for high-accuracy power flow estimation across diverse grid configurations.
<div id='section'>Paperid: <span id='pid'>346, <a href='https://arxiv.org/pdf/2504.16693.pdf' target='_blank'>https://arxiv.org/pdf/2504.16693.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenxuan Li, Hang Zhao, Zhiyuan Yu, Yu Du, Qin Zou, Ruizhen Hu, Kai Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16693">PIN-WM: Learning Physics-INformed World Models for Non-Prehensile Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While non-prehensile manipulation (e.g., controlled pushing/poking) constitutes a foundational robotic skill, its learning remains challenging due to the high sensitivity to complex physical interactions involving friction and restitution. To achieve robust policy learning and generalization, we opt to learn a world model of the 3D rigid body dynamics involved in non-prehensile manipulations and use it for model-based reinforcement learning. We propose PIN-WM, a Physics-INformed World Model that enables efficient end-to-end identification of a 3D rigid body dynamical system from visual observations. Adopting differentiable physics simulation, PIN-WM can be learned with only few-shot and task-agnostic physical interaction trajectories. Further, PIN-WM is learned with observational loss induced by Gaussian Splatting without needing state estimation. To bridge Sim2Real gaps, we turn the learned PIN-WM into a group of Digital Cousins via physics-aware randomizations which perturb physics and rendering parameters to generate diverse and meaningful variations of the PIN-WM. Extensive evaluations on both simulation and real-world tests demonstrate that PIN-WM, enhanced with physics-aware digital cousins, facilitates learning robust non-prehensile manipulation skills with Sim2Real transfer, surpassing the Real2Sim2Real state-of-the-arts.
<div id='section'>Paperid: <span id='pid'>347, <a href='https://arxiv.org/pdf/2503.06994.pdf' target='_blank'>https://arxiv.org/pdf/2503.06994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Zhang, Mukesh Ghimire, Wenlong Zhang, Zhe Xu, Yi Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.06994">Parametric Value Approximation for General-sum Differential Games with State Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>General-sum differential games can approximate values solved by Hamilton-Jacobi-Isaacs (HJI) equations for efficient inference when information is incomplete. However, solving such games through conventional methods encounters the curse of dimensionality (CoD). Physics-informed neural networks (PINNs) offer a scalable approach to alleviate the CoD and approximate values, but there exist convergence issues for value approximations through vanilla PINNs when state constraints lead to values with large Lipschitz constants, particularly in safety-critical applications. In addition to addressing CoD, it is necessary to learn a generalizable value across a parametric space of games, rather than training multiple ones for each specific player-type configuration. To overcome these challenges, we propose a Hybrid Neural Operator (HNO), which is an operator that can map parameter functions for games to value functions. HNO leverages informative supervised data and samples PDE-driven data across entire spatial-temporal space for model refinement. We evaluate HNO on 9D and 13D scenarios with nonlinear dynamics and state constraints, comparing it against a Supervised Neural Operator (a variant of DeepONet). Under the same computational budget and training data, HNO outperforms SNO for safety performance. This work provides a step toward scalable and generalizable value function approximation, enabling real-time inference for complex human-robot or multi-agent interactions.
<div id='section'>Paperid: <span id='pid'>348, <a href='https://arxiv.org/pdf/2503.05201.pdf' target='_blank'>https://arxiv.org/pdf/2503.05201.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rajnish Kumar, Tapas Tripura, Souvik Chakraborty, Sitikantha Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05201">Deep Muscle EMG construction using A Physics-Integrated Deep Learning approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electromyography (EMG)--based computational musculoskeletal modeling is a non-invasive method for studying musculotendon function, human movement, and neuromuscular control, providing estimates of internal variables like muscle forces and joint torques. However, EMG signals from deeper muscles are often challenging to measure by placing the surface EMG electrodes and unfeasible to measure directly using invasive methods. The restriction to the access of EMG data from deeper muscles poses a considerable obstacle to the broad adoption of EMG-driven modeling techniques. A strategic alternative is to use an estimation algorithm to approximate the missing EMG signals from deeper muscle. A similar strategy is used in physics-informed deep learning, where the features of physical systems are learned without labeled data. In this work, we propose a hybrid deep learning algorithm, namely the neural musculoskeletal model (NMM), that integrates physics-informed and data-driven deep learning to approximate the EMG signals from the deeper muscles. While data-driven modeling is used to predict the missing EMG signals, physics-based modeling engraves the subject-specific information into the predictions. Experimental verifications on five test subjects are carried out to investigate the performance of the proposed hybrid framework. The proposed NMM is validated against the joint torque computed from 'OpenSim' software. The predicted deep EMG signals are also compared against the state-of-the-art muscle synergy extrapolation (MSE) approach, where the proposed NMM completely outperforms the existing MSE framework by a significant margin.
<div id='section'>Paperid: <span id='pid'>349, <a href='https://arxiv.org/pdf/2502.00782.pdf' target='_blank'>https://arxiv.org/pdf/2502.00782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizheng Wang, Jinshuai Bai, Mohammad Sadegh Eshaghi, Cosmin Anitescu, Xiaoying Zhuang, Timon Rabczuk, Yinghua Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00782">Transfer Learning in Physics-Informed Neural Networks: Full Fine-Tuning, Lightweight Fine-Tuning, and Low-Rank Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI for PDEs has garnered significant attention, particularly Physics-Informed Neural Networks (PINNs). However, PINNs are typically limited to solving specific problems, and any changes in problem conditions necessitate retraining. Therefore, we explore the generalization capability of transfer learning in the strong and energy form of PINNs across different boundary conditions, materials, and geometries. The transfer learning methods we employ include full finetuning, lightweight finetuning, and Low-Rank Adaptation (LoRA). The results demonstrate that full finetuning and LoRA can significantly improve convergence speed while providing a slight enhancement in accuracy.
<div id='section'>Paperid: <span id='pid'>350, <a href='https://arxiv.org/pdf/2502.00162.pdf' target='_blank'>https://arxiv.org/pdf/2502.00162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eron Ristich, Lei Zhang, Yi Ren, Jiefeng Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00162">Physics-informed Split Koopman Operators for Data-efficient Soft Robotic Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Koopman operator theory provides a powerful data-driven technique for modeling nonlinear dynamical systems in a linear framework, in comparison to computationally expensive and highly nonlinear physics-based simulations. However, Koopman operator-based models for soft robots are very high dimensional and require considerable amounts of data to properly resolve. Inspired by physics-informed techniques from machine learning, we present a novel physics-informed Koopman operator identification method that improves simulation accuracy for small dataset sizes. Through Strang splitting, the method takes advantage of both continuous and discrete Koopman operator approximation to obtain information both from trajectory and phase space data. The method is validated on a tendon-driven soft robotic arm, showing orders of magnitude improvement over standard methods in terms of the shape error. We envision this method can significantly reduce the data requirement of Koopman operators for systems with partially known physical models, and thus reduce the cost of obtaining data.
<div id='section'>Paperid: <span id='pid'>351, <a href='https://arxiv.org/pdf/2501.06572.pdf' target='_blank'>https://arxiv.org/pdf/2501.06572.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Cheng Wong, Abhishek Gupta, Chin Chun Ooi, Pao-Hsiung Chiu, Jiao Liu, Yew-Soon Ong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06572">Evolutionary Optimization of Physics-Informed Neural Networks: Evo-PINN Frontiers and Opportunities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models trained on finite data lack a complete understanding of the physical world. On the other hand, physics-informed neural networks (PINNs) are infused with such knowledge through the incorporation of mathematically expressible laws of nature into their training loss function. By complying with physical laws, PINNs provide advantages over purely data-driven models in limited-data regimes and present as a promising route towards Physical AI. This feature has propelled them to the forefront of scientific machine learning, a domain characterized by scarce and costly data. However, the vision of accurate physics-informed learning comes with significant challenges. This work examines PINNs for the first time in terms of model optimization and generalization, shedding light on the need for new algorithmic advances to overcome issues pertaining to the training speed, precision, and generalizability of today's PINN models. Of particular interest are gradient-free evolutionary algorithms (EAs) for optimizing the uniquely complex loss landscapes arising in PINN training. Methods synergizing gradient descent and EAs for discovering bespoke neural architectures and balancing multiple terms in physics-informed learning objectives are positioned as important avenues for future research. Another exciting track is to cast evolutionary as a meta-learner of generalizable PINN models. To substantiate these proposed avenues, we further highlight results from recent literature to showcase the early success of such approaches in addressing the aforementioned challenges in PINN optimization and generalization.
<div id='section'>Paperid: <span id='pid'>352, <a href='https://arxiv.org/pdf/2501.06572.pdf' target='_blank'>https://arxiv.org/pdf/2501.06572.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Cheng Wong, Abhishek Gupta, Chin Chun Ooi, Pao-Hsiung Chiu, Jiao Liu, Yew-Soon Ong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06572">Evolutionary Optimization of Physics-Informed Neural Networks: Evo-PINN Frontiers and Opportunities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models trained on finite data lack a complete understanding of the physical world. On the other hand, physics-informed neural networks (PINNs) are infused with such knowledge through the incorporation of mathematically expressible laws of nature into their training loss function. By complying with physical laws, PINNs provide advantages over purely data-driven models in limited-data regimes and present as a promising route towards Physical AI. This feature has propelled them to the forefront of scientific machine learning, a domain characterized by scarce and costly data. However, the vision of accurate physics-informed learning comes with significant challenges. This work examines PINNs in terms of model optimization and generalization, shedding light on the need for new algorithmic advances to overcome issues pertaining to the training speed, precision, and generalizability of today's PINN models. Of particular interest are gradient-free evolutionary algorithms (EAs) for optimizing the uniquely complex loss landscapes arising in PINN training. Methods synergizing gradient descent and EAs for discovering bespoke neural architectures and balancing multiple terms in physics-informed learning objectives are positioned as important avenues for future research. Another exciting track is to cast EAs as a meta-learner of generalizable PINN models. To substantiate these proposed avenues, we further highlight results from recent literature to showcase the early success of such approaches in addressing the aforementioned challenges in PINN optimization and generalization.
<div id='section'>Paperid: <span id='pid'>353, <a href='https://arxiv.org/pdf/2501.00742.pdf' target='_blank'>https://arxiv.org/pdf/2501.00742.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yequan Zhao, Xian Xiao, Antoine Descos, Yuan Yuan, Xinling Yu, Geza Kurczveil, Marco Fiorentino, Zheng Zhang, Raymond G. Beausoleil
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.00742">Experimental Demonstration of an Optical Neural PDE Solver via On-Chip PINN Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial differential equation (PDE) is an important math tool in science and engineering. This paper experimentally demonstrates an optical neural PDE solver by leveraging the back-propagation-free on-photonic-chip training of physics-informed neural networks.
<div id='section'>Paperid: <span id='pid'>354, <a href='https://arxiv.org/pdf/2412.13321.pdf' target='_blank'>https://arxiv.org/pdf/2412.13321.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tiankai Xie, Jiaqing Chen, Yaoqing Yang, Caleb Geniesse, Ge Shi, Ajinkya Chaudhari, John Kevin Cava, Michael W. Mahoney, Talita Perciano, Gunther H. Weber, Ross Maciejewski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13321">LossLens: Diagnostics for Machine Learning through Loss Landscape Visual Analytics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern machine learning often relies on optimizing a neural network's parameters using a loss function to learn complex features. Beyond training, examining the loss function with respect to a network's parameters (i.e., as a loss landscape) can reveal insights into the architecture and learning process. While the local structure of the loss landscape surrounding an individual solution can be characterized using a variety of approaches, the global structure of a loss landscape, which includes potentially many local minima corresponding to different solutions, remains far more difficult to conceptualize and visualize. To address this difficulty, we introduce LossLens, a visual analytics framework that explores loss landscapes at multiple scales. LossLens integrates metrics from global and local scales into a comprehensive visual representation, enhancing model diagnostics. We demonstrate LossLens through two case studies: visualizing how residual connections influence a ResNet-20, and visualizing how physical parameters influence a physics-informed neural network (PINN) solving a simple convection problem.
<div id='section'>Paperid: <span id='pid'>355, <a href='https://arxiv.org/pdf/2412.08681.pdf' target='_blank'>https://arxiv.org/pdf/2412.08681.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Ghanem, Ahmet Demirkaya, Tales Imbiriba, Alireza Ramezani, Zachary Danziger, Deniz Erdogmus
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.08681">Learning Physics Informed Neural ODEs With Partial Measurements</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning dynamics governing physical and spatiotemporal processes is a challenging problem, especially in scenarios where states are partially measured. In this work, we tackle the problem of learning dynamics governing these systems when parts of the system's states are not measured, specifically when the dynamics generating the non-measured states are unknown. Inspired by state estimation theory and Physics Informed Neural ODEs, we present a sequential optimization framework in which dynamics governing unmeasured processes can be learned. We demonstrate the performance of the proposed approach leveraging numerical simulations and a real dataset extracted from an electro-mechanical positioning system. We show how the underlying equations fit into our formalism and demonstrate the improved performance of the proposed method when compared with baselines.
<div id='section'>Paperid: <span id='pid'>356, <a href='https://arxiv.org/pdf/2412.07637.pdf' target='_blank'>https://arxiv.org/pdf/2412.07637.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Hagemann, Janina SchÃ¼tte, David Sommer, Martin Eigel, Gabriele Steidl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07637">Sampling from Boltzmann densities with physics informed low-rank formats</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Our method proposes the efficient generation of samples from an unnormalized Boltzmann density by solving the underlying continuity equation in the low-rank tensor train (TT) format. It is based on the annealing path commonly used in MCMC literature, which is given by the linear interpolation in the space of energies. Inspired by Sequential Monte Carlo, we alternate between deterministic time steps from the TT representation of the flow field and stochastic steps, which include Langevin and resampling steps. These adjust the relative weights of the different modes of the target distribution and anneal to the correct path distribution. We showcase the efficiency of our method on multiple numerical examples.
<div id='section'>Paperid: <span id='pid'>357, <a href='https://arxiv.org/pdf/2412.02807.pdf' target='_blank'>https://arxiv.org/pdf/2412.02807.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruikun Zhou, Yiming Meng, Zhexuan Zeng, Jun Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02807">Learning Koopman-based Stability Certificates for Unknown Nonlinear Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Koopman operator theory has gained significant attention in recent years for identifying discrete-time nonlinear systems by embedding them into an infinite-dimensional linear vector space. However, providing stability guarantees while learning the continuous-time dynamics, especially under conditions of relatively low observation frequency, remains a challenge within the existing Koopman-based learning frameworks. To address this challenge, we propose an algorithmic framework to simultaneously learn the vector field and Lyapunov functions for unknown nonlinear systems, using a limited amount of data sampled across the state space and along the trajectories at a relatively low sampling frequency. The proposed framework builds upon recently developed high-accuracy Koopman generator learning for capturing transient system transitions and physics-informed neural networks for training Lyapunov functions. We show that the learned Lyapunov functions can be formally verified using a satisfiability modulo theories (SMT) solver and provide less conservative estimates of the region of attraction compared to existing methods.
<div id='section'>Paperid: <span id='pid'>358, <a href='https://arxiv.org/pdf/2412.00088.pdf' target='_blank'>https://arxiv.org/pdf/2412.00088.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zekun Shi, Zheyuan Hu, Min Lin, Kenji Kawaguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00088">Stochastic Taylor Derivative Estimator: Efficient amortization for arbitrary differential operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optimizing neural networks with loss that contain high-dimensional and high-order differential operators is expensive to evaluate with back-propagation due to $\mathcal{O}(d^{k})$ scaling of the derivative tensor size and the $\mathcal{O}(2^{k-1}L)$ scaling in the computation graph, where $d$ is the dimension of the domain, $L$ is the number of ops in the forward computation graph, and $k$ is the derivative order. In previous works, the polynomial scaling in $d$ was addressed by amortizing the computation over the optimization process via randomization. Separately, the exponential scaling in $k$ for univariate functions ($d=1$) was addressed with high-order auto-differentiation (AD). In this work, we show how to efficiently perform arbitrary contraction of the derivative tensor of arbitrary order for multivariate functions, by properly constructing the input tangents to univariate high-order AD, which can be used to efficiently randomize any differential operator. When applied to Physics-Informed Neural Networks (PINNs), our method provides >1000$\times$ speed-up and >30$\times$ memory reduction over randomization with first-order AD, and we can now solve \emph{1-million-dimensional PDEs in 8 minutes on a single NVIDIA A100 GPU}. This work opens the possibility of using high-order differential operators in large-scale problems.
<div id='section'>Paperid: <span id='pid'>359, <a href='https://arxiv.org/pdf/2411.12136.pdf' target='_blank'>https://arxiv.org/pdf/2411.12136.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Caleb Geniesse, Jiaqing Chen, Tiankai Xie, Ge Shi, Yaoqing Yang, Dmitriy Morozov, Talita Perciano, Michael W. Mahoney, Ross Maciejewski, Gunther H. Weber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.12136">Visualizing Loss Functions as Topological Landscape Profiles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In machine learning, a loss function measures the difference between model predictions and ground-truth (or target) values. For neural network models, visualizing how this loss changes as model parameters are varied can provide insights into the local structure of the so-called loss landscape (e.g., smoothness) as well as global properties of the underlying model (e.g., generalization performance). While various methods for visualizing the loss landscape have been proposed, many approaches limit sampling to just one or two directions, ignoring potentially relevant information in this extremely high-dimensional space. This paper introduces a new representation based on topological data analysis that enables the visualization of higher-dimensional loss landscapes. After describing this new topological landscape profile representation, we show how the shape of loss landscapes can reveal new details about model performance and learning dynamics, highlighting several use cases, including image segmentation (e.g., UNet) and scientific machine learning (e.g., physics-informed neural networks). Through these examples, we provide new insights into how loss landscapes vary across distinct hyperparameter spaces: we find that the topology of the loss landscape is simpler for better-performing models; and we observe greater variation in the shape of loss landscapes near transitions from low to high model performance.
<div id='section'>Paperid: <span id='pid'>360, <a href='https://arxiv.org/pdf/2411.09807.pdf' target='_blank'>https://arxiv.org/pdf/2411.09807.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tiankai Xie, Caleb Geniesse, Jiaqing Chen, Yaoqing Yang, Dmitriy Morozov, Michael W. Mahoney, Ross Maciejewski, Gunther H. Weber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.09807">Evaluating Loss Landscapes from a Topology Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Characterizing the loss of a neural network with respect to model parameters, i.e., the loss landscape, can provide valuable insights into properties of that model. Various methods for visualizing loss landscapes have been proposed, but less emphasis has been placed on quantifying and extracting actionable and reproducible insights from these complex representations. Inspired by powerful tools from topological data analysis (TDA) for summarizing the structure of high-dimensional data, here we characterize the underlying shape (or topology) of loss landscapes, quantifying the topology to reveal new insights about neural networks. To relate our findings to the machine learning (ML) literature, we compute simple performance metrics (e.g., accuracy, error), and we characterize the local structure of loss landscapes using Hessian-based metrics (e.g., largest eigenvalue, trace, eigenvalue spectral density). Following this approach, we study established models from image pattern recognition (e.g., ResNets) and scientific ML (e.g., physics-informed neural networks), and we show how quantifying the shape of loss landscapes can provide new insights into model performance and learning dynamics.
<div id='section'>Paperid: <span id='pid'>361, <a href='https://arxiv.org/pdf/2410.20275.pdf' target='_blank'>https://arxiv.org/pdf/2410.20275.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ze Hu, Ziqing Zhu, Linghua Zhu, Xiang Wei, Siqi Bu, Ka Wing Chan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20275">Advancing Hybrid Quantum Neural Network for Alternative Current Optimal Power Flow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Alternative Current Optimal Power Flow (AC-OPF) is essential for efficient power system planning and real-time operation but remains an NP-hard and non-convex optimization problem with significant computational challenges. This paper proposes a novel hybrid classical-quantum deep learning framework for AC-OPF problem, integrating parameterized quantum circuits (PQCs) for feature extraction with classical deep learning for data encoding and decoding. The proposed framework integrates two types of residual connection structures to mitigate the ``barren plateau" problem in quantum circuits, enhancing training stability and convergence. Furthermore, a physics-informed neural network (PINN) module is incorporated to guarantee tolerable constraint violation, improving the physical consistency and reliability of AC-OPF solutions. Experimental evaluations on multiple IEEE test systems demonstrate that the proposed approach achieves superior accuracy, generalization, and robustness to quantum noise while requiring minimal quantum resources.
<div id='section'>Paperid: <span id='pid'>362, <a href='https://arxiv.org/pdf/2410.19843.pdf' target='_blank'>https://arxiv.org/pdf/2410.19843.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizheng Wang, Jinshuai Bai, Zhongya Lin, Qimin Wang, Cosmin Anitescu, Jia Sun, Mohammad Sadegh Eshaghi, Yuantong Gu, Xi-Qiao Feng, Xiaoying Zhuang, Timon Rabczuk, Yinghua Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19843">Artificial intelligence for partial differential equations in computational mechanics: A review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, Artificial intelligence (AI) has become ubiquitous, empowering various fields, especially integrating artificial intelligence and traditional science (AI for Science: Artificial intelligence for science), which has attracted widespread attention. In AI for Science, using artificial intelligence algorithms to solve partial differential equations (AI for PDEs: Artificial intelligence for partial differential equations) has become a focal point in computational mechanics. The core of AI for PDEs is the fusion of data and partial differential equations (PDEs), which can solve almost any PDEs. Therefore, this article provides a comprehensive review of the research on AI for PDEs, summarizing the existing algorithms and theories. The article discusses the applications of AI for PDEs in computational mechanics, including solid mechanics, fluid mechanics, and biomechanics. The existing AI for PDEs algorithms include those based on Physics-Informed Neural Networks (PINNs), Deep Energy Methods (DEM), Operator Learning, and Physics-Informed Neural Operator (PINO). AI for PDEs represents a new method of scientific simulation that provides approximate solutions to specific problems using large amounts of data, then fine-tuning according to specific physical laws, avoiding the need to compute from scratch like traditional algorithms. Thus, AI for PDEs is the prototype for future foundation models in computational mechanics, capable of significantly accelerating traditional numerical algorithms.
<div id='section'>Paperid: <span id='pid'>363, <a href='https://arxiv.org/pdf/2410.03573.pdf' target='_blank'>https://arxiv.org/pdf/2410.03573.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Madison Cooley, Robert M. Kirby, Shandian Zhe, Varun Shankar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.03573">HyResPINNs: Hybrid Residual Networks for Adaptive Neural and RBF Integration in Solving PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a powerful approach for solving partial differential equations (PDEs) by training neural networks with loss functions that incorporate physical constraints. In this work, we introduce HyResPINNs, a novel class of PINNs featuring adaptive hybrid residual blocks that integrate standard neural networks and radial basis function (RBF) networks. A distinguishing characteristic of HyResPINNs is the use of adaptive combination parameters within each residual block, enabling dynamic weighting of the neural and RBF network contributions. Our empirical evaluation of a diverse set of challenging PDE problems demonstrates that HyResPINNs consistently achieve superior accuracy to baseline methods. These results highlight the potential of HyResPINNs to bridge the gap between classical numerical methods and modern machine learning-based solvers, paving the way for more robust and adaptive approaches to physics-informed modeling.
<div id='section'>Paperid: <span id='pid'>364, <a href='https://arxiv.org/pdf/2410.03496.pdf' target='_blank'>https://arxiv.org/pdf/2410.03496.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Madison Cooley, Varun Shankar, Robert M. Kirby, Shandian Zhe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.03496">Fourier PINNs: From Strong Boundary Conditions to Adaptive Fourier Bases</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Interest is rising in Physics-Informed Neural Networks (PINNs) as a mesh-free alternative to traditional numerical solvers for partial differential equations (PDEs). However, PINNs often struggle to learn high-frequency and multi-scale target solutions. To tackle this problem, we first study a strong Boundary Condition (BC) version of PINNs for Dirichlet BCs and observe a consistent decline in relative error compared to the standard PINNs. We then perform a theoretical analysis based on the Fourier transform and convolution theorem. We find that strong BC PINNs can better learn the amplitudes of high-frequency components of the target solutions. However, constructing the architecture for strong BC PINNs is difficult for many BCs and domain geometries. Enlightened by our theoretical analysis, we propose Fourier PINNs -- a simple, general, yet powerful method that augments PINNs with pre-specified, dense Fourier bases. Our proposed architecture likewise learns high-frequency components better but places no restrictions on the particular BCs or problem domains. We develop an adaptive learning and basis selection algorithm via alternating neural net basis optimization, Fourier and neural net basis coefficient estimation, and coefficient truncation. This scheme can flexibly identify the significant frequencies while weakening the nominal frequencies to better capture the target solution's power spectrum. We show the advantage of our approach through a set of systematic experiments.
<div id='section'>Paperid: <span id='pid'>365, <a href='https://arxiv.org/pdf/2409.20528.pdf' target='_blank'>https://arxiv.org/pdf/2409.20528.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Liu, Maxwell Fitzsimmons, Ruikun Zhou, Yiming Meng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.20528">Formally Verified Physics-Informed Neural Control Lyapunov Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Control Lyapunov functions are a central tool in the design and analysis of stabilizing controllers for nonlinear systems. Constructing such functions, however, remains a significant challenge. In this paper, we investigate physics-informed learning and formal verification of neural network control Lyapunov functions. These neural networks solve a transformed Hamilton-Jacobi-Bellman equation, augmented by data generated using Pontryagin's maximum principle. Similar to how Zubov's equation characterizes the domain of attraction for autonomous systems, this equation characterizes the null-controllability set of a controlled system. This principled learning of neural network control Lyapunov functions outperforms alternative approaches, such as sum-of-squares and rational control Lyapunov functions, as demonstrated by numerical examples. As an intermediate step, we also present results on the formal verification of quadratic control Lyapunov functions, which, aided by satisfiability modulo theories solvers, can perform surprisingly well compared to more sophisticated approaches and efficiently produce global certificates of null-controllability.
<div id='section'>Paperid: <span id='pid'>366, <a href='https://arxiv.org/pdf/2408.13222.pdf' target='_blank'>https://arxiv.org/pdf/2408.13222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Gonon, Arnulf Jentzen, Benno Kuckuck, Siyu Liang, Adrian Riekert, Philippe von Wurstemberger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.13222">An Overview on Machine Learning Methods for Partial Differential Equations: from Physics Informed Neural Networks to Deep Operator Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The approximation of solutions of partial differential equations (PDEs) with numerical algorithms is a central topic in applied mathematics. For many decades, various types of methods for this purpose have been developed and extensively studied. One class of methods which has received a lot of attention in recent years are machine learning-based methods, which typically involve the training of artificial neural networks (ANNs) by means of stochastic gradient descent type optimization methods. While approximation methods for PDEs using ANNs have first been proposed in the 1990s they have only gained wide popularity in the last decade with the rise of deep learning. This article aims to provide an introduction to some of these methods and the mathematical theory on which they are based. We discuss methods such as physics-informed neural networks (PINNs) and deep BSDE methods and consider several operator learning approaches.
<div id='section'>Paperid: <span id='pid'>367, <a href='https://arxiv.org/pdf/2406.14340.pdf' target='_blank'>https://arxiv.org/pdf/2406.14340.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steffen Dereich, Arnulf Jentzen, Adrian Riekert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14340">Learning rate adaptive stochastic gradient descent optimization methods: numerical simulations for deep learning methods for partial differential equations and convergence analyses</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It is known that the standard stochastic gradient descent (SGD) optimization method, as well as accelerated and adaptive SGD optimization methods such as the Adam optimizer fail to converge if the learning rates do not converge to zero (as, for example, in the situation of constant learning rates). Numerical simulations often use human-tuned deterministic learning rate schedules or small constant learning rates. The default learning rate schedules for SGD optimization methods in machine learning implementation frameworks such as TensorFlow and Pytorch are constant learning rates. In this work we propose and study a learning-rate-adaptive approach for SGD optimization methods in which the learning rate is adjusted based on empirical estimates for the values of the objective function of the considered optimization problem (the function that one intends to minimize). In particular, we propose a learning-rate-adaptive variant of the Adam optimizer and implement it in case of several neural network learning problems, particularly, in the context of deep learning approximation methods for partial differential equations such as deep Kolmogorov methods, physics-informed neural networks, and deep Ritz methods. In each of the presented learning problems the proposed learning-rate-adaptive variant of the Adam optimizer faster reduces the value of the objective function than the Adam optimizer with the default learning rate. For a simple class of quadratic minimization problems we also rigorously prove that a learning-rate-adaptive variant of the SGD optimization method converges to the minimizer of the considered minimization problem. Our convergence proof is based on an analysis of the laws of invariant measures of the SGD method as well as on a more general convergence analysis for SGD with random but predictable learning rates which we develop in this work.
<div id='section'>Paperid: <span id='pid'>368, <a href='https://arxiv.org/pdf/2406.11708.pdf' target='_blank'>https://arxiv.org/pdf/2406.11708.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheyuan Hu, Kenji Kawaguchi, Zhongqiang Zhang, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11708">Tackling the Curse of Dimensionality in Fractional and Tempered Fractional PDEs with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fractional and tempered fractional partial differential equations (PDEs) are effective models of long-range interactions, anomalous diffusion, and non-local effects. Traditional numerical methods for these problems are mesh-based, thus struggling with the curse of dimensionality (CoD). Physics-informed neural networks (PINNs) offer a promising solution due to their universal approximation, generalization ability, and mesh-free training. In principle, Monte Carlo fractional PINN (MC-fPINN) estimates fractional derivatives using Monte Carlo methods and thus could lift CoD. However, this may cause significant variance and errors, hence affecting convergence; in addition, MC-fPINN is sensitive to hyperparameters. In general, numerical methods and specifically PINNs for tempered fractional PDEs are under-developed. Herein, we extend MC-fPINN to tempered fractional PDEs to address these issues, resulting in the Monte Carlo tempered fractional PINN (MC-tfPINN). To reduce possible high variance and errors from Monte Carlo sampling, we replace the one-dimensional (1D) Monte Carlo with 1D Gaussian quadrature, applicable to both MC-fPINN and MC-tfPINN. We validate our methods on various forward and inverse problems of fractional and tempered fractional PDEs, scaling up to 100,000 dimensions. Our improved MC-fPINN/MC-tfPINN using quadrature consistently outperforms the original versions in accuracy and convergence speed in very high dimensions.
<div id='section'>Paperid: <span id='pid'>369, <a href='https://arxiv.org/pdf/2406.11676.pdf' target='_blank'>https://arxiv.org/pdf/2406.11676.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheyuan Hu, Zhongqiang Zhang, George Em Karniadakis, Kenji Kawaguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11676">Score-fPINN: Fractional Score-Based Physics-Informed Neural Networks for High-Dimensional Fokker-Planck-Levy Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce an innovative approach for solving high-dimensional Fokker-Planck-LÃ©vy (FPL) equations in modeling non-Brownian processes across disciplines such as physics, finance, and ecology. We utilize a fractional score function and Physical-informed neural networks (PINN) to lift the curse of dimensionality (CoD) and alleviate numerical overflow from exponentially decaying solutions with dimensions. The introduction of a fractional score function allows us to transform the FPL equation into a second-order partial differential equation without fractional Laplacian and thus can be readily solved with standard physics-informed neural networks (PINNs). We propose two methods to obtain a fractional score function: fractional score matching (FSM) and score-fPINN for fitting the fractional score function. While FSM is more cost-effective, it relies on known conditional distributions. On the other hand, score-fPINN is independent of specific stochastic differential equations (SDEs) but requires evaluating the PINN model's derivatives, which may be more costly. We conduct our experiments on various SDEs and demonstrate numerical stability and effectiveness of our method in dealing with high-dimensional problems, marking a significant advancement in addressing the CoD in FPL equations.
<div id='section'>Paperid: <span id='pid'>370, <a href='https://arxiv.org/pdf/2406.11045.pdf' target='_blank'>https://arxiv.org/pdf/2406.11045.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizheng Wang, Jia Sun, Jinshuai Bai, Cosmin Anitescu, Mohammad Sadegh Eshaghi, Xiaoying Zhuang, Timon Rabczuk, Yinghua Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11045">Kolmogorov Arnold Informed neural network: A physics-informed deep learning framework for solving forward and inverse problems based on Kolmogorov Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>AI for partial differential equations (PDEs) has garnered significant attention, particularly with the emergence of Physics-informed neural networks (PINNs). The recent advent of Kolmogorov-Arnold Network (KAN) indicates that there is potential to revisit and enhance the previously MLP-based PINNs. Compared to MLPs, KANs offer interpretability and require fewer parameters. PDEs can be described in various forms, such as strong form, energy form, and inverse form. While mathematically equivalent, these forms are not computationally equivalent, making the exploration of different PDE formulations significant in computational physics. Thus, we propose different PDE forms based on KAN instead of MLP, termed Kolmogorov-Arnold-Informed Neural Network (KINN) for solving forward and inverse problems. We systematically compare MLP and KAN in various numerical examples of PDEs, including multi-scale, singularity, stress concentration, nonlinear hyperelasticity, heterogeneous, and complex geometry problems. Our results demonstrate that KINN significantly outperforms MLP regarding accuracy and convergence speed for numerous PDEs in computational solid mechanics, except for the complex geometry problem. This highlights KINN's potential for more efficient and accurate PDE solutions in AI for PDEs.
<div id='section'>Paperid: <span id='pid'>371, <a href='https://arxiv.org/pdf/2404.05615.pdf' target='_blank'>https://arxiv.org/pdf/2404.05615.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taorui Wang, Zheyuan Hu, Kenji Kawaguchi, Zhongqiang Zhang, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.05615">Tensor neural networks for high-dimensional Fokker-Planck equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We solve high-dimensional steady-state Fokker-Planck equations on the whole space by applying tensor neural networks. The tensor networks are a linear combination of tensor products of one-dimensional feedforward networks or a linear combination of several selected radial basis functions. The use of tensor feedforward networks allows us to efficiently exploit auto-differentiation (in physical variables) in major Python packages while using radial basis functions can fully avoid auto-differentiation, which is rather expensive in high dimensions. We then use the physics-informed neural networks and stochastic gradient descent methods to learn the tensor networks. One essential step is to determine a proper bounded domain or numerical support for the Fokker-Planck equation. To better train the tensor radial basis function networks, we impose some constraints on parameters, which lead to relatively high accuracy. We demonstrate numerically that the tensor neural networks in physics-informed machine learning are efficient for steady-state Fokker-Planck equations from two to ten dimensions.
<div id='section'>Paperid: <span id='pid'>372, <a href='https://arxiv.org/pdf/2403.10013.pdf' target='_blank'>https://arxiv.org/pdf/2403.10013.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Liu, Yiming Meng, Maxwell Fitzsimmons, Ruikun Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10013">LyZNet: A Lightweight Python Tool for Learning and Verifying Neural Lyapunov Functions and Regions of Attraction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we describe a lightweight Python framework that provides integrated learning and verification of neural Lyapunov functions for stability analysis. The proposed tool, named LyZNet, learns neural Lyapunov functions using physics-informed neural networks (PINNs) to solve Zubov's equation and verifies them using satisfiability modulo theories (SMT) solvers. What distinguishes this tool from others in the literature is its ability to provide verified regions of attraction close to the domain of attraction. This is achieved by encoding Zubov's partial differential equation (PDE) into the PINN approach. By embracing the non-convex nature of the underlying optimization problems, we demonstrate that in cases where convex optimization, such as semidefinite programming, fails to capture the domain of attraction, our neural network framework proves more successful. The tool also offers automatic decomposition of coupled nonlinear systems into a network of low-dimensional subsystems for compositional verification. We illustrate the tool's usage and effectiveness with several numerical examples, including both non-trivial low-dimensional nonlinear systems and high-dimensional systems. The repository of the tool can be found at https://git.uwaterloo.ca/hybrid-systems-lab/lyznet.
<div id='section'>Paperid: <span id='pid'>373, <a href='https://arxiv.org/pdf/2402.10119.pdf' target='_blank'>https://arxiv.org/pdf/2402.10119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiming Meng, Ruikun Zhou, Amartya Mukherjee, Maxwell Fitzsimmons, Christopher Song, Jun Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10119">Physics-Informed Neural Network Policy Iteration: Algorithms, Convergence, and Verification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving nonlinear optimal control problems is a challenging task, particularly for high-dimensional problems. We propose algorithms for model-based policy iterations to solve nonlinear optimal control problems with convergence guarantees. The main component of our approach is an iterative procedure that utilizes neural approximations to solve linear partial differential equations (PDEs), ensuring convergence. We present two variants of the algorithms. The first variant formulates the optimization problem as a linear least square problem, drawing inspiration from extreme learning machine (ELM) for solving PDEs. This variant efficiently handles low-dimensional problems with high accuracy. The second variant is based on a physics-informed neural network (PINN) for solving PDEs and has the potential to address high-dimensional problems. We demonstrate that both algorithms outperform traditional approaches, such as Galerkin methods, by a significant margin. We provide a theoretical analysis of both algorithms in terms of convergence of neural approximations towards the true optimal solutions in a general setting. Furthermore, we employ formal verification techniques to demonstrate the verifiable stability of the resulting controllers.
<div id='section'>Paperid: <span id='pid'>374, <a href='https://arxiv.org/pdf/2402.07465.pdf' target='_blank'>https://arxiv.org/pdf/2402.07465.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheyuan Hu, Zhongqiang Zhang, George Em Karniadakis, Kenji Kawaguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07465">Score-Based Physics-Informed Neural Networks for High-Dimensional Fokker-Planck Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Fokker-Planck (FP) equation is a foundational PDE in stochastic processes. However, curse of dimensionality (CoD) poses challenge when dealing with high-dimensional FP PDEs. Although Monte Carlo and vanilla Physics-Informed Neural Networks (PINNs) have shown the potential to tackle CoD, both methods exhibit numerical errors in high dimensions when dealing with the probability density function (PDF) associated with Brownian motion. The point-wise PDF values tend to decrease exponentially as dimension increases, surpassing the precision of numerical simulations and resulting in substantial errors. Moreover, due to its massive sampling, Monte Carlo fails to offer fast sampling. Modeling the logarithm likelihood (LL) via vanilla PINNs transforms the FP equation into a difficult HJB equation, whose error grows rapidly with dimension. To this end, we propose a novel approach utilizing a score-based solver to fit the score function in SDEs. The score function, defined as the gradient of the LL, plays a fundamental role in inferring LL and PDF and enables fast SDE sampling. Three fitting methods, Score Matching (SM), Sliced SM (SSM), and Score-PINN, are introduced. The proposed score-based SDE solver operates in two stages: first, employing SM, SSM, or Score-PINN to acquire the score; and second, solving the LL via an ODE using the obtained score. Comparative evaluations across these methods showcase varying trade-offs. The proposed method is evaluated across diverse SDEs, including anisotropic OU processes, geometric Brownian, and Brownian with varying eigenspace. We also test various distributions, including Gaussian, Log-normal, Laplace, and Cauchy. The numerical results demonstrate the score-based SDE solver's stability, speed, and performance across different settings, solidifying its potential as a solution to CoD for high-dimensional FP equations.
<div id='section'>Paperid: <span id='pid'>375, <a href='https://arxiv.org/pdf/2401.01502.pdf' target='_blank'>https://arxiv.org/pdf/2401.01502.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Zhang, Mukesh Ghimire, Zhe Xu, Wenlong Zhang, Yi Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01502">Pontryagin Neural Operator for Solving Parametric General-Sum Differential Games</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The values of two-player general-sum differential games are viscosity solutions to Hamilton-Jacobi-Isaacs (HJI) equations. Value and policy approximations for such games suffer from the curse of dimensionality (CoD). Alleviating CoD through physics-informed neural networks (PINN) encounters convergence issues when differentiable values with large Lipschitz constants are present due to state constraints. On top of these challenges, it is often necessary to learn generalizable values and policies across a parametric space of games, e.g., for game parameter inference when information is incomplete. To address these challenges, we propose in this paper a Pontryagin-mode neural operator that outperforms the current state-of-the-art hybrid PINN model on safety performance across games with parametric state constraints. Our key contribution is the introduction of a costate loss defined on the discrepancy between forward and backward costate rollouts, which are computationally cheap. We show that the costate dynamics, which can reflect state constraint violation, effectively enables the learning of differentiable values with large Lipschitz constants, without requiring manually supervised data as suggested by the hybrid PINN model. More importantly, we show that the close relationship between costates and policies makes the former critical in learning feedback control policies with generalizable safety performance.
<div id='section'>Paperid: <span id='pid'>376, <a href='https://arxiv.org/pdf/2312.14499.pdf' target='_blank'>https://arxiv.org/pdf/2312.14499.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheyuan Hu, Zekun Shi, George Em Karniadakis, Kenji Kawaguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.14499">Hutchinson Trace Estimation for High-Dimensional and High-Order Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have proven effective in solving partial differential equations (PDEs), especially when some data are available by seamlessly blending data and physics. However, extending PINNs to high-dimensional and even high-order PDEs encounters significant challenges due to the computational cost associated with automatic differentiation in the residual loss. Herein, we address the limitations of PINNs in handling high-dimensional and high-order PDEs by introducing Hutchinson Trace Estimation (HTE). Starting with the second-order high-dimensional PDEs ubiquitous in scientific computing, HTE transforms the calculation of the entire Hessian matrix into a Hessian vector product (HVP). This approach alleviates the computational bottleneck via Taylor-mode automatic differentiation and significantly reduces memory consumption from the Hessian matrix to HVP. We further showcase HTE's convergence to the original PINN loss and its unbiased behavior under specific conditions. Comparisons with Stochastic Dimension Gradient Descent (SDGD) highlight the distinct advantages of HTE, particularly in scenarios with significant variance among dimensions. We further extend HTE to higher-order and higher-dimensional PDEs, specifically addressing the biharmonic equation. By employing tensor-vector products (TVP), HTE efficiently computes the colossal tensor associated with the fourth-order high-dimensional biharmonic equation, saving memory and enabling rapid computation. The effectiveness of HTE is illustrated through experimental setups, demonstrating comparable convergence rates with SDGD under memory and speed constraints. Additionally, HTE proves valuable in accelerating the Gradient-Enhanced PINN (gPINN) version as well as the Biharmonic equation. Overall, HTE opens up a new capability in scientific machine learning for tackling high-order and high-dimensional PDEs.
<div id='section'>Paperid: <span id='pid'>377, <a href='https://arxiv.org/pdf/2312.09131.pdf' target='_blank'>https://arxiv.org/pdf/2312.09131.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Liu, Yiming Meng, Maxwell Fitzsimmons, Ruikun Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.09131">Physics-Informed Neural Network Lyapunov Functions: PDE Characterization, Learning, and Verification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We provide a systematic investigation of using physics-informed neural networks to compute Lyapunov functions. We encode Lyapunov conditions as a partial differential equation (PDE) and use this for training neural network Lyapunov functions. We analyze the analytical properties of the solutions to the Lyapunov and Zubov PDEs. In particular, we show that employing the Zubov equation in training neural Lyapunov functions can lead to approximate regions of attraction close to the true domain of attraction. We also examine approximation errors and the convergence of neural approximations to the unique solution of Zubov's equation. We then provide sufficient conditions for the learned neural Lyapunov functions that can be readily verified by satisfiability modulo theories (SMT) solvers, enabling formal verification of both local stability analysis and region-of-attraction estimates in the large. Through a number of nonlinear examples, ranging from low to high dimensions, we demonstrate that the proposed framework can outperform traditional sums-of-squares (SOS) Lyapunov functions obtained using semidefinite programming (SDP).
<div id='section'>Paperid: <span id='pid'>378, <a href='https://arxiv.org/pdf/2312.03365.pdf' target='_blank'>https://arxiv.org/pdf/2312.03365.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabio Pavirani, Gargya Gokhale, Bert Claessens, Chris Develder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.03365">Demand response for residential building heating: Effective Monte Carlo Tree Search control based on physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To reduce global carbon emissions and limit climate change, controlling energy consumption in buildings is an important piece of the puzzle. Here, we specifically focus on using a demand response (DR) algorithm to limit the energy consumption of a residential building's heating system while respecting user's thermal comfort. In that domain, Reinforcement learning (RL) methods have been shown to be quite effective. One such RL method is Monte Carlo Tree Search (MCTS), which has achieved impressive success in playing board games (go, chess). A particular advantage of MCTS is that its decision tree structure naturally allows to integrate exogenous constraints (e.g., by trimming branches that violate them), while conventional RL solutions need more elaborate techniques (e.g., indirectly by adding penalties in the cost/reward function, or through a backup controller that corrects constraint-violating actions). The main aim of this paper is to study the adoption of MCTS for building control, since this (to the best of our knowledge) has remained largely unexplored. A specific property of MCTS is that it needs a simulator component that can predict subsequent system states, based on actions taken. A straightforward data-driven solution is to use black-box neural networks (NNs). We will however extend a Physics-informed Neural Network (PiNN) model to deliver multi-timestep predictions, and show the benefit it offers in terms of lower prediction errors ($-$32\% MAE) as well as better MCTS performance ($-$4\% energy cost, $+$7\% thermal comfort) compared to a black-box NN. A second contribution will be to extend a vanilla MCTS version to adopt the ideas applied in AlphaZero (i.e., using learned prior and value functions and an action selection heuristic) to obtain lower computational costs while maintaining control performance.
<div id='section'>Paperid: <span id='pid'>379, <a href='https://arxiv.org/pdf/2311.16520.pdf' target='_blank'>https://arxiv.org/pdf/2311.16520.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Zhang, Mukesh Ghimire, Wenlong Zhang, Zhe Xu, Yi Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16520">Value Approximation for Two-Player General-Sum Differential Games with State Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving Hamilton-Jacobi-Isaacs (HJI) PDEs numerically enables equilibrial feedback control in two-player differential games, yet faces the curse of dimensionality (CoD). While physics-informed neural networks (PINNs) have shown promise in alleviating CoD in solving PDEs, vanilla PINNs fall short in learning discontinuous solutions due to their sampling nature, leading to poor safety performance of the resulting policies when values are discontinuous due to state or temporal logic constraints. In this study, we explore three potential solutions to this challenge: (1) a hybrid learning method that is guided by both supervisory equilibria and the HJI PDE, (2) a value-hardening method where a sequence of HJIs are solved with increasing Lipschitz constant on the constraint violation penalty, and (3) the epigraphical technique that lifts the value to a higher dimensional state space where it becomes continuous. Evaluations through 5D and 9D vehicle and 13D drone simulations reveal that the hybrid method outperforms others in terms of generalization and safety performance by taking advantage of both the supervisory equilibrium values and costates, and the low cost of PINN loss gradients.
<div id='section'>Paperid: <span id='pid'>380, <a href='https://arxiv.org/pdf/2311.15283.pdf' target='_blank'>https://arxiv.org/pdf/2311.15283.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheyuan Hu, Zhouhao Yang, Yezhen Wang, George Em Karniadakis, Kenji Kawaguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.15283">Bias-Variance Trade-off in Physics-Informed Neural Networks with Randomized Smoothing for High-Dimensional PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While physics-informed neural networks (PINNs) have been proven effective for low-dimensional partial differential equations (PDEs), the computational cost remains a hurdle in high-dimensional scenarios. This is particularly pronounced when computing high-order and high-dimensional derivatives in the physics-informed loss. Randomized Smoothing PINN (RS-PINN) introduces Gaussian noise for stochastic smoothing of the original neural net model, enabling Monte Carlo methods for derivative approximation, eliminating the need for costly auto-differentiation. Despite its computational efficiency in high dimensions, RS-PINN introduces biases in both loss and gradients, negatively impacting convergence, especially when coupled with stochastic gradient descent (SGD). We present a comprehensive analysis of biases in RS-PINN, attributing them to the nonlinearity of the Mean Squared Error (MSE) loss and the PDE nonlinearity. We propose tailored bias correction techniques based on the order of PDE nonlinearity. The unbiased RS-PINN allows for a detailed examination of its pros and cons compared to the biased version. Specifically, the biased version has a lower variance and runs faster than the unbiased version, but it is less accurate due to the bias. To optimize the bias-variance trade-off, we combine the two approaches in a hybrid method that balances the rapid convergence of the biased version with the high accuracy of the unbiased version. In addition, we present an enhanced implementation of RS-PINN. Extensive experiments on diverse high-dimensional PDEs, including Fokker-Planck, HJB, viscous Burgers', Allen-Cahn, and Sine-Gordon equations, illustrate the bias-variance trade-off and highlight the effectiveness of the hybrid RS-PINN. Empirical guidelines are provided for selecting biased, unbiased, or hybrid versions, depending on the dimensionality and nonlinearity of the specific PDE problem.
<div id='section'>Paperid: <span id='pid'>381, <a href='https://arxiv.org/pdf/2310.06585.pdf' target='_blank'>https://arxiv.org/pdf/2310.06585.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giulio Giacomuzzos, Ruggero Carli, Diego Romeres, Alberto Dalla Libera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06585">A Black-Box Physics-Informed Estimator based on Gaussian Process Regression for Robot Inverse Dynamics Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning the inverse dynamics of robots directly from data, adopting a black-box approach, is interesting for several real-world scenarios where limited knowledge about the system is available. In this paper, we propose a black-box model based on Gaussian Process (GP) Regression for the identification of the inverse dynamics of robotic manipulators. The proposed model relies on a novel multidimensional kernel, called \textit{Lagrangian Inspired Polynomial} (\kernelInitials{}) kernel. The \kernelInitials{} kernel is based on two main ideas. First, instead of directly modeling the inverse dynamics components, we model as GPs the kinetic and potential energy of the system. The GP prior on the inverse dynamics components is derived from those on the energies by applying the properties of GPs under linear operators. Second, as regards the energy prior definition, we prove a polynomial structure of the kinetic and potential energy, and we derive a polynomial kernel that encodes this property. As a consequence, the proposed model allows also to estimate the kinetic and potential energy without requiring any label on these quantities. Results on simulation and on two real robotic manipulators, namely a 7 DOF Franka Emika Panda, and a 6 DOF MELFA RV4FL, show that the proposed model outperforms state-of-the-art black-box estimators based both on Gaussian Processes and Neural Networks in terms of accuracy, generality and data efficiency. The experiments on the MELFA robot also demonstrate that our approach achieves performance comparable to fine-tuned model-based estimators, despite requiring less prior information.
<div id='section'>Paperid: <span id='pid'>382, <a href='https://arxiv.org/pdf/2310.01682.pdf' target='_blank'>https://arxiv.org/pdf/2310.01682.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mukesh Ghimire, Lei Zhang, Wenlong Zhang, Yi Ren, Zhe Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.01682">Solving Two-Player General-Sum Games Between Swarms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hamilton-Jacobi-Isaacs (HJI) PDEs are the governing equations for the two-player general-sum games. Unlike Reinforcement Learning (RL) methods, which are data-intensive methods for learning value function, learning HJ PDEs provide a guaranteed convergence to the Nash Equilibrium value of the game when it exists. However, a caveat is that solving HJ PDEs becomes intractable when the state dimension increases. To circumvent the curse of dimensionality (CoD), physics-informed machine learning methods with supervision can be used and have been shown to be effective in generating equilibrial policies in two-player general-sum games. In this work, we extend the existing work on agent-level two-player games to a two-player swarm-level game, where two sub-swarms play a general-sum game. We consider the \textit{Kolmogorov forward equation} as the dynamic model for the evolution of the densities of the swarms. Results show that policies generated from the physics-informed neural network (PINN) result in a higher payoff than a Nash Double Deep Q-Network (Nash DDQN) agent and have comparable performance with numerical solvers.
<div id='section'>Paperid: <span id='pid'>383, <a href='https://arxiv.org/pdf/2309.10808.pdf' target='_blank'>https://arxiv.org/pdf/2309.10808.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>S. Karthik Mukkavilli, Daniel Salles Civitarese, Johannes Schmude, Johannes Jakubik, Anne Jones, Nam Nguyen, Christopher Phillips, Sujit Roy, Shraddha Singh, Campbell Watson, Raghu Ganti, Hendrik Hamann, Udaysankar Nair, Rahul Ramachandran, Kommy Weldemariam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.10808">AI Foundation Models for Weather and Climate: Applications, Design, and Implementation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning and deep learning methods have been widely explored in understanding the chaotic behavior of the atmosphere and furthering weather forecasting. There has been increasing interest from technology companies, government institutions, and meteorological agencies in building digital twins of the Earth. Recent approaches using transformers, physics-informed machine learning, and graph neural networks have demonstrated state-of-the-art performance on relatively narrow spatiotemporal scales and specific tasks. With the recent success of generative artificial intelligence (AI) using pre-trained transformers for language modeling and vision with prompt engineering and fine-tuning, we are now moving towards generalizable AI. In particular, we are witnessing the rise of AI foundation models that can perform competitively on multiple domain-specific downstream tasks. Despite this progress, we are still in the nascent stages of a generalizable AI model for global Earth system models, regional climate models, and mesoscale weather models. Here, we review current state-of-the-art AI approaches, primarily from transformer and operator learning literature in the context of meteorology. We provide our perspective on criteria for success towards a family of foundation models for nowcasting and forecasting weather and climate predictions. We also discuss how such models can perform competitively on downstream tasks such as downscaling (super-resolution), identifying conditions conducive to the occurrence of wildfires, and predicting consequential meteorological phenomena across various spatiotemporal scales such as hurricanes and atmospheric rivers. In particular, we examine current AI methodologies and contend they have matured enough to design and implement a weather foundation model.
<div id='section'>Paperid: <span id='pid'>384, <a href='https://arxiv.org/pdf/2307.13220.pdf' target='_blank'>https://arxiv.org/pdf/2307.13220.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zi Wang, Xiaotong Yu, Chengyan Wang, Weibo Chen, Jiazheng Wang, Ying-Hua Chu, Hongwei Sun, Rushuai Li, Peiyong Li, Fan Yang, Haiwei Han, Taishan Kang, Jianzhong Lin, Chen Yang, Shufu Chang, Zhang Shi, Sha Hua, Yan Li, Juan Hu, Liuhong Zhu, Jianjun Zhou, Meijing Lin, Jiefeng Guo, Congbo Cai, Zhong Chen, Di Guo, Guang Yang, Xiaobo Qu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.13220">One for Multiple: Physics-informed Synthetic Data Boosts Generalizable Deep Learning for Fast MRI Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Magnetic resonance imaging (MRI) is a widely used radiological modality renowned for its radiation-free, comprehensive insights into the human body, facilitating medical diagnoses. However, the drawback of prolonged scan times hinders its accessibility. The k-space undersampling offers a solution, yet the resultant artifacts necessitate meticulous removal during image reconstruction. Although Deep Learning (DL) has proven effective for fast MRI image reconstruction, its broader applicability across various imaging scenarios has been constrained. Challenges include the high cost and privacy restrictions associated with acquiring large-scale, diverse training data, coupled with the inherent difficulty of addressing mismatches between training and target data in existing DL methodologies. Here, we present a novel Physics-Informed Synthetic data learning framework for Fast MRI, called PISF. PISF marks a breakthrough by enabling generalized DL for multi-scenario MRI reconstruction through a single trained model. Our approach separates the reconstruction of a 2D image into many 1D basic problems, commencing with 1D data synthesis to facilitate generalization. We demonstrate that training DL models on synthetic data, coupled with enhanced learning techniques, yields in vivo MRI reconstructions comparable to or surpassing those of models trained on matched realistic datasets, reducing the reliance on real-world MRI data by up to 96%. Additionally, PISF exhibits remarkable generalizability across multiple vendors and imaging centers. Its adaptability to diverse patient populations has been validated through evaluations by ten experienced medical professionals. PISF presents a feasible and cost-effective way to significantly boost the widespread adoption of DL in various fast MRI applications.
<div id='section'>Paperid: <span id='pid'>385, <a href='https://arxiv.org/pdf/2304.07215.pdf' target='_blank'>https://arxiv.org/pdf/2304.07215.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Liu, Yiming Meng, Maxwell Fitzsimmons, Ruikun Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.07215">Towards Learning and Verifying Maximal Neural Lyapunov Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The search for Lyapunov functions is a crucial task in the analysis of nonlinear systems. In this paper, we present a physics-informed neural network (PINN) approach to learning a Lyapunov function that is nearly maximal for a given stable set. A Lyapunov function is considered nearly maximal if its sub-level sets can be made arbitrarily close to the boundary of the domain of attraction. We use Zubov's equation to train a maximal Lyapunov function defined on the domain of attraction. Additionally, we propose conditions that can be readily verified by satisfiability modulo theories (SMT) solvers for both local and global stability. We provide theoretical guarantees on the existence of maximal Lyapunov functions and demonstrate the effectiveness of our computational approach through numerical examples.
<div id='section'>Paperid: <span id='pid'>386, <a href='https://arxiv.org/pdf/2303.08435.pdf' target='_blank'>https://arxiv.org/pdf/2303.08435.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guojin Chen, Zehua Pei, Haoyu Yang, Yuzhe Ma, Bei Yu, Martin D. F. Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08435">Physics-Informed Optical Kernel Regression Using Complex-valued Neural Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Lithography is fundamental to integrated circuit fabrication, necessitating large computation overhead. The advancement of machine learning (ML)-based lithography models alleviates the trade-offs between manufacturing process expense and capability. However, all previous methods regard the lithography system as an image-to-image black box mapping, utilizing network parameters to learn by rote mappings from massive mask-to-aerial or mask-to-resist image pairs, resulting in poor generalization capability. In this paper, we propose a new ML-based paradigm disassembling the rigorous lithographic model into non-parametric mask operations and learned optical kernels containing determinant source, pupil, and lithography information. By optimizing complex-valued neural fields to perform optical kernel regression from coordinates, our method can accurately restore lithography system using a small-scale training dataset with fewer parameters, demonstrating superior generalization capability as well. Experiments show that our framework can use 31% of parameters while achieving 69$\times$ smaller mean squared error with 1.3$\times$ higher throughput than the state-of-the-art.
<div id='section'>Paperid: <span id='pid'>387, <a href='https://arxiv.org/pdf/2302.14227.pdf' target='_blank'>https://arxiv.org/pdf/2302.14227.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Penwarden, Ameya D. Jagtap, Shandian Zhe, George Em Karniadakis, Robert M. Kirby
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.14227">A unified scalable framework for causal sweeping strategies for Physics-Informed Neural Networks (PINNs) and their temporal decompositions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) as a means of solving partial differential equations (PDE) have garnered much attention in the Computational Science and Engineering (CS&E) world. However, a recent topic of interest is exploring various training (i.e., optimization) challenges - in particular, arriving at poor local minima in the optimization landscape results in a PINN approximation giving an inferior, and sometimes trivial, solution when solving forward time-dependent PDEs with no data. This problem is also found in, and in some sense more difficult, with domain decomposition strategies such as temporal decomposition using XPINNs. We furnish examples and explanations for different training challenges, their cause, and how they relate to information propagation and temporal decomposition. We then propose a new stacked-decomposition method that bridges the gap between time-marching PINNs and XPINNs. We also introduce significant computational speed-ups by using transfer learning concepts to initialize subnetworks in the domain and loss tolerance-based propagation for the subdomains. Finally, we formulate a new time-sweeping collocation point algorithm inspired by the previous PINNs causality literature, which our framework can still describe, and provides a significant computational speed-up via reduced-cost collocation point segmentation. The proposed methods form our unified framework, which overcomes training challenges in PINNs and XPINNs for time-dependent PDEs by respecting the causality in multiple forms and improving scalability by limiting the computation required per optimization iteration. Finally, we provide numerical results for these methods on baseline PDE problems for which unmodified PINNs and XPINNs struggle to train.
<div id='section'>Paperid: <span id='pid'>388, <a href='https://arxiv.org/pdf/2302.05925.pdf' target='_blank'>https://arxiv.org/pdf/2302.05925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Navaneeth N, Tapas Tripura, Souvik Chakraborty
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05925">Physics informed WNO</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural operators are recognized as an effective tool for learning solution operators of complex partial differential equations (PDEs). As compared to laborious analytical and computational tools, a single neural operator can predict solutions of PDEs for varying initial or boundary conditions and different inputs. A recently proposed Wavelet Neural Operator (WNO) is one such operator that harnesses the advantage of time-frequency localization of wavelets to capture the manifolds in the spatial domain effectively. While WNO has proven to be a promising method for operator learning, the data-hungry nature of the framework is a major shortcoming. In this work, we propose a physics-informed WNO for learning the solution operators of families of parametric PDEs without labeled training data. The efficacy of the framework is validated and illustrated with four nonlinear spatiotemporal systems relevant to various fields of engineering and science.
<div id='section'>Paperid: <span id='pid'>389, <a href='https://arxiv.org/pdf/2301.03162.pdf' target='_blank'>https://arxiv.org/pdf/2301.03162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanlong Chen, Luzhe Huang, Tairan Liu, Aydogan Ozcan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.03162">eFIN: Enhanced Fourier Imager Network for generalizable autofocusing and pixel super-resolution in holographic imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The application of deep learning techniques has greatly enhanced holographic imaging capabilities, leading to improved phase recovery and image reconstruction. Here, we introduce a deep neural network termed enhanced Fourier Imager Network (eFIN) as a highly generalizable framework for hologram reconstruction with pixel super-resolution and image autofocusing. Through holographic microscopy experiments involving lung, prostate and salivary gland tissue sections and Papanicolau (Pap) smears, we demonstrate that eFIN has a superior image reconstruction quality and exhibits external generalization to new types of samples never seen during the training phase. This network achieves a wide autofocusing axial range of 0.35 mm, with the capability to accurately predict the hologram axial distances by physics-informed learning. eFIN enables 3x pixel super-resolution imaging and increases the space-bandwidth product of the reconstructed images by 9-fold with almost no performance loss, which allows for significant time savings in holographic imaging and data processing steps. Our results showcase the advancements of eFIN in pushing the boundaries of holographic imaging for various applications in e.g., quantitative phase imaging and label-free microscopy.
<div id='section'>Paperid: <span id='pid'>390, <a href='https://arxiv.org/pdf/2212.07624.pdf' target='_blank'>https://arxiv.org/pdf/2212.07624.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicholas Sung Wei Yong, Jian Cheng Wong, Pao-Hsiung Chiu, Abhishek Gupta, Chinchun Ooi, Yew-Soon Ong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.07624">Neuroevolution of Physics-Informed Neural Nets: Benchmark Problems and Comparative Results</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The potential of learned models for fundamental scientific research and discovery is drawing increasing attention worldwide. Physics-informed neural networks (PINNs), where the loss function directly embeds governing equations of scientific phenomena, is one of the key techniques at the forefront of recent advances. PINNs are typically trained using stochastic gradient descent methods, akin to their deep learning counterparts. However, analysis in this paper shows that PINNs' unique loss formulations lead to a high degree of complexity and ruggedness that may not be conducive for gradient descent. Unlike in standard deep learning, PINN training requires globally optimum parameter values that satisfy physical laws as closely as possible. Spurious local optimum, indicative of erroneous physics, must be avoided. Hence, neuroevolution algorithms, with their superior global search capacity, may be a better choice for PINNs relative to gradient descent methods. Here, we propose a set of five benchmark problems, with open-source codes, spanning diverse physical phenomena for novel neuroevolution algorithm development. Using this, we compare two neuroevolution algorithms against the commonly used stochastic gradient descent, and our baseline results support the claim that neuroevolution can surpass gradient descent, ensuring better physics compliance in the predicted outputs. %Furthermore, implementing neuroevolution with JAX leads to orders of magnitude speedup relative to standard implementations.
<div id='section'>Paperid: <span id='pid'>391, <a href='https://arxiv.org/pdf/2211.08939.pdf' target='_blank'>https://arxiv.org/pdf/2211.08939.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheyuan Hu, Ameya D. Jagtap, George Em Karniadakis, Kenji Kawaguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.08939">Augmented Physics-Informed Neural Networks (APINNs): A gating network-based soft domain decomposition methodology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose the augmented physics-informed neural network (APINN), which adopts soft and trainable domain decomposition and flexible parameter sharing to further improve the extended PINN (XPINN) as well as the vanilla PINN methods. In particular, a trainable gate network is employed to mimic the hard decomposition of XPINN, which can be flexibly fine-tuned for discovering a potentially better partition. It weight-averages several sub-nets as the output of APINN. APINN does not require complex interface conditions, and its sub-nets can take advantage of all training samples rather than just part of the training data in their subdomains. Lastly, each sub-net shares part of the common parameters to capture the similar components in each decomposed function. Furthermore, following the PINN generalization theory in Hu et al. [2021], we show that APINN can improve generalization by proper gate network initialization and general domain & function decomposition. Extensive experiments on different types of PDEs demonstrate how APINN improves the PINN and XPINN methods. Specifically, we present examples where XPINN performs similarly to or worse than PINN, so that APINN can significantly improve both. We also show cases where XPINN is already better than PINN, so APINN can still slightly improve XPINN. Furthermore, we visualize the optimized gating networks and their optimization trajectories, and connect them with their performance, which helps discover the possibly optimal decomposition. Interestingly, if initialized by different decomposition, the performances of corresponding APINNs can differ drastically. This, in turn, shows the potential to design an optimal domain decomposition for the differential equation problem under consideration.
<div id='section'>Paperid: <span id='pid'>392, <a href='https://arxiv.org/pdf/2210.12669.pdf' target='_blank'>https://arxiv.org/pdf/2210.12669.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shibo Li, Michael Penwarden, Yiming Xu, Conor Tillinghast, Akil Narayan, Robert M. Kirby, Shandian Zhe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.12669">Meta Learning of Interface Conditions for Multi-Domain Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are emerging as popular mesh-free solvers for partial differential equations (PDEs). Recent extensions decompose the domain, apply different PINNs to solve the problem in each subdomain, and stitch the subdomains at the interface. Thereby, they can further alleviate the problem complexity, reduce the computational cost, and allow parallelization. However, the performance of multi-domain PINNs is sensitive to the choice of the interface conditions. While quite a few conditions have been proposed, there is no suggestion about how to select the conditions according to specific problems. To address this gap, we propose META Learning of Interface Conditions (METALIC), a simple, efficient yet powerful approach to dynamically determine appropriate interface conditions for solving a family of parametric PDEs. Specifically, we develop two contextual multi-arm bandit (MAB) models. The first one applies to the entire training course, and online updates a Gaussian process (GP) reward that given the PDE parameters and interface conditions predicts the performance. We prove a sub-linear regret bound for both UCB and Thompson sampling, which in theory guarantees the effectiveness of our MAB. The second one partitions the training into two stages, one is the stochastic phase and the other deterministic phase; we update a GP reward for each phase to enable different condition selections at the two stages to further bolster the flexibility and performance. We have shown the advantage of METALIC on four bench-mark PDE families.
<div id='section'>Paperid: <span id='pid'>393, <a href='https://arxiv.org/pdf/2210.11388.pdf' target='_blank'>https://arxiv.org/pdf/2210.11388.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Qian, Haoyu Zhang, Yuncheng Gao, Mingyang Han, Zi Wang, Dan Ruan, Yu Shen, Yaping Wu, Yirong Zhou, Chengyan Wang, Boyu Jiang, Ran Tao, Zhigang Wu, Jiazheng Wang, Liuhong Zhu, Yi Guo, Taishan Kang, Jianzhong Lin, Tao Gong, Chen Yang, Guoqiang Fei, Meijin Lin, Di Guo, Jianjun Zhou, Meiyun Wang, Xiaobo Qu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.11388">Physics-informed Deep Diffusion MRI Reconstruction with Synthetic Data: Break Training Data Bottleneck in Artificial Intelligence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion magnetic resonance imaging (MRI) is the only imaging modality for non-invasive movement detection of in vivo water molecules, with significant clinical and research applications. Diffusion weighted imaging (DWI) MRI acquired by multi-shot techniques can achieve higher resolution, better signal-to-noise ratio, and lower geometric distortion than single-shot, but suffers from inter-shot motion-induced artifacts. These artifacts cannot be removed prospectively, leading to the absence of artifact-free training labels. Thus, the potential of deep learning in multi-shot DWI reconstruction remains largely untapped. To break the training data bottleneck, here, we propose a Physics-Informed Deep DWI reconstruction method (PIDD) to synthesize high-quality paired training data by leveraging the physical diffusion model (magnitude synthesis) and inter-shot motion-induced phase model (motion phase synthesis). The network is trained only once with 100,000 synthetic samples, achieving encouraging results on multiple realistic in vivo data reconstructions. Advantages over conventional methods include: (a) Better motion artifact suppression and reconstruction stability; (b) Outstanding generalization to multi-scenario reconstructions, including multi-resolution, multi-b-value, multi-under-sampling, multi-vendor, and multi-center; (c) Excellent clinical adaptability to patients with verifications by seven experienced doctors (p<0.001). In conclusion, PIDD presents a novel deep learning framework by exploiting the power of MRI physics, providing a cost-effective and explainable way to break the data bottleneck in deep learning medical imaging.
<div id='section'>Paperid: <span id='pid'>394, <a href='https://arxiv.org/pdf/2205.13561.pdf' target='_blank'>https://arxiv.org/pdf/2205.13561.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunsik Jung, Lingfeng Tao, Michael Bowman, Jiucai Zhang, Xiaoli Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.13561">Physics-Guided Hierarchical Reward Mechanism for Learning-Based Robotic Grasping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning-based grasping can afford real-time grasp motion planning of multi-fingered robotics hands thanks to its high computational efficiency. However, learning-based methods are required to explore large search spaces during the learning process. The search space causes low learning efficiency, which has been the main barrier to its practical adoption. In addition, the trained policy lacks a generalizable outcome unless objects are identical to the trained objects. In this work, we develop a novel Physics-Guided Deep Reinforcement Learning with a Hierarchical Reward Mechanism to improve learning efficiency and generalizability for learning-based autonomous grasping. Unlike conventional observation-based grasp learning, physics-informed metrics are utilized to convey correlations between features associated with hand structures and objects to improve learning efficiency and outcomes. Further, the hierarchical reward mechanism enables the robot to learn prioritized components of the grasping tasks. Our method is validated in robotic grasping tasks with a 3-finger MICO robot arm. The results show that our method outperformed the standard Deep Reinforcement Learning methods in various robotic grasping tasks.
<div id='section'>Paperid: <span id='pid'>395, <a href='https://arxiv.org/pdf/2110.13361.pdf' target='_blank'>https://arxiv.org/pdf/2110.13361.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Penwarden, Shandian Zhe, Akil Narayan, Robert M. Kirby
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.13361">A Metalearning Approach for Physics-Informed Neural Networks (PINNs): Application to Parameterized PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) as a means of discretizing partial differential equations (PDEs) are garnering much attention in the Computational Science and Engineering (CS&E) world. At least two challenges exist for PINNs at present: an understanding of accuracy and convergence characteristics with respect to tunable parameters and identification of optimization strategies that make PINNs as efficient as other computational science tools. The cost of PINNs training remains a major challenge of Physics-informed Machine Learning (PiML) - and, in fact, machine learning (ML) in general. This paper is meant to move towards addressing the latter through the study of PINNs on new tasks, for which parameterized PDEs provides a good testbed application as tasks can be easily defined in this context. Following the ML world, we introduce metalearning of PINNs with application to parameterized PDEs. By introducing metalearning and transfer learning concepts, we can greatly accelerate the PINNs optimization process. We present a survey of model-agnostic metalearning, and then discuss our model-aware metalearning applied to PINNs as well as implementation considerations and algorithmic complexity. We then test our approach on various canonical forward parameterized PDEs that have been presented in the emerging PINNs literature.
<div id='section'>Paperid: <span id='pid'>396, <a href='https://arxiv.org/pdf/2106.13361.pdf' target='_blank'>https://arxiv.org/pdf/2106.13361.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Penwarden, Shandian Zhe, Akil Narayan, Robert M. Kirby
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2106.13361">Multifidelity Modeling for Physics-Informed Neural Networks (PINNs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multifidelity simulation methodologies are often used in an attempt to judiciously combine low-fidelity and high-fidelity simulation results in an accuracy-increasing, cost-saving way. Candidates for this approach are simulation methodologies for which there are fidelity differences connected with significant computational cost differences. Physics-informed Neural Networks (PINNs) are candidates for these types of approaches due to the significant difference in training times required when different fidelities (expressed in terms of architecture width and depth as well as optimization criteria) are employed. In this paper, we propose a particular multifidelity approach applied to PINNs that exploits low-rank structure. We demonstrate that width, depth, and optimization criteria can be used as parameters related to model fidelity, and show numerical justification of cost differences in training due to fidelity parameter choices. We test our multifidelity scheme on various canonical forward PDE models that have been presented in the emerging PINNs literature.
<div id='section'>Paperid: <span id='pid'>397, <a href='https://arxiv.org/pdf/2509.24850.pdf' target='_blank'>https://arxiv.org/pdf/2509.24850.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Zhao, Dan Guo, Junzhe Cao, Yong Xu, Tao Tan, Yue Sun, Bochao Zou, Jie Zhang, Zitong Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24850">PHASE-Net: Physics-Grounded Harmonic Attention System for Efficient Remote Photoplethysmography Measurement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Remote photoplethysmography (rPPG) measurement enables non-contact physiological monitoring but suffers from accuracy degradation under head motion and illumination changes. Existing deep learning methods are mostly heuristic and lack theoretical grounding, which limits robustness and interpretability. In this work, we propose a physics-informed rPPG paradigm derived from the Navier-Stokes equations of hemodynamics, showing that the pulse signal follows a second-order dynamical system whose discrete solution naturally leads to a causal convolution. This provides a theoretical justification for using a Temporal Convolutional Network (TCN). Based on this principle, we design PHASE-Net, a lightweight model with three key components: (1) Zero-FLOPs Axial Swapper module, which swaps or transposes a few spatial channels to mix distant facial regions and enhance cross-region feature interaction without breaking temporal order; (2) Adaptive Spatial Filter, which learns a soft spatial mask per frame to highlight signal-rich areas and suppress noise; and (3) Gated TCN, a causal dilated TCN with gating that models long-range temporal dynamics for accurate pulse recovery. Extensive experiments demonstrate that PHASE-Net achieves state-of-the-art performance with strong efficiency, offering a theoretically grounded and deployment-ready rPPG solution.
<div id='section'>Paperid: <span id='pid'>398, <a href='https://arxiv.org/pdf/2509.24801.pdf' target='_blank'>https://arxiv.org/pdf/2509.24801.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anna Scampicchio, Leonardo F. Toso, Rahel Rickenbach, James Anderson, Melanie N. Zeilinger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24801">Physics-informed learning under mixing: How physical knowledge speeds up learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A major challenge in physics-informed machine learning is to understand how the incorporation of prior domain knowledge affects learning rates when data are dependent. Focusing on empirical risk minimization with physics-informed regularization, we derive complexity-dependent bounds on the excess risk in probability and in expectation. We prove that, when the physical prior information is aligned, the learning rate improves from the (slow) Sobolev minimax rate to the (fast) optimal i.i.d. one without any sample-size deflation due to data dependence.
<div id='section'>Paperid: <span id='pid'>399, <a href='https://arxiv.org/pdf/2509.01234.pdf' target='_blank'>https://arxiv.org/pdf/2509.01234.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weihang Ouyang, Min Zhu, Wei Xiong, Si-Wei Liu, Lu Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01234">RAMS: Residual-based adversarial-gradient moving sample method for scientific machine learning in solving partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) and neural operators, two leading scientific machine learning (SciML) paradigms, have emerged as powerful tools for solving partial differential equations (PDEs). Although increasing the training sample size generally enhances network performance, it also increases computational costs for physics-informed or data-driven training. To address this trade-off, different sampling strategies have been developed to sample more points in regions with high PDE residuals. However, existing sampling methods are computationally demanding for high-dimensional problems, such as high-dimensional PDEs or operator learning tasks. Here, we propose a residual-based adversarial-gradient moving sample (RAMS) method, which moves samples according to the adversarial gradient direction to maximize the PDE residual via gradient-based optimization. RAMS can be easily integrated into existing sampling methods. Extensive experiments, ranging from PINN applied to high-dimensional PDEs to physics-informed and data-driven operator learning problems, have been conducted to demonstrate the effectiveness of RAMS. Notably, RAMS represents the first efficient adaptive sampling approach for operator learning, marking a significant advancement in the SciML field.
<div id='section'>Paperid: <span id='pid'>400, <a href='https://arxiv.org/pdf/2508.15300.pdf' target='_blank'>https://arxiv.org/pdf/2508.15300.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>William McDonald, Cedric Le Gentil, Jennifer Wakulicz, Teresa Vidal-Calleja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15300">Mag-Match: Magnetic Vector Field Features for Map Matching and Registration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Map matching and registration are essential tasks in robotics for localisation and integration of multi-session or multi-robot data. Traditional methods rely on cameras or LiDARs to capture visual or geometric information but struggle in challenging conditions like smoke or dust. Magnetometers, on the other hand, detect magnetic fields, revealing features invisible to other sensors and remaining robust in such environments. In this paper, we introduce Mag-Match, a novel method for extracting and describing features in 3D magnetic vector field maps to register different maps of the same area. Our feature descriptor, based on higher-order derivatives of magnetic field maps, is invariant to global orientation, eliminating the need for gravity-aligned mapping. To obtain these higher-order derivatives map-wide given point-wise magnetometer data, we leverage a physics-informed Gaussian Process to perform efficient and recursive probabilistic inference of both the magnetic field and its derivatives. We evaluate Mag-Match in simulated and real-world experiments against a SIFT-based approach, demonstrating accurate map-to-map, robot-to-map, and robot-to-robot transformations - even without initial gravitational alignment.
<div id='section'>Paperid: <span id='pid'>401, <a href='https://arxiv.org/pdf/2508.10680.pdf' target='_blank'>https://arxiv.org/pdf/2508.10680.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Busra Bulut, Maik Dannecker, Thomas Sanchez, Sara Neves Silva, Vladyslav Zalevskyi, Steven Jia, Jean-Baptiste Ledoux, Guillaume Auzias, FranÃ§ois Rousseau, Jana Hutter, Daniel Rueckert, Meritxell Bach Cuadra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10680">Physics-Informed Joint Multi-TE Super-Resolution with Implicit Neural Representation for Robust Fetal T2 Mapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>T2 mapping in fetal brain MRI has the potential to improve characterization of the developing brain, especially at mid-field (0.55T), where T2 decay is slower. However, this is challenging as fetal MRI acquisition relies on multiple motion-corrupted stacks of thick slices, requiring slice-to-volume reconstruction (SVR) to estimate a high-resolution (HR) 3D volume. Currently, T2 mapping involves repeated acquisitions of these stacks at each echo time (TE), leading to long scan times and high sensitivity to motion. We tackle this challenge with a method that jointly reconstructs data across TEs, addressing severe motion. Our approach combines implicit neural representations with a physics-informed regularization that models T2 decay, enabling information sharing across TEs while preserving anatomical and quantitative T2 fidelity. We demonstrate state-of-the-art performance on simulated fetal brain and in vivo adult datasets with fetal-like motion. We also present the first in vivo fetal T2 mapping results at 0.55T. Our study shows potential for reducing the number of stacks per TE in T2 mapping by leveraging anatomical redundancy.
<div id='section'>Paperid: <span id='pid'>402, <a href='https://arxiv.org/pdf/2508.01315.pdf' target='_blank'>https://arxiv.org/pdf/2508.01315.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>MohammadHossein Ashoori, Ali Aminzadeh, Amy Nejati, Abolfazl Lavaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.01315">Physics-Informed Data-Driven Control of Nonlinear Polynomial Systems with Noisy Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work addresses the critical challenge of guaranteeing safety for complex dynamical systems where precise mathematical models are uncertain and data measurements are corrupted by noise. We develop a physics-informed, direct data-driven framework for synthesizing robust safety controllers (R-SCs) for both discrete- and continuous-time nonlinear polynomial systems that are subject to unknown-but-bounded disturbances. To do so, we introduce a notion of safety through robust control barrier certificates (R-CBCs), which ensure avoidance of (potentially multiple) unsafe regions, offering a less conservative alternative to existing methods based on robust invariant sets. Our core innovation lies in integrating the fundamental physical principles with observed noisy data which drastically reduces data requirements, enabling robust safety analysis with significantly shorter trajectories, compared to purely data-driven methods. To achieve this, the proposed synthesis procedure is formulated as a sum-of-squares (SOS) optimization program that systematically designs the R-CBC and its associated R-SC by leveraging both collected data and underlying physical laws. The efficacy of our framework is demonstrated on four benchmark systems, three discrete-time and one continuous-time nonlinear polynomial systems, confirming its ability to offer robust safety guarantees with reduced data demands.
<div id='section'>Paperid: <span id='pid'>403, <a href='https://arxiv.org/pdf/2507.11070.pdf' target='_blank'>https://arxiv.org/pdf/2507.11070.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinmeng Luan, Mirco Pezzoli, Fabio Antonacci, Augusto Sarti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11070">Physics-Informed Transfer Learning for Data-Driven Sound Source Reconstruction in Near-Field Acoustic Holography</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a transfer learning framework for sound source reconstruction in Near-field Acoustic Holography (NAH), which adapts a well-trained data-driven model from one type of sound source to another using a physics-informed procedure. The framework comprises two stages: (1) supervised pre-training of a complex-valued convolutional neural network (CV-CNN) on a large dataset, and (2) purely physics-informed fine-tuning on a single data sample based on the Kirchhoff-Helmholtz integral. This method follows the principles of transfer learning by enabling generalization across different datasets through physics-informed adaptation. The effectiveness of the approach is validated by transferring a pre-trained model from a rectangular plate dataset to a violin top plate dataset, where it shows improved reconstruction accuracy compared to the pre-trained model and delivers performance comparable to that of Compressive-Equivalent Source Method (C-ESM). Furthermore, for successful modes, the fine-tuned model outperforms both the pre-trained model and C-ESM in accuracy.
<div id='section'>Paperid: <span id='pid'>404, <a href='https://arxiv.org/pdf/2506.10778.pdf' target='_blank'>https://arxiv.org/pdf/2506.10778.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Li, Wan Han, Ning Lin, Yu-Liang Zhan, Ruizhi Chengze, Haining Wang, Yi Zhang, Hongsheng Liu, Zidong Wang, Fan Yu, Hao Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10778">SlotPi: Physics-informed Object-centric Reasoning Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding and reasoning about dynamics governed by physical laws through visual observation, akin to human capabilities in the real world, poses significant challenges. Currently, object-centric dynamic simulation methods, which emulate human behavior, have achieved notable progress but overlook two critical aspects: 1) the integration of physical knowledge into models. Humans gain physical insights by observing the world and apply this knowledge to accurately reason about various dynamic scenarios; 2) the validation of model adaptability across diverse scenarios. Real-world dynamics, especially those involving fluids and objects, demand models that not only capture object interactions but also simulate fluid flow characteristics. To address these gaps, we introduce SlotPi, a slot-based physics-informed object-centric reasoning model. SlotPi integrates a physical module based on Hamiltonian principles with a spatio-temporal prediction module for dynamic forecasting. Our experiments highlight the model's strengths in tasks such as prediction and Visual Question Answering (VQA) on benchmark and fluid datasets. Furthermore, we have created a real-world dataset encompassing object interactions, fluid dynamics, and fluid-object interactions, on which we validated our model's capabilities. The model's robust performance across all datasets underscores its strong adaptability, laying a foundation for developing more advanced world models.
<div id='section'>Paperid: <span id='pid'>405, <a href='https://arxiv.org/pdf/2506.08043.pdf' target='_blank'>https://arxiv.org/pdf/2506.08043.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashkan Shahbazi, Kyvia Pereira, Jon S. Heiselman, Elaheh Akbari, Annie C. Benson, Sepehr Seifi, Xinyuan Liu, Garrison L. Johnston, Erwin Terpstra, Anne Draaisma, Jan-Jaap Severes, Jie Ying Wu, Nabil Simaan, Michael L. Miga, Soheil Kolouri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08043">Neural-Augmented Kelvinlet: Real-Time Soft Tissue Deformation with Multiple Graspers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fast and accurate simulation of soft tissue deformation is a critical factor for surgical robotics and medical training. In this paper, we introduce a novel physics-informed neural simulator that approximates soft tissue deformations in a realistic and real-time manner. Our framework integrates Kelvinlet-based priors into neural simulators, making it the first approach to leverage Kelvinlets for residual learning and regularization in data-driven soft tissue modeling. By incorporating large-scale Finite Element Method (FEM) simulations of both linear and nonlinear soft tissue responses, our method improves neural network predictions across diverse architectures, enhancing accuracy and physical consistency while maintaining low latency for real-time performance. We demonstrate the effectiveness of our approach by performing accurate surgical maneuvers that simulate the use of standard laparoscopic tissue grasping tools with high fidelity. These results establish Kelvinlet-augmented learning as a powerful and efficient strategy for real-time, physics-aware soft tissue simulation in surgical applications.
<div id='section'>Paperid: <span id='pid'>406, <a href='https://arxiv.org/pdf/2506.08043.pdf' target='_blank'>https://arxiv.org/pdf/2506.08043.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashkan Shahbazi, Kyvia Pereira, Jon S. Heiselman, Elaheh Akbari, Annie C. Benson, Sepehr Seifi, Xinyuan Liu, Garrison L. Johnston, Jie Ying Wu, Nabil Simaan, Michael L. Miga, Soheil Kolouri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08043">Neural-Augmented Kelvinlet for Real-Time Soft Tissue Deformation Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and efficient modeling of soft-tissue interactions is fundamental for advancing surgical simulation, surgical robotics, and model-based surgical automation. To achieve real-time latency, classical Finite Element Method (FEM) solvers are often replaced with neural approximations; however, naively training such models in a fully data-driven manner without incorporating physical priors frequently leads to poor generalization and physically implausible predictions. We present a novel physics-informed neural simulation framework that enables real-time prediction of soft-tissue deformations under complex single- and multi-grasper interactions. Our approach integrates Kelvinlet-based analytical priors with large-scale FEM data, capturing both linear and nonlinear tissue responses. This hybrid design improves predictive accuracy and physical plausibility across diverse neural architectures while maintaining the low-latency performance required for interactive applications. We validate our method on challenging surgical manipulation tasks involving standard laparoscopic grasping tools, demonstrating substantial improvements in deformation fidelity and temporal stability over existing baselines. These results establish Kelvinlet-augmented learning as a principled and computationally efficient paradigm for real-time, physics-aware soft-tissue simulation in surgical AI.
<div id='section'>Paperid: <span id='pid'>407, <a href='https://arxiv.org/pdf/2504.17968.pdf' target='_blank'>https://arxiv.org/pdf/2504.17968.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Zhang, Ximin Yue, Kexin Tian, Sixu Li, Keshu Wu, Zihao Li, Dominique Lord, Yang Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.17968">Virtual Roads, Smarter Safety: A Digital Twin Framework for Mixed Autonomous Traffic Safety Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a digital-twin platform for active safety analysis in mixed traffic environments. The platform is built using a multi-modal data-enabled traffic environment constructed from drone-based aerial LiDAR, OpenStreetMap, and vehicle sensor data (e.g., GPS and inclinometer readings). High-resolution 3D road geometries are generated through AI-powered semantic segmentation and georeferencing of aerial LiDAR data. To simulate real-world driving scenarios, the platform integrates the CAR Learning to Act (CARLA) simulator, Simulation of Urban MObility (SUMO) traffic model, and NVIDIA PhysX vehicle dynamics engine. CARLA provides detailed micro-level sensor and perception data, while SUMO manages macro-level traffic flow. NVIDIA PhysX enables accurate modeling of vehicle behaviors under diverse conditions, accounting for mass distribution, tire friction, and center of mass. This integrated system supports high-fidelity simulations that capture the complex interactions between autonomous and conventional vehicles. Experimental results demonstrate the platform's ability to reproduce realistic vehicle dynamics and traffic scenarios, enhancing the analysis of active safety measures. Overall, the proposed framework advances traffic safety research by enabling in-depth, physics-informed evaluation of vehicle behavior in dynamic and heterogeneous traffic environments.
<div id='section'>Paperid: <span id='pid'>408, <a href='https://arxiv.org/pdf/2504.04982.pdf' target='_blank'>https://arxiv.org/pdf/2504.04982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Cao, Minghao Li, Feng Lin, Jimin Jia, Yonggang Wen, Jianxiong Yin, Simon See
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04982">Transforming Future Data Center Operations and Management via Physical AI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data centers (DCs) as mission-critical infrastructures are pivotal in powering the growth of artificial intelligence (AI) and the digital economy. The evolution from Internet DC to AI DC has introduced new challenges in operating and managing data centers for improved business resilience and reduced total cost of ownership. As a result, new paradigms, beyond the traditional approaches based on best practices, must be in order for future data centers. In this research, we propose and develop a novel Physical AI (PhyAI) framework for advancing DC operations and management. Our system leverages the emerging capabilities of state-of-the-art industrial products and our in-house research and development. Specifically, it presents three core modules, namely: 1) an industry-grade in-house simulation engine to simulate DC operations in a highly accurate manner, 2) an AI engine built upon NVIDIA PhysicsNemo for the training and evaluation of physics-informed machine learning (PIML) models, and 3) a digital twin platform built upon NVIDIA Omniverse for our proposed 5-tier digital twin framework. This system presents a scalable and adaptable solution to digitalize, optimize, and automate future data center operations and management, by enabling real-time digital twins for future data centers. To illustrate its effectiveness, we present a compelling case study on building a surrogate model for predicting the thermal and airflow profiles of a large-scale DC in a real-time manner. Our results demonstrate its superior performance over traditional time-consuming Computational Fluid Dynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature prediction error of 0.18 Â°C. This emerging approach would open doors to several potential research directions for advancing Physical AI in future DC operations.
<div id='section'>Paperid: <span id='pid'>409, <a href='https://arxiv.org/pdf/2504.04562.pdf' target='_blank'>https://arxiv.org/pdf/2504.04562.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Gan, Pei Li, Keke Long, Bocheng An, Junwei You, Keshu Wu, Bin Ran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04562">Planning Safety Trajectories with Dual-Phase, Physics-Informed, and Transportation Knowledge-Driven Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models have demonstrated strong reasoning and generalization capabilities in driving-related tasks, including scene understanding, planning, and control. However, they still face challenges in hallucinations, uncertainty, and long inference latency. While existing foundation models have general knowledge of avoiding collisions, they often lack transportation-specific safety knowledge. To overcome these limitations, we introduce LetsPi, a physics-informed, dual-phase, knowledge-driven framework for safe, human-like trajectory planning. To prevent hallucinations and minimize uncertainty, this hybrid framework integrates Large Language Model (LLM) reasoning with physics-informed social force dynamics. LetsPi leverages the LLM to analyze driving scenes and historical information, providing appropriate parameters and target destinations (goals) for the social force model, which then generates the future trajectory. Moreover, the dual-phase architecture balances reasoning and computational efficiency through its Memory Collection phase and Fast Inference phase. The Memory Collection phase leverages the physics-informed LLM to process and refine planning results through reasoning, reflection, and memory modules, storing safe, high-quality driving experiences in a memory bank. Surrogate safety measures and physics-informed prompt techniques are introduced to enhance the LLM's knowledge of transportation safety and physical force, respectively. The Fast Inference phase extracts similar driving experiences as few-shot examples for new scenarios, while simplifying input-output requirements to enable rapid trajectory planning without compromising safety. Extensive experiments using the HighD dataset demonstrate that LetsPi outperforms baseline models across five safety metrics.See PDF for project Github link.
<div id='section'>Paperid: <span id='pid'>410, <a href='https://arxiv.org/pdf/2503.08343.pdf' target='_blank'>https://arxiv.org/pdf/2503.08343.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tim Weiland, Marvin PfÃ¶rtner, Philipp Hennig
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08343">Flexible and Efficient Probabilistic PDE Solvers through Gaussian Markov Random Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mechanistic knowledge about the physical world is virtually always expressed via partial differential equations (PDEs). Recently, there has been a surge of interest in probabilistic PDE solvers -- Bayesian statistical models mostly based on Gaussian process (GP) priors which seamlessly combine empirical measurements and mechanistic knowledge. As such, they quantify uncertainties arising from e.g. noisy or missing data, unknown PDE parameters or discretization error by design. Prior work has established connections to classical PDE solvers and provided solid theoretical guarantees. However, scaling such methods to large-scale problems remains a fundamental challenge primarily due to dense covariance matrices. Our approach addresses the scalability issues by leveraging the Markov property of many commonly used GP priors. It has been shown that such priors are solutions to stochastic PDEs (SPDEs) which when discretized allow for highly efficient GP regression through sparse linear algebra. In this work, we show how to leverage this prior class to make probabilistic PDE solvers practical, even for large-scale nonlinear PDEs, through greatly accelerated inference mechanisms. Additionally, our approach also allows for flexible and physically meaningful priors beyond what can be modeled with covariance functions. Experiments confirm substantial speedups and accelerated convergence of our physics-informed priors in nonlinear settings.
<div id='section'>Paperid: <span id='pid'>411, <a href='https://arxiv.org/pdf/2502.00373.pdf' target='_blank'>https://arxiv.org/pdf/2502.00373.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amy Xiang Wang, Zakhar Shumaylov, Peter Zaika, Ferdia Sherry, Carola-Bibiane SchÃ¶nlieb
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00373">Generalized Lie Symmetries in Physics-Informed Neural Operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural operators (PINOs) have emerged as powerful tools for learning solution operators of partial differential equations (PDEs). Recent research has demonstrated that incorporating Lie point symmetry information can significantly enhance the training efficiency of PINOs, primarily through techniques like data, architecture, and loss augmentation. In this work, we focus on the latter, highlighting that point symmetries oftentimes result in no training signal, limiting their effectiveness in many problems. To address this, we propose a novel loss augmentation strategy that leverages evolutionary representatives of point symmetries, a specific class of generalized symmetries of the underlying PDE. These generalized symmetries provide a richer set of generators compared to standard symmetries, leading to a more informative training signal. We demonstrate that leveraging evolutionary representatives enhances the performance of neural operators, resulting in improved data efficiency and accuracy during training.
<div id='section'>Paperid: <span id='pid'>412, <a href='https://arxiv.org/pdf/2501.15057.pdf' target='_blank'>https://arxiv.org/pdf/2501.15057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiang Chang, Deekshith Basvoju, Aleksandar Vakanski, Indrajit Charit, Min Xian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15057">Predictive Modeling and Uncertainty Quantification of Fatigue Life in Metal Alloys using Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in machine learning-based methods have demonstrated great potential for improved property prediction in material science. However, reliable estimation of the confidence intervals for the predicted values remains a challenge, due to the inherent complexities in material modeling. This study introduces a novel approach for uncertainty quantification in fatigue life prediction of metal materials based on integrating knowledge from physics-based fatigue life models and machine learning models. The proposed approach employs physics-based input features estimated using the Basquin fatigue model to augment the experimentally collected data of fatigue life. Furthermore, a physics-informed loss function that enforces boundary constraints for the estimated fatigue life of considered materials is introduced for the neural network models. Experimental validation on datasets comprising collected data from fatigue life tests for Titanium alloys and Carbon steel alloys demonstrates the effectiveness of the proposed approach. The synergy between physics-based models and data-driven models enhances the consistency in predicted values and improves uncertainty interval estimates.
<div id='section'>Paperid: <span id='pid'>413, <a href='https://arxiv.org/pdf/2501.09935.pdf' target='_blank'>https://arxiv.org/pdf/2501.09935.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zekun Zhou, Tan Liu, Bing Yu, Yanru Gong, Liu Shi, Qiegen Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.09935">Physics-informed DeepCT: Sinogram Wavelet Decomposition Meets Masked Diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion model shows remarkable potential on sparse-view computed tomography (SVCT) reconstruction. However, when a network is trained on a limited sample space, its generalization capability may be constrained, which degrades performance on unfamiliar data. For image generation tasks, this can lead to issues such as blurry details and inconsistencies between regions. To alleviate this problem, we propose a Sinogram-based Wavelet random decomposition And Random mask diffusion Model (SWARM) for SVCT reconstruction. Specifically, introducing a random mask strategy in the sinogram effectively expands the limited training sample space. This enables the model to learn a broader range of data distributions, enhancing its understanding and generalization of data uncertainty. In addition, applying a random training strategy to the high-frequency components of the sinogram wavelet enhances feature representation and improves the ability to capture details in different frequency bands, thereby improving performance and robustness. Two-stage iterative reconstruction method is adopted to ensure the global consistency of the reconstructed image while refining its details. Experimental results demonstrate that SWARM outperforms competing approaches in both quantitative and qualitative performance across various datasets.
<div id='section'>Paperid: <span id='pid'>414, <a href='https://arxiv.org/pdf/2412.05545.pdf' target='_blank'>https://arxiv.org/pdf/2412.05545.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xianliang Xu, Ye Li, Zhongyi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05545">Convergence analysis of wide shallow neural operators within the framework of Neural Tangent Kernel</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural operators are aiming at approximating operators mapping between Banach spaces of functions, achieving much success in the field of scientific computing. Compared to certain deep learning-based solvers, such as Physics-Informed Neural Networks (PINNs), Deep Ritz Method (DRM), neural operators can solve a class of Partial Differential Equations (PDEs). Although much work has been done to analyze the approximation and generalization error of neural operators, there is still a lack of analysis on their training error. In this work, we conduct the convergence analysis of gradient descent for the wide shallow neural operators and physics-informed shallow neural operators within the framework of Neural Tangent Kernel (NTK). The core idea lies on the fact that over-parameterization and random initialization together ensure that each weight vector remains near its initialization throughout all iterations, yielding the linear convergence of gradient descent. In this work, we demonstrate that under the setting of over-parametrization, gradient descent can find the global minimum regardless of whether it is in continuous time or discrete time.
<div id='section'>Paperid: <span id='pid'>415, <a href='https://arxiv.org/pdf/2412.03932.pdf' target='_blank'>https://arxiv.org/pdf/2412.03932.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Aminzadeh, MohammadHossein Ashoori, Amy Nejati, Abolfazl Lavaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03932">A Physics-Informed Scenario Approach with Data Mitigation for Safety Verification of Nonlinear Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper develops a physics-informed scenario approach for safety verification of nonlinear systems using barrier certificates (BCs) to ensure that system trajectories remain within safe regions over an infinite time horizon. Designing BCs often relies on an accurate dynamics model; however, such models are often imprecise due to the model complexity involved, particularly when dealing with highly nonlinear systems. In such cases, while scenario approaches effectively address the safety problem using collected data to construct a guaranteed BC for the dynamical system, they often require substantial amounts of data-sometimes millions of samples-due to exponential sample complexity. To address this, we propose a physics-informed scenario approach that selects data samples such that the outputs of the physics-based model and the observed data are sufficiently close (within a specified threshold). This approach guides the scenario optimization process to eliminate redundant samples and significantly reduce the required dataset size. We demonstrate the capability of our approach in mitigating the amount of data required for scenario optimizations with both deterministic (i.e., confidence 1) and probabilistic (i.e., confidence between 0 and 1) guarantees. We validate our physics-informed scenario approach through two physical case studies, showcasing its practical application in reducing the required data.
<div id='section'>Paperid: <span id='pid'>416, <a href='https://arxiv.org/pdf/2411.06842.pdf' target='_blank'>https://arxiv.org/pdf/2411.06842.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vladyslav Zalevskyi, Thomas Sanchez, Margaux Roulet, HÃ©lÃ¨ne Lajous, Jordina Aviles Verdera, Roxane Licandro, Georg Langs, Gregor Kasprian, Jana Hutter, Hamza Kebiri, Meritxell Bach Cuadra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.06842">DRIFTS: Optimizing Domain Randomization with Synthetic Data and Weight Interpolation for Fetal Brain Tissue Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fetal brain tissue segmentation in magnetic resonance imaging (MRI) is a crucial tool that supports understanding of neurodevelopment, yet it faces challenges due to the heterogeneity of data coming from different scanners and settings, as well as data scarcity. Recent approaches based on domain randomization, like SynthSeg, have shown great potential for single-source domain generalization by simulating images with randomized contrast and image resolution from the label maps. In this work, we investigate how to maximize the out-of-domain (OOD) generalization potential of SynthSegbased methods in fetal brain MRI. Specifically, we demonstrate that the simple Gaussian mixture models employed in FetalSynthSeg outperform physics-informed generation methods in terms of OOD generalization. We further show that incorporating intensity clustering significantly enhances generalization in settings with limited label classes by producing more realistic synthetic data. By combining synthetic pretraining with fine-tuning on real images and applying weight-space interpolation between the two models, we propose DRIFTS as an effective and practical solution for single-source domain generalization. DRIFTS consistently outperforms current state-of-the-art models across multiple benchmarks and is, to our knowledge, the first method to achieve accurate brain tissue segmentation on fetal T1-weighted images. We validate our approach on 308 subjects from four datasets acquired at three different sites, covering a range of scanner field strengths (0.55T to 3T) and both T1w and T2w modalities. We conclude with five practical recommendations to guide the development of SynthSeg-based methods for other organs and imaging modalities.
<div id='section'>Paperid: <span id='pid'>417, <a href='https://arxiv.org/pdf/2410.15957.pdf' target='_blank'>https://arxiv.org/pdf/2410.15957.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guangcong Zheng, Teng Li, Rui Jiang, Yehao Lu, Tao Wu, Xi Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15957">CamI2V: Camera-Controlled Image-to-Video Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements have integrated camera pose as a user-friendly and physics-informed condition in video diffusion models, enabling precise camera control. In this paper, we identify one of the key challenges as effectively modeling noisy cross-frame interactions to enhance geometry consistency and camera controllability. We innovatively associate the quality of a condition with its ability to reduce uncertainty and interpret noisy cross-frame features as a form of noisy condition. Recognizing that noisy conditions provide deterministic information while also introducing randomness and potential misguidance due to added noise, we propose applying epipolar attention to only aggregate features along corresponding epipolar lines, thereby accessing an optimal amount of noisy conditions. Additionally, we address scenarios where epipolar lines disappear, commonly caused by rapid camera movements, dynamic objects, or occlusions, ensuring robust performance in diverse environments. Furthermore, we develop a more robust and reproducible evaluation pipeline to address the inaccuracies and instabilities of existing camera control metrics. Our method achieves a 25.64% improvement in camera controllability on the RealEstate10K dataset without compromising dynamics or generation quality and demonstrates strong generalization to out-of-domain images. Training and inference require only 24GB and 12GB of memory, respectively, for 16-frame sequences at 256x256 resolution. We will release all checkpoints, along with training and evaluation code. Dynamic videos are best viewed at https://zgctroy.github.io/CamI2V.
<div id='section'>Paperid: <span id='pid'>418, <a href='https://arxiv.org/pdf/2410.15336.pdf' target='_blank'>https://arxiv.org/pdf/2410.15336.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhekun Shi, Longlin Yu, Tianyu Xie, Cheng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15336">Diffusion-PINN Sampler</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent success of diffusion models has inspired a surge of interest in developing sampling techniques using reverse diffusion processes. However, accurately estimating the drift term in the reverse stochastic differential equation (SDE) solely from the unnormalized target density poses significant challenges, hindering existing methods from achieving state-of-the-art performance. In this paper, we introduce the Diffusion-PINN Sampler (DPS), a novel diffusion-based sampling algorithm that estimates the drift term by solving the governing partial differential equation of the log-density of the underlying SDE marginals via physics-informed neural networks (PINN). We prove that the error of log-density approximation can be controlled by the PINN residual loss, enabling us to establish convergence guarantees of DPS. Experiments on a variety of sampling tasks demonstrate the effectiveness of our approach, particularly in accurately identifying mixing proportions when the target contains isolated components.
<div id='section'>Paperid: <span id='pid'>419, <a href='https://arxiv.org/pdf/2410.04818.pdf' target='_blank'>https://arxiv.org/pdf/2410.04818.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anna Varbella, Damien Briens, Blazhe Gjorgiev, Giuseppe Alessio D'Inverno, Giovanni Sansavini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04818">Physics-Informed GNN for non-linear constrained optimization: PINCO a solver for the AC-optimal power flow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The energy transition is driving the integration of large shares of intermittent power sources in the electric power grid. Therefore, addressing the AC optimal power flow (AC-OPF) effectively becomes increasingly essential. The AC-OPF, which is a fundamental optimization problem in power systems, must be solved more frequently to ensure the safe and cost-effective operation of power systems. Due to its non-linear nature, AC-OPF is often solved in its linearized form, despite inherent inaccuracies. Non-linear solvers, such as the interior point method, are typically employed to solve the full OPF problem. However, these iterative methods may not converge for large systems and do not guarantee global optimality. This work explores a physics-informed graph neural network, PINCO, to solve the AC-OPF. We demonstrate that this method provides accurate solutions in a fraction of the computational time when compared to the established non-linear programming solvers. Remarkably, PINCO generalizes effectively across a diverse set of loading conditions in the power system. We show that our method can solve the AC-OPF without violating inequality constraints. Furthermore, it can function both as a solver and as a hybrid universal function approximator. Moreover, the approach can be easily adapted to different power systems with minimal adjustments to the hyperparameters, including systems with multiple generators at each bus. Overall, this work demonstrates an advancement in the field of power system optimization to tackle the challenges of the energy transition. The code and data utilized in this paper are available at https://anonymous.4open.science/r/opf_pinn_iclr-B83E/.
<div id='section'>Paperid: <span id='pid'>420, <a href='https://arxiv.org/pdf/2410.02698.pdf' target='_blank'>https://arxiv.org/pdf/2410.02698.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zakhar Shumaylov, Peter Zaika, James Rowbottom, Ferdia Sherry, Melanie Weber, Carola-Bibiane SchÃ¶nlieb
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.02698">Lie Algebra Canonicalization: Equivariant Neural Operators under arbitrary Lie Groups</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The quest for robust and generalizable machine learning models has driven recent interest in exploiting symmetries through equivariant neural networks. In the context of PDE solvers, recent works have shown that Lie point symmetries can be a useful inductive bias for Physics-Informed Neural Networks (PINNs) through data and loss augmentation. Despite this, directly enforcing equivariance within the model architecture for these problems remains elusive. This is because many PDEs admit non-compact symmetry groups, oftentimes not studied beyond their infinitesimal generators, making them incompatible with most existing equivariant architectures. In this work, we propose Lie aLgebrA Canonicalization (LieLAC), a novel approach that exploits only the action of infinitesimal generators of the symmetry group, circumventing the need for knowledge of the full group structure. To achieve this, we address existing theoretical issues in the canonicalization literature, establishing connections with frame averaging in the case of continuous non-compact groups. Operating within the framework of canonicalization, LieLAC can easily be integrated with unconstrained pre-trained models, transforming inputs to a canonical form before feeding them into the existing model, effectively aligning the input for model inference according to allowed symmetries. LieLAC utilizes standard Lie group descent schemes, achieving equivariance in pre-trained models. Finally, we showcase LieLAC's efficacy on tasks of invariant image classification and Lie point symmetry equivariant neural PDE solvers using pre-trained models.
<div id='section'>Paperid: <span id='pid'>421, <a href='https://arxiv.org/pdf/2409.10284.pdf' target='_blank'>https://arxiv.org/pdf/2409.10284.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ting Du, Xianliang Xu, Wang Kong, Ye Li, Zhongyi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10284">Physics-Informed Tailored Finite Point Operator Network for Parametric Interface Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning operators for parametric partial differential equations (PDEs) using neural networks has gained significant attention in recent years. However, standard approaches like Deep Operator Networks (DeepONets) require extensive labeled data, and physics-informed DeepONets encounter training challenges. In this paper, we introduce a novel physics-informed tailored finite point operator network (PI-TFPONet) method to solve parametric interface problems without the need for labeled data. Our method fully leverages the prior physical information of the problem, eliminating the need to include the PDE residual in the loss function, thereby avoiding training challenges. The PI-TFPONet is specifically designed to address certain properties of the problem, allowing us to naturally obtain an approximate solution that closely matches the exact solution. Our method is theoretically proven to converge if the local mesh size is sufficiently small and the training loss is minimized. Notably, our approach is uniformly convergent for singularly perturbed interface problems. Extensive numerical studies show that our unsupervised PI-TFPONet is comparable to or outperforms existing state-of-the-art supervised deep operator networks in terms of accuracy and versatility.
<div id='section'>Paperid: <span id='pid'>422, <a href='https://arxiv.org/pdf/2408.14780.pdf' target='_blank'>https://arxiv.org/pdf/2408.14780.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nisal Ranasinghe, Yu Xia, Sachith Seneviratne, Saman Halgamuge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14780">GINN-KAN: Interpretability pipelining with applications in Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks are powerful function approximators, yet their ``black-box" nature often renders them opaque and difficult to interpret. While many post-hoc explanation methods exist, they typically fail to capture the underlying reasoning processes of the networks. A truly interpretable neural network would be trained similarly to conventional models using techniques such as backpropagation, but additionally provide insights into the learned input-output relationships. In this work, we introduce the concept of interpretability pipelineing, to incorporate multiple interpretability techniques to outperform each individual technique. To this end, we first evaluate several architectures that promise such interpretability, with a particular focus on two recent models selected for their potential to incorporate interpretability into standard neural network architectures while still leveraging backpropagation: the Growing Interpretable Neural Network (GINN) and Kolmogorov Arnold Networks (KAN). We analyze the limitations and strengths of each and introduce a novel interpretable neural network GINN-KAN that synthesizes the advantages of both models. When tested on the Feynman symbolic regression benchmark datasets, GINN-KAN outperforms both GINN and KAN. To highlight the capabilities and the generalizability of this approach, we position GINN-KAN as an alternative to conventional black-box networks in Physics-Informed Neural Networks (PINNs). We expect this to have far-reaching implications in the application of deep learning pipelines in the natural sciences. Our experiments with this interpretable PINN on 15 different partial differential equations demonstrate that GINN-KAN augmented PINNs outperform PINNs with black-box networks in solving differential equations and surpass the capabilities of both GINN and KAN.
<div id='section'>Paperid: <span id='pid'>423, <a href='https://arxiv.org/pdf/2408.00573.pdf' target='_blank'>https://arxiv.org/pdf/2408.00573.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xianliang Xu, Ting Du, Wang Kong, Bin Shan, Ye Li, Zhongyi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00573">Convergence Analysis of Natural Gradient Descent for Over-parameterized Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the context of over-parameterization, there is a line of work demonstrating that randomly initialized (stochastic) gradient descent (GD) converges to a globally optimal solution at a linear convergence rate for the quadratic loss function. However, the learning rate of GD for training two-layer neural networks exhibits poor dependence on the sample size and the Gram matrix, leading to a slow training process. In this paper, we show that for training two-layer $\text{ReLU}^3$ Physics-Informed Neural Networks (PINNs), the learning rate can be improved from $\mathcal{O}(Î»_0)$ to $\mathcal{O}(1/\|\bm{H}^{\infty}\|_2)$, implying that GD actually enjoys a faster convergence rate. Despite such improvements, the convergence rate is still tied to the least eigenvalue of the Gram matrix, leading to slow convergence. We then develop the positive definiteness of Gram matrices with general smooth activation functions and provide the convergence analysis of natural gradient descent (NGD) in training two-layer PINNs, demonstrating that the learning rate can be $\mathcal{O}(1)$ and at this rate, the convergence rate is independent of the Gram matrix. In particular, for smooth activation functions, the convergence rate of NGD is quadratic. Numerical experiments are conducted to verify our theoretical results.
<div id='section'>Paperid: <span id='pid'>424, <a href='https://arxiv.org/pdf/2407.18732.pdf' target='_blank'>https://arxiv.org/pdf/2407.18732.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Federico Miotello, Ferdinando Terminiello, Mirco Pezzoli, Alberto Bernardini, Fabio Antonacci, Augusto Sarti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.18732">A Physics-Informed Neural Network-Based Approach for the Spatial Upsampling of Spherical Microphone Arrays</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spherical microphone arrays are convenient tools for capturing the spatial characteristics of a sound field. However, achieving superior spatial resolution requires arrays with numerous capsules, consequently leading to expensive devices. To address this issue, we present a method for spatially upsampling spherical microphone arrays with a limited number of capsules. Our approach exploits a physics-informed neural network with Rowdy activation functions, leveraging physical constraints to provide high-order microphone array signals, starting from low-order devices. Results show that, within its domain of application, our approach outperforms a state of the art method based on signal processing for spherical microphone arrays upsampling.
<div id='section'>Paperid: <span id='pid'>425, <a href='https://arxiv.org/pdf/2407.02827.pdf' target='_blank'>https://arxiv.org/pdf/2407.02827.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xianliang Xu, Ting Du, Wang Kong, Bin Shan, Ye Li, Zhongyi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02827">Convergence of Implicit Gradient Descent for Training Two-Layer Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The optimization algorithms are crucial in training physics-informed neural networks (PINNs), as unsuitable methods may lead to poor solutions. Compared to the common gradient descent (GD) algorithm, implicit gradient descent (IGD) outperforms it in handling certain multi-scale problems. In this paper, we provide convergence analysis for the IGD in training over-parameterized two-layer PINNs. We first derive the training dynamics of IGD in training two-layer PINNs. Then, over-parameterization allows us to prove that the randomly initialized IGD converges to a globally optimal solution at a linear convergence rate. Moreover, due to the distinct training dynamics of IGD compared to GD, the learning rate can be selected independently of the sample size and the least eigenvalue of the Gram matrix. Additionally, the novel approach used in our convergence analysis imposes a milder requirement on the network width. Finally, empirical results validate our theoretical findings.
<div id='section'>Paperid: <span id='pid'>426, <a href='https://arxiv.org/pdf/2406.17812.pdf' target='_blank'>https://arxiv.org/pdf/2406.17812.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wesley Brewer, Aditya Kashi, Sajal Dash, Aristeidis Tsaris, Junqi Yin, Mallikarjun Shankar, Feiyi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.17812">Scalable Artificial Intelligence for Science: Perspectives, Methods and Exemplars</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In a post-ChatGPT world, this paper explores the potential of leveraging scalable artificial intelligence for scientific discovery. We propose that scaling up artificial intelligence on high-performance computing platforms is essential to address such complex problems. This perspective focuses on scientific use cases like cognitive simulations, large language models for scientific inquiry, medical image analysis, and physics-informed approaches. The study outlines the methodologies needed to address such challenges at scale on supercomputers or the cloud and provides exemplars of such approaches applied to solve a variety of scientific problems.
<div id='section'>Paperid: <span id='pid'>427, <a href='https://arxiv.org/pdf/2406.03080.pdf' target='_blank'>https://arxiv.org/pdf/2406.03080.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xianliang Xu, Ye Li, Zhongyi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03080">A Priori Estimation of the Approximation, Optimization and Generalization Errors of Random Neural Networks for Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, neural networks have achieved remarkable progress in various fields and have also drawn much attention in applying them on scientific problems. A line of methods involving neural networks for solving partial differential equations (PDEs), such as Physics-Informed Neural Networks (PINNs) and the Deep Ritz Method (DRM), has emerged. Although these methods outperform classical numerical methods in certain cases, the optimization problems involving neural networks are typically non-convex and non-smooth, which can result in unsatisfactory solutions for PDEs. In contrast to deterministic neural networks, the hidden weights of random neural networks are sampled from some prior distribution and only the output weights participate in training. This makes training much simpler, but it remains unclear how to select the prior distribution. In this paper, we focus on Barron type functions and approximate them under Sobolev norms by random neural networks with clear prior distribution. In addition to the approximation error, we also derive bounds for the optimization and generalization errors of random neural networks for solving PDEs when the solutions are Barron type functions.
<div id='section'>Paperid: <span id='pid'>428, <a href='https://arxiv.org/pdf/2405.08558.pdf' target='_blank'>https://arxiv.org/pdf/2405.08558.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simone Brivio, Stefania Fresca, Andrea Manzoni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08558">PTPI-DL-ROMs: pre-trained physics-informed deep learning-based reduced order models for nonlinear parametrized PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The coupling of Proper Orthogonal Decomposition (POD) and deep learning-based ROMs (DL-ROMs) has proved to be a successful strategy to construct non-intrusive, highly accurate, surrogates for the real time solution of parametric nonlinear time-dependent PDEs. Inexpensive to evaluate, POD-DL-ROMs are also relatively fast to train, thanks to their limited complexity. However, POD-DL-ROMs account for the physical laws governing the problem at hand only through the training data, that are usually obtained through a full order model (FOM) relying on a high-fidelity discretization of the underlying equations. Moreover, the accuracy of POD-DL-ROMs strongly depends on the amount of available data. In this paper, we consider a major extension of POD-DL-ROMs by enforcing the fulfillment of the governing physical laws in the training process -- that is, by making them physics-informed -- to compensate for possible scarce and/or unavailable data and improve the overall reliability. To do that, we first complement POD-DL-ROMs with a trunk net architecture, endowing them with the ability to compute the problem's solution at every point in the spatial domain, and ultimately enabling a seamless computation of the physics-based loss by means of the strong continuous formulation. Then, we introduce an efficient training strategy that limits the notorious computational burden entailed by a physics-informed training phase. In particular, we take advantage of the few available data to develop a low-cost pre-training procedure; then, we fine-tune the architecture in order to further improve the prediction reliability. Accuracy and efficiency of the resulting pre-trained physics-informed DL-ROMs (PTPI-DL-ROMs) are then assessed on a set of test cases ranging from non-affinely parametrized advection-diffusion-reaction equations, to nonlinear problems like the Navier-Stokes equations for fluid flows.
<div id='section'>Paperid: <span id='pid'>429, <a href='https://arxiv.org/pdf/2401.12526.pdf' target='_blank'>https://arxiv.org/pdf/2401.12526.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xianliang Xu, Ye Li, Zhongyi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.12526">Refined generalization analysis of the Deep Ritz Method and Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we derive refined generalization bounds for the Deep Ritz Method (DRM) and Physics-Informed Neural Networks (PINNs). For the DRM, we focus on two prototype elliptic partial differential equations (PDEs): Poisson equation and static SchrÃ¶dinger equation on the $d$-dimensional unit hypercube with the Neumann boundary condition. Furthermore, sharper generalization bounds are derived based on the localization techniques under the assumptions that the exact solutions of the PDEs lie in the Barron spaces or the general Sobolev spaces. For the PINNs, we investigate the general linear second order elliptic PDEs with Dirichlet boundary condition using the local Rademacher complexity in the multi-task learning setting. Finally, we discuss the generalization error in the setting of over-parameterization when solutions of PDEs belong to Barron space.
<div id='section'>Paperid: <span id='pid'>430, <a href='https://arxiv.org/pdf/2401.00212.pdf' target='_blank'>https://arxiv.org/pdf/2401.00212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eduardo Sebastian, Thai Duong, Nikolay Atanasov, Eduardo Montijano, Carlos Sagues
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00212">Physics-Informed Multi-Agent Reinforcement Learning for Distributed Multi-Robot Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The networked nature of multi-robot systems presents challenges in the context of multi-agent reinforcement learning. Centralized control policies do not scale with increasing numbers of robots, whereas independent control policies do not exploit the information provided by other robots, exhibiting poor performance in cooperative-competitive tasks. In this work we propose a physics-informed reinforcement learning approach able to learn distributed multi-robot control policies that are both scalable and make use of all the available information to each robot. Our approach has three key characteristics. First, it imposes a port-Hamiltonian structure on the policy representation, respecting energy conservation properties of physical robot systems and the networked nature of robot team interactions. Second, it uses self-attention to ensure a sparse policy representation able to handle time-varying information at each robot from the interaction graph. Third, we present a soft actor-critic reinforcement learning algorithm parameterized by our self-attention port-Hamiltonian control policy, which accounts for the correlation among robots during training while overcoming the need of value function factorization. Extensive simulations in different multi-robot scenarios demonstrate the success of the proposed approach, surpassing previous multi-robot reinforcement learning solutions in scalability, while achieving similar or superior performance (with averaged cumulative reward up to x2 greater than the state-of-the-art with robot teams x6 larger than the number of robots at training time). We also validate our approach on multiple real robots in the Georgia Tech Robotarium under imperfect communication, demonstrating zero-shot sim-to-real transfer and scalability across number of robots.
<div id='section'>Paperid: <span id='pid'>431, <a href='https://arxiv.org/pdf/2310.18493.pdf' target='_blank'>https://arxiv.org/pdf/2310.18493.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ping-Hsuan Tsai, Seung Whan Chung, Debojyoti Ghosh, John Loffeld, Youngsoo Choi, Jonathan L. Belof
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18493">Local Reduced-Order Modeling for Electrostatic Plasmas by Physics-Informed Solution Manifold Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite advancements in high-performance computing and modern numerical algorithms, computational cost remains prohibitive for multi-query kinetic plasma simulations. In this work, we develop data-driven reduced-order models (ROMs) for collisionless electrostatic plasma dynamics, based on the kinetic Vlasov-Poisson equation. Our ROM approach projects the equation onto a linear subspace defined by the proper orthogonal decomposition (POD) modes. We introduce an efficient tensorial method to update the nonlinear term using a precomputed third-order tensor. We capture multiscale behavior with a minimal number of POD modes by decomposing the solution manifold into multiple time windows and creating temporally local ROMs. We consider two strategies for decomposition: one based on the physical time and the other based on the electric field energy. Applied to the 1D1V Vlasov-Poisson simulations, that is, prescribed E-field, Landau damping, and two-stream instability, we demonstrate that our ROMs accurately capture the total energy of the system both for parametric and time extrapolation cases. The temporally local ROMs are more efficient and accurate than the single ROM. In addition, in the two-stream instability case, we show that the energy-windowing reduced-order model (EW-ROM) is more efficient and accurate than the time-windowing reduced-order model (TW-ROM). With the tensorial approach, EW-ROM solves the equation approximately 90 times faster than Eulerian simulations while maintaining a maximum relative error of 7.5% for the training data and 11% for the testing data.
<div id='section'>Paperid: <span id='pid'>432, <a href='https://arxiv.org/pdf/2306.15969.pdf' target='_blank'>https://arxiv.org/pdf/2306.15969.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junwoo Cho, Seungtae Nam, Hyunmo Yang, Seok-Bae Yun, Youngjoon Hong, Eunbyung Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.15969">Separable Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have recently emerged as promising data-driven PDE solvers showing encouraging results on various PDEs. However, there is a fundamental limitation of training PINNs to solve multi-dimensional PDEs and approximate highly complex solution functions. The number of training points (collocation points) required on these challenging PDEs grows substantially, but it is severely limited due to the expensive computational costs and heavy memory overhead. To overcome this issue, we propose a network architecture and training algorithm for PINNs. The proposed method, separable PINN (SPINN), operates on a per-axis basis to significantly reduce the number of network propagations in multi-dimensional PDEs unlike point-wise processing in conventional PINNs. We also propose using forward-mode automatic differentiation to reduce the computational cost of computing PDE residuals, enabling a large number of collocation points (>10^7) on a single commodity GPU. The experimental results show drastically reduced computational costs (62x in wall-clock time, 1,394x in FLOPs given the same number of collocation points) in multi-dimensional PDEs while achieving better accuracy. Furthermore, we present that SPINN can solve a chaotic (2+1)-d Navier-Stokes equation significantly faster than the best-performing prior method (9 minutes vs 10 hours in a single GPU), maintaining accuracy. Finally, we showcase that SPINN can accurately obtain the solution of a highly nonlinear and multi-dimensional PDE, a (3+1)-d Navier-Stokes equation. For visualized results and code, please see https://jwcho5576.github.io/spinn.github.io/.
<div id='section'>Paperid: <span id='pid'>433, <a href='https://arxiv.org/pdf/2306.11509.pdf' target='_blank'>https://arxiv.org/pdf/2306.11509.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mirco Pezzoli, Fabio Antonacci, Augusto Sarti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.11509">Implicit neural representation with physics-informed neural networks for the reconstruction of the early part of room impulse responses</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently deep learning and machine learning approaches have been widely employed for various applications in acoustics. Nonetheless, in the area of sound field processing and reconstruction classic methods based on the solutions of wave equation are still widespread. Recently, physics-informed neural networks have been proposed as a deep learning paradigm for solving partial differential equations which govern physical phenomena, bridging the gap between purely data-driven and model based methods. Here, we exploit physics-informed neural networks to reconstruct the early part of missing room impulse responses in an uniform linear array. This methodology allows us to exploit the underlying law of acoustics, i.e., the wave equation, forcing the neural network to generate physically meaningful solutions given only a limited number of data points. The results on real measurements show that the proposed model achieves accurate reconstruction and performance in line with respect to state-of-the-art deep-learning and compress sensing techniques while maintaining a lightweight architecture.
<div id='section'>Paperid: <span id='pid'>434, <a href='https://arxiv.org/pdf/2212.12474.pdf' target='_blank'>https://arxiv.org/pdf/2212.12474.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marvin PfÃ¶rtner, Ingo Steinwart, Philipp Hennig, Jonathan Wenger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.12474">Physics-Informed Gaussian Process Regression Generalizes Linear PDE Solvers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Linear partial differential equations (PDEs) are an important, widely applied class of mechanistic models, describing physical processes such as heat transfer, electromagnetism, and wave propagation. In practice, specialized numerical methods based on discretization are used to solve PDEs. They generally use an estimate of the unknown model parameters and, if available, physical measurements for initialization. Such solvers are often embedded into larger scientific models with a downstream application and thus error quantification plays a key role. However, by ignoring parameter and measurement uncertainty, classical PDE solvers may fail to produce consistent estimates of their inherent approximation error. In this work, we approach this problem in a principled fashion by interpreting solving linear PDEs as physics-informed Gaussian process (GP) regression. Our framework is based on a key generalization of the Gaussian process inference theorem to observations made via an arbitrary bounded linear operator. Crucially, this probabilistic viewpoint allows to (1) quantify the inherent discretization error; (2) propagate uncertainty about the model parameters to the solution; and (3) condition on noisy measurements. Demonstrating the strength of this formulation, we prove that it strictly generalizes methods of weighted residuals, a central class of PDE solvers including collocation, finite volume, pseudospectral, and (generalized) Galerkin methods such as finite element and spectral methods. This class can thus be directly equipped with a structured error estimate. In summary, our results enable the seamless integration of mechanistic models as modular building blocks into probabilistic models by blurring the boundaries between numerical analysis and Bayesian inference.
<div id='section'>Paperid: <span id='pid'>435, <a href='https://arxiv.org/pdf/2211.08761.pdf' target='_blank'>https://arxiv.org/pdf/2211.08761.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junwoo Cho, Seungtae Nam, Hyunmo Yang, Seok-Bae Yun, Youngjoon Hong, Eunbyung Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.08761">Separable PINN: Mitigating the Curse of Dimensionality in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as new data-driven PDE solvers for both forward and inverse problems. While promising, the expensive computational costs to obtain solutions often restrict their broader applicability. We demonstrate that the computations in automatic differentiation (AD) can be significantly reduced by leveraging forward-mode AD when training PINN. However, a naive application of forward-mode AD to conventional PINNs results in higher computation, losing its practical benefit. Therefore, we propose a network architecture, called separable PINN (SPINN), which can facilitate forward-mode AD for more efficient computation. SPINN operates on a per-axis basis instead of point-wise processing in conventional PINNs, decreasing the number of network forward passes. Besides, while the computation and memory costs of standard PINNs grow exponentially along with the grid resolution, that of our model is remarkably less susceptible, mitigating the curse of dimensionality. We demonstrate the effectiveness of our model in various PDE systems by significantly reducing the training run-time while achieving comparable accuracy. Project page: https://jwcho5576.github.io/spinn/
<div id='section'>Paperid: <span id='pid'>436, <a href='https://arxiv.org/pdf/2208.03322.pdf' target='_blank'>https://arxiv.org/pdf/2208.03322.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Xu, Junsheng Zeng, Dongxiao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.03322">Discovery of partial differential equations from highly noisy and sparse data with physics-informed information criterion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven discovery of PDEs has made tremendous progress recently, and many canonical PDEs have been discovered successfully for proof-of-concept. However, determining the most proper PDE without prior references remains challenging in terms of practical applications. In this work, a physics-informed information criterion (PIC) is proposed to measure the parsimony and precision of the discovered PDE synthetically. The proposed PIC achieves state-of-the-art robustness to highly noisy and sparse data on seven canonical PDEs from different physical scenes, which confirms its ability to handle difficult situations. The PIC is also employed to discover unrevealed macroscale governing equations from microscopic simulation data in an actual physical scene. The results show that the discovered macroscale PDE is precise and parsimonious, and satisfies underlying symmetries, which facilitates understanding and simulation of the physical process. The proposition of PIC enables practical applications of PDE discovery in discovering unrevealed governing equations in broader physical scenes.
<div id='section'>Paperid: <span id='pid'>437, <a href='https://arxiv.org/pdf/2207.10289.pdf' target='_blank'>https://arxiv.org/pdf/2207.10289.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenxi Wu, Min Zhu, Qinyang Tan, Yadhu Kartha, Lu Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.10289">A comprehensive study of non-adaptive and residual-based adaptive sampling for physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have shown to be an effective tool for solving forward and inverse problems of partial differential equations (PDEs). PINNs embed the PDEs into the loss of the neural network, and this PDE loss is evaluated at a set of scattered residual points. The distribution of these points are highly important to the performance of PINNs. However, in the existing studies on PINNs, only a few simple residual point sampling methods have mainly been used. Here, we present a comprehensive study of two categories of sampling: non-adaptive uniform sampling and adaptive nonuniform sampling. We consider six uniform sampling, including (1) equispaced uniform grid, (2) uniformly random sampling, (3) Latin hypercube sampling, (4) Halton sequence, (5) Hammersley sequence, and (6) Sobol sequence. We also consider a resampling strategy for uniform sampling. To improve the sampling efficiency and the accuracy of PINNs, we propose two new residual-based adaptive sampling methods: residual-based adaptive distribution (RAD) and residual-based adaptive refinement with distribution (RAR-D), which dynamically improve the distribution of residual points based on the PDE residuals during training. Hence, we have considered a total of 10 different sampling methods, including six non-adaptive uniform sampling, uniform sampling with resampling, two proposed adaptive sampling, and an existing adaptive sampling. We extensively tested the performance of these sampling methods for four forward problems and two inverse problems in many setups. Our numerical results presented in this study are summarized from more than 6000 simulations of PINNs. We show that the proposed adaptive sampling methods of RAD and RAR-D significantly improve the accuracy of PINNs with fewer residual points. The results obtained in this study can also be used as a practical guideline in choosing sampling methods.
<div id='section'>Paperid: <span id='pid'>438, <a href='https://arxiv.org/pdf/2206.04406.pdf' target='_blank'>https://arxiv.org/pdf/2206.04406.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tamara G. Grossmann, SÃ¶ren Dittmer, Yury Korolev, Carola-Bibiane SchÃ¶nlieb
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.04406">Unsupervised Learning of the Total Variation Flow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The total variation (TV) flow generates a scale-space representation of an image based on the TV functional. This gradient flow observes desirable features for images, such as sharp edges and enables spectral, scale, and texture analysis. Solving the TV flow is challenging; one reason is the the non-uniqueness of the subgradients. The standard numerical approach for TV flow requires solving multiple non-smooth optimisation problems. Even with state-of-the-art convex optimisation techniques, this is often prohibitively expensive and strongly motivates the use of alternative, faster approaches. Inspired by and extending the framework of physics-informed neural networks (PINNs), we propose the TVflowNET, an unsupervised neural network approach, to approximate the solution of the TV flow given an initial image and a time instance. The TVflowNET requires no ground truth data but rather makes use of the PDE for optimisation of the network parameters. We circumvent the challenges related to the non-uniqueness of the subgradients by additionally learning the related diffusivity term. Our approach significantly speeds up the computation time and we show that the TVflowNET approximates the TV flow solution with high fidelity for different image sizes and image types. Additionally, we give a full comparison of different network architecture designs as well as training regimes to underscore the effectiveness of our approach.
<div id='section'>Paperid: <span id='pid'>439, <a href='https://arxiv.org/pdf/2205.03990.pdf' target='_blank'>https://arxiv.org/pdf/2205.03990.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xin-Yang Liu, Min Zhu, Lu Lu, Hao Sun, Jian-Xun Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.03990">Multi-resolution partial differential equations preserved learning framework for spatiotemporal dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional data-driven deep learning models often struggle with high training costs, error accumulation, and poor generalizability in complex physical processes. Physics-informed deep learning (PiDL) addresses these challenges by incorporating physical principles into the model. Most PiDL approaches regularize training by embedding governing equations into the loss function, yet this depends heavily on extensive hyperparameter tuning to weigh each loss term. To this end, we propose to leverage physics prior knowledge by ``baking'' the discretized governing equations into the neural network architecture via the connection between the partial differential equations (PDE) operators and network structures, resulting in a PDE-preserved neural network (PPNN). This method, embedding discretized PDEs through convolutional residual networks in a multi-resolution setting, largely improves the generalizability and long-term prediction accuracy, outperforming conventional black-box models. The effectiveness and merit of the proposed methods have been demonstrated across various spatiotemporal dynamical systems governed by spatiotemporal PDEs, including reaction-diffusion, Burgers', and Navier-Stokes equations.
<div id='section'>Paperid: <span id='pid'>440, <a href='https://arxiv.org/pdf/2509.15778.pdf' target='_blank'>https://arxiv.org/pdf/2509.15778.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Bahari, Amir Hossein Barjini, Pauli Mustalahti, Jouni Mattila
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15778">All-Electric Heavy-Duty Robotic Manipulator: Actuator Configuration Optimization and Sensorless Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a unified framework that integrates modeling, optimization, and sensorless control of an all-electric heavy-duty robotic manipulator (HDRM) driven by electromechanical linear actuators (EMLAs). An EMLA model is formulated to capture motor electromechanics and direction-dependent transmission efficiencies, while a mathematical model of the HDRM, incorporating both kinematics and dynamics, is established to generate joint-space motion profiles for prescribed TCP trajectories. A safety-ensured trajectory generator, tailored to this model, maps Cartesian goals to joint space while enforcing joint-limit and velocity margins. Based on the resulting force and velocity demands, a multi-objective Non-dominated Sorting Genetic Algorithm II (NSGA-II) is employed to select the optimal EMLA configuration. To accelerate this optimization, a deep neural network, trained with EMLA parameters, is embedded in the optimization process to predict steady-state actuator efficiency from trajectory profiles. For the chosen EMLA design, a physics-informed Kriging surrogate, anchored to the analytic model and refined with experimental data, learns residuals of EMLA outputs to support force and velocity sensorless control. The actuator model is further embedded in a hierarchical virtual decomposition control (VDC) framework that outputs voltage commands. Experimental validation on a one-degree-of-freedom EMLA testbed confirms accurate trajectory tracking and effective sensorless control under varying loads.
<div id='section'>Paperid: <span id='pid'>441, <a href='https://arxiv.org/pdf/2509.13620.pdf' target='_blank'>https://arxiv.org/pdf/2509.13620.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeongjin, Park, Grant Bruer, Huseyin Tuna Erdinc, Abhinav Prakash Gahlot, Felix J. Herrmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13620">A reduced-order derivative-informed neural operator for subsurface fluid-flow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural operators have emerged as cost-effective surrogates for expensive fluid-flow simulators, particularly in computationally intensive tasks such as permeability inversion from time-lapse seismic data, and uncertainty quantification. In these applications, the fidelity of the surrogate's gradients with respect to system parameters is crucial, as the accuracy of downstream tasks, such as optimization and Bayesian inference, relies directly on the quality of the derivative information. Recent advances in physics-informed methods have leveraged derivative information to improve surrogate accuracy. However, incorporating explicit Jacobians can become computationally prohibitive, as the complexity typically scales quadratically with the number of input parameters. To address this limitation, we propose DeFINO (Derivative-based Fisher-score Informed Neural Operator), a reduced-order, derivative-informed training framework. DeFINO integrates Fourier neural operators (FNOs) with a novel derivative-based training strategy guided by the Fisher Information Matrix (FIM). By projecting Jacobians onto dominant eigen-directions identified by the FIM, DeFINO captures critical sensitivity information directly informed by observational data, significantly reducing computational expense. We validate DeFINO through synthetic experiments in the context of subsurface multi-phase fluid-flow, demonstrating improvements in gradient accuracy while maintaining robust forward predictions of underlying fluid dynamics. These results highlight DeFINO's potential to offer practical, scalable solutions for inversion problems in complex real-world scenarios, all at substantially reduced computational cost.
<div id='section'>Paperid: <span id='pid'>442, <a href='https://arxiv.org/pdf/2509.08967.pdf' target='_blank'>https://arxiv.org/pdf/2509.08967.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinquan Huang, Fu Wang, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08967">Physics-informed waveform inversion using pretrained wavefield neural operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Full waveform inversion (FWI) is crucial for reconstructing high-resolution subsurface models, but it is often hindered, considering the limited data, by its null space resulting in low-resolution models, and more importantly, by its computational cost, especially if needed for real-time applications. Recent attempts to accelerate FWI using learned wavefield neural operators have shown promise in efficiency and differentiability, but typically suffer from noisy and unstable inversion performance. To address these limitations, we introduce a novel physics-informed FWI framework to enhance the inversion in accuracy while maintaining the efficiency of neural operator-based FWI. Instead of relying only on the L2 norm objective function via automatic differentiation, resulting in noisy model reconstruction, we integrate a physics constraint term in the loss function of FWI, improving the quality of the inverted velocity models. Specifically, starting with an initial model to simulate wavefields and then evaluating the loss over how much the resulting wavefield obeys the physical laws (wave equation) and matches the recorded data, we achieve a reduction in noise and artifacts. Numerical experiments using the OpenFWI and Overthrust models demonstrate our method's superior performance, offering cleaner and more accurate subsurface velocity than vanilla approaches. Considering the efficiency of the approach compared to FWI, this advancement represents a significant step forward in the practical application of FWI for real-time subsurface monitoring.
<div id='section'>Paperid: <span id='pid'>443, <a href='https://arxiv.org/pdf/2508.20288.pdf' target='_blank'>https://arxiv.org/pdf/2508.20288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoyuan Wang, Raffaele Romagnoli, Kamyar Azizzadenesheli, Yorie Nakahira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20288">Neural Spline Operators for Risk Quantification in Stochastic Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately quantifying long-term risk probabilities in diverse stochastic systems is essential for safety-critical control. However, existing sampling-based and partial differential equation (PDE)-based methods often struggle to handle complex varying dynamics. Physics-informed neural networks learn surrogate mappings for risk probabilities from varying system parameters of fixed and finite dimensions, yet can not account for functional variations in system dynamics. To address these challenges, we introduce physics-informed neural operator (PINO) methods to risk quantification problems, to learn mappings from varying \textit{functional} system dynamics to corresponding risk probabilities. Specifically, we propose Neural Spline Operators (NeSO), a PINO framework that leverages B-spline representations to improve training efficiency and achieve better initial and boundary condition enforcements, which are crucial for accurate risk quantification. We provide theoretical analysis demonstrating the universal approximation capability of NeSO. We also present two case studies, one with varying functional dynamics and another with high-dimensional multi-agent dynamics, to demonstrate the efficacy of NeSO and its significant online speed-up over existing methods. The proposed framework and the accompanying universal approximation theorem are expected to be beneficial for other control or PDE-related problems beyond risk quantification.
<div id='section'>Paperid: <span id='pid'>444, <a href='https://arxiv.org/pdf/2508.12681.pdf' target='_blank'>https://arxiv.org/pdf/2508.12681.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Johann Licher, Max Bartholdt, Henrik Krauss, Tim-Lukas Habich, Thomas Seel, Moritz Schappler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12681">Adaptive Model-Predictive Control of a Soft Continuum Robot Using a Physics-Informed Neural Network Based on Cosserat Rod Theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamic control of soft continuum robots (SCRs) holds great potential for expanding their applications, but remains a challenging problem due to the high computational demands of accurate dynamic models. While data-driven approaches like Koopman-operator-based methods have been proposed, they typically lack adaptability and cannot capture the full robot shape, limiting their applicability. This work introduces a real-time-capable nonlinear model-predictive control (MPC) framework for SCRs based on a domain-decoupled physics-informed neural network (DD-PINN) with adaptable bending stiffness. The DD-PINN serves as a surrogate for the dynamic Cosserat rod model with a speed-up factor of 44000. It is also used within an unscented Kalman filter for estimating the model states and bending compliance from end-effector position measurements. We implement a nonlinear evolutionary MPC running at 70 Hz on the GPU. In simulation, it demonstrates accurate tracking of dynamic trajectories and setpoint control with end-effector position errors below 3 mm (2.3% of the actuator's length). In real-world experiments, the controller achieves similar accuracy and accelerations up to 3.55 m/s2.
<div id='section'>Paperid: <span id='pid'>445, <a href='https://arxiv.org/pdf/2503.19333.pdf' target='_blank'>https://arxiv.org/pdf/2503.19333.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashish S. Nair, Bruno Jacob, Amanda A. Howard, Jan Drgona, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.19333">E-PINNs: Epistemic Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have demonstrated promise as a framework for solving forward and inverse problems involving partial differential equations. Despite recent progress in the field, it remains challenging to quantify uncertainty in these networks. While approaches such as Bayesian PINNs (B-PINNs) provide a principled approach to capturing uncertainty through Bayesian inference, they can be computationally expensive for large-scale applications. In this work, we propose Epistemic Physics-Informed Neural Networks (E-PINNs), a framework that leverages a small network, the \emph{epinet}, to efficiently quantify uncertainty in PINNs. The proposed approach works as an add-on to existing, pre-trained PINNs with a small computational overhead. We demonstrate the applicability of the proposed framework in various test cases and compare the results with B-PINNs using Hamiltonian Monte Carlo (HMC) posterior estimation and dropout-equipped PINNs (Dropout-PINNs). Our experiments show that E-PINNs provide similar coverage to B-PINNs, with often comparable sharpness, while being computationally more efficient. This observation, combined with E-PINNs' more consistent uncertainty estimates and better calibration compared to Dropout-PINNs for the examples presented, indicates that E-PINNs offer a promising approach in terms of accuracy-efficiency trade-off.
<div id='section'>Paperid: <span id='pid'>446, <a href='https://arxiv.org/pdf/2503.16850.pdf' target='_blank'>https://arxiv.org/pdf/2503.16850.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maximilian Zoch, Edward Holmberg, Pujan Pokhrel, Ken Pathak, Steven Sloan, Kendall Niles, Jay Ratcliff, Maik Flanagin, Elias Ioup, Christian Guetl, Mahdi Abdelguerfi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16850">Physics-Informed Neural Network Surrogate Models for River Stage Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work investigates the feasibility of using Physics-Informed Neural Networks (PINNs) as surrogate models for river stage prediction, aiming to reduce computational cost while maintaining predictive accuracy. Our primary contribution demonstrates that PINNs can successfully approximate HEC-RAS numerical solutions when trained on a single river, achieving strong predictive accuracy with generally low relative errors, though some river segments exhibit higher deviations.
  By integrating the governing Saint-Venant equations into the learning process, the proposed PINN-based surrogate model enforces physical consistency and significantly improves computational efficiency compared to HEC-RAS. We evaluate the model's performance in terms of accuracy and computational speed, demonstrating that it closely approximates HEC-RAS predictions while enabling real-time inference.
  These results highlight the potential of PINNs as effective surrogate models for single-river hydrodynamics, offering a promising alternative for computationally efficient river stage forecasting. Future work will explore techniques to enhance PINN training stability and robustness across a more generalized multi-river model.
<div id='section'>Paperid: <span id='pid'>447, <a href='https://arxiv.org/pdf/2503.16777.pdf' target='_blank'>https://arxiv.org/pdf/2503.16777.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoyuan Wang, Raffaele Romagnoli, Jasmine Ratchford, Yorie Nakahira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16777">Physics-Informed Deep B-Spline Networks for Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning provides an approach to combining data and governing physics laws for solving complex partial differential equations (PDEs). However, efficiently solving PDEs with varying parameters and changing initial conditions and boundary conditions (ICBCs) with theoretical guarantees remains an open challenge. We propose a hybrid framework that uses a neural network to learn B-spline control points to approximate solutions to PDEs with varying system and ICBC parameters. The proposed network can be trained efficiently as one can directly specify ICBCs without imposing losses, calculate physics-informed loss functions through analytical formulas, and requires only learning the weights of B-spline functions as opposed to both weights and basis as in traditional neural operator learning methods. We provide theoretical guarantees that the proposed B-spline networks serve as universal approximators for the set of solutions of PDEs with varying ICBCs under mild conditions and establish bounds on the generalization errors in physics-informed learning. We also demonstrate in experiments that the proposed B-spline network can solve problems with discontinuous ICBCs and outperforms existing methods, and is able to learn solutions of 3D dynamics with diverse initial conditions.
<div id='section'>Paperid: <span id='pid'>448, <a href='https://arxiv.org/pdf/2502.08783.pdf' target='_blank'>https://arxiv.org/pdf/2502.08783.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adrian Celaya, Yimo Wang, David Fuentes, Beatrice Riviere
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.08783">Learning Discontinuous Galerkin Solutions to Elliptic Problems via Small Linear Convolutional Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, there has been an increasing interest in using deep learning and neural networks to tackle scientific problems, particularly in solving partial differential equations (PDEs). However, many neural network-based methods, such as physics-informed neural networks, depend on automatic differentiation and the sampling of collocation points, which can result in a lack of interpretability and lower accuracy compared to traditional numerical methods. To address this issue, we propose two approaches for learning discontinuous Galerkin solutions to PDEs using small linear convolutional neural networks. Our first approach is supervised and depends on labeled data, while our second approach is unsupervised and does not rely on any training data. In both cases, our methods use substantially fewer parameters than similar numerics-based neural networks while also demonstrating comparable accuracy to the true and DG solutions for elliptic problems.
<div id='section'>Paperid: <span id='pid'>449, <a href='https://arxiv.org/pdf/2502.01916.pdf' target='_blank'>https://arxiv.org/pdf/2502.01916.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tim-Lukas Habich, Aran Mohammad, Simon F. G. Ehlers, Martin Bensch, Thomas Seel, Moritz Schappler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01916">Generalizable and Fast Surrogates: Model Predictive Control of Articulated Soft Robots using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Soft robots can revolutionize several applications with high demands on dexterity and safety. When operating these systems, real-time estimation and control require fast and accurate models. However, prediction with first-principles (FP) models is slow, and learned black-box models have poor generalizability. Physics-informed machine learning offers excellent advantages here, but it is currently limited to simple, often simulated systems without considering changes after training. We propose physics-informed neural networks (PINNs) for articulated soft robots (ASRs) with a focus on data efficiency. The amount of expensive real-world training data is reduced to a minimum -- one dataset in one system domain. Two hours of data in different domains are used for a comparison against two gold-standard approaches: In contrast to a recurrent neural network, the PINN provides a high generalizability. The prediction speed of an accurate FP model is exceeded with the PINN by up to a factor of 467 at slightly reduced accuracy. This enables nonlinear model predictive control (MPC) of a pneumatic ASR. Accurate position tracking with the MPC running at 47 Hz is achieved in six dynamic experiments.
<div id='section'>Paperid: <span id='pid'>450, <a href='https://arxiv.org/pdf/2501.12654.pdf' target='_blank'>https://arxiv.org/pdf/2501.12654.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taimeng Fu, Zitong Zhan, Zhipeng Zhao, Shaoshu Su, Xiao Lin, Ehsan Tarkesh Esfahani, Karthik Dantu, Souma Chowdhury, Chen Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12654">AnyNav: Visual Neuro-Symbolic Friction Learning for Off-road Navigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Off-road navigation is essential for a wide range of applications in field robotics such as planetary exploration and disaster response. However, it remains an unresolved challenge due to the unstructured environments and inherent complexity of terrain-vehicle interactions. Traditional physics-based methods struggle to accurately model the nonlinear dynamics of these interactions, while data-driven approaches often suffer from overfitting to specific motion patterns, vehicle sizes, and types, limiting their generalizability. To overcome these challenges, we introduce a vision-based friction estimation framework grounded in neuro-symbolic principles, integrating neural networks for visual perception with symbolic reasoning for physical modeling. This enables significantly improved generalization abilities through explicit physical reasoning incorporating the predicted friction. Additionally, we develop a physics-informed planner that leverages the learned friction coefficient to generate physically feasible and efficient paths, along with corresponding speed profiles. We refer to our approach as AnyNav and evaluate it in both simulation and real-world experiments, demonstrating its utility and robustness across various off-road scenarios and multiple types of four-wheeled vehicles. These results mark an important step toward developing neuro-symbolic spatial intelligence to reason about complex, unstructured environments and enable autonomous off-road navigation in challenging scenarios. Video demonstrations are available at https://sairlab.org/anynav/, where the source code will also be released.
<div id='section'>Paperid: <span id='pid'>451, <a href='https://arxiv.org/pdf/2501.12053.pdf' target='_blank'>https://arxiv.org/pdf/2501.12053.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingpo Wuwu, Chonghan Gao, Tianyu Chen, Yihang Huang, Yuekai Zhang, Jianing Wang, Jianxin Li, Haoyi Zhou, Shanghang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12053">PINNsAgent: Automated PDE Surrogation with Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving partial differential equations (PDEs) using neural methods has been a long-standing scientific and engineering research pursuit. Physics-Informed Neural Networks (PINNs) have emerged as a promising alternative to traditional numerical methods for solving PDEs. However, the gap between domain-specific knowledge and deep learning expertise often limits the practical application of PINNs. Previous works typically involve manually conducting extensive PINNs experiments and summarizing heuristic rules for hyperparameter tuning. In this work, we introduce PINNsAgent, a novel surrogation framework that leverages large language models (LLMs) and utilizes PINNs as a foundation to bridge the gap between domain-specific knowledge and deep learning. Specifically, PINNsAgent integrates (1) Physics-Guided Knowledge Replay (PGKR), which encodes the essential characteristics of PDEs and their associated best-performing PINNs configurations into a structured format, enabling efficient knowledge transfer from solved PDEs to similar problems and (2) Memory Tree Reasoning, a strategy that effectively explores the search space for optimal PINNs architectures. By leveraging LLMs and exploration strategies, PINNsAgent enhances the automation and efficiency of PINNs-based solutions. We evaluate PINNsAgent on 14 benchmark PDEs, demonstrating its effectiveness in automating the surrogation process and significantly improving the accuracy of PINNs-based solutions.
<div id='section'>Paperid: <span id='pid'>452, <a href='https://arxiv.org/pdf/2501.07700.pdf' target='_blank'>https://arxiv.org/pdf/2501.07700.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adrian Celaya, David Fuentes, Beatrice Riviere
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.07700">Adaptive Collocation Point Strategies For Physics Informed Neural Networks via the QR Discrete Empirical Interpolation Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have gained significant attention for solving forward and inverse problems related to partial differential equations (PDEs). While advancements in loss functions and network architectures have improved PINN accuracy, the impact of collocation point sampling on their performance remains underexplored. Fixed sampling methods, such as uniform random sampling and equispaced grids, can fail to capture critical regions with high solution gradients, limiting their effectiveness for complex PDEs. Adaptive methods, inspired by adaptive mesh refinement from traditional numerical methods, address this by dynamically updating collocation points during training but may overlook residual dynamics between updates, potentially losing valuable information. To overcome this limitation, we propose two adaptive collocation point selection strategies utilizing the QR Discrete Empirical Interpolation Method (QR-DEIM), a reduced-order modeling technique for efficiently approximating nonlinear functions. Our results on benchmark PDEs demonstrate that our QR-DEIM-based approaches improve PINN accuracy compared to existing methods, offering a promising direction for adaptive collocation point strategies.
<div id='section'>Paperid: <span id='pid'>453, <a href='https://arxiv.org/pdf/2412.16738.pdf' target='_blank'>https://arxiv.org/pdf/2412.16738.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan Diego Toscano, Li-Lian Wang, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.16738">KKANs: Kurkova-Kolmogorov-Arnold Networks and Their Learning Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inspired by the Kolmogorov-Arnold representation theorem and Kurkova's principle of using approximate representations, we propose the Kurkova-Kolmogorov-Arnold Network (KKAN), a new two-block architecture that combines robust multi-layer perceptron (MLP) based inner functions with flexible linear combinations of basis functions as outer functions. We first prove that KKAN is a universal approximator, and then we demonstrate its versatility across scientific machine-learning applications, including function regression, physics-informed machine learning (PIML), and operator-learning frameworks. The benchmark results show that KKANs outperform MLPs and the original Kolmogorov-Arnold Networks (KANs) in function approximation and operator learning tasks and achieve performance comparable to fully optimized MLPs for PIML. To better understand the behavior of the new representation models, we analyze their geometric complexity and learning dynamics using information bottleneck theory, identifying three universal learning stages, fitting, transition, and diffusion, across all types of architectures. We find a strong correlation between geometric complexity and signal-to-noise ratio (SNR), with optimal generalization achieved during the diffusion stage. Additionally, we propose self-scaled residual-based attention weights to maintain high SNR dynamically, ensuring uniform convergence and prolonged learning.
<div id='section'>Paperid: <span id='pid'>454, <a href='https://arxiv.org/pdf/2411.14214.pdf' target='_blank'>https://arxiv.org/pdf/2411.14214.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junhua Liu, Fanfan Lin, Xinze Li, Kwan Hui Lim, Shuai Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14214">Physics-Informed LLM-Agent for Automated Modulation Design in Power Electronics Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LLM-based autonomous agents have demonstrated outstanding performance in solving complex industrial tasks. However, in the pursuit of carbon neutrality and high-performance renewable energy systems, existing AI-assisted design automation faces significant limitations in explainability, scalability, and usability. To address these challenges, we propose LP-COMDA, an LLM-based, physics-informed autonomous agent that automates the modulation design of power converters in Power Electronics Systems with minimal human supervision. Unlike traditional AI-assisted approaches, LP-COMDA contains an LLM-based planner that gathers and validates design specifications through a user-friendly chat interface. The planner then coordinates with physics-informed design and optimization tools to iteratively generate and refine modulation designs autonomously. Through the chat interface, LP-COMDA provides an explainable design process, presenting explanations and charts. Experiments show that LP-COMDA outperforms all baseline methods, achieving a 63.2% reduction in error compared to the second-best benchmark method in terms of standard mean absolute error. Furthermore, empirical studies with 20 experts conclude that design time with LP-COMDA is over 33 times faster than conventional methods, showing its significant improvement on design efficiency over the current processes.
<div id='section'>Paperid: <span id='pid'>455, <a href='https://arxiv.org/pdf/2411.06286.pdf' target='_blank'>https://arxiv.org/pdf/2411.06286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bruno Jacob, Amanda A. Howard, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.06286">SPIKANs: Separable Physics-Informed Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a promising method for solving partial differential equations (PDEs) in scientific computing. While PINNs typically use multilayer perceptrons (MLPs) as their underlying architecture, recent advancements have explored alternative neural network structures. One such innovation is the Kolmogorov-Arnold Network (KAN), which has demonstrated benefits over traditional MLPs, including faster neural scaling and better interpretability. The application of KANs to physics-informed learning has led to the development of Physics-Informed KANs (PIKANs), enabling the use of KANs to solve PDEs. However, despite their advantages, KANs often suffer from slower training speeds, particularly in higher-dimensional problems where the number of collocation points grows exponentially with the dimensionality of the system. To address this challenge, we introduce Separable Physics-Informed Kolmogorov-Arnold Networks (SPIKANs). This novel architecture applies the principle of separation of variables to PIKANs, decomposing the problem such that each dimension is handled by an individual KAN. This approach drastically reduces the computational complexity of training without sacrificing accuracy, facilitating their application to higher-dimensional PDEs. Through a series of benchmark problems, we demonstrate the effectiveness of SPIKANs, showcasing their superior scalability and performance compared to PIKANs and highlighting their potential for solving complex, high-dimensional PDEs in scientific computing.
<div id='section'>Paperid: <span id='pid'>456, <a href='https://arxiv.org/pdf/2410.14764.pdf' target='_blank'>https://arxiv.org/pdf/2410.14764.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda A. Howard, Bruno Jacob, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14764">Multifidelity Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a method for multifidelity Kolmogorov-Arnold networks (KANs), which use a low-fidelity model along with a small amount of high-fidelity data to train a model for the high-fidelity data accurately. Multifidelity KANs (MFKANs) reduce the amount of expensive high-fidelity data needed to accurately train a KAN by exploiting the correlations between the low- and high-fidelity data to give accurate and robust predictions in the absence of a large high-fidelity dataset. In addition, we show that multifidelity KANs can be used to increase the accuracy of physics-informed KANs (PIKANs), without the use of training data.
<div id='section'>Paperid: <span id='pid'>457, <a href='https://arxiv.org/pdf/2408.14951.pdf' target='_blank'>https://arxiv.org/pdf/2408.14951.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Henrik Krauss, Tim-Lukas Habich, Max Bartholdt, Thomas Seel, Moritz Schappler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14951">Domain-decoupled Physics-informed Neural Networks with Closed-form Gradients for Fast Model Learning of Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are trained using physical equations and can also incorporate unmodeled effects by learning from data. PINNs for control (PINCs) of dynamical systems are gaining interest due to their prediction speed compared to classical numerical integration methods for nonlinear state-space models, making them suitable for real-time control applications. We introduce the domain-decoupled physics-informed neural network (DD-PINN) to address current limitations of PINC in handling large and complex nonlinear dynamical systems. The time domain is decoupled from the feed-forward neural network to construct an Ansatz function, allowing for calculation of gradients in closed form. This approach significantly reduces training times, especially for large dynamical systems, compared to PINC, which relies on graph-based automatic differentiation. Additionally, the DD-PINN inherently fulfills the initial condition and supports higher-order excitation inputs, simplifying the training process and enabling improved prediction accuracy. Validation on three systems - a nonlinear mass-spring-damper, a five-mass-chain, and a two-link robot - demonstrates that the DD-PINN achieves significantly shorter training times. In cases where the PINC's prediction diverges, the DD-PINN's prediction remains stable and accurate due to higher physics loss reduction or use of a higher-order excitation input. The DD-PINN allows for fast and accurate learning of large dynamical systems previously out of reach for the PINC.
<div id='section'>Paperid: <span id='pid'>458, <a href='https://arxiv.org/pdf/2407.15727.pdf' target='_blank'>https://arxiv.org/pdf/2407.15727.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan Diego Toscano, Theo KÃ¤ufer, Zhibo Wang, Martin Maxey, Christian Cierpka, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.15727">Inferring turbulent velocity and temperature fields and their statistics from Lagrangian velocity measurements using physics-informed Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the Artificial Intelligence Velocimetry-Thermometry (AIVT) method to infer hidden temperature fields from experimental turbulent velocity data. This physics-informed machine learning method enables us to infer continuous temperature fields using only sparse velocity data, hence eliminating the need for direct temperature measurements. Specifically, AIVT is based on physics-informed Kolmogorov-Arnold Networks (not neural networks) and is trained by optimizing a combined loss function that minimizes the residuals of the velocity data, boundary conditions, and the governing equations. We apply AIVT to a unique set of experimental volumetric and simultaneous temperature and velocity data of Rayleigh-BÃ©nard convection (RBC) that we acquired by combining Particle Image Thermometry and Lagrangian Particle Tracking. This allows us to compare AIVT predictions and measurements directly. We demonstrate that we can reconstruct and infer continuous and instantaneous velocity and temperature fields from sparse experimental data at a fidelity comparable to direct numerical simulations (DNS) of turbulence. This, in turn, enables us to compute important quantities for quantifying turbulence, such as fluctuations, viscous and thermal dissipation, and QR distribution. This paradigm shift in processing experimental data using AIVT to infer turbulent fields at DNS-level fidelity is a promising avenue in breaking the current deadlock of quantitative understanding of turbulence at high Reynolds numbers, where DNS is computationally infeasible.
<div id='section'>Paperid: <span id='pid'>459, <a href='https://arxiv.org/pdf/2407.08868.pdf' target='_blank'>https://arxiv.org/pdf/2407.08868.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoyuan Wang, Albert Chern, Yorie Nakahira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08868">Generalizable Physics-Informed Learning for Stochastic Safety-Critical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate estimate of long-term risk is critical for safe decision-making, but sampling from rare risk events and long-term trajectories can be prohibitively costly. Risk gradient can be used in many first-order techniques for learning and control methods, but gradient estimate is difficult to obtain using Monte Carlo (MC) methods because the infinitesimal divisor may significantly amplify sampling noise. Motivated by this gap, we propose an efficient method to evaluate long-term risk probabilities and their gradients using short-term samples without sufficient risk events. We first derive that four types of long-term risk probability are solutions of certain partial differential equations (PDEs). Then, we propose a physics-informed learning technique that integrates data and physics information (aforementioned PDEs). The physics information helps propagate information beyond available data and obtain provable generalization beyond available data, which in turn enables long-term risk to be estimated using short-term samples of safe events. Finally, we demonstrate in simulation that the proposed technique has improved sample efficiency, generalizes well to unseen regions, and adapts to changing system parameters.
<div id='section'>Paperid: <span id='pid'>460, <a href='https://arxiv.org/pdf/2407.08868.pdf' target='_blank'>https://arxiv.org/pdf/2407.08868.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoyuan Wang, Albert Chern, Yorie Nakahira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08868">Generalizable Physics-Informed Learning for Stochastic Safety-Critical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate estimation of long-term risk is essential for the design and analysis of stochastic dynamical systems. Existing risk quantification methods typically rely on extensive datasets involving risk events observed over extended time horizons, which can be prohibitively expensive to acquire. Motivated by this gap, we propose an efficient method for learning long-term risk probabilities using short-term samples with limited occurrence of risk events. Specifically, we establish that four distinct classes of long-term risk probabilities are characterized by specific partial differential equations (PDEs). Using this characterization, we introduce a physics-informed learning framework that combines empirical data with physics information to infer risk probabilities. We then analyze the theoretical properties of this framework in terms of generalization and convergence. Through numerical experiments, we demonstrate that our framework not only generalizes effectively beyond the sampled states and time horizons but also offers additional benefits such as improved sample efficiency, rapid online inference capabilities under changing system dynamics, and stable computation of probability gradients. These results highlight how embedding PDE constraints, which contain explicit gradient terms and inform how risk probabilities depend on state, time horizon, and system parameters, improves interpolation and generalization between/beyond the available data.
<div id='section'>Paperid: <span id='pid'>461, <a href='https://arxiv.org/pdf/2407.01613.pdf' target='_blank'>https://arxiv.org/pdf/2407.01613.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenqian Chen, Amanda A. Howard, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01613">Self-adaptive weights based on balanced residual decay rate for physics-informed neural networks and deep operator networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed deep learning has emerged as a promising alternative for solving partial differential equations. However, for complex problems, training these networks can still be challenging, often resulting in unsatisfactory accuracy and efficiency. In this work, we demonstrate that the failure of plain physics-informed neural networks arises from the significant discrepancy in the convergence rate of residuals at different training points, where the slowest convergence rate dominates the overall solution convergence. Based on these observations, we propose a pointwise adaptive weighting method that balances the residual decay rate across different training points. The performance of our proposed adaptive weighting method is compared with current state-of-the-art adaptive weighting methods on benchmark problems for both physics-informed neural networks and physics-informed deep operator networks. Through extensive numerical results we demonstrate that our proposed approach of balanced residual decay rates offers several advantages, including bounded weights, high prediction accuracy, fast convergence rate, low training uncertainty, low computational cost, and ease of hyperparameter tuning.
<div id='section'>Paperid: <span id='pid'>462, <a href='https://arxiv.org/pdf/2406.19662.pdf' target='_blank'>https://arxiv.org/pdf/2406.19662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda A. Howard, Bruno Jacob, Sarah H. Murphy, Alexander Heinlein, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.19662">Finite basis Kolmogorov-Arnold networks: domain decomposition for data-driven and physics-informed problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kolmogorov-Arnold networks (KANs) have attracted attention recently as an alternative to multilayer perceptrons (MLPs) for scientific machine learning. However, KANs can be expensive to train, even for relatively small networks. Inspired by finite basis physics-informed neural networks (FBPINNs), in this work, we develop a domain decomposition method for KANs that allows for several small KANs to be trained in parallel to give accurate solutions for multiscale problems. We show that finite basis KANs (FBKANs) can provide accurate results with noisy data and for physics-informed training.
<div id='section'>Paperid: <span id='pid'>463, <a href='https://arxiv.org/pdf/2406.02645.pdf' target='_blank'>https://arxiv.org/pdf/2406.02645.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vladimir Fanaskov, Tianchi Yu, Alexander Rudikov, Ivan Oseledets
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02645">Astral: training physics-informed neural networks with error majorants</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The primal approach to physics-informed learning is a residual minimization. We argue that residual is, at best, an indirect measure of the error of approximate solution and propose to train with error majorant instead. Since error majorant provides a direct upper bound on error, one can reliably estimate how close PiNN is to the exact solution and stop the optimization process when the desired accuracy is reached. We call loss function associated with error majorant $\textbf{Astral}$: neur$\textbf{A}$l a po$\textbf{ST}$erio$\textbf{RI}$ function$\textbf{A}$l Loss. To compare Astral and residual loss functions, we illustrate how error majorants can be derived for various PDEs and conduct experiments with diffusion equations (including anisotropic and in the L-shaped domain), convection-diffusion equation, temporal discretization of Maxwell's equation, and magnetostatics problem. The results indicate that Astral loss is competitive to the residual loss, typically leading to faster convergence and lower error (e.g., for Maxwell's equations, we observe an order of magnitude better relative error and training time). We also report that the error estimate obtained with Astral loss is usually tight enough to be informative, e.g., for a highly anisotropic equation, on average, Astral overestimates error by a factor of $1.5$, and for convection-diffusion by a factor of $1.7$.
<div id='section'>Paperid: <span id='pid'>464, <a href='https://arxiv.org/pdf/2405.09572.pdf' target='_blank'>https://arxiv.org/pdf/2405.09572.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ning Liu, Xuxiao Li, Manoj R. Rajanna, Edward W. Reutzel, Brady Sawyer, Prahalada Rao, Jim Lua, Nam Phan, Yue Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.09572">Deep Neural Operator Enabled Digital Twin Modeling for Additive Manufacturing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A digital twin (DT), with the components of a physics-based model, a data-driven model, and a machine learning (ML) enabled efficient surrogate, behaves as a virtual twin of the real-world physical process. In terms of Laser Powder Bed Fusion (L-PBF) based additive manufacturing (AM), a DT can predict the current and future states of the melt pool and the resulting defects corresponding to the input laser parameters, evolve itself by assimilating in-situ sensor data, and optimize the laser parameters to mitigate defect formation. In this paper, we present a deep neural operator enabled computational framework of the DT for closed-loop feedback control of the L-PBF process. This is accomplished by building a high-fidelity computational model to accurately represent the melt pool states, an efficient surrogate model to approximate the melt pool solution field, followed by an physics-based procedure to extract information from the computed melt pool simulation that can further be correlated to the defect quantities of interest (e.g., surface roughness). In particular, we leverage the data generated from the high-fidelity physics-based model and train a series of Fourier neural operator (FNO) based ML models to effectively learn the relation between the input laser parameters and the corresponding full temperature field of the melt pool. Subsequently, a set of physics-informed variables such as the melt pool dimensions and the peak temperature can be extracted to compute the resulting defects. An optimization algorithm is then exercised to control laser input and minimize defects. On the other hand, the constructed DT can also evolve with the physical twin via offline finetuning and online material calibration. Finally, a probabilistic framework is adopted for uncertainty quantification. The developed DT is envisioned to guide the AM process and facilitate high-quality manufacturing.
<div id='section'>Paperid: <span id='pid'>465, <a href='https://arxiv.org/pdf/2405.02561.pdf' target='_blank'>https://arxiv.org/pdf/2405.02561.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Wang, Bo Zhao, Sicun Gao, Rose Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02561">Understanding the Difficulty of Solving Cauchy Problems with PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have gained popularity in scientific computing in recent years. However, they often fail to achieve the same level of accuracy as classical methods in solving differential equations. In this paper, we identify two sources of this issue in the case of Cauchy problems: the use of $L^2$ residuals as objective functions and the approximation gap of neural networks. We show that minimizing the sum of $L^2$ residual and initial condition error is not sufficient to guarantee the true solution, as this loss function does not capture the underlying dynamics. Additionally, neural networks are not capable of capturing singularities in the solutions due to the non-compactness of their image sets. This, in turn, influences the existence of global minima and the regularity of the network. We demonstrate that when the global minimum does not exist, machine precision becomes the predominant source of achievable error in practice. We also present numerical experiments in support of our theoretical claims.
<div id='section'>Paperid: <span id='pid'>466, <a href='https://arxiv.org/pdf/2404.10296.pdf' target='_blank'>https://arxiv.org/pdf/2404.10296.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chanwook Park, Sourav Saha, Jiachen Guo, Hantao Zhang, Xiaoyu Xie, Miguel A. Bessa, Dong Qian, Wei Chen, Gregory J. Wagner, Jian Cao, Wing Kam Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10296">Interpolating neural network: A novel unification of machine learning and interpolation theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence (AI) has revolutionized software development, shifting from task-specific codes (Software 1.0) to neural network-based approaches (Software 2.0). However, applying this transition in engineering software presents challenges, including low surrogate model accuracy, the curse of dimensionality in inverse design, and rising complexity in physical simulations. We introduce an interpolating neural network (INN), grounded in interpolation theory and tensor decomposition, to realize Engineering Software 2.0 by advancing data training, partial differential equation solving, and parameter calibration. INN offers orders of magnitude fewer trainable/solvable parameters for comparable model accuracy than traditional multi-layer perceptron (MLP) or physics-informed neural networks (PINN). Demonstrated in metal additive manufacturing, INN rapidly constructs an accurate surrogate model of Laser Powder Bed Fusion (L-PBF) heat transfer simulation, achieving sub-10-micrometer resolution for a 10 mm path in under 15 minutes on a single GPU. This makes a transformative step forward across all domains essential to engineering software.
<div id='section'>Paperid: <span id='pid'>467, <a href='https://arxiv.org/pdf/2404.10024.pdf' target='_blank'>https://arxiv.org/pdf/2404.10024.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yogesh Verma, Markus Heinonen, Vikas Garg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10024">ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Climate and weather prediction traditionally relies on complex numerical simulations of atmospheric physics. Deep learning approaches, such as transformers, have recently challenged the simulation paradigm with complex network forecasts. However, they often act as data-driven black-box models that neglect the underlying physics and lack uncertainty quantification. We address these limitations with ClimODE, a spatiotemporal continuous-time process that implements a key principle of advection from statistical mechanics, namely, weather changes due to a spatial movement of quantities over time. ClimODE models precise weather evolution with value-conserving dynamics, learning global weather transport as a neural flow, which also enables estimating the uncertainty in predictions. Our approach outperforms existing data-driven methods in global and regional forecasting with an order of magnitude smaller parameterization, establishing a new state of the art.
<div id='section'>Paperid: <span id='pid'>468, <a href='https://arxiv.org/pdf/2404.02521.pdf' target='_blank'>https://arxiv.org/pdf/2404.02521.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdul Qadir Ibrahim, Sebastian GÃ¶tschel, Daniel Ruprecht
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.02521">Space-time parallel scaling of Parareal with a physics-informed Fourier Neural Operator coarse propagator applied to the Black-Scholes equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Iterative parallel-in-time algorithms like Parareal can extend scaling beyond the saturation of purely spatial parallelization when solving initial value problems. However, they require the user to build coarse models to handle the inevitably serial transport of information in time.This is a time consuming and difficult process since there is still only limited theoretical insight into what constitutes a good and efficient coarse model. Novel approaches from machine learning to solve differential equations could provide a more generic way to find coarse level models for parallel-in-time algorithms. This paper demonstrates that a physics-informed Fourier Neural Operator (PINO) is an effective coarse model for the parallelization in time of the two-asset Black-Scholes equation using Parareal. We demonstrate that PINO-Parareal converges as fast as a bespoke numerical coarse model and that, in combination with spatial parallelization by domain decomposition, it provides better overall speedup than both purely spatial parallelization and space-time parallelizaton with a numerical coarse propagator.
<div id='section'>Paperid: <span id='pid'>469, <a href='https://arxiv.org/pdf/2403.18494.pdf' target='_blank'>https://arxiv.org/pdf/2403.18494.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sokratis J. Anagnostopoulos, Juan Diego Toscano, Nikolaos Stergiopulos, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18494">Learning in PINNs: Phase transition, total diffusion, and generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate the learning dynamics of fully-connected neural networks through the lens of gradient signal-to-noise ratio (SNR), examining the behavior of first-order optimizers like Adam in non-convex objectives. By interpreting the drift/diffusion phases in the information bottleneck theory, focusing on gradient homogeneity, we identify a third phase termed ``total diffusion", characterized by equilibrium in the learning rates and homogeneous gradients. This phase is marked by an abrupt SNR increase, uniform residuals across the sample space and the most rapid training convergence. We propose a residual-based re-weighting scheme to accelerate this diffusion in quadratic loss functions, enhancing generalization. We also explore the information compression phenomenon, pinpointing a significant saturation-induced compression of activations at the total diffusion phase, with deeper layers experiencing negligible information loss. Supported by experimental data on physics-informed neural networks (PINNs), which underscore the importance of gradient homogeneity due to their PDE-based sample inter-dependence, our findings suggest that recognizing phase transitions could refine ML optimization strategies for improved generalization.
<div id='section'>Paperid: <span id='pid'>470, <a href='https://arxiv.org/pdf/2402.16014.pdf' target='_blank'>https://arxiv.org/pdf/2402.16014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianyu Chen, Haoyi Zhou, Ying Li, Hao Wang, Chonghan Gao, Rongye Shi, Shanghang Zhang, Jianxin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16014">OmniArch: Building Foundation Model For Scientific Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models have revolutionized language modeling, while whether this success is replicated in scientific computing remains unexplored. We present OmniArch, the first prototype aiming at solving multi-scale and multi-physics scientific computing problems with physical alignment. We addressed all three challenges with one unified architecture. Its pre-training stage contains a Fourier Encoder-decoder fading out the disharmony across separated dimensions and a Transformer backbone integrating quantities through temporal dynamics, and the novel PDE-Aligner performs physics-informed fine-tuning under flexible conditions. As far as we know, we first conduct 1D-2D-3D united pre-training on the PDEBench, and it sets not only new performance benchmarks for 1D, 2D, and 3D PDEs but also demonstrates exceptional adaptability to new physics via in-context and zero-shot learning approaches, which supports realistic engineering applications and foresight physics discovery.
<div id='section'>Paperid: <span id='pid'>471, <a href='https://arxiv.org/pdf/2402.05585.pdf' target='_blank'>https://arxiv.org/pdf/2402.05585.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vladimir Fanaskov, Alexander Rudikov, Ivan Oseledets
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.05585">Neural functional a posteriori error estimates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a new loss function for supervised and physics-informed training of neural networks and operators that incorporates a posteriori error estimate. More specifically, during the training stage, the neural network learns additional physical fields that lead to rigorous error majorants after a computationally cheap postprocessing stage. Theoretical results are based upon the theory of functional a posteriori error estimates, which allows for the systematic construction of such loss functions for a diverse class of practically relevant partial differential equations. From the numerical side, we demonstrate on a series of elliptic problems that for a variety of architectures and approaches (physics-informed neural networks, physics-informed neural operators, neural operators, and classical architectures in the regression and physics-informed settings), we can reach better or comparable accuracy and in addition to that cheaply recover high-quality upper bounds on the error after training.
<div id='section'>Paperid: <span id='pid'>472, <a href='https://arxiv.org/pdf/2401.07888.pdf' target='_blank'>https://arxiv.org/pdf/2401.07888.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Heinlein, Amanda A. Howard, Damien Beecroft, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.07888">Multifidelity domain decomposition-based physics-informed neural networks and operators for time-dependent problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiscale problems are challenging for neural network-based discretizations of differential equations, such as physics-informed neural networks (PINNs). This can be (partly) attributed to the so-called spectral bias of neural networks. To improve the performance of PINNs for time-dependent problems, a combination of multifidelity stacking PINNs and domain decomposition-based finite basis PINNs is employed. In particular, to learn the high-fidelity part of the multifidelity model, a domain decomposition in time is employed. The performance is investigated for a pendulum and a two-frequency problem as well as the Allen-Cahn equation. It can be observed that the domain decomposition approach clearly improves the PINN and stacking PINN approaches. Finally, it is demonstrated that the FBPINN approach can be extended to multifidelity physics-informed deep operator networks.
<div id='section'>Paperid: <span id='pid'>473, <a href='https://arxiv.org/pdf/2312.14221.pdf' target='_blank'>https://arxiv.org/pdf/2312.14221.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michal K. Grzeszczyk, Tadeusz Satlawa, Angela Lungu, Andrew Swift, Andrew Narracott, Rod Hose, Tomasz Trzcinski, Arkadiusz Sitek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.14221">Noninvasive Estimation of Mean Pulmonary Artery Pressure Using MRI, Computer Models, and Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pulmonary Hypertension (PH) is a severe disease characterized by an elevated pulmonary artery pressure. The gold standard for PH diagnosis is measurement of mean Pulmonary Artery Pressure (mPAP) during an invasive Right Heart Catheterization. In this paper, we investigate noninvasive approach to PH detection utilizing Magnetic Resonance Imaging, Computer Models and Machine Learning. We show using the ablation study, that physics-informed feature engineering based on models of blood circulation increases the performance of Gradient Boosting Decision Trees-based algorithms for classification of PH and regression of values of mPAP. We compare results of regression (with thresholding of estimated mPAP) and classification and demonstrate that metrics achieved in both experiments are comparable. The predicted mPAP values are more informative to the physicians than the probability of PH returned by classification models. They provide the intuitive explanation of the outcome of the machine learning model (clinicians are accustomed to the mPAP metric, contrary to the PH probability).
<div id='section'>Paperid: <span id='pid'>474, <a href='https://arxiv.org/pdf/2311.16632.pdf' target='_blank'>https://arxiv.org/pdf/2311.16632.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Antonio Liguori, Matias Quintana, Chun Fu, Clayton Miller, JÃ©rÃ´me Frisch, Christoph van Treeck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16632">Opening the Black Box: Towards inherently interpretable energy data imputation models using building physics insight</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Missing data are frequently observed by practitioners and researchers in the building energy modeling community. In this regard, advanced data-driven solutions, such as Deep Learning methods, are typically required to reflect the non-linear behavior of these anomalies. As an ongoing research question related to Deep Learning, a model's applicability to limited data settings can be explored by introducing prior knowledge in the network. This same strategy can also lead to more interpretable predictions, hence facilitating the field application of the approach. For that purpose, the aim of this paper is to propose the use of Physics-informed Denoising Autoencoders (PI-DAE) for missing data imputation in commercial buildings. In particular, the presented method enforces physics-inspired soft constraints to the loss function of a Denoising Autoencoder (DAE). In order to quantify the benefits of the physical component, an ablation study between different DAE configurations is conducted. First, three univariate DAEs are optimized separately on indoor air temperature, heating, and cooling data. Then, two multivariate DAEs are derived from the previous configurations. Eventually, a building thermal balance equation is coupled to the last multivariate configuration to obtain PI-DAE. Additionally, two commonly used benchmarks are employed to support the findings. It is shown how introducing physical knowledge in a multivariate Denoising Autoencoder can enhance the inherent model interpretability through the optimized physics-based coefficients. While no significant improvement is observed in terms of reconstruction error with the proposed PI-DAE, its enhanced robustness to varying rates of missing data and the valuable insights derived from the physics-based coefficients create opportunities for wider applications within building systems and the built environment.
<div id='section'>Paperid: <span id='pid'>475, <a href='https://arxiv.org/pdf/2310.11789.pdf' target='_blank'>https://arxiv.org/pdf/2310.11789.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yao Li, Shengzhu Shi, Zhichang Guo, Boying Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11789">Adversarial Training for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks have shown great promise in solving partial differential equations. However, due to insufficient robustness, vanilla PINNs often face challenges when solving complex PDEs, especially those involving multi-scale behaviors or solutions with sharp or oscillatory characteristics. To address these issues, based on the projected gradient descent adversarial attack, we proposed an adversarial training strategy for PINNs termed by AT-PINNs. AT-PINNs enhance the robustness of PINNs by fine-tuning the model with adversarial samples, which can accurately identify model failure locations and drive the model to focus on those regions during training. AT-PINNs can also perform inference with temporal causality by selecting the initial collocation points around temporal initial values. We implement AT-PINNs to the elliptic equation with multi-scale coefficients, Poisson equation with multi-peak solutions, Burgers equation with sharp solutions and the Allen-Cahn equation. The results demonstrate that AT-PINNs can effectively locate and reduce failure regions. Moreover, AT-PINNs are suitable for solving complex PDEs, since locating failure regions through adversarial attacks is independent of the size of failure regions or the complexity of the distribution.
<div id='section'>Paperid: <span id='pid'>476, <a href='https://arxiv.org/pdf/2310.10602.pdf' target='_blank'>https://arxiv.org/pdf/2310.10602.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tariq Alkhalifah, Xinquan Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.10602">Physics-informed neural wavefields with Gabor basis functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, Physics-Informed Neural Networks (PINNs) have gained significant attention for their versatile interpolation capabilities in solving partial differential equations (PDEs). Despite their potential, the training can be computationally demanding, especially for intricate functions like wavefields. This is primarily due to the neural-based (learned) basis functions, biased toward low frequencies, as they are dominated by polynomial calculations, which are not inherently wavefield-friendly. In response, we propose an approach to enhance the efficiency and accuracy of neural network wavefield solutions by modeling them as linear combinations of Gabor basis functions that satisfy the wave equation. Specifically, for the Helmholtz equation, we augment the fully connected neural network model with an adaptable Gabor layer constituting the final hidden layer, employing a weighted summation of these Gabor neurons to compute the predictions (output). These weights/coefficients of the Gabor functions are learned from the previous hidden layers that include nonlinear activation functions. To ensure the Gabor layer's utilization across the model space, we incorporate a smaller auxiliary network to forecast the center of each Gabor function based on input coordinates. Realistic assessments showcase the efficacy of this novel implementation compared to the vanilla PINN, particularly in scenarios involving high-frequencies and realistic models that are often challenging for PINNs.
<div id='section'>Paperid: <span id='pid'>477, <a href='https://arxiv.org/pdf/2308.05843.pdf' target='_blank'>https://arxiv.org/pdf/2308.05843.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinquan Huang, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.05843">GaborPINN: Efficient physics informed neural networks using multiplicative filtered networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The computation of the seismic wavefield by solving the Helmholtz equation is crucial to many practical applications, e.g., full waveform inversion. Physics-informed neural networks (PINNs) provide functional wavefield solutions represented by neural networks (NNs), but their convergence is slow. To address this problem, we propose a modified PINN using multiplicative filtered networks, which embeds some of the known characteristics of the wavefield in training, e.g., frequency, to achieve much faster convergence. Specifically, we use the Gabor basis function due to its proven ability to represent wavefields accurately and refer to the implementation as GaborPINN. Meanwhile, we incorporate prior information on the frequency of the wavefield into the design of the method to mitigate the influence of the discontinuity of the represented wavefield by GaborPINN. The proposed method achieves up to a two-magnitude increase in the speed of convergence as compared with conventional PINNs.
<div id='section'>Paperid: <span id='pid'>478, <a href='https://arxiv.org/pdf/2307.00379.pdf' target='_blank'>https://arxiv.org/pdf/2307.00379.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sokratis J. Anagnostopoulos, Juan Diego Toscano, Nikolaos Stergiopulos, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.00379">Residual-based attention and connection to information bottleneck theory in PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Driven by the need for more efficient and seamless integration of physical models and data, physics-informed neural networks (PINNs) have seen a surge of interest in recent years. However, ensuring the reliability of their convergence and accuracy remains a challenge. In this work, we propose an efficient, gradient-less weighting scheme for PINNs, that accelerates the convergence of dynamic or static systems. This simple yet effective attention mechanism is a function of the evolving cumulative residuals and aims to make the optimizer aware of problematic regions at no extra computational cost or adversarial learning. We illustrate that this general method consistently achieves a relative $L^{2}$ error of the order of $10^{-5}$ using standard optimizers on typical benchmark cases of the literature. Furthermore, by investigating the evolution of weights during training, we identify two distinct learning phases reminiscent of the fitting and diffusion phases proposed by the information bottleneck (IB) theory. Subsequent gradient analysis supports this hypothesis by aligning the transition from high to low signal-to-noise ratio (SNR) with the transition from fitting to diffusion regimes of the adopted weights. This novel correlation between PINNs and IB theory could open future possibilities for understanding the underlying mechanisms behind the training and stability of PINNs and, more broadly, of neural operators.
<div id='section'>Paperid: <span id='pid'>479, <a href='https://arxiv.org/pdf/2305.06432.pdf' target='_blank'>https://arxiv.org/pdf/2305.06432.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoyuan Wang, Yorie Nakahira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.06432">A Generalizable Physics-informed Learning Framework for Risk Probability Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate estimates of long-term risk probabilities and their gradients are critical for many stochastic safe control methods. However, computing such risk probabilities in real-time and in unseen or changing environments is challenging. Monte Carlo (MC) methods cannot accurately evaluate the probabilities and their gradients as an infinitesimal devisor can amplify the sampling noise. In this paper, we develop an efficient method to evaluate the probabilities of long-term risk and their gradients. The proposed method exploits the fact that long-term risk probability satisfies certain partial differential equations (PDEs), which characterize the neighboring relations between the probabilities, to integrate MC methods and physics-informed neural networks. We provide theoretical guarantees of the estimation error given certain choices of training configurations. Numerical results show the proposed method has better sample efficiency, generalizes well to unseen regions, and can adapt to systems with changing parameters. The proposed method can also accurately estimate the gradients of risk probabilities, which enables first- and second-order techniques on risk probabilities to be used for learning and control.
<div id='section'>Paperid: <span id='pid'>480, <a href='https://arxiv.org/pdf/2304.11247.pdf' target='_blank'>https://arxiv.org/pdf/2304.11247.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexandr Sedykh, Maninadh Podapaka, Asel Sagingalieva, Karan Pinto, Markus Pflitsch, Alexey Melnikov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.11247">Hybrid quantum physics-informed neural networks for simulating computational fluid dynamics in complex shapes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Finding the distribution of the velocities and pressures of a fluid by solving the Navier-Stokes equations is a principal task in the chemical, energy, and pharmaceutical industries, as well as in mechanical engineering and the design of pipeline systems. With existing solvers, such as OpenFOAM and Ansys, simulations of fluid dynamics in intricate geometries are computationally expensive and require re-simulation whenever the geometric parameters or the initial and boundary conditions are altered. Physics-informed neural networks are a promising tool for simulating fluid flows in complex geometries, as they can adapt to changes in the geometry and mesh definitions, allowing for generalization across fluid parameters and transfer learning across different shapes. We present a hybrid quantum physics-informed neural network that simulates laminar fluid flows in 3D Y-shaped mixers. Our approach combines the expressive power of a quantum model with the flexibility of a physics-informed neural network, resulting in a 21% higher accuracy compared to a purely classical neural network. Our findings highlight the potential of machine learning approaches, and in particular hybrid quantum physics-informed neural network, for complex shape optimization tasks in computational fluid dynamics. By improving the accuracy of fluid simulations in complex geometries, our research using hybrid quantum models contributes to the development of more efficient and reliable fluid dynamics solvers.
<div id='section'>Paperid: <span id='pid'>481, <a href='https://arxiv.org/pdf/2304.04315.pdf' target='_blank'>https://arxiv.org/pdf/2304.04315.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinquan Huang, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04315">Microseismic source imaging using physics-informed neural networks with hard constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Microseismic source imaging plays a significant role in passive seismic monitoring. However, such a process is prone to failure due to aliasing when dealing with sparsely measured data. Thus, we propose a direct microseismic imaging framework based on physics-informed neural networks (PINNs), which can generate focused source images, even with very sparse recordings. We use the PINNs to represent a multi-frequency wavefield and then apply inverse Fourier transform to extract the source image. To be more specific, we modify the representation of the frequency-domain wavefield to inherently satisfy the boundary conditions (the measured data on the surface) by means of a hard constraint, which helps to avoid the difficulty in balancing the data and PDE losses in PINNs. Furthermore, we propose the causality loss implementation with respect to depth to enhance the convergence of PINNs. The numerical experiments on the Overthrust model show that the method can admit reliable and accurate source imaging for single- or multiple- sources and even in passive monitoring settings. Compared with the time-reversal method, the results of the proposed method are consistent with numerical methods but less noisy. Then, we further apply our method to hydraulic fracturing monitoring field data, and demonstrate that our method can correctly image the source with fewer artifacts.
<div id='section'>Paperid: <span id='pid'>482, <a href='https://arxiv.org/pdf/2304.02811.pdf' target='_blank'>https://arxiv.org/pdf/2304.02811.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoyang Zheng, Yao Huang, Ziyang Huang, Wenrui Hao, Guang Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.02811">HomPINNs: homotopy physics-informed neural networks for solving the inverse problems of nonlinear differential equations with multiple solutions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the complex behavior arising from non-uniqueness, symmetry, and bifurcations in the solution space, solving inverse problems of nonlinear differential equations (DEs) with multiple solutions is a challenging task. To address this, we propose homotopy physics-informed neural networks (HomPINNs), a novel framework that leverages homotopy continuation and neural networks (NNs) to solve inverse problems. The proposed framework begins with the use of NNs to simultaneously approximate unlabeled observations across diverse solutions while adhering to DE constraints. Through homotopy continuation, the proposed method solves the inverse problem by tracing the observations and identifying multiple solutions. The experiments involve testing the performance of the proposed method on one-dimensional DEs and applying it to solve a two-dimensional Gray-Scott simulation. Our findings demonstrate that the proposed method is scalable and adaptable, providing an effective solution for solving DEs with multiple solutions and unknown parameters. Moreover, it has significant potential for various applications in scientific computing, such as modeling complex systems and solving inverse problems in physics, chemistry, biology, etc.
<div id='section'>Paperid: <span id='pid'>483, <a href='https://arxiv.org/pdf/2303.03848.pdf' target='_blank'>https://arxiv.org/pdf/2303.03848.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdul Qadir Ibrahim, Sebastian GÃ¶tschel, Daniel Ruprecht
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.03848">Parareal with a physics-informed neural network as coarse propagator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Parallel-in-time algorithms provide an additional layer of concurrency for the numerical integration of models based on time-dependent differential equations. Methods like Parareal, which parallelize across multiple time steps, rely on a computationally cheap and coarse integrator to propagate information forward in time, while a parallelizable expensive fine propagator provides accuracy. Typically, the coarse method is a numerical integrator using lower resolution, reduced order or a simplified model. Our paper proposes to use a physics-informed neural network (PINN) instead. We demonstrate for the Black-Scholes equation, a partial differential equation from computational finance, that Parareal with a PINN coarse propagator provides better speedup than a numerical coarse propagator. Training and evaluating a neural network are both tasks whose computing patterns are well suited for GPUs. By contrast, mesh-based algorithms with their low computational intensity struggle to perform well. We show that moving the coarse propagator PINN to a GPU while running the numerical fine propagator on the CPU further improves Parareal's single-node performance. This suggests that integrating machine learning techniques into parallel-in-time integration methods and exploiting their differences in computing patterns might offer a way to better utilize heterogeneous architectures.
<div id='section'>Paperid: <span id='pid'>484, <a href='https://arxiv.org/pdf/2303.03478.pdf' target='_blank'>https://arxiv.org/pdf/2303.03478.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rafael Orozco, Mathias Louboutin, Ali Siahkoohi, Gabrio Rizzuti, Tristan van Leeuwen, Felix Herrmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.03478">Amortized Normalizing Flows for Transcranial Ultrasound with Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel approach to transcranial ultrasound computed tomography that utilizes normalizing flows to improve the speed of imaging and provide Bayesian uncertainty quantification. Our method combines physics-informed methods and data-driven methods to accelerate the reconstruction of the final image. We make use of a physics-informed summary statistic to incorporate the known ultrasound physics with the goal of compressing large incoming observations. This compression enables efficient training of the normalizing flow and standardizes the size of the data regardless of imaging configurations. The combinations of these methods results in fast uncertainty-aware image reconstruction that generalizes to a variety of transducer configurations. We evaluate our approach with in silico experiments and demonstrate that it can significantly improve the imaging speed while quantifying uncertainty. We validate the quality of our image reconstructions by comparing against the traditional physics-only method and also verify that our provided uncertainty is calibrated with the error.
<div id='section'>Paperid: <span id='pid'>485, <a href='https://arxiv.org/pdf/2302.13397.pdf' target='_blank'>https://arxiv.org/pdf/2302.13397.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinquan Huang, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.13397">Efficient physics-informed neural networks using hash encoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have attracted a lot of attention in scientific computing as their functional representation of partial differential equation (PDE) solutions offers flexibility and accuracy features. However, their training cost has limited their practical use as a real alternative to classic numerical methods. Thus, we propose to incorporate multi-resolution hash encoding into PINNs to improve the training efficiency, as such encoding offers a locally-aware (at multi resolution) coordinate inputs to the neural network. Borrowed from the neural representation field community (NeRF), we investigate the robustness of calculating the derivatives of such hash encoded neural networks with respect to the input coordinates, which is often needed by the PINN loss terms. We propose to replace the automatic differentiation with finite-difference calculations of the derivatives to address the discontinuous nature of such derivatives. We also share the appropriate ranges for the hash encoding hyperparameters to obtain robust derivatives. We test the proposed method on three problems, including Burgers equation, Helmholtz equation, and Navier-Stokes equation. The proposed method admits about a 10-fold improvement in efficiency over the vanilla PINN implementation.
<div id='section'>Paperid: <span id='pid'>486, <a href='https://arxiv.org/pdf/2302.12235.pdf' target='_blank'>https://arxiv.org/pdf/2302.12235.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Owen Dugan, Peter Y. Lu, Rumen Dangovski, Di Luo, Marin SoljaÄiÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12235">Q-Flow: Generative Modeling for Differential Equations of Open Quantum Dynamics with Normalizing Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Studying the dynamics of open quantum systems can enable breakthroughs both in fundamental physics and applications to quantum engineering and quantum computation. Since the density matrix $Ï$, which is the fundamental description for the dynamics of such systems, is high-dimensional, customized deep generative neural networks have been instrumental in modeling $Ï$. However, the complex-valued nature and normalization constraints of $Ï$, as well as its complicated dynamics, prohibit a seamless connection between open quantum systems and the recent advances in deep generative modeling. Here we lift that limitation by utilizing a reformulation of open quantum system dynamics to a partial differential equation (PDE) for a corresponding probability distribution $Q$, the Husimi Q function. Thus, we model the Q function seamlessly with off-the-shelf deep generative models such as normalizing flows. Additionally, we develop novel methods for learning normalizing flow evolution governed by high-dimensional PDEs based on the Euler method and the application of the time-dependent variational principle. We name the resulting approach $Q$-$Flow$ and demonstrate the scalability and efficiency of Q-Flow on open quantum system simulations, including the dissipative harmonic oscillator and the dissipative bosonic model. Q-Flow is superior to conventional PDE solvers and state-of-the-art physics-informed neural network solvers, especially in high-dimensional systems.
<div id='section'>Paperid: <span id='pid'>487, <a href='https://arxiv.org/pdf/2301.00641.pdf' target='_blank'>https://arxiv.org/pdf/2301.00641.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanzheng Li, Shangyang He, Yang Li, Yang Shi, Zhigang Zeng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.00641">Federated Multi-Agent Deep Reinforcement Learning Approach via Physics-Informed Reward for Multi-Microgrid Energy Management</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The utilization of large-scale distributed renewable energy promotes the development of the multi-microgrid (MMG), which raises the need of developing an effective energy management method to minimize economic costs and keep self energy-sufficiency. The multi-agent deep reinforcement learning (MADRL) has been widely used for the energy management problem because of its real-time scheduling ability. However, its training requires massive energy operation data of microgrids (MGs), while gathering these data from different MGs would threaten their privacy and data security. Therefore, this paper tackles this practical yet challenging issue by proposing a federated multi-agent deep reinforcement learning (F-MADRL) algorithm via the physics-informed reward. In this algorithm, the federated learning (FL) mechanism is introduced to train the F-MADRL algorithm thus ensures the privacy and the security of data. In addition, a decentralized MMG model is built, and the energy of each participated MG is managed by an agent, which aims to minimize economic costs and keep self energy-sufficiency according to the physics-informed reward. At first, MGs individually execute the self-training based on local energy operation data to train their local agent models. Then, these local models are periodically uploaded to a server and their parameters are aggregated to build a global agent, which will be broadcasted to MGs and replace their local agents. In this way, the experience of each MG agent can be shared and the energy operation data is not explicitly transmitted, thus protecting the privacy and ensuring data security. Finally, experiments are conducted on Oak Ridge national laboratory distributed energy control communication lab microgrid (ORNL-MG) test system, and the comparisons are carried out to verify the effectiveness of introducing the FL mechanism and the outperformance of our proposed F-MADRL.
<div id='section'>Paperid: <span id='pid'>488, <a href='https://arxiv.org/pdf/2210.08424.pdf' target='_blank'>https://arxiv.org/pdf/2210.08424.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu-Hau Tseng, Te-Sheng Lin, Wei-Fan Hu, Ming-Chih Lai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.08424">A cusp-capturing PINN for elliptic interface problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a cusp-capturing physics-informed neural network (PINN) to solve discontinuous-coefficient elliptic interface problems whose solution is continuous but has discontinuous first derivatives on the interface. To find such a solution using neural network representation, we introduce a cusp-enforced level set function as an additional feature input to the network to retain the inherent solution properties; that is, capturing the solution cusps (where the derivatives are discontinuous) sharply. In addition, the proposed neural network has the advantage of being mesh-free, so it can easily handle problems in irregular domains. We train the network using the physics-informed framework in which the loss function comprises the residual of the differential equation together with certain interface and boundary conditions. We conduct a series of numerical experiments to demonstrate the effectiveness of the cusp-capturing technique and the accuracy of the present network model. Numerical results show that even using a one-hidden-layer (shallow) network with a moderate number of neurons and sufficient training data points, the present network model can achieve prediction accuracy comparable with traditional methods. Besides, if the solution is discontinuous across the interface, we can simply incorporate an additional supervised learning task for solution jump approximation into the present network without much difficulty.
<div id='section'>Paperid: <span id='pid'>489, <a href='https://arxiv.org/pdf/2204.09157.pdf' target='_blank'>https://arxiv.org/pdf/2204.09157.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda A. Howard, Mauro Perego, George E. Karniadakis, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.09157">Multifidelity Deep Operator Networks For Data-Driven and Physics-Informed Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Operator learning for complex nonlinear systems is increasingly common in modeling multi-physics and multi-scale systems. However, training such high-dimensional operators requires a large amount of expensive, high-fidelity data, either from experiments or simulations. In this work, we present a composite Deep Operator Network (DeepONet) for learning using two datasets with different levels of fidelity to accurately learn complex operators when sufficient high-fidelity data is not available. Additionally, we demonstrate that the presence of low-fidelity data can improve the predictions of physics-informed learning with DeepONets. We demonstrate the new multi-fidelity training in diverse examples, including modeling of the ice-sheet dynamics of the Humboldt glacier, Greenland, using two different fidelity models and also using the same physical model at two different resolutions.
<div id='section'>Paperid: <span id='pid'>490, <a href='https://arxiv.org/pdf/2203.01581.pdf' target='_blank'>https://arxiv.org/pdf/2203.01581.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei-Fan Hu, Yi-Jun Shih, Te-Sheng Lin, Ming-Chih Lai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.01581">A shallow physics-informed neural network for solving partial differential equations on surfaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce a shallow (one-hidden-layer) physics-informed neural network for solving partial differential equations on static and evolving surfaces. For the static surface case, with the aid of level set function, the surface normal and mean curvature used in the surface differential expressions can be computed easily. So instead of imposing the normal extension constraints used in literature, we write the surface differential operators in the form of traditional Cartesian differential operators and use them in the loss function directly. We perform a series of performance study for the present methodology by solving Laplace-Beltrami equation and surface diffusion equation on complex static surfaces. With just a moderate number of neurons used in the hidden layer, we are able to attain satisfactory prediction results. Then we extend the present methodology to solve the advection-diffusion equation on an evolving surface with given velocity. To track the surface, we additionally introduce a prescribed hidden layer to enforce the topological structure of the surface and use the network to learn the homeomorphism between the surface and the prescribed topology. The proposed network structure is designed to track the surface and solve the equation simultaneously. Again, the numerical results show comparable accuracy as the static cases. As an application, we simulate the surfactant transport on the droplet surface under shear flow and obtain some physically plausible results.
<div id='section'>Paperid: <span id='pid'>491, <a href='https://arxiv.org/pdf/2510.06776.pdf' target='_blank'>https://arxiv.org/pdf/2510.06776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Phillip Rothenbeck, Sai Karthikeya Vemuri, Niklas Penzel, Joachim Denzler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06776">Modeling COVID-19 Dynamics in German States Using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The COVID-19 pandemic has highlighted the need for quantitative modeling and analysis to understand real-world disease dynamics. In particular, post hoc analyses using compartmental models offer valuable insights into the effectiveness of public health interventions, such as vaccination strategies and containment policies. However, such compartmental models like SIR (Susceptible-Infectious-Recovered) often face limitations in directly incorporating noisy observational data. In this work, we employ Physics-Informed Neural Networks (PINNs) to solve the inverse problem of the SIR model using infection data from the Robert Koch Institute (RKI). Our main contribution is a fine-grained, spatio-temporal analysis of COVID-19 dynamics across all German federal states over a three-year period. We estimate state-specific transmission and recovery parameters and time-varying reproduction number (R_t) to track the pandemic progression. The results highlight strong variations in transmission behavior across regions, revealing correlations with vaccination uptake and temporal patterns associated with major pandemic phases. Our findings demonstrate the utility of PINNs in localized, long-term epidemiological modeling.
<div id='section'>Paperid: <span id='pid'>492, <a href='https://arxiv.org/pdf/2510.06635.pdf' target='_blank'>https://arxiv.org/pdf/2510.06635.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunpeng Gong, Sihan Lan, Can Yang, Kunpeng Xu, Min Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06635">StruSR: Structure-Aware Symbolic Regression with Physics-Informed Taylor Guidance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Symbolic regression aims to find interpretable analytical expressions by searching over mathematical formula spaces to capture underlying system behavior, particularly in scientific modeling governed by physical laws. However, traditional methods lack mechanisms for extracting structured physical priors from time series observations, making it difficult to capture symbolic expressions that reflect the system's global behavior. In this work, we propose a structure-aware symbolic regression framework, called StruSR, that leverages trained Physics-Informed Neural Networks (PINNs) to extract locally structured physical priors from time series data. By performing local Taylor expansions on the outputs of the trained PINN, we obtain derivative-based structural information to guide symbolic expression evolution. To assess the importance of expression components, we introduce a masking-based attribution mechanism that quantifies each subtree's contribution to structural alignment and physical residual reduction. These sensitivity scores steer mutation and crossover operations within genetic programming, preserving substructures with high physical or structural significance while selectively modifying less informative components. A hybrid fitness function jointly minimizes physics residuals and Taylor coefficient mismatch, ensuring consistency with both the governing equations and the local analytical behavior encoded by the PINN. Experiments on benchmark PDE systems demonstrate that StruSR improves convergence speed, structural fidelity, and expression interpretability compared to conventional baselines, offering a principled paradigm for physics-grounded symbolic discovery.
<div id='section'>Paperid: <span id='pid'>493, <a href='https://arxiv.org/pdf/2509.06782.pdf' target='_blank'>https://arxiv.org/pdf/2509.06782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vittorio Giammarino, Ruiqi Ni, Ahmed H. Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06782">Physics-informed Value Learner for Offline Goal-Conditioned Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline Goal-Conditioned Reinforcement Learning (GCRL) holds great promise for domains such as autonomous navigation and locomotion, where collecting interactive data is costly and unsafe. However, it remains challenging in practice due to the need to learn from datasets with limited coverage of the state-action space and to generalize across long-horizon tasks. To improve on these challenges, we propose a Physics-informed (Pi) regularized loss for value learning, derived from the Eikonal Partial Differential Equation (PDE) and which induces a geometric inductive bias in the learned value function. Unlike generic gradient penalties that are primarily used to stabilize training, our formulation is grounded in continuous-time optimal control and encourages value functions to align with cost-to-go structures. The proposed regularizer is broadly compatible with temporal-difference-based value learning and can be integrated into existing Offline GCRL algorithms. When combined with Hierarchical Implicit Q-Learning (HIQL), the resulting method, Physics-informed HIQL (Pi-HIQL), yields significant improvements in both performance and generalization, with pronounced gains in stitching regimes and large-scale navigation tasks.
<div id='section'>Paperid: <span id='pid'>494, <a href='https://arxiv.org/pdf/2509.06782.pdf' target='_blank'>https://arxiv.org/pdf/2509.06782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vittorio Giammarino, Ruiqi Ni, Ahmed H. Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06782">Physics-informed Value Learner for Offline Goal-Conditioned Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Offline Goal-Conditioned Reinforcement Learning (GCRL) holds great promise for domains such as autonomous navigation and locomotion, where collecting interactive data is costly and unsafe. However, it remains challenging in practice due to the need to learn from datasets with limited coverage of the state-action space and to generalize across long-horizon tasks. To improve on these challenges, we propose a \emph{Physics-informed (Pi)} regularized loss for value learning, derived from the Eikonal Partial Differential Equation (PDE) and which induces a geometric inductive bias in the learned value function. Unlike generic gradient penalties that are primarily used to stabilize training, our formulation is grounded in continuous-time optimal control and encourages value functions to align with cost-to-go structures. The proposed regularizer is broadly compatible with temporal-difference-based value learning and can be integrated into existing Offline GCRL algorithms. When combined with Hierarchical Implicit Q-Learning (HIQL), the resulting method, Eikonal-regularized HIQL (Eik-HIQL), yields significant improvements in both performance and generalization, with pronounced gains in stitching regimes and large-scale navigation tasks.
<div id='section'>Paperid: <span id='pid'>495, <a href='https://arxiv.org/pdf/2509.00936.pdf' target='_blank'>https://arxiv.org/pdf/2509.00936.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kishor Datta Gupta, Md Manjurul Ahsan, Mohd Ariful Haque, Roy George, Azmine Toushik Wasi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.00936">UrbanInsight: A Distributed Edge Computing Framework with LLM-Powered Data Filtering for Smart City Digital Twins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cities today generate enormous streams of data from sensors, cameras, and connected infrastructure. While this information offers unprecedented opportunities to improve urban life, most existing systems struggle with scale, latency, and fragmented insights. This work introduces a framework that blends physics-informed machine learning, multimodal data fusion, and knowledge graph representation with adaptive, rule-based intelligence powered by large language models (LLMs). Physics-informed methods ground learning in real-world constraints, ensuring predictions remain meaningful and consistent with physical dynamics. Knowledge graphs act as the semantic backbone, integrating heterogeneous sensor data into a connected, queryable structure. At the edge, LLMs generate context-aware rules that adapt filtering and decision-making in real time, enabling efficient operation even under constrained resources. Together, these elements form a foundation for digital twin systems that go beyond passive monitoring to provide actionable insights. By uniting physics-based reasoning, semantic data fusion, and adaptive rule generation, this approach opens new possibilities for creating responsive, trustworthy, and sustainable smart infrastructures.
<div id='section'>Paperid: <span id='pid'>496, <a href='https://arxiv.org/pdf/2508.19052.pdf' target='_blank'>https://arxiv.org/pdf/2508.19052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Garnier, Jonathan Viquerat, Elie Hachem
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19052">Automated discovery of finite volume schemes using Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks (GNNs) have deeply modified the landscape of numerical simulations by demonstrating strong capabilities in approximating solutions of physical systems. However, their ability to extrapolate beyond their training domain (\textit{e.g.} larger or structurally different graphs) remains uncertain. In this work, we establish that GNNs can serve purposes beyond their traditional role, and be exploited to generate numerical schemes, in conjunction with symbolic regression. First, we show numerically and theoretically that a GNN trained on a dataset consisting solely of two-node graphs can extrapolate a first-order Finite Volume (FV) scheme for the heat equation on out-of-distribution, unstructured meshes. Specifically, if a GNN achieves a loss $\varepsilon$ on such a dataset, it implements the FV scheme with an error of $\mathcal{O}(\varepsilon)$. Using symbolic regression, we show that the network effectively rediscovers the exact analytical formulation of the standard first-order FV scheme. We then extend this approach to an unsupervised context: the GNN recovers the first-order FV scheme using only a residual loss similar to Physics-Informed Neural Networks (PINNs) with no access to ground-truth data. Finally, we push the methodology further by considering higher-order schemes: we train (i) a 2-hop and (ii) a 2-layers GNN using the same PINN loss, that autonomously discover (i) a second-order correction term to the initial scheme using a 2-hop stencil, and (ii) the classic second-order midpoint scheme. These findings follows a recent paradigm in scientific computing: GNNs are not only strong approximators, but can be active contributors to the development of novel numerical methods.
<div id='section'>Paperid: <span id='pid'>497, <a href='https://arxiv.org/pdf/2508.08947.pdf' target='_blank'>https://arxiv.org/pdf/2508.08947.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyu Su, Majid Sarvi, Feng Liu, Egemen Tanin, Jianzhong Qi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.08947">Generalising Traffic Forecasting to Regions without Traffic Observations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traffic forecasting is essential for intelligent transportation systems. Accurate forecasting relies on continuous observations collected by traffic sensors. However, due to high deployment and maintenance costs, not all regions are equipped with such sensors. This paper aims to forecast for regions without traffic sensors, where the lack of historical traffic observations challenges the generalisability of existing models. We propose a model named GenCast, the core idea of which is to exploit external knowledge to compensate for the missing observations and to enhance generalisation. We integrate physics-informed neural networks into GenCast, enabling physical principles to regularise the learning process. We introduce an external signal learning module to explore correlations between traffic states and external signals such as weather conditions, further improving model generalisability. Additionally, we design a spatial grouping module to filter localised features that hinder model generalisability. Extensive experiments show that GenCast consistently reduces forecasting errors on multiple real-world datasets.
<div id='section'>Paperid: <span id='pid'>498, <a href='https://arxiv.org/pdf/2508.02976.pdf' target='_blank'>https://arxiv.org/pdf/2508.02976.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanwen Ren, Ruiqi Ni, Ahmed H. Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02976">Physics-informed Neural Time Fields for Prehensile Object Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Object manipulation skills are necessary for robots operating in various daily-life scenarios, ranging from warehouses to hospitals. They allow the robots to manipulate the given object to their desired arrangement in the cluttered environment. The existing approaches to solving object manipulations are either inefficient sampling based techniques, require expert demonstrations, or learn by trial and error, making them less ideal for practical scenarios. In this paper, we propose a novel, multimodal physics-informed neural network (PINN) for solving object manipulation tasks. Our approach efficiently learns to solve the Eikonal equation without expert data and finds object manipulation trajectories fast in complex, cluttered environments. Our method is multimodal as it also reactively replans the robot's grasps during manipulation to achieve the desired object poses. We demonstrate our approach in both simulation and real-world scenarios and compare it against state-of-the-art baseline methods. The results indicate that our approach is effective across various objects, has efficient training compared to previous learning-based methods, and demonstrates high performance in planning time, trajectory length, and success rates. Our demonstration videos can be found at https://youtu.be/FaQLkTV9knI.
<div id='section'>Paperid: <span id='pid'>499, <a href='https://arxiv.org/pdf/2507.16008.pdf' target='_blank'>https://arxiv.org/pdf/2507.16008.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dmitry Bylinkin, Mikhail Aleksandrov, Savelii Chezhegov, Aleksandr Beznosikov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16008">Enhancing Stability of Physics-Informed Neural Network Training Through Saddle-Point Reformulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have gained prominence in recent years and are now effectively used in a number of applications. However, their performance remains unstable due to the complex landscape of the loss function. To address this issue, we reformulate PINN training as a nonconvex-strongly concave saddle-point problem. After establishing the theoretical foundation for this approach, we conduct an extensive experimental study, evaluating its effectiveness across various tasks and architectures. Our results demonstrate that the proposed method outperforms the current state-of-the-art techniques.
<div id='section'>Paperid: <span id='pid'>500, <a href='https://arxiv.org/pdf/2507.16008.pdf' target='_blank'>https://arxiv.org/pdf/2507.16008.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dmitry Bylinkin, Mikhail Aleksandrov, Savelii Chezhegov, Aleksandr Beznosikov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16008">Enhancing Stability of Physics-Informed Neural Network Training Through Saddle-Point Reformulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have gained prominence in recent years and are now effectively used in a number of applications. However, their performance remains unstable due to the complex landscape of the loss function. To address this issue, we reformulate PINN training as a nonconvex-strongly concave saddle-point problem. After establishing the theoretical foundation for this approach, we conduct an extensive experimental study, evaluating its effectiveness across various tasks and architectures. Our results demonstrate that the proposed method outperforms the current state-of-the-art techniques.
<div id='section'>Paperid: <span id='pid'>501, <a href='https://arxiv.org/pdf/2507.09968.pdf' target='_blank'>https://arxiv.org/pdf/2507.09968.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangyu Sun, Amin Yousefpour, Shirin Hosseinmardi, Ramin Bostanabad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09968">Compliance Minimization via Physics-Informed Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) techniques have recently gained significant attention for solving compliance minimization (CM) problems. However, these methods typically provide poor feature boundaries, are very expensive, and lack a systematic mechanism to control the design complexity. Herein, we address these limitations by proposing a mesh-free and simultaneous framework based on physics-informed Gaussian processes (GPs). In our approach, we parameterize the design and state variables with GP priors which have independent kernels but share a multi-output neural network (NN) as their mean function. The architecture of this NN is based on Parametric Grid Convolutional Attention Networks (PGCANs) which not only mitigate spectral bias issues, but also provide an interpretable mechanism to control design complexity. We estimate all the parameters of our GP-based representations by simultaneously minimizing the compliance, total potential energy, and residual of volume fraction constraint. Importantly, our loss function exclude all data-based residuals as GPs automatically satisfy them. We also develop computational schemes based on curriculum training and numerical integration to increase the efficiency and robustness of our approach which is shown to (1) produce super-resolution topologies with fast convergence, (2) achieve smaller compliance and less gray area fraction compared to traditional numerical methods, (3) provide control over fine-scale features, and (4) outperform competing ML-based methods.
<div id='section'>Paperid: <span id='pid'>502, <a href='https://arxiv.org/pdf/2506.21499.pdf' target='_blank'>https://arxiv.org/pdf/2506.21499.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hojat Asgariandehkordi, Mostafa Sharifzadeh, Hassan Rivaz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.21499">Lightweight Physics-Informed Zero-Shot Ultrasound Plane Wave Denoising</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ultrasound Coherent Plane Wave Compounding (CPWC) enhances image contrast by combining echoes from multiple steered transmissions. While increasing the number of angles generally improves image quality, it drastically reduces the frame rate and can introduce blurring artifacts in fast-moving targets. Moreover, compounded images remain susceptible to noise, particularly when acquired with a limited number of transmissions. We propose a zero-shot denoising framework tailored for low-angle CPWC acquisitions, which enhances contrast without relying on a separate training dataset. The method divides the available transmission angles into two disjoint subsets, each used to form compound images that include higher noise levels. The new compounded images are then used to train a deep model via a self-supervised residual learning scheme, enabling it to suppress incoherent noise while preserving anatomical structures. Because angle-dependent artifacts vary between the subsets while the underlying tissue response is similar, this physics-informed pairing allows the network to learn to disentangle the inconsistent artifacts from the consistent tissue signal. Unlike supervised methods, our model requires no domain-specific fine-tuning or paired data, making it adaptable across anatomical regions and acquisition setups. The entire pipeline supports efficient training with low computational cost due to the use of a lightweight architecture, which comprises only two convolutional layers. Evaluations on simulation, phantom, and in vivo data demonstrate superior contrast enhancement and structure preservation compared to both classical and deep learning-based denoising methods.
<div id='section'>Paperid: <span id='pid'>503, <a href='https://arxiv.org/pdf/2506.13950.pdf' target='_blank'>https://arxiv.org/pdf/2506.13950.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dimitrios G. Patsatzis, Nikolaos Kazantzis, Ioannis G. Kevrekidis, Constantinos Siettos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13950">A Hybrid Neural Network -- Polynomial Series Scheme for Learning Invariant Manifolds of Discrete Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a hybrid machine learning scheme to learn -- in physics-informed and numerical analysis-informed fashion -- invariant manifolds (IM) of discrete maps for constructing reduced-order models (ROMs) for dynamical systems. The proposed scheme combines polynomial series with shallow neural networks, exploiting the complementary strengths of both approaches. Polynomials enable an efficient and accurate modeling of ROMs with guaranteed local exponential convergence rate around the fixed point, where, under certain assumptions, the IM is demonstrated to be analytic. Neural networks provide approximations to more complex structures beyond the reach of the polynomials' convergence. We evaluate the efficiency of the proposed scheme using three benchmark examples, examining convergence behavior, numerical approximation accuracy, and computational training cost. Additionally, we compare the IM approximations obtained solely with neural networks and with polynomial expansions. We demonstrate that the proposed hybrid scheme outperforms both pure polynomial approximations (power series, Legendre and Chebyshev polynomials) and standalone shallow neural network approximations in terms of numerical approximation accuracy.
<div id='section'>Paperid: <span id='pid'>504, <a href='https://arxiv.org/pdf/2506.12742.pdf' target='_blank'>https://arxiv.org/pdf/2506.12742.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuchen Liu, Alexiy Buynitsky, Ruiqi Ni, Ahmed H. Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.12742">Physics-informed Neural Motion Planning via Domain Decomposition in Large Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Neural Motion Planners (PiNMPs) provide a data-efficient framework for solving the Eikonal Partial Differential Equation (PDE) and representing the cost-to-go function for motion planning. However, their scalability remains limited by spectral bias and the complex loss landscape of PDE-driven training. Domain decomposition mitigates these issues by dividing the environment into smaller subdomains, but existing methods enforce continuity only at individual spatial points. While effective for function approximation, these methods fail to capture the spatial connectivity required for motion planning, where the cost-to-go function depends on both the start and goal coordinates rather than a single query point. We propose Finite Basis Neural Time Fields (FB-NTFields), a novel neural field representation for scalable cost-to-go estimation. Instead of enforcing continuity in output space, FB-NTFields construct a latent space representation, computing the cost-to-go as a distance between the latent embeddings of start and goal coordinates. This enables global spatial coherence while integrating domain decomposition, ensuring efficient large-scale motion planning. We validate FB-NTFields in complex synthetic and real-world scenarios, demonstrating substantial improvements over existing PiNMPs. Finally, we deploy our method on a Unitree B1 quadruped robot, successfully navigating indoor environments. The supplementary videos can be found at https://youtu.be/OpRuCbLNOwM.
<div id='section'>Paperid: <span id='pid'>505, <a href='https://arxiv.org/pdf/2506.11973.pdf' target='_blank'>https://arxiv.org/pdf/2506.11973.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ankit Bhardwaj, Rohail Asim, Sachin Chauhan, Yasir Zaki, Lakshminarayanan Subramanian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.11973">Self-Regulating Cars: Automating Traffic Control in Free Flow Road Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Free-flow road networks, such as suburban highways, are increasingly experiencing traffic congestion due to growing commuter inflow and limited infrastructure. Traditional control mechanisms, such as traffic signals or local heuristics, are ineffective or infeasible in these high-speed, signal-free environments. We introduce self-regulating cars, a reinforcement learning-based traffic control protocol that dynamically modulates vehicle speeds to optimize throughput and prevent congestion, without requiring new physical infrastructure. Our approach integrates classical traffic flow theory, gap acceptance models, and microscopic simulation into a physics-informed RL framework. By abstracting roads into super-segments, the agent captures emergent flow dynamics and learns robust speed modulation policies from instantaneous traffic observations. Evaluated in the high-fidelity PTV Vissim simulator on a real-world highway network, our method improves total throughput by 5%, reduces average delay by 13%, and decreases total stops by 3% compared to the no-control setting. It also achieves smoother, congestion-resistant flow while generalizing across varied traffic patterns, demonstrating its potential for scalable, ML-driven traffic management.
<div id='section'>Paperid: <span id='pid'>506, <a href='https://arxiv.org/pdf/2506.02792.pdf' target='_blank'>https://arxiv.org/pdf/2506.02792.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ayesha Afzal, Georg Hager, Gerhard Wellen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02792">Exploring metrics for analyzing dynamic behavior in MPI programs via a coupled-oscillator model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel, lightweight, and physically inspired approach to modeling the dynamics of parallel distributed-memory programs. Inspired by the Kuramoto model, we represent MPI processes as coupled oscillators with topology-aware interactions, custom coupling potentials, and stochastic noise. The resulting system of nonlinear ordinary differential equations opens a path to modeling key performance phenomena of parallel programs, including synchronization, delay propagation and decay, bottlenecks, and self-desynchronization.
  This paper introduces interaction potentials to describe memory- and compute-bound workloads and employs multiple quantitative metrics -- such as an order parameter, synchronization entropy, phase gradients, and phase differences -- to evaluate phase coherence and disruption. We also investigate the role of local noise and show that moderate noise can accelerate resynchronization in scalable applications. Our simulations align qualitatively with MPI trace data, showing the potential of physics-informed abstractions to predict performance patterns, which offers a new perspective for performance modeling and software-hardware co-design in parallel computing.
<div id='section'>Paperid: <span id='pid'>507, <a href='https://arxiv.org/pdf/2505.19566.pdf' target='_blank'>https://arxiv.org/pdf/2505.19566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Panos Pantidis, Lampros Svolos, Diab Abueidda, Mostafa E. Mobasher
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19566">Integrated Finite Element Neural Network (IFENN) for Phase-Field Fracture with Minimal Input and Generalized Geometry-Load Handling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel formulation for modeling phase-field fracture propagation based on the Integrated Finite Element Neural Network (IFENN) framework. IFENN is a hybrid solver scheme that utilizes neural networks as PDE solvers within FEM, preserving accuracy via residual minimization while achieving speed-up via swift network predictions and reduction of the size of system of equations in coupled problems. In this work, we introduce a radically new formulation of IFENN in which the phase-field variable is calculated using physics-informed convolutional networks (PICNNs), while the equilibrium equation is still solved using FEM to maintain the solver robustness. Unlike conventional approaches, which rely on sequence or time-dependent models, we eliminate the need to include temporal features in the training setup and inference stage. Instead, we show that it is sufficient to learn only the spatial coupling between the strain energy density and the phase-field variable in the vicinity of the fracture process zone, and utilize this information along the advancing crack simulation. We train a single CNN in a purely physics-based, unsupervised manner on just two load increments from a single-notch tension problem, with a total training time of only 5 minutes. Following this exceptionally minimal and fast training, we show that the same PICNN can (when embedded within IFENN) model crack propagation in a very wide range of unseen scenarios, including arbitrarily rectangular domains, single and multiple interacting cracks, varying mesh densities, and arbitrary loading paths. The proposed formulation delivers breakthroughs that address many of the limitations in the existing literature of hybrid modeling, introducing a new paradigm for the development of generalizable, physics-consistent hybrid models that are applicable to fracture and other coupled problems.
<div id='section'>Paperid: <span id='pid'>508, <a href='https://arxiv.org/pdf/2505.03382.pdf' target='_blank'>https://arxiv.org/pdf/2505.03382.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthias HÃ¶fler, Francesco Regazzoni, Stefano Pagani, Elias Karabelas, Christoph Augustin, Gundolf Haase, Gernot Plank, Federica Caforio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03382">Physics-informed neural network estimation of active material properties in time-dependent cardiac biomechanical models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active stress models in cardiac biomechanics account for the mechanical deformation caused by muscle activity, thus providing a link between the electrophysiological and mechanical properties of the tissue. The accurate assessment of active stress parameters is fundamental for a precise understanding of myocardial function but remains difficult to achieve in a clinical setting, especially when only displacement and strain data from medical imaging modalities are available. This work investigates, through an in-silico study, the application of physics-informed neural networks (PINNs) for inferring active contractility parameters in time-dependent cardiac biomechanical models from these types of imaging data. In particular, by parametrising the sought state and parameter field with two neural networks, respectively, and formulating an energy minimisation problem to search for the optimal network parameters, we are able to reconstruct in various settings active stress fields in the presence of noise and with a high spatial resolution. To this end, we also advance the vanilla PINN learning algorithm with the use of adaptive weighting schemes, ad-hoc regularisation strategies, Fourier features, and suitable network architectures. In addition, we thoroughly analyse the influence of the loss weights in the reconstruction of active stress parameters. Finally, we apply the method to the characterisation of tissue inhomogeneities and detection of fibrotic scars in myocardial tissue. This approach opens a new pathway to significantly improve the diagnosis, treatment planning, and management of heart conditions associated with cardiac fibrosis.
<div id='section'>Paperid: <span id='pid'>509, <a href='https://arxiv.org/pdf/2505.01399.pdf' target='_blank'>https://arxiv.org/pdf/2505.01399.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Noah Trupin, Zixing Wang, Ahmed H. Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.01399">Dynamic Robot Tool Use with Vision Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tool use enhances a robot's task capabilities. Recent advances in vision-language models (VLMs) have equipped robots with sophisticated cognitive capabilities for tool-use applications. However, existing methodologies focus on elementary quasi-static tool manipulations or high-level tool selection while neglecting the critical aspect of task-appropriate tool grasping. To address this limitation, we introduce inverse Tool-Use Planning (iTUP), a novel VLM-driven framework that enables grounded fine-grained planning for versatile robotic tool use. Through an integrated pipeline of VLM-based tool and contact point grounding, position-velocity trajectory planning, and physics-informed grasp generation and selection, iTUP demonstrates versatility across (1) quasi-static and more challenging (2) dynamic and (3) cluster tool-use tasks. To ensure robust planning, our framework integrates stable and safe task-aware grasping by reasoning over semantic affordances and physical constraints. We evaluate iTUP and baselines on a comprehensive range of realistic tool use tasks including precision hammering, object scooping, and cluster sweeping. Experimental results demonstrate that iTUP ensures a thorough grounding of cognition and planning for challenging robot tool use across diverse environments.
<div id='section'>Paperid: <span id='pid'>510, <a href='https://arxiv.org/pdf/2504.19112.pdf' target='_blank'>https://arxiv.org/pdf/2504.19112.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Amir Fallah, Mehdi Monemi, Matti Latva-aho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.19112">Vessel Length Estimation from Magnetic Wake Signature: A Physics-Informed Residual Neural Network Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Marine remote sensing enhances maritime surveillance, environmental monitoring, and naval operations. Vessel length estimation, a key component of this technology, supports effective maritime surveillance by empowering features such as vessel classification. Departing from traditional methods relying on two-dimensional hydrodynamic wakes or computationally intensive satellite imagery, this paper introduces an innovative approach for vessel length estimation that leverages the subtle magnetic wake signatures of vessels, captured through a low-complexity one-dimensional profile from a single airborne magnetic sensor scan. The proposed method centers around our characterized nonlinear integral equations that connect the magnetic wake to the vessel length within a realistic finite-depth marine environment. To solve the derived equations, we initially leverage a deep residual neural network (DRNN). The proposed DRNN-based solution framework is shown to be unable to exactly learn the intricate relationships between parameters when constrained by a limited training-dataset. To overcome this issue, we introduce an innovative approach leveraging a physics-informed residual neural network (PIRNN). This model integrates physical formulations directly into the loss function, leading to improved performance in terms of both accuracy and convergence speed. Considering a sensor scan angle of less than $15^\circ$, which maintains a reasonable margin below Kelvin's limit angle of $19.5^\circ$, we explore the impact of various parameters on the accuracy of the vessel
  length estimation, including sensor scan angle, vessel speed, and sea depth. Numerical simulations demonstrate the superiority of the proposed PIRNN method, achieving mean length estimation errors consistently below 5\% for vessels longer than 100m. For shorter vessels, the errors generally remain under 10\%.
<div id='section'>Paperid: <span id='pid'>511, <a href='https://arxiv.org/pdf/2504.17112.pdf' target='_blank'>https://arxiv.org/pdf/2504.17112.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Margherita Lampani, Sabrina Guastavino, Michele Piana, Federico Benvenuto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.17112">Physics-informed features in supervised machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Supervised machine learning involves approximating an unknown functional relationship from a limited dataset of features and corresponding labels. The classical approach to feature-based machine learning typically relies on applying linear regression to standardized features, without considering their physical meaning. This may limit model explainability, particularly in scientific applications. This study proposes a physics-informed approach to feature-based machine learning that constructs non-linear feature maps informed by physical laws and dimensional analysis. These maps enhance model interpretability and, when physical laws are unknown, allow for the identification of relevant mechanisms through feature ranking. The method aims to improve both predictive performance in regression tasks and classification skill scores by integrating domain knowledge into the learning process, while also enabling the potential discovery of new physical equations within the context of explainable machine learning.
<div id='section'>Paperid: <span id='pid'>512, <a href='https://arxiv.org/pdf/2503.15561.pdf' target='_blank'>https://arxiv.org/pdf/2503.15561.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amin Yousefpour, Shirin Hosseinmardi, Xiangyu Sun, Ramin Bostanabad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15561">Localized Physics-informed Gaussian Processes with Curriculum Training for Topology Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a simultaneous and meshfree topology optimization (TO) framework based on physics-informed Gaussian processes (GPs). Our framework endows all design and state variables via GP priors which have a shared, multi-output mean function that is parametrized via a customized deep neural network (DNN). The parameters of this mean function are estimated by minimizing a multi-component loss function that depends on the performance metric, design constraints, and the residuals on the state equations. Our TO approach yields well-defined material interfaces and has a built-in continuation nature that promotes global optimality. Other unique features of our approach include (1) its customized DNN which, unlike fully connected feed-forward DNNs, has a localized learning capacity that enables capturing intricate topologies and reducing residuals in high gradient fields, (2) its loss function that leverages localized weights to promote solution accuracy around interfaces, and (3) its use of curriculum training to avoid local optimality.To demonstrate the power of our framework, we validate it against commercial TO package COMSOL on three problems involving dissipated power minimization in Stokes flow.
<div id='section'>Paperid: <span id='pid'>513, <a href='https://arxiv.org/pdf/2503.10253.pdf' target='_blank'>https://arxiv.org/pdf/2503.10253.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Han Wan, Qi Wang, Yuan Mi, Hao Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.10253">PIMRL: Physics-Informed Multi-Scale Recurrent Learning for Spatiotemporal Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulation of spatiotemporal systems governed by partial differential equations is widely applied in fields such as biology, chemistry, aerospace dynamics, and meteorology. Traditional numerical methods incur high computational costs due to the requirement of small time steps for accurate predictions. While machine learning has reduced these costs, long-term predictions remain challenged by error accumulation, particularly in scenarios with insufficient data or varying time scales, where stability and accuracy are compromised. Existing methods often neglect the effective utilization of multi-scale data, leading to suboptimal robustness in predictions. To address these issues, we propose a novel multi-scale learning framework, namely, the Physics-Informed Multi-Scale Recurrent Learning (PIMRL), to effectively leverage multi-scale data for spatiotemporal dynamics prediction. The PIMRL framework comprises two modules: the micro-scale module embeds physical knowledge into neural networks via pretraining, and the macro-scale module adopts a data-driven approach to learn the temporal evolution of physics in the latent space. Experimental results demonstrate that the PIMRL framework consistently achieves state-of-the-art performance across five benchmark datasets ranging from one to three dimensions, showing average improvements of over 9\% in both RMSE and MAE evaluation metrics, with maximum enhancements reaching up to 80%.
<div id='section'>Paperid: <span id='pid'>514, <a href='https://arxiv.org/pdf/2502.20858.pdf' target='_blank'>https://arxiv.org/pdf/2502.20858.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaochuan Liu, Xin Cheng, Yuchong Sun, Xiaoxue Wu, Ruihua Song, Hao Sun, Denghao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.20858">EyEar: Learning Audio Synchronized Human Gaze Trajectory Based on Physics-Informed Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Imitating how humans move their gaze in a visual scene is a vital research problem for both visual understanding and psychology, kindling crucial applications such as building alive virtual characters. Previous studies aim to predict gaze trajectories when humans are free-viewing an image, searching for required targets, or looking for clues to answer questions in an image. While these tasks focus on visual-centric scenarios, humans move their gaze also along with audio signal inputs in more common scenarios. To fill this gap, we introduce a new task that predicts human gaze trajectories in a visual scene with synchronized audio inputs and provide a new dataset containing 20k gaze points from 8 subjects. To effectively integrate audio information and simulate the dynamic process of human gaze motion, we propose a novel learning framework called EyEar (Eye moving while Ear listening) based on physics-informed dynamics, which considers three key factors to predict gazes: eye inherent motion tendency, vision salient attraction, and audio semantic attraction. We also propose a probability density score to overcome the high individual variability of gaze trajectories, thereby improving the stabilization of optimization and the reliability of the evaluation. Experimental results show that EyEar outperforms all the baselines in the context of all evaluation metrics, thanks to the proposed components in the learning model.
<div id='section'>Paperid: <span id='pid'>515, <a href='https://arxiv.org/pdf/2502.07230.pdf' target='_blank'>https://arxiv.org/pdf/2502.07230.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyuan Wang, Wenchuan Wu, Chenhui Lin, Qi Wang, Shuwei Xu, Binbin Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07230">Physics-Informed Recurrent Network for State-Space Modeling of Gas Pipeline Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a part of the integrated energy system (IES), gas pipeline networks can provide additional flexibility to power systems through coordinated optimal dispatch. An accurate pipeline network model is critical for the optimal operation and control of IESs. However, inaccuracies or unavailability of accurate pipeline parameters often introduce errors in the state-space models of such networks. This paper proposes a physics-informed recurrent network (PIRN) to identify the state-space model of gas pipelines. It fuses sparse measurement data with fluid-dynamic behavior expressed by partial differential equations. By embedding the physical state-space model within the recurrent network, parameter identification becomes an end-to-end PIRN training task. The model can be realized in PyTorch through modifications to a standard RNN backbone. Case studies demonstrate that our proposed PIRN can accurately estimate gas pipeline models from sparse terminal node measurements, providing robust performance and significantly higher parameter efficiency. Furthermore, the identified state-space model of the pipeline network can be seamlessly integrated into optimization frameworks.
<div id='section'>Paperid: <span id='pid'>516, <a href='https://arxiv.org/pdf/2502.04947.pdf' target='_blank'>https://arxiv.org/pdf/2502.04947.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>HÃ©lÃ¨ne Barucq, Michel Duprez, Florian Faucher, Emmanuel Franck, FrÃ©dÃ©rique Lecourtier, Vanessa Lleras, Victor Michel-Dansac, Nicolas Victorion
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04947">Enriching continuous Lagrange finite element approximation spaces using neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present a preliminary study combining two approaches in the context of solving PDEs: the classical finite element method (FEM) and more recent techniques based on neural networks. Indeed, in recent years, physics-informed neural networks (PINNs) have become particularly interesting for rapidly solving such problems, especially in high dimensions. However, their lack of accuracy is a significant drawback in this context, hence the interest in combining them with FEM, for which error estimators are already known. The complete pipeline proposed here, therefore, consists of modifying classical FEM approximation spaces by taking information from a prior, chosen here as the prediction of a neural network. On the one hand, this combination improves and certifies the prediction of neural networks to obtain a fast and accurate solution. On the other hand, error estimates are proven, showing that such strategies outperform classical ones by a factor that depends only on the quality of the prior. We validate our approach with numerical results obtained for this preliminary work on parametric problems with one- and two-dimensional geometries. They demonstrate that to achieve a fixed error target, a coarser mesh can be used with our enhanced FEM compared to the standard one, leading to reduced computation time, particularly for parametric problems.
<div id='section'>Paperid: <span id='pid'>517, <a href='https://arxiv.org/pdf/2502.02682.pdf' target='_blank'>https://arxiv.org/pdf/2502.02682.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keyan Chen, Yile Li, Da Long, Zhitong Xu, Wei Xing, Jacob Hochhalter, Shandian Zhe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.02682">Pseudo-Physics-Informed Neural Operators: Enhancing Operator Learning from Limited Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural operators have shown great potential in surrogate modeling. However, training a well-performing neural operator typically requires a substantial amount of data, which can pose a major challenge in complex applications. In such scenarios, detailed physical knowledge can be unavailable or difficult to obtain, and collecting extensive data is often prohibitively expensive. To mitigate this challenge, we propose the Pseudo Physics-Informed Neural Operator (PPI-NO) framework. PPI-NO constructs a surrogate physics system for the target system using partial differential equations (PDEs) derived from simple, rudimentary physics principles, such as basic differential operators. This surrogate system is coupled with a neural operator model, using an alternating update and learning process to iteratively enhance the model's predictive power. While the physics derived via PPI-NO may not mirror the ground-truth underlying physical laws -- hence the term ``pseudo physics'' -- this approach significantly improves the accuracy of standard operator learning models in data-scarce scenarios, which is evidenced by extensive evaluations across five benchmark tasks and a fatigue modeling application.
<div id='section'>Paperid: <span id='pid'>518, <a href='https://arxiv.org/pdf/2501.11937.pdf' target='_blank'>https://arxiv.org/pdf/2501.11937.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Xiao, Xinhai Chen, Qingling Wang, Jie Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11937">MeshONet: A Generalizable and Efficient Operator Learning Method for Structured Mesh Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mesh generation plays a crucial role in scientific computing. Traditional mesh generation methods, such as TFI and PDE-based methods, often struggle to achieve a balance between efficiency and mesh quality. To address this challenge, physics-informed intelligent learning methods have recently emerged, significantly improving generation efficiency while maintaining high mesh quality. However, physics-informed methods fail to generalize when applied to previously unseen geometries, as even small changes in the boundary shape necessitate burdensome retraining to adapt to new geometric variations. In this paper, we introduce MeshONet, the first generalizable intelligent learning method for structured mesh generation. The method transforms the mesh generation task into an operator learning problem with multiple input and solution functions. To effectively overcome the multivariable mapping restriction of operator learning methods, we propose a dual-branch, shared-trunk architecture to approximate the mapping between function spaces based on input-output pairs. Experimental results show that MeshONet achieves a speedup of up to four orders of magnitude in generation efficiency over traditional methods. It also enables generalization to different geometries without retraining, greatly enhancing the practicality of intelligent methods.
<div id='section'>Paperid: <span id='pid'>519, <a href='https://arxiv.org/pdf/2501.01000.pdf' target='_blank'>https://arxiv.org/pdf/2501.01000.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>D. Isaiah Harp, Joshua Ott, Dylan M. Asmar, John Alora, Mykel J. Kochenderfer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01000">Physics-informed Gaussian Processes for Safe Envelope Expansion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Flight test analysis often requires predefined test points with arbitrarily tight tolerances, leading to extensive and resource-intensive experimental campaigns. To address this challenge, we propose a novel approach to flight test analysis using Gaussian processes (GPs) with physics-informed mean functions to estimate aerodynamic quantities from arbitrary flight test data, validated using real T-38 aircraft data collected in collaboration with the United States Air Force Test Pilot School. We demonstrate our method by estimating the pitching moment coefficient without requiring predefined or repeated flight test points, significantly reducing the need for extensive experimental campaigns. Our approach incorporates aerodynamic models as priors within the GP framework, enhancing predictive accuracy across diverse flight conditions and providing robust uncertainty quantification. Key contributions include the integration of physics-based priors in a probabilistic model, which allows for precise computation from arbitrary flight test maneuvers, and the demonstration of our method capturing relevant dynamic characteristics such as short-period mode behavior. The proposed framework offers a scalable and generalizable solution for efficient data-driven flight test analysis and is able to accurately predict the short period frequency and damping for the T-38 across several Mach and dynamic pressure profiles.
<div id='section'>Paperid: <span id='pid'>520, <a href='https://arxiv.org/pdf/2411.00143.pdf' target='_blank'>https://arxiv.org/pdf/2411.00143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marco Morik, Ali Hashemi, Klaus-Robert MÃ¼ller, Stefan Haufe, Shinichi Nakajima
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00143">Enhancing Brain Source Reconstruction through Physics-Informed 3D Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reconstructing brain sources is a fundamental challenge in neuroscience, crucial for understanding brain function and dysfunction. Electroencephalography (EEG) signals have a high temporal resolution. However, identifying the correct spatial location of brain sources from these signals remains difficult due to the ill-posed structure of the problem. Traditional methods predominantly rely on manually crafted priors, missing the flexibility of data-driven learning, while recent deep learning approaches focus on end-to-end learning, typically using the physical information of the forward model only for generating training data. We propose the novel hybrid method 3D-PIUNet for EEG source localization that effectively integrates the strengths of traditional and deep learning techniques. 3D-PIUNet starts from an initial physics-informed estimate by using the pseudo inverse to map from measurements to source space. Secondly, by viewing the brain as a 3D volume, we use a 3D convolutional U-Net to capture spatial dependencies and refine the solution according to the learned data prior. Training the model relies on simulated pseudo-realistic brain source data, covering different source distributions. Trained on this data, our model significantly improves spatial accuracy, demonstrating superior performance over both traditional and end-to-end data-driven methods. Additionally, we validate our findings with real EEG data from a visual task, where 3D-PIUNet successfully identifies the visual cortex and reconstructs the expected temporal behavior, thereby showcasing its practical applicability.
<div id='section'>Paperid: <span id='pid'>521, <a href='https://arxiv.org/pdf/2410.15250.pdf' target='_blank'>https://arxiv.org/pdf/2410.15250.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haodong Feng, Peiyan Hu, Yue Wang, Dixia Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15250">Multi-modal Policies with Physics-informed Representations in Complex Fluid Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Control in fluid environments is an important research area with numerous applications across various domains, including underwater robotics, aerospace engineering, and biomedical systems. However, in practice, control methods often face challenges due to sparse or missing observations, stemming from sensor limitations and faults. These issues result in observations that are not only sparse but also inconsistent in their number and modalities (e.g., velocity and pressure sensors). In this work, we propose a Physics-Informed Representation (PIR) algorithm for multi-modal policies of control to leverage the sparse and random observations in complex fluid environments. PIR integrates sparse observational data with the Partial Differential Equation (PDE) information to distill a unified representation of fluid systems. The main idea is that PDE solutions are determined by three elements: the equation, initial conditions, and boundary conditions. Given the equation, we only need to learn the representation of the initial and boundary conditions, which define a trajectory of a specific fluid system. Specifically, it leverages PDE loss to fit the neural network and data loss calculated on the observations with random quantities and multi-modalities to propagate the information with initial and boundary conditions into the representations. The representations are the learnable parameters or the output of the encoder. In the experiments, the PIR illustrates the superior consistency with the features of the ground truth compared with baselines, even when there are missing modalities. Furthermore, PIR combined with Reinforcement Learning has been successfully applied in control tasks where the robot leverages the learned state by PIR faster and more accurately, passing through the complex vortex street from a random starting location to reach a random target.
<div id='section'>Paperid: <span id='pid'>522, <a href='https://arxiv.org/pdf/2410.15089.pdf' target='_blank'>https://arxiv.org/pdf/2410.15089.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shima Baharlouei, Jamie M. Taylor, Carlos Uriarte, David Pardo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15089">A Least-Squares-Based Neural Network (LS-Net) for Solving Linear Parametric PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing efficient methods for solving parametric partial differential equations is crucial for addressing inverse problems. This work introduces a Least-Squares-based Neural Network (LS-Net) method for solving linear parametric PDEs. It utilizes a separated representation form for the parametric PDE solution via a deep neural network and a least-squares solver. In this approach, the output of the deep neural network consists of a vector-valued function, interpreted as basis functions for the parametric solution space, and the least-squares solver determines the optimal solution within the constructed solution space for each given parameter. The LS-Net method requires a quadratic loss function for the least-squares solver to find optimal solutions given the set of basis functions. In this study, we consider loss functions derived from the Deep Fourier Residual and Physics-Informed Neural Networks approaches. We also provide theoretical results similar to the Universal Approximation Theorem, stating that there exists a sufficiently large neural network that can theoretically approximate solutions of parametric PDEs with the desired accuracy. We illustrate the LS-net method by solving one- and two-dimensional problems. Numerical results clearly demonstrate the method's ability to approximate parametric solutions.
<div id='section'>Paperid: <span id='pid'>523, <a href='https://arxiv.org/pdf/2410.04743.pdf' target='_blank'>https://arxiv.org/pdf/2410.04743.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Long Wu, Xunyuan Yin, Lei Pan, Jinfeng Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04743">Smart energy management: process structure-based hybrid neural networks for optimal scheduling and economic predictive control in integrated systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Integrated energy systems (IESs) are complex systems consisting of diverse operating units spanning multiple domains. To address its operational challenges, we propose a physics-informed hybrid time-series neural network (NN) surrogate to predict the dynamic performance of IESs across multiple time scales. This neural network-based modeling approach develops time-series multi-layer perceptrons (MLPs) for the operating units and integrates them with prior process knowledge about system structure and fundamental dynamics. This integration forms three hybrid NNs (long-term, slow, and fast MLPs) that predict the entire system dynamics across multiple time scales. Leveraging these MLPs, we design an NN-based scheduler and an NN-based economic model predictive control (NEMPC) framework to meet global operational requirements: rapid electrical power responsiveness to operators requests, adequate cooling supply to customers, and increased system profitability, while addressing the dynamic time-scale multiplicity present in IESs. The proposed day-ahead scheduler is formulated using the ReLU network-based MLP, which effectively represents IES performance under a broad range of conditions from a long-term perspective. The scheduler is then exactly recast into a mixed-integer linear programming problem for efficient evaluation. The real-time NEMPC, based on slow and fast MLPs, comprises two sequential distributed control agents: a slow NEMPC for the cooling-dominant subsystem with slower transient responses and a fast NEMPC for the power-dominant subsystem with faster responses. Extensive simulations demonstrate that the developed scheduler and NEMPC schemes outperform their respective benchmark scheduler and controller by about 25% and 40%. Together, they enhance overall system performance by over 70% compared to benchmark approaches.
<div id='section'>Paperid: <span id='pid'>524, <a href='https://arxiv.org/pdf/2409.15595.pdf' target='_blank'>https://arxiv.org/pdf/2409.15595.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keke Long, Haotian Shi, Yang Zhou, Xiaopeng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.15595">Physics Enhanced Residual Policy Learning (PERPL) for safety cruising in mixed traffic platooning under actuator and communication delay</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Linear control models have gained extensive application in vehicle control due to their simplicity, ease of use, and support for stability analysis. However, these models lack adaptability to the changing environment and multi-objective settings. Reinforcement learning (RL) models, on the other hand, offer adaptability but suffer from a lack of interpretability and generalization capabilities. This paper aims to develop a family of RL-based controllers enhanced by physics-informed policies, leveraging the advantages of both physics-based models (data-efficient and interpretable) and RL methods (flexible to multiple objectives and fast computing). We propose the Physics-Enhanced Residual Policy Learning (PERPL) framework, where the physics component provides model interpretability and stability. The learning-based Residual Policy adjusts the physics-based policy to adapt to the changing environment, thereby refining the decisions of the physics model. We apply our proposed model to decentralized control to mixed traffic platoon of Connected and Automated Vehicles (CAVs) and Human-driven Vehicles (HVs) using a constant time gap (CTG) strategy for cruising and incorporating actuator and communication delays. Experimental results demonstrate that our method achieves smaller headway errors and better oscillation dampening than linear models and RL alone in scenarios with artificially extreme conditions and real preceding vehicle trajectories. At the macroscopic level, overall traffic oscillations are also reduced as the penetration rate of CAVs employing the PERPL scheme increases.
<div id='section'>Paperid: <span id='pid'>525, <a href='https://arxiv.org/pdf/2408.03653.pdf' target='_blank'>https://arxiv.org/pdf/2408.03653.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingxue Yan, Minghao Han, Adrian Wing-Keung Law, Xunyuan Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.03653">Self-tuning moving horizon estimation of nonlinear systems via physics-informed machine learning Koopman modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a physics-informed learning-based Koopman modeling approach and present a Koopman-based self-tuning moving horizon estimation design for a class of nonlinear systems. Specifically, we train Koopman operators and two neural networks - the state lifting network and the noise characterization network - using both data and available physical information. The two neural networks account for the nonlinear lifting functions for Koopman modeling and describing system noise distributions, respectively. Accordingly, a stochastic linear Koopman model is established in the lifted space to forecast the dynamic behavior of the nonlinear system. Based on the Koopman model, a self-tuning linear moving horizon estimation (MHE) scheme is developed. The weighting matrices of the MHE design are updated using the pre-trained noise characterization network at each sampling instant. The proposed estimation scheme is computationally efficient because only convex optimization is involved during online implementation, and updating the weighting matrices of the MHE scheme does not require re-training the neural networks. We verify the effectiveness and evaluate the performance of the proposed method via the application to a simulated chemical process.
<div id='section'>Paperid: <span id='pid'>526, <a href='https://arxiv.org/pdf/2408.03490.pdf' target='_blank'>https://arxiv.org/pdf/2408.03490.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amin Yousefpour, Shirin Hosseinmardi, Carlos Mora, Ramin Bostanabad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.03490">Simultaneous and Meshfree Topology Optimization with Physics-informed Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Topology optimization (TO) provides a principled mathematical approach for optimizing the performance of a structure by designing its material spatial distribution in a pre-defined domain and subject to a set of constraints. The majority of existing TO approaches leverage numerical solvers for design evaluations during the optimization and hence have a nested nature and rely on discretizing the design variables. Contrary to these approaches, herein we develop a new class of TO methods based on the framework of Gaussian processes (GPs) whose mean functions are parameterized via deep neural networks. Specifically, we place GP priors on all design and state variables to represent them via parameterized continuous functions. These GPs share a deep neural network as their mean function but have as many independent kernels as there are state and design variables. We estimate all the parameters of our model in a single for loop that optimizes a penalized version of the performance metric where the penalty terms correspond to the state equations and design constraints. Attractive features of our approach include $(1)$ having a built-in continuation nature since the performance metric is optimized at the same time that the state equations are solved, and $(2)$ being discretization-invariant and accommodating complex domains and topologies. To test our method against conventional TO approaches implemented in commercial software, we evaluate it on four problems involving the minimization of dissipated power in Stokes flow. The results indicate that our approach does not need filtering techniques, has consistent computational costs, and is highly robust against random initializations and problem setup.
<div id='section'>Paperid: <span id='pid'>527, <a href='https://arxiv.org/pdf/2407.20417.pdf' target='_blank'>https://arxiv.org/pdf/2407.20417.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlos Uriarte, Manuela Bastidas, David Pardo, Jamie M. Taylor, Sergio Rojas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.20417">Optimizing Variational Physics-Informed Neural Networks Using Least Squares</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Variational Physics-Informed Neural Networks often suffer from poor convergence when using stochastic gradient-descent-based optimizers. By introducing a Least Squares solver for the weights of the last layer of the neural network, we improve the convergence of the loss during training in most practical scenarios. This work analyzes the computational cost of the resulting hybrid Least-Squares/Gradient-Descent optimizer and explains how to implement it efficiently. In particular, we show that a traditional implementation based on backward-mode automatic differentiation leads to a prohibitively expensive algorithm. To remedy this, we propose using either forward-mode automatic differentiation or an ultraweak-type scheme that avoids the differentiation of trial functions in the discrete weak formulation. The proposed alternatives are up to one hundred times faster than the traditional one, recovering a computational cost-per-iteration similar to that of a conventional gradient-descent-based optimizer alone. To support our analysis, we derive computational estimates and conduct numerical experiments in one- and two-dimensional problems.
<div id='section'>Paperid: <span id='pid'>528, <a href='https://arxiv.org/pdf/2407.08222.pdf' target='_blank'>https://arxiv.org/pdf/2407.08222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xing Wang, Joel Janek Dabrowski, Josh Pinskier, Lois Liow, Vinoth Viswanathan, Richard Scalzo, David Howard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08222">PINN-Ray: A Physics-Informed Neural Network to Model Soft Robotic Fin Ray Fingers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modelling complex deformation for soft robotics provides a guideline to understand their behaviour, leading to safe interaction with the environment. However, building a surrogate model with high accuracy and fast inference speed can be challenging for soft robotics due to the nonlinearity from complex geometry, large deformation, material nonlinearity etc. The reality gap from surrogate models also prevents their further deployment in the soft robotics domain. In this study, we proposed a physics-informed Neural Networks (PINNs) named PINN-Ray to model complex deformation for a Fin Ray soft robotic gripper, which embeds the minimum potential energy principle from elastic mechanics and additional high-fidelity experimental data into the loss function of neural network for training. This method is significant in terms of its generalisation to complex geometry and robust to data scarcity as compared to other data-driven neural networks. Furthermore, it has been extensively evaluated to model the deformation of the Fin Ray finger under external actuation. PINN-Ray demonstrates improved accuracy as compared with Finite element modelling (FEM) after applying the data assimilation scheme to treat the sim-to-real gap. Additionally, we introduced our automated framework to design, fabricate soft robotic fingers, and characterise their deformation by visual tracking, which provides a guideline for the fast prototype of soft robotics.
<div id='section'>Paperid: <span id='pid'>529, <a href='https://arxiv.org/pdf/2406.11390.pdf' target='_blank'>https://arxiv.org/pdf/2406.11390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdullah Saydemir, Marten Lienen, Stephan GÃ¼nnemann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11390">Unfolding Time: Generative Modeling for Turbulent Flows in 4D</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A recent study in turbulent flow simulation demonstrated the potential of generative diffusion models for fast 3D surrogate modeling. This approach eliminates the need for specifying initial states or performing lengthy simulations, significantly accelerating the process. While adept at sampling individual frames from the learned manifold of turbulent flow states, the previous model lacks the capability to generate sequences, hindering analysis of dynamic phenomena. This work addresses this limitation by introducing a 4D generative diffusion model and a physics-informed guidance technique that enables the generation of realistic sequences of flow states. Our findings indicate that the proposed method can successfully sample entire subsequences from the turbulent manifold, even though generalizing from individual frames to sequences remains a challenging task. This advancement opens doors for the application of generative modeling in analyzing the temporal evolution of turbulent flows, providing valuable insights into their complex dynamics.
<div id='section'>Paperid: <span id='pid'>530, <a href='https://arxiv.org/pdf/2406.10108.pdf' target='_blank'>https://arxiv.org/pdf/2406.10108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junzhe Yin, Cristian Meo, Ankush Roy, Zeineh Bou Cher, Yanbo Wang, Ruben Imhoff, Remko Uijlenhoet, Justin Dauwels
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10108">Precipitation Nowcasting Using Physics Informed Discriminator Generative Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nowcasting leverages real-time atmospheric conditions to forecast weather over short periods. State-of-the-art models, including PySTEPS, encounter difficulties in accurately forecasting extreme weather events because of their unpredictable distribution patterns. In this study, we design a physics-informed neural network to perform precipitation nowcasting using the precipitation and meteorological data from the Royal Netherlands Meteorological Institute (KNMI). This model draws inspiration from the novel Physics-Informed Discriminator GAN (PID-GAN) formulation, directly integrating physics-based supervision within the adversarial learning framework. The proposed model adopts a GAN structure, featuring a Vector Quantization Generative Adversarial Network (VQ-GAN) and a Transformer as the generator, with a temporal discriminator serving as the discriminator. Our findings demonstrate that the PID-GAN model outperforms numerical and SOTA deep generative models in terms of precipitation nowcasting downstream metrics.
<div id='section'>Paperid: <span id='pid'>531, <a href='https://arxiv.org/pdf/2406.06150.pdf' target='_blank'>https://arxiv.org/pdf/2406.06150.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kim A. Nicoli, Christopher J. Anders, Lena Funcke, Tobias Hartung, Karl Jansen, Stefan KÃ¼hn, Klaus-Robert MÃ¼ller, Paolo Stornati, Pan Kessel, Shinichi Nakajima
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.06150">Physics-Informed Bayesian Optimization of Variational Quantum Circuits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a novel and powerful method to harness Bayesian optimization for Variational Quantum Eigensolvers (VQEs) -- a hybrid quantum-classical protocol used to approximate the ground state of a quantum Hamiltonian. Specifically, we derive a VQE-kernel which incorporates important prior information about quantum circuits: the kernel feature map of the VQE-kernel exactly matches the known functional form of the VQE's objective function and thereby significantly reduces the posterior uncertainty. Moreover, we propose a novel acquisition function for Bayesian optimization called Expected Maximum Improvement over Confident Regions (EMICoRe) which can actively exploit the inductive bias of the VQE-kernel by treating regions with low predictive uncertainty as indirectly ``observed''. As a result, observations at as few as three points in the search domain are sufficient to determine the complete objective function along an entire one-dimensional subspace of the optimization landscape. Our numerical experiments demonstrate that our approach improves over state-of-the-art baselines.
<div id='section'>Paperid: <span id='pid'>532, <a href='https://arxiv.org/pdf/2405.14110.pdf' target='_blank'>https://arxiv.org/pdf/2405.14110.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jamie M. Taylor, David Pardo, Judit MuÃ±oz-Matute
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14110">Regularity-Conforming Neural Networks (ReCoNNs) for solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Whilst the Universal Approximation Theorem guarantees the existence of approximations to Sobolev functions -- the natural function spaces for PDEs -- by Neural Networks (NNs) of sufficient size, low-regularity solutions may lead to poor approximations in practice. For example, classical fully-connected feed-forward NNs fail to approximate continuous functions whose gradient is discontinuous when employing strong formulations like in Physics Informed Neural Networks (PINNs). In this article, we propose the use of regularity-conforming neural networks, where a priori information on the regularity of solutions to PDEs can be employed to construct proper architectures. We illustrate the potential of such architectures via a two-dimensional (2D) transmission problem, where the solution may admit discontinuities in the gradient across interfaces, as well as power-like singularities at certain points. In particular, we formulate the weak transmission problem in a PINNs-like strong formulation with interface and continuity conditions. Such architectures are partially explainable; discontinuities are explicitly described, allowing the introduction of novel terms into the loss function. We demonstrate via several model problems in one and two dimensions the advantages of using regularity-conforming architectures in contrast to classical architectures. The ideas presented in this article easily extend to problems in higher dimensions.
<div id='section'>Paperid: <span id='pid'>533, <a href='https://arxiv.org/pdf/2403.14059.pdf' target='_blank'>https://arxiv.org/pdf/2403.14059.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fanfan Lin, Junhua Liu, Xinze Li, Shuai Zhao, Bohui Zhao, Hao Ma, Xin Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14059">PE-GPT: A Physics-Informed Interactive Large Language Model for Power Converter Modulation Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes PE-GPT, a custom-tailored large language model uniquely adapted for power converter modulation design. By harnessing in-context learning and specialized tiered physics-informed neural networks, PE-GPT guides users through text-based dialogues, recommending actionable modulation parameters. The effectiveness of PE-GPT is validated through a practical design case involving dual active bridge converters, supported by hardware experimentation. This research underscores the transformative potential of large language models in power converter modulation design, offering enhanced accessibility, explainability, and efficiency, thereby setting a new paradigm in the field.
<div id='section'>Paperid: <span id='pid'>534, <a href='https://arxiv.org/pdf/2403.05765.pdf' target='_blank'>https://arxiv.org/pdf/2403.05765.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiqi Ni, Ahmed H. Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.05765">Physics-informed Neural Motion Planning on Constraint Manifolds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constrained Motion Planning (CMP) aims to find a collision-free path between the given start and goal configurations on the kinematic constraint manifolds. These problems appear in various scenarios ranging from object manipulation to legged-robot locomotion. However, the zero-volume nature of manifolds makes the CMP problem challenging, and the state-of-the-art methods still take several seconds to find a path and require a computationally expansive path dataset for imitation learning. Recently, physics-informed motion planning methods have emerged that directly solve the Eikonal equation through neural networks for motion planning and do not require expert demonstrations for learning. Inspired by these approaches, we propose the first physics-informed CMP framework that solves the Eikonal equation on the constraint manifolds and trains neural function for CMP without expert data. Our results show that the proposed approach efficiently solves various CMP problems in both simulation and real-world, including object manipulation under orientation constraints and door opening with a high-dimensional 6-DOF robot manipulator. In these complex settings, our method exhibits high success rates and finds paths in sub-seconds, which is many times faster than the state-of-the-art CMP methods.
<div id='section'>Paperid: <span id='pid'>535, <a href='https://arxiv.org/pdf/2402.17992.pdf' target='_blank'>https://arxiv.org/pdf/2402.17992.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>R. Bailey Bond, Pu Ren, Jerome F. Hajjar, Hao Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17992">Physics-Informed Machine Learning for Seismic Response Prediction OF Nonlinear Steel Moment Resisting Frame Structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>There is growing interest in using machine learning (ML) methods for structural metamodeling due to the substantial computational cost of traditional simulations. Purely data-driven strategies often face limitations in model robustness, interpretability, and dependency on extensive data. To address these challenges, this paper introduces a novel physics-informed machine learning (PiML) method that integrates scientific principles and physical laws into deep neural networks to model seismic responses of nonlinear structures. The approach constrains the ML model's solution space within known physical bounds through three main features: dimensionality reduction via combined model order reduction and wavelet analysis, long short-term memory (LSTM) networks, and Newton's second law. Dimensionality reduction addresses structural systems' redundancy and boosts efficiency while extracting essential features through wavelet analysis. LSTM networks capture temporal dependencies for accurate time-series predictions. Manipulating the equation of motion helps learn system nonlinearities and confines solutions within physically interpretable results. These attributes allow for model training with sparse data, enhancing accuracy, interpretability, and robustness. Furthermore, a dataset of archetype steel moment resistant frames under seismic loading, available in the DesignSafe-CI Database [1], is considered for evaluation. The resulting metamodel handles complex data better than existing physics-guided LSTM models and outperforms other non-physics data-driven networks.
<div id='section'>Paperid: <span id='pid'>536, <a href='https://arxiv.org/pdf/2402.05460.pdf' target='_blank'>https://arxiv.org/pdf/2402.05460.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Panos Pantidis, Habiba Eldababy, Diab Abueidda, Mostafa E. Mobasher
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.05460">I-FENN with Temporal Convolutional Networks: expediting the load-history analysis of non-local gradient damage propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we demonstrate for the first time how the Integrated Finite Element Neural Network (I-FENN) framework, previously proposed by the authors, can efficiently simulate the entire loading history of non-local gradient damage propagation. To achieve this goal, we first adopt a Temporal Convolutional Network (TCN) as the neural network of choice to capture the history-dependent evolution of the non-local strain in a coarsely meshed domain. The quality of the network predictions governs the computational performance of I-FENN, and therefore we perform an extended investigation aimed at enhancing them. We explore a data-driven vs. physics-informed TCN setup to arrive at an optimum network training, evaluating the network based on a coherent set of relevant performance metrics. We address the crucial issue of training a physics-informed network with input data that span vastly different length scales by proposing a systematic way of input normalization and output un-normalization. We then integrate the trained TCN within the nonlinear iterative FEM solver and apply I-FENN to simulate the damage propagation analysis. I-FENN is always applied in mesh idealizations different from the one used for the TCN training, showcasing the framework's ability to be used at progressively refined mesh resolutions. We illustrate several cases that I-FENN completes the simulation using either a modified or a full Newton-Raphson scheme, and we showcase its computational savings compared to both the classical monolithic and staggered FEM solvers. We underline that we satisfy very strict convergence criteria for every increment across the entire simulation, providing clear evidence of the robustness and accuracy of I-FENN. All the code and data used in this work will be made publicly available upon publication of the article.
<div id='section'>Paperid: <span id='pid'>537, <a href='https://arxiv.org/pdf/2401.04663.pdf' target='_blank'>https://arxiv.org/pdf/2401.04663.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jamie M. Taylor, Manuela Bastidas, Victor M. Calo, David Pardo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04663">Adaptive Deep Fourier Residual method via overlapping domain decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Deep Fourier Residual (DFR) method is a specific type of variational physics-informed neural networks (VPINNs). It provides a robust neural network-based solution to partial differential equations (PDEs). The DFR strategy is based on approximating the dual norm of the weak residual of a PDE. This is equivalent to minimizing the energy norm of the error. To compute the dual of the weak residual norm, the DFR method employs an orthonormal spectral basis of the test space, which is known for rectangles or cuboids for multiple function spaces.
  In this work, we extend the DFR method with ideas of traditional domain decomposition (DD). This enables two improvements: (a) to solve problems in more general polygonal domains, and (b) to develop an adaptive refinement technique in the test space using a Dofler marking algorithm. In the former case, we show that under non-restrictive assumptions we retain the desirable equivalence between the employed loss function and the H1-error, numerically demonstrating adherence to explicit bounds in the case of the L-shaped domain problem. In the latter, we show how refinement strategies lead to potentially significant improvements against a reference, classical DFR implementation with a test function space of significantly lower dimensionality, allowing us to better approximate singular solutions at a more reasonable computational cost.
<div id='section'>Paperid: <span id='pid'>538, <a href='https://arxiv.org/pdf/2401.03492.pdf' target='_blank'>https://arxiv.org/pdf/2401.03492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlos Mora, Amin Yousefpour, Shirin Hosseinmardi, Ramin Bostanabad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.03492">A Gaussian Process Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning (PIML) has emerged as a promising alternative to conventional numerical methods for solving partial differential equations (PDEs). PIML models are increasingly built via deep neural networks (NNs) whose architecture and training process are designed such that the network satisfies the PDE system. While such PIML models have substantially advanced over the past few years, their performance is still very sensitive to the NN's architecture and loss function. Motivated by this limitation, we introduce kernel-weighted Corrective Residuals (CoRes) to integrate the strengths of kernel methods and deep NNs for solving nonlinear PDE systems. To achieve this integration, we design a modular and robust framework which consistently outperforms competing methods in solving a broad range of benchmark problems. This performance improvement has a theoretical justification and is particularly attractive since we simplify the training process while negligibly increasing the inference costs. Additionally, our studies on solving multiple PDEs indicate that kernel-weighted CoRes considerably decrease the sensitivity of NNs to factors such as random initialization, architecture type, and choice of optimizer. We believe our findings have the potential to spark a renewed interest in leveraging kernel methods for solving PDEs.
<div id='section'>Paperid: <span id='pid'>539, <a href='https://arxiv.org/pdf/2311.08035.pdf' target='_blank'>https://arxiv.org/pdf/2311.08035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vasilis Michalakopoulos, Sotiris Pelekis, Giorgos Kormpakis, Vagelis Karakolis, Spiros Mouzakitis, Dimitris Askounis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.08035">Data-driven building energy efficiency prediction using physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The analytical prediction of building energy performance in residential buildings based on the heat losses of its individual envelope components is a challenging task. It is worth noting that this field is still in its infancy, with relatively limited research conducted in this specific area to date, especially when it comes for data-driven approaches. In this paper we introduce a novel physics-informed neural network model for addressing this problem. Through the employment of unexposed datasets that encompass general building information, audited characteristics, and heating energy consumption, we feed the deep learning model with general building information, while the model's output consists of the structural components and several thermal properties that are in fact the basic elements of an energy performance certificate (EPC). On top of this neural network, a function, based on physics equations, calculates the energy consumption of the building based on heat losses and enhances the loss function of the deep learning model. This methodology is tested on a real case study for 256 buildings located in Riga, Latvia. Our investigation comes up with promising results in terms of prediction accuracy, paving the way for automated, and data-driven energy efficiency performance prediction based on basic properties of the building, contrary to exhaustive energy efficiency audits led by humans, which are the current status quo.
<div id='section'>Paperid: <span id='pid'>540, <a href='https://arxiv.org/pdf/2310.14754.pdf' target='_blank'>https://arxiv.org/pdf/2310.14754.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emmanuel Franck, Victor Michel-Dansac, Laurent Navoret
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.14754">Approximately well-balanced Discontinuous Galerkin methods using bases enriched with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work concerns the enrichment of Discontinuous Galerkin (DG) bases, so that the resulting scheme provides a much better approximation of steady solutions to hyperbolic systems of balance laws. The basis enrichment leverages a prior - an approximation of the steady solution - which we propose to compute using a Physics-Informed Neural Network (PINN). To that end, after presenting the classical DG scheme, we show how to enrich its basis with a prior. Convergence results and error estimates follow, in which we prove that the basis with prior does not change the order of convergence, and that the error constant is improved. To construct the prior, we elect to use parametric PINNs, which we introduce, as well as the algorithms to construct a prior from PINNs. We finally perform several validation experiments on four different hyperbolic balance laws to highlight the properties of the scheme. Namely, we show that the DG scheme with prior is much more accurate on steady solutions than the DG scheme without prior, while retaining the same approximation quality on unsteady solutions.
<div id='section'>Paperid: <span id='pid'>541, <a href='https://arxiv.org/pdf/2309.15139.pdf' target='_blank'>https://arxiv.org/pdf/2309.15139.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Feng Liu, Faguo Wu, Xiao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.15139">PINF: Continuous Normalizing Flows for Physics-Constrained Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The normalization constraint on probability density poses a significant challenge for solving the Fokker-Planck equation. Normalizing Flow, an invertible generative model leverages the change of variables formula to ensure probability density conservation and enable the learning of complex data distributions. In this paper, we introduce Physics-Informed Normalizing Flows (PINF), a novel extension of continuous normalizing flows, incorporating diffusion through the method of characteristics. Our method, which is mesh-free and causality-free, can efficiently solve high dimensional time-dependent and steady-state Fokker-Planck equations.
<div id='section'>Paperid: <span id='pid'>542, <a href='https://arxiv.org/pdf/2308.16316.pdf' target='_blank'>https://arxiv.org/pdf/2308.16316.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tanujit Chakraborty, Ujjwal Reddy K S, Shraddha M. Naik, Madhurima Panja, Bayapureddy Manvitha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16316">Ten Years of Generative Adversarial Nets (GANs): A survey of the state-of-the-art</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since their inception in 2014, Generative Adversarial Networks (GANs) have rapidly emerged as powerful tools for generating realistic and diverse data across various domains, including computer vision and other applied areas. Consisting of a discriminative network and a generative network engaged in a Minimax game, GANs have revolutionized the field of generative modeling. In February 2018, GAN secured the leading spot on the ``Top Ten Global Breakthrough Technologies List'' issued by the Massachusetts Science and Technology Review. Over the years, numerous advancements have been proposed, leading to a rich array of GAN variants, such as conditional GAN, Wasserstein GAN, CycleGAN, and StyleGAN, among many others. This survey aims to provide a general overview of GANs, summarizing the latent architecture, validation metrics, and application areas of the most widely recognized variants. We also delve into recent theoretical developments, exploring the profound connection between the adversarial principle underlying GAN and Jensen-Shannon divergence, while discussing the optimality characteristics of the GAN framework. The efficiency of GAN variants and their model architectures will be evaluated along with training obstacles as well as training solutions. In addition, a detailed discussion will be provided, examining the integration of GANs with newly developed deep learning frameworks such as Transformers, Physics-Informed Neural Networks, Large Language models, and Diffusion models. Finally, we reveal several issues as well as future research outlines in this field.
<div id='section'>Paperid: <span id='pid'>543, <a href='https://arxiv.org/pdf/2308.12312.pdf' target='_blank'>https://arxiv.org/pdf/2308.12312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jai Kumar, David Zarzoso, Virginie Grandgirard, Jan Ebert, Stefan Kesselheim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12312">Physics informed Neural Networks applied to the description of wave-particle resonance in kinetic simulations of fusion plasmas</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Vlasov-Poisson system is employed in its reduced form version (1D1V) as a test bed for the applicability of Physics Informed Neural Network (PINN) to the wave-particle resonance. Two examples are explored: the Landau damping and the bump-on-tail instability. PINN is first tested as a compression method for the solution of the Vlasov-Poisson system and compared to the standard neural networks. Second, the application of PINN to solving the Vlasov-Poisson system is also presented with the special emphasis on the integral part, which motivates the implementation of a PINN variant, called Integrable PINN (I-PINN), based on the automatic-differentiation to solve the partial differential equation and on the automatic-integration to solve the integral equation.
<div id='section'>Paperid: <span id='pid'>544, <a href='https://arxiv.org/pdf/2307.15243.pdf' target='_blank'>https://arxiv.org/pdf/2307.15243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lin Yan, Hanqi Guo, Thomas Peterka, Bei Wang, Jiali Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.15243">TROPHY: A Topologically Robust Physics-Informed Tracking Framework for Tropical Cyclones</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tropical cyclones (TCs) are among the most destructive weather systems. Realistically and efficiently detecting and tracking TCs are critical for assessing their impacts and risks. Recently, a multilevel robustness framework has been introduced to study the critical points of time-varying vector fields. The framework quantifies the robustness of critical points across varying neighborhoods. By relating the multilevel robustness with critical point tracking, the framework has demonstrated its potential in cyclone tracking. An advantage is that it identifies cyclonic features using only 2D wind vector fields, which is encouraging as most tracking algorithms require multiple dynamic and thermodynamic variables at different altitudes. A disadvantage is that the framework does not scale well computationally for datasets containing a large number of cyclones. This paper introduces a topologically robust physics-informed tracking framework (TROPHY) for TC tracking. The main idea is to integrate physical knowledge of TC to drastically improve the computational efficiency of multilevel robustness framework for large-scale climate datasets. First, during preprocessing, we propose a physics-informed feature selection strategy to filter 90% of critical points that are short-lived and have low stability, thus preserving good candidates for TC tracking. Second, during in-processing, we impose constraints during the multilevel robustness computation to focus only on physics-informed neighborhoods of TCs. We apply TROPHY to 30 years of 2D wind fields from reanalysis data in ERA5 and generate a number of TC tracks. In comparison with the observed tracks, we demonstrate that TROPHY can capture TC characteristics that are comparable to and sometimes even better than a well-validated TC tracking algorithm that requires multiple dynamic and thermodynamic scalar fields.
<div id='section'>Paperid: <span id='pid'>545, <a href='https://arxiv.org/pdf/2306.00945.pdf' target='_blank'>https://arxiv.org/pdf/2306.00945.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ben Adcock, Juan M. Cardenas, Nick Dexter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.00945">CS4ML: A general framework for active learning with arbitrary data based on Christoffel functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a general framework for active learning in regression problems. Our framework extends the standard setup by allowing for general types of data, rather than merely pointwise samples of the target function. This generalization covers many cases of practical interest, such as data acquired in transform domains (e.g., Fourier data), vector-valued data (e.g., gradient-augmented data), data acquired along continuous curves, and, multimodal data (i.e., combinations of different types of measurements). Our framework considers random sampling according to a finite number of sampling measures and arbitrary nonlinear approximation spaces (model classes). We introduce the concept of generalized Christoffel functions and show how these can be used to optimize the sampling measures. We prove that this leads to near-optimal sample complexity in various important cases. This paper focuses on applications in scientific computing, where active learning is often desirable, since it is usually expensive to generate data. We demonstrate the efficacy of our framework for gradient-augmented learning with polynomials, Magnetic Resonance Imaging (MRI) using generative models and adaptive sampling for solving PDEs using Physics-Informed Neural Networks (PINNs).
<div id='section'>Paperid: <span id='pid'>546, <a href='https://arxiv.org/pdf/2303.03260.pdf' target='_blank'>https://arxiv.org/pdf/2303.03260.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leon Herrmann, Tim BÃ¼rchner, Felix Dietrich, Stefan Kollmannsberger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.03260">On the Use of Neural Networks for Full Waveform Inversion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks have recently gained attention in solving inverse problems. One prominent methodology are Physics-Informed Neural Networks (PINNs) which can solve both forward and inverse problems. In the paper at hand, full waveform inversion is the considered inverse problem. The performance of PINNs is compared against classical adjoint optimization, focusing on three key aspects: the forward-solver, the neural network Ansatz for the inverse field, and the sensitivity computation for the gradient-based minimization. Starting from PINNs, each of these key aspects is adapted individually until the classical adjoint optimization emerges. It is shown that it is beneficial to use the neural network only for the discretization of the unknown material field, where the neural network produces reconstructions without oscillatory artifacts as typically encountered in classical full waveform inversion approaches. Due to this finding, a hybrid approach is proposed. It exploits both the efficient gradient computation with the continuous adjoint method as well as the neural network Ansatz for the unknown material field. This new hybrid approach outperforms Physics-Informed Neural Networks and the classical adjoint optimization in settings of two and three-dimensional examples.
<div id='section'>Paperid: <span id='pid'>547, <a href='https://arxiv.org/pdf/2303.02063.pdf' target='_blank'>https://arxiv.org/pdf/2303.02063.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuan Di, Rongye Shi, Zhaobin Mo, Yongjie Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02063">Physics-Informed Deep Learning For Traffic State Estimation: A Survey and the Outlook</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For its robust predictive power (compared to pure physics-based models) and sample-efficient training (compared to pure deep learning models), physics-informed deep learning (PIDL), a paradigm hybridizing physics-based models and deep neural networks (DNN), has been booming in science and engineering fields. One key challenge of applying PIDL to various domains and problems lies in the design of a computational graph that integrates physics and DNNs. In other words, how physics are encoded into DNNs and how the physics and data components are represented. In this paper, we provide a variety of architecture designs of PIDL computational graphs and how these structures are customized to traffic state estimation (TSE), a central problem in transportation engineering. When observation data, problem type, and goal vary, we demonstrate potential architectures of PIDL computational graphs and compare these variants using the same real-world dataset.
<div id='section'>Paperid: <span id='pid'>548, <a href='https://arxiv.org/pdf/2302.08796.pdf' target='_blank'>https://arxiv.org/pdf/2302.08796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuai Han, Lukas Stelz, Horst Stoecker, Lingxiao Wang, Kai Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08796">Approaching epidemiological dynamics of COVID-19 with physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A physics-informed neural network (PINN) embedded with the susceptible-infected-removed (SIR) model is devised to understand the temporal evolution dynamics of infectious diseases. Firstly, the effectiveness of this approach is demonstrated on synthetic data as generated from the numerical solution of the susceptible-asymptomatic-infected-recovered-dead (SAIRD) model. Then, the method is applied to COVID-19 data reported for Germany and shows that it can accurately identify and predict virus spread trends. The results indicate that an incomplete physics-informed model can approach more complicated dynamics efficiently. Thus, the present work demonstrates the high potential of using machine learning methods, e.g., PINNs, to study and predict epidemic dynamics in combination with compartmental models.
<div id='section'>Paperid: <span id='pid'>549, <a href='https://arxiv.org/pdf/2302.01538.pdf' target='_blank'>https://arxiv.org/pdf/2302.01538.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizheng Wang, Jia Sun, Timon Rabczuk, Yinghua Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.01538">DCEM: A deep complementary energy method for solid mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, the rapid advancement of deep learning has significantly impacted various fields, particularly in solving partial differential equations (PDEs) in the realm of solid mechanics, benefiting greatly from the remarkable approximation capabilities of neural networks. In solving PDEs, Physics-Informed Neural Networks (PINNs) and the Deep Energy Method (DEM) have garnered substantial attention. The principle of minimum potential energy and complementary energy are two important variational principles in solid mechanics. However, the well-known Deep Energy Method (DEM) is based on the principle of minimum potential energy, but there lacks the important form of minimum complementary energy. To bridge this gap, we propose the deep complementary energy method (DCEM) based on the principle of minimum complementary energy. The output function of DCEM is the stress function, which inherently satisfies the equilibrium equation. We present numerical results using the Prandtl and Airy stress functions, and compare DCEM with existing PINNs and DEM algorithms when modeling representative mechanical problems. The results demonstrate that DCEM outperforms DEM in terms of stress accuracy and efficiency and has an advantage in dealing with complex displacement boundary conditions, which is supported by theoretical analyses and numerical simulations. We extend DCEM to DCEM-Plus (DCEM-P), adding terms that satisfy partial differential equations. Furthermore, we propose a deep complementary energy operator method (DCEM-O) by combining operator learning with physical equations. Initially, we train DCEM-O using high-fidelity numerical results and then incorporate complementary energy. DCEM-P and DCEM-O further enhance the accuracy and efficiency of DCEM.
<div id='section'>Paperid: <span id='pid'>550, <a href='https://arxiv.org/pdf/2301.13331.pdf' target='_blank'>https://arxiv.org/pdf/2301.13331.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hrishikesh Viswanath, Md Ashiqur Rahman, Abhijeet Vyas, Andrey Shor, Beatriz Medeiros, Stephanie Hernandez, Suhas Eswarappa Prameela, Aniket Bera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.13331">Neural Operator: Is data all you need to model the world? An insight into the impact of Physics Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Numerical approximations of partial differential equations (PDEs) are routinely employed to formulate the solution of physics, engineering and mathematical problems involving functions of several variables, such as the propagation of heat or sound, fluid flow, elasticity, electrostatics, electrodynamics, and more. While this has led to solving many complex phenomena, there are some limitations. Conventional approaches such as Finite Element Methods (FEMs) and Finite Differential Methods (FDMs) require considerable time and are computationally expensive. In contrast, data driven machine learning-based methods such as neural networks provide a faster, fairly accurate alternative, and have certain advantages such as discretization invariance and resolution invariance. This article aims to provide a comprehensive insight into how data-driven approaches can complement conventional techniques to solve engineering and physics problems, while also noting some of the major pitfalls of machine learning-based approaches. Furthermore, we highlight, a novel and fast machine learning-based approach (~1000x) to learning the solution operator of a PDE operator learning. We will note how these new computational approaches can bring immense advantages in tackling many problems in fundamental and applied physics.
<div id='section'>Paperid: <span id='pid'>551, <a href='https://arxiv.org/pdf/2210.00120.pdf' target='_blank'>https://arxiv.org/pdf/2210.00120.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiqi Ni, Ahmed H. Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.00120">NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Motion Planners (NMPs) have emerged as a promising tool for solving robot navigation tasks in complex environments. However, these methods often require expert data for learning, which limits their application to scenarios where data generation is time-consuming. Recent developments have also led to physics-informed deep neural models capable of representing complex dynamical Partial Differential Equations (PDEs). Inspired by these developments, we propose Neural Time Fields (NTFields) for robot motion planning in cluttered scenarios. Our framework represents a wave propagation model generating continuous arrival time to find path solutions informed by a nonlinear first-order PDE called Eikonal Equation. We evaluate our method in various cluttered 3D environments, including the Gibson dataset, and demonstrate its ability to solve motion planning problems for 4-DOF and 6-DOF robot manipulators where the traditional grid-based Eikonal planners often face the curse of dimensionality. Furthermore, the results show that our method exhibits high success rates and significantly lower computational times than the state-of-the-art methods, including NMPs that require training data from classical planners.
<div id='section'>Paperid: <span id='pid'>552, <a href='https://arxiv.org/pdf/2209.09025.pdf' target='_blank'>https://arxiv.org/pdf/2209.09025.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sourav Sanyal, Kaushik Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.09025">RAMP-Net: A Robust Adaptive MPC for Quadrotors via Physics-informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model Predictive Control (MPC) is a state-of-the-art (SOTA) control technique which requires solving hard constrained optimization problems iteratively. For uncertain dynamics, analytical model based robust MPC imposes additional constraints, increasing the hardness of the problem. The problem exacerbates in performance-critical applications, when more compute is required in lesser time. Data-driven regression methods such as Neural Networks have been proposed in the past to approximate system dynamics. However, such models rely on high volumes of labeled data, in the absence of symbolic analytical priors. This incurs non-trivial training overheads. Physics-informed Neural Networks (PINNs) have gained traction for approximating non-linear system of ordinary differential equations (ODEs), with reasonable accuracy. In this work, we propose a Robust Adaptive MPC framework via PINNs (RAMP-Net), which uses a neural network trained partly from simple ODEs and partly from data. A physics loss is used to learn simple ODEs representing ideal dynamics. Having access to analytical functions inside the loss function acts as a regularizer, enforcing robust behavior for parametric uncertainties. On the other hand, a regular data loss is used for adapting to residual disturbances (non-parametric uncertainties), unaccounted during mathematical modelling. Experiments are performed in a simulated environment for trajectory tracking of a quadrotor. We report 7.8% to 43.2% and 8.04% to 61.5% reduction in tracking errors for speeds ranging from 0.5 to 1.75 m/s compared to two SOTA regression based MPC methods.
<div id='section'>Paperid: <span id='pid'>553, <a href='https://arxiv.org/pdf/2205.06948.pdf' target='_blank'>https://arxiv.org/pdf/2205.06948.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xu Liu, Wen Yao, Wei Peng, Weien Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.06948">Bayesian Physics-Informed Extreme Learning Machine for Forward and Inverse PDE Problems with Noisy Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed extreme learning machine (PIELM) has recently received significant attention as a rapid version of physics-informed neural network (PINN) for solving partial differential equations (PDEs). The key characteristic is to fix the input layer weights with random values and use Moore-Penrose generalized inverse for the output layer weights. The framework is effective, but it easily suffers from overfitting noisy data and lacks uncertainty quantification for the solution under noise scenarios.To this end, we develop the Bayesian physics-informed extreme learning machine (BPIELM) to solve both forward and inverse linear PDE problems with noisy data in a unified framework. In our framework, a prior probability distribution is introduced in the output layer for extreme learning machine with physic laws and the Bayesian method is used to estimate the posterior of parameters. Besides, for inverse PDE problems, problem parameters considered as new output layer weights are unified in a framework with forward PDE problems. Finally, we demonstrate BPIELM considering both forward problems, including Poisson, advection, and diffusion equations, as well as inverse problems, where unknown problem parameters are estimated. The results show that, compared with PIELM, BPIELM quantifies uncertainty arising from noisy data and provides more accurate predictions. In addition, BPIELM is considerably cheaper than PINN in terms of the computational cost.
<div id='section'>Paperid: <span id='pid'>554, <a href='https://arxiv.org/pdf/2009.13291.pdf' target='_blank'>https://arxiv.org/pdf/2009.13291.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddhartha Mishra, Roberto Molinaro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2009.13291">Physics Informed Neural Networks for Simulating Radiative Transfer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel machine learning algorithm for simulating radiative transfer. Our algorithm is based on physics informed neural networks (PINNs), which are trained by minimizing the residual of the underlying radiative tranfer equations. We present extensive experiments and theoretical error estimates to demonstrate that PINNs provide a very easy to implement, fast, robust and accurate method for simulating radiative transfer. We also present a PINN based algorithm for simulating inverse problems for radiative transfer efficiently.
<div id='section'>Paperid: <span id='pid'>555, <a href='https://arxiv.org/pdf/2007.01138.pdf' target='_blank'>https://arxiv.org/pdf/2007.01138.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddhartha Mishra, Roberto Molinaro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2007.01138">Estimates on the generalization error of Physics Informed Neural Networks (PINNs) for approximating a class of inverse problems for PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics informed neural networks (PINNs) have recently been very successfully applied for efficiently approximating inverse problems for PDEs. We focus on a particular class of inverse problems, the so-called data assimilation or unique continuation problems, and prove rigorous estimates on the generalization error of PINNs approximating them. An abstract framework is presented and conditional stability estimates for the underlying inverse problem are employed to derive the estimate on the PINN generalization error, providing rigorous justification for the use of PINNs in this context. The abstract framework is illustrated with examples of four prototypical linear PDEs. Numerical experiments, validating the proposed theory, are also presented.
<div id='section'>Paperid: <span id='pid'>556, <a href='https://arxiv.org/pdf/2006.16144.pdf' target='_blank'>https://arxiv.org/pdf/2006.16144.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddhartha Mishra, Roberto Molinaro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2006.16144">Estimates on the generalization error of Physics Informed Neural Networks (PINNs) for approximating PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics informed neural networks (PINNs) have recently been widely used for robust and accurate approximation of PDEs. We provide rigorous upper bounds on the generalization error of PINNs approximating solutions of the forward problem for PDEs. An abstract formalism is introduced and stability properties of the underlying PDE are leveraged to derive an estimate for the generalization error in terms of the training error and number of training samples. This abstract framework is illustrated with several examples of nonlinear PDEs. Numerical experiments, validating the proposed theory, are also presented.
<div id='section'>Paperid: <span id='pid'>557, <a href='https://arxiv.org/pdf/2510.00457.pdf' target='_blank'>https://arxiv.org/pdf/2510.00457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weilin Xin, Chenyu Huang, Peilin Li, Jing Zhong, Jiawei Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00457">UrbanGraph: Physics-Informed Spatio-Temporal Dynamic Heterogeneous Graphs for Urban Microclimate Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With rapid urbanization, predicting urban microclimates has become critical, as it affects building energy demand and public health risks. However, existing generative and homogeneous graph approaches fall short in capturing physical consistency, spatial dependencies, and temporal variability. To address this, we introduce UrbanGraph, a physics-informed framework integrating heterogeneous and dynamic spatio-temporal graphs. It encodes key physical processes -- vegetation evapotranspiration, shading, and convective diffusion -- while modeling complex spatial dependencies among diverse urban entities and their temporal evolution. We evaluate UrbanGraph on UMC4/12, a physics-based simulation dataset covering diverse urban configurations and climates. Results show that UrbanGraph improves $R^2$ by up to 10.8% and reduces FLOPs by 17.0% over all baselines, with heterogeneous and dynamic graphs contributing 3.5% and 7.1% gains. Our dataset provides the first high-resolution benchmark for spatio-temporal microclimate modeling, and our method extends to broader urban heterogeneous dynamic computing tasks.
<div id='section'>Paperid: <span id='pid'>558, <a href='https://arxiv.org/pdf/2509.21541.pdf' target='_blank'>https://arxiv.org/pdf/2509.21541.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weikai Lin, Haoxiang Li, Yuhao Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21541">ControlHair: Physically-based Video Diffusion for Controllable Dynamic Hair Rendering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hair simulation and rendering are challenging due to complex strand dynamics, diverse material properties, and intricate light-hair interactions. Recent video diffusion models can generate high-quality videos, but they lack fine-grained control over hair dynamics. We present ControlHair, a hybrid framework that integrates a physics simulator with conditional video diffusion to enable controllable dynamic hair rendering. ControlHair adopts a three-stage pipeline: it first encodes physics parameters (e.g., hair stiffness, wind) into per-frame geometry using a simulator, then extracts per-frame control signals, and finally feeds control signals into a video diffusion model to generate videos with desired hair dynamics. This cascaded design decouples physics reasoning from video generation, supports diverse physics, and makes training the video diffusion model easy. Trained on a curated 10K video dataset, ControlHair outperforms text- and pose-conditioned baselines, delivering precisely controlled hair dynamics. We further demonstrate three use cases of ControlHair: dynamic hairstyle try-on, bullet-time effects, and cinemagraphic. ControlHair introduces the first physics-informed video diffusion framework for controllable dynamics. We provide a teaser video and experimental results on our website.
<div id='section'>Paperid: <span id='pid'>559, <a href='https://arxiv.org/pdf/2509.13386.pdf' target='_blank'>https://arxiv.org/pdf/2509.13386.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hansol Lim, Minhyeok Im, Jonathan Boyack, Jee Won Lee, Jongseong Brad Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13386">VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Demands for software-defined vehicles (SDV) are rising and electric vehicles (EVs) are increasingly being equipped with powerful computers. This enables onboard AI systems to optimize charge-aware path optimization customized to reflect vehicle's current condition and environment. We present VEGA, a charge-aware EV navigation agent that plans over a charger-annotated road graph using Proximal Policy Optimization (PPO) with budgeted A* teacher-student guidance under state-of-charge (SoC) feasibility. VEGA consists of two modules. First, a physics-informed neural operator (PINO), trained on real vehicle speed and battery-power logs, uses recent vehicle speed logs to estimate aerodynamic drag, rolling resistance, mass, motor and regenerative-braking efficiencies, and auxiliary load by learning a vehicle-custom dynamics. Second, a Reinforcement Learning (RL) agent uses these dynamics to optimize a path with optimal charging stops and dwell times under SoC constraints. VEGA requires no additional sensors and uses only vehicle speed signals. It may serve as a virtual sensor for power and efficiency to potentially reduce EV cost. In evaluation on long routes like San Francisco to New York, VEGA's stops, dwell times, SoC management, and total travel time closely track Tesla Trip Planner while being slightly more conservative, presumably due to real vehicle conditions such as vehicle parameter drift due to deterioration. Although trained only in U.S. regions, VEGA was able to compute optimal charge-aware paths in France and Japan, demonstrating generalizability. It achieves practical integration of physics-informed learning and RL for EV eco-routing.
<div id='section'>Paperid: <span id='pid'>560, <a href='https://arxiv.org/pdf/2509.07634.pdf' target='_blank'>https://arxiv.org/pdf/2509.07634.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cesare Donati, Martina Mammarella, Giuseppe C. Calafiore, Fabrizio Dabbene, Constantino Lagoa, Carlo Novara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07634">A kernel-based approach to physics-informed nonlinear system identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a kernel-based framework for physics-informed nonlinear system identification. The key contribution is a structured methodology that extends kernel-based techniques to seamlessly integrate partially known physics-based models, improving parameter estimation and overall model accuracy. The proposed method enhances traditional modeling approaches by integrating a parametric model, which provides physical interpretability, with a kernel-based function, which accounts for unmodelled dynamics. The two model's components are identified from data simultaneously, minimizing a suitable cost that balances the relative importance of the physical and the black-box parts of the model. Additionally, nonlinear state smoothing is employed to address scenarios involving state-space models with not fully measurable states. Numerical simulations on an experimental benchmark system demonstrate the effectiveness of the proposed approach, with performance comparisons against state-of-the-art identification techniques.
<div id='section'>Paperid: <span id='pid'>561, <a href='https://arxiv.org/pdf/2508.14807.pdf' target='_blank'>https://arxiv.org/pdf/2508.14807.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zifan Wang, Alice Harting, Matthieu Barreau, Michael M. Zavlanos, Karl H. Johansson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14807">Source-Guided Flow Matching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Guidance of generative models is typically achieved by modifying the probability flow vector field through the addition of a guidance field. In this paper, we instead propose the Source-Guided Flow Matching (SGFM) framework, which modifies the source distribution directly while keeping the pre-trained vector field intact. This reduces the guidance problem to a well-defined problem of sampling from the source distribution. We theoretically show that SGFM recovers the desired target distribution exactly. Furthermore, we provide bounds on the Wasserstein error for the generated distribution when using an approximate sampler of the source distribution and an approximate vector field. The key benefit of our approach is that it allows the user to flexibly choose the sampling method depending on their specific problem. To illustrate this, we systematically compare different sampling methods and discuss conditions for asymptotically exact guidance. Moreover, our framework integrates well with optimal flow matching models since the straight transport map generated by the vector field is preserved. Experimental results on synthetic 2D benchmarks, physics-informed generative tasks, and imaging inverse problems demonstrate the effectiveness and flexibility of the proposed framework.
<div id='section'>Paperid: <span id='pid'>562, <a href='https://arxiv.org/pdf/2508.12602.pdf' target='_blank'>https://arxiv.org/pdf/2508.12602.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hansol Lim, Jongseong Brad Choi, Jee Won Lee, Haeseong Jeoung, Minkyu Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12602">A Hybrid Surrogate for Electric Vehicle Parameter Estimation and Power Consumption via Physics-Informed Neural Operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a hybrid surrogate model for electric vehicle parameter estimation and power consumption. We combine our novel architecture Spectral Parameter Operator built on a Fourier Neural Operator backbone for global context and a differentiable physics module in the forward pass. From speed and acceleration alone, it outputs time-varying motor and regenerative braking efficiencies, as well as aerodynamic drag, rolling resistance, effective mass, and auxiliary power. These parameters drive a physics-embedded estimate of battery power, eliminating any separate physics-residual loss. The modular design lets representations converge to physically meaningful parameters that reflect the current state and condition of the vehicle. We evaluate on real-world logs from a Tesla Model 3, Tesla Model S, and the Kia EV9. The surrogate achieves a mean absolute error of 0.2kW (about 1% of average traction power at highway speeds) for Tesla vehicles and about 0.8kW on the Kia EV9. The framework is interpretable, and it generalizes well to unseen conditions, and sampling rates, making it practical for path optimization, eco-routing, on-board diagnostics, and prognostics health management.
<div id='section'>Paperid: <span id='pid'>563, <a href='https://arxiv.org/pdf/2508.10322.pdf' target='_blank'>https://arxiv.org/pdf/2508.10322.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qixuan Zhou, Chuqi Chen, Tao Luo, Yang Xiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10322">SSBE-PINN: A Sobolev Boundary Scheme Boosting Stability and Accuracy in Elliptic/Parabolic PDE Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs), yet they often fail to achieve accurate convergence in the H1 norm, especially in the presence of boundary approximation errors. In this work, we propose a novel method called Sobolev-Stable Boundary Enforcement (SSBE), which redefines the boundary loss using Sobolev norms to incorporate boundary regularity directly into the training process. We provide rigorous theoretical analysis demonstrating that SSBE ensures bounded H1 error via a stability guarantee and derive generalization bounds that characterize its robustness under finite-sample regimes. Extensive numerical experiments on linear and nonlinear PDEs, including Poisson, heat, and elliptic problems, show that SSBE consistently outperforms standard PINNs in terms of both relative L2 and H1 errors, even in high-dimensional settings. The proposed approach offers a principled and practical solution for improving gradient fidelity and overall solution accuracy in neural network based PDE solvers.
<div id='section'>Paperid: <span id='pid'>564, <a href='https://arxiv.org/pdf/2507.19519.pdf' target='_blank'>https://arxiv.org/pdf/2507.19519.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>J. Poole, P. Gardner, A. J. Hughes, N. Dervilis, R. S. Mills, T. A. Dardeno, K. Worden
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19519">Physics-informed transfer learning for SHM via feature selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data used for training structural health monitoring (SHM) systems are expensive and often impractical to obtain, particularly labelled data. Population-based SHM presents a potential solution to this issue by considering the available data across a population of structures. However, differences between structures will mean the training and testing distributions will differ; thus, conventional machine learning methods cannot be expected to generalise between structures. To address this issue, transfer learning (TL), can be used to leverage information across related domains. An important consideration is that the lack of labels in the target domain limits data-based metrics to quantifying the discrepancy between the marginal distributions. Thus, a prerequisite for the application of typical unsupervised TL methods is to identify suitable source structures (domains), and a set of features, for which the conditional distributions are related to the target structure. Generally, the selection of domains and features is reliant on domain expertise; however, for complex mechanisms, such as the influence of damage on the dynamic response of a structure, this task is not trivial. In this paper, knowledge of physics is leveraged to select more similar features, the modal assurance criterion (MAC) is used to quantify the correspondence between the modes of healthy structures. The MAC is shown to have high correspondence with a supervised metric that measures joint-distribution similarity, which is the primary indicator of whether a classifier will generalise between domains. The MAC is proposed as a measure for selecting a set of features that behave consistently across domains when subjected to damage, i.e. features with invariance in the conditional distributions. This approach is demonstrated on numerical and experimental case studies to verify its effectiveness in various applications.
<div id='section'>Paperid: <span id='pid'>565, <a href='https://arxiv.org/pdf/2507.03860.pdf' target='_blank'>https://arxiv.org/pdf/2507.03860.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chandra Kanth Nagesh, Sriram Sankaranarayanan, Ramneet Kaur, Tuhin Sahai, Susmit Jha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.03860">Taylor-Model Physics-Informed Neural Networks (PINNs) for Ordinary Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the problem of learning neural network models for Ordinary Differential Equations (ODEs) with parametric uncertainties. Such neural network models capture the solution to the ODE over a given set of parameters, initial conditions, and range of times. Physics-Informed Neural Networks (PINNs) have emerged as a promising approach for learning such models that combine data-driven deep learning with symbolic physics models in a principled manner. However, the accuracy of PINNs degrade when they are used to solve an entire family of initial value problems characterized by varying parameters and initial conditions.
  In this paper, we combine symbolic differentiation and Taylor series methods to propose a class of higher-order models for capturing the solutions to ODEs. These models combine neural networks and symbolic terms: they use higher order Lie derivatives and a Taylor series expansion obtained symbolically, with the remainder term modeled as a neural network. The key insight is that the remainder term can itself be modeled as a solution to a first-order ODE. We show how the use of these higher order PINNs can improve accuracy using interesting, but challenging ODE benchmarks. We also show that the resulting model can be quite useful for situations such as controlling uncertain physical systems modeled as ODEs.
<div id='section'>Paperid: <span id='pid'>566, <a href='https://arxiv.org/pdf/2506.22365.pdf' target='_blank'>https://arxiv.org/pdf/2506.22365.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Li, Haozhe Lei, Mingsheng Yin, Yaqi Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22365">Reinforcement Learning with Physics-Informed Symbolic Program Priors for Zero-Shot Wireless Indoor Navigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When using reinforcement learning (RL) to tackle physical control tasks, inductive biases that encode physics priors can help improve sample efficiency during training and enhance generalization in testing. However, the current practice of incorporating these helpful physics-informed inductive biases inevitably runs into significant manual labor and domain expertise, making them prohibitive for general users. This work explores a symbolic approach to distill physics-informed inductive biases into RL agents, where the physics priors are expressed in a domain-specific language (DSL) that is human-readable and naturally explainable. Yet, the DSL priors do not translate directly into an implementable policy due to partial and noisy observations and additional physical constraints in navigation tasks. To address this gap, we develop a physics-informed program-guided RL (PiPRL) framework with applications to indoor navigation. PiPRL adopts a hierarchical and modularized neuro-symbolic integration, where a meta symbolic program receives semantically meaningful features from a neural perception module, which form the bases for symbolic programming that encodes physics priors and guides the RL process of a low-level neural controller. Extensive experiments demonstrate that PiPRL consistently outperforms purely symbolic or neural policies and reduces training time by over 26% with the help of the program-based inductive biases.
<div id='section'>Paperid: <span id='pid'>567, <a href='https://arxiv.org/pdf/2506.18812.pdf' target='_blank'>https://arxiv.org/pdf/2506.18812.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aristotelis Papatheodorou, Pranav Vaidhyanathan, Natalia Ares, Ioannis Havoutis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18812">Learning Physical Systems: Symplectification via Gauge Fixing in Dirac Structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed deep learning has achieved remarkable progress by embedding geometric priors, such as Hamiltonian symmetries and variational principles, into neural networks, enabling structure-preserving models that extrapolate with high accuracy. However, in systems with dissipation and holonomic constraints, ubiquitous in legged locomotion and multibody robotics, the canonical symplectic form becomes degenerate, undermining the very invariants that guarantee stability and long-term prediction. In this work, we tackle this foundational limitation by introducing Presymplectification Networks (PSNs), the first framework to learn the symplectification lift via Dirac structures, restoring a non-degenerate symplectic geometry by embedding constrained systems into a higher-dimensional manifold. Our architecture combines a recurrent encoder with a flow-matching objective to learn the augmented phase-space dynamics end-to-end. We then attach a lightweight Symplectic Network (SympNet) to forecast constrained trajectories while preserving energy, momentum, and constraint satisfaction. We demonstrate our method on the dynamics of the ANYmal quadruped robot, a challenging contact-rich, multibody system. To the best of our knowledge, this is the first framework that effectively bridges the gap between constrained, dissipative mechanical systems and symplectic learning, unlocking a whole new class of geometric machine learning models, grounded in first principles yet adaptable from data.
<div id='section'>Paperid: <span id='pid'>568, <a href='https://arxiv.org/pdf/2506.18357.pdf' target='_blank'>https://arxiv.org/pdf/2506.18357.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenguang Zhao, Huan Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18357">Physics-Informed Neural Networks for Nonlocal Flow Modeling of Connected Automated Vehicles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Connected automated vehicles (CAVs) cruising control strategies have been extensively studied at the microscopic level. CAV controllers sense and react to traffic both upstream and downstream, yet most macroscopic models still assume locality, where the desired speed only depends on local density. The nonlocal macroscopic traffic flow models that explicitly capture the ``look ahead'' and ``look behind'' nonlocal CAV dynamics remain underexplored. In this paper, we propose a Physics-informed Neural Network framework to directly learn a macroscopic non-local flow model from a generic looking-ahead looking-behind vehicle motion model, which bridges the micro-macro modeling gap. We reconstruct macroscopic traffic states from synthetic CAV trajectories generated by the proposed microscopic control designs, and then learn a non-local traffic flow model that embeds a non-local conservation law to capture the resulting look-ahead look-behind dynamics. To analyze how CAV control parameters affect nonlocal traffic flow, we conduct high-fidelity driving simulator experiments to collect human drivers' trajectory data with varying downstream and upstream visibility, which serves as a baseline for tuning CAV control gains. Our analysis validates that the learned non-local flow model predicts CAV traffic dynamics more accurately than local models, and the fundamental diagram exhibits far less scatter in the speed - density relation. We further show that the looking-ahead/looking-behind control gains mainly reshape the non-local kernels, while the macroscopic speed and non-local density relation mainly depends on the desired speed function choice of the CAV controller. Our results provide a systematic approach for learning non-local macroscopic traffic-flow models directly from generic CAV control designs.
<div id='section'>Paperid: <span id='pid'>569, <a href='https://arxiv.org/pdf/2506.17582.pdf' target='_blank'>https://arxiv.org/pdf/2506.17582.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Wang, Biao Chen, Hairun Xie, Rui Wang, Yifan Xia, Jifa Zhang, Hui Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17582">LFR-PINO: A Layered Fourier Reduced Physics-Informed Neural Operator for Parametric PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural operators have emerged as a powerful paradigm for solving parametric partial differential equations (PDEs), particularly in the aerospace field, enabling the learning of solution operators that generalize across parameter spaces. However, existing methods either suffer from limited expressiveness due to fixed basis/coefficient designs, or face computational challenges due to the high dimensionality of the parameter-to-weight mapping space. We present LFR-PINO, a novel physics-informed neural operator that introduces two key innovations: (1) a layered hypernetwork architecture that enables specialized parameter generation for each network layer, and (2) a frequency-domain reduction strategy that significantly reduces parameter count while preserving essential spectral features. This design enables efficient learning of a universal PDE solver through pre-training, capable of directly handling new equations while allowing optional fine-tuning for enhanced precision. The effectiveness of this approach is demonstrated through comprehensive experiments on four representative PDE problems, where LFR-PINO achieves 22.8%-68.7% error reduction compared to state-of-the-art baselines. Notably, frequency-domain reduction strategy reduces memory usage by 28.6%-69.3% compared to Hyper-PINNs while maintaining solution accuracy, striking an optimal balance between computational efficiency and solution fidelity.
<div id='section'>Paperid: <span id='pid'>570, <a href='https://arxiv.org/pdf/2506.14786.pdf' target='_blank'>https://arxiv.org/pdf/2506.14786.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haobo Li, Eunseo Jung, Zixin Chen, Zhaowei Wang, Yueya Wang, Huamin Qu, Alexis Kai Hon Lau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14786">PIPE: Physics-Informed Position Encoding for Alignment of Satellite Images and Time Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal time series forecasting is foundational in various fields, such as utilizing satellite imagery and numerical data for predicting typhoons in climate science. However, existing multimodal approaches primarily focus on utilizing text data to help time series forecasting, leaving the visual data in existing time series datasets untouched. Furthermore, it is challenging for models to effectively capture the physical information embedded in visual data, such as satellite imagery's temporal and geospatial context, which extends beyond images themselves. To address this gap, we propose physics-informed positional encoding (PIPE), a lightweight method that embeds physical information into vision language models (VLMs). PIPE introduces two key innovations: (1) a physics-informed positional indexing scheme for mapping physics to positional IDs, and (2) a variant-frequency positional encoding mechanism for encoding frequency information of physical variables and sequential order of tokens within the embedding space. By preserving both the physical information and sequential order information, PIPE significantly improves multimodal alignment and forecasting accuracy. Through the experiments on the most representative and the largest open-sourced satellite image dataset, PIPE achieves state-of-the-art performance in both deep learning forecasting and climate domain methods, demonstrating superiority across benchmarks, including a 12% improvement in typhoon intensity forecasting over prior works. Our code is provided in the supplementary material.
<div id='section'>Paperid: <span id='pid'>571, <a href='https://arxiv.org/pdf/2506.10243.pdf' target='_blank'>https://arxiv.org/pdf/2506.10243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rongxin Lu, Jiwei Jia, Young Ju Lee, Zheng Lu, Chensong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10243">R-PINN: Recovery-type a-posteriori estimator enhanced adaptive PINN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, with the advancements in machine learning and neural networks, algorithms using physics-informed neural networks (PINNs) to solve PDEs have gained widespread applications. While these algorithms are well-suited for a wide range of equations, they often exhibit suboptimal performance when applied to equations with large local gradients, resulting in substantial localized errors. To address this issue, this paper proposes an adaptive PINN algorithm designed to improve accuracy in such cases. The core idea of the algorithm is to adaptively adjust the distribution of collocation points based on the recovery-type a-posterior error of the current numerical solution, enabling a better approximation of the true solution. This approach is inspired by the adaptive finite element method. By combining the recovery-type a-posteriori estimator, a gradient-recovery estimator commonly used in the adaptive finite element method (FEM) with PINNs, we introduce the Recovery-type a-posteriori estimator enhanced adaptive PINN (R-PINN) and compare its performance with a typical adaptive PINN algorithm, FI-PINN. Our results demonstrate that R-PINN achieves faster convergence with fewer adaptive points and significantly outperforms in the cases with multiple regions of large errors than FI-PINN. Notably, our method is a hybrid numerical approach for solving partial differential equations, integrating adaptive FEM with PINNs.
<div id='section'>Paperid: <span id='pid'>572, <a href='https://arxiv.org/pdf/2506.01153.pdf' target='_blank'>https://arxiv.org/pdf/2506.01153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Roussel Desmond Nzoyem, Nawid Keshtmand, Enrique Crespo Fernandez, Idriss Tsayem, Raul Santos-Rodriguez, David A. W. Barton, Tom Deakin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01153">Weight-Space Linear Recurrent Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce WARP (Weight-space Adaptive Recurrent Prediction), a simple yet powerful model that unifies weight-space learning with linear recurrence to redefine sequence modeling. Unlike conventional recurrent neural networks (RNNs) which collapse temporal dynamics into fixed-dimensional hidden states, WARP explicitly parametrizes its hidden state as the weights and biases of a distinct auxiliary neural network, and uses input differences to drive its recurrence. This brain-inspired formulation enables efficient gradient-free adaptation of the auxiliary network at test-time, in-context learning abilities, and seamless integration of domain-specific physical priors. Empirical validation shows that WARP matches or surpasses state-of-the-art baselines on diverse classification tasks, featuring in the top three in 5 out of 6 real-world challenging datasets. Furthermore, extensive experiments across sequential image completion, multivariate time series forecasting, and dynamical system reconstruction demonstrate its expressiveness and generalisation capabilities. Remarkably, a physics-informed variant of our model outperforms the next best model by more than 10x. Ablation studies confirm the architectural necessity of key components, solidifying weight-space linear RNNs as a transformative paradigm for adaptive machine intelligence.
<div id='section'>Paperid: <span id='pid'>573, <a href='https://arxiv.org/pdf/2505.18647.pdf' target='_blank'>https://arxiv.org/pdf/2505.18647.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kiet Bennema ten Brinke, Koen Minartz, Vlado Menkovski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18647">Flow Matching for Geometric Trajectory Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The simulation of N-body systems is a fundamental problem with applications in a wide range of fields, such as molecular dynamics, biochemistry, and pedestrian dynamics. Machine learning has become an invaluable tool for scaling physics-based simulators and developing models directly from experimental data. In particular, recent advances based on deep generative modeling and geometric deep learning have enabled probabilistic simulation by modeling complex distributions over trajectories while respecting the permutation symmetry that is fundamental to N-body systems. However, to generate realistic trajectories, existing methods must learn complex transformations starting from uninformed noise and do not allow for the exploitation of domain-informed priors. In this work, we propose STFlow to address this limitation. By leveraging flow matching and data-dependent couplings, STFlow facilitates physics-informed simulation of geometric trajectories without sacrificing model expressivity or scalability. Our evaluation on N-body dynamical systems, molecular dynamics, and pedestrian dynamics benchmarks shows that STFlow produces significantly lower prediction errors while enabling more efficient inference, highlighting the benefits of employing physics-informed prior distributions in probabilistic geometric trajectory modeling.
<div id='section'>Paperid: <span id='pid'>574, <a href='https://arxiv.org/pdf/2504.21153.pdf' target='_blank'>https://arxiv.org/pdf/2504.21153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Salma M. Elsherif, Ahmad F. Taha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.21153">Climate Science and Control Engineering: Insights, Parallels, and Connections</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Climate science is the multidisciplinary field that studies the Earth's climate and its evolution. At the very core of climate science are indispensable climate models that predict future climate scenarios, inform policy decisions, and dictate how a country's economy should change in light of the changing climate. Climate models capture a wide range of interacting dynamic processes via extremely complex ordinary and partial differential equations. To model these large-scale complex processes, climate science leverages supercomputers, advanced simulations, and statistical methods to predict future climate. An area of engineering that is rarely studied in climate science is control engineering. Given that climate systems are inherently dynamic, it is intuitive to analyze them within the framework of dynamic system science. This perspective has been underexplored in the literature. In this manuscript, we provide a tutorial that: (i) introduces the control engineering community to climate dynamics and modeling, including spatiotemporal scales and challenges in climate modeling; (ii) offers a fresh perspective on climate models from a control systems viewpoint; and (iii) explores the relevance and applicability of various advanced graph and network control-based approaches in building a physics-informed framework for learning, control and estimation in climate systems. We also present simple and then more complex climate models, depicting fundamental ideas and processes that are instrumental in building climate change projections. This tutorial also builds parallels and observes connections between various contemporary problems at the forefront of climate science and their control theoretic counterparts. We specifically observe that an abundance of climate science problems can be linguistically reworded and mathematically framed as control theoretic ones.
<div id='section'>Paperid: <span id='pid'>575, <a href='https://arxiv.org/pdf/2504.11896.pdf' target='_blank'>https://arxiv.org/pdf/2504.11896.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingxing Yang, Jie Chen, Zaifeng Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11896">Learning Physics-Informed Color-Aware Transforms for Low-Light Image Enhancement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image decomposition offers deep insights into the imaging factors of visual data and significantly enhances various advanced computer vision tasks. In this work, we introduce a novel approach to low-light image enhancement based on decomposed physics-informed priors. Existing methods that directly map low-light to normal-light images in the sRGB color space suffer from inconsistent color predictions and high sensitivity to spectral power distribution (SPD) variations, resulting in unstable performance under diverse lighting conditions. To address these challenges, we introduce a Physics-informed Color-aware Transform (PiCat), a learning-based framework that converts low-light images from the sRGB color space into deep illumination-invariant descriptors via our proposed Color-aware Transform (CAT). This transformation enables robust handling of complex lighting and SPD variations. Complementing this, we propose the Content-Noise Decomposition Network (CNDN), which refines the descriptor distributions to better align with well-lit conditions by mitigating noise and other distortions, thereby effectively restoring content representations to low-light images. The CAT and the CNDN collectively act as a physical prior, guiding the transformation process from low-light to normal-light domains. Our proposed PiCat framework demonstrates superior performance compared to state-of-the-art methods across five benchmark datasets.
<div id='section'>Paperid: <span id='pid'>576, <a href='https://arxiv.org/pdf/2503.23348.pdf' target='_blank'>https://arxiv.org/pdf/2503.23348.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianhua Sun, Jiude Wei, Yuxuan Li, Cewu Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.23348">Physically Ground Commonsense Knowledge for Articulated Object Manipulation with Analytic Concepts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We human rely on a wide range of commonsense knowledge to interact with an extensive number and categories of objects in the physical world. Likewise, such commonsense knowledge is also crucial for robots to successfully develop generalized object manipulation skills. While recent advancements in Large Language Models (LLM) have showcased their impressive capabilities in acquiring commonsense knowledge and conducting commonsense reasoning, effectively grounding this semantic-level knowledge produced by LLMs to the physical world to thoroughly guide robots in generalized articulated object manipulation remains a challenge that has not been sufficiently addressed. To this end, we introduce analytic concepts, procedurally defined upon mathematical symbolism that can be directly computed and simulated by machines. By leveraging the analytic concepts as a bridge between the semantic-level knowledge inferred by LLMs and the physical world where real robots operate, we are able to figure out the knowledge of object structure and functionality with physics-informed representations, and then use the physically grounded knowledge to instruct robot control policies for generalized, interpretable and accurate articulated object manipulation. Extensive experiments in both simulation and real-world environments demonstrate the superiority of our approach.
<div id='section'>Paperid: <span id='pid'>577, <a href='https://arxiv.org/pdf/2503.16455.pdf' target='_blank'>https://arxiv.org/pdf/2503.16455.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiwen Dong, Jessica Rose, Hae Young Noh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16455">Bridging Structural Dynamics and Biomechanics: Human Motion Estimation through Footstep-Induced Floor Vibrations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantitative estimation of human joint motion in daily living spaces is essential for early detection and rehabilitation tracking of neuromusculoskeletal disorders (e.g., Parkinson's) and mitigating trip and fall risks for older adults. Existing approaches involve monitoring devices such as cameras, wearables, and pressure mats, but have operational constraints such as direct line-of-sight, carrying devices, and dense deployment. To overcome these limitations, we leverage gait-induced floor vibration to estimate lower-limb joint motion (e.g., ankle, knee, and hip flexion angles), allowing non-intrusive and contactless gait health monitoring in people's living spaces. To overcome the high uncertainty in lower-limb movement given the limited information provided by the gait-induced floor vibrations, we formulate a physics-informed graph to integrate domain knowledge of gait biomechanics and structural dynamics into the model. Specifically, different types of nodes represent heterogeneous information from joint motions and floor vibrations; Their connecting edges represent the physiological relationships between joints and forces governed by gait biomechanics, as well as the relationships between forces and floor responses governed by the structural dynamics. As a result, our model poses physical constraints to reduce uncertainty while allowing information sharing between the body and the floor to make more accurate predictions. We evaluate our approach with 20 participants through a real-world walking experiment. We achieved an average of 3.7 degrees of mean absolute error in estimating 12 joint flexion angles (38% error reduction from baseline), which is comparable to the performance of cameras and wearables in current medical practices.
<div id='section'>Paperid: <span id='pid'>578, <a href='https://arxiv.org/pdf/2503.15168.pdf' target='_blank'>https://arxiv.org/pdf/2503.15168.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Javier Del Ser, Jesus L. Lobo, Heimo MÃ¼ller, Andreas Holzinger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15168">World Models in Artificial Intelligence: Sensing, Learning, and Reasoning Like a Child</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>World Models help Artificial Intelligence (AI) predict outcomes, reason about its environment, and guide decision-making. While widely used in reinforcement learning, they lack the structured, adaptive representations that even young children intuitively develop. Advancing beyond pattern recognition requires dynamic, interpretable frameworks inspired by Piaget's cognitive development theory. We highlight six key research areas -- physics-informed learning, neurosymbolic learning, continual learning, causal inference, human-in-the-loop AI, and responsible AI -- as essential for enabling true reasoning in AI. By integrating statistical learning with advances in these areas, AI can evolve from pattern recognition to genuine understanding, adaptation and reasoning capabilities.
<div id='section'>Paperid: <span id='pid'>579, <a href='https://arxiv.org/pdf/2502.20772.pdf' target='_blank'>https://arxiv.org/pdf/2502.20772.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianyi Zeng, Tianyi Wang, Junfeng Jiao, Xinbo Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.20772">Damper-B-PINN: Damper Characteristics-Based Bayesian Physics-Informed Neural Network for Vehicle State Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State estimation for Multi-Input Multi-Output (MIMO) systems with noise, such as vehicle chassis systems, presents a significant challenge due to the imperfect and complex relationship between inputs and outputs. To solve this problem, we design a Damper characteristics-based Bayesian Physics-Informed Neural Network (Damper-B-PINN). First, we introduce a neuron forward process inspired by the mechanical properties of dampers, which limits abrupt jumps in neuron values between epochs while maintaining search capability. Additionally, we apply an optimized Bayesian dropout layer to the MIMO system to enhance robustness against noise and prevent non-convergence issues. Physical information is incorporated into the loss function to serve as a physical prior for the neural network. The effectiveness of our Damper-B-PINN architecture is then validated across ten datasets and fourteen vehicle types, demonstrating superior accuracy, computational efficiency, and convergence in vehicle state estimation (i.e., dynamic wheel load) compared to other state-of-the-art benchmarks.
<div id='section'>Paperid: <span id='pid'>580, <a href='https://arxiv.org/pdf/2502.17209.pdf' target='_blank'>https://arxiv.org/pdf/2502.17209.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hannah Eichhorn, Veronika Spieker, Kerstin Hammernik, Elisa Saks, Lina Felsner, Kilian Weiss, Christine Preibisch, Julia A. Schnabel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.17209">Motion-Robust T2* Quantification from Gradient Echo MRI with Physics-Informed Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Purpose: T2* quantification from gradient echo magnetic resonance imaging is particularly affected by subject motion due to the high sensitivity to magnetic field inhomogeneities, which are influenced by motion and might cause signal loss. Thus, motion correction is crucial to obtain high-quality T2* maps. Methods: We extend our previously introduced learning-based physics-informed motion correction method, PHIMO, by utilizing acquisition knowledge to enhance the reconstruction performance for challenging motion patterns and increase PHIMO's robustness to varying strengths of magnetic field inhomogeneities across the brain. We perform comprehensive evaluations regarding motion detection accuracy and image quality for data with simulated and real motion. Results: Our extended version of PHIMO outperforms the learning-based baseline methods both qualitatively and quantitatively with respect to line detection and image quality. Moreover, PHIMO performs on-par with a conventional state-of-the-art motion correction method for T2* quantification from gradient echo MRI, which relies on redundant data acquisition. Conclusion: PHIMO's competitive motion correction performance, combined with a reduction in acquisition time by over 40% compared to the state-of-the-art method, make it a promising solution for motion-robust T2* quantification in research settings and clinical routine.
<div id='section'>Paperid: <span id='pid'>581, <a href='https://arxiv.org/pdf/2502.12093.pdf' target='_blank'>https://arxiv.org/pdf/2502.12093.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiale Zhang, Yuyan Wu, Jesse R Codling, Yen Cheng Chang, Julia Gersey, Pei Zhang, Hae Young Noh, Yiwen Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12093">WeVibe: Weight Change Estimation Through Audio-Induced Shelf Vibrations In Autonomous Stores</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Weight change estimation is crucial in various applications, particularly for detecting pick-up and put-back actions when people interact with the shelf while shopping in autonomous stores. Moreover, accurate weight change estimation allows autonomous stores to automatically identify items being picked up or put back, ensuring precise cost estimation. However, the conventional approach of estimating weight changes requires specialized weight-sensing shelves, which are densely deployed weight scales, incurring intensive sensor consumption and high costs. Prior works explored the vibration-based weight sensing method, but they failed when the location of weight change varies.
  In response to these limitations, we made the following contributions: (1) We propose WeVibe, a first item weight change estimation system through active shelf vibration sensing. The main intuition of the system is that the weight placed on the shelf influences the dynamic vibration response of the shelf, thus altering the shelf vibration patterns. (2) We model a physics-informed relationship between the shelf vibration response and item weight across multiple locations on the shelf based on structural dynamics theory. This relationship is linear and allows easy training of a weight estimation model at a new location without heavy data collection. (3) We evaluate our system on a gondola shelf organized as the real-store settings. WeVibe achieved a mean absolute error down to 38.07g and a standard deviation of 31.2g with one sensor and 10% samples from three weight classes on estimating weight change from 0g to 450g, which can be leveraged for differentiating items with more than 100g differences.
<div id='section'>Paperid: <span id='pid'>582, <a href='https://arxiv.org/pdf/2502.07209.pdf' target='_blank'>https://arxiv.org/pdf/2502.07209.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shaghayegh Fazliani, Zachary Frangella, Madeleine Udell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07209">Enhancing Physics-Informed Neural Networks Through Feature Engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) seek to solve partial differential equations (PDEs) with deep learning. Mainstream approaches that deploy fully-connected multi-layer deep learning architectures require prolonged training to achieve even moderate accuracy, while recent work on feature engineering allows higher accuracy and faster convergence. This paper introduces SAFE-NET, a Single-layered Adaptive Feature Engineering NETwork that achieves orders-of-magnitude lower errors with far fewer parameters than baseline feature engineering methods. SAFE-NET returns to basic ideas in machine learning, using Fourier features, a simplified single hidden layer network architecture, and an effective optimizer that improves the conditioning of the PINN optimization problem. Numerical results show that SAFE-NET converges faster and typically outperforms deeper networks and more complex architectures. It consistently uses fewer parameters -- on average, 65% fewer than the competing feature engineering methods -- while achieving comparable accuracy in less than 30% of the training epochs. Moreover, each SAFE-NET epoch is 95% faster than those of competing feature engineering approaches. These findings challenge the prevailing belief that modern PINNs effectively learn features in these scientific applications and highlight the efficiency gains possible through feature engineering.
<div id='section'>Paperid: <span id='pid'>583, <a href='https://arxiv.org/pdf/2502.06412.pdf' target='_blank'>https://arxiv.org/pdf/2502.06412.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ioannis Karampinis, Petros Ellinas, Ignasi Ventura Nadal, Rahul Nellikkath, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06412">Toolbox for Developing Physics Informed Neural Networks for Power Systems Components</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper puts forward the vision of creating a library of neural-network-based models for power system simulations. Traditional numerical solvers struggle with the growing complexity of modern power systems, necessitating faster and more scalable alternatives. Physics-Informed Neural Networks (PINNs) offer promise to solve fast the ordinary differential equations (ODEs) governing power system dynamics. This is vital for the reliability, cost optimization, and real-time decision-making in the electricity grid. Despite their potential, standardized frameworks to train PINNs remain scarce. This poses a barrier for the broader adoption and reproducibility of PINNs; it also does not allow the streamlined creation of a PINN-based model library. This paper addresses these gaps. It introduces a Python-based toolbox for developing PINNs tailored to power system components, available on GitHub https://github. com/radiakos/PowerPINN. Using this framework, we capture the dynamic characteristics of a 9th-order system, which is probably the most complex power system component trained with a PINN to date, demonstrating the toolbox capabilities, limitations, and potential improvements. The toolbox is open and free to use by anyone interested in creating PINN-based models for power system components.
<div id='section'>Paperid: <span id='pid'>584, <a href='https://arxiv.org/pdf/2502.04406.pdf' target='_blank'>https://arxiv.org/pdf/2502.04406.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vignesh Gopakumar, Ander Gray, Lorenzo Zanisi, Timothy Nunn, Daniel Giles, Matt J. Kusner, Stanislas Pamela, Marc Peter Deisenroth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04406">Calibrated Physics-Informed Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulating complex physical systems is crucial for understanding and predicting phenomena across diverse fields, such as fluid dynamics and heat transfer, as well as plasma physics and structural mechanics. Traditional approaches rely on solving partial differential equations (PDEs) using numerical methods, which are computationally expensive and often prohibitively slow for real-time applications or large-scale simulations. Neural PDEs have emerged as efficient alternatives to these costly numerical solvers, offering significant computational speed-ups. However, their lack of robust uncertainty quantification (UQ) limits deployment in critical applications. We introduce a model-agnostic, physics-informed conformal prediction (CP) framework that provides guaranteed uncertainty estimates without requiring labelled data. By utilising a physics-based approach, we can quantify and calibrate the model's inconsistencies with the physics rather than the uncertainty arising from the data. Our approach utilises convolutional layers as finite-difference stencils and leverages physics residual errors as nonconformity scores, enabling data-free UQ with marginal and joint coverage guarantees across prediction domains for a range of complex PDEs. We further validate the efficacy of our method on neural PDE models for plasma modelling and shot design in fusion reactors.
<div id='section'>Paperid: <span id='pid'>585, <a href='https://arxiv.org/pdf/2501.17621.pdf' target='_blank'>https://arxiv.org/pdf/2501.17621.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ignasi Ventura Nadal, Rahul Nellikkath, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17621">Physics-Informed Neural Networks in Power System Dynamics: Improving Simulation Accuracy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The importance and cost of time-domain simulations when studying power systems have exponentially increased in the last decades. With the growing share of renewable energy sources, the slow and predictable responses from large turbines are replaced by the fast and unpredictable dynamics from power electronics. The current existing simulation tools require new solutions designed for faster dynamics. Physics-Informed Neural Networks (PINNs) have recently emerged in power systems to accelerate such simulations. By incorporating knowledge during the up-front training, PINNs provide more accurate results over larger time steps than traditional numerical methods. This paper introduces PINNs as an alternative approximation method that seamlessly integrates with the current simulation framework. We replace a synchronous machine for a trained PINN in the IEEE 9-, 14-, and 30-bus systems and simulate several network disturbances. Including PINNs systematically boosts the simulations' accuracy, providing more accurate results for both the PINN-modeled component and the whole multi-machine system states.
<div id='section'>Paperid: <span id='pid'>586, <a href='https://arxiv.org/pdf/2501.17621.pdf' target='_blank'>https://arxiv.org/pdf/2501.17621.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ignasi Ventura Nadal, Rahul Nellikkath, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17621">Physics-Informed Neural Networks in Power System Dynamics: Improving Simulation Accuracy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The importance and cost of time-domain simulations when studying power systems have exponentially increased in the last decades. With the growing share of renewable energy sources, the slow and predictable responses from large turbines are replaced by the fast and unpredictable dynamics from power electronics. The current existing simulation tools require new solutions designed for faster dynamics. Physics-Informed Neural Networks (PINNs) have recently emerged in power systems to accelerate such simulations. By incorporating knowledge during the up-front training, PINNs provide more accurate results over larger time steps than traditional numerical methods. This paper introduces PINNs as an alternative approximation method that seamlessly integrates with the current simulation framework. We replace a synchronous machine for a trained PINN in the IEEE 9-, 14-, and 30-bus systems and simulate several network disturbances. Including PINNs systematically boosts the simulations' accuracy, providing more accurate results for both the PINN-modeled component and the whole multi-machine system states.
<div id='section'>Paperid: <span id='pid'>587, <a href='https://arxiv.org/pdf/2501.11222.pdf' target='_blank'>https://arxiv.org/pdf/2501.11222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaqi Luo, Yahong Yang, Yuan Yuan, Shixin Xu, Wenrui Hao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11222">An Imbalanced Learning-based Sampling Method for Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces Residual-based Smote (RSmote), an innovative local adaptive sampling technique tailored to improve the performance of Physics-Informed Neural Networks (PINNs) through imbalanced learning strategies. Traditional residual-based adaptive sampling methods, while effective in enhancing PINN accuracy, often struggle with efficiency and high memory consumption, particularly in high-dimensional problems. RSmote addresses these challenges by targeting regions with high residuals and employing oversampling techniques from imbalanced learning to refine the sampling process. Our approach is underpinned by a rigorous theoretical analysis that supports the effectiveness of RSmote in managing computational resources more efficiently. Through extensive evaluations, we benchmark RSmote against the state-of-the-art Residual-based Adaptive Distribution (RAD) method across a variety of dimensions and differential equations. The results demonstrate that RSmote not only achieves or exceeds the accuracy of RAD but also significantly reduces memory usage, making it particularly advantageous in high-dimensional scenarios. These contributions position RSmote as a robust and resource-efficient solution for solving complex partial differential equations, especially when computational constraints are a critical consideration.
<div id='section'>Paperid: <span id='pid'>588, <a href='https://arxiv.org/pdf/2412.05197.pdf' target='_blank'>https://arxiv.org/pdf/2412.05197.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiming Li, Jiacheng Qiu, Sylvain Calinon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05197">A Riemannian Take on Distance Fields and Geodesic Flows in Robotics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distance functions are crucial in robotics for representing spatial relationships between the robot and the environment. It provides an implicit representation of continuous and differentiable shapes, which can seamlessly be combined with control, optimization, and learning techniques. While standard distance fields rely on the Euclidean metric, many robotic tasks inherently involve non-Euclidean structures. To this end, we generalize the use of Euclidean distance fields to more general metric spaces by solving a Riemannian eikonal equation, a first-order partial differential equation, whose solution defines a distance field and its associated gradient flow on the manifold, enabling the computation of geodesics and globally length-minimizing paths. We show that this \emph{geodesic distance field} can also be exploited in the robot configuration space. To realize this concept, we exploit physics-informed neural networks to solve the eikonal equation for high-dimensional spaces, which provides a flexible and scalable representation without the need for discretization. Furthermore, a variant of our neural eikonal solver is introduced, which enables the gradient flow to march across both task and configuration spaces. As an example of application, we validate the proposed approach in an energy-aware motion generation task. This is achieved by considering a manifold defined by a Riemannian metric in configuration space, effectively taking the property of the robot's dynamics into account. Our approach produces minimal-energy trajectories for a 7-axis Franka robot by iteratively tracking geodesics through gradient flow backpropagation.
<div id='section'>Paperid: <span id='pid'>589, <a href='https://arxiv.org/pdf/2411.14691.pdf' target='_blank'>https://arxiv.org/pdf/2411.14691.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hansol Lim, Jee Won Lee, Jonathan Boyack, Jongseong Brad Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14691">EV-PINN: A Physics-Informed Neural Network for Predicting Electric Vehicle Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An onboard prediction of dynamic parameters (e.g. Aerodynamic drag, rolling resistance) enables accurate path planning for EVs. This paper presents EV-PINN, a Physics-Informed Neural Network approach in predicting instantaneous battery power and cumulative energy consumption during cruising while generalizing to the nonlinear dynamics of an EV. Our method learns real-world parameters such as motor efficiency, regenerative braking efficiency, vehicle mass, coefficient of aerodynamic drag, and coefficient of rolling resistance using automatic differentiation based on dynamics and ensures consistency with ground truth vehicle data. EV-PINN was validated using 15 and 35 minutes of in-situ battery log data from the Tesla Model 3 Long Range and Tesla Model S, respectively. With only vehicle speed and time as inputs, our model achieves high accuracy and generalization to dynamics, with validation losses of 0.002195 and 0.002292, respectively. This demonstrates EV-PINN's effectiveness in estimating parameters and predicting battery usage under actual driving conditions without the need for additional sensors.
<div id='section'>Paperid: <span id='pid'>590, <a href='https://arxiv.org/pdf/2411.05866.pdf' target='_blank'>https://arxiv.org/pdf/2411.05866.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihuai Zhang, Ruiguo Zhong, Huan Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.05866">Mitigating Stop-and-Go Traffic Congestion with Operator Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel neural operator learning framework for designing boundary control to mitigate stop-and-go congestion on freeways. The freeway traffic dynamics are described by second-order coupled hyperbolic partial differential equations (PDEs). The proposed framework learns feedback boundary control strategies from the closed-loop PDE solution using backstepping controllers, which are widely employed for boundary stabilization of PDE systems. The PDE backstepping control design is time-consuming and requires intensive depth of expertise, since it involves constructing and solving backstepping control kernels. To address these challenges, we present neural operator (NO) learning schemes for the ARZ traffic system that not only ensure closed-loop stability robust to parameter and initial condition variations but also accelerate boundary controller computation. The stability guarantee of the NO-approximated control laws is obtained using Lyapunov analysis. We further propose the physics-informed neural operator (PINO) to reduce the reliance on extensive training data. The performance of the NO schemes is evaluated by simulated and real traffic data, compared with the benchmark backstepping controller, a Proportional Integral (PI) controller, and a PINN-based controller. The NO-approximated methods achieve a computational speedup of approximately 300 times with only a 1% error trade-off compared to the backstepping controller, while outperforming the other two controllers in both accuracy and computational efficiency. The robustness of the NO schemes is validated using real traffic data, and tested across various initial traffic conditions and demand scenarios. The results show that neural operators can significantly expedite and simplify the process of obtaining controllers for traffic PDE systems with great potential application for traffic management.
<div id='section'>Paperid: <span id='pid'>591, <a href='https://arxiv.org/pdf/2411.01665.pdf' target='_blank'>https://arxiv.org/pdf/2411.01665.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youngsun Wi, Jayjun Lee, Miquel Oller, Nima Fazeli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.01665">Neural Inverse Source Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reconstructing unknown external source functions is an important perception capability for a large range of robotics domains including manipulation, aerial, and underwater robotics. In this work, we propose a Physics-Informed Neural Network (PINN [1]) based approach for solving the inverse source problems in robotics, jointly identifying unknown source functions and the complete state of a system given partial and noisy observations. Our approach demonstrates several advantages over prior works (Finite Element Methods (FEM) and data-driven approaches): it offers flexibility in integrating diverse constraints and boundary conditions; eliminates the need for complex discretizations (e.g., meshing); easily accommodates gradients from real measurements; and does not limit performance based on the diversity and quality of training data. We validate our method across three simulation and real-world scenarios involving up to 4th order partial differential equations (PDEs), constraints such as Signorini and Dirichlet, and various regression losses including Chamfer distance and L2 norm.
<div id='section'>Paperid: <span id='pid'>592, <a href='https://arxiv.org/pdf/2410.19492.pdf' target='_blank'>https://arxiv.org/pdf/2410.19492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefan Wahl, Armand Rousselot, Felix Draxler, Henrik Schopmans, Ullrich KÃ¶the
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19492">TRADE: Transfer of Distributions between External Conditions with Normalizing Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling distributions that depend on external control parameters is a common scenario in diverse applications like molecular simulations, where system properties like temperature affect molecular configurations. Despite the relevance of these applications, existing solutions are unsatisfactory as they require severely restricted model architectures or rely on energy-based training, which is prone to instability. We introduce TRADE, which overcomes these limitations by formulating the learning process as a boundary value problem. By initially training the model for a specific condition using either i.i.d.~samples or backward KL training, we establish a boundary distribution. We then propagate this information across other conditions using the gradient of the unnormalized density with respect to the external parameter. This formulation, akin to the principles of physics-informed neural networks, allows us to efficiently learn parameter-dependent distributions without restrictive assumptions. Experimentally, we demonstrate that TRADE achieves excellent results in a wide range of applications, ranging from Bayesian inference and molecular simulations to physical lattice models.
<div id='section'>Paperid: <span id='pid'>593, <a href='https://arxiv.org/pdf/2410.13962.pdf' target='_blank'>https://arxiv.org/pdf/2410.13962.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Subhadip Ghosh, Aydin Zaboli, Junho Hong, Jaerock Kwon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13962">A Physics-Informed Context-Aware Approach for Anomaly Detection in Tele-driving Operations Under False Data Injection Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tele-operated driving (ToD) systems are special types of cyber-physical systems (CPSs) where the operator remotely controls the steering, acceleration, and braking actions of the vehicle. Malicious actors may inject false data in communication channels to manipulate the tele-operators driving commands to cause harm. Hence, protection of this communication is necessary for the safe operation of the target vehicle. However, according to the National Institute of Standards and Technology (NIST) cybersecurity framework, protection merely is not enough and the detection of an attack is necessary. Moreover, UN R155 mandates that security incidents across vehicle fleets be detected and logged. Thus, cyber-physical threats of ToD are modeled with an attack-centric approach in this paper. Then, an attack model with false data injection (FDI) on steering control commands is created from real vehicle data. The risk of this attack model is assessed for a last-mile delivery (LMD) application. Finally, a physics-informed context-aware anomaly detection system (PCADS) is proposed to detect such false injection attacks, and preliminary experimental results are presented to validate the model.
<div id='section'>Paperid: <span id='pid'>594, <a href='https://arxiv.org/pdf/2409.20383.pdf' target='_blank'>https://arxiv.org/pdf/2409.20383.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yesom Park, Changhoon Song, Myungjoo Kang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.20383">Beyond Derivative Pathology of PINNs: Variable Splitting Strategy with Convergence Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have recently emerged as effective methods for solving partial differential equations (PDEs) in various problems. Substantial research focuses on the failure modes of PINNs due to their frequent inaccuracies in predictions. However, most are based on the premise that minimizing the loss function to zero causes the network to converge to a solution of the governing PDE. In this study, we prove that PINNs encounter a fundamental issue that the premise is invalid. We also reveal that this issue stems from the inability to regulate the behavior of the derivatives of the predicted solution. Inspired by the \textit{derivative pathology} of PINNs, we propose a \textit{variable splitting} strategy that addresses this issue by parameterizing the gradient of the solution as an auxiliary variable. We demonstrate that using the auxiliary variable eludes derivative pathology by enabling direct monitoring and regulation of the gradient of the predicted solution. Moreover, we prove that the proposed method guarantees convergence to a generalized solution for second-order linear PDEs, indicating its applicability to various problems.
<div id='section'>Paperid: <span id='pid'>595, <a href='https://arxiv.org/pdf/2409.06560.pdf' target='_blank'>https://arxiv.org/pdf/2409.06560.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Glyn-Davies, Arnaud Vadeboncoeur, O. Deniz Akyildiz, Ieva Kazlauskaite, Mark Girolami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06560">A Primer on Variational Inference for Physics-Informed Deep Generative Modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Variational inference (VI) is a computationally efficient and scalable methodology for approximate Bayesian inference. It strikes a balance between accuracy of uncertainty quantification and practical tractability. It excels at generative modelling and inversion tasks due to its built-in Bayesian regularisation and flexibility, essential qualities for physics related problems. For such problems, the underlying physical model determines the dependence between variables of interest, which in turn will require a tailored derivation for the central VI learning objective. Furthermore, in many physical inference applications this structure has rich meaning and is essential for accurately capturing the dynamics of interest. In this paper, we provide an accessible and thorough technical introduction to VI for forward and inverse problems, guiding the reader through standard derivations of the VI framework and how it can best be realized through deep learning. We then review and unify recent literature exemplifying the flexibility allowed by VI. This paper is designed for a general scientific audience looking to solve physics-based problems with an emphasis on uncertainty quantification
<div id='section'>Paperid: <span id='pid'>596, <a href='https://arxiv.org/pdf/2409.01410.pdf' target='_blank'>https://arxiv.org/pdf/2409.01410.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vyacheslav Kungurtsev, Yuanfang Peng, Jianyang Gu, Saeed Vahidian, Anthony Quinn, Fadwa Idlahcen, Yiran Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01410">Dataset Distillation from First Principles: Integrating Core Information Extraction and Purposeful Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dataset distillation (DD) is an increasingly important technique that focuses on constructing a synthetic dataset capable of capturing the core information in training data to achieve comparable performance in models trained on the latter. While DD has a wide range of applications, the theory supporting it is less well evolved. New methods of DD are compared on a common set of benchmarks, rather than oriented towards any particular learning task. In this work, we present a formal model of DD, arguing that a precise characterization of the underlying optimization problem must specify the inference task associated with the application of interest. Without this task-specific focus, the DD problem is under-specified, and the selection of a DD algorithm for a particular task is merely heuristic. Our formalization reveals novel applications of DD across different modeling environments. We analyze existing DD methods through this broader lens, highlighting their strengths and limitations in terms of accuracy and faithfulness to optimal DD operation. Finally, we present numerical results for two case studies important in contemporary settings. Firstly, we address a critical challenge in medical data analysis: merging the knowledge from different datasets composed of intersecting, but not identical, sets of features, in order to construct a larger dataset in what is usually a small sample setting. Secondly, we consider out-of-distribution error across boundary conditions for physics-informed neural networks (PINNs), showing the potential for DD to provide more physically faithful data. By establishing this general formulation of DD, we aim to establish a new research paradigm by which DD can be understood and from which new DD techniques can arise.
<div id='section'>Paperid: <span id='pid'>597, <a href='https://arxiv.org/pdf/2408.13101.pdf' target='_blank'>https://arxiv.org/pdf/2408.13101.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sai Karthikeya Vemuri, Tim BÃ¼chner, Julia Niebling, Joachim Denzler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.13101">Functional Tensor Decompositions for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have shown continuous and increasing promise in approximating partial differential equations (PDEs), although they remain constrained by the curse of dimensionality. In this paper, we propose a generalized PINN version of the classical variable separable method. To do this, we first show that, using the universal approximation theorem, a multivariate function can be approximated by the outer product of neural networks, whose inputs are separated variables. We leverage tensor decomposition forms to separate the variables in a PINN setting. By employing Canonic Polyadic (CP), Tensor-Train (TT), and Tucker decomposition forms within the PINN framework, we create robust architectures for learning multivariate functions from separate neural networks connected by outer products. Our methodology significantly enhances the performance of PINNs, as evidenced by improved results on complex high-dimensional PDEs, including the 3d Helmholtz and 5d Poisson equations, among others. This research underscores the potential of tensor decomposition-based variably separated PINNs to surpass the state-of-the-art, offering a compelling solution to the dimensionality challenge in PDE approximation.
<div id='section'>Paperid: <span id='pid'>598, <a href='https://arxiv.org/pdf/2407.13981.pdf' target='_blank'>https://arxiv.org/pdf/2407.13981.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiwei Cheng, Xiangxin Zhou, Yuwei Yang, Yu Bao, Quanquan Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13981">Decomposed Direct Preference Optimization for Structure-Based Drug Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models have achieved promising results for Structure-Based Drug Design (SBDD). Nevertheless, high-quality protein subpocket and ligand data are relatively scarce, which hinders the models' generation capabilities. Recently, Direct Preference Optimization (DPO) has emerged as a pivotal tool for aligning generative models with human preferences. In this paper, we propose DecompDPO, a structure-based optimization method aligns diffusion models with pharmaceutical needs using multi-granularity preference pairs. DecompDPO introduces decomposition into the optimization objectives and obtains preference pairs at the molecule or decomposed substructure level based on each objective's decomposability. Additionally, DecompDPO introduces a physics-informed energy term to ensure reasonable molecular conformations in the optimization results. Notably, DecompDPO can be effectively used for two main purposes: (1) fine-tuning pretrained diffusion models for molecule generation across various protein families, and (2) molecular optimization given a specific protein subpocket after generation. Extensive experiments on the CrossDocked2020 benchmark show that DecompDPO significantly improves model performance, achieving up to 95.2% Med. High Affinity and a 36.2% success rate for molecule generation, and 100% Med. High Affinity and a 52.1% success rate for molecular optimization.
<div id='section'>Paperid: <span id='pid'>599, <a href='https://arxiv.org/pdf/2405.20836.pdf' target='_blank'>https://arxiv.org/pdf/2405.20836.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chinmay Datar, Taniya Kapoor, Abhishek Chandra, Qing Sun, Iryna Burak, Erik Lien Bolager, Anna Veselovska, Massimo Fornasier, Felix Dietrich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.20836">Solving partial differential equations with sampled neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Approximation of solutions to partial differential equations (PDE) is an important problem in computational science and engineering. Using neural networks as an ansatz for the solution has proven a challenge in terms of training time and approximation accuracy. In this contribution, we discuss how sampling the hidden weights and biases of the ansatz network from data-agnostic and data-dependent probability distributions allows us to progress on both challenges. In most examples, the random sampling schemes outperform iterative, gradient-based optimization of physics-informed neural networks regarding training time and accuracy by several orders of magnitude. For time-dependent PDE, we construct neural basis functions only in the spatial domain and then solve the associated ordinary differential equation with classical methods from scientific computing over a long time horizon. This alleviates one of the greatest challenges for neural PDE solvers because it does not require us to parameterize the solution in time. For second-order elliptic PDE in Barron spaces, we prove the existence of sampled networks with $L^2$ convergence to the solution. We demonstrate our approach on several time-dependent and static PDEs. We also illustrate how sampled networks can effectively solve inverse problems in this setting. Benefits compared to common numerical schemes include spectral convergence and mesh-free construction of basis functions.
<div id='section'>Paperid: <span id='pid'>600, <a href='https://arxiv.org/pdf/2405.20836.pdf' target='_blank'>https://arxiv.org/pdf/2405.20836.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chinmay Datar, Taniya Kapoor, Abhishek Chandra, Qing Sun, Erik Lien Bolager, Iryna Burak, Anna Veselovska, Massimo Fornasier, Felix Dietrich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.20836">Fast training of accurate physics-informed neural networks without gradient descent</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving time-dependent Partial Differential Equations (PDEs) is one of the most critical problems in computational science. While Physics-Informed Neural Networks (PINNs) offer a promising framework for approximating PDE solutions, their accuracy and training speed are limited by two core barriers: gradient-descent-based iterative optimization over complex loss landscapes and non-causal treatment of time as an extra spatial dimension. We present Frozen-PINN, a novel PINN based on the principle of space-time separation that leverages random features instead of training with gradient descent, and incorporates temporal causality by construction. On eight PDE benchmarks, including challenges such as extreme advection speeds, shocks, and high dimensionality, Frozen-PINNs achieve superior training efficiency and accuracy over state-of-the-art PINNs, often by several orders of magnitude. Our work addresses longstanding training and accuracy bottlenecks of PINNs, delivering quickly trainable, highly accurate, and inherently causal PDE solvers, a combination that prior methods could not realize. Our approach challenges the reliance of PINNs on stochastic gradient-descent-based methods and specialized hardware, leading to a paradigm shift in PINN training and providing a challenging benchmark for the community.
<div id='section'>Paperid: <span id='pid'>601, <a href='https://arxiv.org/pdf/2405.14096.pdf' target='_blank'>https://arxiv.org/pdf/2405.14096.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenrui Hao, Xinliang Liu, Yahong Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14096">Newton Informed Neural Operator for Computing Multiple Solutions of Nonlinear Partials Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving nonlinear partial differential equations (PDEs) with multiple solutions using neural networks has found widespread applications in various fields such as physics, biology, and engineering. However, classical neural network methods for solving nonlinear PDEs, such as Physics-Informed Neural Networks (PINN), Deep Ritz methods, and DeepONet, often encounter challenges when confronted with the presence of multiple solutions inherent in the nonlinear problem. These methods may encounter ill-posedness issues. In this paper, we propose a novel approach called the Newton Informed Neural Operator, which builds upon existing neural network techniques to tackle nonlinearities. Our method combines classical Newton methods, addressing well-posed problems, and efficiently learns multiple solutions in a single learning process while requiring fewer supervised data points compared to existing neural network methods.
<div id='section'>Paperid: <span id='pid'>602, <a href='https://arxiv.org/pdf/2403.15415.pdf' target='_blank'>https://arxiv.org/pdf/2403.15415.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Apolline Mellot, Antoine Collas, Sylvain Chevallier, Denis Engemann, Alexandre Gramfort
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15415">Physics-informed and Unsupervised Riemannian Domain Adaptation for Machine Learning on Heterogeneous EEG Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Combining electroencephalogram (EEG) datasets for supervised machine learning (ML) is challenging due to session, subject, and device variability. ML algorithms typically require identical features at train and test time, complicating analysis due to varying sensor numbers and positions across datasets. Simple channel selection discards valuable data, leading to poorer performance, especially with datasets sharing few channels. To address this, we propose an unsupervised approach leveraging EEG signal physics. We map EEG channels to fixed positions using field interpolation, facilitating source-free domain adaptation. Leveraging Riemannian geometry classification pipelines and transfer learning steps, our method demonstrates robust performance in brain-computer interface (BCI) tasks and potential biomarker applications. Comparative analysis against a statistical-based approach known as Dimensionality Transcending, a signal-based imputation called ComImp, source-dependent methods, as well as common channel selection and spherical spline interpolation, was conducted with leave-one-dataset-out validation on six public BCI datasets for a right-hand/left-hand classification task. Numerical experiments show that in the presence of few shared channels in train and test, the field interpolation consistently outperforms other methods, demonstrating enhanced classification performance across all datasets. When more channels are shared, field interpolation was found to be competitive with other methods and faster to compute than source-dependent methods.
<div id='section'>Paperid: <span id='pid'>603, <a href='https://arxiv.org/pdf/2402.17232.pdf' target='_blank'>https://arxiv.org/pdf/2402.17232.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiao Zhuang, Chris Ziyi Yao, Zhongqiang Zhang, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17232">Two-scale Neural Networks for Partial Differential Equations with Small Parameters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a two-scale neural network method for solving partial differential equations (PDEs) with small parameters using physics-informed neural networks (PINNs). We directly incorporate the small parameters into the architecture of neural networks. The proposed method enables solving PDEs with small parameters in a simple fashion, without adding Fourier features or other computationally taxing searches of truncation parameters. Various numerical examples demonstrate reasonable accuracy in capturing features of large derivatives in the solutions caused by small parameters.
<div id='section'>Paperid: <span id='pid'>604, <a href='https://arxiv.org/pdf/2402.16587.pdf' target='_blank'>https://arxiv.org/pdf/2402.16587.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmad Abubakar, Yahya Zweiri, AbdelGafoor Haddad, Mubarak Yakubu, Ruqayya Alhammadi, Lakmal Seneviratne
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16587">Physics-Informed LSTM-Based Delay Compensation Framework for Teleoperated UGVs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bilateral teleoperation of low-speed Unmanned Ground Vehicles (UGVs) on soft terrains is crucial for applications like lunar exploration, offering effective control of terrain-induced longitudinal slippage. However, latency arising from transmission delays over a network presents a challenge in maintaining high-fidelity closed-loop integration, potentially hindering UGV controls and leading to poor command-tracking performance. To address this challenge, this paper proposes a novel predictor framework that employs a Physics-informed Long Short-Term Memory (PiLSTM) network for designing bilateral teleoperator controls that effectively compensate for large delays. Contrasting with conventional model-free predictor frameworks, which are limited by their linear nature in capturing nonlinear and temporal dynamic behaviors, our approach integrates the LSTM structure with physical constraints for enhanced performance and better generalization across varied scenarios. Specifically, four distinct predictors were employed in the framework: two compensate for forward delays, while the other two compensate for backward delays. Due to their effectiveness in learning from temporal data, the proposed PiLSTM framework demonstrates a 26.1\ improvement in delay compensation over the conventional model-free predictors for large delays in open-loop case studies. Subsequently, experiments were conducted to validate the efficacy of the framework in close-loop scenarios, particularly to compensate for the real-network delays experienced by teleoperated UGVs coupled with longitudinal slippage. The results confirm the proposed framework is effective in restoring the fidelity of the closed-loop integration. This improvement is showcased through improved performance and transparency, which leads to excellent command-tracking performance.
<div id='section'>Paperid: <span id='pid'>605, <a href='https://arxiv.org/pdf/2402.11126.pdf' target='_blank'>https://arxiv.org/pdf/2402.11126.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Penwarden, Houman Owhadi, Robert M. Kirby
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11126">Kolmogorov n-Widths for Multitask Physics-Informed Machine Learning (PIML) Methods: Towards Robust Metrics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning (PIML) as a means of solving partial differential equations (PDE) has garnered much attention in the Computational Science and Engineering (CS&E) world. This topic encompasses a broad array of methods and models aimed at solving a single or a collection of PDE problems, called multitask learning. PIML is characterized by the incorporation of physical laws into the training process of machine learning models in lieu of large data when solving PDE problems. Despite the overall success of this collection of methods, it remains incredibly difficult to analyze, benchmark, and generally compare one approach to another. Using Kolmogorov n-widths as a measure of effectiveness of approximating functions, we judiciously apply this metric in the comparison of various multitask PIML architectures. We compute lower accuracy bounds and analyze the model's learned basis functions on various PDE problems. This is the first objective metric for comparing multitask PIML architectures and helps remove uncertainty in model validation from selective sampling and overfitting. We also identify avenues of improvement for model architectures, such as the choice of activation function, which can drastically affect model generalization to "worst-case" scenarios, which is not observed when reporting task-specific errors. We also incorporate this metric into the optimization process through regularization, which improves the models' generalizability over the multitask PDE problem.
<div id='section'>Paperid: <span id='pid'>606, <a href='https://arxiv.org/pdf/2402.07251.pdf' target='_blank'>https://arxiv.org/pdf/2402.07251.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Chen, Gonzalo E. Constante Flores, Can Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07251">Physics-Informed Neural Networks with Hard Linear Equality Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Surrogate modeling is used to replace computationally expensive simulations. Neural networks have been widely applied as surrogate models that enable efficient evaluations over complex physical systems. Despite this, neural networks are data-driven models and devoid of any physics. The incorporation of physics into neural networks can improve generalization and data efficiency. The physics-informed neural network (PINN) is an approach to leverage known physical constraints present in the data, but it cannot strictly satisfy them in the predictions. This work proposes a novel physics-informed neural network, KKT-hPINN, which rigorously guarantees hard linear equality constraints through projection layers derived from KKT conditions. Numerical experiments on Aspen models of a continuous stirred-tank reactor (CSTR) unit, an extractive distillation subsystem, and a chemical plant demonstrate that this model can further enhance the prediction accuracy.
<div id='section'>Paperid: <span id='pid'>607, <a href='https://arxiv.org/pdf/2402.01868.pdf' target='_blank'>https://arxiv.org/pdf/2402.01868.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pratik Rathore, Weimu Lei, Zachary Frangella, Lu Lu, Madeleine Udell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01868">Challenges in Training PINNs: A Loss Landscape Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper explores challenges in training Physics-Informed Neural Networks (PINNs), emphasizing the role of the loss landscape in the training process. We examine difficulties in minimizing the PINN loss function, particularly due to ill-conditioning caused by differential operators in the residual term. We compare gradient-based optimizers Adam, L-BFGS, and their combination Adam+L-BFGS, showing the superiority of Adam+L-BFGS, and introduce a novel second-order optimizer, NysNewton-CG (NNCG), which significantly improves PINN performance. Theoretically, our work elucidates the connection between ill-conditioned differential operators and ill-conditioning in the PINN loss and shows the benefits of combining first- and second-order optimization methods. Our work presents valuable insights and more powerful optimization strategies for training PINNs, which could improve the utility of PINNs for solving difficult partial differential equations.
<div id='section'>Paperid: <span id='pid'>608, <a href='https://arxiv.org/pdf/2401.15122.pdf' target='_blank'>https://arxiv.org/pdf/2401.15122.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengchao Liu, Weitao Du, Hannan Xu, Yanjing Li, Zhuoxinran Li, Vignesh Bhethanabotla, Divin Yan, Christian Borgs, Anima Anandkumar, Hongyu Guo, Jennifer Chayes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.15122">A Multi-Grained Symmetric Differential Equation Model for Learning Protein-Ligand Binding Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In drug discovery, molecular dynamics (MD) simulation for protein-ligand binding provides a powerful tool for predicting binding affinities, estimating transport properties, and exploring pocket sites. There has been a long history of improving the efficiency of MD simulations through better numerical methods and, more recently, by utilizing machine learning (ML) methods. Yet, challenges remain, such as accurate modeling of extended-timescale simulations. To address this issue, we propose NeuralMD, the first ML surrogate that can facilitate numerical MD and provide accurate simulations in protein-ligand binding dynamics. We propose a principled approach that incorporates a novel physics-informed multi-grained group symmetric framework. Specifically, we propose (1) the BindingNet model that satisfies group symmetry using vector frames and captures the multi-level protein-ligand interactions, and (2) an augmented neural differential equation solver that learns the trajectory under Newtonian mechanics. For the experiment, we design ten single-trajectory and three multi-trajectory binding simulation tasks. We demonstrate the efficiency and effectiveness of NeuralMD, achieving over 1K$\times$ speedup compared to standard numerical MD simulations. NeuralMD also outperforms all other ML approaches, achieving up to 15$\times$ reduction in reconstruction error and 70% increase in validity. Additionally, we qualitatively illustrate that the oscillations in the predicted trajectories align more closely with ground-truth dynamics than those of other machine-learning methods. We believe NeuralMD paves the foundation for a new research paradigm in simulating protein-ligand dynamics.
<div id='section'>Paperid: <span id='pid'>609, <a href='https://arxiv.org/pdf/2401.08667.pdf' target='_blank'>https://arxiv.org/pdf/2401.08667.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sunwoong Yang, Hojin Kim, Yoonpyo Hong, Kwanjung Yee, Romit Maulik, Namwoo Kang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08667">Data-Driven Physics-Informed Neural Networks: A Digital Twin Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study explores the potential of physics-informed neural networks (PINNs) for the realization of digital twins (DT) from various perspectives. First, various adaptive sampling approaches for collocation points are investigated to verify their effectiveness in the mesh-free framework of PINNs, which allows automated construction of virtual representation without manual mesh generation. Then, the overall performance of the data-driven PINNs (DD-PINNs) framework is examined, which can utilize the acquired datasets in DT scenarios. Its scalability to more general physics is validated within parametric Navier-Stokes equations, where PINNs do not need to be retrained as the Reynolds number varies. In addition, since datasets can be often collected from different fidelity/sparsity in practice, multi-fidelity DD-PINNs are also proposed and evaluated. They show remarkable prediction performance even in the extrapolation tasks, with $42\sim62\%$ improvement over the single-fidelity approach. Finally, the uncertainty quantification performance of multi-fidelity DD-PINNs is investigated by the ensemble method to verify their potential in DT, where an accurate measure of predictive uncertainty is critical. The DD-PINN frameworks explored in this study are found to be more suitable for DT scenarios than traditional PINNs from the above perspectives, bringing engineers one step closer to seamless DT realization.
<div id='section'>Paperid: <span id='pid'>610, <a href='https://arxiv.org/pdf/2401.02403.pdf' target='_blank'>https://arxiv.org/pdf/2401.02403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pouyan Sajadi, Mostafa Rahmani Dehaghani, Yifan Tang, G. Gary Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02403">Real-Time 2D Temperature Field Prediction in Metal Additive Manufacturing Using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting the temperature field in metal additive manufacturing (AM) processes is critical to preventing overheating, adjusting process parameters, and ensuring process stability. While physics-based computational models offer precision, they are often time-consuming and unsuitable for real-time predictions and online control in iterative design scenarios. Conversely, machine learning models rely heavily on high-quality datasets, which can be costly and challenging to obtain within the metal AM domain. Our work addresses this by introducing a physics-informed neural network framework specifically designed for temperature field prediction in metal AM. This framework incorporates a physics-informed input, physics-informed loss function, and a Convolutional Long Short-Term Memory (ConvLSTM) architecture. Utilizing real-time temperature data from the process, our model predicts 2D temperature fields for future timestamps across diverse geometries, deposition patterns, and process parameters. We validate the proposed framework in two scenarios: full-field temperature prediction for a thin wall and 2D temperature field prediction for cylinder and cubic parts, demonstrating errors below 3% and 1%, respectively. Our proposed framework exhibits the flexibility to be applied across diverse scenarios with varying process parameters, geometries, and deposition patterns.
<div id='section'>Paperid: <span id='pid'>611, <a href='https://arxiv.org/pdf/2312.02770.pdf' target='_blank'>https://arxiv.org/pdf/2312.02770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenguang Zhao, Huan Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.02770">Learning "Look-Ahead" Nonlocal Traffic Dynamics in a Ring Road</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The macroscopic traffic flow model is widely used for traffic control and management. To incorporate drivers' anticipative behaviors and to remove impractical speed discontinuity inherent in the classic Lighthill-Whitham-Richards (LWR) traffic model, nonlocal partial differential equation (PDE) models with ``look-ahead" dynamics have been proposed, which assume that the speed is a function of weighted downstream traffic density. However, it lacks data validation on two important questions: whether there exist nonlocal dynamics, and how the length and weight of the ``look-ahead" window affect the spatial temporal propagation of traffic densities. In this paper, we adopt traffic trajectory data from a ring-road experiment and design a physics-informed neural network to learn the fundamental diagram and look-ahead kernel that best fit the data, and reinvent a data-enhanced nonlocal LWR model via minimizing the loss function combining the data discrepancy and the nonlocal model discrepancy. Results show that the learned nonlocal LWR yields a more accurate prediction of traffic wave propagation in three different scenarios: stop-and-go oscillations, congested, and free traffic. We first demonstrate the existence of ``look-ahead" effect with real traffic data. The optimal nonlocal kernel is found out to take a length of around 35 to 50 meters, and the kernel weight within 5 meters accounts for the majority of the nonlocal effect. Our results also underscore the importance of choosing a priori physics in machine learning models.
<div id='section'>Paperid: <span id='pid'>612, <a href='https://arxiv.org/pdf/2310.20360.pdf' target='_blank'>https://arxiv.org/pdf/2310.20360.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arnulf Jentzen, Benno Kuckuck, Philippe von Wurstemberger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.20360">Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-Åojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet have any background in deep learning at all and would like to gain a solid foundation as well as for practitioners who would like to obtain a firmer mathematical understanding of the objects and methods considered in deep learning.
<div id='section'>Paperid: <span id='pid'>613, <a href='https://arxiv.org/pdf/2310.02913.pdf' target='_blank'>https://arxiv.org/pdf/2310.02913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cristiano Fanelli, James Giroux
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02913">ELUQuant: Event-Level Uncertainty Quantification in Deep Inelastic Scattering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a physics-informed Bayesian Neural Network (BNN) with flow approximated posteriors using multiplicative normalizing flows (MNF) for detailed uncertainty quantification (UQ) at the physics event-level. Our method is capable of identifying both heteroskedastic aleatoric and epistemic uncertainties, providing granular physical insights. Applied to Deep Inelastic Scattering (DIS) events, our model effectively extracts the kinematic variables $x$, $Q^2$, and $y$, matching the performance of recent deep learning regression techniques but with the critical enhancement of event-level UQ. This detailed description of the underlying uncertainty proves invaluable for decision-making, especially in tasks like event filtering. It also allows for the reduction of true inaccuracies without directly accessing the ground truth. A thorough DIS simulation using the H1 detector at HERA indicates possible applications for the future EIC. Additionally, this paves the way for related tasks such as data quality monitoring and anomaly detection. Remarkably, our approach effectively processes large samples at high rates.
<div id='section'>Paperid: <span id='pid'>614, <a href='https://arxiv.org/pdf/2310.02286.pdf' target='_blank'>https://arxiv.org/pdf/2310.02286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Roussel Desmond Nzoyem, David A. W. Barton, Tom Deakin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02286">A Comparison of Mesh-Free Differentiable Programming and Data-Driven Strategies for Optimal Control under PDE Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The field of Optimal Control under Partial Differential Equations (PDE) constraints is rapidly changing under the influence of Deep Learning and the accompanying automatic differentiation libraries. Novel techniques like Physics-Informed Neural Networks (PINNs) and Differentiable Programming (DP) are to be contrasted with established numerical schemes like Direct-Adjoint Looping (DAL). We present a comprehensive comparison of DAL, PINN, and DP using a general-purpose mesh-free differentiable PDE solver based on Radial Basis Functions. Under Laplace and Navier-Stokes equations, we found DP to be extremely effective as it produces the most accurate gradients; thriving even when DAL fails and PINNs struggle. Additionally, we provide a detailed benchmark highlighting the limited conditions under which any of those methods can be efficiently used. Our work provides a guide to Optimal Control practitioners and connects them further to the Deep Learning community.
<div id='section'>Paperid: <span id='pid'>615, <a href='https://arxiv.org/pdf/2306.17648.pdf' target='_blank'>https://arxiv.org/pdf/2306.17648.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alena KopaniÄÃ¡kovÃ¡, Hardik Kothari, George Em Karniadakis, Rolf Krause
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.17648">Enhancing training of physics-informed neural networks using domain-decomposition based preconditioning strategies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose to enhance the training of physics-informed neural networks (PINNs). To this aim, we introduce nonlinear additive and multiplicative preconditioning strategies for the widely used L-BFGS optimizer. The nonlinear preconditioners are constructed by utilizing the Schwarz domain-decomposition framework, where the parameters of the network are decomposed in a layer-wise manner. Through a series of numerical experiments, we demonstrate that both, additive and multiplicative preconditioners significantly improve the convergence of the standard L-BFGS optimizer, while providing more accurate solutions of the underlying partial differential equations. Moreover, the additive preconditioner is inherently parallel, thus giving rise to a novel approach to model parallelism.
<div id='section'>Paperid: <span id='pid'>616, <a href='https://arxiv.org/pdf/2305.20006.pdf' target='_blank'>https://arxiv.org/pdf/2305.20006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manchang Jin, Gaosheng Liu, Kunshu Hu, Xin Luo, Kun Li, Jingyu Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.20006">Physics-Informed Ensemble Representation for Light-Field Image Super-Resolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent learning-based approaches have achieved significant progress in light field (LF) image super-resolution (SR) by exploring convolution-based or transformer-based network structures. However, LF imaging has many intrinsic physical priors that have not been fully exploited. In this paper, we analyze the coordinate transformation of the LF imaging process to reveal the geometric relationship in the LF images. Based on such geometric priors, we introduce a new LF subspace of virtual-slit images (VSI) that provide sub-pixel information complementary to sub-aperture images. To leverage the abundant correlation across the four-dimensional data with manageable complexity, we propose learning ensemble representation of all $C_4^2$ LF subspaces for more effective feature extraction. To super-resolve image structures from undersampled LF data, we propose a geometry-aware decoder, named EPIXformer, which constrains the transformer's operational searching regions with a LF physical prior. Experimental results on both spatial and angular SR tasks demonstrate that the proposed method outperforms other state-of-the-art schemes, especially in handling various disparities.
<div id='section'>Paperid: <span id='pid'>617, <a href='https://arxiv.org/pdf/2305.08174.pdf' target='_blank'>https://arxiv.org/pdf/2305.08174.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yesom Park, Chang hoon Song, Jooyoung Hahn, Myungjoo Kang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.08174">ReSDF: Redistancing Implicit Surfaces using Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a deep-learning-based method for recovering a signed distance function (SDF) of a given hypersurface represented by an implicit level set function. Using the flexibility of constructing a neural network, we use an augmented network by defining an auxiliary output to represent the gradient of the SDF. There are three advantages of the augmented network; (i) the target interface is accurately captured, (ii) the gradient has a unit norm, and (iii) two outputs are approximated by a single network. Moreover, unlike a conventional loss term which uses a residual of the eikonal equation, a novel training objective consisting of three loss terms is designed. The first loss function enforces a pointwise matching between two outputs of the augmented network. The second loss function leveraged by a geometric characteristic of the SDF imposes the shortest path obtained by the gradient. The third loss function regularizes a singularity of the SDF caused by discontinuities of the gradient. Numerical results across a wide range of complex and irregular interfaces in two and three-dimensional domains confirm the effectiveness and accuracy of the proposed method. We also compare the results of the proposed method with physics-informed neural networks approaches and the fast marching method.
<div id='section'>Paperid: <span id='pid'>618, <a href='https://arxiv.org/pdf/2305.01243.pdf' target='_blank'>https://arxiv.org/pdf/2305.01243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Zhang, Xiaohan Lin, Weinan E, Yi Qin Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.01243">Invertible Coarse Graining with Physics-Informed Generative Artificial Intelligence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiscale molecular modeling is widely applied in scientific research of molecular properties over large time and length scales. Two specific challenges are commonly present in multiscale modeling, provided that information between the coarse and fine representations of molecules needs to be properly exchanged: One is to construct coarse grained models by passing information from the fine to coarse levels; the other is to restore finer molecular details given coarse grained configurations. Although these two problems are commonly addressed independently, in this work, we present a theory connecting them, and develop a methodology called Cycle Coarse Graining (CCG) to solve both problems in a unified manner. In CCG, reconstruction can be achieved via a tractable deep generative model, allowing retrieval of fine details from coarse-grained simulations. The reconstruction in turn delivers better coarse-grained models which are informed of the fine-grained physics, and enables calculation of the free energies in a rare-event-free manner. CCG thus provides a systematic way for multiscale molecular modeling, where the finer details of coarse-grained simulations can be efficiently retrieved, and the coarse-grained models can be improved consistently.
<div id='section'>Paperid: <span id='pid'>619, <a href='https://arxiv.org/pdf/2304.04964.pdf' target='_blank'>https://arxiv.org/pdf/2304.04964.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hamza Boukraichi, Nissrine Akkari, Fabien Casenave, David Ryckelynck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04964">A priori compression of convolutional neural networks for wave simulators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Convolutional neural networks are now seeing widespread use in a variety of fields, including image classification, facial and object recognition, medical imaging analysis, and many more. In addition, there are applications such as physics-informed simulators in which accurate forecasts in real time with a minimal lag are required. The present neural network designs include millions of parameters, which makes it difficult to install such complex models on devices that have limited memory. Compression techniques might be able to resolve these issues by decreasing the size of CNN models that are created by reducing the number of parameters that contribute to the complexity of the models. We propose a compressed tensor format of convolutional layer, a priori, before the training of the neural network. 3-way kernels or 2-way kernels in convolutional layers are replaced by one-way fiters. The overfitting phenomena will be reduced also. The time needed to make predictions or time required for training using the original Convolutional Neural Networks model would be cut significantly if there were fewer parameters to deal with. In this paper we present a method of a priori compressing convolutional neural networks for finite element (FE) predictions of physical data. Afterwards we validate our a priori compressed models on physical data from a FE model solving a 2D wave equation. We show that the proposed convolutinal compression technique achieves equivalent performance as classical convolutional layers with fewer trainable parameters and lower memory footprint.
<div id='section'>Paperid: <span id='pid'>620, <a href='https://arxiv.org/pdf/2304.00062.pdf' target='_blank'>https://arxiv.org/pdf/2304.00062.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Robert Ferrando, Laurent Pagnier, Robert Mieth, Zhirui Liang, Yury Dvorkin, Daniel Bienstock, Michael Chertkov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.00062">A Physics-Informed Machine Learning for Electricity Markets: A NYISO Case Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the challenge of efficiently solving the optimal power flow problem in real-time electricity markets. The proposed solution, named Physics-Informed Market-Aware Active Set learning OPF (PIMA-AS-OPF), leverages physical constraints and market properties to ensure physical and economic feasibility of market-clearing outcomes. Specifically, PIMA-AS-OPF employs the active set learning technique and expands its capabilities to account for curtailment in load or renewable power generation, which is a common challenge in real-world power systems. The core of PIMA-AS-OPF is a fully-connected neural network that takes the net load and the system topology as input. The outputs of this neural network include active constraints such as saturated generators and transmission lines, as well as non-zero load shedding and wind curtailments. These outputs allow for reducing the original market-clearing optimization to a system of linear equations, which can be solved efficiently and yield both the dispatch decisions and the locational marginal prices (LMPs). The dispatch decisions and LMPs are then tested for their feasibility with respect to the requirements for efficient market-clearing results. The accuracy and scalability of the proposed method is tested on a realistic 1814-bus NYISO system with current and future renewable energy penetration levels.
<div id='section'>Paperid: <span id='pid'>621, <a href='https://arxiv.org/pdf/2303.12116.pdf' target='_blank'>https://arxiv.org/pdf/2303.12116.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahul Nellikkath, Andreas Venzke, Mohammad Kazem Bakhshizadeh, Ilgiz Murzakhanov, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.12116">Physics Informed Neural Networks for Phase Locked Loop Transient Stability Assessment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A significant increase in renewable energy production is necessary to achieve the UN's net-zero emission targets for 2050. Using power-electronic controllers, such as Phase Locked Loops (PLLs), to keep grid-tied renewable resources in synchronism with the grid can cause fast transient behavior during grid faults leading to instability. However, assessing all the probable scenarios is impractical, so determining the stability boundary or region of attraction (ROA) is necessary. However, using EMT simulations or Reduced-order models (ROMs) to accurately determine the ROA is computationally expensive. Alternatively, Machine Learning (ML) models have been proposed as an efficient method to predict stability. However, traditional ML algorithms require large amounts of labeled data for training, which is computationally expensive. This paper proposes a Physics-Informed Neural Network (PINN) architecture that accurately predicts the nonlinear transient dynamics of a PLL controller under fault with less labeled training data. The proposed PINN algorithm can be incorporated into conventional simulations, accelerating EMT simulations or ROMs by over 100 times. The PINN algorithm's performance is compared against a ROM and an EMT simulation in PSCAD for the CIGRE benchmark model C4.49, demonstrating its ability to accurately approximate trajectories and ROAs of a PLL controller under varying grid impedance.
<div id='section'>Paperid: <span id='pid'>622, <a href='https://arxiv.org/pdf/2303.04679.pdf' target='_blank'>https://arxiv.org/pdf/2303.04679.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Petr Karnakov, Sergey Litvinov, Petros Koumoutsakos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.04679">Flow reconstruction by multiresolution optimization of a discrete loss with automatic differentiation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a potent computational method for the solution of inverse problems in fluid mechanics. We consider inverse problems formulated in terms of a deterministic loss function that can accommodate data and regularization terms. We introduce a multigrid decomposition technique that accelerates the convergence of gradient-based methods for optimization problems with parameters on a grid. We incorporate this multigrid technique to the ODIL (Optimizing a DIscrete Loss) framework. The multiresolution ODIL (mODIL) accelerates by an order of magnitude the original formalism and improves the avoidance of local minima. Moreover, mODIL accommodates the use of automatic differentiation for calculating the gradients of the loss function, thus facilitating the implementation of the framework. We demonstrate the capabilities of mODIL on a variety of inverse and flow reconstruction problems: solution reconstruction for the Burgers equation, inferring conductivity from temperature measurements, and inferring the body shape from wake velocity measurements in three dimensions. We also provide a comparative study with the related, popular Physics-Informed Neural Networks (PINNs) method. We demonstrate that mODIL has three to five orders of magnitude lower computational cost than PINNs in benchmark problems including simple PDEs and lid-driven cavity problems. Our results suggest that mODIL is a very potent, fast and consistent method for solving inverse problems in fluid mechanics.
<div id='section'>Paperid: <span id='pid'>623, <a href='https://arxiv.org/pdf/2301.11040.pdf' target='_blank'>https://arxiv.org/pdf/2301.11040.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arnaud Vadeboncoeur, Ieva Kazlauskaite, Yanni Papandreou, Fehmi Cirak, Mark Girolami, Ãmer Deniz Akyildiz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.11040">Random Grid Neural Processes for Parametric Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a new class of spatially stochastic physics and data informed deep latent models for parametric partial differential equations (PDEs) which operate through scalable variational neural processes. We achieve this by assigning probability measures to the spatial domain, which allows us to treat collocation grids probabilistically as random variables to be marginalised out. Adapting this spatial statistics view, we solve forward and inverse problems for parametric PDEs in a way that leads to the construction of Gaussian process models of solution fields. The implementation of these random grids poses a unique set of challenges for inverse physics informed deep learning frameworks and we propose a new architecture called Grid Invariant Convolutional Networks (GICNets) to overcome these challenges. We further show how to incorporate noisy data in a principled manner into our physics informed model to improve predictions for problems where data may be available but whose measurement location does not coincide with any fixed mesh or grid. The proposed method is tested on a nonlinear Poisson problem, Burgers equation, and Navier-Stokes equations, and we provide extensive numerical comparisons. We demonstrate significant computational advantages over current physics informed neural learning methods for parametric PDEs while improving the predictive capabilities and flexibility of these models.
<div id='section'>Paperid: <span id='pid'>624, <a href='https://arxiv.org/pdf/2301.05739.pdf' target='_blank'>https://arxiv.org/pdf/2301.05739.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yan Li, Mingzhou Yang, Matthew Eagon, Majid Farhadloo, Yiqun Xie, William F. Northrop, Shashi Shekhar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.05739">Eco-PiNN: A Physics-informed Neural Network for Eco-toll Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The eco-toll estimation problem quantifies the expected environmental cost (e.g., energy consumption, exhaust emissions) for a vehicle to travel along a path. This problem is important for societal applications such as eco-routing, which aims to find paths with the lowest exhaust emissions or energy need. The challenges of this problem are three-fold: (1) the dependence of a vehicle's eco-toll on its physical parameters; (2) the lack of access to data with eco-toll information; and (3) the influence of contextual information (i.e. the connections of adjacent segments in the path) on the eco-toll of road segments. Prior work on eco-toll estimation has mostly relied on pure data-driven approaches and has high estimation errors given the limited training data. To address these limitations, we propose a novel Eco-toll estimation Physics-informed Neural Network framework (Eco-PiNN) using three novel ideas, namely, (1) a physics-informed decoder that integrates the physical laws of the vehicle engine into the network, (2) an attention-based contextual information encoder, and (3) a physics-informed regularization to reduce overfitting. Experiments on real-world heavy-duty truck data show that the proposed method can greatly improve the accuracy of eco-toll estimation compared with state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>625, <a href='https://arxiv.org/pdf/2208.04856.pdf' target='_blank'>https://arxiv.org/pdf/2208.04856.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arnaud Vadeboncoeur, Ãmer Deniz Akyildiz, Ieva Kazlauskaite, Mark Girolami, Fehmi Cirak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.04856">Fully probabilistic deep models for forward and inverse problems in parametric PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a physics-driven deep latent variable model (PDDLVM) to learn simultaneously parameter-to-solution (forward) and solution-to-parameter (inverse) maps of parametric partial differential equations (PDEs). Our formulation leverages conventional PDE discretization techniques, deep neural networks, probabilistic modelling, and variational inference to assemble a fully probabilistic coherent framework. In the posited probabilistic model, both the forward and inverse maps are approximated as Gaussian distributions with a mean and covariance parameterized by deep neural networks. The PDE residual is assumed to be an observed random vector of value zero, hence we model it as a random vector with a zero mean and a user-prescribed covariance. The model is trained by maximizing the probability, that is the evidence or marginal likelihood, of observing a residual of zero by maximizing the evidence lower bound (ELBO). Consequently, the proposed methodology does not require any independent PDE solves and is physics-informed at training time, allowing the real-time solution of PDE forward and inverse problems after training. The proposed framework can be easily extended to seamlessly integrate observed data to solve inverse problems and to build generative models. We demonstrate the efficiency and robustness of our method on finite element discretized parametric PDE problems such as linear and nonlinear Poisson problems, elastic shells with complex 3D geometries, and time-dependent nonlinear and inhomogeneous PDEs using a physics-informed neural network (PINN) discretization. We achieve up to three orders of magnitude speed-up after training compared to traditional finite element method (FEM), while outputting coherent uncertainty estimates.
<div id='section'>Paperid: <span id='pid'>626, <a href='https://arxiv.org/pdf/2204.07497.pdf' target='_blank'>https://arxiv.org/pdf/2204.07497.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiwei Jia, Young Ju Lee, Ziqian Li, Zheng Lu, Ran Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.07497">Helicity-conservative Physics-informed Neural Network Model for Navier-Stokes Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We design the helicity-conservative physics-informed neural network model for the Navier-Stokes equation in the ideal case. The key is to provide an appropriate PDE model as loss function so that its neural network solutions produce helicity conservation. Physics-informed neural network model is based on the strong form of PDE. We compare the proposed Physics-informed neural network model and a relevant helicity-conservative finite element method. We arrive at the conclusion that the strong form PDE is better suited for conservation issues. We also present theoretical justifications for helicity conservation as well as supporting numerical calculations.
<div id='section'>Paperid: <span id='pid'>627, <a href='https://arxiv.org/pdf/2110.13680.pdf' target='_blank'>https://arxiv.org/pdf/2110.13680.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hamza Boukraichi, Nissrine Akkari, Fabien Casenave, David Ryckelynck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.13680">Uncertainty quantification in a mechanical submodel driven by a Wasserstein-GAN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The analysis of parametric and non-parametric uncertainties of very large dynamical systems requires the construction of a stochastic model of said system. Linear approaches relying on random matrix theory and principal componant analysis can be used when systems undergo low-frequency vibrations. In the case of fast dynamics and wave propagation, we investigate a random generator of boundary conditions for fast submodels by using machine learning. We show that the use of non-linear techniques in machine learning and data-driven methods is highly relevant.
  Physics-informed neural networks is a possible choice for a data-driven method to replace linear modal analysis. An architecture that support a random component is necessary for the construction of the stochastic model of the physical system for non-parametric uncertainties, since the goal is to learn the underlying probabilistic distribution of uncertainty in the data. Generative Adversarial Networks (GANs) are suited for such applications, where the Wasserstein-GAN with gradient penalty variant offers improved convergence results for our problem.
  The objective of our approach is to train a GAN on data from a finite element method code (Fenics) so as to extract stochastic boundary conditions for faster finite element predictions on a submodel. The submodel and the training data have both the same geometrical support. It is a zone of interest for uncertainty quantification and relevant to engineering purposes. In the exploitation phase, the framework can be viewed as a randomized and parametrized simulation generator on the submodel, which can be used as a Monte Carlo estimator.
<div id='section'>Paperid: <span id='pid'>628, <a href='https://arxiv.org/pdf/2103.13683.pdf' target='_blank'>https://arxiv.org/pdf/2103.13683.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thomas Daniel, Fabien Casenave, Nissrine Akkari, Ali Ketata, David Ryckelynck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2103.13683">Physics-informed cluster analysis and a priori efficiency criterion for the construction of local reduced-order bases</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nonlinear model order reduction has opened the door to parameter optimization and uncertainty quantification in complex physics problems governed by nonlinear equations. In particular, the computational cost of solving these equations can be reduced by means of local reduced-order bases. This article examines the benefits of a physics-informed cluster analysis for the construction of cluster-specific reduced-order bases. We illustrate that the choice of the dissimilarity measure for clustering is fundamental and highly affects the performances of the local reduced-order bases. It is shown that clustering with an angle-based dissimilarity on simulation data efficiently decreases the intra-cluster Kolmogorov $N$-width. Additionally, an a priori efficiency criterion is introduced to assess the relevance of a ROM-net, a methodology for the reduction of nonlinear physics problems introduced in our previous work in [T. Daniel, F. Casenave, N. Akkari, D. Ryckelynck, Model order reduction assisted by deep neural networks (ROM-net), Advanced Modeling and Simulation in Engineering Sciences 7 (16), 2020]. This criterion also provides engineers with a very practical method for ROM-nets' hyperparameters calibration under constrained computational costs for the training phase. On five different physics problems, our physics-informed clustering strategy significantly outperforms classic strategies for the construction of local reduced-order bases in terms of projection errors.
<div id='section'>Paperid: <span id='pid'>629, <a href='https://arxiv.org/pdf/2010.08019.pdf' target='_blank'>https://arxiv.org/pdf/2010.08019.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yeonjong Shin, Zhongqiang Zhang, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2010.08019">Error estimates of residual minimization using neural networks for linear PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose an abstract framework for analyzing the convergence of least-squares methods based on residual minimization when feasible solutions are neural networks. With the norm relations and compactness arguments, we derive error estimates for both continuous and discrete formulations of residual minimization in strong and weak forms. The formulations cover recently developed physics-informed neural networks based on strong and variational formulations.
<div id='section'>Paperid: <span id='pid'>630, <a href='https://arxiv.org/pdf/2510.02982.pdf' target='_blank'>https://arxiv.org/pdf/2510.02982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Dehtyriov, Jonathan F. MacArt, Justin Sirignano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.02982">oRANS: Online optimisation of RANS machine learning models with embedded DNS data generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning (DL) has demonstrated promise for accelerating and enhancing the accuracy of flow physics simulations, but progress is constrained by the scarcity of high-fidelity training data, which is costly to generate and inherently limited to a small set of flow conditions. Consequently, closures trained in the conventional offline paradigm tend to overfit and fail to generalise to new regimes. We introduce an online optimisation framework for DL-based Reynolds-averaged Navier--Stokes (RANS) closures which seeks to address the challenge of limited high-fidelity datasets. Training data is dynamically generated by embedding a direct numerical simulation (DNS) within a subdomain of the RANS domain. The RANS solution supplies boundary conditions to the DNS, while the DNS provides mean velocity and turbulence statistics that are used to update a DL closure model during the simulation. This feedback loop enables the closure to adapt to the embedded DNS target flow, avoiding reliance on precomputed datasets and improving out-of-distribution performance. The approach is demonstrated for the stochastically forced Burgers equation and for turbulent channel flow at $Re_τ=180$, $270$, $395$ and $590$ with varying embedded domain lengths $1\leq L_0/L\leq 8$. Online-optimised RANS models significantly outperform both offline-trained and literature-calibrated closures, with accurate training achieved using modest DNS subdomains. Performance degrades primarily when boundary-condition contamination dominates or when domains are too short to capture low-wavenumber modes. This framework provides a scalable route to physics-informed machine learning closures, enabling data-adaptive reduced-order models that generalise across flow regimes without requiring large precomputed training datasets.
<div id='section'>Paperid: <span id='pid'>631, <a href='https://arxiv.org/pdf/2509.11768.pdf' target='_blank'>https://arxiv.org/pdf/2509.11768.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Milos Babic, Franz M. Rohrhofer, Bernhard C. Geiger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11768">Stabilizing PINNs: A regularization scheme for PINN training to avoid unstable fixed points of dynamical systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It was recently shown that the loss function used for training physics-informed neural networks (PINNs) exhibits local minima at solutions corresponding to fixed points of dynamical systems. In the forward setting, where the PINN is trained to solve initial value problems, these local minima can interfere with training and potentially leading to physically incorrect solutions. Building on stability theory, this paper proposes a regularization scheme that penalizes solutions corresponding to unstable fixed points. Experimental results on four dynamical systems, including the Lotka-Volterra model and the van der Pol oscillator, show that our scheme helps avoiding physically incorrect solutions and substantially improves the training success rate of PINNs.
<div id='section'>Paperid: <span id='pid'>632, <a href='https://arxiv.org/pdf/2508.14093.pdf' target='_blank'>https://arxiv.org/pdf/2508.14093.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Ajeleye, Ashutosh Trivedi, Majid Zamani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14093">Physics-Informed Reward Machines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reward machines (RMs) provide a structured way to specify non-Markovian rewards in reinforcement learning (RL), thereby improving both expressiveness and programmability. Viewed more broadly, they separate what is known about the environment, captured by the reward mechanism, from what remains unknown and must be discovered through sampling. This separation supports techniques such as counterfactual experience generation and reward shaping, which reduce sample complexity and speed up learning. We introduce physics-informed reward machines (pRMs), a symbolic machine designed to express complex learning objectives and reward structures for RL agents, thereby enabling more programmable, expressive, and efficient learning. We present RL algorithms capable of exploiting pRMs via counterfactual experiences and reward shaping. Our experimental results show that these techniques accelerate reward acquisition during the training phases of RL. We demonstrate the expressiveness and effectiveness of pRMs through experiments in both finite and continuous physical environments, illustrating that incorporating pRMs significantly improves learning efficiency across several control tasks.
<div id='section'>Paperid: <span id='pid'>633, <a href='https://arxiv.org/pdf/2507.22493.pdf' target='_blank'>https://arxiv.org/pdf/2507.22493.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaodong Feng, Ling Guo, Xiaoliang Wan, Hao Wu, Tao Zhou, Wenwen Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.22493">LVM-GP: Uncertainty-Aware PDE Solver via coupling latent variable model and Gaussian process</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel probabilistic framework, termed LVM-GP, for uncertainty quantification in solving forward and inverse partial differential equations (PDEs) with noisy data. The core idea is to construct a stochastic mapping from the input to a high-dimensional latent representation, enabling uncertainty-aware prediction of the solution. Specifically, the architecture consists of a confidence-aware encoder and a probabilistic decoder. The encoder implements a high-dimensional latent variable model based on a Gaussian process (LVM-GP), where the latent representation is constructed by interpolating between a learnable deterministic feature and a Gaussian process prior, with the interpolation strength adaptively controlled by a confidence function learned from data. The decoder defines a conditional Gaussian distribution over the solution field, where the mean is predicted by a neural operator applied to the latent representation, allowing the model to learn flexible function-to-function mapping. Moreover, physical laws are enforced as soft constraints in the loss function to ensure consistency with the underlying PDE structure. Compared to existing approaches such as Bayesian physics-informed neural networks (B-PINNs) and deep ensembles, the proposed framework can efficiently capture functional dependencies via merging a latent Gaussian process and neural operator, resulting in competitive predictive accuracy and robust uncertainty quantification. Numerical experiments demonstrate the effectiveness and reliability of the method.
<div id='section'>Paperid: <span id='pid'>634, <a href='https://arxiv.org/pdf/2507.12941.pdf' target='_blank'>https://arxiv.org/pdf/2507.12941.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangtao Deng, Qiaolin He, Xiaoping Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.12941">Adaptive feature capture method for solving partial differential equations with near singular solutions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial differential equations (PDEs) with near singular solutions pose significant challenges for traditional numerical methods, particularly in complex geometries where mesh generation and adaptive refinement become computationally expensive. While deep-learning-based approaches, such as Physics-Informed Neural Networks (PINNs) and the Random Feature Method (RFM), offer mesh-free alternatives, they often lack adaptive resolution in critical regions, limiting their accuracy for solutions with steep gradients or singularities. In this work, we propose the Adaptive Feature Capture Method (AFCM), a novel machine learning framework that adaptively redistributes neurons and collocation points in high-gradient regions to enhance local expressive power. Inspired by adaptive moving mesh techniques, AFCM employs the gradient norm of an approximate solution as a monitor function to guide the reinitialization of feature function parameters. This ensures that partition hyperplanes and collocation points cluster where they are most needed, achieving higher resolution without increasing computational overhead. The AFCM extends the capabilities of RFM to handle PDEs with near-singular solutions while preserving its mesh-free efficiency. Numerical experiments demonstrate the method's effectiveness in accurately resolving near-singular problems, even in complex geometries. By bridging the gap between adaptive mesh refinement and randomized neural networks, AFCM offers a robust and scalable approach for solving challenging PDEs in scientific and engineering applications.
<div id='section'>Paperid: <span id='pid'>635, <a href='https://arxiv.org/pdf/2507.01714.pdf' target='_blank'>https://arxiv.org/pdf/2507.01714.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kevin Innerebner, Franz M. Rohrhofer, Bernhard C. Geiger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01714">B-PL-PINN: Stabilizing PINN Training with Bayesian Pseudo Labeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training physics-informed neural networks (PINNs) for forward problems often suffers from severe convergence issues, hindering the propagation of information from regions where the desired solution is well-defined. Haitsiukevich and Ilin (2023) proposed an ensemble approach that extends the active training domain of each PINN based on i) ensemble consensus and ii) vicinity to (pseudo-)labeled points, thus ensuring that the information from the initial condition successfully propagates to the interior of the computational domain.
  In this work, we suggest replacing the ensemble by a Bayesian PINN, and consensus by an evaluation of the PINN's posterior variance. Our experiments show that this mathematically principled approach outperforms the ensemble on a set of benchmark problems and is competitive with PINN ensembles trained with combinations of Adam and LBFGS.
<div id='section'>Paperid: <span id='pid'>636, <a href='https://arxiv.org/pdf/2506.18332.pdf' target='_blank'>https://arxiv.org/pdf/2506.18332.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiachun Zheng, Yunqing Huang, Nianyu Yi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18332">AE-PINNs: Attention-enhanced physics-informed neural networks for solving elliptic interface problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inspired by the attention mechanism, we develop an attention-enhanced physics-informed neural networks (AE-PINNs) for solving elliptic interface equations. In AE-PINNs, we decompose the solution into two complementary components: a continuous component and a component with discontinuities across the interface. The continuous component is approximated by a fully connected neural network in the whole domain, while the discontinuous component is approximated by an interface-attention neural network in each subdomain separated by the interface. The interface-attention neural network adopts a network structure similar to the attention mechanism to focus on the interface, with its key extension is to introduce a neural network that transmits interface information. Some numerical experiments have confirmed the effectiveness of the AE-PINNs, demonstrating higher accuracy compared with PINNs, I-PINNs and M-PINNs.
<div id='section'>Paperid: <span id='pid'>637, <a href='https://arxiv.org/pdf/2506.17654.pdf' target='_blank'>https://arxiv.org/pdf/2506.17654.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wentao Peng, Yunqing Huang, Nianyu Yi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17654">Rank Inspired Neural Network for solving linear partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a rank inspired neural network (RINN) to tackle the initialization sensitivity issue of physics informed extreme learning machines (PIELM) when numerically solving partial differential equations (PDEs). Unlike PIELM which randomly initializes the parameters of its hidden layers, RINN incorporates a preconditioning stage. In this stage, covariance-driven regularization is employed to optimize the orthogonality of the basis functions generated by the last hidden layer. The key innovation lies in minimizing the off-diagonal elements of the covariance matrix derived from the hidden-layer output. By doing so, pairwise orthogonality constraints across collocation points are enforced which effectively enhances both the numerical stability and the approximation ability of the optimized function space.The RINN algorithm unfolds in two sequential stages. First, it conducts a non-linear optimization process to orthogonalize the basis functions. Subsequently, it solves the PDE constraints using linear least-squares method. Extensive numerical experiments demonstrate that RINN significantly reduces performance variability due to parameter initialization compared to PIELM. Incorporating an early stopping mechanism based on PDE loss further improves stability, ensuring consistently high accuracy across diverse initialization settings.
<div id='section'>Paperid: <span id='pid'>638, <a href='https://arxiv.org/pdf/2506.08475.pdf' target='_blank'>https://arxiv.org/pdf/2506.08475.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaolong He, Yeonjong Shin, Anthony Gruber, Sohyeon Jung, Kookjin Lee, Youngsoo Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08475">Thermodynamically Consistent Latent Dynamics Identification for Parametric Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose an efficient thermodynamics-informed latent space dynamics identification (tLaSDI) framework for the reduced-order modeling of parametric nonlinear dynamical systems. This framework integrates autoencoders for dimensionality reduction with newly developed parametric GENERIC formalism-informed neural networks (pGFINNs), which enable efficient learning of parametric latent dynamics while preserving key thermodynamic principles such as free energy conservation and entropy generation across the parameter space. To further enhance model performance, a physics-informed active learning strategy is incorporated, leveraging a greedy, residual-based error indicator to adaptively sample informative training data, outperforming uniform sampling at equivalent computational cost. Numerical experiments on the Burgers' equation and the 1D/1V Vlasov-Poisson equation demonstrate that the proposed method achieves up to 3,528x speed-up with 1-3% relative errors, and significant reduction in training (50-90%) and inference (57-61%) cost. Moreover, the learned latent space dynamics reveal the underlying thermodynamic behavior of the system, offering valuable insights into the physical-space dynamics.
<div id='section'>Paperid: <span id='pid'>639, <a href='https://arxiv.org/pdf/2505.12556.pdf' target='_blank'>https://arxiv.org/pdf/2505.12556.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taniya Kapoor, Abhishek Chandra, Anastasios Stamou, Stephen J Roberts
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12556">Beyond Accuracy: EcoL2 Metric for Sustainable Neural PDE Solvers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world systems, from aerospace to railway engineering, are modeled with partial differential equations (PDEs) describing the physics of the system. Estimating robust solutions for such problems is essential. Deep learning-based architectures, such as neural PDE solvers, have recently gained traction as a reliable solution method. The current state of development of these approaches, however, primarily focuses on improving accuracy. The environmental impact of excessive computation, leading to increased carbon emissions, has largely been overlooked. This paper introduces a carbon emission measure for a range of PDE solvers. Our proposed metric, EcoL2, balances model accuracy with emissions across data collection, model training, and deployment. Experiments across both physics-informed machine learning and operator learning architectures demonstrate that the proposed metric presents a holistic assessment of model performance and emission cost. As such solvers grow in scale and deployment, EcoL2 represents a step toward building performant scientific machine learning systems with lower long-term environmental impact.
<div id='section'>Paperid: <span id='pid'>640, <a href='https://arxiv.org/pdf/2505.11578.pdf' target='_blank'>https://arxiv.org/pdf/2505.11578.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peimian Du, Jiabin Liu, Xiaowei Jin, Wangmeng Zuo, Hui Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11578">Spatiotemporal Field Generation Based on Hybrid Mamba-Transformer with Physics-informed Fine-tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This research confronts the challenge of substantial physical equation discrepancies encountered in the generation of spatiotemporal physical fields through data-driven trained models. A spatiotemporal physical field generation model, named HMT-PF, is developed based on the hybrid Mamba-Transformer architecture, incorporating unstructured grid information as input. A fine-tuning block, enhanced with physical information, is introduced to effectively reduce the physical equation discrepancies. The physical equation residuals are computed through a point query mechanism for efficient gradient evaluation, then encoded into latent space for refinement. The fine-tuning process employs a self-supervised learning approach to achieve physical consistency while maintaining essential field characteristics. Results show that the hybrid Mamba-Transformer model achieves good performance in generating spatiotemporal fields, while the physics-informed fine-tuning mechanism further reduces significant physical errors effectively. A MSE-R evaluation method is developed to assess the accuracy and realism of physical field generation.
<div id='section'>Paperid: <span id='pid'>641, <a href='https://arxiv.org/pdf/2505.07090.pdf' target='_blank'>https://arxiv.org/pdf/2505.07090.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bilal Ahmed, Yuqing Qiu, Diab W. Abueidda, Waleed El-Sekelly, Tarek Abdoun, Mostafa E. Mobasher
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07090">Physics-informed Multiple-Input Operators for efficient dynamic response prediction of structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Finite element (FE) modeling is essential for structural analysis but remains computationally intensive, especially under dynamic loading. While operator learning models have shown promise in replicating static structural responses at FEM level accuracy, modeling dynamic behavior remains more challenging. This work presents a Multiple Input Operator Network (MIONet) that incorporates a second trunk network to explicitly encode temporal dynamics, enabling accurate prediction of structural responses under moving loads. Traditional DeepONet architectures using recurrent neural networks (RNNs) are limited by fixed time discretization and struggle to capture continuous dynamics. In contrast, MIONet predicts responses continuously over both space and time, removing the need for step wise modeling. It maps scalar inputs including load type, velocity, spatial mesh, and time steps to full field structural responses. To improve efficiency and enforce physical consistency, we introduce a physics informed loss based on dynamic equilibrium using precomputed mass, damping, and stiffness matrices, without solving the governing PDEs directly. Further, a Schur complement formulation reduces the training domain, significantly cutting computational costs while preserving global accuracy. The model is validated on both a simple beam and the KW-51 bridge, achieving FEM level accuracy within seconds. Compared to GRU based DeepONet, our model offers comparable accuracy with improved temporal continuity and over 100 times faster inference, making it well suited for real-time structural monitoring and digital twin applications.
<div id='section'>Paperid: <span id='pid'>642, <a href='https://arxiv.org/pdf/2504.15311.pdf' target='_blank'>https://arxiv.org/pdf/2504.15311.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fei Shang, Haohua Du, Dawei Yan, Panlong Yang, Xiang-Yang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15311">RINN: One Sample Radio Frequency Imaging based on Physics Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to its ability to work in non-line-of-sight and low-light environments, radio frequency (RF) imaging technology is expected to bring new possibilities for embodied intelligence and multimodal sensing. However, widely used RF devices (such as Wi-Fi) often struggle to provide high-precision electromagnetic measurements and large-scale datasets, hindering the application of RF imaging technology. In this paper, we combine the ideas of PINN to design the RINN network, using physical constraints instead of true value comparison constraints and adapting it with the characteristics of ubiquitous RF signals, allowing the RINN network to achieve RF imaging using only one sample without phase and with amplitude noise. Our numerical evaluation results show that compared with 5 classic algorithms based on phase data for imaging results, RINN's imaging results based on phaseless data are good, with indicators such as RRMSE (0.11) performing similarly well. RINN provides new possibilities for the universal development of radio frequency imaging technology.
<div id='section'>Paperid: <span id='pid'>643, <a href='https://arxiv.org/pdf/2504.12952.pdf' target='_blank'>https://arxiv.org/pdf/2504.12952.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan Drgona, Truong X. Nghiem, Thomas Beckers, Mahyar Fazlyab, Enrique Mallada, Colin Jones, Draguna Vrabie, Steven L. Brunton, Rolf Findeisen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.12952">Safe Physics-Informed Machine Learning for Dynamics and Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This tutorial paper focuses on safe physics-informed machine learning in the context of dynamics and control, providing a comprehensive overview of how to integrate physical models and safety guarantees. As machine learning techniques enhance the modeling and control of complex dynamical systems, ensuring safety and stability remains a critical challenge, especially in safety-critical applications like autonomous vehicles, robotics, medical decision-making, and energy systems. We explore various approaches for embedding and ensuring safety constraints, including structural priors, Lyapunov and Control Barrier Functions, predictive control, projections, and robust optimization techniques. Additionally, we delve into methods for uncertainty quantification and safety verification, including reachability analysis and neural network verification tools, which help validate that control policies remain within safe operating bounds even in uncertain environments. The paper includes illustrative examples demonstrating the implementation aspects of safe learning frameworks that combine the strengths of data-driven approaches with the rigor of physical principles, offering a path toward the safe control of complex dynamical systems.
<div id='section'>Paperid: <span id='pid'>644, <a href='https://arxiv.org/pdf/2504.11650.pdf' target='_blank'>https://arxiv.org/pdf/2504.11650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengyuan Yan, Farzad Vazinram, Zeynab Kaseb, Lindsay Spoor, Jochen Stiasny, Betul Mamudi, Amirhossein Heydarian Ardakani, Ugochukwu Orji, Pedro P. Vergara, Yu Xiang, Jerry Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11650">Data driven approach towards more efficient Newton-Raphson power flow calculation for distribution grids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Power flow (PF) calculations are fundamental to power system analysis to ensure stable and reliable grid operation. The Newton-Raphson (NR) method is commonly used for PF analysis due to its rapid convergence when initialized properly. However, as power grids operate closer to their capacity limits, ill-conditioned cases and convergence issues pose significant challenges. This work, therefore, addresses these challenges by proposing strategies to improve NR initialization, hence minimizing iterations and avoiding divergence. We explore three approaches: (i) an analytical method that estimates the basin of attraction using mathematical bounds on voltages, (ii) Two data-driven models leveraging supervised learning or physics-informed neural networks (PINNs) to predict optimal initial guesses, and (iii) a reinforcement learning (RL) approach that incrementally adjusts voltages to accelerate convergence. These methods are tested on benchmark systems. This research is particularly relevant for modern power systems, where high penetration of renewables and decentralized generation require robust and scalable PF solutions. In experiments, all three proposed methods demonstrate a strong ability to provide an initial guess for Newton-Raphson method to converge with fewer steps. The findings provide a pathway for more efficient real-time grid operations, which, in turn, support the transition toward smarter and more resilient electricity networks.
<div id='section'>Paperid: <span id='pid'>645, <a href='https://arxiv.org/pdf/2503.04579.pdf' target='_blank'>https://arxiv.org/pdf/2503.04579.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rafael I. Cabral Muchacho, Florian T. Pokorny
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04579">Data-augmented Learning of Geodesic Distances in Irregular Domains through Soner Boundary Conditions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Geodesic distances play a fundamental role in robotics, as they efficiently encode global geometric information of the domain. Recent methods use neural networks to approximate geodesic distances by solving the Eikonal equation through physics-informed approaches. While effective, these approaches often suffer from unstable convergence during training in complex environments. We propose a framework to learn geodesic distances in irregular domains by using the Soner boundary condition, and systematically evaluate the impact of data losses on training stability and solution accuracy. Our experiments demonstrate that incorporating data losses significantly improves convergence robustness, reducing training instabilities and sensitivity to initialization. These findings suggest that hybrid data-physics approaches can effectively enhance the reliability of learning-based geodesic distance solvers with sparse data.
<div id='section'>Paperid: <span id='pid'>646, <a href='https://arxiv.org/pdf/2502.21033.pdf' target='_blank'>https://arxiv.org/pdf/2502.21033.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Awais, Abu Safyan Ali, Giacomo Dimarco, Federica Ferrarese, Lorenzo Pareschi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.21033">A data augmentation strategy for deep neural networks with application to epidemic modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we integrate the predictive capabilities of compartmental disease dynamics models with machine learning ability to analyze complex, high-dimensional data and uncover patterns that conventional models may overlook. Specifically, we present a proof of concept demonstrating the application of data-driven methods and deep neural networks to a recently introduced Susceptible-Infected-Recovered type model with social features, including a saturated incidence rate, to improve epidemic prediction and forecasting. Our results show that a robust data augmentation strategy trough suitable data-driven models can improve the reliability of Feed-Forward Neural Networks and Nonlinear Autoregressive Networks, providing a complementary strategy to Physics-Informed Neural Networks, particularly in settings where data augmentation from mechanistic models can enhance learning. This approach enhances the ability to handle nonlinear dynamics and offers scalable, data-driven solutions for epidemic forecasting, prioritizing predictive accuracy over the constraints of physics-based models. Numerical simulations of the lockdown and post-lockdown phase of the COVID-19 epidemic in Italy and Spain validate our methodology.
<div id='section'>Paperid: <span id='pid'>647, <a href='https://arxiv.org/pdf/2502.16444.pdf' target='_blank'>https://arxiv.org/pdf/2502.16444.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amirmoez Jamaat, Yalan Song, Farshid Rahmani, Jiangtao Liu, Kathryn Lawson, Chaopeng Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16444">Update hydrological states or meteorological forcings? Comparing data assimilation methods for differentiable hydrologic models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data assimilation (DA) enables hydrologic models to update their internal states using near-real-time observations for more accurate forecasts. With deep neural networks like long short-term memory (LSTM), using either lagged observations as inputs (called "data integration") or variational DA has shown success in improving forecasts. However, it is unclear which methods are performant or optimal for physics-informed machine learning ("differentiable") models, which represent only a small amount of physically-meaningful states while using deep networks to supply parameters or missing processes. Here we developed variational DA methods for differentiable models, including optimizing adjusters for just precipitation data, just model internal hydrological states, or both. Our results demonstrated that differentiable streamflow models using the CAMELS dataset can benefit strongly and equivalently from variational DA as LSTM, with one-day lead time median Nash-Sutcliffe efficiency (NSE) elevated from 0.75 to 0.82. The resulting forecast matched or outperformed LSTM with DA in the eastern, northwestern, and central Great Plains regions of the conterminous United States. Both precipitation and state adjusters were needed to achieve these results, with the latter being substantially more effective on its own, and the former adding moderate benefits for high flows. Our DA framework does not need systematic training data and could serve as a practical DA scheme for whole river networks.
<div id='section'>Paperid: <span id='pid'>648, <a href='https://arxiv.org/pdf/2502.16373.pdf' target='_blank'>https://arxiv.org/pdf/2502.16373.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kejun Chen, Shourya Bose, Yu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.16373">Physics-Informed Gradient Estimation for Accelerating Deep Learning based AC-OPF</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The optimal power flow (OPF) problem can be rapidly and reliably solved by employing responsive online solvers based on neural networks. The dynamic nature of renewable energy generation and the variability of power grid conditions necessitate frequent neural network updates with new data instances. To address this need and reduce the time required for data preparation time, we propose a semi-supervised learning framework aided by data augmentation. In this context, ridge regression replaces the traditional solver, facilitating swift prediction of optimal solutions for the given input load demands. Additionally, to accelerate the backpropagation during training, we develop novel batch-mean gradient estimation approaches along with a reduced branch set to alleviate the complexity of gradient computation. Numerical simulations demonstrate that our neural network, equipped with the proposed gradient estimators, consistently achieves feasible and near-optimal solutions. These results underline the effectiveness of our approach for practical implementation in real-time OPF applications.
<div id='section'>Paperid: <span id='pid'>649, <a href='https://arxiv.org/pdf/2502.11504.pdf' target='_blank'>https://arxiv.org/pdf/2502.11504.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Janak M. Patel, Milad Ramezankhani, Anirudh Deodhar, Dagnachew Birru
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11504">Accelerated Gradient-based Design Optimization Via Differentiable Physics-Informed Neural Operator: A Composites Autoclave Processing Case Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulation and optimization are crucial for advancing the engineering design of complex systems and processes. Traditional optimization methods require substantial computational time and effort due to their reliance on resource-intensive simulations, such as finite element analysis, and the complexity of rigorous optimization algorithms. Data-agnostic AI-based surrogate models, such as Physics-Informed Neural Operators (PINOs), offer a promising alternative to these conventional simulations, providing drastically reduced inference time, unparalleled data efficiency, and zero-shot super-resolution capability. However, the predictive accuracy of these models is often constrained to small, low-dimensional design spaces or systems with relatively simple dynamics. To address this, we introduce a novel Physics-Informed DeepONet (PIDON) architecture, which extends the capabilities of conventional neural operators to effectively model the nonlinear behavior of complex engineering systems across high-dimensional design spaces and a wide range of dynamic design configurations. This new architecture outperforms existing SOTA models, enabling better predictions across broader design spaces. Leveraging PIDON's differentiability, we integrate a gradient-based optimization approach using the Adam optimizer to efficiently determine optimal design variables. This forms an end-to-end gradient-based optimization framework that accelerates the design process while enhancing scalability and efficiency. We demonstrate the effectiveness of this framework in the optimization of aerospace-grade composites curing processes achieving a 3x speedup in obtaining optimal design variables compared to gradient-free methods. Beyond composites processing, the proposed model has the potential to be used as a scalable and efficient optimization tool for broader applications in advanced engineering and digital twin systems.
<div id='section'>Paperid: <span id='pid'>650, <a href='https://arxiv.org/pdf/2501.00502.pdf' target='_blank'>https://arxiv.org/pdf/2501.00502.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Miro Miranda, Marcela Charfuelan, Andreas Dengel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.00502">Exploring Physics-Informed Neural Networks for Crop Yield Loss Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In response to climate change, assessing crop productivity under extreme weather conditions is essential to enhance food security. Crop simulation models, which align with physical processes, offer explainability but often perform poorly. Conversely, machine learning (ML) models for crop modeling are powerful and scalable yet operate as black boxes and lack adherence to crop growths physical principles. To bridge this gap, we propose a novel method that combines the strengths of both approaches by estimating the water use and the crop sensitivity to water scarcity at the pixel level. This approach enables yield loss estimation grounded in physical principles by sequentially solving the equation for crop yield response to water scarcity, using an enhanced loss function. Leveraging Sentinel-2 satellite imagery, climate data, simulated water use data, and pixel-level yield data, our model demonstrates high accuracy, achieving an R2 of up to 0.77, matching or surpassing state-of-the-art models like RNNs and Transformers. Additionally, it provides interpretable and physical consistent outputs, supporting industry, policymakers, and farmers in adapting to extreme weather conditions.
<div id='section'>Paperid: <span id='pid'>651, <a href='https://arxiv.org/pdf/2412.17838.pdf' target='_blank'>https://arxiv.org/pdf/2412.17838.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuyi Wang, Huan Zhao, Yuji Cao, Zibin Pan, Guolong Liu, Gaoqi Liang, Junhua Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.17838">Coordinated Power Smoothing Control for Wind Storage Integrated System with Physics-informed Deep Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Wind Storage Integrated System with Power Smoothing Control (PSC) has emerged as a promising solution to ensure both efficient and reliable wind energy generation. However, existing PSC strategies overlook the intricate interplay and distinct control frequencies between batteries and wind turbines, and lack consideration of wake effect and battery degradation cost. In this paper, a novel coordinated control framework with hierarchical levels is devised to address these challenges effectively, which integrates the wake model and battery degradation model. In addition, after reformulating the problem as a Markov decision process, the multi-agent reinforcement learning method is introduced to overcome the bi-level characteristic of the problem. Moreover, a Physics-informed Neural Network-assisted Multi-agent Deep Deterministic Policy Gradient (PAMA-DDPG) algorithm is proposed to incorporate the power fluctuation differential equation and expedite the learning process. The effectiveness of the proposed methodology is evaluated through simulations conducted in four distinct scenarios using WindFarmSimulator (WFSim). The results demonstrate that the proposed algorithm facilitates approximately an 11% increase in total profit and a 19% decrease in power fluctuation compared to the traditional methods, thereby addressing the dual objectives of economic efficiency and grid-connected energy reliability.
<div id='section'>Paperid: <span id='pid'>652, <a href='https://arxiv.org/pdf/2412.05994.pdf' target='_blank'>https://arxiv.org/pdf/2412.05994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Namgyu Kang, Jaemin Oh, Youngjoon Hong, Eunbyung Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05994">PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The numerical approximation of partial differential equations (PDEs) using neural networks has seen significant advancements through Physics-Informed Neural Networks (PINNs). Despite their straightforward optimization framework and flexibility in implementing various PDEs, PINNs often suffer from limited accuracy due to the spectral bias of Multi-Layer Perceptrons (MLPs), which struggle to effectively learn high-frequency and nonlinear components. Recently, parametric mesh representations in combination with neural networks have been investigated as a promising approach to eliminate the inductive bias of MLPs. However, they usually require high-resolution grids and a large number of collocation points to achieve high accuracy while avoiding overfitting. In addition, the fixed positions of the mesh parameters restrict their flexibility, making accurate approximation of complex PDEs challenging. To overcome these limitations, we propose Physics-Informed Gaussians (PIGs), which combine feature embeddings using Gaussian functions with a lightweight neural network. Our approach uses trainable parameters for the mean and variance of each Gaussian, allowing for dynamic adjustment of their positions and shapes during training. This adaptability enables our model to optimally approximate PDE solutions, unlike models with fixed parameter positions. Furthermore, the proposed approach maintains the same optimization framework used in PINNs, allowing us to benefit from their excellent properties. Experimental results show the competitive performance of our model across various PDEs, demonstrating its potential as a robust tool for solving complex PDEs. Our project page is available at https://namgyukang.github.io/Physics-Informed-Gaussians/
<div id='section'>Paperid: <span id='pid'>653, <a href='https://arxiv.org/pdf/2411.19769.pdf' target='_blank'>https://arxiv.org/pdf/2411.19769.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeheon Woo, Seonghwan Kim, Jun Hyeong Kim, Woo Youn Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.19769">Riemannian Denoising Score Matching for Molecular Structure Optimization with Accurate Energy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study introduces a modified score matching method aimed at generating molecular structures with high energy accuracy. The denoising process of score matching or diffusion models mirrors molecular structure optimization, where scores act like physical force fields that guide particles toward equilibrium states. To achieve energetically accurate structures, it can be advantageous to have the score closely approximate the gradient of the actual potential energy surface. Unlike conventional methods that simply design the target score based on structural differences in Euclidean space, we propose a Riemannian score matching approach. This method represents molecular structures on a manifold defined by physics-informed internal coordinates to efficiently mimic the energy landscape, and performs noising and denoising within this space. Our method has been evaluated by refining several types of starting structures on the QM9 and GEOM datasets, demonstrating that the proposed Riemannian score matching method significantly improves the accuracy of the generated molecular structures, attaining chemical accuracy. The implications of this study extend to various applications in computational chemistry, offering a robust tool for accurate molecular structure prediction.
<div id='section'>Paperid: <span id='pid'>654, <a href='https://arxiv.org/pdf/2411.19374.pdf' target='_blank'>https://arxiv.org/pdf/2411.19374.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Colby Fronk, Linda Petzold
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.19374">Performance Evaluation of Single-step Explicit Exponential Integration Methods on Stiff Ordinary Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Stiff systems of ordinary differential equations (ODEs) arise in a wide range of scientific and engineering disciplines and are traditionally solved using implicit integration methods due to their stability and efficiency. However, these methods are computationally expensive, particularly for applications requiring repeated integration, such as parameter estimation, Bayesian inference, neural ODEs, physics-informed neural networks, and MeshGraphNets. Explicit exponential integration methods have been proposed as a potential alternative, leveraging the matrix exponential to address stiffness without requiring nonlinear solvers. This study evaluates several state-of-the-art explicit single-step exponential schemes against classical implicit methods on benchmark stiff ODE problems, analyzing their accuracy, stability, and scalability with step size. Despite their initial appeal, our results reveal that explicit exponential methods significantly lag behind implicit schemes in accuracy and scalability for stiff ODEs. The backward Euler method consistently outperformed higher-order exponential methods in accuracy at small step sizes, with none surpassing the accuracy of the first-order integrating factor Euler method. Exponential methods fail to improve upon first-order accuracy, revealing the integrating factor Euler method as the only reliable choice for repeated, inexpensive integration in applications such as neural ODEs and parameter estimation. This study exposes the limitations of explicit exponential methods and calls for the development of improved algorithms.
<div id='section'>Paperid: <span id='pid'>655, <a href='https://arxiv.org/pdf/2411.08702.pdf' target='_blank'>https://arxiv.org/pdf/2411.08702.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Charalambos G. Makridakis, Aaron Pim, Tristan Pryer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08702">A Deep Uzawa-Lagrange Multiplier Approach for Boundary Conditions in PINNs and Deep Ritz Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a deep learning-based framework for weakly enforcing boundary conditions in the numerical approximation of partial differential equations. Building on existing physics-informed neural network and deep Ritz methods, we propose the Deep Uzawa algorithm, which incorporates Lagrange multipliers to handle boundary conditions effectively. This modification requires only a minor computational adjustment but ensures enhanced convergence properties and provably accurate enforcement of boundary conditions, even for singularly perturbed problems.
  We provide a comprehensive mathematical analysis demonstrating the convergence of the scheme and validate the effectiveness of the Deep Uzawa algorithm through numerical experiments, including high-dimensional, singularly perturbed problems and those posed over non-convex domains.
<div id='section'>Paperid: <span id='pid'>656, <a href='https://arxiv.org/pdf/2410.17445.pdf' target='_blank'>https://arxiv.org/pdf/2410.17445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anthony Baez, Wang Zhang, Ziwen Ma, Subhro Das, Lam M. Nguyen, Luca Daniel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.17445">Guaranteeing Conservation Laws with Projection in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) incorporate physical laws into their training to efficiently solve partial differential equations (PDEs) with minimal data. However, PINNs fail to guarantee adherence to conservation laws, which are also important to consider in modeling physical systems. To address this, we proposed PINN-Proj, a PINN-based model that uses a novel projection method to enforce conservation laws. We found that PINN-Proj substantially outperformed PINN in conserving momentum and lowered prediction error by three to four orders of magnitude from the best benchmark tested. PINN-Proj also performed marginally better in the separate task of state prediction on three PDE datasets.
<div id='section'>Paperid: <span id='pid'>657, <a href='https://arxiv.org/pdf/2409.09207.pdf' target='_blank'>https://arxiv.org/pdf/2409.09207.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Milad Ramezankhani, Rishi Yash Parekh, Anirudh Deodhar, Dagnachew Birru
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.09207">FB-HyDON: Parameter-Efficient Physics-Informed Operator Learning of Complex PDEs via Hypernetwork and Finite Basis Domain Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep operator networks (DeepONet) and neural operators have gained significant attention for their ability to map infinite-dimensional function spaces and perform zero-shot super-resolution. However, these models often require large datasets for effective training. While physics-informed operators offer a data-agnostic learning approach, they introduce additional training complexities and convergence issues, especially in highly nonlinear systems. To overcome these challenges, we introduce Finite Basis Physics-Informed HyperDeepONet (FB-HyDON), an advanced operator architecture featuring intrinsic domain decomposition. By leveraging hypernetworks and finite basis functions, FB-HyDON effectively mitigates the training limitations associated with existing physics-informed operator learning methods. We validated our approach on the high-frequency harmonic oscillator, Burgers' equation at different viscosity levels, and Allen-Cahn equation demonstrating substantial improvements over other operator learning models.
<div id='section'>Paperid: <span id='pid'>658, <a href='https://arxiv.org/pdf/2409.00994.pdf' target='_blank'>https://arxiv.org/pdf/2409.00994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bilal Ahmed, Yuqing Qiu, Diab W. Abueidda, Waleed El-Sekelly, Borja Garcia de Soto, Tarek Abdoun, Mostafa E. Mobasher
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.00994">Physics-informed DeepONet with stiffness-based loss functions for structural response prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Finite element modeling is a well-established tool for structural analysis, yet modeling complex structures often requires extensive pre-processing, significant analysis effort, and considerable time. This study addresses this challenge by introducing an innovative method for real-time prediction of structural static responses using DeepOnet which relies on a novel approach to physics-informed networks driven by structural balance laws. This approach offers the flexibility to accurately predict responses under various load classes and magnitudes. The trained DeepONet can generate solutions for the entire domain, within a fraction of a second. This capability effectively eliminates the need for extensive remodeling and analysis typically required for each new case in FE modeling. We apply the proposed method to two structures: a simple 2D beam structure and a comprehensive 3D model of a real bridge. To predict multiple variables with DeepONet, we utilize two strategies: a split branch/trunk and multiple DeepONets combined into a single DeepONet. In addition to data-driven training, we introduce a novel physics-informed training approaches. This method leverages structural stiffness matrices to enforce fundamental equilibrium and energy conservation principles, resulting in two novel physics-informed loss functions: energy conservation and static equilibrium using the Schur complement. We use various combinations of loss functions to achieve an error rate of less than 5% with significantly reduced training time. This study shows that DeepONet, enhanced with hybrid loss functions, can accurately and efficiently predict displacements and rotations at each mesh point, with reduced training time.
<div id='section'>Paperid: <span id='pid'>659, <a href='https://arxiv.org/pdf/2408.16599.pdf' target='_blank'>https://arxiv.org/pdf/2408.16599.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rajnish Kumar, Anand Gupta, Suriya Prakash Muthukrishnan, Lalan Kumar, Sitikantha Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16599">sEMG-Driven Physics-Informed Gated Recurrent Networks for Modeling Upper Limb Multi-Joint Movement Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Exoskeletons and rehabilitation systems have the potential to improve human strength and recovery by using adaptive human-machine interfaces. Achieving precise and responsive control in these systems depends on accurately estimating joint movement dynamics, such as joint angle, velocity, acceleration, external mass, and torque. While machine learning (ML) approaches have been employed to predict joint kinematics from surface electromyography (sEMG) data, traditional ML models often struggle to generalize across dynamic movements. In contrast, physics-informed neural networks integrate biomechanical principles, but their effectiveness in predicting full movement dynamics has not been thoroughly explored. To address this, we introduce the Physics-informed Gated Recurrent Network (PiGRN), a novel model designed to predict multi-joint movement dynamics from sEMG data. PiGRN uses a Gated Recurrent Unit (GRU) to process time-series sEMG inputs, estimate multi-joint kinematics and external loads, and predict joint torque while incorporating physics-based constraints during training. Experimental validation, using sEMG data from five participants performing elbow flexion-extension tasks with 0 kg, 2 kg, and 4 kg loads, showed that PiGRN accurately predicted joint torques for 10 novel movements. RMSE values ranged from 4.02\% to 11.40\%, with correlation coefficients between 0.87 and 0.98. These results underscore PiGRN's potential for real-time applications in exoskeletons and rehabilitation. Future work will focus on expanding datasets, improving musculoskeletal models, and investigating unsupervised learning approaches.
<div id='section'>Paperid: <span id='pid'>660, <a href='https://arxiv.org/pdf/2408.11691.pdf' target='_blank'>https://arxiv.org/pdf/2408.11691.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>FÃ©lix Chavelli, Zi-Yu Khoo, Dawen Wu, Jonathan Sze Choong Low, StÃ©phane Bressan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11691">Physics-informed Discovery of State Variables in Second-Order and Hamiltonian Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The modeling of dynamical systems is a pervasive concern for not only describing but also predicting and controlling natural phenomena and engineered systems. Current data-driven approaches often assume prior knowledge of the relevant state variables or result in overparameterized state spaces. Boyuan Chen and his co-authors proposed a neural network model that estimates the degrees of freedom and attempts to discover the state variables of a dynamical system. Despite its innovative approach, this baseline model lacks a connection to the physical principles governing the systems it analyzes, leading to unreliable state variables.
  This research proposes a method that leverages the physical characteristics of second-order Hamiltonian systems to constrain the baseline model. The proposed model outperforms the baseline model in identifying a minimal set of non-redundant and interpretable state variables.
<div id='section'>Paperid: <span id='pid'>661, <a href='https://arxiv.org/pdf/2407.16463.pdf' target='_blank'>https://arxiv.org/pdf/2407.16463.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marieke Wesselkamp, Matthew Chantry, Ewan Pinnington, Margarita Choulga, Souhail Boussetta, Maria Kalweit, Joschka Boedecker, Carsten F. Dormann, Florian Pappenberger, Gianpaolo Balsamo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16463">Advances in Land Surface Model-based Forecasting: A comparative study of LSTM, Gradient Boosting, and Feedforward Neural Network Models as prognostic state emulators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most useful weather prediction for the public is near the surface. The processes that are most relevant for near-surface weather prediction are also those that are most interactive and exhibit positive feedback or have key role in energy partitioning. Land surface models (LSMs) consider these processes together with surface heterogeneity and forecast water, carbon and energy fluxes, and coupled with an atmospheric model provide boundary and initial conditions. This numerical parametrization of atmospheric boundaries being computationally expensive, statistical surrogate models are increasingly used to accelerated progress in experimental research. We evaluated the efficiency of three surrogate models in speeding up experimental research by simulating land surface processes, which are integral to forecasting water, carbon, and energy fluxes in coupled atmospheric models. Specifically, we compared the performance of a Long-Short Term Memory (LSTM) encoder-decoder network, extreme gradient boosting, and a feed-forward neural network within a physics-informed multi-objective framework. This framework emulates key states of the ECMWF's Integrated Forecasting System (IFS) land surface scheme, ECLand, across continental and global scales. Our findings indicate that while all models on average demonstrate high accuracy over the forecast period, the LSTM network excels in continental long-range predictions when carefully tuned, the XGB scores consistently high across tasks and the MLP provides an excellent implementation-time-accuracy trade-off. The runtime reduction achieved by the emulators in comparison to the full numerical models are significant, offering a faster, yet reliable alternative for conducting numerical experiments on land surfaces.
<div id='section'>Paperid: <span id='pid'>662, <a href='https://arxiv.org/pdf/2407.07358.pdf' target='_blank'>https://arxiv.org/pdf/2407.07358.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>John Anticev, Ali Aghdaei, Wuxinlin Cheng, Zhuo Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.07358">SGM-PINN: Sampling Graphical Models for Faster Training of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>SGM-PINN is a graph-based importance sampling framework to improve the training efficacy of Physics-Informed Neural Networks (PINNs) on parameterized problems. By applying a graph decomposition scheme to an undirected Probabilistic Graphical Model (PGM) built from the training dataset, our method generates node clusters encoding conditional dependence between training samples. Biasing sampling towards more important clusters allows smaller mini-batches and training datasets, improving training speed and accuracy. We additionally fuse an efficient robustness metric with residual losses to determine regions requiring additional sampling. Experiments demonstrate the advantages of the proposed framework, achieving $3\times$ faster convergence compared to prior state-of-the-art sampling methods.
<div id='section'>Paperid: <span id='pid'>663, <a href='https://arxiv.org/pdf/2407.05477.pdf' target='_blank'>https://arxiv.org/pdf/2407.05477.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anran Jiao, Qile Yan, Jhn Harlim, Lu Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.05477">Solving forward and inverse PDE problems on unknown manifolds via physics-informed neural operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we evaluate the effectiveness of deep operator networks (DeepONets) in solving both forward and inverse problems of partial differential equations (PDEs) on unknown manifolds. By unknown manifolds, we identify the manifold by a set of randomly sampled data point clouds that are assumed to lie on or close to the manifold. When the loss function incorporates the physics, resulting in the so-called physics-informed DeepONets (PI-DeepONets), we approximate the differentiation terms in the PDE by an appropriate operator approximation scheme. For the second-order elliptic PDE with a nontrivial diffusion coefficient, we approximate the differentiation term with one of these methods: the Diffusion Maps (DM), the Radial Basis Functions (RBF), and the Generalized Moving Least Squares (GMLS) methods. For the GMLS approximation, which is more flexible for problems with boundary conditions, we derive the theoretical error bound induced by the approximate differentiation. Numerically, we found that DeepONet is accurate for various types of diffusion coefficients, including linear, exponential, piecewise linear, and quadratic functions, for linear and semi-linear PDEs with/without boundaries. When the number of observations is small, PI-DeepONet trained with sufficiently large samples of PDE constraints produces more accurate approximations than DeepONet. For the inverse problem, we incorporate PI-DeepONet in a Bayesian Markov Chain Monte Carlo (MCMC) framework to estimate the diffusion coefficient from noisy solutions of the PDEs measured at a finite number of point cloud data. Numerically, we found that PI-DeepONet provides accurate approximations comparable to those obtained by a more expensive method that directly solves the PDE on the proposed diffusion coefficient in each MCMC iteration.
<div id='section'>Paperid: <span id='pid'>664, <a href='https://arxiv.org/pdf/2406.17661.pdf' target='_blank'>https://arxiv.org/pdf/2406.17661.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qing Shen, Yifan Zhou, Peng Zhang, Yacov A. Shamash, Roshan Sharma, Bo Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.17661">Physics-Informed AI Inverter</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This letter devises an AI-Inverter that pilots the use of a physics-informed neural network (PINN) to enable AI-based electromagnetic transient simulations (EMT) of grid-forming inverters. The contributions are threefold: (1) A PINN-enabled AI-Inverter is formulated; (2) An enhanced learning strategy, balanced-adaptive PINN, is devised; (3) extensive validations and comparative analysis of the accuracy and efficiency of AI-Inverter are made to show its superiority over the classical electromagnetic transient programs (EMTP).
<div id='section'>Paperid: <span id='pid'>665, <a href='https://arxiv.org/pdf/2406.15787.pdf' target='_blank'>https://arxiv.org/pdf/2406.15787.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peifeng Hui, Chenggang Cui, Pengfeng Lin, Amer M. Y. M. Ghias, Xitong Niu, Chuanlin Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.15787">On Physics-Informed Neural Network Control for Power Electronics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Considering the growing necessity for precise modeling of power electronics amidst operational and environmental uncertainties, this paper introduces an innovative methodology that ingeniously combines model-driven and data-driven approaches to enhance the stability of power electronics interacting with grid-forming microgrids. By employing the physics-informed neural network (PINN) as a foundation, this strategy merges robust data-fitting capabilities with fundamental physical principles, thereby constructing an accurate system model. By this means, it significantly enhances the ability to understand and replicate the dynamics of power electronics systems under complex working conditions. Moreover, by incorporating advanced learning-based control methods, the proposed method is enabled to make precise predictions and implement the satisfactory control laws even under serious uncertain conditions. Experimental validation demonstrates the effectiveness and robustness of the proposed approach, highlighting its substantial potential in addressing prevalent uncertainties in controlling modern power electronics systems.
<div id='section'>Paperid: <span id='pid'>666, <a href='https://arxiv.org/pdf/2406.14715.pdf' target='_blank'>https://arxiv.org/pdf/2406.14715.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Milad Ramezankhani, Anirudh Deodhar, Rishi Yash Parekh, Dagnachew Birru
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14715">An Advanced Physics-Informed Neural Operator for Comprehensive Design Optimization of Highly-Nonlinear Systems: An Aerospace Composites Processing Case Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Operator Networks (DeepONets) and their physics-informed variants have shown significant promise in learning mappings between function spaces of partial differential equations, enhancing the generalization of traditional neural networks. However, for highly nonlinear real-world applications like aerospace composites processing, existing models often fail to capture underlying solutions accurately and are typically limited to single input functions, constraining rapid process design development. This paper introduces an advanced physics-informed DeepONet tailored for such complex systems with multiple input functions. Equipped with architectural enhancements like nonlinear decoders and effective training strategies such as curriculum learning and domain decomposition, the proposed model handles high-dimensional design spaces with significantly improved accuracy, outperforming the vanilla physics-informed DeepONet by two orders of magnitude. Its zero-shot prediction capability across a broad design space makes it a powerful tool for accelerating composites process design and optimization, with potential applications in other engineering fields characterized by strong nonlinearity.
<div id='section'>Paperid: <span id='pid'>667, <a href='https://arxiv.org/pdf/2406.09178.pdf' target='_blank'>https://arxiv.org/pdf/2406.09178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minglun Wei, Xintong Yang, Yu-Kun Lai, Seyed Amir Tafrishi, Ze Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09178">AutomaChef: A Physics-informed Demonstration-guided Learning Framework for Granular Material Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the complex physical properties of granular materials, research on robot learning for manipulating such materials predominantly either disregards the consideration of their physical characteristics or uses surrogate models to approximate their physical properties. Learning to manipulate granular materials based on physical information obtained through precise modelling remains an unsolved problem. In this paper, we propose to address this challenge by constructing a differentiable physics simulator for granular materials based on the Taichi programming language and developing a learning framework accelerated by imperfect demonstrations that are generated via gradient-based optimisation on non-granular materials through our simulator. Experimental results show that our method trains three policies that, when chained, are capable of executing the task of transporting granular materials in both simulated and real-world scenarios, which existing popular deep reinforcement learning models fail to accomplish.
<div id='section'>Paperid: <span id='pid'>668, <a href='https://arxiv.org/pdf/2405.10389.pdf' target='_blank'>https://arxiv.org/pdf/2405.10389.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongwei Jin, Prasanna Balaprakash, Allen Zou, Pieter Ghysels, Aditi S. Krishnapriyan, Adam Mate, Arthur Barnes, Russell Bent
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.10389">Physics-Informed Heterogeneous Graph Neural Networks for DC Blocker Placement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The threat of geomagnetic disturbances (GMDs) to the reliable operation of the bulk energy system has spurred the development of effective strategies for mitigating their impacts. One such approach involves placing transformer neutral blocking devices, which interrupt the path of geomagnetically induced currents (GICs) to limit their impact. The high cost of these devices and the sparsity of transformers that experience high GICs during GMD events, however, calls for a sparse placement strategy that involves high computational cost. To address this challenge, we developed a physics-informed heterogeneous graph neural network (PIHGNN) for solving the graph-based dc-blocker placement problem. Our approach combines a heterogeneous graph neural network (HGNN) with a physics-informed neural network (PINN) to capture the diverse types of nodes and edges in ac/dc networks and incorporates the physical laws of the power grid. We train the PIHGNN model using a surrogate power flow model and validate it using case studies. Results demonstrate that PIHGNN can effectively and efficiently support the deployment of GIC dc-current blockers, ensuring the continued supply of electricity to meet societal demands. Our approach has the potential to contribute to the development of more reliable and resilient power grids capable of withstanding the growing threat that GMDs pose.
<div id='section'>Paperid: <span id='pid'>669, <a href='https://arxiv.org/pdf/2405.01975.pdf' target='_blank'>https://arxiv.org/pdf/2405.01975.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rasoul Najafi Koopas, Shahed Rezaei, Natalie Rauter, Richard Ostwald, Rolf Lammering
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01975">Introducing a microstructure-embedded autoencoder approach for reconstructing high-resolution solution field data from a reduced parametric space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we develop a novel multi-fidelity deep learning approach that transforms low-fidelity solution maps into high-fidelity ones by incorporating parametric space information into a standard autoencoder architecture. This method's integration of parametric space information significantly reduces the need for training data to effectively predict high-fidelity solutions from low-fidelity ones. In this study, we examine a two-dimensional steady-state heat transfer analysis within a highly heterogeneous materials microstructure. The heat conductivity coefficients for two different materials are condensed from a 101 x 101 grid to smaller grids. We then solve the boundary value problem on the coarsest grid using a pre-trained physics-informed neural operator network known as Finite Operator Learning (FOL). The resulting low-fidelity solution is subsequently upscaled back to a 101 x 101 grid using a newly designed enhanced autoencoder. The novelty of the developed enhanced autoencoder lies in the concatenation of heat conductivity maps of different resolutions to the decoder segment in distinct steps. Hence the developed algorithm is named microstructure-embedded autoencoder (MEA). We compare the MEA outcomes with those from finite element methods, the standard U-Net, and various other upscaling techniques, including interpolation functions and feedforward neural networks (FFNN). Our analysis shows that MEA outperforms these methods in terms of computational efficiency and error on test cases. As a result, the MEA serves as a potential supplement to neural operator networks, effectively upscaling low-fidelity solutions to high fidelity while preserving critical details often lost in traditional upscaling methods, particularly at sharp interfaces like those seen with interpolation.
<div id='section'>Paperid: <span id='pid'>670, <a href='https://arxiv.org/pdf/2404.18362.pdf' target='_blank'>https://arxiv.org/pdf/2404.18362.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoyu Ge, Javad Khazaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.18362">Physics-informed Convolutional Neural Network for Microgrid Economic Dispatch</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The variability of renewable energy generation and the unpredictability of electricity demand create a need for real-time economic dispatch (ED) of assets in microgrids. However, solving numerical optimization problems in real-time can be incredibly challenging. This study proposes using a convolutional neural network (CNN) based on deep learning to address these challenges. Compared to traditional methods, CNN is more efficient, delivers more dependable results, and has a shorter response time when dealing with uncertainties. While CNN has shown promising results, it does not extract explainable knowledge from the data. To address this limitation, a physics-inspired CNN model is developed by incorporating constraints of the ED problem into the CNN training to ensure that the model follows physical laws while fitting the data. The proposed method can significantly accelerate real-time economic dispatch of microgrids without compromising the accuracy of numerical optimization techniques. The effectiveness of the proposed data-driven approach for optimal allocation of microgrid resources in real-time is verified through a comprehensive comparison with conventional numerical optimization approaches.
<div id='section'>Paperid: <span id='pid'>671, <a href='https://arxiv.org/pdf/2404.13325.pdf' target='_blank'>https://arxiv.org/pdf/2404.13325.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ignasi Ventura Nadal, Jochen Stiasny, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.13325">Physics-Informed Neural Networks: a Plug and Play Integration into Power System Dynamic Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time-domain simulations are crucial for ensuring power system stability and avoiding critical scenarios that could lead to blackouts. The next-generation power systems require a significant increase in the computational cost and complexity of these simulations due to additional degrees of uncertainty, non-linearity and states. Physics-Informed Neural Networks (PINN) have been shown to accelerate single-component simulations by several orders of magnitude. However, their application to current time-domain simulation solvers has been particularly challenging since the system's dynamics depend on multiple components. Using a new training formulation, this paper introduces the first natural step to integrate PINNs into multi-component time-domain simulations. We propose PINNs as an alternative to other classical numerical methods for individual components. Once trained, these neural networks approximate component dynamics more accurately for longer time steps. Formulated as an implicit and consistent method with the transient simulation workflow, PINNs speed up simulation time by significantly increasing the time steps used. For explanation clarity, we demonstrate the training, integration, and simulation framework for several combinations of PINNs and numerical solution methods using the IEEE 9-bus system, although the method applies equally well to any power system size.
<div id='section'>Paperid: <span id='pid'>672, <a href='https://arxiv.org/pdf/2404.11149.pdf' target='_blank'>https://arxiv.org/pdf/2404.11149.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Stock, Davood Babazadeh, Sari Eid, Christian Becker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.11149">Physics-informed Actor-Critic for Coordination of Virtual Inertia from Power Distribution Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The vanishing inertia of synchronous generators in transmission systems requires the utilization of renewables for inertial support. These are often connected to the distribution system and their support should be coordinated to avoid violation of grid limits. To this end, this paper presents the Physics-informed Actor-Critic (PI-AC) algorithm for coordination of Virtual Inertia (VI) from renewable Inverter-based Resources (IBRs) in power distribution systems. Acquiring a model of the distribution grid can be difficult, since certain parts are often unknown or the parameters are highly uncertain. To favor model-free coordination, Reinforcement Learning (RL) methods can be employed, necessitating a substantial level of training beforehand. The PI-AC is a RL algorithm that integrates the physical behavior of the power system into the Actor-Critic (AC) approach in order to achieve faster learning. To this end, we regularize the loss function with an aggregated power system dynamics model based on the swing equation. Throughout this paper, we explore the PI-AC functionality in a case study with the CIGRE 14-bus and IEEE 37-bus power distribution system in various grid settings. The PI-AC is able to achieve better rewards and faster learning than the exclusively data-driven AC algorithm and the metaheuristic Genetic Algorithm (GA).
<div id='section'>Paperid: <span id='pid'>673, <a href='https://arxiv.org/pdf/2403.18570.pdf' target='_blank'>https://arxiv.org/pdf/2403.18570.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Inaam Ashraf, Janine Strotherm, Luca Hermes, Barbara Hammer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18570">Physics-Informed Graph Neural Networks for Water Distribution Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Water distribution systems (WDS) are an integral part of critical infrastructure which is pivotal to urban development. As 70% of the world's population will likely live in urban environments in 2050, efficient simulation and planning tools for WDS play a crucial role in reaching UN's sustainable developmental goal (SDG) 6 - "Clean water and sanitation for all". In this realm, we propose a novel and efficient machine learning emulator, more precisely, a physics-informed deep learning (DL) model, for hydraulic state estimation in WDS. Using a recursive approach, our model only needs a few graph convolutional neural network (GCN) layers and employs an innovative algorithm based on message passing. Unlike conventional machine learning tasks, the model uses hydraulic principles to infer two additional hydraulic state features in the process of reconstructing the available ground truth feature in an unsupervised manner. To the best of our knowledge, this is the first DL approach to emulate the popular hydraulic simulator EPANET, utilizing no additional information. Like most DL models and unlike the hydraulic simulator, our model demonstrates vastly faster emulation times that do not increase drastically with the size of the WDS. Moreover, we achieve high accuracy on the ground truth and very similar results compared to the hydraulic simulator as demonstrated through experiments on five real-world WDS datasets.
<div id='section'>Paperid: <span id='pid'>674, <a href='https://arxiv.org/pdf/2403.15025.pdf' target='_blank'>https://arxiv.org/pdf/2403.15025.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Xu, Yue Sun, Chao Chen, Parv Venkitasubramaniam, Sihong Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15025">Robust Conformal Prediction under Distribution Shift via Physics-Informed Structural Causal Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty is critical to reliable decision-making with machine learning. Conformal prediction (CP) handles uncertainty by predicting a set on a test input, hoping the set to cover the true label with at least $(1-Î±)$ confidence. This coverage can be guaranteed on test data even if the marginal distributions $P_X$ differ between calibration and test datasets. However, as it is common in practice, when the conditional distribution $P_{Y|X}$ is different on calibration and test data, the coverage is not guaranteed and it is essential to measure and minimize the coverage loss under distributional shift at \textit{all} possible confidence levels. To address these issues, we upper bound the coverage difference at all levels using the cumulative density functions of calibration and test conformal scores and Wasserstein distance. Inspired by the invariance of physics across data distributions, we propose a physics-informed structural causal model (PI-SCM) to reduce the upper bound. We validated that PI-SCM can improve coverage robustness along confidence level and test domain on a traffic speed prediction task and an epidemic spread task with multiple real-world datasets.
<div id='section'>Paperid: <span id='pid'>675, <a href='https://arxiv.org/pdf/2403.13602.pdf' target='_blank'>https://arxiv.org/pdf/2403.13602.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Stock, Davood Babazadeh, Christian Becker, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.13602">Bayesian Physics-informed Neural Networks for System Identification of Inverter-dominated Power Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While the uncertainty in generation and demand increases, accurately estimating the dynamic characteristics of power systems becomes crucial for employing the appropriate control actions to maintain their stability. In our previous work, we have shown that Bayesian Physics-informed Neural Networks (BPINNs) outperform conventional system identification methods in identifying the power system dynamic behavior under measurement noise. This paper takes the next natural step and addresses the more significant challenge, exploring how BPINN perform in estimating power system dynamics under increasing uncertainty from many Inverter-based Resources (IBRs) connected to the grid. These introduce a different type of uncertainty, compared to noisy measurements. The BPINN combines the advantages of Physics-informed Neural Networks (PINNs), such as inverse problem applicability, with Bayesian approaches for uncertainty quantification. We explore the BPINN performance on a wide range of systems, starting from a single machine infinite bus (SMIB) system and 3-bus system to extract important insights, to the 14-bus CIGRE distribution grid, and the large IEEE 118-bus system. We also investigate approaches that can accelerate the BPINN training, such as pretraining and transfer learning. Throughout this paper, we show that in presence of uncertainty, the BPINN achieves orders of magnitude lower errors than the widely popular method for system identification SINDy and significantly lower errors than PINN, while transfer learning helps reduce training time by up to 80 %.
<div id='section'>Paperid: <span id='pid'>676, <a href='https://arxiv.org/pdf/2403.07786.pdf' target='_blank'>https://arxiv.org/pdf/2403.07786.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ronald B. Liu, Zhe Liu, Max G. A. Wolf, Krishna P. Purohit, Gregor Fritz, Yi Feng, Carsten G. Hansen, Pierre O. Bagnaninchi, Xavier Casadevall i Solvas, Yunjie Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.07786">Physics-informed generative real-time lens-free imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advancements in high-throughput biomedical applications require real-time, large field-of-view (FOV) imaging. While current 2D lens-free imaging (LFI) systems improve FOV, they are often hindered by time-consuming multi-position measurements, extensive data pre-processing, and strict optical parameterization, limiting their application to static, thin samples. To overcome these limitations, we introduce GenLFI, combining a generative unsupervised physics-informed neural network (PINN) with a large FOV LFI setup for straightforward holographic image reconstruction, without multi-measurement. GenLFI enables real-time 2D imaging for 3D samples, such as droplet-based microfluidics and 3D cell models, in dynamic complex optical fields. Unlike previous methods, our approach decouples the reconstruction algorithm from optical setup parameters, enabling a large FOV limited only by hardware. We demonstrate a real-time FOV exceeding 550 mm$^2$, over 20 times larger than current real-time LFI systems. This framework unlocks the potential of LFI systems, providing a robust tool for advancing automated high-throughput biomedical applications.
<div id='section'>Paperid: <span id='pid'>677, <a href='https://arxiv.org/pdf/2403.06342.pdf' target='_blank'>https://arxiv.org/pdf/2403.06342.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaemin Oh, Seung Yeon Cho, Seok-Bae Yun, Eunbyung Park, Youngjoon Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.06342">Separable Physics-informed Neural Networks for Solving the BGK Model of the Boltzmann Equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we introduce a method based on Separable Physics-Informed Neural Networks (SPINNs) for effectively solving the BGK model of the Boltzmann equation. While the mesh-free nature of PINNs offers significant advantages in handling high-dimensional partial differential equations (PDEs), challenges arise when applying quadrature rules for accurate integral evaluation in the BGK operator, which can compromise the mesh-free benefit and increase computational costs. To address this, we leverage the canonical polyadic decomposition structure of SPINNs and the linear nature of moment calculation, achieving a substantial reduction in computational expense for quadrature rule application. The multi-scale nature of the particle density function poses difficulties in precisely approximating macroscopic moments using neural networks. To improve SPINN training, we introduce the integration of Gaussian functions into SPINNs, coupled with a relative loss approach. This modification enables SPINNs to decay as rapidly as Maxwellian distributions, thereby enhancing the accuracy of macroscopic moment approximations. The relative loss design further ensures that both large and small-scale features are effectively captured by the SPINNs. The efficacy of our approach is demonstrated through a series of five numerical experiments, including the solution to a challenging 3D Riemann problem. These results highlight the potential of our novel method in efficiently and accurately addressing complex challenges in computational physics.
<div id='section'>Paperid: <span id='pid'>678, <a href='https://arxiv.org/pdf/2402.12503.pdf' target='_blank'>https://arxiv.org/pdf/2402.12503.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Phong C. H. Nguyen, Xinlun Cheng, Shahab Azarfar, Pradeep Seshadri, Yen T. Nguyen, Munho Kim, Sanghun Choi, H. S. Udaykumar, Stephen Baek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.12503">PARCv2: Physics-aware Recurrent Convolutional Neural Networks for Spatiotemporal Dynamics Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling unsteady, fast transient, and advection-dominated physics problems is a pressing challenge for physics-aware deep learning (PADL). The physics of complex systems is governed by large systems of partial differential equations (PDEs) and ancillary constitutive models with nonlinear structures, as well as evolving state fields exhibiting sharp gradients and rapidly deforming material interfaces. Here, we investigate an inductive bias approach that is versatile and generalizable to model generic nonlinear field evolution problems. Our study focuses on the recent physics-aware recurrent convolutions (PARC), which incorporates a differentiator-integrator architecture that inductively models the spatiotemporal dynamics of generic physical systems. We extend the capabilities of PARC to simulate unsteady, transient, and advection-dominant systems. The extended model, referred to as PARCv2, is equipped with differential operators to model advection-reaction-diffusion equations, as well as a hybrid integral solver for stable, long-time predictions. PARCv2 is tested on both standard benchmark problems in fluid dynamics, namely Burgers and Navier-Stokes equations, and then applied to more complex shock-induced reaction problems in energetic materials. We evaluate the behavior of PARCv2 in comparison to other physics-informed and learning bias models and demonstrate its potential to model unsteady and advection-dominant dynamics regimes.
<div id='section'>Paperid: <span id='pid'>679, <a href='https://arxiv.org/pdf/2402.08313.pdf' target='_blank'>https://arxiv.org/pdf/2402.08313.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Franz M. Rohrhofer, Stefan Posch, Clemens GÃ¶Ãnitzer, Bernhard C. Geiger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08313">Approximating Families of Sharp Solutions to Fisher's Equation with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper employs physics-informed neural networks (PINNs) to solve Fisher's equation, a fundamental reaction-diffusion system with both simplicity and significance. The focus is on investigating Fisher's equation under conditions of large reaction rate coefficients, where solutions exhibit steep traveling waves that often present challenges for traditional numerical methods. To address these challenges, a residual weighting scheme is introduced in the network training to mitigate the difficulties associated with standard PINN approaches. Additionally, a specialized network architecture designed to capture traveling wave solutions is explored. The paper also assesses the ability of PINNs to approximate a family of solutions by generalizing across multiple reaction rate coefficients. The proposed method demonstrates high effectiveness in solving Fisher's equation with large reaction rate coefficients and shows promise for meshfree solutions of generalized reaction-diffusion systems.
<div id='section'>Paperid: <span id='pid'>680, <a href='https://arxiv.org/pdf/2402.07153.pdf' target='_blank'>https://arxiv.org/pdf/2402.07153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Beatrice Lorenz, Aras Bacho, Gitta Kutyniok
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07153">Error Estimation for Physics-informed Neural Networks Approximating Semilinear Wave Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper provides rigorous error bounds for physics-informed neural networks approximating the semilinear wave equation. We provide bounds for the generalization and training error in terms of the width of the network's layers and the number of training points for a tanh neural network with two hidden layers. Our main result is a bound of the total error in the $H^1([0,T];L^2(Î©))$-norm in terms of the training error and the number of training points, which can be made arbitrarily small under some assumptions. We illustrate our theoretical bounds with numerical experiments.
<div id='section'>Paperid: <span id='pid'>681, <a href='https://arxiv.org/pdf/2401.14081.pdf' target='_blank'>https://arxiv.org/pdf/2401.14081.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tayebeh Taheri, Alireza Afzal Aghaei, Kourosh Parand
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.14081">Accelerating Fractional PINNs using Operational Matrices of Derivative</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel operational matrix method to accelerate the training of fractional Physics-Informed Neural Networks (fPINNs). Our approach involves a non-uniform discretization of the fractional Caputo operator, facilitating swift computation of fractional derivatives within Caputo-type fractional differential problems with $0<Î±<1$. In this methodology, the operational matrix is precomputed, and during the training phase, automatic differentiation is replaced with a matrix-vector product. While our methodology is compatible with any network, we particularly highlight its successful implementation in PINNs, emphasizing the enhanced accuracy achieved when utilizing the Legendre Neural Block (LNB) architecture. LNB incorporates Legendre polynomials into the PINN structure, providing a significant boost in accuracy. The effectiveness of our proposed method is validated across diverse differential equations, including Delay Differential Equations (DDEs) and Systems of Differential Algebraic Equations (DAEs). To demonstrate its versatility, we extend the application of the method to systems of differential equations, specifically addressing nonlinear Pantograph fractional-order DDEs/DAEs. The results are supported by a comprehensive analysis of numerical outcomes.
<div id='section'>Paperid: <span id='pid'>682, <a href='https://arxiv.org/pdf/2401.13098.pdf' target='_blank'>https://arxiv.org/pdf/2401.13098.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruixin Song, Gabriel Spadon, Ronald Pelot, Stan Matwin, Amilcar Soares
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.13098">Enhancing Global Maritime Traffic Network Forecasting with Gravity-Inspired Deep Learning Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Aquatic non-indigenous species (NIS) pose significant threats to biodiversity, disrupting ecosystems and inflicting substantial economic damages across agriculture, forestry, and fisheries. Due to the fast growth of global trade and transportation networks, NIS has been introduced and spread unintentionally in new environments. This study develops a new physics-informed model to forecast maritime shipping traffic between port regions worldwide. The predicted information provided by these models, in turn, is used as input for risk assessment of NIS spread through transportation networks to evaluate the capability of our solution. Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs. Accordingly, this paper introduces transformers to gravity models to rebuild the short- and long-term dependencies that make the risk analysis feasible. Thus, we introduce a physics-inspired framework that achieves an 89% binary accuracy for existing and non-existing trajectories and an 84.8% accuracy for the number of vessels flowing between key port areas, representing more than 10% improvement over the traditional deep-gravity model. Along these lines, this research contributes to a better understanding of NIS risk assessment. It allows policymakers, conservationists, and stakeholders to prioritize management actions by identifying high-risk invasion pathways. Besides, our model is versatile and can include new data sources, making it suitable for assessing international vessel traffic flow in a changing global landscape.
<div id='section'>Paperid: <span id='pid'>683, <a href='https://arxiv.org/pdf/2401.05211.pdf' target='_blank'>https://arxiv.org/pdf/2401.05211.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jochen Stiasny, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05211">Error estimation for physics-informed neural networks with implicit Runge-Kutta methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to accurately approximate trajectories of dynamical systems enables their analysis, prediction, and control. Neural network (NN)-based approximations have attracted significant interest due to fast evaluation with good accuracy over long integration time steps. In contrast to established numerical approximation schemes such as Runge-Kutta methods, the estimation of the error of the NN-based approximations proves to be difficult. In this work, we propose to use the NN's predictions in a high-order implicit Runge-Kutta (IRK) method. The residuals in the implicit system of equations can be related to the NN's prediction error, hence, we can provide an error estimate at several points along a trajectory. We find that this error estimate highly correlates with the NN's prediction error and that increasing the order of the IRK method improves this estimate. We demonstrate this estimation methodology for Physics-Informed Neural Network (PINNs) on the logistic equation as an illustrative example and then apply it to a four-state electric generator model that is regularly used in power system modelling.
<div id='section'>Paperid: <span id='pid'>684, <a href='https://arxiv.org/pdf/2401.01828.pdf' target='_blank'>https://arxiv.org/pdf/2401.01828.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ilia Kamyshev, Sahar Moghimian Hoosh, Henni Ouerdane
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01828">Physics-informed appliance signatures generator for energy disaggregation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Energy disaggregation is a promising solution to access detailed information on energy consumption in a household, by itemizing its total energy consumption. However, in real-world applications, overfitting remains a challenging problem for data-driven disaggregation methods. First, the available real-world datasets are biased towards the most frequently used appliances. Second, both real and synthetic publicly-available datasets are limited in number of appliances, which may not be sufficient for a disaggregation algorithm to learn complex relations among different types of appliances and their states. To address the lack of appliance data, we propose two physics-informed data generators: one for high sampling rate signals (kHz) and another for low sampling rate signals (Hz). These generators rely on prior knowledge of the physics of appliance energy consumption, and are capable of simulating a virtually unlimited number of different appliances and their corresponding signatures for any time period. Both methods involve defining a mathematical model, selecting centroids corresponding to individual appliances, sampling model parameters around each centroid, and finally substituting the obtained parameters into the mathematical model. Additionally, by using Principal Component Analysis and Kullback-Leibler divergence, we demonstrate that our methods significantly outperform the previous approaches.
<div id='section'>Paperid: <span id='pid'>685, <a href='https://arxiv.org/pdf/2312.10389.pdf' target='_blank'>https://arxiv.org/pdf/2312.10389.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaxin Feng, Yuan Lan, Luchan Zhang, Yang Xiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10389">ElasticLaneNet: An Efficient Geometry-Flexible Approach for Lane Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The task of lane detection involves identifying the boundaries of driving areas in real-time. Recognizing lanes with variable and complex geometric structures remains a challenge. In this paper, we explore a novel and flexible way of implicit lanes representation named \textit{Elastic Lane map (ELM)}, and introduce an efficient physics-informed end-to-end lane detection framework, namely, ElasticLaneNet (Elastic interaction energy-informed Lane detection Network). The approach considers predicted lanes as moving zero-contours on the flexibly shaped \textit{ELM} that are attracted to the ground truth guided by an elastic interaction energy-loss function (EIE loss). Our framework well integrates the global information and low-level features. The method performs well in complex lane scenarios, including those with large curvature, weak geometry features at intersections, complicated cross lanes, Y-shapes lanes, dense lanes, etc. We apply our approach on three datasets: SDLane, CULane, and TuSimple. The results demonstrate exceptional performance of our method, with the state-of-the-art results on the structurally diverse SDLane, achieving F1-score of 89.51, Recall rate of 87.50, and Precision of 91.61 with fast inference speed.
<div id='section'>Paperid: <span id='pid'>686, <a href='https://arxiv.org/pdf/2312.09775.pdf' target='_blank'>https://arxiv.org/pdf/2312.09775.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zi-Yu Khoo, Jonathan Sze Choong Low, StÃ©phane Bressan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.09775">A Comparative Evaluation of Additive Separability Tests for Physics-Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many functions characterising physical systems are additively separable. This is the case, for instance, of mechanical Hamiltonian functions in physics, population growth equations in biology, and consumer preference and utility functions in economics. We consider the scenario in which a surrogate of a function is to be tested for additive separability. The detection that the surrogate is additively separable can be leveraged to improve further learning. Hence, it is beneficial to have the ability to test for such separability in surrogates. The mathematical approach is to test if the mixed partial derivative of the surrogate is zero; or empirically, lower than a threshold. We present and comparatively and empirically evaluate the eight methods to compute the mixed partial derivative of a surrogate function.
<div id='section'>Paperid: <span id='pid'>687, <a href='https://arxiv.org/pdf/2312.09418.pdf' target='_blank'>https://arxiv.org/pdf/2312.09418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rajnish Kumar, Suriya Prakash Muthukrishnan, Lalan Kumar, Sitikantha Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.09418">Predicting Multi-Joint Kinematics of the Upper Limb from EMG Signals Across Varied Loads with a Physics-Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this research, we present an innovative method known as a physics-informed neural network (PINN) model to predict multi-joint kinematics using electromyography (EMG) signals recorded from the muscles surrounding these joints across various loads. The primary aim is to simultaneously predict both the shoulder and elbow joint angles while executing elbow flexion-extension (FE) movements, especially under varying load conditions. The PINN model is constructed by combining a feed-forward Artificial Neural Network (ANN) with a joint torque computation model. During the training process, the model utilizes a custom loss function derived from an inverse dynamics joint torque musculoskeletal model, along with a mean square angle loss. The training dataset for the PINN model comprises EMG and time data collected from four different subjects. To assess the model's performance, we conducted a comparison between the predicted joint angles and experimental data using a testing data set. The results demonstrated strong correlations of 58% to 83% in joint angle prediction. The findings highlight the potential of incorporating physical principles into the model, not only increasing its versatility but also enhancing its accuracy. The findings could have significant implications for the precise estimation of multi-joint kinematics in dynamic scenarios, particularly concerning the advancement of human-machine interfaces (HMIs) for exoskeletons and prosthetic control systems.
<div id='section'>Paperid: <span id='pid'>688, <a href='https://arxiv.org/pdf/2311.16167.pdf' target='_blank'>https://arxiv.org/pdf/2311.16167.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Yang, Qihong Yang, Yangtao Deng, Qiaolin He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16167">Moving Sampling Physics-informed Neural Networks induced by Moving Mesh PDE</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we propose an end-to-end adaptive sampling neural network (MMPDE-Net) based on the moving mesh method, which can adaptively generate new sampling points by solving the moving mesh PDE. This model focuses on improving the quality of sampling points generation. Moreover, we develop an iterative algorithm based on MMPDE-Net, which makes the sampling points more precise and controllable. Since MMPDE-Net is a framework independent of the deep learning solver, we combine it with physics-informed neural networks (PINN) to propose moving sampling PINN (MS-PINN) and demonstrate its effectiveness by error analysis under some assumptions. Finally, we demonstrate the performance improvement of MS-PINN compared to PINN through numerical experiments of four typical examples, which numerically verify the effectiveness of our method.
<div id='section'>Paperid: <span id='pid'>689, <a href='https://arxiv.org/pdf/2310.18612.pdf' target='_blank'>https://arxiv.org/pdf/2310.18612.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saad Qadeer, Andrew Engel, Amanda Howard, Adam Tsou, Max Vargas, Panos Stinis, Tony Chiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18612">Efficient kernel surrogates for neural network-based regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite their immense promise in performing a variety of learning tasks, a theoretical understanding of the limitations of Deep Neural Networks (DNNs) has so far eluded practitioners. This is partly due to the inability to determine the closed forms of the learned functions, making it harder to study their generalization properties on unseen datasets. Recent work has shown that randomly initialized DNNs in the infinite width limit converge to kernel machines relying on a Neural Tangent Kernel (NTK) with known closed form. These results suggest, and experimental evidence corroborates, that empirical kernel machines can also act as surrogates for finite width DNNs. The high computational cost of assembling the full NTK, however, makes this approach infeasible in practice, motivating the need for low-cost approximations. In the current work, we study the performance of the Conjugate Kernel (CK), an efficient approximation to the NTK that has been observed to yield fairly similar results. For the regression problem of smooth functions and logistic regression classification, we show that the CK performance is only marginally worse than that of the NTK and, in certain cases, is shown to be superior. In particular, we establish bounds for the relative test losses, verify them with numerical tests, and identify the regularity of the kernel as the key determinant of performance. In addition to providing a theoretical grounding for using CKs instead of NTKs, our framework suggests a recipe for improving DNN accuracy inexpensively. We present a demonstration of this on the foundation model GPT-2 by comparing its performance on a classification task using a conventional approach and our prescription. We also show how our approach can be used to improve physics-informed operator network training for regression tasks as well as convolutional neural network training for vision classification tasks.
<div id='section'>Paperid: <span id='pid'>690, <a href='https://arxiv.org/pdf/2310.17331.pdf' target='_blank'>https://arxiv.org/pdf/2310.17331.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianfu Luo, Yelin Feng, Qingfu Huang, Zongliang Zhang, Mingjiao Yan, Zaihong Yang, Dawei Zheng, Yang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.17331">A novel solution for seepage problems using physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A Physics-Informed Neural Network (PINN) provides a distinct advantage by synergizing neural networks' capabilities with the problem's governing physical laws. In this study, we introduce an innovative approach for solving seepage problems by utilizing the PINN, harnessing the capabilities of Deep Neural Networks (DNNs) to approximate hydraulic head distributions in seepage analysis. To effectively train the PINN model, we introduce a comprehensive loss function comprising three components: one for evaluating differential operators, another for assessing boundary conditions, and a third for appraising initial conditions. The validation of the PINN involves solving four benchmark seepage problems. The results unequivocally demonstrate the exceptional accuracy of the PINN in solving seepage problems, surpassing the accuracy of FEM in addressing both steady-state and free-surface seepage problems. Hence, the presented approach highlights the robustness of the PINN and underscores its precision in effectively addressing a spectrum of seepage challenges. This amalgamation enables the derivation of accurate solutions, overcoming limitations inherent in conventional methods such as mesh generation and adaptability to complex geometries.
<div id='section'>Paperid: <span id='pid'>691, <a href='https://arxiv.org/pdf/2309.16950.pdf' target='_blank'>https://arxiv.org/pdf/2309.16950.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qing Shen, Yifan Zhou, Huanfeng Zhao, Peng Zhang, Qiang Zhang, Slava Maslenniko, Xiaochuan Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16950">Scalable Neural Dynamic Equivalence for Power Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional grid analytics are model-based, relying strongly on accurate models of power systems, especially the dynamic models of generators, controllers, loads and other dynamic components. However, acquiring thorough power system models can be impractical in real operation due to inaccessible system parameters and privacy of consumers, which necessitate data-driven dynamic equivalencing of unknown subsystems. Learning reliable dynamic equivalent models for the external systems from SCADA and PMU data, however, is a long-standing intractable problem in power system analysis due to complicated nonlinearity and unforeseeable dynamic modes of power systems. This paper advances a practical application of neural dynamic equivalence (NeuDyE) called Driving Port NeuDyE (DP-NeuDyE), which exploits physics-informed machine learning and neural-ordinary-differential-equations (ODE-NET) to discover a dynamic equivalence of external power grids while preserving its dynamic behaviors after disturbances. The new contributions are threefold: A NeuDyE formulation to enable a continuous-time, data-driven dynamic equivalence of power systems, saving the effort and expense of acquiring inaccessible system; An introduction of a Physics-Informed NeuDyE learning (PI-NeuDyE) to actively control the closed-loop accuracy of NeuDyE; and A DP-NeuDyE to reduce the number of inputs required for the training. We conduct extensive case studies on the NPCC system to validate the generalizability and accuracy of both PI-NeuDyE and DP-NeuDyE, which span a multitude of scenarios, differing in the time required for fault clearance, the specific fault locations, and the limitations of data. Test results have demonstrated the scalability and practicality of NeuDyE, showing its potential to be used in ISO and utility control centers for online transient stability analysis and for planning purposes.
<div id='section'>Paperid: <span id='pid'>692, <a href='https://arxiv.org/pdf/2309.16943.pdf' target='_blank'>https://arxiv.org/pdf/2309.16943.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qing Shen, Yifan Zhou, Peng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16943">Physics-Informed Induction Machine Modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This rapid communication devises a Neural Induction Machine (NeuIM) model, which pilots the use of physics-informed machine learning to enable AI-based electromagnetic transient simulations. The contributions are threefold: (1) a formation of NeuIM to represent the induction machine in phase domain; (2) a physics-informed neural network capable of capturing fast and slow IM dynamics even in the absence of data; and (3) a data-physics-integrated hybrid NeuIM approach which is adaptive to various levels of data availability. Extensive case studies validate the efficacy of NeuIM and in particular, its advantage over purely data-driven approaches.
<div id='section'>Paperid: <span id='pid'>693, <a href='https://arxiv.org/pdf/2309.16934.pdf' target='_blank'>https://arxiv.org/pdf/2309.16934.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qing Shen, Yifan Zhou, Qiang Zhang, Slava Maslennikov, Xiaochuan Luo, Peng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16934">Physics-Aware Neural Dynamic Equivalence of Power Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This letter devises Neural Dynamic Equivalence (NeuDyE), which explores physics-aware machine learning and neural-ordinary-differential-equations (ODE-Net) to discover a dynamic equivalence of external power grids while preserving its dynamic behaviors after disturbances. The contributions are threefold: (1) an ODE-Net-enabled NeuDyE formulation to enable a continuous-time, data-driven dynamic equivalence of power systems; (2) a physics-informed NeuDyE learning method (PI-NeuDyE) to actively control the closed-loop accuracy of NeuDyE without an additional verification module; (3) a physics-guided NeuDyE (PG-NeuDyE) to enhance the method's applicability even in the absence of analytical physics models. Extensive case studies in the NPCC system validate the efficacy of NeuDyE, and, in particular, its capability under various contingencies.
<div id='section'>Paperid: <span id='pid'>694, <a href='https://arxiv.org/pdf/2308.14537.pdf' target='_blank'>https://arxiv.org/pdf/2308.14537.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sidi Wu, Aiqing Zhu, Yifa Tang, Benzhuo Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.14537">Solving parametric elliptic interface problems via interfaced operator network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning operators mapping between infinite-dimensional Banach spaces via neural networks has attracted a considerable amount of attention in recent years. In this paper, we propose an interfaced operator network (IONet) to solve parametric elliptic interface PDEs, where different coefficients, source terms, and boundary conditions are considered as input features. To capture the discontinuities in both the input functions and the output solutions across the interface, IONet divides the entire domain into several separate subdomains according to the interface and uses multiple branch nets and trunk nets. Each branch net extracts latent representations of input functions at a fixed number of sensors on a specific subdomain, and each trunk net is responsible for output solutions on one subdomain. Additionally, tailored physics-informed loss of IONet is proposed to ensure physical consistency, which greatly reduces the training dataset requirement and makes IONet effective without any paired input-output observations inside the computational domain. Extensive numerical studies demonstrate that IONet outperforms existing state-of-the-art deep operator networks in terms of accuracy and versatility.
<div id='section'>Paperid: <span id='pid'>695, <a href='https://arxiv.org/pdf/2308.08989.pdf' target='_blank'>https://arxiv.org/pdf/2308.08989.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taniya Kapoor, Abhishek Chandra, Daniel M. Tartakovsky, Hongrui Wang, Alfredo Nunez, Rolf Dollevoet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08989">Neural oscillators for generalization of physics-informed machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A primary challenge of physics-informed machine learning (PIML) is its generalization beyond the training domain, especially when dealing with complex physical problems represented by partial differential equations (PDEs). This paper aims to enhance the generalization capabilities of PIML, facilitating practical, real-world applications where accurate predictions in unexplored regions are crucial. We leverage the inherent causality and temporal sequential characteristics of PDE solutions to fuse PIML models with recurrent neural architectures based on systems of ordinary differential equations, referred to as neural oscillators. Through effectively capturing long-time dependencies and mitigating the exploding and vanishing gradient problem, neural oscillators foster improved generalization in PIML tasks. Extensive experimentation involving time-dependent nonlinear PDEs and biharmonic beam equations demonstrates the efficacy of the proposed approach. Incorporating neural oscillators outperforms existing state-of-the-art methods on benchmark problems across various metrics. Consequently, the proposed method improves the generalization capabilities of PIML, providing accurate solutions for extrapolation and prediction beyond the training data.
<div id='section'>Paperid: <span id='pid'>696, <a href='https://arxiv.org/pdf/2307.07344.pdf' target='_blank'>https://arxiv.org/pdf/2307.07344.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaoyu Liu, Zhonghua Qiao, Chao Li, Carola-Bibiane SchÃ¶nlieb
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.07344">Inverse Evolution Layers: Physics-informed Regularizers for Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional image processing methods employing partial differential equations (PDEs) offer a multitude of meaningful regularizers, along with valuable theoretical foundations for a wide range of image-related tasks. This makes their integration into neural networks a promising avenue. In this paper, we introduce a novel regularization approach inspired by the reverse process of PDE-based evolution models. Specifically, we propose inverse evolution layers (IELs), which serve as bad property amplifiers to penalize neural networks of which outputs have undesired characteristics. Using IELs, one can achieve specific regularization objectives and endow neural networks' outputs with corresponding properties of the PDE models. Our experiments, focusing on semantic segmentation tasks using heat-diffusion IELs, demonstrate their effectiveness in mitigating noisy label effects. Additionally, we develop curve-motion IELs to enforce convex shape regularization in neural network-based segmentation models for preventing the generation of concave outputs. Theoretical analysis confirms the efficacy of IELs as an effective regularization mechanism, particularly in handling training with label issues.
<div id='section'>Paperid: <span id='pid'>697, <a href='https://arxiv.org/pdf/2306.06304.pdf' target='_blank'>https://arxiv.org/pdf/2306.06304.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Santiago Badia, Wei Li, Alberto F. MartÃ­n
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06304">Finite element interpolated neural networks for solving forward and inverse problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a general framework for solving forward and inverse problems constrained by partial differential equations, where we interpolate neural networks onto finite element spaces to represent the (partial) unknowns. The framework overcomes the challenges related to the imposition of boundary conditions, the choice of collocation points in physics-informed neural networks, and the integration of variational physics-informed neural networks. A numerical experiment set confirms the framework's capability of handling various forward and inverse problems. In particular, the trained neural network generalises well for smooth problems, beating finite element solutions by some orders of magnitude. We finally propose an effective one-loop solver with an initial data fitting step (to obtain a cheap initialisation) to solve inverse problems.
<div id='section'>Paperid: <span id='pid'>698, <a href='https://arxiv.org/pdf/2305.17799.pdf' target='_blank'>https://arxiv.org/pdf/2305.17799.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Diab W. Abueidda, Mostafa E. Mobasher
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.17799">I-FENN for thermoelasticity based on physics-informed temporal convolutional network (PI-TCN)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most currently available methods for modeling multiphysics, including thermoelasticity, using machine learning approaches, are focused on solving complete multiphysics problems using data-driven or physics-informed multi-layer perceptron (MLP) networks. Such models rely on incremental step-wise training of the MLPs, and lead to elevated computational expense; they also lack the rigor of existing numerical methods like the finite element method. We propose an integrated finite element neural network (I-FENN) framework to expedite the solution of coupled transient thermoelasticity. A novel physics-informed temporal convolutional network (PI-TCN) is developed and embedded within the finite element framework to leverage the fast inference of neural networks (NNs). The PI-TCN model captures some of the fields in the multiphysics problem; then, the network output is used to compute the other fields of interest using the finite element method. We establish a framework that computationally decouples the energy equation from the linear momentum equation. We first develop a PI-TCN model to predict the spatiotemporal evolution of the temperature field across the simulation time based on the energy equation and strain data. The PI-TCN model is integrated into the finite element framework, where the PI-TCN output (temperature) is used to introduce the temperature effect to the linear momentum equation. The finite element problem is solved using the implicit Euler time discretization scheme, resulting in a computational cost comparable to that of a weakly-coupled thermoelasticity problem but with the ability to solve fully-coupled problems. Finally, we demonstrate I-FENN's computational efficiency and generalization capability in thermoelasticity through several numerical examples.
<div id='section'>Paperid: <span id='pid'>699, <a href='https://arxiv.org/pdf/2305.10952.pdf' target='_blank'>https://arxiv.org/pdf/2305.10952.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amartya Mukherjee, Jun Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.10952">Actor-Critic Methods using Physics-Informed Neural Networks: Control of a 1D PDE Model for Fluid-Cooled Battery Packs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes an actor-critic algorithm for controlling the temperature of a battery pack using a cooling fluid. This is modeled by a coupled 1D partial differential equation (PDE) with a controlled advection term that determines the speed of the cooling fluid. The Hamilton-Jacobi-Bellman (HJB) equation is a PDE that evaluates the optimality of the value function and determines an optimal controller. We propose an algorithm that treats the value network as a Physics-Informed Neural Network (PINN) to solve for the continuous-time HJB equation rather than a discrete-time Bellman optimality equation, and we derive an optimal controller for the environment that we exploit to achieve optimal control. Our experiments show that a hybrid-policy method that updates the value network using the HJB equation and updates the policy network identically to PPO achieves the best results in the control of this PDE system.
<div id='section'>Paperid: <span id='pid'>700, <a href='https://arxiv.org/pdf/2305.08466.pdf' target='_blank'>https://arxiv.org/pdf/2305.08466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yahong Yang, Haizhao Yang, Yang Xiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.08466">Nearly Optimal VC-Dimension and Pseudo-Dimension Bounds for Deep Neural Network Derivatives</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the problem of nearly optimal Vapnik--Chervonenkis dimension (VC-dimension) and pseudo-dimension estimations of the derivative functions of deep neural networks (DNNs). Two important applications of these estimations include: 1) Establishing a nearly tight approximation result of DNNs in the Sobolev space; 2) Characterizing the generalization error of machine learning methods with loss functions involving function derivatives. This theoretical investigation fills the gap of learning error estimations for a wide range of physics-informed machine learning models and applications including generative models, solving partial differential equations, operator learning, network compression, distillation, regularization, etc.
<div id='section'>Paperid: <span id='pid'>701, <a href='https://arxiv.org/pdf/2304.13807.pdf' target='_blank'>https://arxiv.org/pdf/2304.13807.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyeonjung, Jung, Jayant Gupta, Bharat Jayaprakash, Matthew Eagon, Harish Panneer Selvam, Carl Molnar, William Northrop, Shashi Shekhar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.13807">A Survey on Solving and Discovering Differential Equations Using Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ordinary and partial differential equations (DE) are used extensively in scientific and mathematical domains to model physical systems. Current literature has focused primarily on deep neural network (DNN) based methods for solving a specific DE or a family of DEs. Research communities with a history of using DE models may view DNN-based differential equation solvers (DNN-DEs) as a faster and transferable alternative to current numerical methods. However, there is a lack of systematic surveys detailing the use of DNN-DE methods across physical application domains and a generalized taxonomy to guide future research. This paper surveys and classifies previous works and provides an educational tutorial for senior practitioners, professionals, and graduate students in engineering and computer science. First, we propose a taxonomy to navigate domains of DE systems studied under the umbrella of DNN-DE. Second, we examine the theory and performance of the Physics Informed Neural Network (PINN) to demonstrate how the influential DNN-DE architecture mathematically solves a system of equations. Third, to reinforce the key ideas of solving and discovery of DEs using DNN, we provide a tutorial using DeepXDE, a Python package for developing PINNs, to develop DNN-DEs for solving and discovering a classic DE, the linear transport equation.
<div id='section'>Paperid: <span id='pid'>702, <a href='https://arxiv.org/pdf/2303.10256.pdf' target='_blank'>https://arxiv.org/pdf/2303.10256.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jochen Stiasny, Baosen Zhang, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.10256">PINNSim: A Simulator for Power System Dynamics based on Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The dynamic behaviour of a power system can be described by a system of differential-algebraic equations. Time-domain simulations are used to simulate the evolution of these dynamics. They often require the use of small time step sizes and therefore become computationally expensive. To accelerate these simulations, we propose a simulator - PINNSim - that allows to take significantly larger time steps. It is based on Physics-Informed Neural Networks (PINNs) for the solution of the dynamics of single components in the power system. To resolve their interaction we employ a scalable root-finding algorithm. We demonstrate PINNSim on a 9-bus system and show the increased time step size compared to a trapezoidal integration rule. We discuss key characteristics of PINNSim and important steps for developing PINNSim into a fully fledged simulator. As such, it could offer the opportunity for significantly increasing time step sizes and thereby accelerating time-domain simulations.
<div id='section'>Paperid: <span id='pid'>703, <a href='https://arxiv.org/pdf/2303.08994.pdf' target='_blank'>https://arxiv.org/pdf/2303.08994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jochen Stiasny, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08994">Physics-Informed Neural Networks for Time-Domain Simulations: Accuracy, Computational Cost, and Flexibility</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The simulation of power system dynamics poses a computationally expensive task. Considering the growing uncertainty of generation and demand patterns, thousands of scenarios need to be continuously assessed to ensure the safety of power systems. Physics-Informed Neural Networks (PINNs) have recently emerged as a promising solution for drastically accelerating computations of non-linear dynamical systems. This work investigates the applicability of these methods for power system dynamics, focusing on the dynamic response to load disturbances. Comparing the prediction of PINNs to the solution of conventional solvers, we find that PINNs can be 10 to 1000 times faster than conventional solvers. At the same time, we find them to be sufficiently accurate and numerically stable even for large time steps. To facilitate a deeper understanding, this paper also present a new regularisation of Neural Network (NN) training by introducing a gradient-based term in the loss function. The resulting NNs, which we call dtNNs, help us deliver a comprehensive analysis about the strengths and weaknesses of the NN based approaches, how incorporating knowledge of the underlying physics affects NN performance, and how this compares with conventional solvers for power system dynamics.
<div id='section'>Paperid: <span id='pid'>704, <a href='https://arxiv.org/pdf/2303.08455.pdf' target='_blank'>https://arxiv.org/pdf/2303.08455.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Yang, Helin Gong, Qihong Yang, Yangtao Deng, Qiaolin He, Shiquan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08455">On the uncertainty analysis of the data-enabled physics-informed neural network for solving neutron diffusion eigenvalue problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In practical engineering experiments, the data obtained through detectors are inevitably noisy. For the already proposed data-enabled physics-informed neural network (DEPINN) \citep{DEPINN}, we investigate the performance of DEPINN in calculating the neutron diffusion eigenvalue problem from several perspectives when the prior data contain different scales of noise. Further, in order to reduce the effect of noise and improve the utilization of the noisy prior data, we propose innovative interval loss functions and give some rigorous mathematical proofs. The robustness of DEPINN is examined on two typical benchmark problems through a large number of numerical results, and the effectiveness of the proposed interval loss function is demonstrated by comparison. This paper confirms the feasibility of the improved DEPINN for practical engineering applications in nuclear reactor physics.
<div id='section'>Paperid: <span id='pid'>705, <a href='https://arxiv.org/pdf/2303.02306.pdf' target='_blank'>https://arxiv.org/pdf/2303.02306.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyue Wang, Haiwang Zhong, Guanglun Zhang, Guangchun Ruan, Yiliu He, Zekuan Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02306">Look-Ahead AC Optimal Power Flow: A Model-Informed Reinforcement Learning Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the increasing proportion of renewable energy in the generation side, it becomes more difficult to accurately predict the power generation and adapt to the large deviations between the optimal dispatch scheme and the day-ahead scheduling in the process of real-time dispatch. Therefore, it is necessary to conduct look-ahead dispatches to revise the operation plan according to the real-time status of the power grid and reliable ultra-short-term prediction. Application of traditional model-driven methods is often limited by the scale of the power system and cannot meet the computational time requirements of real-time dispatch. Data-driven methods can provide strong online decision-making support abilities when facing large-scale systems, while it is limited by the quantity and quality of the training dataset. This paper proposes a model-informed reinforcement learning approach for look-ahead AC optimal power flow. The reinforcement learning model is first formulated based on the domain knowledge of economic dispatch, and then the physics-informed neural network is constructed to enhance the reliability and efficiency. At last, the case study based on the SG 126-bus system validates the accuracy and efficiency of the proposed approach.
<div id='section'>Paperid: <span id='pid'>706, <a href='https://arxiv.org/pdf/2302.01518.pdf' target='_blank'>https://arxiv.org/pdf/2302.01518.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Cheng Wong, Pao-Hsiung Chiu, Chinchun Ooi, My Ha Dao, Yew-Soon Ong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.01518">LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex Geometry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel loss formulation for efficient learning of complex dynamics from governing physics, typically described by partial differential equations (PDEs), using physics-informed neural networks (PINNs). In our experiments, existing versions of PINNs are seen to learn poorly in many problems, especially for complex geometries, as it becomes increasingly difficult to establish appropriate sampling strategy at the near boundary region. Overly dense sampling can adversely impede training convergence if the local gradient behaviors are too complex to be adequately modelled by PINNs. On the other hand, if the samples are too sparse, existing PINNs tend to overfit the near boundary region, leading to incorrect solution. To prevent such issues, we propose a new Boundary Connectivity (BCXN) loss function which provides linear local structure approximation (LSA) to the gradient behaviors at the boundary for PINN. Our BCXN-loss implicitly imposes local structure during training, thus facilitating fast physics-informed learning across entire problem domains with order of magnitude sparser training samples. This LSA-PINN method shows a few orders of magnitude smaller errors than existing methods in terms of the standard L2-norm metric, while using dramatically fewer training samples and iterations. Our proposed LSA-PINN does not pose any requirement on the differentiable property of the networks, and we demonstrate its benefits and ease of implementation on both multi-layer perceptron and convolutional neural network versions as commonly used in current PINN literature.
<div id='section'>Paperid: <span id='pid'>707, <a href='https://arxiv.org/pdf/2302.00237.pdf' target='_blank'>https://arxiv.org/pdf/2302.00237.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amartya Mukherjee, Jun Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.00237">Bridging Physics-Informed Neural Networks with Reinforcement Learning: Hamilton-Jacobi-Bellman Proximal Policy Optimization (HJBPPO)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces the Hamilton-Jacobi-Bellman Proximal Policy Optimization (HJBPPO) algorithm into reinforcement learning. The Hamilton-Jacobi-Bellman (HJB) equation is used in control theory to evaluate the optimality of the value function. Our work combines the HJB equation with reinforcement learning in continuous state and action spaces to improve the training of the value network. We treat the value network as a Physics-Informed Neural Network (PINN) to solve for the HJB equation by computing its derivatives with respect to its inputs exactly. The Proximal Policy Optimization (PPO)-Clipped algorithm is improvised with this implementation as it uses a value network to compute the objective function for its policy network. The HJBPPO algorithm shows an improved performance compared to PPO on the MuJoCo environments.
<div id='section'>Paperid: <span id='pid'>708, <a href='https://arxiv.org/pdf/2301.10714.pdf' target='_blank'>https://arxiv.org/pdf/2301.10714.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vahidullah Tac, Kevin Linka, Francisco Sahli-Costabal, Ellen Kuhl, Adrian Buganza Tepole
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.10714">Benchmarks for physics-informed data-driven hyperelasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven methods have changed the way we understand and model materials. However, while providing unmatched flexibility, these methods have limitations such as reduced capacity to extrapolate, overfitting, and violation of physics constraints. Recent developments have led to modeling frameworks that automatically satisfy these requirements. Here we review, extend, and compare three promising data-driven methods: Constitutive Artificial Neural Networks (CANN), Input Convex Neural Networks (ICNN), and Neural Ordinary Differential Equations (NODE). Our formulation expands the strain energy potentials in terms of sums of convex non-decreasing functions of invariants and linear combinations of these. The expansion of the energy is shared across all three methods and guarantees the automatic satisfaction of objectivity and polyconvexity, essential within the context of hyperelasticity. To benchmark the methods, we train them against rubber and skin stress-strain data. All three approaches capture the data almost perfectly, without overfitting, and have some capacity to extrapolate. Interestingly, the methods find different energy functions even though the prediction on the stress data is nearly identical. The most notable differences are observed in the second derivatives, which could impact performance of numerical solvers. On the rich set of data used in these benchmarks, the models show the anticipated trade-off between number of parameters and accuracy. Overall, CANN, ICNN and NODE retain the flexibility and accuracy of other data-driven methods without compromising on the physics. These methods are thus ideal options to model arbitrary hyperelastic material behavior.
<div id='section'>Paperid: <span id='pid'>709, <a href='https://arxiv.org/pdf/2207.01765.pdf' target='_blank'>https://arxiv.org/pdf/2207.01765.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jae Yong Lee, Juhi Jang, Hyung Ju Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.01765">opPINN: Physics-Informed Neural Network with operator learning to approximate solutions to the Fokker-Planck-Landau equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a hybrid framework opPINN: physics-informed neural network (PINN) with operator learning for approximating the solution to the Fokker-Planck-Landau (FPL) equation. The opPINN framework is divided into two steps: Step 1 and Step 2. After the operator surrogate models are trained during Step 1, PINN can effectively approximate the solution to the FPL equation during Step 2 by using the pre-trained surrogate models. The operator surrogate models greatly reduce the computational cost and boost PINN by approximating the complex Landau collision integral in the FPL equation. The operator surrogate models can also be combined with the traditional numerical schemes. It provides a high efficiency in computational time when the number of velocity modes becomes larger. Using the opPINN framework, we provide the neural network solutions for the FPL equation under the various types of initial conditions, and interaction models in two and three dimensions. Furthermore, based on the theoretical properties of the FPL equation, we show that the approximated neural network solution converges to the a priori classical solution of the FPL equation as the pre-defined loss function is reduced.
<div id='section'>Paperid: <span id='pid'>710, <a href='https://arxiv.org/pdf/2203.13648.pdf' target='_blank'>https://arxiv.org/pdf/2203.13648.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Franz M. Rohrhofer, Stefan Posch, Clemens GÃ¶Ãnitzer, Bernhard C. Geiger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.13648">On the Role of Fixed Points of Dynamical Systems in Training Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper empirically studies commonly observed training difficulties of Physics-Informed Neural Networks (PINNs) on dynamical systems. Our results indicate that fixed points which are inherent to these systems play a key role in the optimization of the in PINNs embedded physics loss function. We observe that the loss landscape exhibits local optima that are shaped by the presence of fixed points. We find that these local optima contribute to the complexity of the physics loss optimization which can explain common training difficulties and resulting nonphysical predictions. Under certain settings, e.g., initial conditions close to fixed points or long simulations times, we show that those optima can even become better than that of the desired solution.
<div id='section'>Paperid: <span id='pid'>711, <a href='https://arxiv.org/pdf/2203.03407.pdf' target='_blank'>https://arxiv.org/pdf/2203.03407.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sidi Wu, Aiqing Zhu, Yifa Tang, Benzhuo Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.03407">Convergence of physics-informed neural networks applied to linear second-order elliptic interface problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the remarkable empirical success of neural networks across diverse scientific disciplines, rigorous error and convergence analysis are also being developed and enriched. However, there has been little theoretical work focusing on neural networks in solving interface problems. In this paper, we perform a convergence analysis of physics-informed neural networks (PINNs) for solving second-order elliptic interface problems. Specifically, we consider PINNs with domain decomposition technologies and introduce gradient-enhanced strategies on the interfaces to deal with boundary and interface jump conditions. It is shown that the neural network sequence obtained by minimizing a Lipschitz regularized loss function converges to the unique solution to the interface problem in $H^2$ as the number of samples increases. Numerical experiments are provided to demonstrate our theoretical analysis.
<div id='section'>Paperid: <span id='pid'>712, <a href='https://arxiv.org/pdf/2201.05395.pdf' target='_blank'>https://arxiv.org/pdf/2201.05395.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcello Longo, Joost A. A. Opschoor, Nico Disch, Christoph Schwab, Jakob Zech
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.05395">De Rham compatible Deep Neural Network FEM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>On general regular simplicial partitions $\mathcal{T}$ of bounded polytopal domains $Î©\subset \mathbb{R}^d$, $d\in\{2,3\}$, we construct \emph{exact neural network (NN) emulations} of all lowest order finite element spaces in the discrete de Rham complex. These include the spaces of piecewise constant functions, continuous piecewise linear (CPwL) functions, the classical ``Raviart-Thomas element'', and the ``NÃ©dÃ©lec edge element''. For all but the CPwL case, our network architectures employ both ReLU (rectified linear unit) and BiSU (binary step unit) activations to capture discontinuities. In the important case of CPwL functions, we prove that it suffices to work with pure ReLU nets. Our construction and DNN architecture generalizes previous results in that no geometric restrictions on the regular simplicial partitions $\mathcal{T}$ of $Î©$ are required for DNN emulation. In addition, for CPwL functions our DNN construction is valid in any dimension $d\geq 2$. Our ``FE-Nets'' are required in the variationally correct, structure-preserving approximation of boundary value problems of electromagnetism in nonconvex polyhedra $Î©\subset \mathbb{R}^3$. They are thus an essential ingredient in the application of e.g., the methodology of ``physics-informed NNs'' or ``deep Ritz methods'' to electromagnetic field simulation via deep learning techniques. We indicate generalizations of our constructions to higher-order compatible spaces and other, non-compatible classes of discretizations, in particular the ``Crouzeix-Raviart'' elements and Hybridized, Higher Order (HHO) methods.
<div id='section'>Paperid: <span id='pid'>713, <a href='https://arxiv.org/pdf/2111.08108.pdf' target='_blank'>https://arxiv.org/pdf/2111.08108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chandrajit Bajaj, Minh Nguyen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2111.08108">Physics-informed neural networks via stochastic Hamiltonian dynamics learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose novel learning frameworks to tackle optimal control problems by applying the Pontryagin maximum principle and then solving for a Hamiltonian dynamical system. Applying the Pontryagin maximum principle to the original optimal control problem shifts the learning focus to reduced Hamiltonian dynamics and corresponding adjoint variables. Then, the reduced Hamiltonian networks can be learned by going backwards in time and then minimizing loss function deduced from the Pontryagin maximum principle's conditions. The learning process is further improved by progressively learning a posterior distribution of the reduced Hamiltonians. This is achieved through utilizing a variational autoencoder which leads to more effective path exploration process. We apply our learning frameworks called NeuralPMP to various control tasks and obtain competitive results.
<div id='section'>Paperid: <span id='pid'>714, <a href='https://arxiv.org/pdf/2106.13638.pdf' target='_blank'>https://arxiv.org/pdf/2106.13638.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jochen Stiasny, Georgios S. Misyris, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2106.13638">Transient Stability Analysis with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We explore the possibility to use physics-informed neural networks to drastically accelerate the solution of ordinary differential-algebraic equations that govern the power system dynamics. When it comes to transient stability assessment, the traditionally applied methods either carry a significant computational burden, require model simplifications, or use overly conservative surrogate models. Conventional neural networks can circumvent these limitations but are faced with high demand of high-quality training datasets, while they ignore the underlying governing equations. Physics-informed neural networks are different: they incorporate the power system differential algebraic equations directly into the neural network training and drastically reduce the need for training data. This paper takes a deep dive into the performance of physics-informed neural networks for power system transient stability assessment. Introducing a new neural network training procedure to facilitate a thorough comparison, we explore how physics-informed neural networks compare with conventional differential-algebraic solvers and classical neural networks in terms of computation time, requirements in data, and prediction accuracy. We illustrate the findings on the Kundur two-area system, and assess the opportunities and challenges of physics-informed neural networks to serve as a transient stability analysis tool, highlighting possible pathways to further develop this method.
<div id='section'>Paperid: <span id='pid'>715, <a href='https://arxiv.org/pdf/2105.00862.pdf' target='_blank'>https://arxiv.org/pdf/2105.00862.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Franz M. Rohrhofer, Stefan Posch, Clemens GÃ¶Ãnitzer, Bernhard C. Geiger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2105.00862">Data vs. Physics: The Apparent Pareto Front of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a promising deep learning method, capable of solving forward and inverse problems governed by differential equations. Despite their recent advance, it is widely acknowledged that PINNs are difficult to train and often require a careful tuning of loss weights when data and physics loss functions are combined by scalarization of a multi-objective (MO) problem. In this paper, we aim to understand how parameters of the physical system, such as characteristic length and time scales, the computational domain, and coefficients of differential equations affect MO optimization and the optimal choice of loss weights. Through a theoretical examination of where these system parameters appear in PINN training, we find that they effectively and individually scale the loss residuals, causing imbalances in MO optimization with certain choices of system parameters. The immediate effects of this are reflected in the apparent Pareto front, which we define as the set of loss values achievable with gradient-based training and visualize accordingly. We empirically verify that loss weights can be used successfully to compensate for the scaling of system parameters, and enable the selection of an optimal solution on the apparent Pareto front that aligns well with the physically valid solution. We further demonstrate that by altering the system parameterization, the apparent Pareto front can shift and exhibit locally convex parts, resulting in a wider range of loss weights for which gradient-based training becomes successful. This work explains the effects of system parameters on MO optimization in PINNs, and highlights the utility of proposed loss weighting schemes.
<div id='section'>Paperid: <span id='pid'>716, <a href='https://arxiv.org/pdf/2510.08184.pdf' target='_blank'>https://arxiv.org/pdf/2510.08184.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rakesh Kumar Sahoo, Paridhi Choudhary, Manoranjan Sinha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.08184">Satellite Navigation and Control using Physics-Informed Artificial Potential Field and Sliding Mode Controller</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Increase in the number of space exploration missions has led to the accumulation of space debris, posing risk of collision with the operational satellites. Addressing this challenge is crucial for the sustainability of space operations. To plan a safe trajectory in the presence of moving space debris, an integrated approach of artificial potential field and sliding mode controller is proposed and implemented in this paper. The relative 6-DOF kinematics and dynamics of the spacecraft is modelled in the framework of geometric mechanics with the relative configuration expressed through exponential coordinates. Various collision avoidance guidance algorithms have been proposed in the literature but the Artificial Potential Field guidance algorithm is computationally efficient and enables real-time path adjustments to avoid collision with obstacles. However, it is prone to issues such as local minima. In literature, local minima issue is typically avoided by either redefining the potential function such as adding vorticity or by employing search techniques which are computationally expensive. To address these challenges, a physics-informed APF is proposed in this paper where Hamiltonian mechanics is used instead of the traditional Newtonian mechanics-based approach. In this approach, instead of relying on attractive and repulsive forces for path planning, the Hamiltonian approach uses the potential field to define a path of minimum potential. Additionally, to track the desired trajectory planned by the guidance algorithm within a fixed-time frame, a non-singular fixed-time sliding mode controller (FTSMC) is used. The proposed fixed-time sliding surface not only ensures fixed-time convergence of system states but also guarantees the global stability of the closed-loop system without singularity. The simulation results presented support the claims made.
<div id='section'>Paperid: <span id='pid'>717, <a href='https://arxiv.org/pdf/2510.07160.pdf' target='_blank'>https://arxiv.org/pdf/2510.07160.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fengze Xie, Xiaozhou Fan, Jacob Schuster, Yisong Yue, Morteza Gharib
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.07160">A Narwhal-Inspired Sensing-to-Control Framework for Small Fixed-Wing Aircraft</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fixed-wing unmanned aerial vehicles (UAVs) offer endurance and efficiency but lack low-speed agility due to highly coupled dynamics. We present an end-to-end sensing-to-control pipeline that combines bio-inspired hardware, physics-informed dynamics learning, and convex control allocation. Measuring airflow on a small airframe is difficult because near-body aerodynamics, propeller slipstream, control-surface actuation, and ambient gusts distort pressure signals. Inspired by the narwhal's protruding tusk, we mount in-house multi-hole probes far upstream and complement them with sparse, carefully placed wing pressure sensors for local flow measurement. A data-driven calibration maps probe pressures to airspeed and flow angles. We then learn a control-affine dynamics model using the estimated airspeed/angles and sparse sensors. A soft left/right symmetry regularizer improves identifiability under partial observability and limits confounding between wing pressures and flaperon inputs. Desired wrenches (forces and moments) are realized by a regularized least-squares allocator that yields smooth, trimmed actuation. Wind-tunnel studies across a wide operating range show that adding wing pressures reduces force-estimation error by 25-30%, the proposed model degrades less under distribution shift (about 12% versus 44% for an unstructured baseline), and force tracking improves with smoother inputs, including a 27% reduction in normal-force RMSE versus a plain affine model and 34% versus an unstructured baseline.
<div id='section'>Paperid: <span id='pid'>718, <a href='https://arxiv.org/pdf/2510.04490.pdf' target='_blank'>https://arxiv.org/pdf/2510.04490.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akshay Govind Srinivasan, Vikas Dwivedi, Balaji Srinivasan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04490">Deep vs. Shallow: Benchmarking Physics-Informed Neural Architectures on the Biharmonic Equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial differential equation (PDE) solvers are fundamental to engineering simulation. Classical mesh-based approaches (finite difference/volume/element) are fast and accurate on high-quality meshes but struggle with higher-order operators and complex, hard-to-mesh geometries. Recently developed physics-informed neural networks (PINNs) and their variants are mesh-free and flexible, yet compute-intensive and often less accurate. This paper systematically benchmarks RBF-PIELM, a rapid PINN variant-an extreme learning machine with radial-basis activations-for higher-order PDEs. RBF-PIELM replaces PINNs' time-consuming gradient descent with a single-shot least-squares solve. We test RBF-PIELM on the fourth-order biharmonic equation using two benchmarks: lid-driven cavity flow (streamfunction formulation) and a manufactured oscillatory solution. Our results show up to $(350\times)$ faster training than PINNs and over $(10\times)$ fewer parameters for comparable solution accuracy. Despite surpassing PINNs, RBF-PIELM still lags mature mesh-based solvers and its accuracy degrades on highly oscillatory solutions, highlighting remaining challenges for practical deployment.
<div id='section'>Paperid: <span id='pid'>719, <a href='https://arxiv.org/pdf/2510.04322.pdf' target='_blank'>https://arxiv.org/pdf/2510.04322.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akshay Govind Srinivasan, Anuj Jagannath Said, Sathwik Pentela, Vikas Dwivedi, Balaji Srinivasan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04322">Towards Fast Option Pricing PDE Solvers Powered by PIELM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial differential equation (PDE) solvers underpin modern quantitative finance, governing option pricing and risk evaluation. Physics-Informed Neural Networks (PINNs) have emerged as a promising approach for solving the forward and inverse problems of partial differential equations (PDEs) using deep learning. However they remain computationally expensive due to their iterative gradient descent based optimization and scale poorly with increasing model size. This paper introduces Physics-Informed Extreme Learning Machines (PIELMs) as fast alternative to PINNs for solving both forward and inverse problems in financial PDEs. PIELMs replace iterative optimization with a single least-squares solve, enabling deterministic and efficient training. We benchmark PIELM on the Black-Scholes and Heston-Hull-White models for forward pricing and demonstrate its capability in inverse model calibration to recover volatility and interest rate parameters from noisy data. From experiments we observe that PIELM achieve accuracy comparable to PINNs while being up to $30\times$ faster, highlighting their potential for real-time financial modeling.
<div id='section'>Paperid: <span id='pid'>720, <a href='https://arxiv.org/pdf/2510.02503.pdf' target='_blank'>https://arxiv.org/pdf/2510.02503.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tejaswini Sanjay Katale, Lu Gao, Yunpeng Zhang, Alaa Senouci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.02503">A Bilevel Optimization Framework for Adversarial Control of Gas Pipeline Operations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cyberattacks on pipeline operational technology systems pose growing risks to energy infrastructure. This study develops a physics-informed simulation and optimization framework for analyzing cyber-physical threats in petroleum pipeline networks. The model integrates networked hydraulic dynamics, SCADA-based state estimation, model predictive control (MPC), and a bi-level formulation for stealthy false-data injection (FDI) attacks. Pipeline flow and pressure dynamics are modeled on a directed graph using nodal pressure evolution and edge-based Weymouth-type relations, including control-aware equipment such as valves and compressors. An extended Kalman filter estimates the full network state from partial SCADA telemetry. The controller computes pressure-safe control inputs via MPC under actuator constraints and forecasted demands. Adversarial manipulation is formalized as a bi-level optimization problem where an attacker perturbs sensor data to degrade throughput while remaining undetected by bad-data detectors. This attack-control interaction is solved via Karush-Kuhn-Tucker (KKT) reformulation, which results in a tractable mixed-integer quadratic program. Test gas pipeline case studies demonstrate the covert reduction of service delivery under attack. Results show that undetectable attacks can cause sustained throughput loss with minimal instantaneous deviation. This reveals the need for integrated detection and control strategies in cyber-physical infrastructure.
<div id='section'>Paperid: <span id='pid'>721, <a href='https://arxiv.org/pdf/2510.00401.pdf' target='_blank'>https://arxiv.org/pdf/2510.00401.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shounak Sural, Charles Kekeh, Wenliang Liu, Federico Pecora, Mouhacine Benosman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00401">Physics-Informed Neural Controlled Differential Equations for Scalable Long Horizon Multi-Agent Motion Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Long-horizon motion forecasting for multiple autonomous robots is challenging due to non-linear agent interactions, compounding prediction errors, and continuous-time evolution of dynamics. Learned dynamics of such a system can be useful in various applications such as travel time prediction, prediction-guided planning and generative simulation. In this work, we aim to develop an efficient trajectory forecasting model conditioned on multi-agent goals. Motivated by the recent success of physics-guided deep learning for partially known dynamical systems, we develop a model based on neural Controlled Differential Equations (CDEs) for long-horizon motion forecasting. Unlike discrete-time methods such as RNNs and transformers, neural CDEs operate in continuous time, allowing us to combine physics-informed constraints and biases to jointly model multi-robot dynamics. Our approach, named PINCoDE (Physics-Informed Neural Controlled Differential Equations), learns differential equation parameters that can be used to predict the trajectories of a multi-agent system starting from an initial condition. PINCoDE is conditioned on future goals and enforces physics constraints for robot motion over extended periods of time. We adopt a strategy that scales our model from 10 robots to 100 robots without the need for additional model parameters, while producing predictions with an average ADE below 0.5 m for a 1-minute horizon. Furthermore, progressive training with curriculum learning for our PINCoDE model results in a 2.7X reduction of forecasted pose error over 4 minute horizons compared to analytical models.
<div id='section'>Paperid: <span id='pid'>722, <a href='https://arxiv.org/pdf/2509.25730.pdf' target='_blank'>https://arxiv.org/pdf/2509.25730.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Indu Kant Deo, Akash Venkateshwaran, Rajeev K. Jaiman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25730">A Physics-Guided Probabilistic Surrogate Modeling Framework for Digital Twins of Underwater Radiated Noise</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ship traffic is an increasing source of underwater radiated noise in coastal waters, motivating real-time digital twins of ocean acoustics for operational noise mitigation. We present a physics-guided probabilistic framework to predict three-dimensional transmission loss in realistic ocean environments. As a case study, we consider the Salish Sea along shipping routes from the Pacific Ocean to the Port of Vancouver. A dataset of over 30 million source-receiver pairs was generated with a Gaussian beam solver across seasonal sound speed profiles and one-third-octave frequency bands spanning 12.5 Hz to 8 kHz. We first assess sparse variational Gaussian processes (SVGP) and then incorporate physics-based mean functions combining spherical spreading with frequency-dependent absorption. To capture nonlinear effects, we examine deep sigma-point processes and stochastic variational deep kernel learning. The final framework integrates four components: (i) a learnable physics-informed mean that represents dominant propagation trends, (ii) a convolutional encoder for bathymetry along the source-receiver track, (iii) a neural encoder for source, receiver, and frequency coordinates, and (iv) a residual SVGP layer that provides calibrated predictive uncertainty. This probabilistic digital twin facilitates the construction of sound-exposure bounds and worst-case scenarios for received levels. We further demonstrate the application of the framework to ship speed optimization, where predicted transmission loss combined with near-field source models provides sound exposure level estimates for minimizing acoustic impacts on marine mammals. The proposed framework advances uncertainty-aware digital twins for ocean acoustics and illustrates how physics-guided machine learning can support sustainable maritime operations.
<div id='section'>Paperid: <span id='pid'>723, <a href='https://arxiv.org/pdf/2509.23307.pdf' target='_blank'>https://arxiv.org/pdf/2509.23307.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Jarry, Ramon Dalmau, Xavier Olive, Philippe Very
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.23307">A Neural ODE Approach to Aircraft Flight Dynamics Modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate aircraft trajectory prediction is critical for air traffic management, airline operations, and environmental assessment. This paper introduces NODE-FDM, a Neural Ordinary Differential Equations-based Flight Dynamics Model trained on Quick Access Recorder (QAR) data. By combining analytical kinematic relations with data-driven components, NODE-FDM achieves a more accurate reproduction of recorded trajectories than state-of-the-art models such as a BADA-based trajectory generation methodology (BADA4 performance model combined with trajectory control routines), particularly in the descent phase of the flight. The analysis demonstrates marked improvements across altitude, speed, and mass dynamics. Despite current limitations, including limited physical constraints and the limited availability of QAR data, the results demonstrate the potential of physics-informed neural ordinary differential equations as a high-fidelity, data-driven approach to aircraft performance modelling. Future work will extend the framework to incorporate a full modelling of the lateral dynamics of the aircraft.
<div id='section'>Paperid: <span id='pid'>724, <a href='https://arxiv.org/pdf/2509.14568.pdf' target='_blank'>https://arxiv.org/pdf/2509.14568.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hai Siong Tan, Kuancheng Wang, Rafe McBeth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14568">Evidential Physics-Informed Neural Networks for Scientific Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present the fundamental theory and implementation guidelines underlying Evidential Physics-Informed Neural Network (E-PINN) -- a novel class of uncertainty-aware PINN. It leverages the marginal distribution loss function of evidential deep learning for estimating uncertainty of outputs, and infers unknown parameters of the PDE via a learned posterior distribution. Validating our model on two illustrative case studies -- the 1D Poisson equation with a Gaussian source and the 2D Fisher-KPP equation, we found that E-PINN generated empirical coverage probabilities that were calibrated significantly better than Bayesian PINN and Deep Ensemble methods. To demonstrate real-world applicability, we also present a brief case study on applying E-PINN to analyze clinical glucose-insulin datasets that have featured in medical research on diabetes pathophysiology.
<div id='section'>Paperid: <span id='pid'>725, <a href='https://arxiv.org/pdf/2509.14437.pdf' target='_blank'>https://arxiv.org/pdf/2509.14437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Afrah Farea, Saiful Khan, Mustafa Serdar Celebi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14437">Multi-Objective Loss Balancing in Physics-Informed Neural Networks for Fluid Flow Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a promising machine learning approach for solving partial differential equations (PDEs). However, PINNs face significant challenges in balancing multi-objective losses, as multiple competing loss terms such as physics residuals, boundary conditions, and initial conditions must be appropriately weighted. While various loss balancing schemes have been proposed, they have been implemented within neural network architectures with fixed activation functions, and their effectiveness has been assessed using simpler PDEs. We hypothesize that the effectiveness of loss balancing schemes depends not only on the balancing strategy itself, but also on the neural network's inherent function approximation capabilities, which are influenced by the choice of activation function. In this paper, we extend existing solutions by incorporating trainable activation functions within the neural network architecture and evaluate the proposed approach on complex fluid flow applications modeled by the Navier-Stokes equations. Our evaluation across diverse Navier-Stokes problems demonstrates that this proposed solution achieves root mean square error (RMSE) improvements ranging from 7.4% to 95.2% across different scenarios. These findings underscore the importance of carefully considering the interaction between activation function selection and balancing algorithms when designing loss balancing strategies.
<div id='section'>Paperid: <span id='pid'>726, <a href='https://arxiv.org/pdf/2509.14437.pdf' target='_blank'>https://arxiv.org/pdf/2509.14437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Afrah Farea, Saiful Khan, Mustafa Serdar Celebi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14437">Multi-Objective Loss Balancing in Physics-Informed Neural Networks for Fluid Flow Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a promising machine learning approach for solving partial differential equations (PDEs). However, PINNs face significant challenges in balancing multi-objective losses, as multiple competing loss terms such as physics residuals, boundary conditions, and initial conditions must be appropriately weighted. While various loss balancing schemes have been proposed, they have been implemented within neural network architectures with fixed activation functions, and their effectiveness has been assessed using simpler PDEs. We hypothesize that the effectiveness of loss balancing schemes depends not only on the balancing strategy itself, but also on the loss function design and the neural network's inherent function approximation capabilities, which are influenced by the choice of activation function. In this paper, we extend existing solutions by incorporating trainable activation functions within the neural network architecture and evaluate the proposed approach on complex fluid flow applications modeled by the Navier-Stokes equations. Our evaluation across diverse Navier-Stokes problems demonstrates that this proposed solution achieves root mean square error (RMSE) improvements ranging from 7.4% to 95.2% across different scenarios. These findings highlight the importance of carefully designing the loss function and selecting activation functions for effective loss balancing.
<div id='section'>Paperid: <span id='pid'>727, <a href='https://arxiv.org/pdf/2509.06257.pdf' target='_blank'>https://arxiv.org/pdf/2509.06257.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuyan Wu, Jiale Zhang, Moon Lee, Cherrelle Smith, Xinyi Li, Ankur Senapati, Pei Zhang, Hae Young Noh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06257">Human Body Weight Estimation Through Music-Induced Bed Vibrations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rapid and accurate body weight estimation is critical in emergency medical care, as it directly influences treatment decisions, such as drug dosing, defibrillation energy selection, and fluid resuscitation. Traditional methods such as stand-on scales, length-based tapes, or transfer-based weighing scales are often impractical for immobilized patients, inaccurate, or labor-intensive and time-consuming. This paper introduces MelodyBedScale, a non-intrusive and rapid on-bed weight estimation system that leverages bed vibration induced by music. The core insight is that body weight affects the vibration transfer function of the bed-body system, which is captured using vibration sensors placed on opposite sides of the bed. First, we identify weight-sensitive frequency bands and compose clinically acceptable soft, natural music with high signal energy in these frequency bands. This music is then played through a speaker mounted on the bed to induce bed vibrations. Additionally, to efficiently capture the complex weight-vibration relationship with limited data and enhance generalizability to unseen individuals and weights, we theoretically analyze the weight-vibration relationship and integrate the results into the activation functions of the neural network for physics-informed weight regression. We evaluated MelodyBedScale on both wooden and steel beds across 11 participants, achieving a mean absolute error of up to 1.55 kg.
<div id='section'>Paperid: <span id='pid'>728, <a href='https://arxiv.org/pdf/2509.05117.pdf' target='_blank'>https://arxiv.org/pdf/2509.05117.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rafael Bischof, Michal Piovarči, Michael A. Kraus, Siddhartha Mishra, Bernd Bickel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05117">HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present HyPINO, a multi-physics neural operator designed for zero-shot generalization across a broad class of parametric PDEs without requiring task-specific fine-tuning. Our approach combines a Swin Transformer-based hypernetwork with mixed supervision: (i) labeled data from analytical solutions generated via the Method of Manufactured Solutions (MMS), and (ii) unlabeled samples optimized using physics-informed objectives. The model maps PDE parametrizations to target Physics-Informed Neural Networks (PINNs) and can handle linear elliptic, hyperbolic, and parabolic equations in two dimensions with varying source terms, geometries, and mixed Dirichlet/Neumann boundary conditions, including interior boundaries. HyPINO achieves strong zero-shot accuracy on seven benchmark problems from PINN literature, outperforming U-Nets, Poseidon, and Physics-Informed Neural Operators (PINO). Further, we introduce an iterative refinement procedure that compares the physics of the generated PINN to the requested PDE and uses the discrepancy to generate a "delta" PINN. Summing their contributions and repeating this process forms an ensemble whose combined solution progressively reduces the error on six benchmarks and achieves over 100x gain in average $L_2$ loss in the best case, while retaining forward-only inference. Additionally, we evaluate the fine-tuning behavior of PINNs initialized by HyPINO and show that they converge faster and to lower final error than both randomly initialized and Reptile-meta-learned PINNs on five benchmarks, performing on par on the remaining two. Our results highlight the potential of this scalable approach as a foundation for extending neural operators toward solving increasingly complex, nonlinear, and high-dimensional PDE problems with significantly improved accuracy and reduced computational cost.
<div id='section'>Paperid: <span id='pid'>729, <a href='https://arxiv.org/pdf/2509.01679.pdf' target='_blank'>https://arxiv.org/pdf/2509.01679.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhi-Feng Wei, Wenqian Chen, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01679">Efficient Transformer-Inspired Variants of Physics-Informed Deep Operator Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Operator learning has emerged as a promising tool for accelerating the solution of partial differential equations (PDEs). The Deep Operator Networks (DeepONets) represent a pioneering framework in this area: the "vanilla" DeepONet is valued for its simplicity and efficiency, while the modified DeepONet achieves higher accuracy at the cost of increased training time. In this work, we propose a series of Transformer-inspired DeepONet variants that introduce bidirectional cross-conditioning between the branch and trunk networks in DeepONet. Query-point information is injected into the branch network and input-function information into the trunk network, enabling dynamic dependencies while preserving the simplicity and efficiency of the "vanilla" DeepONet in a non-intrusive manner. Experiments on four PDE benchmarks -- advection, diffusion-reaction, Burgers', and Korteweg-de Vries equations -- show that for each case, there exists a variant that matches or surpasses the accuracy of the modified DeepONet while offering improved training efficiency. Moreover, the best-performing variant for each equation aligns naturally with the equation's underlying characteristics, suggesting that the effectiveness of cross-conditioning depends on the characteristics of the equation and its underlying physics. To ensure robustness, we validate the effectiveness of our variants through a range of rigorous statistical analyses, among them the Wilcoxon Two One-Sided Test, Glass's Delta, and Spearman's rank correlation.
<div id='section'>Paperid: <span id='pid'>730, <a href='https://arxiv.org/pdf/2508.21022.pdf' target='_blank'>https://arxiv.org/pdf/2508.21022.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gil Goldshlager, Jiang Hu, Lin Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21022">Fast Convergence Rates for Subsampled Natural Gradient Algorithms on Quadratic Model Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Subsampled natural gradient descent (SNGD) has shown impressive results for parametric optimization tasks in scientific machine learning, such as neural network wavefunctions and physics-informed neural networks, but it has lacked a theoretical explanation. We address this gap by analyzing the convergence of SNGD and its accelerated variant, SPRING, for idealized parametric optimization problems where the model is linear and the loss function is strongly convex and quadratic. In the special case of a least-squares loss, namely the standard linear least-squares problem, we prove that SNGD is equivalent to a regularized Kaczmarz method while SPRING is equivalent to an accelerated regularized Kaczmarz method. As a result, by leveraging existing analyses we obtain under mild conditions (i) the first fast convergence rate for SNGD, (ii) the first convergence guarantee for SPRING in any setting, and (iii) the first proof that SPRING can accelerate SNGD. In the case of a general strongly convex quadratic loss, we extend the analysis of the regularized Kaczmarz method to obtain a fast convergence rate for SNGD under stronger conditions, providing the first explanation for the effectiveness of SNGD outside of the least-squares setting. Overall, our results illustrate how tools from randomized linear algebra can shed new light on the interplay between subsampling and curvature-aware optimization strategies.
<div id='section'>Paperid: <span id='pid'>731, <a href='https://arxiv.org/pdf/2508.19419.pdf' target='_blank'>https://arxiv.org/pdf/2508.19419.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harun Ur Rashid, Aleksandra Pachalieva, Daniel O'Malley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19419">Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate subsurface reservoir pressure control is extremely challenging due to geological heterogeneity and multiphase fluid-flow dynamics. Predicting behavior in this setting relies on high-fidelity physics-based simulations that are computationally expensive. Yet, the uncertain, heterogeneous properties that control these flows make it necessary to perform many of these expensive simulations, which is often prohibitive. To address these challenges, we introduce a physics-informed machine learning workflow that couples a fully differentiable multiphase flow simulator, which is implemented in the DPFEHM framework with a convolutional neural network (CNN). The CNN learns to predict fluid extraction rates from heterogeneous permeability fields to enforce pressure limits at critical reservoir locations. By incorporating transient multiphase flow physics into the training process, our method enables more practical and accurate predictions for realistic injection-extraction scenarios compare to previous works. To speed up training, we pretrain the model on single-phase, steady-state simulations and then fine-tune it on full multiphase scenarios, which dramatically reduces the computational cost. We demonstrate that high-accuracy training can be achieved with fewer than three thousand full-physics multiphase flow simulations -- compared to previous estimates requiring up to ten million. This drastic reduction in the number of simulations is achieved by leveraging transfer learning from much less expensive single-phase simulations.
<div id='section'>Paperid: <span id='pid'>732, <a href='https://arxiv.org/pdf/2508.15695.pdf' target='_blank'>https://arxiv.org/pdf/2508.15695.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qifeng Hu, Shamsulhaq Basir, Inanc Senocak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15695">Conditionally adaptive augmented Lagrangian method for physics-informed learning of forward and inverse problems using artificial neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present several advances to the physics and equality constrained artificial neural networks (PECANN) framework that substantially improve its capability to learn solutions of canonical partial differential equations (PDEs). First, we generalize the augmented Lagrangian method (ALM) to support multiple independent penalty parameters, enabling simultaneous enforcement of heterogeneous constraints. Second, we reformulate pointwise constraint enforcement and Lagrange multipliers as expectations over constraint terms, reducing memory overhead and permitting efficient mini-batch training. Third, to address PDEs with oscillatory, multi-scale features, we incorporate Fourier feature mappings and show that a single mapping suffices where multiple mappings or more costly architectures were required in related methods. Fourth, we introduce a time-windowing strategy for long-time evolution in which the terminal state of each window is enforced as an initial-condition constraint for the next, ensuring continuity without discrete time models. Crucially, we propose a conditionally adaptive penalty update (CAPU) strategy for ALM, which preserves the principle that larger constraint violations incur stronger penalties. CAPU accelerates the growth of Lagrange multipliers for selectively challenging constraints, enhancing constraint enforcement during training. We demonstrate the effectiveness of PECANN-CAPU on problems including the transonic rarefaction problem, reversible advection of a passive by a vortex, high-wavenumber Helmholtz and Poisson equations, and inverse identification of spatially varying heat sources. Comparisons with established methods and recent Kolmogorov-Arnold network approaches show that PECANN-CAPU achieves competitive accuracy across all cases. Collectively, these advances improve PECANN's robustness, efficiency, and applicability to demanding problems in scientific computing.
<div id='section'>Paperid: <span id='pid'>733, <a href='https://arxiv.org/pdf/2508.14688.pdf' target='_blank'>https://arxiv.org/pdf/2508.14688.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Veronica Ruozzi, Sasan Matinfar, Laura SchÃ¼tz, Benedikt Wiestler, Alberto Redaelli, Emiliano Votta, Nassir Navab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14688">BioSonix: Can Physics-Based Sonification Perceptualize Tissue Deformations From Tool Interactions?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Perceptualizing tool interactions with deformable structures in surgical procedures remains challenging, as unimodal visualization techniques often fail to capture the complexity of these interactions due to constraints such as occlusion and limited depth perception. This paper presents a novel approach to augment tool navigation in mixed reality environments by providing auditory representations of tool-tissue dynamics, particularly for interactions with soft tissue. BioSonix, a physics-informed design framework, utilizes tissue displacements in 3D space to compute excitation forces for a sound model encoding tissue properties such as stiffness and density. Biomechanical simulations were employed to model particle displacements resulting from tool-tissue interactions, establishing a robust foundation for the method. An optimization approach was used to define configurations for capturing diverse interaction scenarios with varying tool trajectories. Experiments were conducted to validate the accuracy of the sound-displacement mappings. Additionally, two user studies were performed: the first involved two clinical professionals (a neuroradiologist and a cardiologist), who confirmed the method's impact and achieved high task accuracy; the second included 22 biomedical experts, who demonstrated high discrimination accuracy in tissue differentiation and targeting tasks. The results revealed a strong correlation between tool-tissue dynamics and their corresponding auditory profiles, highlighting the potential of these sound representations to enhance the intuitive understanding of complex interactions.
<div id='section'>Paperid: <span id='pid'>734, <a href='https://arxiv.org/pdf/2508.12226.pdf' target='_blank'>https://arxiv.org/pdf/2508.12226.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhijun Zeng, Youjia Zheng, Chang Su, Qianhang Wu, Hao Hu, Zeyuan Dong, Shan Gao, Yang Lv, Rui Tang, Ligang Cui, Zhiyong Hou, Weijun Lin, Zuoqiang Shi, Yubing Li, He Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12226">In vivo 3D ultrasound computed tomography of musculoskeletal tissues with generative neural physics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ultrasound computed tomography (USCT) is a radiation-free, high-resolution modality but remains limited for musculoskeletal imaging due to conventional ray-based reconstructions that neglect strong scattering. We propose a generative neural physics framework that couples generative networks with physics-informed neural simulation for fast, high-fidelity 3D USCT. By learning a compact surrogate of ultrasonic wave propagation from only dozens of cross-modality images, our method merges the accuracy of wave modeling with the efficiency and stability of deep learning. This enables accurate quantitative imaging of in vivo musculoskeletal tissues, producing spatial maps of acoustic properties beyond reflection-mode images. On synthetic and in vivo data (breast, arm, leg), we reconstruct 3D maps of tissue parameters in under ten minutes, with sensitivity to biomechanical properties in muscle and bone and resolution comparable to MRI. By overcoming computational bottlenecks in strongly scattering regimes, this approach advances USCT toward routine clinical assessment of musculoskeletal disease.
<div id='section'>Paperid: <span id='pid'>735, <a href='https://arxiv.org/pdf/2508.03421.pdf' target='_blank'>https://arxiv.org/pdf/2508.03421.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahao Song, Wenbo Cao, Weiwei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03421">A matrix preconditioning framework for physics-informed neural networks based on adjoint method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have recently emerged as a popular approach for solving forward and inverse problems involving partial differential equations (PDEs). Compared to fully connected neural networks, PINNs based on convolutional neural networks offer advantages in the hard enforcement of boundary conditions and in reducing the computational cost of partial derivatives. However, the latter still struggles with slow convergence and even failure in some scenarios. In this study, we propose a matrix preconditioning method to improve the convergence of the latter. Specifically, we combine automatic differentiation with matrix coloring to compute the Jacobian matrix of the PDE system, which is used to construct the preconditioner via incomplete LU factorization. We subsequently use the preconditioner to scale the PDE residual in the loss function in order to reduce the condition number of the Jacobian matrix, which is key to improving the convergence of PINNs. To overcome the incompatibility between automatic differentiation and triangular solves in the preconditioning, we also design a framework based on the adjoint method to compute the gradients of the loss function with respect to the network parameters. By numerical experiments, we validate that the proposed method successfully and efficiently solves the multi-scale problem and the high Reynolds number problem, in both of which PINNs fail to obtain satisfactory results.
<div id='section'>Paperid: <span id='pid'>736, <a href='https://arxiv.org/pdf/2508.02692.pdf' target='_blank'>https://arxiv.org/pdf/2508.02692.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenbo Cao, Weiwei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02692">Overcoming the Loss Conditioning Bottleneck in Optimization-Based PDE Solvers: A Novel Well-Conditioned Loss Function</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optimization-based PDE solvers that minimize scalar loss functions have gained increasing attention in recent years. These methods either define the loss directly over discrete variables, as in Optimizing a Discrete Loss (ODIL), or indirectly through a neural network surrogate, as in Physics-Informed Neural Networks (PINNs). However, despite their promise, such methods often converge much more slowly than classical iterative solvers and are commonly regarded as inefficient. This work provides a theoretical insight, attributing the inefficiency to the use of the mean squared error (MSE) loss, which implicitly forms the normal equations, squares the condition number, and severely impairs optimization. To address this, we propose a novel Stabilized Gradient Residual (SGR) loss. By tuning a weight parameter, it flexibly modulates the condition number between the original system and its normal equations, while reducing to the MSE loss in the limiting case. We systematically benchmark the convergence behavior and optimization stability of the SGR loss within both the ODIL framework and PINNs-employing either numerical or automatic differentiation-and compare its performance against classical iterative solvers. Numerical experiments on a range of benchmark problems demonstrate that, within the ODIL framework, the proposed SGR loss achieves orders-of-magnitude faster convergence than the MSE loss. Further validation within the PINNs framework shows that, despite the high nonlinearity of neural networks, SGR consistently outperforms the MSE loss. These theoretical and empirical findings help bridge the performance gap between classical iterative solvers and optimization-based solvers, highlighting the central role of loss conditioning, and provide key insights for the design of more efficient PDE solvers.
<div id='section'>Paperid: <span id='pid'>737, <a href='https://arxiv.org/pdf/2507.22678.pdf' target='_blank'>https://arxiv.org/pdf/2507.22678.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matteo CalafÃ, Tito Andriollo, Allan P. Engsig-Karup, Cheol-Ho Jeong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.22678">A holomorphic Kolmogorov-Arnold network framework for solving elliptic problems on arbitrary 2D domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed holomorphic neural networks (PIHNNs) have recently emerged as efficient surrogate models for solving differential problems. By embedding the underlying problem structure into the network, PIHNNs require training only to satisfy boundary conditions, often resulting in significantly improved accuracy and computational efficiency compared to traditional physics-informed neural networks (PINNs). In this work, we improve and extend the application of PIHNNs to two-dimensional problems. First, we introduce a novel holomorphic network architecture based on the Kolmogorov-Arnold representation (PIHKAN), which achieves higher accuracy with reduced model complexity. Second, we develop mathematical extensions that broaden the applicability of PIHNNs to a wider class of elliptic partial differential equations, including the Helmholtz equation. Finally, we propose a new method based on Laurent series theory that enables the application of holomorphic networks to multiply-connected plane domains, thereby removing the previous limitation to simply-connected geometries.
<div id='section'>Paperid: <span id='pid'>738, <a href='https://arxiv.org/pdf/2507.21749.pdf' target='_blank'>https://arxiv.org/pdf/2507.21749.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>D. Veerababu, Ashwin A. Raikar, Prasanta K. Ghosh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21749">Improving Neural Network Training using Dynamic Learning Rate Schedule for PINNs and Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training neural networks can be challenging, especially as the complexity of the problem increases. Despite using wider or deeper networks, training them can be a tedious process, especially if a wrong choice of the hyperparameter is made. The learning rate is one of such crucial hyperparameters, which is usually kept static during the training process. Learning dynamics in complex systems often requires a more adaptive approach to the learning rate. This adaptability becomes crucial to effectively navigate varying gradients and optimize the learning process during the training process. In this paper, a dynamic learning rate scheduler (DLRS) algorithm is presented that adapts the learning rate based on the loss values calculated during the training process. Experiments are conducted on problems related to physics-informed neural networks (PINNs) and image classification using multilayer perceptrons and convolutional neural networks, respectively. The results demonstrate that the proposed DLRS accelerates training and improves stability.
<div id='section'>Paperid: <span id='pid'>739, <a href='https://arxiv.org/pdf/2507.21350.pdf' target='_blank'>https://arxiv.org/pdf/2507.21350.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenkai Tan, Alvaro Velasquez, Houbing Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21350">DEM-NeRF: A Neuro-Symbolic Method for Scientific Discovery through Physics-Informed Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks have emerged as a powerful tool for modeling physical systems, offering the ability to learn complex representations from limited data while integrating foundational scientific knowledge. In particular, neuro-symbolic approaches that combine data-driven learning, the neuro, with symbolic equations and rules, the symbolic, address the tension between methods that are purely empirical, which risk straying from established physical principles, and traditional numerical solvers that demand complete geometric knowledge and can be prohibitively expensive for high-fidelity simulations. In this work, we present a novel neuro-symbolic framework for reconstructing and simulating elastic objects directly from sparse multi-view image sequences, without requiring explicit geometric information. Specifically, we integrate a neural radiance field (NeRF) for object reconstruction with physics-informed neural networks (PINN) that incorporate the governing partial differential equations of elasticity. In doing so, our method learns a spatiotemporal representation of deforming objects that leverages both image supervision and symbolic physical constraints. To handle complex boundary and initial conditions, which are traditionally confronted using finite element methods, boundary element methods, or sensor-based measurements, we employ an energy-constrained Physics-Informed Neural Network architecture. This design enhances both simulation accuracy and the explainability of results.
<div id='section'>Paperid: <span id='pid'>740, <a href='https://arxiv.org/pdf/2507.10241.pdf' target='_blank'>https://arxiv.org/pdf/2507.10241.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vikas Dwivedi, Balaji Srinivasan, Monica Sigovan, Bruno Sixou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10241">Kernel-Adaptive PI-ELMs for Forward and Inverse Problems in PDEs with Sharp Gradients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces the Kernel Adaptive Physics-Informed Extreme Learning Machine (KAPI-ELM), an adaptive Radial Basis Function (RBF)-based extension of PI-ELM designed to solve both forward and inverse Partial Differential Equation (PDE) problems involving localized sharp gradients. While PI-ELMs outperform the traditional Physics-Informed Neural Networks (PINNs) in speed due to their single-shot, least square optimization, this advantage comes at a cost: their fixed, randomly initialized input layer limits their ability to capture sharp gradients. To overcome this limitation, we introduce a lightweight Bayesian Optimization (BO) framework that, instead of adjusting each input layer parameter individually as in traditional backpropagation, learns a small set of hyperparameters defining the statistical distribution from which the input weights are drawn. This novel distributional optimization strategy -- combining BO for input layer distributional parameters with least-squares optimization for output layer network parameters -- enables KAPI-ELM to preserve PI-ELM's speed while matching or exceeding the expressiveness of PINNs. We validate the proposed methodology on several challenging forward and inverse PDE benchmarks, including a 1D singularly perturbed convection-diffusion equation, a 2D Poisson equation with sharp localized sources, and a time-dependent advection equation. Notably, KAPI-ELM achieves state-of-the-art accuracy in both forward and inverse settings. In stiff PDE regimes, it matches or even outperforms advanced methods such as the Extended Theory of Functional Connections (XTFC), while requiring nearly an order of magnitude fewer tunable parameters. These results establish the potential of KAPI-ELM as a scalable, interpretable, and generalizable physics-informed learning framework, especially in stiff PDE regimes.
<div id='section'>Paperid: <span id='pid'>741, <a href='https://arxiv.org/pdf/2507.08121.pdf' target='_blank'>https://arxiv.org/pdf/2507.08121.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianchi Yu, Ivan Oseledets
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08121">Quasi-Random Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks have shown promise in solving partial differential equations (PDEs) by integrating physical constraints into neural network training, but their performance is sensitive to the sampling of points. Based on the impressive performance of quasi Monte-Carlo methods in high dimensional problems, this paper proposes Quasi-Random Physics-Informed Neural Networks (QRPINNs), which use low-discrepancy sequences for sampling instead of random points directly from the domain. Theoretically, QRPINNs have been proven to have a better convergence rate than PINNs. Empirically, experiments demonstrate that QRPINNs significantly outperform PINNs and some representative adaptive sampling methods, especially in high-dimensional PDEs. Furthermore, combining QRPINNs with adaptive sampling can further improve the performance.
<div id='section'>Paperid: <span id='pid'>742, <a href='https://arxiv.org/pdf/2506.19503.pdf' target='_blank'>https://arxiv.org/pdf/2506.19503.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Afila Ajithkumar Sophiya, Sepehr Maleki, Giuseppe Bruni, Senthil K. Krishnababu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19503">Physics-Informed Neural Networks for Industrial Gas Turbines: Recent Trends, Advancements and Challenges</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a promising computational framework for solving differential equations by integrating deep learning with physical constraints. However, their application in gas turbines is still in its early stages, requiring further refinement and standardization for wider adoption. This survey provides a comprehensive review of PINNs in Industrial Gas Turbines (IGTs) research, highlighting their contributions to the analysis of aerodynamic and aeromechanical phenomena, as well as their applications in flow field reconstruction, fatigue evaluation, and flutter prediction, and reviews recent advancements in accuracy, computational efficiency, and hybrid modelling strategies. In addition, it explores key research efforts, implementation challenges, and future directions aimed at improving the robustness and scalability of PINNs.
<div id='section'>Paperid: <span id='pid'>743, <a href='https://arxiv.org/pdf/2506.15687.pdf' target='_blank'>https://arxiv.org/pdf/2506.15687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yajie Ji, Yanlai Chen, Shawn Koohy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15687">S$^2$GPT-PINNs: Sparse and Small models for PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose S$^2$GPT-PINN, a sparse and small model for solving parametric partial differential equations (PDEs). Similar to Small Language Models (SLMs), S$^2$GPT-PINN is tailored to domain-specific (families of) PDEs and characterized by its compact architecture and minimal computational power. Leveraging a small amount of extremely high quality data via a mathematically rigorous greedy algorithm that is enabled by the large full-order models, S$^2$GPT-PINN relies on orders of magnitude less parameters than PINNs to achieve extremely high efficiency via two levels of customizations. The first is knowledge distillation via task-specific activation functions that are transferred from Pre-Trained PINNs. The second is a judicious down-sampling when calculating the physics-informed loss of the network compressing the number of data sites by orders of magnitude to the size of the small model.
<div id='section'>Paperid: <span id='pid'>744, <a href='https://arxiv.org/pdf/2506.12029.pdf' target='_blank'>https://arxiv.org/pdf/2506.12029.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Md Mahbub Alam, Amilcar Soares, JosÃ© F. Rodrigues-Jr, Gabriel Spadon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.12029">Physics-Informed Neural Networks for Vessel Trajectory Prediction: Learning Time-Discretized Kinematic Dynamics via Finite Differences</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate vessel trajectory prediction is crucial for navigational safety, route optimization, traffic management, search and rescue operations, and autonomous navigation. Traditional data-driven models lack real-world physical constraints, leading to forecasts that disobey vessel motion dynamics, such as in scenarios with limited or noisy data where sudden course changes or speed variations occur due to external factors. To address this limitation, we propose a Physics-Informed Neural Network (PINN) approach for trajectory prediction that integrates a streamlined kinematic model for vessel motion into the neural network training process via a first- and second-order, finite difference physics-based loss function. This loss function, discretized using the first-order forward Euler method, Heun's second-order approximation, and refined with a midpoint approximation based on Taylor series expansion, enforces fidelity to fundamental physical principles by penalizing deviations from expected kinematic behavior. We evaluated PINN using real-world AIS datasets that cover diverse maritime conditions and compared it with state-of-the-art models. Our results demonstrate that the proposed method reduces average displacement errors by up to 32% across models and datasets while maintaining physical consistency. These results enhance model reliability and adherence to mission-critical maritime activities, where precision translates into better situational awareness in the oceans.
<div id='section'>Paperid: <span id='pid'>745, <a href='https://arxiv.org/pdf/2506.08462.pdf' target='_blank'>https://arxiv.org/pdf/2506.08462.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Margadji, Sebastian W. Pattinson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08462">Hybrid Reasoning for Perception, Explanation, and Autonomous Action in Manufacturing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Industrial processes must be robust and adaptable, as environments and tasks are often unpredictable, while operational errors remain costly and difficult to detect. AI-based control systems offer a path forward, yet typically depend on supervised learning with extensive labelled datasets, which limits their ability to generalize across variable and data-scarce industrial settings. Foundation models could enable broader reasoning and knowledge integration, but rarely deliver the quantitative precision demanded by engineering applications. Here, we introduceControl and Interpretation of Production via Hybrid Expertise and Reasoning (CIPHER): a vision-language-action (VLA) model framework aiming to replicate human-like reasoning for industrial control, instantiated in a commercial-grade 3D printer. It integrates a process expert, a regression model enabling quantitative characterization of system states required for engineering tasks. CIPHER also incorporates retrieval-augmented generation to access external expert knowledge and support physics-informed, chain-of-thought reasoning. This hybrid architecture exhibits strong generalization to out-of-distribution tasks. It interprets visual or textual inputs from process monitoring, explains its decisions, and autonomously generates precise machine instructions, without requiring explicit annotations. CIPHER thus lays the foundations for autonomous systems that act with precision, reason with context, and communicate decisions transparently, supporting safe and trusted deployment in industrial settings.
<div id='section'>Paperid: <span id='pid'>746, <a href='https://arxiv.org/pdf/2506.06188.pdf' target='_blank'>https://arxiv.org/pdf/2506.06188.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis Kin Miyatake, Eduardo Camponogara, Eric Aislan Antonelo, Alexey Pavlov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06188">Physics-Informed Neural Networks for Control of Single-Phase Flow Systems Governed by Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The modeling and control of single-phase flow systems governed by Partial Differential Equations (PDEs) present challenges, especially under transient conditions. In this work, we extend the Physics-Informed Neural Nets for Control (PINC) framework, originally proposed to modeling and control of Ordinary Differential Equations (ODE) without the need of any labeled data, to the PDE case, particularly to single-phase incompressible and compressible flows, integrating neural networks with physical conservation laws. The PINC model for PDEs is structured into two stages: a steady-state network, which learns equilibrium solutions for a wide range of control inputs, and a transient network, which captures dynamic responses under time-varying boundary conditions. We propose a simplifying assumption that reduces the dimensionality of the spatial coordinate regarding the initial condition, allowing the efficient training of the PINC network. This simplification enables the derivation of optimal control policies using Model Predictive Control (MPC). We validate our approach through numerical experiments, demonstrating that the PINC model, which is trained exclusively using physical laws, i.e., without labeled data, accurately represents flow dynamics and enables real-time control applications. The results highlight the PINC's capability to efficiently approximate PDE solutions without requiring iterative solvers, making it a promising alternative for fluid flow monitoring and optimization in engineering applications.
<div id='section'>Paperid: <span id='pid'>747, <a href='https://arxiv.org/pdf/2506.02244.pdf' target='_blank'>https://arxiv.org/pdf/2506.02244.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Xue, Giuseppe Claudio Guarnera, Shuang Zhao, Zahra Montazeri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02244">Motion aware video generative model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in diffusion-based video generation have yielded unprecedented quality in visual content and semantic coherence. However, current approaches predominantly rely on statistical learning from vast datasets without explicitly modeling the underlying physics of motion, resulting in subtle yet perceptible non-physical artifacts that diminish the realism of generated videos. This paper introduces a physics-informed frequency domain approach to enhance the physical plausibility of generated videos. We first conduct a systematic analysis of the frequency-domain characteristics of diverse physical motions (translation, rotation, scaling), revealing that each motion type exhibits distinctive and identifiable spectral signatures. Building on this theoretical foundation, we propose two complementary components: (1) a physical motion loss function that quantifies and optimizes the conformity of generated videos to ideal frequency-domain motion patterns, and (2) a frequency domain enhancement module that progressively learns to adjust video features to conform to physical motion constraints while preserving original network functionality through a zero-initialization strategy. Experiments across multiple video diffusion architectures demonstrate that our approach significantly enhances motion quality and physical plausibility without compromising visual quality or semantic alignment. Our frequency-domain physical motion framework generalizes effectively across different video generation architectures, offering a principled approach to incorporating physical constraints into deep learning-based video synthesis pipelines. This work seeks to establish connections between data-driven models and physics-based motion models.
<div id='section'>Paperid: <span id='pid'>748, <a href='https://arxiv.org/pdf/2505.21404.pdf' target='_blank'>https://arxiv.org/pdf/2505.21404.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anas Jnini, Flavio Vella
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21404">Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Natural-gradient methods markedly accelerate the training of Physics-Informed Neural Networks (PINNs), yet their Gauss--Newton update must be solved in the parameter space, incurring a prohibitive $O(n^3)$ time complexity, where $n$ is the number of network trainable weights. We show that exactly the same step can instead be formulated in a generally smaller residual space of size $m = \sum_Î³ N_Î³ d_Î³$, where each residual class $Î³$ (e.g. PDE interior, boundary, initial data) contributes $N_Î³$ collocation points of output dimension $d_Î³$.
  Building on this insight, we introduce \textit{Dual Natural Gradient Descent} (D-NGD). D-NGD computes the Gauss--Newton step in residual space, augments it with a geodesic-acceleration correction at negligible extra cost, and provides both a dense direct solver for modest $m$ and a Nystrom-preconditioned conjugate-gradient solver for larger $m$.
  Experimentally, D-NGD scales second-order PINN optimization to networks with up to 12.8 million parameters, delivers one- to three-order-of-magnitude lower final error $L^2$ than first-order methods (Adam, SGD) and quasi-Newton methods, and -- crucially -- enables natural-gradient training of PINNs at this scale on a single GPU.
<div id='section'>Paperid: <span id='pid'>749, <a href='https://arxiv.org/pdf/2505.21404.pdf' target='_blank'>https://arxiv.org/pdf/2505.21404.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anas Jnini, Flavio Vella
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21404">Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Natural-gradient methods markedly accelerate the training of Physics-Informed Neural Networks (PINNs), yet their Gauss--Newton update must be solved in the parameter space, incurring a prohibitive $O(n^3)$ time complexity, where $n$ is the number of network trainable weights. We show that exactly the same step can instead be formulated in a generally smaller residual space of size $m = \sum_γ N_γ d_γ$, where each residual class $γ$ (e.g. PDE interior, boundary, initial data) contributes $N_γ$ collocation points of output dimension $d_γ$. Building on this insight, we introduce \textit{Dual Natural Gradient Descent} (D-NGD). D-NGD computes the Gauss--Newton step in residual space, augments it with a geodesic-acceleration correction at negligible extra cost, and provides both a dense direct solver for modest $m$ and a Nystrom-preconditioned conjugate-gradient solver for larger $m$. Experimentally, D-NGD scales second-order PINN optimization to networks with up to 12.8 million parameters, delivers one- to three-order-of-magnitude lower final error $L^2$ than first-order methods (Adam, SGD) and quasi-Newton methods, and -- crucially -- enables natural-gradient training of PINNs at this scale on a single GPU.
<div id='section'>Paperid: <span id='pid'>750, <a href='https://arxiv.org/pdf/2505.20327.pdf' target='_blank'>https://arxiv.org/pdf/2505.20327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aurora Poggi, Giuseppe Alessio D'Inverno, Hjalmar Brismar, Ozan Ãktem, Matthieu Barreau, Kateryna Morozovska
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20327">Data-driven multi-agent modelling of calcium interactions in cell culture: PINN vs Regularized Least-squares</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven discovery of dynamics in biological systems allows for better observation and characterization of processes, such as calcium signaling in cell culture. Recent advancements in techniques allow the exploration of previously unattainable insights of dynamical systems, such as the Sparse Identification of Non-Linear Dynamics (SINDy), overcoming the limitations of more classic methodologies. The latter requires some prior knowledge of an effective library of candidate terms, which is not realistic for a real case study. Using inspiration from fields like traffic density estimation and control theory, we propose a methodology for characterization and performance analysis of calcium delivery in a family of cells. In this work, we compare the performance of the Constrained Regularized Least-Squares Method (CRLSM) and Physics-Informed Neural Networks (PINN) for system identification and parameter discovery for governing ordinary differential equations (ODEs). The CRLSM achieves a fairly good parameter estimate and a good data fit when using the learned parameters in the Consensus problem. On the other hand, despite the initial hypothesis, PINNs fail to match the CRLSM performance and, under the current configuration, do not provide fair parameter estimation. However, we have only studied a limited number of PINN architectures, and it is expected that additional hyperparameter tuning, as well as uncertainty quantification, could significantly improve the performance in future works.
<div id='section'>Paperid: <span id='pid'>751, <a href='https://arxiv.org/pdf/2505.18565.pdf' target='_blank'>https://arxiv.org/pdf/2505.18565.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Afrah Farea, Saiful Khan, Reza Daryani, Emre Cenk Ersan, Mustafa Serdar Celebi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18565">Learning Fluid-Structure Interaction Dynamics with Physics-Informed Neural Networks and Immersed Boundary Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a promising approach for solving complex fluid dynamics problems, yet their application to fluid-structure interaction (FSI) problems with moving boundaries remains largely unexplored. This work addresses the critical challenge of modeling FSI systems with deformable interfaces, where traditional unified PINN architectures struggle to capture the distinct physics governing fluid and structural domains simultaneously. We present an innovative Eulerian-Lagrangian PINN architecture that integrates immersed boundary method (IBM) principles to solve FSI problems with moving boundary conditions. Our approach fundamentally departs from conventional unified architectures by introducing domain-specific neural networks: an Eulerian network for fluid dynamics and a Lagrangian network for structural interfaces, coupled through physics-based constraints. Additionally, we incorporate learnable B-spline activation functions with SiLU to capture both localized high-gradient features near interfaces and global flow patterns. Empirical studies on a 2D cavity flow problem involving a moving solid structure show that while baseline unified PINNs achieve reasonable velocity predictions, they suffer from substantial pressure errors (12.9%) in structural regions. Our Eulerian-Lagrangian architecture with learnable activations (EL-L) achieves better performance across all metrics, improving accuracy by 24.1-91.4% and particularly reducing pressure errors from 12.9% to 2.39%. These results demonstrate that domain decomposition aligned with physical principles, combined with locality-aware activation functions, is essential for accurate FSI modeling within the PINN framework.
<div id='section'>Paperid: <span id='pid'>752, <a href='https://arxiv.org/pdf/2505.10925.pdf' target='_blank'>https://arxiv.org/pdf/2505.10925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jichao Yin, Mingxuan Li, Jianguang Fang, Hu Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.10925">Enforced Interface Constraints for Domain Decomposition Method of Discrete Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a discrete physics-informed neural network (dPINN) framework, enhanced with enforced interface constraints (EIC), for modeling physical systems using the domain decomposition method (DDM). Built upon finite element-style mesh discretization, the dPINN accurately evaluates system energy through Gaussian quadrature-based element-wise integration. To ensure physical field continuity across subdomain interfaces, the EIC mechanism enforces interfacial displacement constraints without requiring auxiliary sampling or loss penalties.This formulation supports independent meshing in each subdomain, simplifying preprocessing and improving computational flexibility. Additionally, by eliminating the influence of weak spatial constraints (WSC) commonly observed in traditional PINNs, the EIC-dPINN delivers more stable and physically consistent predictions.Extensive two- and three-dimensional numerical experiments validate the proposed framework's accuracy and demonstrate the computational efficiency gains achieved through parallel training. The results highlight the framework's scalability, robustness, and potential for solving large-scale, geometrically complex problems.
<div id='section'>Paperid: <span id='pid'>753, <a href='https://arxiv.org/pdf/2505.07855.pdf' target='_blank'>https://arxiv.org/pdf/2505.07855.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuqi Shen, Junjie Yang, Hongliang Lu, Hui Zhong, Qiming Zhang, Xinhu Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07855">A Physics-informed End-to-End Occupancy Framework for Motion Planning of Autonomous Vehicles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and interpretable motion planning is essential for autonomous vehicles (AVs) navigating complex and uncertain environments. While recent end-to-end occupancy prediction methods have improved environmental understanding, they typically lack explicit physical constraints, limiting safety and generalization. In this paper, we propose a unified end-to-end framework that integrates verifiable physical rules into the occupancy learning process. Specifically, we embed artificial potential fields (APF) as physics-informed guidance during network training to ensure that predicted occupancy maps are both data-efficient and physically plausible. Our architecture combines convolutional and recurrent neural networks to capture spatial and temporal dependencies while preserving model flexibility. Experimental results demonstrate that our method improves task completion rate, safety margins, and planning efficiency across diverse driving scenarios, confirming its potential for reliable deployment in real-world AV systems.
<div id='section'>Paperid: <span id='pid'>754, <a href='https://arxiv.org/pdf/2505.04018.pdf' target='_blank'>https://arxiv.org/pdf/2505.04018.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xudong Jian, Kiran Bacsa, Gregory DuthÃ©, Eleni Chatzi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04018">Modal Decomposition and Identification for a Population of Structures Using Physics-Informed Graph Neural Networks and Transformers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modal identification is crucial for structural health monitoring and structural control, providing critical insights into structural dynamics and performance. This study presents a novel deep learning framework that integrates graph neural networks (GNNs), transformers, and a physics-informed loss function to achieve modal decomposition and identification across a population of structures. The transformer module decomposes multi-degrees-of-freedom (MDOF) structural dynamic measurements into single-degree-of-freedom (SDOF) modal responses, facilitating the identification of natural frequencies and damping ratios. Concurrently, the GNN captures the structural configurations and identifies mode shapes corresponding to the decomposed SDOF modal responses. The proposed model is trained in a purely physics-informed and unsupervised manner, leveraging modal decomposition theory and the independence of structural modes to guide learning without the need for labeled data. Validation through numerical simulations and laboratory experiments demonstrates its effectiveness in accurately decomposing dynamic responses and identifying modal properties from sparse structural dynamic measurements, regardless of variations in external loads or structural configurations. Comparative analyses against established modal identification techniques and model variations further underscore its superior performance, positioning it as a favorable approach for population-based structural health monitoring.
<div id='section'>Paperid: <span id='pid'>755, <a href='https://arxiv.org/pdf/2505.03590.pdf' target='_blank'>https://arxiv.org/pdf/2505.03590.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julian P. Merkofer, Dennis M. J. van de Sande, Alex A. Bhogal, Ruud J. G. van Sloun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03590">Physics-Informed Sylvester Normalizing Flows for Bayesian Inference in Magnetic Resonance Spectroscopy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Magnetic resonance spectroscopy (MRS) is a non-invasive technique to measure the metabolic composition of tissues, offering valuable insights into neurological disorders, tumor detection, and other metabolic dysfunctions. However, accurate metabolite quantification is hindered by challenges such as spectral overlap, low signal-to-noise ratio, and various artifacts. Traditional methods like linear-combination modeling are susceptible to ambiguities and commonly only provide a theoretical lower bound on estimation accuracy in the form of the CramÃ©r-Rao bound. This work introduces a Bayesian inference framework using Sylvester normalizing flows (SNFs) to approximate posterior distributions over metabolite concentrations, enhancing quantification reliability. A physics-based decoder incorporates prior knowledge of MRS signal formation, ensuring realistic distribution representations. We validate the method on simulated 7T proton MRS data, demonstrating accurate metabolite quantification, well-calibrated uncertainties, and insights into parameter correlations and multi-modal distributions.
<div id='section'>Paperid: <span id='pid'>756, <a href='https://arxiv.org/pdf/2504.19564.pdf' target='_blank'>https://arxiv.org/pdf/2504.19564.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuchen Song, Min Zhang, Yao Zhang, Yan Shi, Shikui Shen, Xiongyan Tang, Shanguo Huang, Danshi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.19564">Lifecycle Management of Optical Networks with Dynamic-Updating Digital Twin: A Hybrid Data-Driven and Physics-Informed Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Digital twin (DT) techniques have been proposed for the autonomous operation and lifecycle management of next-generation optical networks. To fully utilize potential capacity and accommodate dynamic services, the DT must dynamically update in sync with deployed optical networks throughout their lifecycle, ensuring low-margin operation. This paper proposes a dynamic-updating DT for the lifecycle management of optical networks, employing a hybrid approach that integrates data-driven and physics-informed techniques for fiber channel modeling. This integration ensures both rapid calculation speed and high physics consistency in optical performance prediction while enabling the dynamic updating of critical physical parameters for DT. The lifecycle management of optical networks, covering accurate performance prediction at the network deployment and dynamic updating during network operation, is demonstrated through simulation in a large-scale network. Up to 100 times speedup in prediction is observed compared to classical numerical methods. In addition, the fiber Raman gain strength, amplifier frequency-dependent gain profile, and connector loss between fiber and amplifier on C and L bands can be simultaneously updated. Moreover, the dynamic-updating DT is verified on a field-trial C+L-band transmission link, achieving a maximum accuracy improvement of 1.4 dB for performance estimation post-device replacement. Overall, the dynamic-updating DT holds promise for driving the next-generation optical networks towards lifecycle autonomous management.
<div id='section'>Paperid: <span id='pid'>757, <a href='https://arxiv.org/pdf/2504.19013.pdf' target='_blank'>https://arxiv.org/pdf/2504.19013.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>JÃºlia Vicens Figueres, Juliette Vanderhaeghen, Federica Bragone, Kateryna Morozovska, Khemraj Shukla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.19013">$PINN - a Domain Decomposition Method for Bayesian Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are a novel computational approach for solving partial differential equations (PDEs) with noisy and sparse initial and boundary data. Although, efficient quantification of epistemic and aleatoric uncertainties in big multi-scale problems remains challenging. We propose \$PINN a novel method of computing global uncertainty in PDEs using a Bayesian framework, by combining local Bayesian Physics-Informed Neural Networks (BPINN) with domain decomposition. The solution continuity across subdomains is obtained by imposing the flux continuity across the interface of neighboring subdomains. To demonstrate the effectiveness of \$PINN, we conduct a series of computational experiments on PDEs in 1D and 2D spatial domains. Although we have adopted conservative PINNs (cPINNs), the method can be seamlessly extended to other domain decomposition techniques. The results infer that the proposed method recovers the global uncertainty by computing the local uncertainty exactly more efficiently as the uncertainty in each subdomain can be computed concurrently. The robustness of \$PINN is verified by adding uncorrelated random noise to the training data up to 15% and testing for different domain sizes.
<div id='section'>Paperid: <span id='pid'>758, <a href='https://arxiv.org/pdf/2504.13768.pdf' target='_blank'>https://arxiv.org/pdf/2504.13768.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vinay Sharma, RÃ©mi Tanguy Oddon, Pietro Tesini, Jens Ravesloot, Cees Taal, Olga Fink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13768">Equi-Euler GraphNet: An Equivariant, Temporal-Dynamics Informed Graph Neural Network for Dual Force and Trajectory Prediction in Multi-Body Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate real-time modeling of multi-body dynamical systems is essential for enabling digital twin applications across industries. While many data-driven approaches aim to learn system dynamics, jointly predicting internal loads and system trajectories remains a key challenge. This dual prediction is especially important for fault detection and predictive maintenance, where internal loads-such as contact forces-act as early indicators of faults, reflecting wear or misalignment before affecting motion. These forces also serve as inputs to degradation models (e.g., crack growth), enabling damage prediction and remaining useful life estimation. We propose Equi-Euler GraphNet, a physics-informed graph neural network (GNN) that simultaneously predicts internal forces and global trajectories in multi-body systems. In this mesh-free framework, nodes represent system components and edges encode interactions. Equi-Euler GraphNet introduces two inductive biases: (1) an equivariant message-passing scheme, interpreting edge messages as interaction forces consistent under Euclidean transformations; and (2) a temporal-aware iterative node update mechanism, based on Euler integration, to capture influence of distant interactions over time. Tailored for cylindrical roller bearings, it decouples ring dynamics from constrained motion of rolling elements. Trained on high-fidelity multiphysics simulations, Equi-Euler GraphNet generalizes beyond the training distribution, accurately predicting loads and trajectories under unseen speeds, loads, and configurations. It outperforms state-of-the-art GNNs focused on trajectory prediction, delivering stable rollouts over thousands of time steps with minimal error accumulation. Achieving up to a 200x speedup over conventional solvers while maintaining comparable accuracy, it serves as an efficient reduced-order model for digital twins, design, and maintenance.
<div id='section'>Paperid: <span id='pid'>759, <a href='https://arxiv.org/pdf/2504.07481.pdf' target='_blank'>https://arxiv.org/pdf/2504.07481.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tian Xie, Menghui Jiang, Huanfeng Shen, Huifang Li, Chao Zeng, Jun Ma, Guanhao Zhang, Liangpei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07481">A Mechanism-Learning Deeply Coupled Model for Remote Sensing Retrieval of Global Land Surface Temperature</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Land surface temperature (LST) retrieval from remote sensing data is pivotal for analyzing climate processes and surface energy budgets. However, LST retrieval is an ill-posed inverse problem, which becomes particularly severe when only a single band is available. In this paper, we propose a deeply coupled framework integrating mechanistic modeling and machine learning to enhance the accuracy and generalizability of single-channel LST retrieval. Training samples are generated using a physically-based radiative transfer model and a global collection of 5810 atmospheric profiles. A physics-informed machine learning framework is proposed to systematically incorporate the first principles from classical physical inversion models into the learning workflow, with optimization constrained by radiative transfer equations. Global validation demonstrated a 30% reduction in root-mean-square error versus standalone methods. Under extreme humidity, the mean absolute error decreased from 4.87 K to 2.29 K (53% improvement). Continental-scale tests across five continents confirmed the superior generalizability of this model.
<div id='section'>Paperid: <span id='pid'>760, <a href='https://arxiv.org/pdf/2504.03484.pdf' target='_blank'>https://arxiv.org/pdf/2504.03484.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Federica Bragone, Kateryna Morozovska, Tor Laneryd, Khemraj Shukla, Stefano Markidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03484">Discovering Partially Known Ordinary Differential Equations: a Case Study on the Chemical Kinetics of Cellulose Degradation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The degree of polymerization (DP) is one of the methods for estimating the aging of the polymer based insulation systems, such as cellulose insulation in power components. The main degradation mechanisms in polymers are hydrolysis, pyrolysis, and oxidation. These mechanisms combined cause a reduction of the DP. However, the data availability for these types of problems is usually scarce. This study analyzes insulation aging using cellulose degradation data from power transformers. The aging problem for the cellulose immersed in mineral oil inside power transformers is modeled with ordinary differential equations (ODEs). We recover the governing equations of the degradation system using Physics-Informed Neural Networks (PINNs) and symbolic regression. We apply PINNs to discover the Arrhenius equation's unknown parameters in the Ekenstam ODE describing cellulose contamination content and the material aging process related to temperature for synthetic data and real DP values. A modification of the Ekenstam ODE is given by Emsley's system of ODEs, where the rate constant expressed by the Arrhenius equation decreases in time with the new formulation. We use PINNs and symbolic regression to recover the functional form of one of the ODEs of the system and to identify an unknown parameter.
<div id='section'>Paperid: <span id='pid'>761, <a href='https://arxiv.org/pdf/2504.03483.pdf' target='_blank'>https://arxiv.org/pdf/2504.03483.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dennis Wilkman, Kateryna Morozovska, Karl Henrik Johansson, Matthieu Barreau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03483">Online Traffic Density Estimation using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent works on the application of Physics-Informed Neural Networks to traffic density estimation have shown to be promising for future developments due to their robustness to model errors and noisy data. In this paper, we introduce a methodology for online approximation of the traffic density using measurements from probe vehicles in two settings: one using the Greenshield model and the other considering a high-fidelity traffic simulation. The proposed method continuously estimates the real-time traffic density in space and performs model identification with each new set of measurements. The density estimate is updated in almost real-time using gradient descent and adaptive weights. In the case of full model knowledge, the resulting algorithm has similar performance to the classical open-loop one. However, in the case of model mismatch, the iterative solution behaves as a closed-loop observer and outperforms the baseline method. Similarly, in the high-fidelity setting, the proposed algorithm correctly reproduces the traffic characteristics.
<div id='section'>Paperid: <span id='pid'>762, <a href='https://arxiv.org/pdf/2504.02529.pdf' target='_blank'>https://arxiv.org/pdf/2504.02529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amy Hodgkin, Nick Pepper, Marc Thomas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02529">Probabilistic Simulation of Aircraft Descent via a Physics-Informed Machine Learning Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a method for generating probabilistic descent trajectories in simulations of real-world airspace. A dataset of 116,066 trajectories harvested from Mode S radar returns in UK airspace was used to train and test the model. Thirteen aircraft types with varying performance characteristics were investigated. It was found that the error in the mean prediction of time to reach the bottom of descent for the proposed method was less than that of the the Base of Aircraft Data (BADA) model by a factor of 10. Furthermore, the method was capable of generating a range of trajectories that were similar to the held out test dataset when analysed in distribution. The proposed method is hybrid, with aircraft drag and calibrated airspeed functions generated probabilistically to parameterise the BADA equations, ensuring the physical plausibility of generated trajectories.
<div id='section'>Paperid: <span id='pid'>763, <a href='https://arxiv.org/pdf/2504.02459.pdf' target='_blank'>https://arxiv.org/pdf/2504.02459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Reza Najian Asl, Yusuke Yamazaki, Kianoosh Taghikhani, Mayu Muramatsu, Markus Apel, Shahed Rezaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02459">A Physics-Informed Meta-Learning Framework for the Continuous Solution of Parametric PDEs on Arbitrary Geometries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we introduce implicit Finite Operator Learning (iFOL) for the continuous and parametric solution of partial differential equations (PDEs) on arbitrary geometries. We propose a physics-informed encoder-decoder network to establish the mapping between continuous parameter and solution spaces. The decoder constructs the parametric solution field by leveraging an implicit neural field network conditioned on a latent or feature code. Instance-specific codes are derived through a PDE encoding process based on the second-order meta-learning technique. In training and inference, a physics-informed loss function is minimized during the PDE encoding and decoding. iFOL expresses the loss function in an energy or weighted residual form and evaluates it using discrete residuals derived from standard numerical PDE methods. This approach results in the backpropagation of discrete residuals during both training and inference.
  iFOL features several key properties: (1) its unique loss formulation eliminates the need for the conventional encode-process-decode pipeline previously used in operator learning with conditional neural fields for PDEs; (2) it not only provides accurate parametric and continuous fields but also delivers solution-to-parameter gradients without requiring additional loss terms or sensitivity analysis; (3) it can effectively capture sharp discontinuities in the solution; and (4) it removes constraints on the geometry and mesh, making it applicable to arbitrary geometries and spatial sampling (zero-shot super-resolution capability). We critically assess these features and analyze the network's ability to generalize to unseen samples across both stationary and transient PDEs. The overall performance of the proposed method is promising, demonstrating its applicability to a range of challenging problems in computational mechanics.
<div id='section'>Paperid: <span id='pid'>764, <a href='https://arxiv.org/pdf/2503.22528.pdf' target='_blank'>https://arxiv.org/pdf/2503.22528.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tiago de Souza Farias, Gubio Gomes de Lima, Jonas Maziero, Celso Jorge Villas-Boas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22528">MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.
<div id='section'>Paperid: <span id='pid'>765, <a href='https://arxiv.org/pdf/2503.20222.pdf' target='_blank'>https://arxiv.org/pdf/2503.20222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>D. Veerababu, Prasanta K. Ghosh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.20222">Solving 2-D Helmholtz equation in the rectangular, circular, and elliptical domains using neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks offered an alternate way to solve several differential equations that govern complicated physics. However, their success in predicting the acoustic field is limited by the vanishing-gradient problem that occurs when solving the Helmholtz equation. In this paper, a formulation is presented that addresses this difficulty. The problem of solving the two-dimensional Helmholtz equation with the prescribed boundary conditions is posed as an unconstrained optimization problem using trial solution method. According to this method, a trial neural network that satisfies the given boundary conditions prior to the training process is constructed using the technique of transfinite interpolation and the theory of R-functions. This ansatz is initially applied to the rectangular domain and later extended to the circular and elliptical domains. The acoustic field predicted from the proposed formulation is compared with that obtained from the two-dimensional finite element methods. Good agreement is observed in all three domains considered. Minor limitations associated with the proposed formulation and their remedies are also discussed.
<div id='section'>Paperid: <span id='pid'>766, <a href='https://arxiv.org/pdf/2503.19158.pdf' target='_blank'>https://arxiv.org/pdf/2503.19158.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefano De Carli, Nicola Licini, Davide Previtali, Fabio Previdi, Antonio Ferramosca
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.19158">Integrating Biological-Informed Recurrent Neural Networks for Glucose-Insulin Dynamics Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Type 1 Diabetes (T1D) management is a complex task due to many variability factors. Artificial Pancreas (AP) systems have alleviated patient burden by automating insulin delivery through advanced control algorithms. However, the effectiveness of these systems depends on accurate modeling of glucose-insulin dynamics, which traditional mathematical models often fail to capture due to their inability to adapt to patient-specific variations. This study introduces a Biological-Informed Recurrent Neural Network (BIRNN) framework to address these limitations. The BIRNN leverages a Gated Recurrent Units (GRU) architecture augmented with physics-informed loss functions that embed physiological constraints, ensuring a balance between predictive accuracy and consistency with biological principles. The framework is validated using the commercial UVA/Padova simulator, outperforming traditional linear models in glucose prediction accuracy and reconstruction of unmeasured states, even under circadian variations in insulin sensitivity. The results demonstrate the potential of BIRNN for personalized glucose regulation and future adaptive control strategies in AP systems.
<div id='section'>Paperid: <span id='pid'>767, <a href='https://arxiv.org/pdf/2503.16678.pdf' target='_blank'>https://arxiv.org/pdf/2503.16678.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Afrah Farea, Saiful Khan, Mustafa Serdar Celebi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16678">QCPINN: Quantum-Classical Physics-Informed Neural Networks for Solving PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as promising methods for solving partial differential equations (PDEs) by embedding physical laws within neural architectures. However, these classical approaches often require a large number of parameters to achieve reasonable accuracy, particularly for complex PDEs. In this paper, we present a quantum-classical physics-informed neural network (QCPINN) that combines quantum and classical components, allowing us to solve PDEs with significantly fewer parameters while maintaining comparable accuracy and convergence to classical PINNs. We systematically evaluated two quantum circuit architectures across various configurations on five benchmark PDEs to identify optimal QCPINN designs. Our results demonstrate that the QCPINN achieves stable convergence and comparable accuracy, while requiring approximately 10\% of the trainable parameters used in classical approaches. It also results in a 40\% reduction in the relative error $L_2$ for the convection-diffusion equation. These findings demonstrate the potential of parameter efficiency as a measurable quantum advantage in physics-informed machine learning, significantly reducing model complexity while preserving solution quality. This approach presents a promising solution to the computational challenges associated with solving PDEs.
<div id='section'>Paperid: <span id='pid'>768, <a href='https://arxiv.org/pdf/2503.11124.pdf' target='_blank'>https://arxiv.org/pdf/2503.11124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongyi Jia, Shu Miao, Jiayu Wu, Ming Yang, Chengzhi Hu, Xiang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.11124">Flow-Aware Navigation of Magnetic Micro-Robots in Complex Fluids via PINN-Based Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While magnetic micro-robots have demonstrated significant potential across various applications, including drug delivery and microsurgery, the open issue of precise navigation and control in complex fluid environments is crucial for in vivo implementation. This paper introduces a novel flow-aware navigation and control strategy for magnetic micro-robots that explicitly accounts for the impact of fluid flow on their movement. First, the proposed method employs a Physics-Informed U-Net (PI-UNet) to refine the numerically predicted fluid velocity using local observations. Then, the predicted velocity is incorporated in a flow-aware A* path planning algorithm, ensuring efficient navigation while mitigating flow-induced disturbances. Finally, a control scheme is developed to compensate for the predicted fluid velocity, thereby optimizing the micro-robot's performance. A series of simulation studies and real-world experiments are conducted to validate the efficacy of the proposed approach. This method enhances both planning accuracy and control precision, expanding the potential applications of magnetic micro-robots in fluid-affected environments typical of many medical scenarios.
<div id='section'>Paperid: <span id='pid'>769, <a href='https://arxiv.org/pdf/2503.09418.pdf' target='_blank'>https://arxiv.org/pdf/2503.09418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gledson Rodrigo Tondo, Igor Kavrakov, Guido Morgenthal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.09418">Efficient dynamic modal load reconstruction using physics-informed Gaussian processes based on frequency-sparse Fourier basis functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Knowledge of the force time history of a structure is essential to assess its behaviour, ensure safety and maintain reliability. However, direct measurement of external forces is often challenging due to sensor limitations, unknown force characteristics, or inaccessible load points. This paper presents an efficient dynamic load reconstruction method using physics-informed Gaussian processes (GP) based on frequency-sparse Fourier basis functions. The GP's covariance matrices are built using the description of the system dynamics, and the model is trained using structural response measurements. This provides support and interpretability to the machine learning model, in contrast to purely data-driven methods. In addition, the model filters out irrelevant components in the Fourier basis function by leveraging the sparsity of structural responses in the frequency domain, thereby reducing computational complexity during optimization. The trained model for structural responses is then integrated with the differential equation for a harmonic oscillator, creating a probabilistic dynamic load model that predicts load patterns without requiring force data during training. The model's effectiveness is validated through two case studies: a numerical model of a wind-excited 76-story building and an experiment using a physical scale model of the LillebÃ¦lt Bridge in Denmark, excited by a servo motor. For both cases, validation of the reconstructed forces is provided using comparison metrics for several signal properties. The developed model holds potential for applications in structural health monitoring, damage prognosis, and load model validation.
<div id='section'>Paperid: <span id='pid'>770, <a href='https://arxiv.org/pdf/2503.05716.pdf' target='_blank'>https://arxiv.org/pdf/2503.05716.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jichao Ma, Dandan Liu, Jinran Wu, Xi'an Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05716">Normalized Fourier-induced PINN method for solving the wave propagation equation in a non-unitized domain over an extended time range</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have gained significant attention for their simplicity and flexibility in engineering and scientific computing. In this study, we introduce a normalized PINN (NPINN) framework to solve a class of wave propagation equations in non-unitized domains over extended time ranges. This is achieved through a normalization technique that involves either spatial or temporal variable normalization. To enhance the capability of NPINN in solving wave equations, we integrate a Fourier-induced deep neural network as the solver, leading to a novel architecture termed NFPINN. Furthermore, we explore different normalization strategies for spatial and temporal variables and identify the optimal normalization approach for our method. To assess the effectiveness and robustness of the proposed NFPINN, we present numerical experiments in both two-dimensional and three-dimensional Euclidean spaces, considering regular and irregular domains. The results confirm the accuracy and stability of our approach.
<div id='section'>Paperid: <span id='pid'>771, <a href='https://arxiv.org/pdf/2503.04585.pdf' target='_blank'>https://arxiv.org/pdf/2503.04585.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manuel Santos Pereira, LuÃ­s Tripa, NÃ©lson Lima, Francisco Caldas, ClÃ¡udia Soares
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04585">Advancing Solutions for the Three-Body Problem Through Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>First formulated by Sir Isaac Newton in his work "Philosophiae Naturalis Principia Mathematica", the concept of the Three-Body Problem was put forth as a study of the motion of the three celestial bodies within the Earth-Sun-Moon system. In a generalized definition, it seeks to predict the motion for an isolated system composed of three point masses freely interacting under Newton's law of universal attraction. This proves to be analogous to a multitude of interactions between celestial bodies, and thus, the problem finds applicability within the studies of celestial mechanics. Despite numerous attempts by renowned physicists to solve it throughout the last three centuries, no general closed-form solutions have been reached due to its inherently chaotic nature for most initial conditions. Current state-of-the-art solutions are based on two approaches, either numerical high-precision integration or machine learning-based. Notwithstanding the breakthroughs of neural networks, these present a significant limitation, which is their ignorance of any prior knowledge of the chaotic systems presented. Thus, in this work, we propose a novel method that utilizes Physics-Informed Neural Networks (PINNs). These deep neural networks are able to incorporate any prior system knowledge expressible as an Ordinary Differential Equation (ODE) into their learning processes as a regularizing agent. Our findings showcase that PINNs surpass current state-of-the-art machine learning methods with comparable prediction quality. Despite a better prediction quality, the usability of numerical integrators suffers due to their prohibitively high computational cost. These findings confirm that PINNs are both effective and time-efficient open-form solvers of the Three-Body Problem that capitalize on the extensive knowledge we hold of classical mechanics.
<div id='section'>Paperid: <span id='pid'>772, <a href='https://arxiv.org/pdf/2503.00331.pdf' target='_blank'>https://arxiv.org/pdf/2503.00331.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hajar Kazemi Naeini, Roya Shomali, Abolhassan Pishahang, Hamidreza Hasanzadeh, Mahdieh Mohammadi, Saeed Asadi, Abbas Varmaghani, Ahmad Gholizadeh Lonbar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00331">PINN-DT: Optimizing Energy Consumption in Smart Building Using Hybrid Physics-Informed Neural Networks and Digital Twin Framework with Blockchain Security</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The advancement of smart grid technologies necessitates the integration of cutting-edge computational methods to enhance predictive energy optimization. This study proposes a multi-faceted approach by incorporating (1) Deep Reinforcement Learning (DRL) agents trained using data from Digital Twins (DTs) to optimize energy consumption in real time, (2) Physics-Informed Neural Networks (PINNs) to seamlessly embed physical laws within the optimization process, ensuring model accuracy and interpretability, and (3) Blockchain (BC) technology to facilitate secure and transparent communication across the smart grid infrastructure. The model was trained and validated using comprehensive datasets, including smart meter energy consumption data, renewable energy outputs, dynamic pricing, and user preferences collected from IoT devices. The proposed framework achieved superior predictive performance with a Mean Absolute Error (MAE) of 0.237 kWh, Root Mean Square Error (RMSE) of 0.298 kWh, and an R-squared (R2) value of 0.978, indicating a 97.8% explanation of data variance. Classification metrics further demonstrated the model's robustness, achieving 97.7% accuracy, 97.8% precision, 97.6% recall, and an F1 Score of 97.7%. Comparative analysis with traditional models like Linear Regression, Random Forest, SVM, LSTM, and XGBoost revealed the superior accuracy and real-time adaptability of the proposed method. In addition to enhancing energy efficiency, the model reduced energy costs by 35%, maintained a 96% user comfort index, and increased renewable energy utilization to 40%. This study demonstrates the transformative potential of integrating PINNs, DT, and Blockchain technologies to optimize energy consumption in smart grids, paving the way for sustainable, secure, and efficient energy management systems.
<div id='section'>Paperid: <span id='pid'>773, <a href='https://arxiv.org/pdf/2502.00552.pdf' target='_blank'>https://arxiv.org/pdf/2502.00552.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sirui Li, Federica Bragone, Matthieu Barreau, Tor Laneryd, Kateryna Morozovska
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00552">Optimal Sensor Placement in Power Transformers Using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Our work aims at simulating and predicting the temperature conditions inside a power transformer using Physics-Informed Neural Networks (PINNs). The predictions obtained are then used to determine the optimal placement for temperature sensors inside the transformer under the constraint of a limited number of sensors, enabling efficient performance monitoring. The method consists of combining PINNs with Mixed Integer Optimization Programming to obtain the optimal temperature reconstruction inside the transformer. First, we extend our PINN model for the thermal modeling of power transformers to solve the heat diffusion equation from 1D to 2D space. Finally, we construct an optimal sensor placement model inside the transformer that can be applied to problems in 1D and 2D.
<div id='section'>Paperid: <span id='pid'>774, <a href='https://arxiv.org/pdf/2501.18258.pdf' target='_blank'>https://arxiv.org/pdf/2501.18258.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weihao Yan, Christoph Brune, Mengwu Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18258">PDE-DKL: PDE-constrained deep kernel learning in high dimensionality</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many physics-informed machine learning methods for PDE-based problems rely on Gaussian processes (GPs) or neural networks (NNs). However, both face limitations when data are scarce and the dimensionality is high. Although GPs are known for their robust uncertainty quantification in low-dimensional settings, their computational complexity becomes prohibitive as the dimensionality increases. In contrast, while conventional NNs can accommodate high-dimensional input, they often require extensive training data and do not offer uncertainty quantification. To address these challenges, we propose a PDE-constrained Deep Kernel Learning (PDE-DKL) framework that combines DL and GPs under explicit PDE constraints. Specifically, NNs learn a low-dimensional latent representation of the high-dimensional PDE problem, reducing the complexity of the problem. GPs then perform kernel regression subject to the governing PDEs, ensuring accurate solutions and principled uncertainty quantification, even when available data are limited. This synergy unifies the strengths of both NNs and GPs, yielding high accuracy, robust uncertainty estimates, and computational efficiency for high-dimensional PDEs. Numerical experiments demonstrate that PDE-DKL achieves high accuracy with reduced data requirements. They highlight its potential as a practical, reliable, and scalable solver for complex PDE-based applications in science and engineering.
<div id='section'>Paperid: <span id='pid'>775, <a href='https://arxiv.org/pdf/2501.16153.pdf' target='_blank'>https://arxiv.org/pdf/2501.16153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sirui Li, Federica Bragone, Matthieu Barreau, Kateryna Morozovska
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16153">MILP initialization for solving parabolic PDEs with PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are a powerful deep learning method capable of providing solutions and parameter estimations of physical systems. Given the complexity of their neural network structure, the convergence speed is still limited compared to numerical methods, mainly when used in applications that model realistic systems. The network initialization follows a random distribution of the initial weights, as in the case of traditional neural networks, which could lead to severe model convergence bottlenecks. To overcome this problem, we follow current studies that deal with optimal initial weights in traditional neural networks. In this paper, we use a convex optimization model to improve the initialization of the weights in PINNs and accelerate convergence. We investigate two optimization models as a first training step, defined as pre-training, one involving only the boundaries and one including physics. The optimization is focused on the first layer of the neural network part of the PINN model, while the other weights are randomly initialized. We test the methods using a practical application of the heat diffusion equation to model the temperature distribution of power transformers. The PINN model with boundary pre-training is the fastest converging method at the current stage.
<div id='section'>Paperid: <span id='pid'>776, <a href='https://arxiv.org/pdf/2501.15908.pdf' target='_blank'>https://arxiv.org/pdf/2501.15908.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hai Siong Tan, Kuancheng Wang, Rafe McBeth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15908">Evidential Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel class of Physics-Informed Neural Networks that is formulated based on the principles of Evidential Deep Learning, where the model incorporates uncertainty quantification by learning parameters of a higher-order distribution. The dependent and trainable variables of the PDE residual loss and data-fitting loss terms are recast as functions of the hyperparameters of an evidential prior distribution. Our model is equipped with an information-theoretic regularizer that contains the Kullback-Leibler divergence between two inverse-gamma distributions characterizing predictive uncertainty. Relative to Bayesian-Physics-Informed-Neural-Networks, our framework appeared to exhibit higher sensitivity to data noise, preserve boundary conditions more faithfully and yield empirical coverage probabilities closer to nominal ones. Toward examining its relevance for data mining in scientific discoveries, we demonstrate how to apply our model to inverse problems involving 1D and 2D nonlinear differential equations.
<div id='section'>Paperid: <span id='pid'>777, <a href='https://arxiv.org/pdf/2501.15186.pdf' target='_blank'>https://arxiv.org/pdf/2501.15186.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianhao Hu, Bangti Jin, Fengru Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15186">An Iterative Deep Ritz Method for Monotone Elliptic Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present a novel iterative deep Ritz method (IDRM) for solving a general class of elliptic problems. It is inspired by the iterative procedure for minimizing the loss during the training of the neural network, but at each step encodes the geometry of the underlying function space and incorporates a convex penalty to enhance the performance of the algorithm. The algorithm is applicable to elliptic problems involving a monotone operator (not necessarily of variational form) and does not impose any stringent regularity assumption on the solution. It improves several existing neural PDE solvers, e.g., physics informed neural network and deep Ritz method, in terms of the accuracy for the concerned class of elliptic problems. Further, we establish a convergence rate for the method using tools from geometry of Banach spaces and theory of monotone operators, and also analyze the learning error. To illustrate the effectiveness of the method, we present several challenging examples, including a comparative study with existing techniques.
<div id='section'>Paperid: <span id='pid'>778, <a href='https://arxiv.org/pdf/2501.15085.pdf' target='_blank'>https://arxiv.org/pdf/2501.15085.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xianyuan Zhan, Xiangyu Zhu, Peng Cheng, Xiao Hu, Ziteng He, Hanfei Geng, Jichao Leng, Huiwen Zheng, Chenhui Liu, Tianshun Hong, Yan Liang, Yunxin Liu, Feng Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15085">Data Center Cooling System Optimization Using Offline Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent advances in information technology and artificial intelligence have fueled a rapid expansion of the data center (DC) industry worldwide, accompanied by an immense appetite for electricity to power the DCs. In a typical DC, around 30~40% of the energy is spent on the cooling system rather than on computer servers, posing a pressing need for developing new energy-saving optimization technologies for DC cooling systems. However, optimizing such real-world industrial systems faces numerous challenges, including but not limited to a lack of reliable simulation environments, limited historical data, and stringent safety and control robustness requirements. In this work, we present a novel physics-informed offline reinforcement learning (RL) framework for energy efficiency optimization of DC cooling systems. The proposed framework models the complex dynamical patterns and physical dependencies inside a server room using a purposely designed graph neural network architecture that is compliant with the fundamental time-reversal symmetry. Because of its well-behaved and generalizable state-action representations, the model enables sample-efficient and robust latent space offline policy learning using limited real-world operational data. Our framework has been successfully deployed and verified in a large-scale production DC for closed-loop control of its air-cooling units (ACUs). We conducted a total of 2000 hours of short and long-term experiments in the production DC environment. The results show that our method achieves 14~21% energy savings in the DC cooling system, without any violation of the safety or operational constraints. Our results have demonstrated the significant potential of offline RL in solving a broad range of data-limited, safety-critical real-world industrial control problems.
<div id='section'>Paperid: <span id='pid'>779, <a href='https://arxiv.org/pdf/2501.14573.pdf' target='_blank'>https://arxiv.org/pdf/2501.14573.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huang Zhang, Xixi Liu, Faisal Altaf, Torsten Wik
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.14573">A Transferable Physics-Informed Framework for Battery Degradation Diagnosis, Knee-Onset Detection and Knee Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The techno-economic and safety concerns of battery capacity knee occurrence call for developing online knee detection and prediction methods as an advanced battery management system (BMS) function. To address this, a transferable physics-informed framework that consists of a histogram-based feature engineering method, a hybrid physics-informed model, and a fine-tuning strategy, is proposed for online battery degradation diagnosis and knee-onset detection. The hybrid model is first developed and evaluated using a scenario-aware pipeline in protocol cycling scenarios and then fine-tuned to create local models deployed in a dynamic cycling scenario. A 2D histogram-based 17-feature set is found to be the best choice in both source and target scenarios. The fine-tuning strategy is proven to be effective in improving battery degradation mode estimation and degradation phase detection performance in the target scenario. Again, a strong linear correlation was found between the identified knee-onset and knee points. As a result, advanced BMS functions, such as online degradation diagnosis and prognosis, online knee-onset detection and knee prediction, aging-aware battery classification, and second-life repurposing, can be enabled through a battery performance digital twin in the cloud.
<div id='section'>Paperid: <span id='pid'>780, <a href='https://arxiv.org/pdf/2501.01587.pdf' target='_blank'>https://arxiv.org/pdf/2501.01587.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yajie Ji, Yanlai Chen, Zhenli Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01587">EGPT-PINN: Entropy-enhanced Generative Pre-Trained Physics Informed Neural Networks for parameterized nonlinear conservation laws</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose an entropy-enhanced Generative Pre-Trained Physics-Informed Neural Network with a transform layer (EGPT-PINN) for solving parameterized nonlinear conservation laws. The EGPT-PINN extends the traditional physics-informed neural networks and its recently proposed generative pre-trained strategy for linear model reduction to nonlinear model reduction and shock-capturing domains. By utilizing an adaptive meta-network, a simultaneously trained transform layer, entropy enhancement strategies, implementable shock interaction analysis, and a separable training process, the EGPT-PINN efficiently captures complex parameter-dependent shock formations and interactions. Numerical results of EGPT-PINN applied to the families of inviscid Burgers' equation and the Euler equations, parameterized by their initial conditions, demonstrate the robustness and accuracy of the proposed technique. It accurately solves the viscosity solution via very few neurons without leveraging any {\it a priori} knowledge of the equations or its initial condition. Moreover, via a simple augmentation of the loss function by model-data mismatch, we demonstrate the robustness of EGPT-PINN in solving inverse problems more accurately than the vanilla and entropy-enhanced versions of PINN.
<div id='section'>Paperid: <span id='pid'>781, <a href='https://arxiv.org/pdf/2501.00016.pdf' target='_blank'>https://arxiv.org/pdf/2501.00016.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elham Kiyani, Manav Manav, Nikhil Kadivar, Laura De Lorenzis, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.00016">Predicting Crack Nucleation and Propagation in Brittle Materials Using Deep Operator Networks with Diverse Trunk Architectures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Phase-field modeling reformulates fracture problems as energy minimization problems and enables a comprehensive characterization of the fracture process, including crack nucleation, propagation, merging, and branching, without relying on ad-hoc assumptions. However, the numerical solution of phase-field fracture problems is characterized by a high computational cost. To address this challenge, in this paper, we employ a deep neural operator (DeepONet) consisting of a branch network and a trunk network to solve brittle fracture problems. We explore three distinct approaches that vary in their trunk network configurations. In the first approach, we demonstrate the effectiveness of a two-step DeepONet, which results in a simplification of the learning task. In the second approach, we employ a physics-informed DeepONet, whereby the mathematical expression of the energy is integrated into the trunk network's loss to enforce physical consistency. The integration of physics also results in a substantially smaller data size needed for training. In the third approach, we replace the neural network in the trunk with a Kolmogorov-Arnold Network and train it without the physics loss. Using these methods, we model crack nucleation in a one-dimensional homogeneous bar under prescribed end displacements, as well as crack propagation and branching in single edge-notched specimens with varying notch lengths subjected to tensile and shear loading. We show that the networks predict the solution fields accurately, and the error in the predicted fields is localized near the crack.
<div id='section'>Paperid: <span id='pid'>782, <a href='https://arxiv.org/pdf/2412.20851.pdf' target='_blank'>https://arxiv.org/pdf/2412.20851.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vasiliy A. Es'kin, Alexey O. Malkhanov, Mikhail E. Smorkalov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20851">About rectified sigmoid function for enhancing the accuracy of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The article is devoted to the study of neural networks with one hidden layer and a modified activation function for solving physical problems. A rectified sigmoid activation function has been proposed to solve physical problems described by the ODE with neural networks. Algorithms for physics-informed data-driven initialization of a neural network and a neuron-by-neuron gradient-free fitting method have been presented for the neural network with this activation function. Numerical experiments demonstrate the superiority of neural networks with a rectified sigmoid function over neural networks with a sigmoid function in the accuracy of solving physical problems (harmonic oscillator, relativistic slingshot, and Lorentz system).
<div id='section'>Paperid: <span id='pid'>783, <a href='https://arxiv.org/pdf/2412.19517.pdf' target='_blank'>https://arxiv.org/pdf/2412.19517.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunwoo Cho, Sung Woong Cho, Hyeontae Jo, Hyung Ju Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.19517">Estimation of System Parameters Including Repeated Cross-Sectional Data through Emulator-Informed Deep Generative Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Differential equations (DEs) are crucial for modeling the evolution of natural or engineered systems. Traditionally, the parameters in DEs are adjusted to fit data from system observations. However, in fields such as politics, economics, and biology, available data are often independently collected at distinct time points from different subjects (i.e., repeated cross-sectional (RCS) data). Conventional optimization techniques struggle to accurately estimate DE parameters when RCS data exhibit various heterogeneities, leading to a significant loss of information. To address this issue, we propose a new estimation method called the emulator-informed deep-generative model (EIDGM), designed to handle RCS data. Specifically, EIDGM integrates a physics-informed neural network-based emulator that immediately generates DE solutions and a Wasserstein generative adversarial network-based parameter generator that can effectively mimic the RCS data. We evaluated EIDGM on exponential growth, logistic population models, and the Lorenz system, demonstrating its superior ability to accurately capture parameter distributions. Additionally, we applied EIDGM to an experimental dataset of Amyloid beta 40 and beta 42, successfully capturing diverse parameter distribution shapes. This shows that EIDGM can be applied to model a wide range of systems and extended to uncover the operating principles of systems based on limited data.
<div id='section'>Paperid: <span id='pid'>784, <a href='https://arxiv.org/pdf/2412.19235.pdf' target='_blank'>https://arxiv.org/pdf/2412.19235.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vasiliy A. Es'kin, Alexey O. Malkhanov, Mikhail E. Smorkalov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.19235">Are Two Hidden Layers Still Enough for the Physics-Informed Neural Networks?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The article discusses the development of various methods and techniques for initializing and training neural networks with a single hidden layer, as well as training a separable physics-informed neural network consisting of neural networks with a single hidden layer to solve physical problems described by ordinary differential equations (ODEs) and partial differential equations (PDEs). A method for strictly deterministic initialization of a neural network with one hidden layer for solving physical problems described by an ODE is proposed. Modifications to existing methods for weighting the loss function are given, as well as new methods developed for training strictly deterministic-initialized neural networks to solve ODEs (detaching, additional weighting based on the second derivative, predicted solution-based weighting, relative residuals). An algorithm for physics-informed data-driven initialization of a neural network with one hidden layer is proposed. A neural network with pronounced generalizing properties is presented, whose generalizing abilities of which can be precisely controlled by adjusting network parameters. A metric for measuring the generalization of such neural network has been introduced. A gradient-free neuron-by-neuron fitting method has been developed for adjusting the parameters of a single-hidden-layer neural network, which does not require the use of an optimizer or solver for its implementation. The proposed methods have been extended to 2D problems using the separable physics-informed neural networks approach. Numerous experiments have been carried out to develop the above methods and approaches. Experiments on physical problems, such as solving various ODEs and PDEs, have demonstrated that these methods for initializing and training neural networks with one or two hidden layers (SPINN) achieve competitive accuracy and, in some cases, state-of-the-art results.
<div id='section'>Paperid: <span id='pid'>785, <a href='https://arxiv.org/pdf/2412.11967.pdf' target='_blank'>https://arxiv.org/pdf/2412.11967.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kamaljyoti Nath, Varun Kumar, Daniel J. Smith, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.11967">A Digital twin for Diesel Engines: Operator-infused PINNs with Transfer Learning for Engine Health Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Improving diesel engine efficiency and emission reduction have been critical research topics. Recent government regulations have shifted this focus to another important area related to engine health and performance monitoring. Although the advancements in the use of deep learning methods for system monitoring have shown promising results in this direction, designing efficient methods suitable for field systems remains an open research challenge. The objective of this study is to develop a computationally efficient neural network-based approach for identifying unknown parameters of a mean value diesel engine model to facilitate physics-based health monitoring and maintenance forecasting. We propose a hybrid method combining physics informed neural networks, PINNs, and a deep neural operator, DeepONet to predict unknown parameters and gas flow dynamics in a diesel engine. The operator network predicts independent actuator dynamics learnt through offline training, thereby reducing the PINNs online computational cost. To address PINNs need for retraining with changing input scenarios, we propose two transfer learning (TL) strategies. The first strategy involves multi-stage transfer learning for parameter identification. While this method is computationally efficient as compared to online PINN training, improvements are required to meet field requirements. The second TL strategy focuses solely on training the output weights and biases of a subset of multi-head networks pretrained on a larger dataset, substantially reducing computation time during online prediction. We also evaluate our model for epistemic and aleatoric uncertainty by incorporating dropout in pretrained networks and Gaussian noise in the training dataset. This strategy offers a tailored, computationally inexpensive, and physics-based approach for parameter identification in diesel engine sub systems.
<div id='section'>Paperid: <span id='pid'>786, <a href='https://arxiv.org/pdf/2411.18050.pdf' target='_blank'>https://arxiv.org/pdf/2411.18050.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anmol Dwivedi, Ali Tajer, Santiago Paternain, Nurali Virani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.18050">RL for Mitigating Cascading Failures: Targeted Exploration via Sensitivity Factors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electricity grid's resiliency and climate change strongly impact one another due to an array of technical and policy-related decisions that impact both. This paper introduces a physics-informed machine learning-based framework to enhance grid's resiliency. Specifically, when encountering disruptive events, this paper designs remedial control actions to prevent blackouts. The proposed Physics-Guided Reinforcement Learning (PG-RL) framework determines effective real-time remedial line-switching actions, considering their impact on power balance, system security, and grid reliability. To identify an effective blackout mitigation policy, PG-RL leverages power-flow sensitivity factors to guide the RL exploration during agent training. Comprehensive evaluations using the Grid2Op platform demonstrate that incorporating physical signals into RL significantly improves resource utilization within electric grids and achieves better blackout mitigation policies - both of which are critical in addressing climate change.
<div id='section'>Paperid: <span id='pid'>787, <a href='https://arxiv.org/pdf/2411.17039.pdf' target='_blank'>https://arxiv.org/pdf/2411.17039.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Yang, Pingan He, Xiaoling Peng, Qiaolin He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17039">A novel number-theoretic sampling method for neural network solutions of partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional Monte Carlo integration using uniform random sampling exhibits degraded efficiency in low-regularity or high-dimensional problems. We propose a novel deep learning framework based on deterministic number-theoretic sampling points, which is a robust approach specifically designed to handle partial differential equations with rough solutions or in high dimensions. The sample points are generated by the generating vector to achieve the smallest discrepancy. The architecture integrates Physics-Informed Neural Networks (PINNs) with rigorous mathematical guarantees demonstrating lower error bounds compared to conventional uniform random sampling. Numerical validation includes low-regularity Poisson equations, two-dimensional inverse Helmholtz problems, and high-dimensional linear/nonlinear PDEs, systematically demonstrating the algorithm's superior performance and generalization capabilities.
<div id='section'>Paperid: <span id='pid'>788, <a href='https://arxiv.org/pdf/2411.15111.pdf' target='_blank'>https://arxiv.org/pdf/2411.15111.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Afrah Farea, Mustafa Serdar Celebi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15111">Learnable Activation Functions in Physics-Informed Neural Networks for Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a promising approach for solving Partial Differential Equations (PDEs). However, they face challenges related to spectral bias (the tendency to learn low-frequency components while struggling with high-frequency features) and unstable convergence dynamics (mainly stemming from the multi-objective nature of the PINN loss function). These limitations impact their accuracy for problems involving rapid oscillations, sharp gradients, and complex boundary behaviors. We systematically investigate learnable activation functions as a solution to these challenges, comparing Multilayer Perceptrons (MLPs) using fixed and learnable activation functions against Kolmogorov-Arnold Networks (KANs) that employ learnable basis functions. Our evaluation spans diverse PDE types, including linear and non-linear wave problems, mixed-physics systems, and fluid dynamics. Using empirical Neural Tangent Kernel (NTK) analysis and Hessian eigenvalue decomposition, we assess spectral bias and convergence stability of the models. Our results reveal a trade-off between expressivity and training convergence stability. While learnable activation functions work well in simpler architectures, they encounter scalability issues in complex networks due to the higher functional dimensionality. Counterintuitively, we find that low spectral bias alone does not guarantee better accuracy, as functions with broader NTK eigenvalue spectra may exhibit convergence instability. We demonstrate that activation function selection remains inherently problem-specific, with different bases showing distinct advantages for particular PDE characteristics. We believe these insights will help in the design of more robust neural PDE solvers.
<div id='section'>Paperid: <span id='pid'>789, <a href='https://arxiv.org/pdf/2411.06781.pdf' target='_blank'>https://arxiv.org/pdf/2411.06781.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thang Nguyen, Dung Nguyen, Kha Pham, Truyen Tran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.06781">MP-PINN: A Multi-Phase Physics-Informed Neural Network for Epidemic Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Forecasting temporal processes such as virus spreading in epidemics often requires more than just observed time-series data, especially at the beginning of a wave when data is limited. Traditional methods employ mechanistic models like the SIR family, which make strong assumptions about the underlying spreading process, often represented as a small set of compact differential equations. Data-driven methods such as deep neural networks make no such assumptions and can capture the generative process in more detail, but fail in long-term forecasting due to data limitations. We propose a new hybrid method called MP-PINN (Multi-Phase Physics-Informed Neural Network) to overcome the limitations of these two major approaches. MP-PINN instils the spreading mechanism into a neural network, enabling the mechanism to update in phases over time, reflecting the dynamics of the epidemics due to policy interventions. Experiments on COVID-19 waves demonstrate that MP-PINN achieves superior performance over pure data-driven or model-driven approaches for both short-term and long-term forecasting.
<div id='section'>Paperid: <span id='pid'>790, <a href='https://arxiv.org/pdf/2410.23388.pdf' target='_blank'>https://arxiv.org/pdf/2410.23388.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>EfraÃ­n MagaÃ±a, Simone Pezzuto, Francisco Sahli Costabal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.23388">Ensemble learning of the atrial fiber orientation with physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The anisotropic structure of the myocardium is a key determinant of the cardiac function. To date, there is no imaging modality to assess in-vivo the cardiac fiber structure. We recently proposed Fibernet, a method for the automatic identification of the anisotropic conduction -- and thus fibers -- in the atria from local electrical recordings. Fibernet uses cardiac activation as recorded during electroanatomical mappings to infer local conduction properties using physics-informed neural networks. In this work, we extend Fibernet to cope with the uncertainty in the estimated fiber field. Specifically, we use an ensemble of neural networks to produce multiple samples, all fitting the observed data, and compute posterior statistics. We also introduce a methodology to select the best fiber orientation members and define the input of the neural networks directly on the atrial surface. With these improvements, we outperform the previous methodology in terms of fiber orientation error in 8 different atrial anatomies. Currently, our approach can estimate the fiber orientation and conduction velocities in under 7 minutes with quantified uncertainty, which opens the door to its application in clinical practice. We hope the proposed methodology will enable further personalization of cardiac digital twins for precision medicine.
<div id='section'>Paperid: <span id='pid'>791, <a href='https://arxiv.org/pdf/2410.21657.pdf' target='_blank'>https://arxiv.org/pdf/2410.21657.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hira Saleem, Flora Salim, Cormac Purcell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21657">PACER: Physics Informed Uncertainty Aware Climate Emulator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Climate models serve as critical tools for evaluating the effects of climate change and projecting future climate scenarios. However, the reliance on numerical simulations of physical equations renders them computationally intensive and inefficient. While deep learning methodologies have made significant progress in weather forecasting, they are still unstable for climate emulation tasks. Here, we propose PACER, a lightweight 684K parameter Physics Informed Uncertainty Aware Climate Emulator. PACER emulates temperature and precipitation stably for 86 years while only being trained on greenhouse gas emissions data. We incorporate a fundamental physical law of advection-diffusion in PACER accounting for boundary conditions and empirically estimating the diffusion co-efficient and flow velocities from emissions data. PACER has been trained on 15 climate models provided by ClimateSet outperforming baselines across most of the climate models and advancing a new state of the art in a climate diagnostic task.
<div id='section'>Paperid: <span id='pid'>792, <a href='https://arxiv.org/pdf/2410.21657.pdf' target='_blank'>https://arxiv.org/pdf/2410.21657.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hira Saleem, Flora Salim, Cormac Purcell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21657">PACER: Physics Informed and Uncertainty Aware Climate Emulator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics based numerical climate models serve as critical tools for evaluating the effects of climate change and projecting future climate scenarios. However, the reliance on numerical simulations of physical equations renders them computationally intensive and inefficient. While deep learning methodologies have made significant progress in weather forecasting, they are still unstable for longer roll-out climate emulation task. Here, we propose PACER, a relatively lightweight 2.1M parameter Physics Informed Uncertainty Aware Climate EmulatoR. PACER is trained across is trained across varying spatial resolutions and physics based climate models, enabling faithful and stable emulation of temperature fields at multiple surface levels over a 10 year horizon. We propose an auto-regressive ODE-SDE framework for climate emulation that integrates the fundamental physical law of advection, while being trained under a negative log-likelihood objective to enable principled uncertainty quantification of stochastic variability. We show PACER's emulation performance across 20 climate models outperforming relevant baselines and advancing towards explicit physics infusion in ML emulator.
<div id='section'>Paperid: <span id='pid'>793, <a href='https://arxiv.org/pdf/2410.19027.pdf' target='_blank'>https://arxiv.org/pdf/2410.19027.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Harandi, Hooman Danesh, Kevin Linka, Stefanie Reese, Shahed Rezaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.19027">A Spectral-based Physics-informed Finite Operator Learning for Prediction of Mechanical Behavior of Microstructures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A novel physics-informed operator learning technique based on spectral methods is introduced to model the complex behavior of heterogeneous materials. The Lippmann-Schwinger operator in Fourier space is employed to construct physical constraints with minimal computational overhead, effectively eliminating the need for automatic differentiation. The introduced methodology accelerates the training process by enabling gradient construction on a fixed, finite discretization in Fourier space. Later, the spectral physics-informed finite operator learning (SPiFOL) framework is built based on this discretization and trained to map the arbitrary shape of microstructures to their mechanical responses (strain fields) without relying on labeled data. The training is done by minimizing equilibrium in Fourier space concerning the macroscopic loading condition, which also guarantees the periodicity. SPiFOL, as a physics-informed operator learning method, enables rapid predictions through forward inference after training. To ensure accuracy, we incorporate physical constraints and diversify the training data. However, performance may still degrade for out-of-distribution microstructures. SPiFOL is further enhanced by integrating a Fourier Neural Operator (FNO). Compared to the standard data-driven FNO, SPiFOL shows higher accuracy in predicting stress fields and provides nearly resolution-independent results. Additionally, its zero-shot super-resolution capabilities are explored in heterogeneous domains. Finally, SPiFOL is extended to handle 3D problems and further adapted to finite elasticity, demonstrating the robustness of the framework in handling nonlinear mechanical behavior. The framework shows great potential for efficient and scalable prediction of mechanical responses in complex material systems while also reducing the training time required for training physics-informed neural operators.
<div id='section'>Paperid: <span id='pid'>794, <a href='https://arxiv.org/pdf/2410.18553.pdf' target='_blank'>https://arxiv.org/pdf/2410.18553.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel MaÃ®tre, Vishal S. Ngairangbam, Michael Spannowsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.18553">Optimal Equivariant Architectures from the Symmetries of Matrix-Element Likelihoods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Matrix-Element Method (MEM) has long been a cornerstone of data analysis in high-energy physics. It leverages theoretical knowledge of parton-level processes and symmetries to evaluate the likelihood of observed events. In parallel, the advent of geometric deep learning has enabled neural network architectures that incorporate known symmetries directly into their design, leading to more efficient learning. This paper presents a novel approach that combines MEM-inspired symmetry considerations with equivariant neural network design for particle physics analysis. Even though Lorentz invariance and permutation invariance overall reconstructed objects are the largest and most natural symmetry in the input domain, we find that they are sub-optimal in most practical search scenarios. We propose a longitudinal boost-equivariant message-passing neural network architecture that preserves relevant discrete symmetries. We present numerical studies demonstrating MEM-inspired architectures achieve new state-of-the-art performance in distinguishing di-Higgs decays to four bottom quarks from the QCD background, with enhanced sample and parameter efficiencies. This synergy between MEM and equivariant deep learning opens new directions for physics-informed architecture design, promising more powerful tools for probing physics beyond the Standard Model.
<div id='section'>Paperid: <span id='pid'>795, <a href='https://arxiv.org/pdf/2410.17525.pdf' target='_blank'>https://arxiv.org/pdf/2410.17525.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoqian Qi, Haoye Chai, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.17525">Physics-driven AI for Channel Estimation in Cellular Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In cellular mobile networks, wireless channel quality (CQ) is a crucial factor in determining communication performance and user's network experience. Accurately predicting CQ based on real environmental characteristics, specific base station configurations and user trajectories can help network operators optimize base station deployment, improving coverage and capacity. The Received Signal Reference Power (RSRP) and Signal-to-Interference-plus-Noise Ratio (SINR) of user equipment (UE) are key indicators of CQ in wireless communication. However, existing researches have limitations in terms of generation accuracy. Regression methods such as statistical inference and random forests fail to effectively capture the unique characteristics of wireless environments; theoretical derivations relying on specific communication protocols lack generalization capability; data-driven machine learning (ML) methods like Long Short-Term Memory (LSTM) Network often suffer from a lack of interpretability. To overcome these limitations, we propose physics-informed diffusion models, which accurately generate RSRP and SINR at UE based on the wireless environment, base station configurations, and user trajectories. The model adopts a modular and end-to-end design, employing a teacher-student framework to achieve knowledge distillation. This method integrates expert knowledge into the training of diffusion models, enhancing both the interpretability and accuracy, while also facilitating faster convergence of the model parameters. Furthermore, it allows for self-adaptation in various scenarios through few-shot learning. This approach provides valuable guidance for optimizing base station deployment, predicting user network experience, and building real-world simulators.
<div id='section'>Paperid: <span id='pid'>796, <a href='https://arxiv.org/pdf/2410.04096.pdf' target='_blank'>https://arxiv.org/pdf/2410.04096.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianchi Yu, Jingwei Qiu, Jiang Yang, Ivan Oseledets
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04096">Sinc Kolmogorov-Arnold Network and Its Applications on Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose to use Sinc interpolation in the context of Kolmogorov-Arnold Networks, neural networks with learnable activation functions, which recently gained attention as alternatives to multilayer perceptron. Many different function representations have already been tried, but we show that Sinc interpolation proposes a viable alternative, since it is known in numerical analysis to represent well both smooth functions and functions with singularities. This is important not only for function approximation but also for the solutions of partial differential equations with physics-informed neural networks. Through a series of experiments, we show that SincKANs provide better results in almost all of the examples we have considered.
<div id='section'>Paperid: <span id='pid'>797, <a href='https://arxiv.org/pdf/2409.19140.pdf' target='_blank'>https://arxiv.org/pdf/2409.19140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eric Mochiutti, Eric Aislan Antonelo, Eduardo Camponogara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19140">Physics-Informed Echo State Networks for Modeling Controllable Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Echo State Networks (ESNs) are recurrent neural networks usually employed for modeling nonlinear dynamic systems with relatively ease of training. By incorporating physical laws into the training of ESNs, Physics-Informed ESNs (PI-ESNs) were proposed initially to model chaotic dynamic systems without external inputs. They require less data for training since Ordinary Differential Equations (ODEs) of the considered system help to regularize the ESN. In this work, the PI-ESN is extended with external inputs to model controllable nonlinear dynamic systems. Additionally, an existing self-adaptive balancing loss method is employed to balance the contributions of the residual regression term and the physics-informed loss term in the total loss function. The experiments with two nonlinear systems modeled by ODEs, the Van der Pol oscillator and the four-tank system, and with one differential-algebraic (DAE) system, an electric submersible pump, revealed that the proposed PI-ESN outperforms the conventional ESN, especially in scenarios with limited data availability, showing that PI-ESNs can regularize an ESN model with external inputs previously trained on just a few datapoints, reducing its overfitting and improving its generalization error (up to 92% relative reduction in the test error). Further experiments demonstrated that the proposed PI-ESN is robust to parametric uncertainties in the ODE equations and that model predictive control using PI-ESN outperforms the one using plain ESN, particularly when training data is scarce.
<div id='section'>Paperid: <span id='pid'>798, <a href='https://arxiv.org/pdf/2409.13644.pdf' target='_blank'>https://arxiv.org/pdf/2409.13644.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qifeng Hu, Shamsulhaq Basir, Inanc Senocak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13644">Non-overlapping, Schwarz-type Domain Decomposition Method for Physics and Equality Constrained Artificial Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a non-overlapping, Schwarz-type domain decomposition method with a generalized interface condition, designed for physics-informed machine learning of partial differential equations (PDEs) in both forward and inverse contexts. Our approach employs physics and equality-constrained artificial neural networks (PECANN) within each subdomain. Unlike the original PECANN method, which relies solely on initial and boundary conditions to constrain PDEs, our method uses both boundary conditions and the governing PDE to constrain a unique interface loss function for each subdomain. This modification improves the learning of subdomain-specific interface parameters while reducing communication overhead by delaying information exchange between neighboring subdomains. To address the constrained optimization in each subdomain, we apply an augmented Lagrangian method with a conditionally adaptive update strategy, transforming the problem into an unconstrained dual optimization. A distinct advantage of our domain decomposition method is its ability to learn solutions to both Poisson's and Helmholtz equations, even in cases with high-wavenumber and complex-valued solutions. Through numerical experiments with up to 64 subdomains, we demonstrate that our method consistently generalizes well as the number of subdomains increases.
<div id='section'>Paperid: <span id='pid'>799, <a href='https://arxiv.org/pdf/2409.02345.pdf' target='_blank'>https://arxiv.org/pdf/2409.02345.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kenjiro Nishimura, Hikaru Hoshino, Eiko Furutani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02345">Combined Plant and Control Co-design via Solutions of Hamilton-Jacobi-Bellman Equation Based on Physics-informed Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses integrated design of engineering systems, where physical structure of the plant and controller design are optimized simultaneously. To cope with uncertainties due to noises acting on the dynamics and modeling errors, an Uncertain Control Co-design (UCCD) problem formulation is proposed. Existing UCCD methods usually rely on uncertainty propagation analyses using Monte Calro methods for open-loop solutions of optimal control, which suffer from stringent trade-offs among accuracy, time horizon, and computational time. The proposed method utilizes closed-loop solutions characterized by the Hamilton-Jacobi-Bellman equation, a Partial Differential Equation (PDE) defined on the state space. A solution algorithm for the proposed UCCD formulation is developed based on PDE solutions of Physics-informed Neural Networks (PINNs). Numerical examples of regulator design problems are provided, and it is shown that simultaneous update of PINN weights and the design parameters effectively works for solving UCCD problems.
<div id='section'>Paperid: <span id='pid'>800, <a href='https://arxiv.org/pdf/2409.02339.pdf' target='_blank'>https://arxiv.org/pdf/2409.02339.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jin Song, Zhenya Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02339">Data-driven 2D stationary quantum droplets and wave propagations in the amended GP equation with two potentials via deep neural networks learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we develop a systematic deep learning approach to solve two-dimensional (2D) stationary quantum droplets (QDs) and investigate their wave propagation in the 2D amended Gross-Pitaevskii equation with Lee-Huang-Yang correction and two kinds of potentials. Firstly, we use the initial-value iterative neural network (IINN) algorithm for 2D stationary quantum droplets of stationary equations. Then the learned stationary QDs are used as the initial value conditions for physics-informed neural networks (PINNs) to explore their evolutions in the some space-time region. Especially, we consider two types of potentials, one is the 2D quadruple-well Gaussian potential and the other is the PT-symmetric HO-Gaussian potential, which lead to spontaneous symmetry breaking and the generation of multi-component QDs. The used deep learning method can also be applied to study wave propagations of other nonlinear physical models.
<div id='section'>Paperid: <span id='pid'>801, <a href='https://arxiv.org/pdf/2409.01124.pdf' target='_blank'>https://arxiv.org/pdf/2409.01124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jin Song, Ming Zhong, George Em Karniadakis, Zhenya Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01124">Two-stage initial-value iterative physics-informed neural networks for simulating solitary waves of nonlinear wave equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a new two-stage initial-value iterative neural network (IINN) algorithm for solitary wave computations of nonlinear wave equations based on traditional numerical iterative methods and physics-informed neural networks (PINNs). Specifically, the IINN framework consists of two subnetworks, one of which is used to fit a given initial value, and the other incorporates physical information and continues training on the basis of the first subnetwork. Importantly, the IINN method does not require any additional data information including boundary conditions, apart from the given initial value. Corresponding theoretical guarantees are provided to demonstrate the effectiveness of our IINN method. The proposed IINN method is efficiently applied to learn some types of solutions in different nonlinear wave equations, including the one-dimensional (1D) nonlinear SchrÃ¶dinger equations (NLS) equation (with and without potentials), the 1D saturable NLS equation with PT -symmetric optical lattices, the 1D focusing-defocusing coupled NLS equations, the KdV equation, the two-dimensional (2D) NLS equation with potentials, the 2D amended GP equation with a potential, the (2+1)-dimensional KP equation, and the 3D NLS equation with a potential. These applications serve as evidence for the efficacy of our method. Finally, by comparing with the traditional methods, we demonstrate the advantages of the proposed IINN method.
<div id='section'>Paperid: <span id='pid'>802, <a href='https://arxiv.org/pdf/2408.16414.pdf' target='_blank'>https://arxiv.org/pdf/2408.16414.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianchi Yu, Yiming Qi, Ivan Oseledets, Shiyi Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16414">Spectral Informed Neural Network: An Efficient and Low-Memory PINN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With growing investigations into solving partial differential equations by physics-informed neural networks (PINNs), more accurate and efficient PINNs are required to meet the practical demands of scientific computing. One bottleneck of current PINNs is computing the high-order derivatives via automatic differentiation which often necessitates substantial computing resources. In this paper, we focus on removing the automatic differentiation of the spatial derivatives and propose a spectral-based neural network that substitutes the differential operator with a multiplication. Compared to the PINNs, our approach requires lower memory and shorter training time. Thanks to the exponential convergence of the spectral basis, our approach is more accurate. Moreover, to handle the different situations between physics domain and spectral domain, we provide two strategies to train networks by their spectral information. Through a series of comprehensive experiments, We validate the aforementioned merits of our proposed network.
<div id='section'>Paperid: <span id='pid'>803, <a href='https://arxiv.org/pdf/2408.15267.pdf' target='_blank'>https://arxiv.org/pdf/2408.15267.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahdi Nasiri, Sahel Iqbal, Simo SÃ¤rkkÃ¤
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15267">Physics-Informed Machine Learning for Grade Prediction in Froth Flotation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, physics-informed neural network models are developed to predict the concentrate gold grade in froth flotation cells. Accurate prediction of concentrate grades is important for the automatic control and optimization of mineral processing. Both first-principles and data-driven machine learning methods have been used to model the flotation process. The complexity of models based on first-principles restricts their direct use, while purely data-driven models often fail in dynamic industrial environments, leading to poor generalization. To address these limitations, this study integrates classical mathematical models of froth flotation processes with conventional deep learning methods to construct physics-informed neural networks. These models demonstrated superior generalization and predictive performance compared to purely data-driven models, on simulated data from two flotation cells, in terms of mean squared error and mean relative error.
<div id='section'>Paperid: <span id='pid'>804, <a href='https://arxiv.org/pdf/2408.09340.pdf' target='_blank'>https://arxiv.org/pdf/2408.09340.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yilong Hou, Xi'an Li, Jinran Wu, You-Gan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09340">Enhanced BPINN Training Convergence in Solving General and Multi-scale Elliptic PDEs with Noise</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Physics Informed Neural Networks (BPINN) have attracted considerable attention for inferring the system states and physical parameters of differential equations according to noisy observations. However, in practice, Hamiltonian Monte Carlo (HMC) used to estimate the internal parameters of the solver for BPINN often encounters these troubles including poor performance and awful convergence for a given step size used to adjust the momentum of those parameters. To address the convergence of HMC for the BPINN method and extend its application scope to multi-scale partial differential equations (PDE), we develop a robust multi-scale BPINN (dubbed MBPINN) method by integrating multi-scale deep neural networks (MscaleDNN) and the BPINN framework. In this newly proposed MBPINN method, we reframe HMC with Stochastic Gradient Descent (SGD) to ensure the most ``likely'' estimation is always provided, and we configure its solver as a Fourier feature mapping-induced MscaleDNN. This novel method offers several key advantages: (1) it is more robust than HMC, (2) it incurs less computational cost than HMC, and (3) it is more flexible for complex problems. We demonstrate the applicability and performance of the proposed method through some general Poisson and multi-scale elliptic problems in one and two-dimensional Euclidean spaces. Our findings indicate that the proposed method can avoid HMC failures and provide valid results. Additionally, our method is capable of handling complex elliptic PDE and producing comparable results for general elliptic PDE under the case of lower signal-to-noise rate. These findings suggest that our proposed approach has great potential for physics-informed machine learning for parameter estimation and solution recovery in the case of ill-posed problems.
<div id='section'>Paperid: <span id='pid'>805, <a href='https://arxiv.org/pdf/2408.04718.pdf' target='_blank'>https://arxiv.org/pdf/2408.04718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dule Shu, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.04718">Zero-Shot Uncertainty Quantification using Diffusion Probabilistic Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The success of diffusion probabilistic models in generative tasks, such as text-to-image generation, has motivated the exploration of their application to regression problems commonly encountered in scientific computing and various other domains. In this context, the use of diffusion regression models for ensemble prediction is becoming a practice with increasing popularity. Under such background, we conducted a study to quantitatively evaluate the effectiveness of ensemble methods on solving different regression problems using diffusion models. We consider the ensemble prediction of a diffusion model as a means for zero-shot uncertainty quantification, since the diffusion models in our study are not trained with a loss function containing any uncertainty estimation. Through extensive experiments on 1D and 2D data, we demonstrate that ensemble methods consistently improve model prediction accuracy across various regression tasks. Notably, we observed a larger accuracy gain in auto-regressive prediction compared with point-wise prediction, and that enhancements take place in both the mean-square error and the physics-informed loss. Additionally, we reveal a statistical correlation between ensemble prediction error and ensemble variance, offering insights into balancing computational complexity with prediction accuracy and monitoring prediction confidence in practical applications where the ground truth is unknown. Our study provides a comprehensive view of the utility of diffusion ensembles, serving as a useful reference for practitioners employing diffusion models in regression problem-solving.
<div id='section'>Paperid: <span id='pid'>806, <a href='https://arxiv.org/pdf/2408.03508.pdf' target='_blank'>https://arxiv.org/pdf/2408.03508.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Shen, Yuan Li, Wenkang Zhan, Shujie Pan, Fuxin Lin, Kaiyao Xin, Hui Cong, Chi Xu, Xiaotian Cheng, Ruixiang Liu, Zhibo Ni, Chaoyuan Jin, Bo Xu, Siming Chen, Zhongming Wei, Chunlai Xue, Zhanguo Wang, Chao Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.03508">On-Demand Growth of Semiconductor Heterostructures Guided by Physics-Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing tailored semiconductor heterostructures on demand represents a critical capability for addressing the escalating performance demands in electronic and optoelectronic devices. However, traditional fabrication methods remain constrained by simulation-based design and iterative trial-and-error optimization. Here, we introduce SemiEpi, a self-driving platform designed for molecular beam epitaxy (MBE) to perform multi-step semiconductor heterostructure growth through in-situ monitoring and on-the-fly feedback control. By integrating standard MBE reactors, physics-informed machine learning (ML) models, and parameter initialization, SemiEpi identifies optimal initial conditions and proposes experiments for heterostructure growth, eliminating the need for extensive expertise in MBE processes. As a proof of concept, we demonstrate the optimization of high-density InAs quantum dot (QD) growth with a target emission wavelength of 1240 nm, showcasing the power of SemiEpi. We achieve a QD density of 5 x 10^10 cm^-2, a 1.6-fold increase in photoluminescence (PL) intensity, and a reduced full width at half maximum (FWHM) of 29.13 meV, leveraging in-situ reflective high-energy electron diffraction monitoring with feedback control for adjusting growth temperatures. Taken together, our results highlight the potential of ML-guided systems to address challenges in multi-step heterostructure growth, facilitate the development of a hardware-independent framework, and enhance process repeatability and stability, even without exhaustive knowledge of growth parameters.
<div id='section'>Paperid: <span id='pid'>807, <a href='https://arxiv.org/pdf/2407.18057.pdf' target='_blank'>https://arxiv.org/pdf/2407.18057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>James H. Adler, Samuel Hocking, Xiaozhe Hu, Shafiqul Islam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.18057">Physics-informed nonlinear vector autoregressive models for the prediction of dynamical systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning techniques have recently been of great interest for solving differential equations. Training these models is classically a data-fitting task, but knowledge of the expression of the differential equation can be used to supplement the training objective, leading to the development of physics-informed scientific machine learning. In this article, we focus on one class of models called nonlinear vector autoregression (NVAR) to solve ordinary differential equations (ODEs). Motivated by connections to numerical integration and physics-informed neural networks, we explicitly derive the physics-informed NVAR (piNVAR) which enforces the right-hand side of the underlying differential equation regardless of NVAR construction. Because NVAR and piNVAR completely share their learned parameters, we propose an augmented procedure to jointly train the two models. Then, using both data-driven and ODE-driven metrics, we evaluate the ability of the piNVAR model to predict solutions to various ODE systems, such as the undamped spring, a Lotka-Volterra predator-prey nonlinear model, and the chaotic Lorenz system.
<div id='section'>Paperid: <span id='pid'>808, <a href='https://arxiv.org/pdf/2407.07611.pdf' target='_blank'>https://arxiv.org/pdf/2407.07611.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shahroz Khan, Zahid Masood, Muhammad Usama, Konstantinos Kostas, Panagiotis Kaklis, Wei, Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.07611">Physics-Informed Geometric Operators to Support Surrogate, Dimension Reduction and Generative Models for Engineering Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we propose a set of physics-informed geometric operators (GOs) to enrich the geometric data provided for training surrogate/discriminative models, dimension reduction, and generative models, typically employed for performance prediction, dimension reduction, and creating data-driven parameterisations, respectively. However, as both the input and output streams of these models consist of low-level shape representations, they often fail to capture shape characteristics essential for performance analyses. Therefore, the proposed GOs exploit the differential and integral properties of shapes--accessed through Fourier descriptors, curvature integrals, geometric moments, and their invariants--to infuse high-level intrinsic geometric information and physics into the feature vector used for training, even when employing simple model architectures or low-level parametric descriptions. We showed that for surrogate modelling, along with the inclusion of the notion of physics, GOs enact regularisation to reduce over-fitting and enhance generalisation to new, unseen designs. Furthermore, through extensive experimentation, we demonstrate that for dimension reduction and generative models, incorporating the proposed GOs enriches the training data with compact global and local geometric features. This significantly enhances the quality of the resulting latent space, thereby facilitating the generation of valid and diverse designs. Lastly, we also show that GOs can enable learning parametric sensitivities to a great extent. Consequently, these enhancements accelerate the convergence rate of shape optimisers towards optimal solutions.
<div id='section'>Paperid: <span id='pid'>809, <a href='https://arxiv.org/pdf/2407.04157.pdf' target='_blank'>https://arxiv.org/pdf/2407.04157.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shahed Rezaei, Reza Najian Asl, Kianoosh Taghikhani, Ahmad Moeineddin, Michael Kaliske, Markus Apel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04157">Finite Operator Learning: Bridging Neural Operators and Numerical Methods for Efficient Parametric Solution and Optimization of PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a method that combines neural operators, physics-informed machine learning, and standard numerical methods for solving PDEs. The proposed approach extends each of the aforementioned methods and unifies them within a single framework. We can parametrically solve partial differential equations in a data-free manner and provide accurate sensitivities, meaning the derivatives of the solution space with respect to the design space. These capabilities enable gradient-based optimization without the typical sensitivity analysis costs, unlike adjoint methods that scale directly with the number of response functions. Our Finite Operator Learning (FOL) approach uses an uncomplicated feed-forward neural network model to directly map the discrete design space (i.e. parametric input space) to the discrete solution space (i.e. finite number of sensor points in the arbitrary shape domain) ensuring compliance with physical laws by designing them into loss functions. The discretized governing equations, as well as the design and solution spaces, can be derived from any well-established numerical techniques. In this work, we employ the Finite Element Method (FEM) to approximate fields and their spatial derivatives. Subsequently, we conduct Sobolev training to minimize a multi-objective loss function, which includes the discretized weak form of the energy functional, boundary conditions violations, and the stationarity of the residuals with respect to the design variables. Our study focuses on the steady-state heat equation within heterogeneous materials that exhibits significant phase contrast and possibly temperature-dependent conductivity. The network's tangent matrix is directly used for gradient-based optimization to improve the microstructure's heat transfer characteristics. ...
<div id='section'>Paperid: <span id='pid'>810, <a href='https://arxiv.org/pdf/2407.02861.pdf' target='_blank'>https://arxiv.org/pdf/2407.02861.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlo Cena, Silvia Bucci, Alessandro Balossino, Marcello Chiaberge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02861">A Self-Supervised Task for Fault Detection in Satellite Multivariate Time Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the space sector, due to environmental conditions and restricted accessibility, robust fault detection methods are imperative for ensuring mission success and safeguarding valuable assets. This work proposes a novel approach leveraging Physics-Informed Real NVP neural networks, renowned for their ability to model complex and high-dimensional distributions, augmented with a self-supervised task based on sensors' data permutation. It focuses on enhancing fault detection within the satellite multivariate time series. The experiments involve various configurations, including pre-training with self-supervision, multi-task learning, and standalone self-supervised training. Results indicate significant performance improvements across all settings. In particular, employing only the self-supervised loss yields the best overall results, suggesting its efficacy in guiding the network to extract relevant features for fault detection. This study presents a promising direction for improving fault detection in space systems and warrants further exploration in other datasets and applications.
<div id='section'>Paperid: <span id='pid'>811, <a href='https://arxiv.org/pdf/2407.00337.pdf' target='_blank'>https://arxiv.org/pdf/2407.00337.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaolong He, April Tran, David M. Bortz, Youngsoo Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.00337">Physics-informed active learning with simultaneous weak-form latent space dynamics identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The parametric greedy latent space dynamics identification (gLaSDI) framework has demonstrated promising potential for accurate and efficient modeling of high-dimensional nonlinear physical systems. However, it remains challenging to handle noisy data. To enhance robustness against noise, we incorporate the weak-form estimation of nonlinear dynamics (WENDy) into gLaSDI. In the proposed weak-form gLaSDI (WgLaSDI) framework, an autoencoder and WENDy are trained simultaneously to discover intrinsic nonlinear latent-space dynamics of high-dimensional data. Compared to the standard sparse identification of nonlinear dynamics (SINDy) employed in gLaSDI, WENDy enables variance reduction and robust latent space discovery, therefore leading to more accurate and efficient reduced-order modeling. Furthermore, the greedy physics-informed active learning in WgLaSDI enables adaptive sampling of optimal training data on the fly for enhanced modeling accuracy. The effectiveness of the proposed framework is demonstrated by modeling various nonlinear dynamical problems, including viscous and inviscid Burgers' equations, time-dependent radial advection, and the Vlasov equation for plasma physics. With data that contains 5-10% Gaussian white noise, WgLaSDI outperforms gLaSDI by orders of magnitude, achieving 1-7% relative errors. Compared with the high-fidelity models, WgLaSDI achieves 121 to 1,779x speed-up.
<div id='section'>Paperid: <span id='pid'>812, <a href='https://arxiv.org/pdf/2406.15299.pdf' target='_blank'>https://arxiv.org/pdf/2406.15299.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zesheng Liu, Maryam Rahnemoonfar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.15299">Learning Spatio-Temporal Patterns of Polar Ice Layers With Physics-Informed Graph Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning spatio-temporal patterns of polar ice layers is crucial for monitoring the change in ice sheet balance and evaluating ice dynamic processes. While a few researchers focus on learning ice layer patterns from echogram images captured by airborne snow radar sensors via different convolutional neural networks, the noise in the echogram images proves to be a major obstacle. Instead, we focus on geometric deep learning based on graph neural networks to learn the spatio-temporal patterns from thickness information of shallow ice layers and make predictions for deep layers. In this paper, we propose a physics-informed hybrid graph neural network that combines the GraphSAGE framework for graph feature learning with the long short-term memory (LSTM) structure for learning temporal changes, and introduce measurements of physical ice properties from Model Atmospheric Regional (MAR) weather model as physical node features. We found that our proposed network can consistently outperform the current non-inductive or non-physical model in predicting deep ice layer thickness.
<div id='section'>Paperid: <span id='pid'>813, <a href='https://arxiv.org/pdf/2406.10997.pdf' target='_blank'>https://arxiv.org/pdf/2406.10997.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youngkyu Lee, Alena Kopaničáková, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10997">Two-level overlapping additive Schwarz preconditioner for training scientific machine learning applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel two-level overlapping additive Schwarz preconditioner for accelerating the training of scientific machine learning applications. The design of the proposed preconditioner is motivated by the nonlinear two-level overlapping additive Schwarz preconditioner. The neural network parameters are decomposed into groups (subdomains) with overlapping regions. In addition, the network's feed-forward structure is indirectly imposed through a novel subdomain-wise synchronization strategy and a coarse-level training step. Through a series of numerical experiments, which consider physics-informed neural networks and operator learning approaches, we demonstrate that the proposed two-level preconditioner significantly speeds up the convergence of the standard (LBFGS) optimizer while also yielding more accurate machine learning models. Moreover, the devised preconditioner is designed to take advantage of model-parallel computations, which can further reduce the training time.
<div id='section'>Paperid: <span id='pid'>814, <a href='https://arxiv.org/pdf/2406.09217.pdf' target='_blank'>https://arxiv.org/pdf/2406.09217.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrea Bonito, Ronald DeVore, Guergana Petrova, Jonathan W. Siegel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09217">Convergence and error control of consistent PINNs for elliptic PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We provide an a priori analysis of collocation methods for solving elliptic boundary value problems. They begin with information in the form of point values of the data and utilize only this information to numerically approximate the solution u of the PDE. For such a method to provide an approximation with guaranteed error bounds, additional assumptions on the data, called model class assumptions, are needed. We determine the best error of approximating u in the energy norm, in terms of the total number of point samples, under all Besov class model assumptions for the right hand side and boundary data.
  We then turn to the study of numerical procedures and analyze whether a proposed numerical procedure achieves the optimal recovery error. We analyze numerical methods which generate the numerical approximation to $u$ by minimizing specified data driven loss functions over a set $Î£$ which is either a finite dimensional linear space, or more generally, a finite dimensional manifold. We show that the success of such a procedure depends critically on choosing a data driven loss function that is consistent with the PDE and provides sharp error control. Based on this analysis a new loss function is proposed.
  We also address the recent methods of Physics Informed Neural Networks. We prove that minimization of the new loss over restricted neural network spaces $Î£$ provides an optimal recovery of the solution $u$, provided that the optimization problem can be numerically executed and $Î£$ has sufficient approximation capabilities. We also analyze variants of the new loss function which are more practical for implementation. Finally, numerical examples illustrating the benefits of the proposed loss functions are given.
<div id='section'>Paperid: <span id='pid'>815, <a href='https://arxiv.org/pdf/2405.18311.pdf' target='_blank'>https://arxiv.org/pdf/2405.18311.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Anton, Jendrik-Alexander TrÃ¶ger, Henning Wessels, Ulrich RÃ¶mer, Alexander Henkes, Stefan Hartmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18311">Deterministic and statistical calibration of constitutive models from full-field data with parametric physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The calibration of constitutive models from full-field data has recently gained increasing interest due to improvements in full-field measurement capabilities. In addition to the experimental characterization of novel materials, continuous structural health monitoring is another application that is of great interest. However, monitoring is usually associated with severe time constraints, difficult to meet with standard numerical approaches. Therefore, parametric physics-informed neural networks (PINNs) for constitutive model calibration from full-field displacement data are investigated. In an offline stage, a parametric PINN can be trained to learn a parameterized solution of the underlying partial differential equation. In the subsequent online stage, the parametric PINN then acts as a surrogate for the parameters-to-state map in calibration. We test the proposed approach for the deterministic least-squares calibration of a linear elastic as well as a hyperelastic constitutive model from noisy synthetic displacement data. We further carry out Markov chain Monte Carlo-based Bayesian inference to quantify the uncertainty. A proper statistical evaluation of the results underlines the high accuracy of the deterministic calibration and that the estimated uncertainty is valid. Finally, we consider experimental data and show that the results are in good agreement with a finite element method-based calibration. Due to the fast evaluation of PINNs, calibration can be performed in near real-time. This advantage is particularly evident in many-query applications such as Markov chain Monte Carlo-based Bayesian inference.
<div id='section'>Paperid: <span id='pid'>816, <a href='https://arxiv.org/pdf/2405.13944.pdf' target='_blank'>https://arxiv.org/pdf/2405.13944.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrea Serani, Matteo Diez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13944">A Survey on Design-space Dimensionality Reduction Methods for Shape Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapidly evolving field of engineering design of functional surfaces necessitates sophisticated tools to manage the inherent complexity of high-dimensional design spaces. This survey paper offers a scoping review, i.e., a literature mapping synthesis borrowed from clinical medicine, delving into the field of design-space dimensionality reduction techniques tailored for shape optimization, bridging traditional methods and cutting-edge technologies. Dissecting the spectrum of these techniques, from classical linear approaches like principal component analysis to more nuanced nonlinear methods such as autoencoders, the discussion extends to innovative physics-informed methods that integrate physical data into the dimensionality reduction process, enhancing the physical relevance and effectiveness of reduced design spaces. By integrating these methods into optimization frameworks, it is shown how they significantly mitigate the curse of dimensionality, streamline computational processes, and refine the design exploration and optimization of complex functional surfaces. The survey provides a classification of methods and highlights the transformative impact of these techniques in simplifying design challenges, thereby fostering more efficient and effective engineering solutions.
<div id='section'>Paperid: <span id='pid'>817, <a href='https://arxiv.org/pdf/2405.12802.pdf' target='_blank'>https://arxiv.org/pdf/2405.12802.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Igor Kavrakov, Gledson Rodrigo Tondo, Guido Morgenthal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12802">Stochastic Inference of Plate Bending from Heterogeneous Data: Physics-informed Gaussian Processes via Kirchhoff-Love Theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advancements in machine learning and an abundance of structural monitoring data have inspired the integration of mechanical models with probabilistic models to identify a structure's state and quantify the uncertainty of its physical parameters and response. In this paper, we propose an inference methodology for classical Kirchhoff-Love plates via physics-informed Gaussian Processes (GP). A probabilistic model is formulated as a multi-output GP by placing a GP prior on the deflection and deriving the covariance function using the linear differential operators of the plate governing equations. The posteriors of the flexural rigidity, hyperparameters, and plate response are inferred in a Bayesian manner using Markov chain Monte Carlo (MCMC) sampling from noisy measurements. We demonstrate the applicability with two examples: a simply supported plate subjected to a sinusoidal load and a fixed plate subjected to a uniform load. The results illustrate how the proposed methodology can be employed to perform stochastic inference for plate rigidity and physical quantities by integrating measurements from various sensor types and qualities. Potential applications of the presented methodology are in structural health monitoring and uncertainty quantification of plate-like structures.
<div id='section'>Paperid: <span id='pid'>818, <a href='https://arxiv.org/pdf/2404.19536.pdf' target='_blank'>https://arxiv.org/pdf/2404.19536.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zesheng Liu, YoungHyun Koo, Maryam Rahnemoonfar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.19536">Physics-Informed Machine Learning On Polar Ice: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The mass loss of the polar ice sheets contributes considerably to ongoing sea-level rise and changing ocean circulation, leading to coastal flooding and risking the homes and livelihoods of tens of millions of people globally. To address the complex problem of ice behavior, physical models and data-driven models have been proposed in the literature. Although traditional physical models can guarantee physically meaningful results, they have limitations in producing high-resolution results. On the other hand, data-driven approaches require large amounts of high-quality and labeled data, which is rarely available in the polar regions. Hence, as a promising framework that leverages the advantages of physical models and data-driven methods, physics-informed machine learning (PIML) has been widely studied in recent years. In this paper, we review the existing algorithms of PIML, provide our own taxonomy based on the methods of combining physics and data-driven approaches, and analyze the advantages of PIML in the aspects of accuracy and efficiency. Further, our survey discusses some current challenges and highlights future opportunities, including PIML on sea ice studies, PIML with different combination methods and backbone networks, and neural operator methods.
<div id='section'>Paperid: <span id='pid'>819, <a href='https://arxiv.org/pdf/2404.18384.pdf' target='_blank'>https://arxiv.org/pdf/2404.18384.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jordan Meadows, Tamsin James, Andre Freitas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.18384">Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Language models (LMs) can hallucinate when performing complex mathematical reasoning. Physics provides a rich domain for assessing their mathematical capabilities, where physical context requires that any symbolic manipulation satisfies complex semantics (\textit{e.g.,} units, tensorial order). In this work, we systematically remove crucial context from prompts to force instances where model inference may be algebraically coherent, yet unphysical. We assess LM capabilities in this domain using a curated dataset encompassing multiple notations and Physics subdomains. Further, we improve zero-shot scores using synthetic in-context examples, and demonstrate non-linear degradation of derivation quality with perturbation strength via the progressive omission of supporting premises. We find that the models' mathematical reasoning is not physics-informed in this setting, where physical context is predominantly ignored in favour of reverse-engineering solutions.
<div id='section'>Paperid: <span id='pid'>820, <a href='https://arxiv.org/pdf/2404.16980.pdf' target='_blank'>https://arxiv.org/pdf/2404.16980.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ulrich RÃ¶mer, Stefan Hartmann, Jendrik-Alexander TrÃ¶ger, David Anton, Henning Wessels, Moritz Flaschel, Laura De Lorenzis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.16980">Reduced and All-at-Once Approaches for Model Calibration and Discovery in Computational Solid Mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the framework of solid mechanics, the task of deriving material parameters from experimental data has recently re-emerged with the progress in full-field measurement capabilities and the renewed advances of machine learning. In this context, new methods such as the virtual fields method and physics-informed neural networks have been developed as alternatives to the already established least-squares and finite element-based approaches. Moreover, model discovery problems are starting to emerge and can also be addressed in a parameter estimation framework. These developments call for a new unified perspective, which is able to cover both traditional parameter estimation methods and novel approaches in which the state variables or the model structure itself are inferred as well. Adopting concepts discussed in the inverse problems community, we distinguish between all-at-once and reduced approaches. With this general framework, we are able to structure a large portion of the literature on parameter estimation in computational mechanics - and we can identify combinations that have not yet been addressed, two of which are proposed in this paper. We also discuss statistical approaches to quantify the uncertainty related to the estimated parameters, and we propose a novel two-step procedure for identification of complex material models based on both frequentist and Bayesian principles. Finally, we illustrate and compare several of the aforementioned methods with mechanical benchmarks based on synthetic and real data.
<div id='section'>Paperid: <span id='pid'>821, <a href='https://arxiv.org/pdf/2404.00074.pdf' target='_blank'>https://arxiv.org/pdf/2404.00074.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shahed Rezaei, Reza Najian Asl, Shirko Faroughi, Mahdi Asgharzadeh, Ali Harandi, Rasoul Najafi Koopas, Gottfried Laschet, Stefanie Reese, Markus Apel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00074">A finite operator learning technique for mapping the elastic properties of microstructures to their mechanical deformations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To obtain fast solutions for governing physical equations in solid mechanics, we introduce a method that integrates the core ideas of the finite element method with physics-informed neural networks and concept of neural operators. This approach generalizes and enhances each method, learning the parametric solution for mechanical problems without relying on data from other resources (e.g. other numerical solvers). We propose directly utilizing the available discretized weak form in finite element packages to construct the loss functions algebraically, thereby demonstrating the ability to find solutions even in the presence of sharp discontinuities. Our focus is on micromechanics as an example, where knowledge of deformation and stress fields for a given heterogeneous microstructure is crucial for further design applications. The primary parameter under investigation is the Young's modulus distribution within the heterogeneous solid system. Our investigations reveal that physics-based training yields higher accuracy compared to purely data-driven approaches for unseen microstructures. Additionally, we offer two methods to directly improve the process of obtaining high-resolution solutions, avoiding the need to use basic interpolation techniques. First is based on an autoencoder approach to enhance the efficiency for calculation on high resolution grid point. Next, Fourier-based parametrization is utilized to address complex 2D and 3D problems in micromechanics. The latter idea aims to represent complex microstructures efficiently using Fourier coefficients. Comparisons with other well-known operator learning algorithms, further emphasize the advantages of the newly proposed method.
<div id='section'>Paperid: <span id='pid'>822, <a href='https://arxiv.org/pdf/2403.06990.pdf' target='_blank'>https://arxiv.org/pdf/2403.06990.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stamatios Stamatatelopoulos, Shahroz Khan, Panagiotis Kaklis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.06990">Accelerating Dimensionality Reduction in Wave-Resistance Problems through Geometric Operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reducing the dimensionality and uncertainty of design spaces is a key prerequisite for shape optimisation in computationally intensive fluid problems. However, running these analyses at an offline stage itself poses a computationally demanding task. In this work, we propose a unique framework for the inexpensive implementation of sensitivity analyses for reducing the dimensionality of the design space in wave-resistance problems. At the heart of our approach is the formulation of a geometric operator that leverages, via high-order geometric moments, the underlying connection between geometry and physics, specifically the wave-resistance coefficient ($C_w$), of ships using the slender body theory based on the well-known Vossers' integral. The resulting geometric operator is computationally inexpensive yet physics-informed and can act as a geometry-based surrogate to drive parametric sensitivities. To analytically demonstrate the capability of the proposed approach, we use a well-known benchmark geometry, namely, the modified Wigley hull. Its simple analytical formulation allows for closed expressions of the geometric operators and exploration of computational domains that would otherwise be inaccessible. In this context, the proposed geometric operator outperforms existing similar approaches by achieving 100% similarity with $C_w$ at a fraction of the computational cost.
<div id='section'>Paperid: <span id='pid'>823, <a href='https://arxiv.org/pdf/2403.03459.pdf' target='_blank'>https://arxiv.org/pdf/2403.03459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanlai Chen, Yajie Ji, Akil Narayan, Zhenli Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.03459">TGPT-PINN: Nonlinear model reduction with transformed GPT-PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce the Transformed Generative Pre-Trained Physics-Informed Neural Networks (TGPT-PINN) for accomplishing nonlinear model order reduction (MOR) of transport-dominated partial differential equations in an MOR-integrating PINNs framework. Building on the recent development of the GPT-PINN that is a network-of-networks design achieving snapshot-based model reduction, we design and test a novel paradigm for nonlinear model reduction that can effectively tackle problems with parameter-dependent discontinuities. Through incorporation of a shock-capturing loss function component as well as a parameter-dependent transform layer, the TGPT-PINN overcomes the limitations of linear model reduction in the transport-dominated regime. We demonstrate this new capability for nonlinear model reduction in the PINNs framework by several nontrivial parametric partial differential equations.
<div id='section'>Paperid: <span id='pid'>824, <a href='https://arxiv.org/pdf/2403.02289.pdf' target='_blank'>https://arxiv.org/pdf/2403.02289.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonas Ekeland Kittelsen, Eric Aislan Antonelo, Eduardo Camponogara, Lars Struen Imsland
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.02289">Physics-Informed Neural Networks with Skip Connections for Modeling and Control of Gas-Lifted Oil Wells</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks, while powerful, often lack interpretability. Physics-Informed Neural Networks (PINNs) address this limitation by incorporating physics laws into the loss function, making them applicable to solving Ordinary Differential Equations (ODEs) and Partial Differential Equations (PDEs). The recently introduced PINC framework extends PINNs to control applications, allowing for open-ended long-range prediction and control of dynamic systems. In this work, we enhance PINC for modeling highly nonlinear systems such as gas-lifted oil wells. By introducing skip connections in the PINC network and refining certain terms in the ODE, we achieve more accurate gradients during training, resulting in an effective modeling process for the oil well system. Our proposed improved PINC demonstrates superior performance, reducing the validation prediction error by an average of 67% in the oil well application and significantly enhancing gradient flow through the network layers, increasing its magnitude by four orders of magnitude compared to the original PINC. Furthermore, experiments showcase the efficacy of Model Predictive Control (MPC) in regulating the bottom-hole pressure of the oil well using the improved PINC model, even in the presence of noisy measurements.
<div id='section'>Paperid: <span id='pid'>825, <a href='https://arxiv.org/pdf/2402.17966.pdf' target='_blank'>https://arxiv.org/pdf/2402.17966.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hira Saleem, Flora Salim, Cormac Purcell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17966">STC-ViT: Spatio Temporal Continuous Vision Transformer for Weather Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Operational weather forecasting system relies on computationally expensive physics-based models. Recently, transformer based models have shown remarkable potential in weather forecasting achieving state-of-the-art results. However, transformers are discrete and physics-agnostic models which limit their ability to learn the continuous spatio-temporal features of the dynamical weather system. We address this issue with STC-ViT, a Spatio-Temporal Continuous Vision Transformer for weather forecasting. STC-ViT incorporates the continuous time Neural ODE layers with multi-head attention mechanism to learn the continuous weather evolution over time. The attention mechanism is encoded as a differentiable function in the transformer architecture to model the complex weather dynamics. Further, we define a customised physics informed loss for STC-ViT which penalize the model's predictions for deviating away from physical laws. We evaluate STC-ViT against operational Numerical Weather Prediction (NWP) model and several deep learning based weather forecasting models. STC-ViT, trained on 1.5-degree 6-hourly data, demonstrates computational efficiency and competitive performance compared to state-of-the-art data-driven models trained on higher-resolution data for global forecasting.
<div id='section'>Paperid: <span id='pid'>826, <a href='https://arxiv.org/pdf/2402.16517.pdf' target='_blank'>https://arxiv.org/pdf/2402.16517.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matteo Caldana, Paola F. Antonietti, Luca Dede'
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.16517">Discovering Artificial Viscosity Models for Discontinuous Galerkin Approximation of Conservation Laws using Physics-Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Finite element-based high-order solvers of conservation laws offer large accuracy but face challenges near discontinuities due to the Gibbs phenomenon. Artificial viscosity is a popular and effective solution to this problem based on physical insight. In this work, we present a physics-informed machine learning algorithm to automate the discovery of artificial viscosity models in a non-supervised paradigm. The algorithm is inspired by reinforcement learning and trains a neural network acting cell-by-cell (the viscosity model) by minimizing a loss defined as the difference with respect to a reference solution thanks to automatic differentiation. This enables a dataset-free training procedure. We prove that the algorithm is effective by integrating it into a state-of-the-art Runge-Kutta discontinuous Galerkin solver. We showcase several numerical tests on scalar and vectorial problems, such as Burgers' and Euler's equations in one and two dimensions. Results demonstrate that the proposed approach trains a model that is able to outperform classical viscosity models. Moreover, we show that the learnt artificial viscosity model is able to generalize across different problems and parameters.
<div id='section'>Paperid: <span id='pid'>827, <a href='https://arxiv.org/pdf/2402.08540.pdf' target='_blank'>https://arxiv.org/pdf/2402.08540.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Usama, Zahid Masood, Shahroz Khan, Konstantinos Kostas, Panagiotis Kaklis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08540">Generative VS non-Generative Models in Engineering Shape Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we perform a systematic comparison of the effectiveness and efficiency of generative and non-generative models in constructing design spaces for novel and efficient design exploration and shape optimization. We apply these models in the case of airfoil/hydrofoil design and conduct the comparison on the resulting design spaces. A conventional Generative Adversarial Network (GAN) and a state-of-the-art generative model, the Performance-Augmented Diverse Generative Adversarial Network (PaDGAN), are juxtaposed with a linear non-generative model based on the coupling of the Karhunen-LoÃ¨ve Expansion and a physics-informed Shape Signature Vector (SSV-KLE). The comparison demonstrates that, with an appropriate shape encoding and a physics-augmented design space, non-generative models have the potential to cost-effectively generate high-performing valid designs with enhanced coverage of the design space. In this work, both approaches are applied to two large foil profile datasets comprising real-world and artificial designs generated through either a profile-generating parametric model or deep-learning approach. These datasets are further enriched with integral properties of their members' shapes as well as physics-informed parameters. Our results illustrate that the design spaces constructed by the non-generative model outperform the generative model in terms of design validity, generating robust latent spaces with none or significantly fewer invalid designs when compared to generative models. We aspire that these findings will aid the engineering design community in making informed decisions when constructing designs spaces for shape optimization, as we have show that under certain conditions computationally inexpensive approaches can closely match or even outperform state-of-the art generative models.
<div id='section'>Paperid: <span id='pid'>828, <a href='https://arxiv.org/pdf/2402.08367.pdf' target='_blank'>https://arxiv.org/pdf/2402.08367.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chengxi Zeng, Tilo Burghardt, Alberto M Gambaruto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08367">RBF-PINN: Non-Fourier Positional Embedding in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While many recent Physics-Informed Neural Networks (PINNs) variants have had considerable success in solving Partial Differential Equations, the empirical benefits of feature mapping drawn from the broader Neural Representations research have been largely overlooked. We highlight the limitations of widely used Fourier-based feature mapping in certain situations and suggest the use of the conditionally positive definite Radial Basis Function. The empirical findings demonstrate the effectiveness of our approach across a variety of forward and inverse problem cases. Our method can be seamlessly integrated into coordinate-based input neural networks and contribute to the wider field of PINNs research.
<div id='section'>Paperid: <span id='pid'>829, <a href='https://arxiv.org/pdf/2402.07084.pdf' target='_blank'>https://arxiv.org/pdf/2402.07084.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Philippe G. LeFloch, Jean-Marc Mercier, Shohruh Miryusupov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07084">Reproducing kernel methods for machine learning, PDEs, and statistics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This monograph develops a unified, application-driven framework for kernel methods grounded in reproducing kernel Hilbert spaces (RKHS) and optimal transport (OT). Part I lays the theoretical and numerical foundations on positive-definite kernels; discrete and continuous RKHS; kernel engineering and scaling maps; error assessment via kernel discrepancy/maximum mean discrepancy (MMD); and a systematic operator view of kernels. In this viewpoint, projection, gradient, divergence, and Laplace-Beltrami operators are built directly from kernels, enabling discrete analogues of differential operators and variational tools that connect learning with PDE-style modeling. Part II turns to practice across four domains. In machine learning, we treat supervised and unsupervised tasks, then develop RKHS-based generative modeling, contrasting density and projection approaches and enhancing them with OT and scalable, combinatorial assignments. We introduce clustering strategies that reduce computational burden and support large-scale regression and transport. In physics-informed modeling, we present mesh-free kernel discretizations for elliptic and time-dependent PDEs, discuss automatic differentiation, and propose high-order discrete approximations. In reinforcement learning, we formulate kernel Q-learning and non-parametric HJB methods, and show how kernel operators yield sample-efficient baselines on continuous-state, discrete-action tasks. In mathematical finance, we build nonparametric time-series models and market generators, study benchmarking and extrapolation for pricing, and apply the framework to stress testing and portfolio methods.
<div id='section'>Paperid: <span id='pid'>830, <a href='https://arxiv.org/pdf/2402.06955.pdf' target='_blank'>https://arxiv.org/pdf/2402.06955.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chengxi Zeng, Tilo Burghardt, Alberto M Gambaruto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06955">Feature Mapping in Physics-Informed Neural Networks (PINNs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, the training dynamics of PINNs with a feature mapping layer via the limiting Conjugate Kernel and Neural Tangent Kernel is investigated, shedding light on the convergence of PINNs; Although the commonly used Fourier-based feature mapping has achieved great success, we show its inadequacy in some physics scenarios. Via these two scopes, we propose conditionally positive definite Radial Basis Function as a better alternative. Lastly, we explore the feature mapping numerically in wide neural networks. Our empirical results reveal the efficacy of our method in diverse forward and inverse problem sets. Composing feature functions is found to be a practical way to address the expressivity and generalisability trade-off, viz., tuning the bandwidth of the kernels and the surjectivity of the feature mapping function. This simple technique can be implemented for coordinate inputs and benefits the broader PINNs research.
<div id='section'>Paperid: <span id='pid'>831, <a href='https://arxiv.org/pdf/2402.03349.pdf' target='_blank'>https://arxiv.org/pdf/2402.03349.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdenour Hadid, Tanujit Chakraborty, Daniel Busby
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03349">When Geoscience Meets Generative AI and Large Language Models: Foundations, Trends, and Future Challenges</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative Artificial Intelligence (GAI) represents an emerging field that promises the creation of synthetic data and outputs in different modalities. GAI has recently shown impressive results across a large spectrum of applications ranging from biology, medicine, education, legislation, computer science, and finance. As one strives for enhanced safety, efficiency, and sustainability, generative AI indeed emerges as a key differentiator and promises a paradigm shift in the field. This paper explores the potential applications of generative AI and large language models in geoscience. The recent developments in the field of machine learning and deep learning have enabled the generative model's utility for tackling diverse prediction problems, simulation, and multi-criteria decision-making challenges related to geoscience and Earth system dynamics. This survey discusses several GAI models that have been used in geoscience comprising generative adversarial networks (GANs), physics-informed neural networks (PINNs), and generative pre-trained transformer (GPT)-based structures. These tools have helped the geoscience community in several applications, including (but not limited to) data generation/augmentation, super-resolution, panchromatic sharpening, haze removal, restoration, and land surface changing. Some challenges still remain such as ensuring physical interpretation, nefarious use cases, and trustworthiness. Beyond that, GAI models show promises to the geoscience community, especially with the support to climate change, urban science, atmospheric science, marine science, and planetary science through their extraordinary ability to data-driven modeling and uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>832, <a href='https://arxiv.org/pdf/2402.03243.pdf' target='_blank'>https://arxiv.org/pdf/2402.03243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dat Phan-Trong, Hung The Tran, Alistair Shilton, Sunil Gupta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03243">PINN-BO: A Black-box Optimization Algorithm using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Black-box optimization is a powerful approach for discovering global optima in noisy and expensive black-box functions, a problem widely encountered in real-world scenarios. Recently, there has been a growing interest in leveraging domain knowledge to enhance the efficacy of machine learning methods. Partial Differential Equations (PDEs) often provide an effective means for elucidating the fundamental principles governing the black-box functions. In this paper, we propose PINN-BO, a black-box optimization algorithm employing Physics-Informed Neural Networks that integrates the knowledge from Partial Differential Equations (PDEs) to improve the sample efficiency of the optimization. We analyze the theoretical behavior of our algorithm in terms of regret bound using advances in NTK theory and prove that the use of the PDE alongside the black-box function evaluations, PINN-BO leads to a tighter regret bound. We perform several experiments on a variety of optimization tasks and show that our algorithm is more sample-efficient compared to existing methods.
<div id='section'>Paperid: <span id='pid'>833, <a href='https://arxiv.org/pdf/2401.16327.pdf' target='_blank'>https://arxiv.org/pdf/2401.16327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cooper Lorsung, Amir Barati Farimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.16327">PICL: Physics Informed Contrastive Learning for Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural operators have recently grown in popularity as Partial Differential Equation (PDE) surrogate models. Learning solution functionals, rather than functions, has proven to be a powerful approach to calculate fast, accurate solutions to complex PDEs. While much work has been done evaluating neural operator performance on a wide variety of surrogate modeling tasks, these works normally evaluate performance on a single equation at a time. In this work, we develop a novel contrastive pretraining framework utilizing Generalized Contrastive Loss that improves neural operator generalization across multiple governing equations simultaneously. Governing equation coefficients are used to measure ground-truth similarity between systems. A combination of physics-informed system evolution and latent-space model output are anchored to input data and used in our distance function. We find that physics-informed contrastive pretraining improves accuracy for the Fourier Neural Operator in fixed-future and autoregressive rollout tasks for the 1D and 2D Heat, Burgers', and linear advection equations.
<div id='section'>Paperid: <span id='pid'>834, <a href='https://arxiv.org/pdf/2401.13486.pdf' target='_blank'>https://arxiv.org/pdf/2401.13486.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vasiliy A. Es'kin, Danil V. Davydov, Julia V. Gur'eva, Alexey O. Malkhanov, Mikhail E. Smorkalov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.13486">Separable Physics-Informed Neural Networks for the solution of elasticity problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A method for solving elasticity problems based on separable physics-informed neural networks (SPINN) in conjunction with the deep energy method (DEM) is presented. Numerical experiments have been carried out for a number of problems showing that this method has a significantly higher convergence rate and accuracy than the vanilla physics-informed neural networks (PINN) and even SPINN based on a system of partial differential equations (PDEs). In addition, using the SPINN in the framework of DEM approach it is possible to solve problems of the linear theory of elasticity on complex geometries, which is unachievable with the help of PINNs in frames of partial differential equations. Considered problems are very close to the industrial problems in terms of geometry, loading, and material parameters.
<div id='section'>Paperid: <span id='pid'>835, <a href='https://arxiv.org/pdf/2401.06196.pdf' target='_blank'>https://arxiv.org/pdf/2401.06196.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiahao Song, Wenbo Cao, Fei Liao, Weiwei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.06196">VW-PINNs: A volume weighting method for PDE residuals in physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have shown remarkable prospects in the solving the forward and inverse problems involving partial differential equations (PDEs). The method embeds PDEs into the neural network by calculating PDE loss at a series of collocation points, providing advantages such as meshfree and more convenient adaptive sampling. However, when solving PDEs using nonuniform collocation points, PINNs still face challenge regarding inefficient convergence of PDE residuals or even failure. In this work, we first analyze the ill-conditioning of the PDE loss in PINNs under nonuniform collocation points. To address the issue, we define volume-weighted residual and propose volume-weighted physics-informed neural networks (VW-PINNs). Through weighting the PDE residuals by the volume that the collocation points occupy within the computational domain, we embed explicitly the spatial distribution characteristics of collocation points in the residual evaluation. The fast and sufficient convergence of the PDE residuals for the problems involving nonuniform collocation points is guaranteed. Considering the meshfree characteristics of VW-PINNs, we also develop a volume approximation algorithm based on kernel density estimation to calculate the volume of the collocation points. We verify the universality of VW-PINNs by solving the forward problems involving flow over a circular cylinder and flow over the NACA0012 airfoil under different inflow conditions, where conventional PINNs fail; By solving the Burgers' equation, we verify that VW-PINNs can enhance the efficiency of existing the adaptive sampling method in solving the forward problem by 3 times, and can reduce the relative error of conventional PINNs in solving the inverse problem by more than one order of magnitude.
<div id='section'>Paperid: <span id='pid'>836, <a href='https://arxiv.org/pdf/2401.02363.pdf' target='_blank'>https://arxiv.org/pdf/2401.02363.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shahed Rezaei, Ahmad Moeineddin, Michael Kaliske, Markus Apel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02363">Integration of physics-informed operator learning and finite element method for parametric learning of partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a method that employs physics-informed deep learning techniques for parametrically solving partial differential equations. The focus is on the steady-state heat equations within heterogeneous solids exhibiting significant phase contrast. Similar equations manifest in diverse applications like chemical diffusion, electrostatics, and Darcy flow. The neural network aims to establish the link between the complex thermal conductivity profiles and temperature distributions, as well as heat flux components within the microstructure, under fixed boundary conditions. A distinctive aspect is our independence from classical solvers like finite element methods for data. A noteworthy contribution lies in our novel approach to defining the loss function, based on the discretized weak form of the governing equation. This not only reduces the required order of derivatives but also eliminates the need for automatic differentiation in the construction of loss terms, accepting potential numerical errors from the chosen discretization method. As a result, the loss function in this work is an algebraic equation that significantly enhances training efficiency. We benchmark our methodology against the standard finite element method, demonstrating accurate yet faster predictions using the trained neural network for temperature and flux profiles. We also show higher accuracy by using the proposed method compared to purely data-driven approaches for unforeseen scenarios.
<div id='section'>Paperid: <span id='pid'>837, <a href='https://arxiv.org/pdf/2401.02300.pdf' target='_blank'>https://arxiv.org/pdf/2401.02300.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcin ÅoÅ, Tomasz SÅuÅ¼alec, PaweÅ Maczuga, Askold Vilkha, Carlos Uriarte, Maciej PaszyÅski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02300">Collocation-based Robust Variational Physics-Informed Neural Networks (CRVPINN)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have been successfully applied to solve Partial Differential Equations (PDEs). Their loss function is founded on a strong residual minimization scheme. Variational Physics-Informed Neural Networks (VPINNs) are their natural extension to weak variational settings. In this context, the recent work of Robust Variational Physics-Informed Neural Networks (RVPINNs) highlights the importance of conveniently translating the norms of the underlying continuum-level spaces to the discrete level. Otherwise, VPINNs might become unrobust, implying that residual minimization might be highly uncorrelated with a desired minimization of the error in the energy norm. However, applying this robustness to VPINNs typically entails dealing with the inverse of a Gram matrix, usually producing slow convergence speeds during training. In this work, we accelerate the implementation of RVPINN, establishing a LU factorization of sparse Gram matrix in a kind of point-collocation scheme with the same spirit as original PINNs. We call out method the Collocation-based Robust Variational Physics Informed Neural Networks (CRVPINN). We test our efficient CRVPINN algorithm on Laplace, advection-diffusion, and Stokes problems in two spatial dimensions.
<div id='section'>Paperid: <span id='pid'>838, <a href='https://arxiv.org/pdf/2401.00670.pdf' target='_blank'>https://arxiv.org/pdf/2401.00670.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>SebastiÃ¡n Espinel-RÃ­os, JosÃ© L. Avalos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00670">Hybrid physics-informed metabolic cybergenetics: process rates augmented with machine-learning surrogates informed by flux balance analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Metabolic cybergenetics is a promising concept that interfaces gene expression and cellular metabolism with computers for real-time dynamic metabolic control. The focus is on control at the transcriptional level, serving as a means to modulate intracellular metabolic fluxes. Recent strategies in this field have employed constraint-based dynamic models for process optimization, control, and estimation. However, this results in bilevel dynamic optimization problems, which pose considerable numerical and conceptual challenges. In this study, we present an alternative hybrid physics-informed dynamic modeling framework for metabolic cybergenetics, aimed at simplifying optimization, control, and estimation tasks. By utilizing machine-learning surrogates, our approach effectively embeds the physics of metabolic networks into the process rates of structurally simpler macro-kinetic models coupled with gene expression. These surrogates, informed by flux balance analysis, link the domains of manipulatable intracellular enzymes to metabolic exchange fluxes. This ensures that critical knowledge captured by the system's metabolic network is preserved. The resulting models can be integrated into metabolic cybergenetic schemes involving single-level optimizations. Additionally, the hybrid modeling approach maintains the number of system states at a necessary minimum, easing the burden of process monitoring and estimation. Our hybrid physics-informed metabolic cybergenetic framework is demonstrated using a computational case study on the optogenetically-assisted production of itaconate by $\textit{Escherichia coli}$.
<div id='section'>Paperid: <span id='pid'>839, <a href='https://arxiv.org/pdf/2312.06993.pdf' target='_blank'>https://arxiv.org/pdf/2312.06993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jichao Yin, Ziming Wen, Shuhao Li, Yaya Zhanga, Hu Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.06993">Dynamically configured physics-informed neural network in topology optimization applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Integration of machine learning (ML) into the topology optimization (TO) framework is attracting increasing attention, but data acquisition in data-driven models is prohibitive. Compared with popular ML methods, the physics-informed neural network (PINN) can avoid generating enormous amounts of data when solving forward problems and additionally provide better inference. To this end, a dynamically configured PINN-based topology optimization (DCPINN-TO) method is proposed. The DCPINN is composed of two subnetworks, namely the backbone neural network (NN) and the coefficient NN, where the coefficient NN has fewer trainable parameters. The designed architecture aims to dynamically configure trainable parameters; that is, an inexpensive NN is used to replace an expensive one at certain optimization cycles. Furthermore, an active sampling strategy is proposed to selectively sample collocations depending on the pseudo-densities at each optimization cycle. In this manner, the number of collocations will decrease with the optimization process but will hardly affect it. The Gaussian integral is used to calculate the strain energy of elements, which yields a byproduct of decoupling the mapping of the material at the collocations. Several examples with different resolutions validate the feasibility of the DCPINN-TO method, and multiload and multiconstraint problems are employed to illustrate its generalization. In addition, compared to finite element analysis-based TO (FEA-TO), the accuracy of the displacement prediction and optimization results indicate that the DCPINN-TO method is effective and efficient.
<div id='section'>Paperid: <span id='pid'>840, <a href='https://arxiv.org/pdf/2311.13885.pdf' target='_blank'>https://arxiv.org/pdf/2311.13885.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ritam Majumdar, Amey Varhade, Shirish Karande, Lovekesh Vig
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13885">Can Physics Informed Neural Operators Self Improve?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-training techniques have shown remarkable value across many deep learning models and tasks. However, such techniques remain largely unexplored when considered in the context of learning fast solvers for systems of partial differential equations (Eg: Neural Operators). In this work, we explore the use of self-training for Fourier Neural Operators (FNO). Neural Operators emerged as a data driven technique, however, data from experiments or traditional solvers is not always readily available. Physics Informed Neural Operators (PINO) overcome this constraint by utilizing a physics loss for the training, however the accuracy of PINO trained without data does not match the performance obtained by training with data. In this work we show that self-training can be used to close this gap in performance. We examine canonical examples, namely the 1D-Burgers and 2D-Darcy PDEs, to showcase the efficacy of self-training. Specifically, FNOs, when trained exclusively with physics loss through self-training, approach 1.07x for Burgers and 1.02x for Darcy, compared to FNOs trained with both data and physics loss. Furthermore, we discover that pseudo-labels can be used for self-training without necessarily training to convergence in each iteration. A consequence of this is that we are able to discover self-training schedules that improve upon the baseline performance of PINO in terms of accuracy as well as time.
<div id='section'>Paperid: <span id='pid'>841, <a href='https://arxiv.org/pdf/2311.11228.pdf' target='_blank'>https://arxiv.org/pdf/2311.11228.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuo Zhang, Yang Liu, Lei Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.11228">A Universal Framework for Accurate and Efficient Geometric Deep Learning of Molecular Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Molecular sciences address a wide range of problems involving molecules of different types and sizes and their complexes. Recently, geometric deep learning, especially Graph Neural Networks, has shown promising performance in molecular science applications. However, most existing works often impose targeted inductive biases to a specific molecular system, and are inefficient when applied to macromolecules or large-scale tasks, thereby limiting their applications to many real-world problems. To address these challenges, we present PAMNet, a universal framework for accurately and efficiently learning the representations of three-dimensional (3D) molecules of varying sizes and types in any molecular system. Inspired by molecular mechanics, PAMNet induces a physics-informed bias to explicitly model local and non-local interactions and their combined effects. As a result, PAMNet can reduce expensive operations, making it time and memory efficient. In extensive benchmark studies, PAMNet outperforms state-of-the-art baselines regarding both accuracy and efficiency in three diverse learning tasks: small molecule properties, RNA 3D structures, and protein-ligand binding affinities. Our results highlight the potential for PAMNet in a broad range of molecular science applications.
<div id='section'>Paperid: <span id='pid'>842, <a href='https://arxiv.org/pdf/2311.07002.pdf' target='_blank'>https://arxiv.org/pdf/2311.07002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vikas Dwivedi, Balaji Srinivasan, Ganapathy Krishnamurthi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.07002">PICS in Pics: Physics Informed Contour Selection for Rapid Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Effective training of deep image segmentation models is challenging due to the need for abundant, high-quality annotations. Generating annotations is laborious and time-consuming for human experts, especially in medical image segmentation. To facilitate image annotation, we introduce Physics Informed Contour Selection (PICS) - an interpretable, physics-informed algorithm for rapid image segmentation without relying on labeled data. PICS draws inspiration from physics-informed neural networks (PINNs) and an active contour model called snake. It is fast and computationally lightweight because it employs cubic splines instead of a deep neural network as a basis function. Its training parameters are physically interpretable because they directly represent control knots of the segmentation curve. Traditional snakes involve minimization of the edge-based loss functionals by deriving the Euler-Lagrange equation followed by its numerical solution. However, PICS directly minimizes the loss functional, bypassing the Euler Lagrange equations. It is the first snake variant to minimize a region-based loss function instead of traditional edge-based loss functions. PICS uniquely models the three-dimensional (3D) segmentation process with an unsteady partial differential equation (PDE), which allows accelerated segmentation via transfer learning. To demonstrate its effectiveness, we apply PICS for 3D segmentation of the left ventricle on a publicly available cardiac dataset. While doing so, we also introduce a new convexity-preserving loss term that encodes the shape information of the left ventricle to enhance PICS's segmentation quality. Overall, PICS presents several novelties in network architecture, transfer learning, and physics-inspired losses for image segmentation, thereby showing promising outcomes and potential for further refinement.
<div id='section'>Paperid: <span id='pid'>843, <a href='https://arxiv.org/pdf/2311.04293.pdf' target='_blank'>https://arxiv.org/pdf/2311.04293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tara Akhound-Sadegh, Laurence Perreault-Levasseur, Johannes Brandstetter, Max Welling, Siamak Ravanbakhsh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.04293">Lie Point Symmetry and Physics Informed Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Symmetries have been leveraged to improve the generalization of neural networks through different mechanisms from data augmentation to equivariant architectures. However, despite their potential, their integration into neural solvers for partial differential equations (PDEs) remains largely unexplored. We explore the integration of PDE symmetries, known as Lie point symmetries, in a major family of neural solvers known as physics-informed neural networks (PINNs). We propose a loss function that informs the network about Lie point symmetries in the same way that PINN models try to enforce the underlying PDE through a loss function. Intuitively, our symmetry loss ensures that the infinitesimal generators of the Lie group conserve the PDE solutions. Effectively, this means that once the network learns a solution, it also learns the neighbouring solutions generated by Lie point symmetries. Empirical evaluations indicate that the inductive bias introduced by the Lie point symmetries of the PDEs greatly boosts the sample efficiency of PINNs.
<div id='section'>Paperid: <span id='pid'>844, <a href='https://arxiv.org/pdf/2310.19590.pdf' target='_blank'>https://arxiv.org/pdf/2310.19590.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bin Lin, Zhiping Mao, Zhicheng Wang, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19590">Operator Learning Enhanced Physics-informed Neural Networks for Solving Partial Differential Equations Characterized by Sharp Solutions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Neural Networks (PINNs) have been shown as a promising approach for solving both forward and inverse problems of partial differential equations (PDEs). Meanwhile, the neural operator approach, including methods such as Deep Operator Network (DeepONet) and Fourier neural operator (FNO), has been introduced and extensively employed in approximating solution of PDEs. Nevertheless, to solve problems consisting of sharp solutions poses a significant challenge when employing these two approaches. To address this issue, we propose in this work a novel framework termed Operator Learning Enhanced Physics-informed Neural Networks (OL-PINN). Initially, we utilize DeepONet to learn the solution operator for a set of smooth problems relevant to the PDEs characterized by sharp solutions. Subsequently, we integrate the pre-trained DeepONet with PINN to resolve the target sharp solution problem. We showcase the efficacy of OL-PINN by successfully addressing various problems, such as the nonlinear diffusion-reaction equation, the Burgers equation and the incompressible Navier-Stokes equation at high Reynolds number. Compared with the vanilla PINN, the proposed method requires only a small number of residual points to achieve a strong generalization capability. Moreover, it substantially enhances accuracy, while also ensuring a robust training process. Furthermore, OL-PINN inherits the advantage of PINN for solving inverse problems. To this end, we apply the OL-PINN approach for solving problems with only partial boundary conditions, which usually cannot be solved by the classical numerical methods, showing its capacity in solving ill-posed problems and consequently more complex inverse problems.
<div id='section'>Paperid: <span id='pid'>845, <a href='https://arxiv.org/pdf/2310.18201.pdf' target='_blank'>https://arxiv.org/pdf/2310.18201.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Luo, Qixuan Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18201">On Residual Minimization for PDEs: Failure of PINN, Modified Equation, and Implicit Bias</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a popular and easy-to-implement machine learning method for solving differential equations, the physics-informed neural network (PINN) sometimes may fail and find poor solutions which bias against the exact ones. In this paper, we establish a framework of modified equation to explain the failure phenomenon and characterize the implicit bias of a general residual minimization (RM) method. We provide a simple way to derive the modified equation which models the numerical solution obtained by RM methods. Next, we show the modified solution deviates from the original exact solution. The proof uses a by-product of this paper, that is, a necessary and sufficient condition on characterizing the singularity of the coefficients. This equivalent condition can be extended to other types of equations in the future. Finally, we prove, as a complete characterization of the implicit bias, that RM method implicitly biases the numerical solution against the exact solution and towards a modified solution. In this work, we focus on elliptic equations with discontinuous coefficients, but our approach can be extended to other types of equations and our understanding of the implicit bias may shed light on further development of deep learning based methods for solving equations.
<div id='section'>Paperid: <span id='pid'>846, <a href='https://arxiv.org/pdf/2310.16491.pdf' target='_blank'>https://arxiv.org/pdf/2310.16491.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenbo Cao, Weiwei Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.16491">TSONN: Time-stepping-oriented neural network for solving partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs), especially physics-informed neural networks (PINNs), have recently become a new popular method for solving forward and inverse problems governed by partial differential equations (PDEs). However, these methods still face challenges in achieving stable training and obtaining correct results in many problems, since minimizing PDE residuals with PDE-based soft constraint make the problem ill-conditioned. Different from all existing methods that directly minimize PDE residuals, this work integrates time-stepping method with deep learning, and transforms the original ill-conditioned optimization problem into a series of well-conditioned sub-problems over given pseudo time intervals. The convergence of model training is significantly improved by following the trajectory of the pseudo time-stepping process, yielding a robust optimization-based PDE solver. Our results show that the proposed method achieves stable training and correct results in many problems that standard PINNs fail to solve, requiring only a simple modification on the loss function. In addition, we demonstrate several novel properties and advantages of time-stepping methods within the framework of neural network-based optimization approach, in comparison to traditional grid-based numerical method. Specifically, explicit scheme allows significantly larger time step, while implicit scheme can be implemented as straightforwardly as explicit scheme.
<div id='section'>Paperid: <span id='pid'>847, <a href='https://arxiv.org/pdf/2310.13947.pdf' target='_blank'>https://arxiv.org/pdf/2310.13947.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xi'an Li, Jinran Wu, Yujia Huang, Zhe Ding, Xin Tai, Liang Liu, You-Gan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.13947">Augmented physics informed extreme learning machine to solve the biharmonic equations via Fourier expansions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To address the sensitivity of parameters and limited precision for physics-informed extreme learning machines (PIELM) with common activation functions, such as sigmoid, tangent, and Gaussian, in solving high-order partial differential equations (PDEs) relevant to scientific computation and engineering applications, this work develops a Fourier-induced PIELM (FPIELM) method. This approach aims to approximate solutions for a class of fourth-order biharmonic equations with two boundary conditions on both unitized and non-unitized domains. By carefully calculating the differential and boundary operators of the biharmonic equation on discretized collections, the solution for this high-order equation is reformulated as a linear least squares minimization problem. We further evaluate the FPIELM with varying hidden nodes and scaling factors for uniform distribution initialization, and then determine the optimal range for these two hyperparameters. Numerical experiments and comparative analyses demonstrate that the proposed FPIELM method is more stable, robust, precise, and efficient than other PIELM approaches in solving biharmonic equations across both regular and irregular domains.
<div id='section'>Paperid: <span id='pid'>848, <a href='https://arxiv.org/pdf/2310.06948.pdf' target='_blank'>https://arxiv.org/pdf/2310.06948.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Navid Aftabi, Dan Li, Paritosh Ramanan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06948">A Variational Autoencoder Framework for Robust, Physics-Informed Cyberattack Recognition in Industrial Cyber-Physical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cybersecurity of Industrial Cyber-Physical Systems is drawing significant concerns as data communication increasingly leverages wireless networks. A lot of data-driven methods were develope for detecting cyberattacks, but few are focused on distinguishing them from equipment faults. In this paper, we develop a data-driven framework that can be used to detect, diagnose, and localize a type of cyberattack called covert attacks on networked industrial control systems. The framework has a hybrid design that combines a variational autoencoder (VAE), a recurrent neural network (RNN), and a Deep Neural Network (DNN). This data-driven framework considers the temporal behavior of a generic physical system that extracts features from the time series of the sensor measurements that can be used for detecting covert attacks, distinguishing them from equipment faults, as well as localize the attack/fault. We evaluate the performance of the proposed method through a realistic simulation study on a networked power transmission system as a typical example of ICS. We compare the performance of the proposed method with the traditional model-based method to show its applicability and efficacy.
<div id='section'>Paperid: <span id='pid'>849, <a href='https://arxiv.org/pdf/2310.03755.pdf' target='_blank'>https://arxiv.org/pdf/2310.03755.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>PaweÅ Maczuga, Maciej Sikora, Maciej SkoczeÅ, PrzemysÅaw RoÅ¼nawski, Filip TÅuszcz, Marcin Szubert, Marcin ÅoÅ, Witold Dzwinel, Keshav Pingali, Maciej PaszyÅski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03755">Physics Informed Neural Network Code for 2D Transient Problems (PINN-2DT) Compatible with Google Colab</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present an open-source Physics Informed Neural Network environment for simulations of transient phenomena on two-dimensional rectangular domains, with the following features: (1) it is compatible with Google Colab which allows automatic execution on cloud environment; (2) it supports two dimensional time-dependent PDEs; (3) it provides simple interface for definition of the residual loss, boundary condition and initial loss, together with their weights; (4) it support Neumann and Dirichlet boundary conditions; (5) it allows for customizing the number of layers and neurons per layer, as well as for arbitrary activation function; (6) the learning rate and number of epochs are available as parameters; (7) it automatically differentiates PINN with respect to spatial and temporal variables; (8) it provides routines for plotting the convergence (with running average), initial conditions learnt, 2D and 3D snapshots from the simulation and movies (9) it includes a library of problems: (a) non-stationary heat transfer; (b) wave equation modeling a tsunami; (c) atmospheric simulations including thermal inversion; (d) tumor growth simulations.
<div id='section'>Paperid: <span id='pid'>850, <a href='https://arxiv.org/pdf/2310.02276.pdf' target='_blank'>https://arxiv.org/pdf/2310.02276.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jin Song, Zhenya Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02276">Deep learning soliton dynamics and complex potentials recognition for 1D and 2D PT-symmetric saturable nonlinear SchrÃ¶dinger equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we firstly extend the physics-informed neural networks (PINNs) to learn data-driven stationary and non-stationary solitons of 1D and 2D saturable nonlinear SchrÃ¶dinger equations (SNLSEs) with two fundamental PT-symmetric Scarf-II and periodic potentials in optical fibers. Secondly, the data-driven inverse problems are studied for PT-symmetric potential functions discovery rather than just potential parameters in the 1D and 2D SNLSEs. Particularly, we propose a modified PINNs (mPINNs) scheme to identify directly the PT potential functions of the 1D and 2D SNLSEs by the solution data. And the inverse problems about 1D and 2D PT -symmetric potentials depending on propagation distance z are also investigated using mPINNs method. We also identify the potential functions by the PINNs applied to the stationary equation of the SNLSE. Furthermore, two network structures are compared under different parameter conditions such that the predicted PT potentials can achieve the similar high accuracy. These results illustrate that the established deep neural networks can be successfully used in 1D and 2D SNLSEs with high accuracies. Moreover, some main factors affecting neural networks performance are discussed in 1D and 2D PT Scarf-II and periodic potentials, including activation functions, structures of the networks, and sizes of the training data. In particular, twelve different nonlinear activation functions are in detail analyzed containing the periodic and non-periodic functions such that it is concluded that selecting activation functions according to the form of solution and equation usually can achieve better effect.
<div id='section'>Paperid: <span id='pid'>851, <a href='https://arxiv.org/pdf/2309.17240.pdf' target='_blank'>https://arxiv.org/pdf/2309.17240.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junchao Chen, Jin Song, Zijian Zhou, Zhenya Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.17240">Data-driven localized waves and parameter discovery in the massive Thirring model via extended physics-informed neural networks with interface zones</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we study data-driven localized wave solutions and parameter discovery in the massive Thirring (MT) model via the deep learning in the framework of physics-informed neural networks (PINNs) algorithm. Abundant data-driven solutions including soliton of bright/dark type, breather and rogue wave are simulated accurately and analyzed contrastively with relative and absolute errors. For higher-order localized wave solutions, we employ the extended PINNs (XPINNs) with domain decomposition to capture the complete pictures of dynamic behaviors such as soliton collisions, breather oscillations and rogue-wave superposition. In particular, we modify the interface line in domain decomposition of XPINNs into a small interface zone and introduce the pseudo initial, residual and gradient conditions as interface conditions linked adjacently with individual neural networks. Then this modified approach is applied successfully to various solutions ranging from bright-bright soliton, dark-dark soliton, dark-antidark soliton, general breather, Kuznetsov-Ma breather and second-order rogue wave. Experimental results show that this improved version of XPINNs reduce the complexity of computation with faster convergence rate and keep the quality of learned solutions with smoother stitching performance as well. For the inverse problems, the unknown coefficient parameters of linear and nonlinear terms in the MT model are identified accurately with and without noise by using the classical PINNs algorithm.
<div id='section'>Paperid: <span id='pid'>852, <a href='https://arxiv.org/pdf/2309.11875.pdf' target='_blank'>https://arxiv.org/pdf/2309.11875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gledson Rodrigo Tondo, Sebastian Rau, Igor Kavrakov, Guido Morgenthal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.11875">Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models trained with structural health monitoring data have become a powerful tool for system identification. This paper presents a physics-informed Gaussian process (GP) model for Timoshenko beam elements. The model is constructed as a multi-output GP with covariance and cross-covariance kernels analytically derived based on the differential equations for deflections, rotations, strains, bending moments, shear forces and applied loads. Stiffness identification is performed in a Bayesian format by maximising a posterior model through a Markov chain Monte Carlo method, yielding a stochastic model for the structural parameters. The optimised GP model is further employed for probabilistic predictions of unobserved responses. Additionally, an entropy-based method for physics-informed sensor placement optimisation is presented, exploiting heterogeneous sensor position information and structural boundary conditions built into the GP model. Results demonstrate that the proposed approach is effective at identifying structural parameters and is capable of fusing data from heterogeneous and multi-fidelity sensors. Probabilistic predictions of structural responses and internal forces are in closer agreement with measured data. We validate our model with an experimental setup and discuss the quality and uncertainty of the obtained results. The proposed approach has potential applications in the field of structural health monitoring (SHM) for both mechanical and structural systems.
<div id='section'>Paperid: <span id='pid'>853, <a href='https://arxiv.org/pdf/2309.10605.pdf' target='_blank'>https://arxiv.org/pdf/2309.10605.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yile Angela Zhang, Fei Ma, Thushara Abhayapala, Prasanga Samarasinghe, Amy Bastine
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.10605">An Active Noise Control System Based on Soundfield Interpolation Using a Physics-informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conventional multiple-point active noise control (ANC) systems require placing error microphones within the region of interest (ROI), inconveniencing users. This paper designs a feasible monitoring microphone arrangement placed outside the ROI, providing a user with more freedom of movement. The soundfield within the ROI is interpolated from the microphone signals using a physics-informed neural network (PINN). PINN exploits the acoustic wave equation to assist soundfield interpolation under a limited number of monitoring microphones, and demonstrates better interpolation performance than the spherical harmonic method in simulations. An ANC system is designed to take advantage of the interpolated signal to reduce noise signal within the ROI. The PINN-assisted ANC system reduces noise more than that of the multiple-point ANC system in simulations.
<div id='section'>Paperid: <span id='pid'>854, <a href='https://arxiv.org/pdf/2309.09007.pdf' target='_blank'>https://arxiv.org/pdf/2309.09007.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruslan Agishev, Karel Zimmermann, VladimÃ­r Kubelka, Martin Pecka, TomÃ¡Å¡ Svoboda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.09007">MonoForce: Self-supervised Learning of Physics-informed Model for Predicting Robot-terrain Interaction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While autonomous navigation of mobile robots on rigid terrain is a well-explored problem, navigating on deformable terrain such as tall grass or bushes remains a challenge. To address it, we introduce an explainable, physics-aware and end-to-end differentiable model which predicts the outcome of robot-terrain interaction from camera images, both on rigid and non-rigid terrain. The proposed MonoForce model consists of a black-box module which predicts robot-terrain interaction forces from onboard cameras, followed by a white-box module, which transforms these forces and a control signals into predicted trajectories, using only the laws of classical mechanics. The differentiable white-box module allows backpropagating the predicted trajectory errors into the black-box module, serving as a self-supervised loss that measures consistency between the predicted forces and ground-truth trajectories of the robot. Experimental evaluation on a public dataset and our data has shown that while the prediction capabilities are comparable to state-of-the-art algorithms on rigid terrain, MonoForce shows superior accuracy on non-rigid terrain such as tall grass or bushes. To facilitate the reproducibility of our results, we release both the code and datasets.
<div id='section'>Paperid: <span id='pid'>855, <a href='https://arxiv.org/pdf/2309.07899.pdf' target='_blank'>https://arxiv.org/pdf/2309.07899.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>RÃ¼diger Brecht, Dmytro R. Popovych, Alex Bihlo, Roman O. Popovych
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.07899">Improving physics-informed DeepONets with hard constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current physics-informed (standard or deep operator) neural networks still rely on accurately learning the initial and/or boundary conditions of the system of differential equations they are solving. In contrast, standard numerical methods involve such conditions in computations without needing to learn them. In this study, we propose to improve current physics-informed deep learning strategies such that initial and/or boundary conditions do not need to be learned and are represented exactly in the predicted solution. Moreover, this method guarantees that when a deep operator network is applied multiple times to time-step a solution of an initial value problem, the resulting function is at least continuous.
<div id='section'>Paperid: <span id='pid'>856, <a href='https://arxiv.org/pdf/2309.00767.pdf' target='_blank'>https://arxiv.org/pdf/2309.00767.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenqian Chen, Peiyuan Gao, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.00767">Physics-informed machine learning of the correlation functions in bulk fluids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Ornstein-Zernike (OZ) equation is the fundamental equation for pair correlation function computations in the modern integral equation theory for liquids. In this work, machine learning models, notably physics-informed neural networks and physics-informed neural operator networks, are explored to solve the OZ equation. The physics-informed machine learning models demonstrate great accuracy and high efficiency in solving the forward and inverse OZ problems of various bulk fluids. The results highlight the significant potential of physics-informed machine learning for applications in thermodynamic state theory.
<div id='section'>Paperid: <span id='pid'>857, <a href='https://arxiv.org/pdf/2308.10038.pdf' target='_blank'>https://arxiv.org/pdf/2308.10038.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazunari Wada, Katsuyuki Suzuki, Kazuo Yonekura
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10038">Physics-guided training of GAN to improve accuracy in airfoil design synthesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative adversarial networks (GAN) have recently been used for a design synthesis of mechanical shapes. A GAN sometimes outputs physically unreasonable shapes. For example, when a GAN model is trained to output airfoil shapes that indicate required aerodynamic performance, significant errors occur in the performance values. This is because the GAN model only considers data but does not consider the aerodynamic equations that lie under the data. This paper proposes the physics-guided training of the GAN model to guide the model to learn physical validity. Physical validity is computed using general-purpose software located outside the neural network model. Such general-purpose software cannot be used in physics-informed neural network frameworks, because physical equations must be implemented inside the neural network models. Additionally, a limitation of generative models is that the output data are similar to the training data and cannot generate completely new shapes. However, because the proposed model is guided by a physical model and does not use a training dataset, it can generate completely new shapes. Numerical experiments show that the proposed model drastically improves the accuracy. Moreover, the output shapes differ from those of the training dataset but still satisfy the physical validity, overcoming the limitations of existing GAN models.
<div id='section'>Paperid: <span id='pid'>858, <a href='https://arxiv.org/pdf/2308.09290.pdf' target='_blank'>https://arxiv.org/pdf/2308.09290.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ritam Majumdar, Vishal Jadhav, Anirudh Deodhar, Shirish Karande, Lovekesh Vig, Venkataramana Runkana
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09290">HyperLoRA for PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have been widely used to develop neural surrogates for solutions of Partial Differential Equations. A drawback of PINNs is that they have to be retrained with every change in initial-boundary conditions and PDE coefficients. The Hypernetwork, a model-based meta learning technique, takes in a parameterized task embedding as input and predicts the weights of PINN as output. Predicting weights of a neural network however, is a high-dimensional regression problem, and hypernetworks perform sub-optimally while predicting parameters for large base networks. To circumvent this issue, we use a low ranked adaptation (LoRA) formulation to decompose every layer of the base network into low-ranked tensors and use hypernetworks to predict the low-ranked tensors. Despite the reduced dimensionality of the resulting weight-regression problem, LoRA-based Hypernetworks violate the underlying physics of the given task. We demonstrate that the generalization capabilities of LoRA-based hypernetworks drastically improve when trained with an additional physics-informed loss component (HyperPINN) to satisfy the governing differential equations. We observe that LoRA-based HyperPINN training allows us to learn fast solutions for parameterized PDEs like Burger's equation and Navier Stokes: Kovasznay flow, while having an 8x reduction in prediction parameters on average without compromising on accuracy when compared to all other baselines.
<div id='section'>Paperid: <span id='pid'>859, <a href='https://arxiv.org/pdf/2308.08571.pdf' target='_blank'>https://arxiv.org/pdf/2308.08571.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gledson Rodrigo Tondo, Igor Kavrakov, Guido Morgenthal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08571">A physics-informed machine learning model for reconstruction of dynamic loads</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Long-span bridges are subjected to a multitude of dynamic excitations during their lifespan. To account for their effects on the structural system, several load models are used during design to simulate the conditions the structure is likely to experience. These models are based on different simplifying assumptions and are generally guided by parameters that are stochastically identified from measurement data, making their outputs inherently uncertain. This paper presents a probabilistic physics-informed machine-learning framework based on Gaussian process regression for reconstructing dynamic forces based on measured deflections, velocities, or accelerations. The model can work with incomplete and contaminated data and offers a natural regularization approach to account for noise in the measurement system. An application of the developed framework is given by an aerodynamic analysis of the Great Belt East Bridge. The aerodynamic response is calculated numerically based on the quasi-steady model, and the underlying forces are reconstructed using sparse and noisy measurements. Results indicate a good agreement between the applied and the predicted dynamic load and can be extended to calculate global responses and the resulting internal forces. Uses of the developed framework include validation of design models and assumptions, as well as prognosis of responses to assist in damage detection and structural health monitoring.
<div id='section'>Paperid: <span id='pid'>860, <a href='https://arxiv.org/pdf/2308.05027.pdf' target='_blank'>https://arxiv.org/pdf/2308.05027.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karolis Martinkus, Jan Ludwiczak, Kyunghyun Cho, Wei-Ching Liang, Julien Lafrance-Vanasse, Isidro Hotzel, Arvind Rajpal, Yan Wu, Richard Bonneau, Vladimir Gligorijevic, Andreas Loukas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.05027">AbDiffuser: Full-Atom Generation of in vitro Functioning Antibodies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce AbDiffuser, an equivariant and physics-informed diffusion model for the joint generation of antibody 3D structures and sequences. AbDiffuser is built on top of a new representation of protein structure, relies on a novel architecture for aligned proteins, and utilizes strong diffusion priors to improve the denoising process. Our approach improves protein diffusion by taking advantage of domain knowledge and physics-based constraints; handles sequence-length changes; and reduces memory complexity by an order of magnitude, enabling backbone and side chain generation. We validate AbDiffuser in silico and in vitro. Numerical experiments showcase the ability of AbDiffuser to generate antibodies that closely track the sequence and structural properties of a reference set. Laboratory experiments confirm that all 16 HER2 antibodies discovered were expressed at high levels and that 57.1% of the selected designs were tight binders.
<div id='section'>Paperid: <span id='pid'>861, <a href='https://arxiv.org/pdf/2308.02894.pdf' target='_blank'>https://arxiv.org/pdf/2308.02894.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gledson Rodrigo Tondo, Sebastian Rau, Igor Kavrakov, Guido Morgenthal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02894">Physics-informed Gaussian process model for Euler-Bernoulli beam elements</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A physics-informed machine learning model, in the form of a multi-output Gaussian process, is formulated using the Euler-Bernoulli beam equation. Given appropriate datasets, the model can be used to regress the analytical value of the structure's bending stiffness, interpolate responses, and make probabilistic inferences on latent physical quantities. The developed model is applied on a numerically simulated cantilever beam, where the regressed bending stiffness is evaluated and the influence measurement noise on the prediction quality is investigated. Further, the regressed probabilistic stiffness distribution is used in a structural health monitoring context, where the Mahalanobis distance is employed to reason about the possible location and extent of damage in the structural system. To validate the developed framework, an experiment is conducted and measured heterogeneous datasets are used to update the assumed analytical structural model.
<div id='section'>Paperid: <span id='pid'>862, <a href='https://arxiv.org/pdf/2307.06267.pdf' target='_blank'>https://arxiv.org/pdf/2307.06267.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Tang, Li Jin, Kaan Ozbay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.06267">Physics-informed Machine Learning for Calibrating Macroscopic Traffic Flow Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Well-calibrated traffic flow models are fundamental to understanding traffic phenomena and designing control strategies. Traditional calibration has been developed base on optimization methods. In this paper, we propose a novel physics-informed, learning-based calibration approach that achieves performances comparable to and even better than those of optimization-based methods. To this end, we combine the classical deep autoencoder, an unsupervised machine learning model consisting of one encoder and one decoder, with traffic flow models. Our approach informs the decoder of the physical traffic flow models and thus induces the encoder to yield reasonable traffic parameters given flow and speed measurements. We also introduce the denoising autoencoder into our method so that it can handles not only with normal data but also with corrupted data with missing values. We verified our approach with a case study of I-210 E in California.
<div id='section'>Paperid: <span id='pid'>863, <a href='https://arxiv.org/pdf/2306.15891.pdf' target='_blank'>https://arxiv.org/pdf/2306.15891.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keke Wu, Xiong-bin Yan, Shi Jin, Zheng Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.15891">Capturing the Diffusive Behavior of the Multiscale Linear Transport Equations by Asymptotic-Preserving Convolutional DeepONets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce two types of novel Asymptotic-Preserving Convolutional Deep Operator Networks (APCONs) designed to address the multiscale time-dependent linear transport problem. We observe that the vanilla physics-informed DeepONets with modified MLP may exhibit instability in maintaining the desired limiting macroscopic behavior. Therefore, this necessitates the utilization of an asymptotic-preserving loss function. Drawing inspiration from the heat kernel in the diffusion equation, we propose a new architecture called Convolutional Deep Operator Networks, which employ multiple local convolution operations instead of a global heat kernel, along with pooling and activation operations in each filter layer. Our APCON methods possess a parameter count that is independent of the grid size and are capable of capturing the diffusive behavior of the linear transport problem. Finally, we validate the effectiveness of our methods through several numerical examples.
<div id='section'>Paperid: <span id='pid'>864, <a href='https://arxiv.org/pdf/2306.12749.pdf' target='_blank'>https://arxiv.org/pdf/2306.12749.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xi'an Li, Jiaxin Deng, Jinran Wu, Shaotong Zhang, Weide Li, You-Gan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.12749">Physical informed neural networks with soft and hard boundary constraints for solving advection-diffusion equations using Fourier expansions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning methods have gained considerable interest in the numerical solution of various partial differential equations (PDEs). One particular focus is physics-informed neural networks (PINN), which integrate physical principles into neural networks. This transforms the process of solving PDEs into optimization problems for neural networks. To address a collection of advection-diffusion equations (ADE) in a range of difficult circumstances, this paper proposes a novel network structure. This architecture integrates the solver, a multi-scale deep neural networks (MscaleDNN) utilized in the PINN method, with a hard constraint technique known as HCPINN. This method introduces a revised formulation of the desired solution for ADE by utilizing a loss function that incorporates the residuals of the governing equation and penalizes any deviations from the specified boundary and initial constraints. By surpassing the boundary constraints automatically, this method improves the accuracy and efficiency of the PINN technique. To address the ``spectral bias'' phenomenon in neural networks, a subnetwork structure of MscaleDNN and a Fourier-induced activation function are incorporated into the HCPINN, resulting in a hybrid approach called SFHCPINN. The effectiveness of SFHCPINN is demonstrated through various numerical experiments involving ADE in different dimensions. The numerical results indicate that SFHCPINN outperforms both standard PINN and its subnetwork version with Fourier feature embedding. It achieves remarkable accuracy and efficiency while effectively handling complex boundary conditions and high-frequency scenarios in ADE.
<div id='section'>Paperid: <span id='pid'>865, <a href='https://arxiv.org/pdf/2306.01010.pdf' target='_blank'>https://arxiv.org/pdf/2306.01010.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenqian Chen, Yucheng Fu, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.01010">Physics-informed machine learning of redox flow battery based on a two-dimensional unit cell model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present a physics-informed neural network (PINN) approach for predicting the performance of an all-vanadium redox flow battery, with its physics constraints enforced by a two-dimensional (2D) mathematical model. The 2D model, which includes 6 governing equations and 24 boundary conditions, provides a detailed representation of the electrochemical reactions, mass transport and hydrodynamics occurring inside the redox flow battery. To solve the 2D model with the PINN approach, a composite neural network is employed to approximate species concentration and potentials; the input and output are normalized according to prior knowledge of the battery system; the governing equations and boundary conditions are first scaled to an order of magnitude around 1, and then further balanced with a self-weighting method. Our numerical results show that the PINN is able to predict cell voltage correctly, but the prediction of potentials shows a constant-like shift. To fix the shift, the PINN is enhanced by further constrains derived from the current collector boundary. Finally, we show that the enhanced PINN can be even further improved if a small number of labeled data is available.
<div id='section'>Paperid: <span id='pid'>866, <a href='https://arxiv.org/pdf/2305.03257.pdf' target='_blank'>https://arxiv.org/pdf/2305.03257.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianqi Cui, Tom S. Bertalan, Nelson Ndahiro, Pratik Khare, Michael Betenbaugh, Costas Maranas, Ioannis G. Kevrekidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.03257">Data-driven and Physics Informed Modelling of Chinese Hamster Ovary Cell Bioreactors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fed-batch culture is an established operation mode for the production of biologics using mammalian cell cultures. Quantitative modeling integrates both kinetics for some key reaction steps and optimization-driven metabolic flux allocation, using flux balance analysis; this is known to lead to certain mathematical inconsistencies. Here, we propose a physically-informed data-driven hybrid model (a "gray box") to learn models of the dynamical evolution of Chinese Hamster Ovary (CHO) cell bioreactors from process data. The approach incorporates physical laws (e.g. mass balances) as well as kinetic expressions for metabolic fluxes. Machine learning (ML) is then used to (a) directly learn evolution equations (black-box modelling); (b) recover unknown physical parameters ("white-box" parameter fitting) or -- importantly -- (c) learn partially unknown kinetic expressions (gray-box modelling). We encode the convex optimization step of the overdetermined metabolic biophysical system as a differentiable, feed-forward layer into our architectures, connecting partial physical knowledge with data-driven machine learning.
<div id='section'>Paperid: <span id='pid'>867, <a href='https://arxiv.org/pdf/2305.00210.pdf' target='_blank'>https://arxiv.org/pdf/2305.00210.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shahroz Khan, Kosa Goucher-Lambert, Konstantinos Kostas, Panagiotis Kaklis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.00210">ShipHullGAN: A generic parametric modeller for ship hull design using deep convolutional generative model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we introduce ShipHullGAN, a generic parametric modeller built using deep convolutional generative adversarial networks (GANs) for the versatile representation and generation of ship hulls. At a high level, the new model intends to address the current conservatism in the parametric ship design paradigm, where parametric modellers can only handle a particular ship type. We trained ShipHullGAN on a large dataset of 52,591 \textit{physically validated} designs from a wide range of existing ship types, including container ships, tankers, bulk carriers, tugboats, and crew supply vessels. We developed a new shape extraction and representation strategy to convert all training designs into a common geometric representation of the same resolution, as typically GANs can only accept vectors of fixed dimension as input. A space-filling layer is placed right after the generator component to ensure that the trained generator can cover all design classes. During training, designs are provided in the form of a shape-signature tensor (SST) which harnesses the compact geometric representation using geometric moments that further enable the inexpensive incorporation of physics-informed elements in ship design. We have shown through extensive comparative studies and optimisation cases that ShipHullGAN can generate designs with augmented features resulting in versatile design spaces that produce traditional and novel designs with geometrically valid and practically feasible shapes.
<div id='section'>Paperid: <span id='pid'>868, <a href='https://arxiv.org/pdf/2304.14214.pdf' target='_blank'>https://arxiv.org/pdf/2304.14214.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saurabh Malani, Tom S. Bertalan, Tianqi Cui, Jose L. Avalos, Michael Betenbaugh, Ioannis G. Kevrekidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.14214">Some of the variables, some of the parameters, some of the times, with some physics known: Identification with partial information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Experimental data is often comprised of variables measured independently, at different sampling rates (non-uniform $Î$t between successive measurements); and at a specific time point only a subset of all variables may be sampled. Approaches to identifying dynamical systems from such data typically use interpolation, imputation or subsampling to reorganize or modify the training data $\textit{prior}$ to learning. Partial physical knowledge may also be available $\textit{a priori}$ (accurately or approximately), and data-driven techniques can complement this knowledge. Here we exploit neural network architectures based on numerical integration methods and $\textit{a priori}$ physical knowledge to identify the right-hand side of the underlying governing differential equations. Iterates of such neural-network models allow for learning from data sampled at arbitrary time points $\textit{without}$ data modification. Importantly, we integrate the network with available partial physical knowledge in "physics informed gray-boxes"; this enables learning unknown kinetic rates or microbial growth functions while simultaneously estimating experimental parameters.
<div id='section'>Paperid: <span id='pid'>869, <a href='https://arxiv.org/pdf/2304.09070.pdf' target='_blank'>https://arxiv.org/pdf/2304.09070.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>RÃ¼diger Brecht, Alex Bihlo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.09070">M-ENIAC: A machine learning recreation of the first successful numerical weather forecasts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In 1950 the first successful numerical weather forecast was obtained by solving the barotropic vorticity equation using the Electronic Numerical Integrator and Computer (ENIAC), which marked the beginning of the age of numerical weather prediction. Here, we ask the question of how these numerical forecasts would have turned out, if machine learning based solvers had been used instead of standard numerical discretizations. Specifically, we recreate these numerical forecasts using physics-informed neural networks. We show that physics-informed neural networks provide an easier and more accurate methodology for solving meteorological equations on the sphere, as compared to the ENIAC solver.
<div id='section'>Paperid: <span id='pid'>870, <a href='https://arxiv.org/pdf/2304.06044.pdf' target='_blank'>https://arxiv.org/pdf/2304.06044.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shahed Rezaei, Ahmad Moeineddin, Ali Harandi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06044">Learning solution of nonlinear constitutive material models using physics-informed neural networks: COMM-PINN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We applied physics-informed neural networks to solve the constitutive relations for nonlinear, path-dependent material behavior. As a result, the trained network not only satisfies all thermodynamic constraints but also instantly provides information about the current material state (i.e., free energy, stress, and the evolution of internal variables) under any given loading scenario without requiring initial data. One advantage of this work is that it bypasses the repetitive Newton iterations needed to solve nonlinear equations in complex material models. Additionally, strategies are provided to reduce the required order of derivative for obtaining the tangent operator. The trained model can be directly used in any finite element package (or other numerical methods) as a user-defined material model. However, challenges remain in the proper definition of collocation points and in integrating several non-equality constraints that become active or non-active simultaneously. We tested this methodology on rate-independent processes such as the classical von Mises plasticity model with a nonlinear hardening law, as well as local damage models for interface cracking behavior with a nonlinear softening law. In order to demonstrate the applicability of the methodology in handling complex path dependency in a three-dimensional (3D) scenario, we tested the approach using the equations governing a damage model for a three-dimensional interface model. Such models are frequently employed for intergranular fracture at grain boundaries. We have observed a perfect agreement between the results obtained through the proposed methodology and those obtained using the classical approach. Furthermore, the proposed approach requires significantly less effort in terms of implementation and computing time compared to the traditional methods.
<div id='section'>Paperid: <span id='pid'>871, <a href='https://arxiv.org/pdf/2304.04854.pdf' target='_blank'>https://arxiv.org/pdf/2304.04854.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aleksandr Dekhovich, Marcel H. F. Sluiter, David M. J. Tax, Miguel A. Bessa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04854">iPINNs: Incremental learning for Physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have recently become a powerful tool for solving partial differential equations (PDEs). However, finding a set of neural network parameters that lead to fulfilling a PDE can be challenging and non-unique due to the complexity of the loss landscape that needs to be traversed. Although a variety of multi-task learning and transfer learning approaches have been proposed to overcome these issues, there is no incremental training procedure for PINNs that can effectively mitigate such training challenges. We propose incremental PINNs (iPINNs) that can learn multiple tasks (equations) sequentially without additional parameters for new tasks and improve performance for every equation in the sequence. Our approach learns multiple PDEs starting from the simplest one by creating its own subnetwork for each PDE and allowing each subnetwork to overlap with previously learned subnetworks. We demonstrate that previous subnetworks are a good initialization for a new equation if PDEs share similarities. We also show that iPINNs achieve lower prediction error than regular PINNs for two different scenarios: (1) learning a family of equations (e.g., 1-D convection PDE); and (2) learning PDEs resulting from a combination of processes (e.g., 1-D reaction-diffusion PDE). The ability to learn all problems with a single network together with learning more complex PDEs with better generalization than regular PINNs will open new avenues in this field.
<div id='section'>Paperid: <span id='pid'>872, <a href='https://arxiv.org/pdf/2304.02282.pdf' target='_blank'>https://arxiv.org/pdf/2304.02282.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vasiliy A. Es'kin, Danil V. Davydov, Ekaterina D. Egorova, Alexey O. Malkhanov, Mikhail A. Akhukov, Mikhail E. Smorkalov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.02282">About optimal loss function for training physics-informed neural networks under respecting causality</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A method is presented that allows to reduce a problem described by differential equations with initial and boundary conditions to the problem described only by differential equations. The advantage of using the modified problem for physics-informed neural networks (PINNs) methodology is that it becomes possible to represent the loss function in the form of a single term associated with differential equations, thus eliminating the need to tune the scaling coefficients for the terms related to boundary and initial conditions. The weighted loss functions respecting causality were modified and new weighted loss functions based on generalized functions are derived. Numerical experiments have been carried out for a number of problems, demonstrating the accuracy of the proposed methods.
<div id='section'>Paperid: <span id='pid'>873, <a href='https://arxiv.org/pdf/2303.14194.pdf' target='_blank'>https://arxiv.org/pdf/2303.14194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ritam Majumdar, Shirish Karande, Lovekesh Vig
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.14194">DeepEpiSolver: Unravelling Inverse problems in Covid, HIV, Ebola and Disease Transmission</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The spread of many infectious diseases is modeled using variants of the SIR compartmental model, which is a coupled differential equation. The coefficients of the SIR model determine the spread trajectories of disease, on whose basis proactive measures can be taken. Hence, the coefficient estimates must be both fast and accurate. Shaier et al. in the paper "Disease Informed Neural Networks" used Physics Informed Neural Networks (PINNs) to estimate the parameters of the SIR model. There are two drawbacks to this approach. First, the training time for PINNs is high, with certain diseases taking close to 90 hrs to train. Second, PINNs don't generalize for a new SIDR trajectory, and learning its corresponding SIR parameters requires retraining the PINN from scratch. In this work, we aim to eliminate both of these drawbacks. We generate a dataset between the parameters of ODE and the spread trajectories by solving the forward problem for a large distribution of parameters using the LSODA algorithm. We then use a neural network to learn the mapping between spread trajectories and coefficients of SIDR in an offline manner. This allows us to learn the parameters of a new spread trajectory without having to retrain, enabling generalization at test time. We observe a speed-up of 3-4 orders of magnitude with accuracy comparable to that of PINNs for 11 highly infectious diseases. Further finetuning of neural network inferred ODE coefficients using PINN further leads to 2-3 orders improvement of estimated coefficients.
<div id='section'>Paperid: <span id='pid'>874, <a href='https://arxiv.org/pdf/2303.11577.pdf' target='_blank'>https://arxiv.org/pdf/2303.11577.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenqian Chen, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.11577">Feature-adjacent multi-fidelity physics-informed machine learning for partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks have emerged as an alternative method for solving partial differential equations. However, for complex problems, the training of such networks can still require high-fidelity data which can be expensive to generate. To reduce or even eliminate the dependency on high-fidelity data, we propose a novel multi-fidelity architecture which is based on a feature space shared by the low- and high-fidelity solutions. In the feature space, the projections of the low-fidelity and high-fidelity solutions are adjacent by constraining their relative distance. The feature space is represented with an encoder and its mapping to the original solution space is effected through a decoder. The proposed multi-fidelity approach is validated on forward and inverse problems for steady and unsteady problems described by partial differential equations.
<div id='section'>Paperid: <span id='pid'>875, <a href='https://arxiv.org/pdf/2303.07009.pdf' target='_blank'>https://arxiv.org/pdf/2303.07009.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ritam Majumdar, Vishal Jadhav, Anirudh Deodhar, Shirish Karande, Lovekesh Vig, Venkataramana Runkana
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.07009">Symbolic Regression for PDEs using Pruned Differentiable Programs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Neural Networks (PINNs) have been widely used to obtain accurate neural surrogates for a system of Partial Differential Equations (PDE). One of the major limitations of PINNs is that the neural solutions are challenging to interpret, and are often treated as black-box solvers. While Symbolic Regression (SR) has been studied extensively, very few works exist which generate analytical expressions to directly perform SR for a system of PDEs. In this work, we introduce an end-to-end framework for obtaining mathematical expressions for solutions of PDEs. We use a trained PINN to generate a dataset, upon which we perform SR. We use a Differentiable Program Architecture (DPA) defined using context-free grammar to describe the space of symbolic expressions. We improve the interpretability by pruning the DPA in a depth-first manner using the magnitude of weights as our heuristic. On average, we observe a 95.3% reduction in parameters of DPA while maintaining accuracy at par with PINNs. Furthermore, on an average, pruning improves the accuracy of DPA by 7.81% . We demonstrate our framework outperforms the existing state-of-the-art SR solvers on systems of complex PDEs like Navier-Stokes: Kovasznay flow and Taylor-Green Vortex flow. Furthermore, we produce analytical expressions for a complex industrial use-case of an Air-Preheater, without suffering from performance loss viz-a-viz PINNs.
<div id='section'>Paperid: <span id='pid'>876, <a href='https://arxiv.org/pdf/2302.04954.pdf' target='_blank'>https://arxiv.org/pdf/2302.04954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Harandi, Ahmad Moeineddin, Michael Kaliske, Stefanie Reese, Shahed Rezaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.04954">Mixed formulation of physics-informed neural networks for thermo-mechanically coupled systems and heterogeneous domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are a new tool for solving boundary value problems by defining loss functions of neural networks based on governing equations, boundary conditions, and initial conditions. Recent investigations have shown that when designing loss functions for many engineering problems, using first-order derivatives and combining equations from both strong and weak forms can lead to much better accuracy, especially when there are heterogeneity and variable jumps in the domain. This new approach is called the mixed formulation for PINNs, which takes ideas from the mixed finite element method. In this method, the PDE is reformulated as a system of equations where the primary unknowns are the fluxes or gradients of the solution, and the secondary unknowns are the solution itself. In this work, we propose applying the mixed formulation to solve multi-physical problems, specifically a stationary thermo-mechanically coupled system of equations. Additionally, we discuss both sequential and fully coupled unsupervised training and compare their accuracy and computational cost. To improve the accuracy of the network, we incorporate hard boundary constraints to ensure valid predictions. We then investigate how different optimizers and architectures affect accuracy and efficiency. Finally, we introduce a simple approach for parametric learning that is similar to transfer learning. This approach combines data and physics to address the limitations of PINNs regarding computational cost and improves the network's ability to predict the response of the system for unseen cases. The outcomes of this work will be useful for many other engineering applications where deep learning is employed on multiple coupled systems of equations for fast and reliable computations.
<div id='section'>Paperid: <span id='pid'>877, <a href='https://arxiv.org/pdf/2301.07769.pdf' target='_blank'>https://arxiv.org/pdf/2301.07769.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Patricio Clark Di Leoni, Lokahith Agasthya, Michele Buzzicotti, Luca Biferale
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.07769">Reconstructing Rayleigh-Benard flows out of temperature-only measurements using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate the capabilities of Physics-Informed Neural Networks (PINNs) to reconstruct turbulent Rayleigh-Benard flows using only temperature information. We perform a quantitative analysis of the quality of the reconstructions at various amounts of low-passed-filtered information and turbulent intensities. We compare our results with those obtained via nudging, a classical equation-informed data assimilation technique. At low Rayleigh numbers, PINNs are able to reconstruct with high precision, comparable to the one achieved with nudging. At high Rayleigh numbers, PINNs outperform nudging and are able to achieve satisfactory reconstruction of the velocity fields only when data for temperature is provided with high spatial and temporal density. When data becomes sparse, the PINNs performance worsens, not only in a point-to-point error sense but also, and contrary to nudging, in a statistical sense, as can be seen in the probability density functions and energy spectra.
<div id='section'>Paperid: <span id='pid'>878, <a href='https://arxiv.org/pdf/2211.08760.pdf' target='_blank'>https://arxiv.org/pdf/2211.08760.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihang Gao, Ka Chun Cheung, Michael K. Ng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.08760">SVD-PINNs: Transfer Learning of Physics-Informed Neural Networks via Singular Value Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have attracted significant attention for solving partial differential equations (PDEs) in recent years because they alleviate the curse of dimensionality that appears in traditional methods. However, the most disadvantage of PINNs is that one neural network corresponds to one PDE. In practice, we usually need to solve a class of PDEs, not just one. With the explosive growth of deep learning, many useful techniques in general deep learning tasks are also suitable for PINNs. Transfer learning methods may reduce the cost for PINNs in solving a class of PDEs. In this paper, we proposed a transfer learning method of PINNs via keeping singular vectors and optimizing singular values (namely SVD-PINNs). Numerical experiments on high dimensional PDEs (10-d linear parabolic equations and 10-d Allen-Cahn equations) show that SVD-PINNs work for solving a class of PDEs with different but close right-hand-side functions.
<div id='section'>Paperid: <span id='pid'>879, <a href='https://arxiv.org/pdf/2209.03984.pdf' target='_blank'>https://arxiv.org/pdf/2209.03984.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francisco Sahli Costabal, Simone Pezzuto, Paris Perdikaris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.03984">$Î$-PINNs: physics-informed neural networks on complex geometries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have demonstrated promise in solving forward and inverse problems involving partial differential equations. Despite recent progress on expanding the class of problems that can be tackled by PINNs, most of existing use-cases involve simple geometric domains. To date, there is no clear way to inform PINNs about the topology of the domain where the problem is being solved. In this work, we propose a novel positional encoding mechanism for PINNs based on the eigenfunctions of the Laplace-Beltrami operator. This technique allows to create an input space for the neural network that represents the geometry of a given object. We approximate the eigenfunctions as well as the operators involved in the partial differential equations with finite elements. We extensively test and compare the proposed methodology against traditional PINNs in complex shapes, such as a coil, a heat sink and a bunny, with different physics, such as the Eikonal equation and heat transfer. We also study the sensitivity of our method to the number of eigenfunctions used, as well as the discretization used for the eigenfunctions and the underlying operators. Our results show excellent agreement with the ground truth data in cases where traditional PINNs fail to produce a meaningful solution. We envision this new technique will expand the effectiveness of PINNs to more realistic applications.
<div id='section'>Paperid: <span id='pid'>880, <a href='https://arxiv.org/pdf/2206.09961.pdf' target='_blank'>https://arxiv.org/pdf/2206.09961.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shamsulhaq Basir, Inanc Senocak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.09961">Critical Investigation of Failure Modes in Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Several recent works in scientific machine learning have revived interest in the application of neural networks to partial differential equations (PDEs). A popular approach is to aggregate the residual form of the governing PDE and its boundary conditions as soft penalties into a composite objective/loss function for training neural networks, which is commonly referred to as physics-informed neural networks (PINNs). In the present study, we visualize the loss landscapes and distributions of learned parameters and explain the ways this particular formulation of the objective function may hinder or even prevent convergence when dealing with challenging target solutions. We construct a purely data-driven loss function composed of both the boundary loss and the domain loss. Using this data-driven loss function and, separately, a physics-informed loss function, we then train two neural network models with the same architecture. We show that incomparable scales between boundary and domain loss terms are the culprit behind the poor performance. Additionally, we assess the performance of both approaches on two elliptic problems with increasingly complex target solutions. Based on our analysis of their loss landscapes and learned parameter distributions, we observe that a physics-informed neural network with a composite objective function formulation produces highly non-convex loss surfaces that are difficult to optimize and are more prone to the problem of vanishing gradients.
<div id='section'>Paperid: <span id='pid'>881, <a href='https://arxiv.org/pdf/2205.01059.pdf' target='_blank'>https://arxiv.org/pdf/2205.01059.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hwijae Son, Sung Woong Cho, Hyung Ju Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.01059">Enhanced Physics-Informed Neural Networks with Augmented Lagrangian Relaxation Method (AL-PINNs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have become a prominent application of deep learning in scientific computation, as they are powerful approximators of solutions to nonlinear partial differential equations (PDEs). There have been numerous attempts to facilitate the training process of PINNs by adjusting the weight of each component of the loss function, called adaptive loss-balancing algorithms. In this paper, we propose an Augmented Lagrangian relaxation method for PINNs (AL-PINNs). We treat the initial and boundary conditions as constraints for the optimization problem of the PDE residual. By employing Augmented Lagrangian relaxation, the constrained optimization problem becomes a sequential max-min problem so that the learnable parameters $Î»$ adaptively balance each loss component. Our theoretical analysis reveals that the sequence of minimizers of the proposed loss functions converges to an actual solution for the Helmholtz, viscous Burgers, and Klein--Gordon equations. We demonstrate through various numerical experiments that AL-PINNs yield a much smaller relative error compared with that of state-of-the-art adaptive loss-balancing algorithms.
<div id='section'>Paperid: <span id='pid'>882, <a href='https://arxiv.org/pdf/2204.12445.pdf' target='_blank'>https://arxiv.org/pdf/2204.12445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felipe Galarce, Karsten Tabelown, JÃ¶rg Polzehl, Christos Panagiotis Papanikas, Vasileios Vavourakis, Ledia Lilaj, Ingolf Sack, Alfonso Caiazzo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.12445">Displacement and pressure reconstruction from magnetic resonance elastography images: application to an in silico brain model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Magnetic resonance elastography is a motion-sensitive image modality that allows to measure in vivo tissue displacement fields in response to mechanical excitations. This paper investigates a data assimilation approach for reconstructing tissue displacement and pressure fields in an in silico brain model from partial elastography data. The data assimilation is based on a parametrized-background data weak methodology, in which the state of the physical system -- tissue displacements and pressure fields -- is reconstructed from the available data assuming an underlying poroelastic biomechanics model. For this purpose, a physics-informed manifold is built by sampling the space of parameters describing the tissue model close to their physiological ranges to simulate the corresponding poroelastic problem, and computing a reduced basis via Proper Orthogonal Decomposition. Displacements and pressure reconstruction is sought in a reduced space after solving a minimization problem that encompasses both the structure of the reduced-order model and the available measurements. The proposed pipeline is validated using synthetic data obtained after simulating the poroelastic mechanics of a physiological brain. The numerical experiments demonstrate that the framework can exhibit accurate joint reconstructions of both displacement and pressure fields. The methodology can be formulated for an arbitrary resolution of available displacement data from pertinent images.
<div id='section'>Paperid: <span id='pid'>883, <a href='https://arxiv.org/pdf/2204.12005.pdf' target='_blank'>https://arxiv.org/pdf/2204.12005.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaolong He, Youngsoo Choi, William D. Fries, Jon Belof, Jiun-Shyan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.12005">gLaSDI: Parametric Physics-informed Greedy Latent Space Dynamics Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A parametric adaptive physics-informed greedy Latent Space Dynamics Identification (gLaSDI) method is proposed for accurate, efficient, and robust data-driven reduced-order modeling of high-dimensional nonlinear dynamical systems. In the proposed gLaSDI framework, an autoencoder discovers intrinsic nonlinear latent representations of high-dimensional data, while dynamics identification (DI) models capture local latent-space dynamics. An interactive training algorithm is adopted for the autoencoder and local DI models, which enables identification of simple latent-space dynamics and enhances accuracy and efficiency of data-driven reduced-order modeling. To maximize and accelerate the exploration of the parameter space for the optimal model performance, an adaptive greedy sampling algorithm integrated with a physics-informed residual-based error indicator and random-subset evaluation is introduced to search for the optimal training samples on the fly. Further, to exploit local latent-space dynamics captured by the local DI models for an improved modeling accuracy with a minimum number of local DI models in the parameter space, a k-nearest neighbor convex interpolation scheme is employed. The effectiveness of the proposed framework is demonstrated by modeling various nonlinear dynamical problems, including Burgers equations, nonlinear heat conduction, and radial advection. The proposed adaptive greedy sampling outperforms the conventional predefined uniform sampling in terms of accuracy. Compared with the high-fidelity models, gLaSDI achieves 17 to 2,658x speed-up with 1 to 5% relative errors.
<div id='section'>Paperid: <span id='pid'>884, <a href='https://arxiv.org/pdf/2202.10446.pdf' target='_blank'>https://arxiv.org/pdf/2202.10446.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander RodrÃ­guez, Jiaming Cui, Naren Ramakrishnan, Bijaya Adhikari, B. Aditya Prakash
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.10446">EINNs: Epidemiologically-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce EINNs, a framework crafted for epidemic forecasting that builds upon the theoretical grounds provided by mechanistic models as well as the data-driven expressibility afforded by AI models, and their capabilities to ingest heterogeneous information. Although neural forecasting models have been successful in multiple tasks, predictions well-correlated with epidemic trends and long-term predictions remain open challenges. Epidemiological ODE models contain mechanisms that can guide us in these two tasks; however, they have limited capability of ingesting data sources and modeling composite signals. Thus, we propose to leverage work in physics-informed neural networks to learn latent epidemic dynamics and transfer relevant knowledge to another neural network which ingests multiple data sources and has more appropriate inductive bias. In contrast with previous work, we do not assume the observability of complete dynamics and do not need to numerically solve the ODE equations during training. Our thorough experiments on all US states and HHS regions for COVID-19 and influenza forecasting showcase the clear benefits of our approach in both short-term and long-term forecasting as well as in learning the mechanistic dynamics over other non-trivial alternatives.
<div id='section'>Paperid: <span id='pid'>885, <a href='https://arxiv.org/pdf/2109.11313.pdf' target='_blank'>https://arxiv.org/pdf/2109.11313.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikolas Borrel-Jensen, Allan P. Engsig-Karup, Cheol-Ho Jeong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2109.11313">Physics-informed neural networks for one-dimensional sound field predictions with parameterized sources and impedance boundaries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Realistic sound is essential in virtual environments, such as computer games and mixed reality. Efficient and accurate numerical methods for pre-calculating acoustics have been developed over the last decade; however, pre-calculating acoustics makes handling dynamic scenes with moving sources challenging, requiring intractable memory storage. A physics-informed neural network (PINN) method in 1D is presented, which learns a compact and efficient surrogate model with parameterized moving Gaussian sources and impedance boundaries, and satisfies a system of coupled equations. The model shows relative mean errors below 2%/0.2 dB and proposes a first step in developing PINNs for realistic 3D scenes.
<div id='section'>Paperid: <span id='pid'>886, <a href='https://arxiv.org/pdf/2104.02556.pdf' target='_blank'>https://arxiv.org/pdf/2104.02556.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eric Aislan Antonelo, Eduardo Camponogara, Laio Oriel Seman, Eduardo Rehbein de Souza, Jean P. Jordanou, Jomi F. Hubner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2104.02556">Physics-Informed Neural Nets for Control of Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) impose known physical laws into the learning of deep neural networks, making sure they respect the physics of the process while decreasing the demand of labeled data. For systems represented by Ordinary Differential Equations (ODEs), the conventional PINN has a continuous time input variable and outputs the solution of the corresponding ODE. In their original form, PINNs do not allow control inputs, neither can they simulate for variable long-range intervals without serious degradation in their predictions. In this context, this work presents a new framework called Physics-Informed Neural Nets for Control (PINC), which proposes a novel PINN-based architecture that is amenable to control problems and able to simulate for longer-range time horizons that are not fixed beforehand, making it a very flexible framework when compared to traditional PINNs. Furthermore, this long-range time simulation of differential equations is faster than numerical methods since it relies only on signal propagation through the network, making it less computationally costly and, thus, a better alternative for simulation of models in Model Predictive Control. We showcase our proposal in the control of two nonlinear dynamic systems: the Van der Pol oscillator and the four-tank system.
<div id='section'>Paperid: <span id='pid'>887, <a href='https://arxiv.org/pdf/1907.08967.pdf' target='_blank'>https://arxiv.org/pdf/1907.08967.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vikas Dwivedi, Nishant Parashar, Balaji Srinivasan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/1907.08967">Distributed physics informed neural network for data-efficient solution to partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The physics informed neural network (PINN) is evolving as a viable method to solve partial differential equations. In the recent past PINNs have been successfully tested and validated to find solutions to both linear and non-linear partial differential equations (PDEs). However, the literature lacks detailed investigation of PINNs in terms of their representation capability. In this work, we first test the original PINN method in terms of its capability to represent a complicated function. Further, to address the shortcomings of the PINN architecture, we propose a novel distributed PINN, named DPINN. We first perform a direct comparison of the proposed DPINN approach against PINN to solve a non-linear PDE (Burgers' equation). We show that DPINN not only yields a more accurate solution to the Burgers' equation, but it is found to be more data-efficient as well. At last, we employ our novel DPINN to two-dimensional steady-state Navier-Stokes equation, which is a system of non-linear PDEs. To the best of the authors' knowledge, this is the first such attempt to directly solve the Navier-Stokes equation using a physics informed neural network.
<div id='section'>Paperid: <span id='pid'>888, <a href='https://arxiv.org/pdf/2510.06684.pdf' target='_blank'>https://arxiv.org/pdf/2510.06684.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kang An, Chenhao Si, Ming Yan, Shiqian Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06684">AutoBalance: An Automatic Balancing Framework for Training Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) provide a powerful and general framework for solving Partial Differential Equations (PDEs) by embedding physical laws into loss functions. However, training PINNs is notoriously difficult due to the need to balance multiple loss terms, such as PDE residuals and boundary conditions, which often have conflicting objectives and vastly different curvatures. Existing methods address this issue by manipulating gradients before optimization (a "pre-combine" strategy). We argue that this approach is fundamentally limited, as forcing a single optimizer to process gradients from spectrally heterogeneous loss landscapes disrupts its internal preconditioning. In this work, we introduce AutoBalance, a novel "post-combine" training paradigm. AutoBalance assigns an independent adaptive optimizer to each loss component and aggregates the resulting preconditioned updates afterwards. Extensive experiments on challenging PDE benchmarks show that AutoBalance consistently outperforms existing frameworks, achieving significant reductions in solution error, as measured by both the MSE and $L^{\infty}$ norms. Moreover, AutoBalance is orthogonal to and complementary with other popular PINN methodologies, amplifying their effectiveness on demanding benchmarks.
<div id='section'>Paperid: <span id='pid'>889, <a href='https://arxiv.org/pdf/2510.06020.pdf' target='_blank'>https://arxiv.org/pdf/2510.06020.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sai Karthikeya Vemuri, Adithya Ashok Chalain Valapil, Tim Büchner, Joachim Denzler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06020">RamPINN: Recovering Raman Spectra From Coherent Anti-Stokes Spectra Using Embedded Physics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transferring the recent advancements in deep learning into scientific disciplines is hindered by the lack of the required large-scale datasets for training. We argue that in these knowledge-rich domains, the established body of scientific theory provides reliable inductive biases in the form of governing physical laws. We address the ill-posed inverse problem of recovering Raman spectra from noisy Coherent Anti-Stokes Raman Scattering (CARS) measurements, as the true Raman signal here is suppressed by a dominating non-resonant background. We propose RamPINN, a model that learns to recover Raman spectra from given CARS spectra. Our core methodological contribution is a physics-informed neural network that utilizes a dual-decoder architecture to disentangle resonant and non-resonant signals. This is done by enforcing the Kramers-Kronig causality relations via a differentiable Hilbert transform loss on the resonant and a smoothness prior on the non-resonant part of the signal. Trained entirely on synthetic data, RamPINN demonstrates strong zero-shot generalization to real-world experimental data, explicitly closing this gap and significantly outperforming existing baselines. Furthermore, we show that training with these physics-based losses alone, without access to any ground-truth Raman spectra, still yields competitive results. This work highlights a broader concept: formal scientific rules can act as a potent inductive bias, enabling robust, self-supervised learning in data-limited scientific domains.
<div id='section'>Paperid: <span id='pid'>890, <a href='https://arxiv.org/pdf/2510.05158.pdf' target='_blank'>https://arxiv.org/pdf/2510.05158.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xin He, Liangliang You, Hongduan Tian, Bo Han, Ivor Tsang, Yew-Soon Ong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05158">Lang-PINN: From Language to Physics-Informed Neural Networks via a Multi-Agent Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) provide a powerful approach for solving partial differential equations (PDEs), but constructing a usable PINN remains labor-intensive and error-prone. Scientists must interpret problems as PDE formulations, design architectures and loss functions, and implement stable training pipelines. Existing large language model (LLM) based approaches address isolated steps such as code generation or architecture suggestion, but typically assume a formal PDE is already specified and therefore lack an end-to-end perspective. We present Lang-PINN, an LLM-driven multi-agent system that builds trainable PINNs directly from natural language task descriptions. Lang-PINN coordinates four complementary agents: a PDE Agent that parses task descriptions into symbolic PDEs, a PINN Agent that selects architectures, a Code Agent that generates modular implementations, and a Feedback Agent that executes and diagnoses errors for iterative refinement. This design transforms informal task statements into executable and verifiable PINN code. Experiments show that Lang-PINN achieves substantially lower errors and greater robustness than competitive baselines: mean squared error (MSE) is reduced by up to 3--5 orders of magnitude, end-to-end execution success improves by more than 50\%, and reduces time overhead by up to 74\%.
<div id='section'>Paperid: <span id='pid'>891, <a href='https://arxiv.org/pdf/2510.03589.pdf' target='_blank'>https://arxiv.org/pdf/2510.03589.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ankit Bhardwaj, Ananth Balashankar, Lakshminarayanan Subramanian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03589">FieldFormer: Physics-Informed Transformers for Spatio-Temporal Field Reconstruction from Sparse Sensors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spatio-temporal sensor data is often sparse, noisy, and irregular, and existing interpolation or learning methods struggle here because they either ignore governing PDEs or do not scale. We introduce FieldFormer, a transformer-based framework for mesh-free spatio-temporal field reconstruction that combines data-driven flexibility with physics-based structure. For each query, FieldFormer gathers a local neighborhood using a learnable velocity-scaled distance metric, enabling anisotropic adaptation to different propagation regimes. Neighborhoods are built efficiently via per-batch offset recomputation, and refined in an expectation-maximization style as the velocity scales evolve. Predictions are made by a local transformer encoder, and physics consistency is enforced through autograd-based PDE residuals and boundary-specific penalties. Across three benchmarks--a scalar anisotropic heat equation, a vector-valued shallow-water system, and a realistic advection-diffusion pollution simulation--FieldFormer consistently outperforms strong baselines by more than 40%. Our results demonstrate that FieldFormer enables accurate (RMSE$<10^{-2}$), efficient, and physically consistent field reconstruction from sparse (0.4%-2%) and noisy(10%) data.
<div id='section'>Paperid: <span id='pid'>892, <a href='https://arxiv.org/pdf/2509.22411.pdf' target='_blank'>https://arxiv.org/pdf/2509.22411.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Xue, Marco F. P. ten Eikelder, Mingyang Gao, Xiaoyuan Cheng, Yiming Yang, Yi He, Shuo Wang, Sibo Cheng, Yukun Hu, Peter V. Coveney
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.22411">Fast-Forward Lattice Boltzmann: Learning Kinetic Behaviour with Physics-Informed Neural Operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The lattice Boltzmann equation (LBE), rooted in kinetic theory, provides a powerful framework for capturing complex flow behaviour by describing the evolution of single-particle distribution functions (PDFs). Despite its success, solving the LBE numerically remains computationally intensive due to strict time-step restrictions imposed by collision kernels. Here, we introduce a physics-informed neural operator framework for the LBE that enables prediction over large time horizons without step-by-step integration, effectively bypassing the need to explicitly solve the collision kernel. We incorporate intrinsic moment-matching constraints of the LBE, along with global equivariance of the full distribution field, enabling the model to capture the complex dynamics of the underlying kinetic system. Our framework is discretization-invariant, enabling models trained on coarse lattices to generalise to finer ones (kinetic super-resolution). In addition, it is agnostic to the specific form of the underlying collision model, which makes it naturally applicable across different kinetic datasets regardless of the governing dynamics. Our results demonstrate robustness across complex flow scenarios, including von Karman vortex shedding, ligament breakup, and bubble adhesion. This establishes a new data-driven pathway for modelling kinetic systems.
<div id='section'>Paperid: <span id='pid'>893, <a href='https://arxiv.org/pdf/2509.17621.pdf' target='_blank'>https://arxiv.org/pdf/2509.17621.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Khoa Tran, Hung-Cuong Trinh, Vy-Rin Nguyen, T. Nguyen-Thoi, Vin Nguyen-Thai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17621">SeqBattNet: A Discrete-State Physics-Informed Neural Network with Aging Adaptation for Battery Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate battery modeling is essential for reliable state estimation in modern applications, such as predicting the remaining discharge time and remaining discharge energy in battery management systems. Existing approaches face several limitations: model-based methods require a large number of parameters; data-driven methods rely heavily on labeled datasets; and current physics-informed neural networks (PINNs) often lack aging adaptation, or still depend on many parameters, or continuously regenerate states. In this work, we propose SeqBattNet, a discrete-state PINN with built-in aging adaptation for battery modeling, to predict terminal voltage during the discharge process. SeqBattNet consists of two components: (i) an encoder, implemented as the proposed HRM-GRU deep learning module, which generates cycle-specific aging adaptation parameters; and (ii) a decoder, based on the equivalent circuit model (ECM) combined with deep learning, which uses these parameters together with the input current to predict voltage. The model requires only three basic battery parameters and, when trained on data from a single cell, still achieves robust performance. Extensive evaluations across three benchmark datasets (TRI, RT-Batt, and NASA) demonstrate that SeqBattNet significantly outperforms classical sequence models and PINN baselines, achieving consistently lower RMSE while maintaining computational efficiency.
<div id='section'>Paperid: <span id='pid'>894, <a href='https://arxiv.org/pdf/2509.15124.pdf' target='_blank'>https://arxiv.org/pdf/2509.15124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sanduni Pinnawala, Annabelle Hartanto, Ivor J. A. Simpson, Peter A. Wijeratne
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15124">Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modelling the underlying mechanisms of neurodegenerative diseases demands methods that capture heterogeneous and spatially varying dynamics from sparse, high-dimensional neuroimaging data. Integrating partial differential equation (PDE) based physics knowledge with machine learning provides enhanced interpretability and utility over classic numerical methods. However, current physics-integrated machine learning methods are limited to considering a single PDE, severely limiting their application to diseases where multiple mechanisms are responsible for different groups (i.e., subtypes) and aggravating problems with model misspecification and degeneracy. Here, we present a deep generative model for learning mixtures of latent dynamic models governed by physics-based PDEs, going beyond traditional approaches that assume a single PDE structure. Our method integrates reaction-diffusion PDEs within a variational autoencoder (VAE) mixture model framework, supporting inference of subtypes of interpretable latent variables (e.g. diffusivity and reaction rates) from neuroimaging data. We evaluate our method on synthetic benchmarks and demonstrate its potential for uncovering mechanistic subtypes of Alzheimer's disease progression from positron emission tomography (PET) data.
<div id='section'>Paperid: <span id='pid'>895, <a href='https://arxiv.org/pdf/2509.09183.pdf' target='_blank'>https://arxiv.org/pdf/2509.09183.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiasheng Guo, Xin Gao, Yuxiang Yan, Guanghao Li, Jian Pu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.09183">Dark-ISP: Enhancing RAW Image Processing for Low-Light Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Low-light Object detection is crucial for many real-world applications but remains challenging due to degraded image quality. While recent studies have shown that RAW images offer superior potential over RGB images, existing approaches either use RAW-RGB images with information loss or employ complex frameworks. To address these, we propose a lightweight and self-adaptive Image Signal Processing (ISP) plugin, Dark-ISP, which directly processes Bayer RAW images in dark environments, enabling seamless end-to-end training for object detection. Our key innovations are: (1) We deconstruct conventional ISP pipelines into sequential linear (sensor calibration) and nonlinear (tone mapping) sub-modules, recasting them as differentiable components optimized through task-driven losses. Each module is equipped with content-aware adaptability and physics-informed priors, enabling automatic RAW-to-RGB conversion aligned with detection objectives. (2) By exploiting the ISP pipeline's intrinsic cascade structure, we devise a Self-Boost mechanism that facilitates cooperation between sub-modules. Through extensive experiments on three RAW image datasets, we demonstrate that our method outperforms state-of-the-art RGB- and RAW-based detection approaches, achieving superior results with minimal parameters in challenging low-light environments.
<div id='section'>Paperid: <span id='pid'>896, <a href='https://arxiv.org/pdf/2509.07579.pdf' target='_blank'>https://arxiv.org/pdf/2509.07579.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liya Gaynutdinova, Martin Doškář, Ondřej Rokoš, Ivana Pultarová
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07579">Homogenization with Guaranteed Bounds via Primal-Dual Physically Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have shown promise in solving partial differential equations (PDEs) relevant to multiscale modeling, but they often fail when applied to materials with discontinuous coefficients, such as media with piecewise constant properties. This paper introduces a dual formulation for the PINN framework to improve the reliability of the homogenization of periodic thermo-conductive composites, for both strong and variational (weak) formulations. The dual approach facilitates the derivation of guaranteed upper and lower error bounds, enabling more robust detection of PINN failure. We compare standard PINNs applied to smoothed material approximations with variational PINNs (VPINNs) using both spectral and neural network-based test functions. Our results indicate that while strong-form PINNs may outperform VPINNs in controlled settings, they are sensitive to material discontinuities and may fail without clear diagnostics. In contrast, VPINNs accommodate piecewise constant material parameters directly but require careful selection of test functions to avoid instability. Dual formulation serves as a reliable indicator of convergence quality, and its integration into PINN frameworks enhances their applicability to homogenization problems in micromechanics.
<div id='section'>Paperid: <span id='pid'>897, <a href='https://arxiv.org/pdf/2509.02649.pdf' target='_blank'>https://arxiv.org/pdf/2509.02649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nathan Doumèche, Francis Bach, Gérard Biau, Claire Boyer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02649">Fast kernel methods: Sobolev, physics-informed, and additive models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kernel methods are powerful tools in statistical learning, but their cubic complexity in the sample size n limits their use on large-scale datasets. In this work, we introduce a scalable framework for kernel regression with O(n log n) complexity, fully leveraging GPU acceleration. The approach is based on a Fourier representation of kernels combined with non-uniform fast Fourier transforms (NUFFT), enabling exact, fast, and memory-efficient computations. We instantiate our framework in three settings: Sobolev kernel regression, physics-informed regression, and additive models. When known, the proposed estimators are shown to achieve minimax convergence rates, consistent with classical kernel theory. Empirical results demonstrate that our methods can process up to tens of billions of samples within minutes, providing both statistical accuracy and computational scalability. These contributions establish a flexible approach, paving the way for the routine application of kernel methods in large-scale learning tasks.
<div id='section'>Paperid: <span id='pid'>898, <a href='https://arxiv.org/pdf/2509.02366.pdf' target='_blank'>https://arxiv.org/pdf/2509.02366.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianwen Zhu, Hao Wang, Zhiwei Cao, Jiarong Xi, Yonggang Wen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02366">Towards Intelligent Battery Management via A Five-Tier Digital Twin Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Battery management systems (BMSs) are critical to ensuring safety, efficiency, and longevity across electronics, transportation, and energy storage. However, with the rapid growth of lithium-ion batteries, conventional reactive BMS approaches face limitations in health prediction and advanced maintenance management, resulting in increased safety risks and economic costs. To address these challenges, we propose a five-tier digital twin framework for intelligent battery management. The framework spans geometric visualization, predictive modeling, prescriptive optimization, and autonomous operation, enabling full lifecycle optimization. In validation, an electrochemical model calibrated via Bayesian optimization achieved strong alignment with measured voltage and temperature, with Mean Absolute Percentage Errors (MAPE) below 1.57\% and 0.39\%. A Physics-Informed Neural Network (PINN) then combined data and simulations to predict State of Health (SOH), attaining MAPE under 3\% with quantified uncertainty. This framework elevates BMSs into intelligent systems capable of proactive management and autonomous optimization, advancing safety and reliability in critical applications.
<div id='section'>Paperid: <span id='pid'>899, <a href='https://arxiv.org/pdf/2508.20886.pdf' target='_blank'>https://arxiv.org/pdf/2508.20886.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Himanshu Sharma, LukÃ¡Å¡ NovÃ¡k, Michael D. Shields
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20886">Polynomial Chaos Expansion for Operator Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Operator learning (OL) has emerged as a powerful tool in scientific machine learning (SciML) for approximating mappings between infinite-dimensional functional spaces. One of its main applications is learning the solution operator of partial differential equations (PDEs). While much of the progress in this area has been driven by deep neural network-based approaches such as Deep Operator Networks (DeepONet) and Fourier Neural Operator (FNO), recent work has begun to explore traditional machine learning methods for OL. In this work, we introduce polynomial chaos expansion (PCE) as an OL method. PCE has been widely used for uncertainty quantification (UQ) and has recently gained attention in the context of SciML. For OL, we establish a mathematical framework that enables PCE to approximate operators in both purely data-driven and physics-informed settings. The proposed framework reduces the task of learning the operator to solving a system of equations for the PCE coefficients. Moreover, the framework provides UQ by simply post-processing the PCE coefficients, without any additional computational cost. We apply the proposed method to a diverse set of PDE problems to demonstrate its capabilities. Numerical results demonstrate the strong performance of the proposed method in both OL and UQ tasks, achieving excellent numerical accuracy and computational efficiency.
<div id='section'>Paperid: <span id='pid'>900, <a href='https://arxiv.org/pdf/2508.20612.pdf' target='_blank'>https://arxiv.org/pdf/2508.20612.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aye Phyu Phyu Aung, Lucas Lum, Zhansen Shi, Wen Qiu, Bernice Zee, JM Chin, Yeow Kheng Lim, J. Senthilnath
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20612">Physics Informed Generative Models for Magnetic Field Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In semiconductor manufacturing, defect detection and localization are critical to ensuring product quality and yield. While X-ray imaging is a reliable non-destructive testing method, it is memory-intensive and time-consuming for large-scale scanning, Magnetic Field Imaging (MFI) offers a more efficient means to localize regions of interest (ROI) for targeted X-ray scanning. However, the limited availability of MFI datasets due to proprietary concerns presents a significant bottleneck for training machine learning (ML) models using MFI. To address this challenge, we consider an ML-driven approach leveraging diffusion models with two physical constraints. We propose Physics Informed Generative Models for Magnetic Field Images (PI-GenMFI) to generate synthetic MFI samples by integrating specific physical information. We generate MFI images for the most common defect types: power shorts. These synthetic images will serve as training data for ML algorithms designed to localize defect areas efficiently. To evaluate generated MFIs, we compare our model to SOTA generative models from both variational autoencoder (VAE) and diffusion methods. We present a domain expert evaluation to assess the generated samples. In addition, we present qualitative and quantitative evaluation using various metrics used for image generation and signal processing, showing promising results to optimize the defect localization process.
<div id='section'>Paperid: <span id='pid'>901, <a href='https://arxiv.org/pdf/2508.18653.pdf' target='_blank'>https://arxiv.org/pdf/2508.18653.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoliang Chen, Xin Yu, Le Chang, Teng Jing, Jiashuai He, Ze Wang, Yangjun Luo, Xingyu Chen, Jiayue Liang, Yuchen Wang, Jiaying Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18653">The Sound of Risk: A Multimodal Physics-Informed Acoustic Model for Forecasting Market Volatility and Enhancing Market Interpretability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Information asymmetry in financial markets, often amplified by strategically crafted corporate narratives, undermines the effectiveness of conventional textual analysis. We propose a novel multimodal framework for financial risk assessment that integrates textual sentiment with paralinguistic cues derived from executive vocal tract dynamics in earnings calls. Central to this framework is the Physics-Informed Acoustic Model (PIAM), which applies nonlinear acoustics to robustly extract emotional signatures from raw teleconference sound subject to distortions such as signal clipping. Both acoustic and textual emotional states are projected onto an interpretable three-dimensional Affective State Label (ASL) space-Tension, Stability, and Arousal. Using a dataset of 1,795 earnings calls (approximately 1,800 hours), we construct features capturing dynamic shifts in executive affect between scripted presentation and spontaneous Q&A exchanges. Our key finding reveals a pronounced divergence in predictive capacity: while multimodal features do not forecast directional stock returns, they explain up to 43.8% of the out-of-sample variance in 30-day realized volatility. Importantly, volatility predictions are strongly driven by emotional dynamics during executive transitions from scripted to spontaneous speech, particularly reduced textual stability and heightened acoustic instability from CFOs, and significant arousal variability from CEOs. An ablation study confirms that our multimodal approach substantially outperforms a financials-only baseline, underscoring the complementary contributions of acoustic and textual modalities. By decoding latent markers of uncertainty from verifiable biometric signals, our methodology provides investors and regulators a powerful tool for enhancing market interpretability and identifying hidden corporate uncertainty.
<div id='section'>Paperid: <span id='pid'>902, <a href='https://arxiv.org/pdf/2508.11216.pdf' target='_blank'>https://arxiv.org/pdf/2508.11216.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Han Zhang, Xue-Cheng Tai, Jean-Michel Morel, Raymond H. Chan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.11216">Fluid Dynamics and Domain Reconstruction from Noisy Flow Images Using Physics-Informed Neural Networks and Quasi-Conformal Mapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Blood flow imaging provides important information for hemodynamic behavior within the vascular system and plays an essential role in medical diagnosis and treatment planning. However, obtaining high-quality flow images remains a significant challenge. In this work, we address the problem of denoising flow images that may suffer from artifacts due to short acquisition times or device-induced errors. We formulate this task as an optimization problem, where the objective is to minimize the discrepancy between the modeled velocity field, constrained to satisfy the Navier-Stokes equations, and the observed noisy velocity data. To solve this problem, we decompose it into two subproblems: a fluid subproblem and a geometry subproblem. The fluid subproblem leverages a Physics-Informed Neural Network to reconstruct the velocity field from noisy observations, assuming a fixed domain. The geometry subproblem aims to infer the underlying flow region by optimizing a quasi-conformal mapping that deforms a reference domain. These two subproblems are solved in an alternating Gauss-Seidel fashion, iteratively refining both the velocity field and the domain. Upon convergence, the framework yields a high-quality reconstruction of the flow image. We validate the proposed method through experiments on synthetic flow data in a converging channel geometry under varying levels of Gaussian noise, and on real-like flow data in an aortic geometry with signal-dependent noise. The results demonstrate the effectiveness and robustness of the approach. Additionally, ablation studies are conducted to assess the influence of key hyperparameters.
<div id='section'>Paperid: <span id='pid'>903, <a href='https://arxiv.org/pdf/2508.10921.pdf' target='_blank'>https://arxiv.org/pdf/2508.10921.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiale Linghu, Weifeng Gao, Hao Dong, Yufeng Nie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10921">SO-PIFRNN: Self-optimization physics-informed Fourier-features randomized neural network for solving partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study proposes a self-optimization physics-informed Fourier-features randomized neural network (SO-PIFRNN) framework, which significantly improves the numerical solving accuracy of PDEs through hyperparameter optimization mechanism. The framework employs a bi-level optimization architecture: the outer-level optimization utilizes a multi-strategy collaborated particle swarm optimization (MSC-PSO) algorithm to search for optimal hyperparameters of physics-informed Fourier-features randomized neural network, while the inner-level optimization determines the output layer weights of the neural network via the least squares method. The core innovation of this study is embodied in the following three aspects: First, the Fourier basis function activation mechanism is introduced in the hidden layer of neural network, which significantly enhances the ability of the network to capture multi-frequency components of the solution. Secondly, a novel derivative neural network method is proposed, which improves the calculation accuracy and efficiency of PIFRNN method. Finally, the MSC-PSO algorithm of the hybrid optimization strategy is designed to improve the global search ability and convergence accuracy through the synergistic effect of dynamic parameter adjustment, elitist and mutation strategies. Through a series of numerical experiments, including multiscale equations in complex regions, high-order equations, high-dimensional equations and nonlinear equations, the validity of SO-PIFRNN is verified. The experimental results affirm that SO-PIFRNN exhibits superior approximation accuracy and frequency capture capability.
<div id='section'>Paperid: <span id='pid'>904, <a href='https://arxiv.org/pdf/2508.10555.pdf' target='_blank'>https://arxiv.org/pdf/2508.10555.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoran Sun, Daoqi Liu, Hongyu Zhou, Maokun Li, Shenheng Xu, Fan Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10555">Physics-Informed Deep Contrast Source Inversion: A Unified Framework for Inverse Scattering Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse scattering problems are critical in electromagnetic imaging and medical diagnostics but are challenged by their nonlinearity and diverse measurement scenarios. This paper proposes a physics-informed deep contrast source inversion framework (DeepCSI) for fast and accurate medium reconstruction across various measurement conditions. Inspired by contrast source inversion (CSI) and neural operator methods, a residual multilayer perceptron (ResMLP) is employed to model current distributions in the region of interest under different transmitter excitations, effectively linearizing the nonlinear inverse scattering problem and significantly reducing the computational cost of traditional full-waveform inversion. By modeling medium parameters as learnable tensors and utilizing a hybrid loss function that integrates state equation loss, data equation loss, and total variation regularization, DeepCSI establishes a fully differentiable framework for joint optimization of network parameters and medium properties. Compared with conventional methods, DeepCSI offers advantages in terms of simplicity and universal modeling capabilities for diverse measurement scenarios, including phase-less and multi-frequency observation. Simulations and experiments demonstrate that DeepCSI achieves high-precision, robust reconstruction under full-data, phaseless data, and multifrequency conditions, outperforming traditional CSI methods and providing an efficient and universal solution for complex inverse scattering problems.
<div id='section'>Paperid: <span id='pid'>905, <a href='https://arxiv.org/pdf/2508.07566.pdf' target='_blank'>https://arxiv.org/pdf/2508.07566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Conor K. Trygstad, Cody R. Longwell, Francisco M. F. R. GonÃ§alves, Elijah K. Blankenship, NÃ©stor O. PÃ©rez-Arancibia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07566">Feedback Control of a Single-Tail Bioinspired 59-mg Swimmer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present an evolved steerable version of the single-tail Fish-&-Ribbon-Inspired Small Swimming Harmonic roBot (FRISSHBot), a 59-mg biologically inspired swimmer, which is driven by a new shape-memory alloy (SMA)-based bimorph actuator. The new FRISSHBot is controllable in the two-dimensional (2D) space, which enabled the first demonstration of feedback-controlled trajectory tracking of a single-tail aquatic robot with onboard actuation at the subgram scale. These new capabilities are the result of a physics-informed design with an enlarged head and shortened tail relative to those of the original platform. Enhanced by its design, this new platform achieves forward swimming speeds of up to 13.6 mm/s (0.38 Bl/s), which is over four times that of the original platform. Furthermore, when following 2D references in closed loop, the tested FRISSHBot prototype attains forward swimming speeds of up to 9.1 mm/s, root-mean-square (RMS) tracking errors as low as 2.6 mm, turning rates of up to 13.1 Â°/s, and turning radii as small as 10 mm.
<div id='section'>Paperid: <span id='pid'>906, <a href='https://arxiv.org/pdf/2508.05418.pdf' target='_blank'>https://arxiv.org/pdf/2508.05418.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bharadwaj Dogga, Gibin Raju, Wilhelm Louw, Kelly Cohen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05418">Fuzzy Decisions on Fluid Instabilities: Autoencoder-Based Reconstruction meets Rule-Based Anomaly Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Shockwave classification in shadowgraph imaging is challenging due to limited labeled data and complex flow structures. This study presents a hybrid framework that combines unsupervised autoencoder models with a fuzzy inference system to generate and interpret anomaly maps. Among the evaluated methods, the hybrid $Î²$-VAE autoencoder with a fuzzy rule-based system most effectively captured coherent shock features, integrating spatial context to enhance anomaly classification. The resulting approach enables interpretable, unsupervised classification of flow disruptions and lays the groundwork for real-time, physics-informed diagnostics in experimental and industrial fluid applications.
<div id='section'>Paperid: <span id='pid'>907, <a href='https://arxiv.org/pdf/2508.03774.pdf' target='_blank'>https://arxiv.org/pdf/2508.03774.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Zhu, Yuexing Peng, Peng Wang, George C. Alexandropoulos, Wenbo Wang, Wei Xiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03774">U-PINet: End-to-End Hierarchical Physics-Informed Learning With Sparse Graph Coupling for 3D EM Scattering Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electromagnetic (EM) scattering modeling is critical for radar remote sensing, however, its inherent complexity introduces significant computational challenges. Traditional numerical solvers offer high accuracy, but suffer from scalability issues and substantial computational costs. Pure data-driven deep learning approaches, while efficient, lack physical constraints embedding during training and require extensive labeled data, limiting their applicability and generalization. To overcome these limitations, we propose a U-shaped Physics-Informed Network (U-PINet), the first fully deep-learning-based, physics-informed hierarchical framework for computational EM designed to ensure physical consistency while maximizing computational efficiency. Motivated by the hierarchical decomposition strategy in EM solvers and the inherent sparsity of local EM coupling, the U-PINet models the decomposition and coupling of near- and far-field interactions through a multiscale processing neural network architecture, while employing a physics-inspired sparse graph representation to efficiently model both self- and mutual- coupling among mesh elements of complex $3$-Dimensional (3D) objects. This principled approach enables end-to-end multiscale EM scattering modeling with improved efficiency, generalization, and physical consistency. Experimental results showcase that the U-PINet accurately predicts surface current distributions, achieving close agreement with traditional solver, while significantly reducing computational time and outperforming conventional deep learning baselines in both accuracy and robustness. Furthermore, our evaluations on radar cross section prediction tasks confirm the feasibility of the U-PINet for downstream EM scattering applications.
<div id='section'>Paperid: <span id='pid'>908, <a href='https://arxiv.org/pdf/2508.03315.pdf' target='_blank'>https://arxiv.org/pdf/2508.03315.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Svenja Ehlers, Merten Stender, Norbert Hoffmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03315">Bridging ocean wave physics and deep learning: Physics-informed neural operators for nonlinear wavefield reconstruction in real-time</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate real-time prediction of phase-resolved ocean wave fields remains a critical yet largely unsolved problem, primarily due to the absence of practical data assimilation methods for reconstructing initial conditions from sparse or indirect wave measurements. While recent advances in supervised deep learning have shown potential for this purpose, they require large labelled datasets of ground truth wave data, which are infeasible to obtain in real-world scenarios. To overcome this limitation, we propose a Physics-Informed Neural Operator (PINO) framework for reconstructing spatially and temporally phase-resolved, nonlinear ocean wave fields from sparse measurements, without the need for ground truth data during training. This is achieved by embedding residuals of the free surface boundary conditions of ocean gravity waves into the loss function of the PINO, constraining the solution space in a soft manner. After training, we validate our approach using highly realistic synthetic wave data and demonstrate the accurate reconstruction of nonlinear wave fields from both buoy time series and radar snapshots. Our results indicate that PINOs enable accurate, real-time reconstruction and generalize robustly across a wide range of wave conditions, thereby paving the way for operational, data-driven wave reconstruction and prediction in realistic marine environments.
<div id='section'>Paperid: <span id='pid'>909, <a href='https://arxiv.org/pdf/2508.01720.pdf' target='_blank'>https://arxiv.org/pdf/2508.01720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yeongjong Kim, Namkyeong Cho, Minseok Kim, Yeoneung Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.01720">Physics-informed approach for exploratory Hamilton--Jacobi--Bellman equations via policy iterations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a mesh-free policy iteration framework based on physics-informed neural networks (PINNs) for solving entropy-regularized stochastic control problems. The method iteratively alternates between soft policy evaluation and improvement using automatic differentiation and neural approximation, without relying on spatial discretization. We present a detailed $L^2$ error analysis that decomposes the total approximation error into three sources: iteration error, policy network error, and PDE residual error. The proposed algorithm is validated with a range of challenging control tasks, including high-dimensional linear-quadratic regulation in 5D and 10D, as well as nonlinear systems such as pendulum and cartpole problems. Numerical results confirm the scalability, accuracy, and robustness of our approach across both linear and nonlinear benchmarks.
<div id='section'>Paperid: <span id='pid'>910, <a href='https://arxiv.org/pdf/2508.01718.pdf' target='_blank'>https://arxiv.org/pdf/2508.01718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yeongjong Kim, Yeoneung Kim, Minseok Kim, Namkyeong Cho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.01718">Neural Policy Iteration for Stochastic Optimal Control: A Physics-Informed Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a physics-informed neural network policy iteration (PINN-PI) framework for solving stochastic optimal control problems governed by second-order Hamilton--Jacobi--Bellman (HJB) equations. At each iteration, a neural network is trained to approximate the value function by minimizing the residual of a linear PDE induced by a fixed policy. This linear structure enables systematic $L^2$ error control at each policy evaluation step, and allows us to derive explicit Lipschitz-type bounds that quantify how value gradient errors propagate to the policy updates. This interpretability provides a theoretical basis for evaluating policy quality during training. Our method extends recent deterministic PINN-based approaches to stochastic settings, inheriting the global exponential convergence guarantees of classical policy iteration under mild conditions. We demonstrate the effectiveness of our method on several benchmark problems, including stochastic cartpole, pendulum problems and high-dimensional linear quadratic regulation (LQR) problems in up to 10D.
<div id='section'>Paperid: <span id='pid'>911, <a href='https://arxiv.org/pdf/2507.15386.pdf' target='_blank'>https://arxiv.org/pdf/2507.15386.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juntao Wang, Feng Yin, Tian Ding, Tsung-Hui Chang, Zhi-Quan Luo, Qi Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.15386">Learning to Gridize: Segment Physical World by Wireless Communication Channel</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Gridization, the process of partitioning space into grids where users share similar channel characteristics, serves as a fundamental prerequisite for efficient large-scale network optimization. However, existing methods like Geographical or Beam Space Gridization (GSG or BSG) are limited by reliance on unavailable location data or the flawed assumption that similar signal strengths imply similar channel properties. We propose Channel Space Gridization (CSG), a pioneering framework that unifies channel estimation and gridization for the first time. Formulated as a joint optimization problem, CSG uses only beam-level reference signal received power (RSRP) to estimate Channel Angle Power Spectra (CAPS) and partition samples into grids with homogeneous channel characteristics. To perform CSG, we develop the CSG Autoencoder (CSG-AE), featuring a trainable RSRP-to-CAPS encoder, a learnable sparse codebook quantizer, and a physics-informed decoder based on the Localized Statistical Channel Model. On recognizing the limitations of naive training scheme, we propose a novel Pretraining-Initialization-Detached-Asynchronous (PIDA) training scheme for CSG-AE, ensuring stable and effective training by systematically addressing the common pitfalls of the naive training paradigm. Evaluations reveal that CSG-AE excels in CAPS estimation accuracy and clustering quality on synthetic data. On real-world datasets, it reduces Active Mean Absolute Error (MAE) by 30\% and Overall MAE by 65\% on RSRP prediction accuracy compared to salient baselines using the same data, while improving channel consistency, cluster sizes balance, and active ratio, advancing the development of gridization for large-scale network optimization.
<div id='section'>Paperid: <span id='pid'>912, <a href='https://arxiv.org/pdf/2507.11853.pdf' target='_blank'>https://arxiv.org/pdf/2507.11853.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>J. Senthilnath, Jayasanker Jayabalan, Zhuoyi Lin, Aye Phyu Phyu Aung, Chen Hao, Kaixin Xu, Yeow Kheng Lim, F. C. Wellstood
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11853">A Spatial-Physics Informed Model for 3D Spiral Sample Scanned by SQUID Microscopy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The development of advanced packaging is essential in the semiconductor manufacturing industry. However, non-destructive testing (NDT) of advanced packaging becomes increasingly challenging due to the depth and complexity of the layers involved. In such a scenario, Magnetic field imaging (MFI) enables the imaging of magnetic fields generated by currents. For MFI to be effective in NDT, the magnetic fields must be converted into current density. This conversion has typically relied solely on a Fast Fourier Transform (FFT) for magnetic field inversion; however, the existing approach does not consider eddy current effects or image misalignment in the test setup. In this paper, we present a spatial-physics informed model (SPIM) designed for a 3D spiral sample scanned using Superconducting QUantum Interference Device (SQUID) microscopy. The SPIM encompasses three key components: i) magnetic image enhancement by aligning all the "sharp" wire field signals to mitigate the eddy current effect using both in-phase (I-channel) and quadrature-phase (Q-channel) images; (ii) magnetic image alignment that addresses skew effects caused by any misalignment of the scanning SQUID microscope relative to the wire segments; and (iii) an inversion method for converting magnetic fields to magnetic currents by integrating the Biot-Savart Law with FFT. The results show that the SPIM improves I-channel sharpness by 0.3% and reduces Q-channel sharpness by 25%. Also, we were able to remove rotational and skew misalignments of 0.30 in a real image. Overall, SPIM highlights the potential of combining spatial analysis with physics-driven models in practical applications.
<div id='section'>Paperid: <span id='pid'>913, <a href='https://arxiv.org/pdf/2507.09782.pdf' target='_blank'>https://arxiv.org/pdf/2507.09782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Luthfi Shahab, Fidya Almira Suheri, Rudy Kusdiantara, Hadi Susanto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09782">Physics-informed neural networks for high-dimensional solutions and snaking bifurcations in nonlinear lattices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a framework based on physics-informed neural networks (PINNs) for addressing key challenges in nonlinear lattices, including solution approximation, bifurcation diagram construction, and linear stability analysis. We first employ PINNs to approximate solutions of nonlinear systems arising from lattice models, using the Levenberg-Marquardt algorithm to optimize network weights for greater accuracy. To enhance computational efficiency in high-dimensional settings, we integrate a stochastic sampling strategy. We then extend the method by coupling PINNs with a continuation approach to compute snaking bifurcation diagrams, incorporating an auxiliary equation to effectively track successive solution branches. For linear stability analysis, we adapt PINNs to compute eigenvectors, introducing output constraints to enforce positivity, in line with Sturm-Liouville theory. Numerical experiments are conducted on the discrete Allen-Cahn equation with cubic and quintic nonlinearities in one to five spatial dimensions. The results demonstrate that the proposed approach achieves accuracy comparable to, or better than, traditional numerical methods, especially in high-dimensional regimes where computational resources are a limiting factor. These findings highlight the potential of neural networks as scalable and efficient tools for the study of complex nonlinear lattice systems.
<div id='section'>Paperid: <span id='pid'>914, <a href='https://arxiv.org/pdf/2507.02730.pdf' target='_blank'>https://arxiv.org/pdf/2507.02730.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Miguel Ãngel de Carvalho Servia, Ilya Orson Sandoval, King Kuok, Hii, Klaus Hellgardt, Dongda Zhang, Ehecatl Antonio del Rio Chanona
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02730">Constraint-Guided Symbolic Regression for Data-Efficient Kinetic Model Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The industrialization of catalytic processes hinges on the availability of reliable kinetic models for design, optimization, and control. Traditional mechanistic models demand extensive domain expertise, while many data-driven approaches often lack interpretability and fail to enforce physical consistency. To overcome these limitations, we propose the Physics-Informed Automated Discovery of Kinetics (PI-ADoK) framework. By integrating physical constraints directly into a symbolic regression approach, PI-ADoK narrows the search space and substantially reduces the number of experiments required for model convergence. Additionally, the framework incorporates a robust uncertainty quantification strategy via the Metropolis-Hastings algorithm, which propagates parameter uncertainty to yield credible prediction intervals. Benchmarking our method against conventional approaches across several catalytic case studies demonstrates that PI-ADoK not only enhances model fidelity but also lowers the experimental burden, highlighting its potential for efficient and reliable kinetic model discovery in chemical reaction engineering.
<div id='section'>Paperid: <span id='pid'>915, <a href='https://arxiv.org/pdf/2506.23311.pdf' target='_blank'>https://arxiv.org/pdf/2506.23311.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Perla Mayo, Carolin M. Pirkl, Alin Achim, Bjoern Menze, Mohammad Golbabaee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23311">Physics informed guided diffusion for accelerated multi-parametric MRI reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce MRF-DiPh, a novel physics informed denoising diffusion approach for multiparametric tissue mapping from highly accelerated, transient-state quantitative MRI acquisitions like Magnetic Resonance Fingerprinting (MRF). Our method is derived from a proximal splitting formulation, incorporating a pretrained denoising diffusion model as an effective image prior to regularize the MRF inverse problem. Further, during reconstruction it simultaneously enforces two key physical constraints: (1) k-space measurement consistency and (2) adherence to the Bloch response model. Numerical experiments on in-vivo brain scans data show that MRF-DiPh outperforms deep learning and compressed sensing MRF baselines, providing more accurate parameter maps while better preserving measurement fidelity and physical model consistency-critical for solving reliably inverse problems in medical imaging.
<div id='section'>Paperid: <span id='pid'>916, <a href='https://arxiv.org/pdf/2506.20537.pdf' target='_blank'>https://arxiv.org/pdf/2506.20537.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>R. Sharma, M. Raissi, Y. B. Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.20537">Physics-Informed Machine Learning Regulated by Finite Element Analysis for Simulation Acceleration of Laser Powder Bed Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for process prediction due to the lasting issue of high computation cost using traditional numerical methods such as finite element analysis (FEA). This study presents an efficient modeling framework termed FEA-Regulated Physics-Informed Neural Network (FEA-PINN) to accelerate the thermal field prediction in a LPBF process while maintaining the FEA accuracy. A novel dynamic material updating strategy is developed to capture the dynamic phase change of powder-liquid-solid in the PINN model. The PINN model incorporates temperature-dependent material properties and phase change behavior using the apparent heat capacity method. While the PINN model demonstrates high accuracy with a small training data and enables generalization of new process parameters via transfer learning, it faces the challenge of high computation cost in time-dependent problems due to the residual accumulation. To overcome this issue, the FEA-PINN framework integrates corrective FEA simulations during inference to enforce physical consistency and reduce error drift. A comparative analysis shows that FEA-PINN achieves equivalent accuracy to FEA while significantly reducing computational cost. The framework has been validated using the benchmark FEA data and demonstrated through single-track scanning in LPBF.
<div id='section'>Paperid: <span id='pid'>917, <a href='https://arxiv.org/pdf/2506.19805.pdf' target='_blank'>https://arxiv.org/pdf/2506.19805.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhao Si, Ming Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19805">Convolution-weighting method for the physics-informed neural network: A Primal-Dual Optimization Perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are extensively employed to solve partial differential equations (PDEs) by ensuring that the outputs and gradients of deep learning models adhere to the governing equations. However, constrained by computational limitations, PINNs are typically optimized using a finite set of points, which poses significant challenges in guaranteeing their convergence and accuracy. In this study, we proposed a new weighting scheme that will adaptively change the weights to the loss functions from isolated points to their continuous neighborhood regions. The empirical results show that our weighting scheme can reduce the relative $L^2$ errors to a lower value.
<div id='section'>Paperid: <span id='pid'>918, <a href='https://arxiv.org/pdf/2506.18954.pdf' target='_blank'>https://arxiv.org/pdf/2506.18954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Diego Di Carlo, Mathieu Fontaine, Aditya Arie Nugraha, Yoshiaki Bando, Kazuyoshi Yoshii
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18954">SHAMaNS: Sound Localization with Hybrid Alpha-Stable Spatial Measure and Neural Steerer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper describes a sound source localization (SSL) technique that combines an $Î±$-stable model for the observed signal with a neural network-based approach for modeling steering vectors. Specifically, a physics-informed neural network, referred to as Neural Steerer, is used to interpolate measured steering vectors (SVs) on a fixed microphone array. This allows for a more robust estimation of the so-called $Î±$-stable spatial measure, which represents the most plausible direction of arrival (DOA) of a target signal. As an $Î±$-stable model for the non-Gaussian case ($Î±$ $\in$ (0, 2)) theoretically defines a unique spatial measure, we choose to leverage it to account for residual reconstruction error of the Neural Steerer in the downstream tasks. The objective scores indicate that our proposed technique outperforms state-of-the-art methods in the case of multiple sound sources.
<div id='section'>Paperid: <span id='pid'>919, <a href='https://arxiv.org/pdf/2506.18565.pdf' target='_blank'>https://arxiv.org/pdf/2506.18565.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhongya Lin, Jinshuai Bai, Shuang Li, Xindong Chen, Bo Li, Xi-Qiao Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18565">A Physics-Informed Neural Network Framework for Simulating Creep Buckling in Growing Viscoelastic Biological Tissues</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling viscoelastic behavior is crucial in engineering and biomechanics, where materials undergo time-dependent deformations, including stress relaxation, creep buckling and biological tissue development. Traditional numerical methods, like the finite element method, often require explicit meshing, artificial perturbations or embedding customised programs to capture these phenomena, adding computational complexity. In this study, we develop an energy-based physics-informed neural network (PINN) framework using an incremental approach to model viscoelastic creep, stress relaxation, buckling, and growth-induced morphogenesis. Physics consistency is ensured by training neural networks to minimize the systems potential energy functional, implicitly satisfying equilibrium and constitutive laws. We demonstrate that this framework can naturally capture creep buckling without pre-imposed imperfections, leveraging inherent training dynamics to trigger instabilities. Furthermore, we extend our framework to biological tissue growth and morphogenesis, predicting both uniform expansion and differential growth-induced buckling in cylindrical structures. Results show that the energy-based PINN effectively predicts viscoelastic instabilities, post-buckling evolution and tissue morphological evolution, offering a promising alternative to traditional methods. This study demonstrates that PINN can be a flexible robust tool for modeling complex, time-dependent material behavior, opening possible applications in structural engineering, soft materials, and tissue development.
<div id='section'>Paperid: <span id='pid'>920, <a href='https://arxiv.org/pdf/2506.18247.pdf' target='_blank'>https://arxiv.org/pdf/2506.18247.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manaswin Oddiraju, Bharath Varma Penumatsa, Divyang Amin, Michael Piedmonte, Souma Chowdhury
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.18247">Exploring Efficient Quantification of Modeling Uncertainties with Differentiable Physics-Informed Machine Learning Architectures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantifying and propagating modeling uncertainties is crucial for reliability analysis, robust optimization, and other model-based algorithmic processes in engineering design and control. Now, physics-informed machine learning (PIML) methods have emerged in recent years as a new alternative to traditional computational modeling and surrogate modeling methods, offering a balance between computing efficiency, modeling accuracy, and interpretability. However, their ability to predict and propagate modeling uncertainties remains mostly unexplored. In this paper, a promising class of auto-differentiable hybrid PIML architectures that combine partial physics and neural networks or ANNs (for input transformation or adaptive parameter estimation) is integrated with Bayesian Neural networks (replacing the ANNs); this is done with the goal to explore whether BNNs can successfully provision uncertainty propagation capabilities in the PIML architectures as well, further supported by the auto-differentiability of these architectures. A two-stage training process is used to alleviate the challenges traditionally encountered in training probabilistic ML models. The resulting BNN-integrated PIML architecture is evaluated on an analytical benchmark problem and flight experiments data for a fixed-wing RC aircraft, with prediction performance observed to be slightly worse or at par with purely data-driven ML and original PIML models. Moreover, Monte Carlo sampling of probabilistic BNN weights was found to be most effective in propagating uncertainty in the BNN-integrated PIML architectures.
<div id='section'>Paperid: <span id='pid'>921, <a href='https://arxiv.org/pdf/2506.17755.pdf' target='_blank'>https://arxiv.org/pdf/2506.17755.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinghao Huang, Shengyu Tao, Chen Liang, Jiawei Chen, Junzhe Shi, Yuqi Li, Bizhong Xia, Guangmin Zhou, Xuan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17755">Physics-informed mixture of experts network for interpretable battery degradation trajectory computation amid second-life complexities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Retired electric vehicle batteries offer immense potential to support low-carbon energy systems, but uncertainties in their degradation behavior and data inaccessibilities under second-life use pose major barriers to safe and scalable deployment. This work proposes a Physics-Informed Mixture of Experts (PIMOE) network that computes battery degradation trajectories using partial, field-accessible signals in a single cycle. PIMOE leverages an adaptive multi-degradation prediction module to classify degradation modes using expert weight synthesis underpinned by capacity-voltage and relaxation data, producing latent degradation trend embeddings. These are input to a use-dependent recurrent network for long-term trajectory prediction. Validated on 207 batteries across 77 use conditions and 67,902 cycles, PIMOE achieves an average mean absolute percentage (MAPE) errors of 0.88% with a 0.43 ms inference time. Compared to the state-of-the-art Informer and PatchTST, it reduces computational time and MAPE by 50%, respectively. Compatible with random state of charge region sampling, PIMOE supports 150-cycle forecasts with 1.50% average and 6.26% maximum MAPE, and operates effectively even with pruned 5MB training data. Broadly, PIMOE framework offers a deployable, history-free solution for battery degradation trajectory computation, redefining how second-life energy storage systems are assessed, optimized, and integrated into the sustainable energy landscape.
<div id='section'>Paperid: <span id='pid'>922, <a href='https://arxiv.org/pdf/2506.17626.pdf' target='_blank'>https://arxiv.org/pdf/2506.17626.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan Willem van Beek, Victorita Dolean, Ben Moseley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17626">Local Feature Filtering for Scalable and Well-Conditioned Domain-Decomposed Random Feature Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Random Feature Methods (RFMs) and their variants such as extreme learning machine finite-basis physics-informed neural networks (ELM-FBPINNs) offer a scalable approach for solving partial differential equations (PDEs) by using localized, overlapping and randomly initialized neural network basis functions to approximate the PDE solution and training them to minimize PDE residuals through solving structured least-squares problems. This combination leverages the approximation power of randomized neural networks and the parallelism of domain decomposition. However, the resulting least-squares systems are often severely ill-conditioned, due to local redundancy among random basis functions, which significantly affects the convergence of standard solvers. In this work, we introduce a block rank-revealing QR (RRQR) filtering and preconditioning strategy that operates directly on the structured least-squares problem. First, local RRQR factorizations identify and remove redundant basis functions while preserving numerically informative ones, reducing problem size, and improving conditioning. Second, we use these factorizations to construct a right preconditioner for the global problem which preserves block-sparsity and numerical stability. Third, we derive deterministic bounds of the condition number of the preconditioned system, with probabilistic refinements for small overlaps. We validate our approach on challenging, multi-scale PDE problems in 1D, 2D, and (2+1)D, demonstrating reductions in condition numbers by up to eleven orders of magnitude, LSQR convergence speedups by factors of 10-1000, and higher accuracy than both unpreconditioned and additive Schwarz-preconditioned baselines, all at significantly lower memory and computational cost. These results establish RRQR-based preconditioning as a scalable, accurate, and efficient enhancement for RFM-based PDE solvers.
<div id='section'>Paperid: <span id='pid'>923, <a href='https://arxiv.org/pdf/2506.15960.pdf' target='_blank'>https://arxiv.org/pdf/2506.15960.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>K. Adhikari, Md. Lal Mamud, M. K. Mudunuru, K. B. Nakshatrala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15960">Reactive Transport Modeling with Physics-Informed Machine Learning for Critical Minerals Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a physics-informed neural network (PINN) framework for reactive transport modeling for simulating fast bimolecular reactions in porous media. Accurate characterization of chemical interactions and product formation in surface and subsurface environments is essential for advancing critical mineral extraction and related geoscience applications.
<div id='section'>Paperid: <span id='pid'>924, <a href='https://arxiv.org/pdf/2506.13833.pdf' target='_blank'>https://arxiv.org/pdf/2506.13833.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoliang Chen, Le Chang, Xin Yu, Yunhe Huang, Xianling Tu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13833">A Survey on World Models Grounded in Acoustic Physical Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This survey provides a comprehensive overview of the emerging field of world models grounded in the foundation of acoustic physical information. It examines the theoretical underpinnings, essential methodological frameworks, and recent technological advancements in leveraging acoustic signals for high-fidelity environmental perception, causal physical reasoning, and predictive simulation of dynamic events. The survey explains how acoustic signals, as direct carriers of mechanical wave energy from physical events, encode rich, latent information about material properties, internal geometric structures, and complex interaction dynamics. Specifically, this survey establishes the theoretical foundation by explaining how fundamental physical laws govern the encoding of physical information within acoustic signals. It then reviews the core methodological pillars, including Physics-Informed Neural Networks (PINNs), generative models, and self-supervised multimodal learning frameworks. Furthermore, the survey details the significant applications of acoustic world models in robotics, autonomous driving, healthcare, and finance. Finally, it systematically outlines the important technical and ethical challenges while proposing a concrete roadmap for future research directions toward robust, causal, uncertainty-aware, and responsible acoustic intelligence. These elements collectively point to a research pathway towards embodied active acoustic intelligence, empowering AI systems to construct an internal "intuitive physics" engine through sound.
<div id='section'>Paperid: <span id='pid'>925, <a href='https://arxiv.org/pdf/2506.13678.pdf' target='_blank'>https://arxiv.org/pdf/2506.13678.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Wang, Zhenghong Wang, Fan Zhang, Chaogui Kang, Sijie Ruan, Di Zhu, Chengling Tang, Zhongfu Ma, Weiyu Zhang, Yu Zheng, Philip S. Yu, Yu Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13678">A Gravity-informed Spatiotemporal Transformer for Human Activity Intensity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human activity intensity prediction is crucial to many location-based services. Despite tremendous progress in modeling dynamics of human activity, most existing methods overlook physical constraints of spatial interaction, leading to uninterpretable spatial correlations and over-smoothing phenomenon. To address these limitations, this work proposes a physics-informed deep learning framework, namely Gravity-informed Spatiotemporal Transformer (Gravityformer) by integrating the universal law of gravitation to refine transformer attention. Specifically, it (1) estimates two spatially explicit mass parameters based on spatiotemporal embedding feature, (2) models the spatial interaction in end-to-end neural network using proposed adaptive gravity model to learn the physical constraint, and (3) utilizes the learned spatial interaction to guide and mitigate the over-smoothing phenomenon in transformer attention. Moreover, a parallel spatiotemporal graph convolution transformer is proposed for achieving a balance between coupled spatial and temporal learning. Systematic experiments on six real-world large-scale activity datasets demonstrate the quantitative and qualitative superiority of our model over state-of-the-art benchmarks. Additionally, the learned gravity attention matrix can be not only disentangled and interpreted based on geographical laws, but also improved the generalization in zero-shot cross-region inference. This work provides a novel insight into integrating physical laws with deep learning for spatiotemporal prediction.
<div id='section'>Paperid: <span id='pid'>926, <a href='https://arxiv.org/pdf/2506.12902.pdf' target='_blank'>https://arxiv.org/pdf/2506.12902.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pantelis Dogoulis, Karim Tit, Maxime Cordy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.12902">KCLNet: Physics-Informed Power Flow Prediction via Constraints Projections</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the modern context of power systems, rapid, scalable, and physically plausible power flow predictions are essential for ensuring the grid's safe and efficient operation. While traditional numerical methods have proven robust, they require extensive computation to maintain physical fidelity under dynamic or contingency conditions. In contrast, recent advancements in artificial intelligence (AI) have significantly improved computational speed; however, they often fail to enforce fundamental physical laws during real-world contingencies, resulting in physically implausible predictions. In this work, we introduce KCLNet, a physics-informed graph neural network that incorporates Kirchhoff's Current Law as a hard constraint via hyperplane projections. KCLNet attains competitive prediction accuracy while ensuring zero KCL violations, thereby delivering reliable and physically consistent power flow predictions critical to secure the operation of modern smart grids.
<div id='section'>Paperid: <span id='pid'>927, <a href='https://arxiv.org/pdf/2506.09891.pdf' target='_blank'>https://arxiv.org/pdf/2506.09891.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Hickman, Ilija Trajkovic, Julia Kaltenborn, Francis Pelletier, Alex Archibald, Yaniv Gurwicz, Peer Nowack, David Rolnick, Julien Boussard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09891">Causal Climate Emulation with Bayesian Filtering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional models of climate change use complex systems of coupled equations to simulate physical processes across the Earth system. These simulations are highly computationally expensive, limiting our predictions of climate change and analyses of its causes and effects. Machine learning has the potential to quickly emulate data from climate models, but current approaches are not able to incorporate physics-informed causal relationships. Here, we develop an interpretable climate model emulator based on causal representation learning. We derive a physics-informed approach including a Bayesian filter for stable long-term autoregressive emulation. We demonstrate that our emulator learns accurate climate dynamics, and we show the importance of each one of its components on a realistic synthetic dataset and data from two widely deployed climate models.
<div id='section'>Paperid: <span id='pid'>928, <a href='https://arxiv.org/pdf/2506.00471.pdf' target='_blank'>https://arxiv.org/pdf/2506.00471.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shijun Cheng, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00471">DiffPINN: Generative diffusion-initialized physics-informed neural networks for accelerating seismic wavefield representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) offer a powerful framework for seismic wavefield modeling, yet they typically require time-consuming retraining when applied to different velocity models. Moreover, their training can suffer from slow convergence due to the complexity of of the wavefield solution. To address these challenges, we introduce a latent diffusion-based strategy for rapid and effective PINN initialization. First, we train multiple PINNs to represent frequency-domain scattered wavefields for various velocity models, then flatten each trained network's parameters into a one-dimensional vector, creating a comprehensive parameter dataset. Next, we employ an autoencoder to learn latent representations of these parameter vectors, capturing essential patterns across diverse PINN's parameters. We then train a conditional diffusion model to store the distribution of these latent vectors, with the corresponding velocity models serving as conditions. Once trained, this diffusion model can generate latent vectors corresponding to new velocity models, which are subsequently decoded by the autoencoder into complete PINN parameters. Experimental results indicate that our method significantly accelerates training and maintains high accuracy across in-distribution and out-of-distribution velocity scenarios.
<div id='section'>Paperid: <span id='pid'>929, <a href='https://arxiv.org/pdf/2505.23354.pdf' target='_blank'>https://arxiv.org/pdf/2505.23354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meital Bojan, Sanketh Vedula, Advaith Maddipatla, Nadav Bojan Sellam, Federico Napoli, Paul Schanda, Alex M. Bronstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23354">Representing local protein environments with atomistic foundation models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The local structure of a protein strongly impacts its function and interactions with other molecules. Therefore, a concise, informative representation of a local protein environment is essential for modeling and designing proteins and biomolecular interactions. However, these environments' extensive structural and chemical variability makes them challenging to model, and such representations remain under-explored. In this work, we propose a novel representation for a local protein environment derived from the intermediate features of atomistic foundation models (AFMs). We demonstrate that this embedding effectively captures both local structure (e.g., secondary motifs), and chemical features (e.g., amino-acid identity and protonation state). We further show that the AFM-derived representation space exhibits meaningful structure, enabling the construction of data-driven priors over the distribution of biomolecular environments. Finally, in the context of biomolecular NMR spectroscopy, we demonstrate that the proposed representations enable a first-of-its-kind physics-informed chemical shift predictor that achieves state-of-the-art accuracy. Our results demonstrate the surprising effectiveness of atomistic foundation models and their emergent representations for protein modeling beyond traditional molecular simulations. We believe this will open new lines of work in constructing effective functional representations for protein environments.
<div id='section'>Paperid: <span id='pid'>930, <a href='https://arxiv.org/pdf/2505.23002.pdf' target='_blank'>https://arxiv.org/pdf/2505.23002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiao Zhu, Dmitrii Chaikovskii, Bangti Jin, Ye Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23002">Deep asymptotic expansion method for solving singularly perturbed time-dependent reaction-advection-diffusion equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural network (PINN) has shown great potential in solving partial differential equations. However, it faces challenges when dealing with problems involving steep gradients. The solutions to singularly perturbed time-dependent reaction-advection-diffusion equations exhibit internal moving transition layers with sharp gradients, and thus the standard PINN becomes ineffective. In this work, we propose a deep asymptotic expansion (DAE) method, which is inspired by asymptotic analysis and leverages deep learning to approximate the smooth part of the expansion. We first derive the governing equations for transition layers, which are then solved using PINN. Numerical experiments show that the DAE outperforms the standard PINN, gPINN, and PINN with adaptive sampling. We also show its robustness with respect to training point distributions, network architectures, and random seeds.
<div id='section'>Paperid: <span id='pid'>931, <a href='https://arxiv.org/pdf/2505.22761.pdf' target='_blank'>https://arxiv.org/pdf/2505.22761.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Afila Ajithkumar Sophiya, Akarsh K Nair, Sepehr Maleki, Senthil K. Krishnababu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22761">A comprehensive analysis of PINNs: Variants, Applications, and Challenges</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics Informed Neural Networks (PINNs) have been emerging as a powerful computational tool for solving differential equations. However, the applicability of these models is still in its initial stages and requires more standardization to gain wider popularity. Through this survey, we present a comprehensive overview of PINNs approaches exploring various aspects related to their architecture, variants, areas of application, real-world use cases, challenges, and so on. Even though existing surveys can be identified, they fail to provide a comprehensive view as they primarily focus on either different application scenarios or limit their study to a superficial level. This survey attempts to bridge the gap in the existing literature by presenting a detailed analysis of all these factors combined with recent advancements and state-of-the-art research in PINNs. Additionally, we discuss prevalent challenges in PINNs implementation and present some of the future research directions as well. The overall contributions of the survey can be summarised into three sections: A detailed overview of PINNs architecture and variants, a performance analysis of PINNs on different equations and application domains highlighting their features. Finally, we present a detailed discussion of current issues and future research directions.
<div id='section'>Paperid: <span id='pid'>932, <a href='https://arxiv.org/pdf/2505.19414.pdf' target='_blank'>https://arxiv.org/pdf/2505.19414.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruihang Wang, Zhiwei Cao, Qingang Zhang, Rui Tan, Yonggang Wen, Tommy Leung, Stuart Kennedy, Justin Teoh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19414">Toward Physics-Informed Machine Learning for Data Center Operations: A Tropical Case Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data centers are the backbone of computing capacity. Operating data centers in the tropical regions faces unique challenges due to consistently high ambient temperature and elevated relative humidity throughout the year. These conditions result in increased cooling costs to maintain the reliability of the computing systems. While existing machine learning-based approaches have demonstrated potential to elevate operations to a more proactive and intelligent level, their deployment remains dubious due to concerns about model extrapolation capabilities and associated system safety issues. To address these concerns, this article proposes incorporating the physical characteristics of data centers into traditional data-driven machine learning solutions. We begin by introducing the data center system, including the relevant multiphysics processes and the data-physics availability. Next, we outline the associated modeling and optimization problems and propose an integrated, physics-informed machine learning system to address them. Using the proposed system, we present relevant applications across varying levels of operational intelligence. A case study on an industry-grade tropical data center is provided to demonstrate the effectiveness of our approach. Finally, we discuss key challenges and highlight potential future directions.
<div id='section'>Paperid: <span id='pid'>933, <a href='https://arxiv.org/pdf/2505.17308.pdf' target='_blank'>https://arxiv.org/pdf/2505.17308.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Philipp Pilar, Markus Heinonen, Niklas WahlstrÃ¶m
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17308">Repulsive Ensembles for Bayesian Inference in Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have proven an effective tool for solving differential equations, in particular when considering non-standard or ill-posed settings. When inferring solutions and parameters of the differential equation from data, uncertainty estimates are preferable to point estimates, as they give an idea about the accuracy of the solution. In this work, we consider the inverse problem and employ repulsive ensembles of PINNs (RE-PINN) for obtaining such estimates. The repulsion is implemented by adding a particular repulsive term to the loss function, which has the property that the ensemble predictions correspond to the true Bayesian posterior in the limit of infinite ensemble members. Where possible, we compare the ensemble predictions to Monte Carlo baselines. Whereas the standard ensemble tends to collapse to maximum-a-posteriori solutions, the repulsive ensemble produces significantly more accurate uncertainty estimates and exhibits higher sample diversity.
<div id='section'>Paperid: <span id='pid'>934, <a href='https://arxiv.org/pdf/2505.16035.pdf' target='_blank'>https://arxiv.org/pdf/2505.16035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alejandro GarcÃ­a-Castellanos, David R. Wessels, Nicky J. van den Berg, Remco Duits, DaniÃ«l M. Pelt, Erik J. Bekkers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16035">Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Equivariant Neural Eikonal Solvers, a novel framework that integrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our approach employs a single neural field where a unified shared backbone is conditioned on signal-specific latent variables - represented as point clouds in a Lie group - to model diverse Eikonal solutions. The ENF integration ensures equivariant mapping from these latent representations to the solution field, delivering three key benefits: enhanced representation efficiency through weight-sharing, robust geometric grounding, and solution steerability. This steerability allows transformations applied to the latent point cloud to induce predictable, geometrically meaningful modifications in the resulting Eikonal solution. By coupling these steerable representations with Physics-Informed Neural Networks (PINNs), our framework accurately models Eikonal travel-time solutions while generalizing to arbitrary Riemannian manifolds with regular group actions. This includes homogeneous spaces such as Euclidean, position-orientation, spherical, and hyperbolic manifolds. We validate our approach through applications in seismic travel-time modeling of 2D and 3D benchmark datasets. Experimental results demonstrate superior performance, scalability, adaptability, and user controllability compared to existing Neural Operator-based Eikonal solver methods.
<div id='section'>Paperid: <span id='pid'>935, <a href='https://arxiv.org/pdf/2505.13241.pdf' target='_blank'>https://arxiv.org/pdf/2505.13241.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuan-Zheng Lei, Yaobang Gong, Dianwei Chen, Yao Cheng, Xianfeng Terry Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13241">Reconstructing Physics-Informed Machine Learning for Traffic Flow Modeling: a Multi-Gradient Descent and Pareto Learning Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning (PIML) is crucial in modern traffic flow modeling because it combines the benefits of both physics-based and data-driven approaches. In conventional PIML, physical information is typically incorporated by constructing a hybrid loss function that combines data-driven loss and physics loss through linear scalarization. The goal is to find a trade-off between these two objectives to improve the accuracy of model predictions. However, from a mathematical perspective, linear scalarization is limited to identifying only the convex region of the Pareto front, as it treats data-driven and physics losses as separate objectives. Given that most PIML loss functions are non-convex, linear scalarization restricts the achievable trade-off solutions. Moreover, tuning the weighting coefficients for the two loss components can be both time-consuming and computationally challenging. To address these limitations, this paper introduces a paradigm shift in PIML by reformulating the training process as a multi-objective optimization problem, treating data-driven loss and physics loss independently. We apply several multi-gradient descent algorithms (MGDAs), including traditional multi-gradient descent (TMGD) and dual cone gradient descent (DCGD), to explore the Pareto front in this multi-objective setting. These methods are evaluated on both macroscopic and microscopic traffic flow models. In the macroscopic case, MGDAs achieved comparable performance to traditional linear scalarization methods. Notably, in the microscopic case, MGDAs significantly outperformed their scalarization-based counterparts, demonstrating the advantages of a multi-objective optimization approach in complex PIML scenarios.
<div id='section'>Paperid: <span id='pid'>936, <a href='https://arxiv.org/pdf/2505.11755.pdf' target='_blank'>https://arxiv.org/pdf/2505.11755.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew Kim, William Sharpless, Hyun Joe Jeong, Sander Tonkens, Somil Bansal, Sylvia Herbert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11755">Reachability Barrier Networks: Learning Hamilton-Jacobi Solutions for Smooth and Flexible Control Barrier Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent developments in autonomous driving and robotics underscore the necessity of safety-critical controllers. Control barrier functions (CBFs) are a popular method for appending safety guarantees to a general control framework, but they are notoriously difficult to generate beyond low dimensions. Existing methods often yield non-differentiable or inaccurate approximations that lack integrity, and thus fail to ensure safety. In this work, we use physics-informed neural networks (PINNs) to generate smooth approximations of CBFs by computing Hamilton-Jacobi (HJ) optimal control solutions. These reachability barrier networks (RBNs) avoid traditional dimensionality constraints and support the tuning of their conservativeness post-training through a parameterized discount term. To ensure robustness of the discounted solutions, we leverage conformal prediction methods to derive probabilistic safety guarantees for RBNs. We demonstrate that RBNs are highly accurate in low dimensions, and safer than the standard neural CBF approach in high dimensions. Namely, we showcase the RBNs in a 9D multi-vehicle collision avoidance problem where it empirically proves to be 5.5x safer and 1.9x less conservative than the neural CBFs, offering a promising method to synthesize CBFs for general nonlinear autonomous systems.
<div id='section'>Paperid: <span id='pid'>937, <a href='https://arxiv.org/pdf/2505.11491.pdf' target='_blank'>https://arxiv.org/pdf/2505.11491.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuan-Zheng Lei, Yaobang Gong, Dianwei Chen, Yao Cheng, Xianfeng Terry Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11491">Potential failures of physics-informed machine learning in traffic flow modeling: theoretical and experimental analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates why physics-informed machine learning (PIML) can fail in macroscopic traffic flow modeling. We define failure as cases where a PIML model underperforms both purely data-driven and purely physics-based baselines by a given threshold. Unlike in other fields, physics residuals themselves do not hinder optimization in this setting. Instead, effective updates require both data and physics gradients to form acute angles with the true gradient, a condition difficult to satisfy with low-resolution loop data. In such cases, neural networks cannot accurately approximate density and speed, and the constructed physics residuals, already degraded by discrete sampling and temporal averaging, lose their ability to capture PDE dynamics, which directly leads to PIML failure. Theoretically, although LWR and ARZ solutions are weak solutions, for piecewise $C^k$ initial data they remain $C^k$ off the shock set under mild conditions, which has Lebesgue measure zero. Thus, almost all detector or collocation points lie in smooth regions where residuals are valid, and the MLP's inability to exactly represent discontinuities is immaterial. Finally, we establish MSE lower bounds of physics residuals: higher-order models such as ARZ have strictly larger consistency error bounds than LWR under mild conditions. This explains why LWR-based PIML can outperform ARZ-based PIML even with high-resolution data, with the gap shrinking as resolution increases, consistent with prior empirical findings.
<div id='section'>Paperid: <span id='pid'>938, <a href='https://arxiv.org/pdf/2505.06331.pdf' target='_blank'>https://arxiv.org/pdf/2505.06331.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Feilong Jiang, Xiaonan Hou, Jianqiao Ye, Min Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06331">Mask-PINNs: Mitigating Internal Covariate Shift in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical laws directly into the loss function. However, as a fundamental optimization issue, internal covariate shift (ICS) hinders the stable and effective training of PINNs by disrupting feature distributions and limiting model expressiveness. Unlike standard deep learning tasks, conventional remedies for ICS -- such as Batch Normalization and Layer Normalization -- are not directly applicable to PINNs, as they distort the physical consistency required for reliable PDE solutions. To address this issue, we propose Mask-PINNs, a novel architecture that introduces a learnable mask function to regulate feature distributions while preserving the underlying physical constraints of PINNs. We provide a theoretical analysis showing that the mask suppresses the expansion of feature representations through a carefully designed modulation mechanism. Empirically, we validate the method on multiple PDE benchmarks -- including convection, wave propagation, and Helmholtz equations -- across diverse activation functions. Our results show consistent improvements in prediction accuracy, convergence stability, and robustness. Furthermore, we demonstrate that Mask-PINNs enable the effective use of wider networks, overcoming a key limitation in existing PINN frameworks.
<div id='section'>Paperid: <span id='pid'>939, <a href='https://arxiv.org/pdf/2505.05625.pdf' target='_blank'>https://arxiv.org/pdf/2505.05625.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenqing Peng, Zhi-Song Liu, Michael Boy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.05625">SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating rate coefficients from complex chemical reactions is essential for advancing detailed chemistry. However, the stiffness inherent in real-world atmospheric chemistry systems poses severe challenges, leading to training instability and poor convergence, which hinder effective rate coefficient estimation using learning-based approaches. To address this, we propose a Stiff Physics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction modelling. Our method introduces a three-stage optimisation process: first, a black-box neural ODE is trained to fit concentration trajectories; second, a Chemical Reaction Neural Network (CRNN) is pre-trained to learn the mapping between concentrations and their time derivatives; and third, the rate coefficients are fine-tuned by integrating with the pre-trained CRNN. Extensive experiments on both synthetic and newly proposed real-world datasets validate the effectiveness and robustness of our approach. As the first work addressing stiff neural ODE for chemical rate coefficient discovery, our study opens promising directions for integrating neural networks with detailed chemistry.
<div id='section'>Paperid: <span id='pid'>940, <a href='https://arxiv.org/pdf/2505.05625.pdf' target='_blank'>https://arxiv.org/pdf/2505.05625.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenqing Peng, Zhi-Song Liu, Michael Boy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.05625">SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating rate coefficients from complex chemical reactions is essential for advancing detailed chemistry. However, the stiffness inherent in real-world atmospheric chemistry systems poses severe challenges, leading to training instability and poor convergence, which hinder effective rate coefficient estimation using learning-based approaches. To address this, we propose a Stiff Physics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction modelling. Our method introduces a three-stage optimisation process: first, a black-box neural ODE is trained to fit concentration trajectories; second, a Chemical Reaction Neural Network (CRNN) is pre-trained to learn the mapping between concentrations and their time derivatives; and third, the rate coefficients are fine-tuned by integrating with the pre-trained CRNN. Extensive experiments on both synthetic and newly proposed real-world datasets validate the effectiveness and robustness of our approach. As the first work addressing stiff neural ODE for chemical rate coefficient discovery, our study opens promising directions for integrating neural networks with detailed chemistry.
<div id='section'>Paperid: <span id='pid'>941, <a href='https://arxiv.org/pdf/2505.03783.pdf' target='_blank'>https://arxiv.org/pdf/2505.03783.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tian Chen, Shengping Liu, Li Liu, Heng Yong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03783">A general physics-constrained method for the modelling of equation's closure terms with sparse data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate modeling of closure terms is a critical challenge in engineering and scientific research, particularly when data is sparse (scarse or incomplete), making widely applicable models difficult to develop. This study proposes a novel approach for constructing closure models in such challenging scenarios. We introduce a Series-Parallel Multi-Network Architecture that integrates Physics-Informed Neural Networks (PINNs) to incorporate physical constraints and heterogeneous data from multiple initial and boundary conditions, while employing dedicated subnetworks to independently model unknown closure terms, enhancing generalizability across diverse problems. These closure models are integrated into an accurate Partial Differential Equation (PDE) solver, enabling robust solutions to complex predictive simulations in engineering applications.
<div id='section'>Paperid: <span id='pid'>942, <a href='https://arxiv.org/pdf/2505.01424.pdf' target='_blank'>https://arxiv.org/pdf/2505.01424.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>D. Patel, R. Sharma, Y. B. Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.01424">Computational, Data-Driven, and Physics-Informed Machine Learning Approaches for Microstructure Modeling in Metal Additive Manufacturing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Metal additive manufacturing enables unprecedented design freedom and the production of customized, complex components. However, the rapid melting and solidification dynamics inherent to metal AM processes generate heterogeneous, non-equilibrium microstructures that significantly impact mechanical properties and subsequent functionality. Predicting microstructure and its evolution across spatial and temporal scales remains a central challenge for process optimization and defect mitigation. While conventional experimental techniques and physics-based simulations provide a physical foundation and valuable insights, they face critical limitations. In contrast, data-driven machine learning offers an alternative prediction approach and powerful pattern recognition but often operate as black-box, lacking generalizability and physical consistency. To overcome these limitations, physics-informed machine learning, including physics-informed neural networks, has emerged as a promising paradigm by embedding governing physical laws into neural network architectures, thereby enhancing accuracy, transparency, data efficiency, and extrapolation capabilities. This work presents a comprehensive evaluation of modeling strategies for microstructure prediction in metal AM. The strengths and limitations of experimental, computational, and data-driven methods are analyzed in depth, and highlight recent advances in hybrid PIML frameworks that integrate physical knowledge with ML. Key challenges, such as data scarcity, multi-scale coupling, and uncertainty quantification, are discussed alongside future directions. Ultimately, this assessment underscores the importance of PIML-based hybrid approaches in enabling predictive, scalable, and physically consistent microstructure modeling for site-specific, microstructure-aware process control and the reliable production of high-performance AM components.
<div id='section'>Paperid: <span id='pid'>943, <a href='https://arxiv.org/pdf/2504.13875.pdf' target='_blank'>https://arxiv.org/pdf/2504.13875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>N. Sibuet, S. Ares de Parga, J. R. Bravo, R. Rossi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13875">A discrete physics-informed training for projection-based reduced order models with neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a physics-informed training framework for projection-based Reduced Order Models (ROMs). We extend the PROM-ANN architecture by complementing snapshot-based training with a FEM-based, discrete physics-informed residual loss, bridging the gap between traditional projection-based ROMs and physics-informed neural networks (PINNs). Unlike conventional PINNs that rely on analytical PDEs, our approach leverages FEM residuals to guide the learning of the ROM approximation manifold. Key contributions include: (1) a parameter-agnostic, discrete residual loss applicable to non-linear problems, (2) an architectural modification to PROM-ANN improving accuracy for fast-decaying singular values, and (3) an empirical study on the proposed physics informed training process for ROMs.
  The method is demonstrated on a non-linear hyperelasticity problem, simulating a rubber cantilever under multi-axial loads. The main accomplishment in regards to the proposed residual-based loss is its applicability on non-linear problems by interfacing with FEM software while maintaining reasonable training times. The modified PROM-ANN outperforms POD by orders of magnitude in snapshot reconstruction accuracy, while the original formulation is not able to learn a proper mapping for this use-case. Finally, the application of physics informed training in ANN-PROM modestly narrows the gap between data reconstruction and ROM accuracy, however it highlights the untapped potential of the proposed residual-driven optimization for future ROM development. This work underscores the critical role of FEM residuals in ROM construction and calls for further exploration on architectures beyond PROM-ANN.
<div id='section'>Paperid: <span id='pid'>944, <a href='https://arxiv.org/pdf/2504.06327.pdf' target='_blank'>https://arxiv.org/pdf/2504.06327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Kashefi, Tapan Mukerji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.06327">Physics-informed KAN PointNet: Deep learning for simultaneous solutions to inverse problems in incompressible flow on numerous irregular geometries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kolmogorov-Arnold Networks (KANs) have gained attention as an alternative to traditional multilayer perceptrons (MLPs) for deep learning applications in computational physics, particularly for solving inverse problems with sparse data, as exemplified by the physics-informed Kolmogorov-Arnold network (PIKAN). However, the capability of KANs to simultaneously solve inverse problems over multiple irregular geometries within a single training run remains unexplored. To address this gap, we introduce the physics-informed Kolmogorov-Arnold PointNet (PI-KAN-PointNet), in which shared KANs are integrated into the PointNet architecture to capture the geometric features of computational domains. The loss function comprises the squared residuals of the governing equations, computed via automatic differentiation, along with sparse observations and partially known boundary conditions. We construct shared KANs using Jacobi polynomials and investigate their performance by considering Jacobi polynomials of different degrees and types in terms of both computational cost and prediction accuracy. As a benchmark test case, we consider natural convection in a square enclosure with a cylinder, where the cylinder's shape varies across a dataset of 135 geometries. PI-KAN-PointNet offers two main advantages. First, it overcomes the limitation of current PIKANs, which are restricted to solving only a single computational domain per training run, thereby reducing computational costs. Second, when comparing the performance of PI-KAN-PointNet with that of the physics-informed PointNet using MLPs, we observe that, with approximately the same number of trainable parameters and comparable computational cost in terms of the number of epochs, training time per epoch, and memory usage, PI-KAN-PointNet yields more accurate predictions, particularly for values on unknown boundary conditions involving nonsmooth geometries.
<div id='section'>Paperid: <span id='pid'>945, <a href='https://arxiv.org/pdf/2504.01913.pdf' target='_blank'>https://arxiv.org/pdf/2504.01913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyu Ni, Jingrui Xing, Xingqiao Li, Bin Wang, Baoquan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01913">Representing Flow Fields with Divergence-Free Kernels for Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately reconstructing continuous flow fields from sparse or indirect measurements remains an open challenge, as existing techniques often suffer from oversmoothing artifacts, reliance on heterogeneous architectures, and the computational burden of enforcing physics-informed losses in implicit neural representations (INRs). In this paper, we introduce a novel flow field reconstruction framework based on divergence-free kernels (DFKs), which inherently enforce incompressibility while capturing fine structures without relying on hierarchical or heterogeneous representations. Through qualitative analysis and quantitative ablation studies, we identify the matrix-valued radial basis functions derived from Wendland's $\mathcal{C}^4$ polynomial (DFKs-Wen4) as the optimal form of analytically divergence-free approximation for velocity fields, owing to their favorable numerical properties, including compact support, positive definiteness, and second-order differentiablility. Experiments across various reconstruction tasks, spanning data compression, inpainting, super-resolution, and time-continuous flow inference, has demonstrated that DFKs-Wen4 outperform INRs and other divergence-free representations in both reconstruction accuracy and computational efficiency while requiring the fewest trainable parameters.
<div id='section'>Paperid: <span id='pid'>946, <a href='https://arxiv.org/pdf/2503.17973.pdf' target='_blank'>https://arxiv.org/pdf/2503.17973.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanxiao Jiang, Hao-Yu Hsu, Kaifeng Zhang, Hsin-Ni Yu, Shenlong Wang, Yunzhu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17973">PhysTwin: Physics-Informed Reconstruction and Simulation of Deformable Objects from Videos</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Creating a physical digital twin of a real-world object has immense potential in robotics, content creation, and XR. In this paper, we present PhysTwin, a novel framework that uses sparse videos of dynamic objects under interaction to produce a photo- and physically realistic, real-time interactive virtual replica. Our approach centers on two key components: (1) a physics-informed representation that combines spring-mass models for realistic physical simulation, generative shape models for geometry, and Gaussian splats for rendering; and (2) a novel multi-stage, optimization-based inverse modeling framework that reconstructs complete geometry, infers dense physical properties, and replicates realistic appearance from videos. Our method integrates an inverse physics framework with visual perception cues, enabling high-fidelity reconstruction even from partial, occluded, and limited viewpoints. PhysTwin supports modeling various deformable objects, including ropes, stuffed animals, cloth, and delivery packages. Experiments show that PhysTwin outperforms competing methods in reconstruction, rendering, future prediction, and simulation under novel interactions. We further demonstrate its applications in interactive real-time simulation and model-based robotic motion planning.
<div id='section'>Paperid: <span id='pid'>947, <a href='https://arxiv.org/pdf/2503.17379.pdf' target='_blank'>https://arxiv.org/pdf/2503.17379.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jassem Abbasi, Ameya D. Jagtap, Ben Moseley, Aksel Hiorth, PÃ¥l ÃstebÃ¸ Andersen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17379">Challenges and Advancements in Modeling Shock Fronts with Physics-Informed Neural Networks: A Review and Benchmarking Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving partial differential equations (PDEs) with discontinuous solutions , such as shock waves in multiphase viscous flow in porous media , is critical for a wide range of scientific and engineering applications, as they represent sudden changes in physical quantities. Physics-Informed Neural Networks (PINNs), an approach proposed for solving PDEs, encounter significant challenges when applied to such systems. Accurately solving PDEs with discontinuities using PINNs requires specialized techniques to ensure effective solution accuracy and numerical stability. A benchmarking study was conducted on two multiphase flow problems in porous media: the classic Buckley-Leverett (BL) problem and a fully coupled system of equations involving shock waves but with varying levels of solution complexity. The findings show that PM and LM approaches can provide accurate solutions for the BL problem by effectively addressing the infinite gradients associated with shock occurrences. In contrast, AM methods failed to effectively resolve the shock waves. When applied to fully coupled PDEs (with more complex loss landscape), the generalization error in the solutions quickly increased, highlighting the need for ongoing innovation. This study provides a comprehensive review of existing techniques for managing PDE discontinuities using PINNs, offering information on their strengths and limitations. The results underscore the necessity for further research to improve PINNs ability to handle complex discontinuities, particularly in more challenging problems with complex loss landscapes. This includes problems involving higher dimensions or multiphysics systems, where current methods often struggle to maintain accuracy and efficiency.
<div id='section'>Paperid: <span id='pid'>948, <a href='https://arxiv.org/pdf/2503.15679.pdf' target='_blank'>https://arxiv.org/pdf/2503.15679.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahul Sundar, Didier Lucor, Sunetra Sarkar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15679">Sequential learning based PINNs to overcome temporal domain complexities in unsteady flow past flapping wings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For a data-driven and physics combined modelling of unsteady flow systems with moving immersed boundaries, Sundar {\it et al.} introduced an immersed boundary-aware (IBA) framework, combining Physics-Informed Neural Networks (PINNs) and the immersed boundary method (IBM). This approach was beneficial because it avoided case-specific transformations to a body-attached reference frame. Building on this, we now address the challenges of long time integration in velocity reconstruction and pressure recovery by extending this IBA framework with sequential learning strategies. Key difficulties for PINNs in long time integration include temporal sparsity, long temporal domains and rich spectral content. To tackle these, a moving boundary-enabled PINN is developed, proposing two sequential learning strategies: - a time marching with gradual increase in time domain size, however, this approach struggles with error accumulation over long time domains; and - a time decomposition which divides the temporal domain into smaller segments, combined with transfer learning it effectively reduces error propagation and computational complexity. The key findings for modelling of incompressible unsteady flows past a flapping airfoil include: - for quasi-periodic flows, the time decomposition approach with preferential spatio-temporal sampling improves accuracy and efficiency for pressure recovery and aerodynamic load reconstruction, and, - for long time domains, decomposing it into smaller temporal segments and employing multiple sub-networks, simplifies the problem ensuring stability and reduced network sizes. This study highlights the limitations of traditional PINNs for long time integration of flow-structure interaction problems and demonstrates the benefits of decomposition-based strategies for addressing error accumulation, computational cost, and complex dynamics.
<div id='section'>Paperid: <span id='pid'>949, <a href='https://arxiv.org/pdf/2503.08482.pdf' target='_blank'>https://arxiv.org/pdf/2503.08482.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pouya Shaeri, Saud AlKhaled, Ariane Middel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08482">A Multimodal Physics-Informed Neural Network Approach for Mean Radiant Temperature Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Outdoor thermal comfort is a critical determinant of urban livability, particularly in hot desert climates where extreme heat poses challenges to public health, energy consumption, and urban planning. Mean Radiant Temperature ($T_{mrt}$) is a key parameter for evaluating outdoor thermal comfort, especially in urban environments where radiation dynamics significantly impact human thermal exposure. Traditional methods of estimating $T_{mrt}$ rely on field measurements and computational simulations, both of which are resource intensive. This study introduces a Physics-Informed Neural Network (PINN) approach that integrates shortwave and longwave radiation modeling with deep learning techniques. By leveraging a multimodal dataset that includes meteorological data, built environment characteristics, and fisheye image-derived shading information, our model enhances predictive accuracy while maintaining physical consistency. Our experimental results demonstrate that the proposed PINN framework outperforms conventional deep learning models, with the best-performing configurations achieving an RMSE of 3.50 and an $R^2$ of 0.88. This approach highlights the potential of physics-informed machine learning in bridging the gap between computational modeling and real-world applications, offering a scalable and interpretable solution for urban thermal comfort assessments.
<div id='section'>Paperid: <span id='pid'>950, <a href='https://arxiv.org/pdf/2502.19890.pdf' target='_blank'>https://arxiv.org/pdf/2502.19890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minseok Kim, Yeongjong Kim, Yeoneung Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19890">Physics-Informed Neural Networks for Optimal Vaccination Plan in SIR Epidemic Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work focuses on understanding the minimum eradication time for the controlled Susceptible-Infectious-Recovered (SIR) model in the time-homogeneous setting, where the infection and recovery rates are constant. The eradication time is defined as the earliest time the infectious population drops below a given threshold and remains below it. For time-homogeneous models, the eradication time is well-defined due to the predictable dynamics of the infectious population, and optimal control strategies can be systematically studied. We utilize Physics-Informed Neural Networks (PINNs) to solve the partial differential equation (PDE) governing the eradication time and derive the corresponding optimal vaccination control. The PINN framework enables a mesh-free solution to the PDE by embedding the dynamics directly into the loss function of a deep neural network. We use a variable scaling method to ensure stable training of PINN and mathematically analyze that this method is effective in our setting. This approach provides an efficient computational alternative to traditional numerical methods, allowing for an approximation of the eradication time and the optimal control strategy. Through numerical experiments, we validate the effectiveness of the proposed method in computing the minimum eradication time and achieving optimal control. This work offers a novel application of PINNs to epidemic modeling, bridging mathematical theory and computational practice for time-homogeneous SIR models.
<div id='section'>Paperid: <span id='pid'>951, <a href='https://arxiv.org/pdf/2502.19543.pdf' target='_blank'>https://arxiv.org/pdf/2502.19543.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Biao Yuan, He Wang, Yanjie Song, Ana Heitor, Xiaohui Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19543">High-fidelity Multiphysics Modelling for Rapid Predictions Using Physics-informed Parallel Neural Operator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modelling complex multiphysics systems governed by nonlinear and strongly coupled partial differential equations (PDEs) is a cornerstone in computational science and engineering. However, it remains a formidable challenge for traditional numerical solvers due to high computational cost, making them impractical for large-scale applications. Neural operators' reliance on data-driven training limits their applicability in real-world scenarios, as data is often scarce or expensive to obtain. Here, we propose a novel paradigm, physics-informed parallel neural operator (PIPNO), a scalable and unsupervised learning framework that enables data-free PDE modelling by leveraging only governing physical laws. The parallel kernel integration design, incorporating ensemble learning, significantly enhances both compatibility and computational efficiency, enabling scalable operator learning for nonlinear and strongly coupled PDEs. PIPNO efficiently captures nonlinear operator mappings across diverse physics, including geotechnical engineering, material science, electromagnetism, quantum mechanics, and fluid dynamics. The proposed method achieves high-fidelity and rapid predictions, outperforming existing operator learning approaches in modelling nonlinear and strongly coupled multiphysics systems. Therefore, PIPNO offers a powerful alternative to conventional solvers, broadening the applicability of neural operators for multiphysics modelling while ensuring efficiency, robustness, and scalability.
<div id='section'>Paperid: <span id='pid'>952, <a href='https://arxiv.org/pdf/2502.04917.pdf' target='_blank'>https://arxiv.org/pdf/2502.04917.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhao Si, Ming Yan, Xin Li, Zhihong Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.04917">Complex Physics-Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose compleX-PINN, a novel physics-informed neural network (PINN) architecture incorporating a learnable activation function inspired by the Cauchy integral theorem. By optimizing the activation parameters, compleX-PINN achieves high accuracy with just a single hidden layer. Empirically, we demonstrate that compleX-PINN solves high-dimensional problems that pose significant challenges for PINNs. Our results show that compleX-PINN consistently achieves substantially greater precision, often improving accuracy by an order of magnitude, on these complex tasks.
<div id='section'>Paperid: <span id='pid'>953, <a href='https://arxiv.org/pdf/2502.00897.pdf' target='_blank'>https://arxiv.org/pdf/2502.00897.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shijun Cheng, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00897">Multi-frequency wavefield solutions for variable velocity models using meta-learning enhanced low-rank physics-informed neural network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) face significant challenges in modeling multi-frequency wavefields in complex velocity models due to their slow convergence, difficulty in representing high-frequency details, and lack of generalization to varying frequencies and velocity scenarios. To address these issues, we propose Meta-LRPINN, a novel framework that combines low-rank parameterization using singular value decomposition (SVD) with meta-learning and frequency embedding. Specifically, we decompose the weights of PINN's hidden layers using SVD and introduce an innovative frequency embedding hypernetwork (FEH) that links input frequencies with the singular values, enabling efficient and frequency-adaptive wavefield representation. Meta-learning is employed to provide robust initialization, improving optimization stability and reducing training time. Additionally, we implement adaptive rank reduction and FEH pruning during the meta-testing phase to further enhance efficiency. Numerical experiments, which are presented on multi-frequency scattered wavefields for different velocity models, demonstrate that Meta-LRPINN achieves much fast convergence speed and much high accuracy compared to baseline methods such as Meta-PINN and vanilla PINN. Also, the proposed framework shows strong generalization to out-of-distribution frequencies while maintaining computational efficiency. These results highlight the potential of our Meta-LRPINN for scalable and adaptable seismic wavefield modeling.
<div id='section'>Paperid: <span id='pid'>954, <a href='https://arxiv.org/pdf/2501.17110.pdf' target='_blank'>https://arxiv.org/pdf/2501.17110.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ricardo Baptista, Edoardo Calvello, Matthieu Darcy, Houman Owhadi, Andrew M. Stuart, Xianjin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17110">Solving Roughly Forced Nonlinear PDEs via Misspecified Kernel Methods and Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the use of Gaussian Processes (GPs) or Neural Networks (NNs) to numerically approximate the solutions to nonlinear partial differential equations (PDEs) with rough forcing or source terms, which commonly arise as pathwise solutions to stochastic PDEs. Kernel methods have recently been generalized to solve nonlinear PDEs by approximating their solutions as the maximum a posteriori estimator of GPs that are conditioned to satisfy the PDE at a finite set of collocation points. The convergence and error guarantees of these methods, however, rely on the PDE being defined in a classical sense and its solution possessing sufficient regularity to belong to the associated reproducing kernel Hilbert space. We propose a generalization of these methods to handle roughly forced nonlinear PDEs while preserving convergence guarantees with an oversmoothing GP kernel that is misspecified relative to the true solution's regularity. This is achieved by conditioning a regular GP to satisfy the PDE with a modified source term in a weak sense (when integrated against a finite number of test functions). This is equivalent to replacing the empirical $L^2$-loss on the PDE constraint by an empirical negative-Sobolev norm. We further show that this loss function can be used to extend physics-informed neural networks (PINNs) to stochastic equations, thereby resulting in a new NN-based variant termed Negative Sobolev Norm-PINN (NeS-PINN).
<div id='section'>Paperid: <span id='pid'>955, <a href='https://arxiv.org/pdf/2501.12914.pdf' target='_blank'>https://arxiv.org/pdf/2501.12914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pierluigi Francesco De Paola, Jared Miller, Alessandro Borri, Alessia Paglialonga, Fabrizio Dabbene
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12914">A control system framework for counterfactuals: an optimization based approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Counterfactuals are a concept inherited from the field of logic and in general attain to the existence of causal relations between sentences or events. In particular, this concept has been introduced also in the context of interpretability in artificial intelligence, where counterfactuals refer to the minimum change to the feature values that changes the prediction of a classification model. The artificial intelligence framework of counterfactuals is mostly focused on machine learning approaches, typically neglecting the physics of the variables that determine a change in class. However, a theoretical formulation of counterfactuals in a control system framework - i.e., able to account for the mechanisms underlying a change in class - is lacking. To fill this gap, in this work we propose an original control system, physics-informed, theoretical foundation for counterfactuals, by means of the formulation of an optimal control problem. We apply the proposed methodology to a general glucose-insulin regulation model and results appear promising and pave the way to the possible integration with artificial intelligence techniques, with the aim of feeding machine learning models with the physics knowledge acquired through the system framework.
<div id='section'>Paperid: <span id='pid'>956, <a href='https://arxiv.org/pdf/2501.11655.pdf' target='_blank'>https://arxiv.org/pdf/2501.11655.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>M. Umar B. Niazi, John Cao, Matthieu Barreau, Karl Henrik Johansson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11655">KKL Observer Synthesis for Nonlinear Systems via Physics-Informed Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a novel learning approach for designing Kazantzis-Kravaris/Luenberger (KKL) observers for autonomous nonlinear systems. The design of a KKL observer involves finding an injective map that transforms the system state into a higher-dimensional observer state, whose dynamics is linear and stable. The observer's state is then mapped back to the original system coordinates via the inverse map to obtain the state estimate. However, finding this transformation and its inverse is quite challenging. We propose to sequentially approximate these maps by neural networks that are trained using physics-informed learning. We generate synthetic data for training by numerically solving the system and observer dynamics. Theoretical guarantees for the robustness of state estimation against approximation error and system uncertainties are provided. Additionally, a systematic method for optimizing observer performance through parameter selection is presented. The effectiveness of the proposed approach is demonstrated through numerical simulations on benchmark examples and its application to sensor fault detection and isolation in a network of Kuramoto oscillators using learned KKL observers.
<div id='section'>Paperid: <span id='pid'>957, <a href='https://arxiv.org/pdf/2501.08430.pdf' target='_blank'>https://arxiv.org/pdf/2501.08430.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Svenja Ehlers, Norbert Hoffmann, Tianning Tang, Adrian H. Callaghan, Rui Cao, Enrique M. Padilla, Yuxin Fang, Merten Stender
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08430">Physics-informed neural networks for phase-resolved data assimilation and prediction of nonlinear ocean waves</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The assimilation and prediction of phase-resolved surface gravity waves are critical challenges in ocean science and engineering. Potential flow theory (PFT) has been widely employed to develop wave models and numerical techniques for wave prediction. However, traditional wave prediction methods are often limited. For example, most simplified wave models have a limited ability to capture strong wave nonlinearity, while fully nonlinear PFT solvers often fail to meet the speed requirements of engineering applications. This computational inefficiency also hinders the development of effective data assimilation techniques, which are required to reconstruct spatial wave information from sparse measurements to initialize the wave prediction. To address these challenges, we propose a novel solver method that leverages physics-informed neural networks (PINNs) that parameterize PFT solutions as neural networks. This provides a computationally inexpensive way to assimilate and predict wave data. The proposed PINN framework is validated through comparisons with analytical linear PFT solutions and experimental data collected in a laboratory wave flume. The results demonstrate that our approach accurately captures and predicts irregular, nonlinear, and dispersive wave surface dynamics. Moreover, the PINN can infer the fully nonlinear velocity potential throughout the entire fluid volume solely from surface elevation measurements, enabling the calculation of fluid velocities that are difficult to measure experimentally.
<div id='section'>Paperid: <span id='pid'>958, <a href='https://arxiv.org/pdf/2501.07765.pdf' target='_blank'>https://arxiv.org/pdf/2501.07765.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nahil Sobh, Rini Jasmine Gladstone, Hadi Meidani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.07765">PINN-FEM: A Hybrid Approach for Enforcing Dirichlet Boundary Conditions in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) solve partial differential equations (PDEs) by embedding governing equations and boundary/initial conditions into the loss function. However, enforcing Dirichlet boundary conditions accurately remains challenging, often leading to soft enforcement that compromises convergence and reliability in complex domains. We propose a hybrid approach, PINN-FEM, which combines PINNs with finite element methods (FEM) to impose strong Dirichlet boundary conditions via domain decomposition. This method incorporates FEM-based representations near the boundary, ensuring exact enforcement without compromising convergence. Through six experiments of increasing complexity, PINN-FEM outperforms standard PINN models, showcasing superior accuracy and robustness. While distance functions and similar techniques have been proposed for boundary condition enforcement, they lack generality for real-world applications. PINN-FEM bridges this gap by leveraging FEM near boundaries, making it well-suited for industrial and scientific problems.
<div id='section'>Paperid: <span id='pid'>959, <a href='https://arxiv.org/pdf/2501.07373.pdf' target='_blank'>https://arxiv.org/pdf/2501.07373.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vinay Sharma, Olga Fink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.07373">Dynami-CAL GraphNet: A Physics-Informed Graph Neural Network Conserving Linear and Angular Momentum for Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate, interpretable, and real-time modeling of multi-body dynamical systems is essential for predicting behaviors and inferring physical properties in natural and engineered environments. Traditional physics-based models face scalability challenges and are computationally demanding, while data-driven approaches like Graph Neural Networks (GNNs) often lack physical consistency, interpretability, and generalization. In this paper, we propose Dynami-CAL GraphNet, a Physics-Informed Graph Neural Network that integrates the learning capabilities of GNNs with physics-based inductive biases to address these limitations. Dynami-CAL GraphNet enforces pairwise conservation of linear and angular momentum for interacting nodes using edge-local reference frames that are equivariant to rotational symmetries, invariant to translations, and equivariant to node permutations. This design ensures physically consistent predictions of node dynamics while offering interpretable, edge-wise linear and angular impulses resulting from pairwise interactions. Evaluated on a 3D granular system with inelastic collisions, Dynami-CAL GraphNet demonstrates stable error accumulation over extended rollouts, effective extrapolations to unseen configurations, and robust handling of heterogeneous interactions and external forces. Dynami-CAL GraphNet offers significant advantages in fields requiring accurate, interpretable, and real-time modeling of complex multi-body dynamical systems, such as robotics, aerospace engineering, and materials science. By providing physically consistent and scalable predictions that adhere to fundamental conservation laws, it enables the inference of forces and moments while efficiently handling heterogeneous interactions and external forces.
<div id='section'>Paperid: <span id='pid'>960, <a href='https://arxiv.org/pdf/2412.18786.pdf' target='_blank'>https://arxiv.org/pdf/2412.18786.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>R. Sharma, Y. B. Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.18786">Thermal-Mechanical Physics Informed Deep Learning For Fast Prediction of Thermal Stress Evolution in Laser Metal Deposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding thermal stress evolution in metal additive manufacturing (AM) is crucial for producing high-quality components. Recent advancements in machine learning (ML) have shown great potential for modeling complex multiphysics problems in metal AM. While physics-based simulations face the challenge of high computational costs, conventional data-driven ML models require large, labeled training datasets to achieve accurate predictions. Unfortunately, generating large datasets for ML model training through time-consuming experiments or high-fidelity simulations is highly expensive in metal AM. To address these challenges, this study introduces a physics-informed neural network (PINN) framework that incorporates governing physical laws into deep neural networks (NNs) to predict temperature and thermal stress evolution during the laser metal deposition (LMD) process. The study also discusses the enhanced accuracy and efficiency of the PINN model when supplemented with small simulation data. Furthermore, it highlights the PINN transferability, enabling fast predictions with a set of new process parameters using a pre-trained PINN model as an online soft sensor, significantly reducing computation time compared to physics-based numerical models while maintaining accuracy.
<div id='section'>Paperid: <span id='pid'>961, <a href='https://arxiv.org/pdf/2412.13695.pdf' target='_blank'>https://arxiv.org/pdf/2412.13695.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dominik Werner Wolf, Alexander Braun, Markus Ulrich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13695">Optical aberrations in autonomous driving: Physics-informed parameterized temperature scaling for neural network uncertainty calibration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>'A trustworthy representation of uncertainty is desirable and should be considered as a key feature of any machine learning method' (Huellermeier and Waegeman, 2021). This conclusion of Huellermeier et al. underpins the importance of calibrated uncertainties. Since AI-based algorithms are heavily impacted by dataset shifts, the automotive industry needs to safeguard its system against all possible contingencies. One important but often neglected dataset shift is caused by optical aberrations induced by the windshield. For the verification of the perception system performance, requirements on the AI performance need to be translated into optical metrics by a bijective mapping. Given this bijective mapping it is evident that the optical system characteristics add additional information about the magnitude of the dataset shift. As a consequence, we propose to incorporate a physical inductive bias into the neural network calibration architecture to enhance the robustness and the trustworthiness of the AI target application, which we demonstrate by using a semantic segmentation task as an example. By utilizing the Zernike coefficient vector of the optical system as a physical prior we can significantly reduce the mean expected calibration error in case of optical aberrations. As a result, we pave the way for a trustworthy uncertainty representation and for a holistic verification strategy of the perception chain.
<div id='section'>Paperid: <span id='pid'>962, <a href='https://arxiv.org/pdf/2412.13200.pdf' target='_blank'>https://arxiv.org/pdf/2412.13200.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Myeong-Su Lee, Jaemin Oh, Dong-Chan Lee, KangWook Lee, Sooncheol Park, Youngjoon Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13200">Forward and Inverse Simulation of Pseudo-Two-Dimensional Model of Lithium-Ion Batteries Using Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we address the challenges posed by the high nonlinearity of the Butler-Volmer (BV) equation in forward and inverse simulations of the pseudo-two-dimensional (P2D) model using the physics-informed neural network (PINN) framework. The BV equation presents significant challenges for PINNs, primarily due to the hyperbolic sine term, which renders the Hessian of the PINN loss function highly ill-conditioned. To address this issue, we introduce a bypassing term that improves numerical stability by substantially reducing the condition number of the Hessian matrix. Furthermore, the small magnitude of the ionic flux \( j \) often leads to a common failure mode where PINNs converge to incorrect solutions. We demonstrate that incorporating a secondary conservation law for the solid-phase potential \( Ï\) effectively prevents such convergence issues and ensures solution accuracy. The proposed methods prove effective for solving both forward and inverse problems involving the BV equation. Specifically, we achieve precise parameter estimation in inverse scenarios and reliable solution predictions for forward simulations.
<div id='section'>Paperid: <span id='pid'>963, <a href='https://arxiv.org/pdf/2412.07514.pdf' target='_blank'>https://arxiv.org/pdf/2412.07514.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Branislava Lalic, Dinh Viet Cuong, Mina Petric, Vladimir Pavlovic, Ana Firanj Sremac, Mark Roantree
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07514">Modelling Mosquito Population Dynamics using PINN-derived Empirical Parameters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vector-borne diseases continue to pose a significant health threat globally with more than 3 billion people at risk each year. Despite some limitations, mechanistic dynamic models are a popular approach to representing biological processes using ordinary differential equations where the parameters describe the different development and survival rates. Recent advances in population modelling have seen the combination of these mechanistic models with machine learning. One approach is physics-informed neural networks (PINNs) whereby the machine learning framework embeds physical, biological, or chemical laws into neural networks trained on observed or measured data. This enables forward simulations, predicting system behaviour from given parameters and inputs, and inverse modelling, improving parameterisation of existing parameters and estimating unknown or latent variables. In this paper, we focus on improving the parameterisation of biological processes in mechanistic models using PINNs to determine inverse parameters. In comparing mechanistic and PINN models, our experiments offer important insights into the strengths and weaknesses of both approaches but demonstrated that the PINN approach generally outperforms the dynamic model. For a deeper understanding of the performance of PINN models, a final validation was used to investigate how modifications to PINN architectures affect the performance of the framework. By varying only a single component at a time and keeping all other factors constant, we are able to observe the effect of each change.
<div id='section'>Paperid: <span id='pid'>964, <a href='https://arxiv.org/pdf/2412.01954.pdf' target='_blank'>https://arxiv.org/pdf/2412.01954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shinjan Ghosh, Julian Busch, Georgia Olympia Brikis, Biswadip Dey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01954">Geometry-aware PINNs for Turbulent Flow Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Design exploration or optimization using computational fluid dynamics (CFD) is commonly used in the industry. Geometric variation is a key component of such design problems, especially in turbulent flow scenarios, which involves running costly simulations at every design iteration. While parametric RANS-PINN type approaches have been proven to make effective turbulent surrogates, as a means of predicting unknown Reynolds number flows for a given geometry at near real-time, geometry aware physics informed surrogates with the ability to predict varying geometries are a relatively less studied topic. A novel geometry aware parametric PINN surrogate model has been created, which can predict flow fields for NACA 4 digit airfoils in turbulent conditions, for unseen shapes as well as inlet flow conditions. A local+global approach for embedding has been proposed, where known global design parameters for an airfoil as well as local SDF values can be used as inputs to the model along with velocity inlet/Reynolds number ($\mathcal{R}_e$) to predict the flow fields. A RANS formulation of the Navier-Stokes equations with a 2-equation k-epsilon turbulence model has been used for the PDE losses, in addition to limited CFD data from 8 different NACA airfoils for training. The models have then been validated with unknown NACA airfoils at unseen Reynolds numbers.
<div id='section'>Paperid: <span id='pid'>965, <a href='https://arxiv.org/pdf/2411.15919.pdf' target='_blank'>https://arxiv.org/pdf/2411.15919.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lena Podina, Diba Darooneh, Joshveer Grewal, Mohammad Kohandel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15919">Enhancing Symbolic Regression and Universal Physics-Informed Neural Networks with Dimensional Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a new method for enhancing symbolic regression for differential equations via dimensional analysis, specifically Ipsen's and Buckingham pi methods. Since symbolic regression often suffers from high computational costs and overfitting, non-dimensionalizing datasets reduces the number of input variables, simplifies the search space, and ensures that derived equations are physically meaningful. As our main contribution, we integrate Ipsen's method of dimensional analysis with Universal Physics-Informed Neural Networks. We also combine dimensional analysis with the AI Feynman symbolic regression algorithm to show that dimensional analysis significantly improves the accuracy of the recovered equation. The results demonstrate that transforming data into a dimensionless form significantly decreases computation time and improves accuracy of the recovered hidden term. For algebraic equations, using the Buckingham pi theorem reduced complexity, allowing the AI Feynman model to converge faster with fewer data points and lower error rates. For differential equations, Ipsen's method was combined with Universal Physics-Informed Neural Networks (UPINNs) to identify hidden terms more effectively. These findings suggest that integrating dimensional analysis with symbolic regression can significantly lower computational costs, enhance model interpretability, and increase accuracy, providing a robust framework for automated discovery of governing equations in complex systems when data is limited.
<div id='section'>Paperid: <span id='pid'>966, <a href='https://arxiv.org/pdf/2410.20801.pdf' target='_blank'>https://arxiv.org/pdf/2410.20801.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jassem Abbasi, Ben Moseley, Takeshi Kurotori, Ameya D. Jagtap, Anthony R. Kovscek, Aksel Hiorth, PÃ¥l ÃstebÃ¸ Andersen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20801">History-Matching of Imbibition Flow in Multiscale Fractured Porous Media Using Physics-Informed Neural Networks (PINNs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a workflow based on physics-informed neural networks (PINNs) to model multiphase fluid flow in fractured porous media. After validating the workflow in forward and inverse modeling of a synthetic problem of flow in fractured porous media, we applied it to a real experimental dataset in which brine is injected at a constant pressure drop into a CO2 saturated naturally fractured shale core plug. The exact spatial positions of natural fractures and the dynamic in-situ distribution of fluids were imaged using a CT-scan setup. To model the targeted system, we followed a domain decomposition approach for matrix and fractures and a multi-network architecture for the separate calculation of water saturation and pressure. The flow equations in the matrix, fractures and interplay between them were solved during training. Prior to fully-coupled simulations, we proposed pre-training the model. This aided in a more efficient and successful training of the coupled system. Both for the synthetic and experimental inverse problems, we determined flow parameters within the matrix and the fractures. Multiple random initializations of network and system parameters were performed to assess the uncertainty and uniqueness of the results. The results confirmed the precision of the inverse calculated parameters in retrieving the main flow characteristics of the system. The consideration of multiscale matrix-fracture impacts is commonly overlooked in existing workflows. Accounting for them led to several orders of magnitude variations in the calculated flow properties compared to not accounting for them. To the best of our knowledge, the proposed PINNs-based workflow is the first to offer a reliable and computationally efficient solution for inverse modeling of multiphase flow in fractured porous media, achieved through history-matching noisy and multi-fidelity experimental measurements.
<div id='section'>Paperid: <span id='pid'>967, <a href='https://arxiv.org/pdf/2410.18917.pdf' target='_blank'>https://arxiv.org/pdf/2410.18917.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shinjan Ghosh, Amit Chakraborty, Georgia Olympia Brikis, Biswadip Dey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.18917">Using Parametric PINNs for Predicting Internal and External Turbulent Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational fluid dynamics (CFD) solvers employing two-equation eddy viscosity models are the industry standard for simulating turbulent flows using the Reynolds-averaged Navier-Stokes (RANS) formulation. While these methods are computationally less expensive than direct numerical simulations, they can still incur significant computational costs to achieve the desired accuracy. In this context, physics-informed neural networks (PINNs) offer a promising approach for developing parametric surrogate models that leverage both existing, but limited CFD solutions and the governing differential equations to predict simulation outcomes in a computationally efficient, differentiable, and near real-time manner. In this work, we build upon the previously proposed RANS-PINN framework, which only focused on predicting flow over a cylinder. To investigate the efficacy of RANS-PINN as a viable approach to building parametric surrogate models, we investigate its accuracy in predicting relevant turbulent flow variables for both internal and external flows. To ensure training convergence with a more complex loss function, we adopt a novel sampling approach that exploits the domain geometry to ensure a proper balance among the contributions from various regions within the solution domain. The effectiveness of this framework is then demonstrated for two scenarios that represent a broad class of internal and external flow problems.
<div id='section'>Paperid: <span id='pid'>968, <a href='https://arxiv.org/pdf/2410.16173.pdf' target='_blank'>https://arxiv.org/pdf/2410.16173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Josue N. Rivera, Jianqi Ruan, XiaoLin Xu, Shuting Yang, Dengfeng Sun, Neera Jain
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.16173">Fast Physics-Informed Model Predictive Control Approximation for Lyapunov Stability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>At the forefront of control techniques is Model Predictive Control (MPC). While MPCs are effective, their requisite to recompute an optimal control given a new state leads to sparse response to the system and may make their implementation infeasible in small systems with low computational resources. To address these limitations in stability control, this research presents a small deterministic Physics-Informed MPC Surrogate model (PI-MPCS). PI-MPCS was developed to approximate the control by an MPC while encouraging stability and robustness through the integration of the system dynamics and the formation of a Lyapunov stability profile. Empirical results are presented on the task of 2D quadcopter landing. They demonstrate a rapid and precise MPC approximation on a non-linear system along with an estimated two times speed up on the computational requirements when compared against an MPC. PI-MPCS, in addition, displays a level of stable control for in- and out-of-distribution states as encouraged by the discrete dynamics residual and Lyapunov stability loss functions. PI-MPCS is meant to serve as a surrogate to MPC on situations in which the computational resources are limited.
<div id='section'>Paperid: <span id='pid'>969, <a href='https://arxiv.org/pdf/2410.05507.pdf' target='_blank'>https://arxiv.org/pdf/2410.05507.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Kuang, Xinfan Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.05507">Structural Constraints for Physics-augmented Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When the physics is wrong, physics-informed machine learning becomes physics-misinformed machine learning. A powerful black-box model should not be able to conceal misconceived physics. We propose two criteria that can be used to assert integrity that a hybrid (physics plus black-box) model: 0) the black-box model should be unable to replicate the physical model, and 1) any best-fit hybrid model has the same physical parameter as a best-fit standalone physics model. We demonstrate them for a sample nonlinear mechanical system approximated by its small-signal linearization.
<div id='section'>Paperid: <span id='pid'>970, <a href='https://arxiv.org/pdf/2409.19221.pdf' target='_blank'>https://arxiv.org/pdf/2409.19221.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xin Li, Zhihong Xia, Hongkun Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19221">Cauchy activation function and XNet</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We have developed a novel activation function, named the Cauchy Activation Function. This function is derived from the Cauchy Integral Theorem in complex analysis and is specifically tailored for problems requiring high precision. This innovation has led to the creation of a new class of neural networks, which we call (Comple)XNet, or simply XNet. We will demonstrate that XNet is particularly effective for high-dimensional challenges such as image classification and solving Partial Differential Equations (PDEs). Our evaluations show that XNet significantly outperforms established benchmarks like MNIST and CIFAR-10 in computer vision, and offers substantial advantages over Physics-Informed Neural Networks (PINNs) in both low-dimensional and high-dimensional PDE scenarios.
<div id='section'>Paperid: <span id='pid'>971, <a href='https://arxiv.org/pdf/2409.13786.pdf' target='_blank'>https://arxiv.org/pdf/2409.13786.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nathan Doumèche, Francis Bach, Gérard Biau, Claire Boyer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13786">Physics-informed kernel learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning typically integrates physical priors into the learning process by minimizing a loss function that includes both a data-driven term and a partial differential equation (PDE) regularization. Building on the formulation of the problem as a kernel regression task, we use Fourier methods to approximate the associated kernel, and propose a tractable estimator that minimizes the physics-informed risk function. We refer to this approach as physics-informed kernel learning (PIKL). This framework provides theoretical guarantees, enabling the quantification of the physical prior's impact on convergence speed. We demonstrate the numerical performance of the PIKL estimator through simulations, both in the context of hybrid modeling and in solving PDEs. In particular, we show that PIKL can outperform physics-informed neural networks in terms of both accuracy and computation time. Additionally, we identify cases where PIKL surpasses traditional PDE solvers, particularly in scenarios with noisy boundary conditions.
<div id='section'>Paperid: <span id='pid'>972, <a href='https://arxiv.org/pdf/2409.04708.pdf' target='_blank'>https://arxiv.org/pdf/2409.04708.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>N Navaneeth, Tushar, Souvik Chakraborty
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04708">Harnessing physics-informed operators for high-dimensional reliability analysis problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliability analysis is a formidable task, particularly in systems with a large number of stochastic parameters. Conventional methods for quantifying reliability often rely on extensive simulations or experimental data, which can be costly and time-consuming, especially when dealing with systems governed by complex physical laws which necessitates computationally intensive numerical methods such as finite element or finite volume techniques. On the other hand, surrogate-based methods offer an efficient alternative for computing reliability by approximating the underlying model from limited data. Neural operators have recently emerged as effective surrogates for modelling physical systems governed by partial differential equations. These operators can learn solutions to PDEs for varying inputs and parameters. Here, we investigate the efficacy of the recently developed physics-informed wavelet neural operator in solving reliability analysis problems. In particular, we investigate the possibility of using physics-informed operator for solving high-dimensional reliability analysis problems, while bypassing the need for any simulation. Through four numerical examples, we illustrate that physics-informed operator can seamlessly solve high-dimensional reliability analysis problems with reasonable accuracy, while eliminating the need for running expensive simulations.
<div id='section'>Paperid: <span id='pid'>973, <a href='https://arxiv.org/pdf/2409.01949.pdf' target='_blank'>https://arxiv.org/pdf/2409.01949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel Anderson, Victorita Dolean, Ben Moseley, Jennifer Pestana
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01949">ELM-FBPINN: efficient finite-basis physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics Informed Neural Networks (PINNs) offer several advantages when compared to traditional numerical methods for solving PDEs, such as being a mesh-free approach and being easily extendable to solving inverse problems. One promising approach for allowing PINNs to scale to multi-scale problems is to combine them with domain decomposition; for example, finite basis physics-informed neural networks (FBPINNs) replace the global PINN network with many localised networks which are summed together to approximate the solution. In this work, we significantly accelerate the training of FBPINNs by linearising their underlying optimisation problem. We achieve this by employing extreme learning machines (ELMs) as their subdomain networks and showing that this turns the FBPINN optimisation problem into one of solving a linear system or least-squares problem. We test our workflow in a preliminary fashion by using it to solve an illustrative 1D problem.
<div id='section'>Paperid: <span id='pid'>974, <a href='https://arxiv.org/pdf/2408.16379.pdf' target='_blank'>https://arxiv.org/pdf/2408.16379.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zakaria Elabid, Lena Sasal, Daniel Busby, Abdenour Hadid
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16379">TG-PhyNN: An Enhanced Physically-Aware Graph Neural Network framework for forecasting Spatio-Temporal Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately forecasting dynamic processes on graphs, such as traffic flow or disease spread, remains a challenge. While Graph Neural Networks (GNNs) excel at modeling and forecasting spatio-temporal data, they often lack the ability to directly incorporate underlying physical laws. This work presents TG-PhyNN, a novel Temporal Graph Physics-Informed Neural Network framework. TG-PhyNN leverages the power of GNNs for graph-based modeling while simultaneously incorporating physical constraints as a guiding principle during training. This is achieved through a two-step prediction strategy that enables the calculation of physical equation derivatives within the GNN architecture. Our findings demonstrate that TG-PhyNN significantly outperforms traditional forecasting models (e.g., GRU, LSTM, GAT) on real-world spatio-temporal datasets like PedalMe (traffic flow), COVID-19 spread, and Chickenpox outbreaks. These datasets are all governed by well-defined physical principles, which TG-PhyNN effectively exploits to offer more reliable and accurate forecasts in various domains where physical processes govern the dynamics of data. This paves the way for improved forecasting in areas like traffic flow prediction, disease outbreak prediction, and potentially other fields where physics plays a crucial role.
<div id='section'>Paperid: <span id='pid'>975, <a href='https://arxiv.org/pdf/2408.14615.pdf' target='_blank'>https://arxiv.org/pdf/2408.14615.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Asghar A. Jadoon, Knut A. Meyer, Jan N. Fuhg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14615">Automated model discovery of finite strain elastoplasticity from uniaxial experiments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constitutive modeling lies at the core of mechanics, allowing us to map strains onto stresses for a material in a given mechanical setting. Historically, researchers relied on phenomenological modeling where simple mathematical relationships were derived through experimentation and curve fitting. Recently, to automate the constitutive modeling process, data-driven approaches based on neural networks have been explored. While initial naive approaches violated established mechanical principles, recent efforts concentrate on designing neural network architectures that incorporate physics and mechanistic assumptions into machine-learning-based constitutive models. For history-dependent materials, these models have so far predominantly been restricted to small-strain formulations. In this work, we develop a finite strain plasticity formulation based on thermodynamic potentials to model mixed isotropic and kinematic hardening. We then leverage physics-augmented neural networks to automate the discovery of thermodynamically consistent constitutive models of finite strain elastoplasticity from uniaxial experiments. We apply the framework to both synthetic and experimental data, demonstrating its ability to capture complex material behavior under cyclic uniaxial loading. Furthermore, we show that the neural network enhanced model trains easier than traditional phenomenological models as it is less sensitive to varying initial seeds. our model's ability to generalize beyond the training set underscores its robustness and predictive power. By automating the discovery of hardening models, our approach eliminates user bias and ensures that the resulting constitutive model complies with thermodynamic principles, thus offering a more systematic and physics-informed framework.
<div id='section'>Paperid: <span id='pid'>976, <a href='https://arxiv.org/pdf/2408.11104.pdf' target='_blank'>https://arxiv.org/pdf/2408.11104.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiang Liu, Mengyu Chu, Nils Thuerey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11104">ConFIG: Towards Conflict-free Training of Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The loss functions of many learning problems contain multiple additive terms that can disagree and yield conflicting update directions. For Physics-Informed Neural Networks (PINNs), loss terms on initial/boundary conditions and physics equations are particularly interesting as they are well-established as highly difficult tasks. To improve learning the challenging multi-objective task posed by PINNs, we propose the ConFIG method, which provides conflict-free updates by ensuring a positive dot product between the final update and each loss-specific gradient. It also maintains consistent optimization rates for all loss terms and dynamically adjusts gradient magnitudes based on conflict levels. We additionally leverage momentum to accelerate optimizations by alternating the back-propagation of different loss terms. We provide a mathematical proof showing the convergence of the ConFIG method, and it is evaluated across a range of challenging PINN scenarios. ConFIG consistently shows superior performance and runtime compared to baseline methods. We also test the proposed method in a classic multi-task benchmark, where the ConFIG method likewise exhibits a highly promising performance. Source code is available at https://tum-pbs.github.io/ConFIG
<div id='section'>Paperid: <span id='pid'>977, <a href='https://arxiv.org/pdf/2407.11183.pdf' target='_blank'>https://arxiv.org/pdf/2407.11183.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Honghui Du, Binyao Guo, QiZhi He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11183">Differentiable Neural-Integrated Meshfree Method for Forward and Inverse Modeling of Finite Strain Hyperelasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The present study aims to extend the novel physics-informed machine learning approach, specifically the neural-integrated meshfree (NIM) method, to model finite-strain problems characterized by nonlinear elasticity and large deformations. To this end, the hyperelastic material models are integrated into the loss function of the NIM method by employing a consistent local variational formulation. Thanks to the inherent differentiable programming capabilities, NIM can circumvent the need for derivation of Newton-Raphson linearization of the variational form and the resulting tangent stiffness matrix, typically required in traditional numerical methods. Additionally, NIM utilizes a hybrid neural-numerical approximation encoded with partition-of-unity basis functions, coined NeuroPU, to effectively represent the displacement and streamline the training process. NeuroPU can also be used for approximating the unknown material fields, enabling NIM a unified framework for both forward and inverse modeling. For the imposition of displacement boundary conditions, this study introduces a new approach based on singular kernel functions into the NeuroPU approximation, leveraging its unique feature that allows for customized basis functions. Numerical experiments demonstrate the NIM method's capability in forward hyperelasticity modeling, achieving desirable accuracy, with errors among $10^{-3} \sim 10^{-5}$ in the relative $L_2$ norm, comparable to the well-established finite element solvers. Furthermore, NIM is applied to address the complex task of identifying heterogeneous mechanical properties of hyperelastic materials from strain data, validating its effectiveness in the inverse modeling of nonlinear materials. To leverage GPU acceleration, NIM is fully implemented on the JAX deep learning framework in this study, utilizing the accelerator-oriented array computation capabilities offered by JAX.
<div id='section'>Paperid: <span id='pid'>978, <a href='https://arxiv.org/pdf/2407.11106.pdf' target='_blank'>https://arxiv.org/pdf/2407.11106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kuangdai Leng, Jia Bi, Jaehoon Cha, Samuel Pinilla, Jeyan Thiyagalingam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11106">Deep Learning Evidence for Global Optimality of Gerver's Sofa</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Moving Sofa Problem, formally proposed by Leo Moser in 1966, seeks to determine the largest area of a two-dimensional shape that can navigate through an $L$-shaped corridor with unit width. The current best lower bound is about 2.2195, achieved by Joseph Gerver in 1992, though its global optimality remains unproven. In this paper, we investigate this problem by leveraging the universal approximation strength and computational efficiency of neural networks. We report two approaches, both supporting Gerver's conjecture that his shape is the unique global maximum. Our first approach is continuous function learning. We drop Gerver's assumptions that i) the rotation of the corridor is monotonic and symmetric and, ii) the trajectory of its corner as a function of rotation is continuously differentiable. We parameterize rotation and trajectory by independent piecewise linear neural networks (with input being some pseudo time), allowing for rich movements such as backward rotation and pure translation. We then compute the sofa area as a differentiable function of rotation and trajectory using our "waterfall" algorithm. Our final loss function includes differential terms and initial conditions, leveraging the principles of physics-informed machine learning. Under such settings, extensive training starting from diverse function initialization and hyperparameters is conducted, unexceptionally showing rapid convergence to Gerver's solution. Our second approach is via discrete optimization of the Kallus-Romik upper bound, which converges to the maximum sofa area from above as the number of rotation angles increases. We uplift this number to 10000 to reveal its asymptotic behavior. It turns out that the upper bound yielded by our models does converge to Gerver's area (within an error of 0.01% when the number of angles reaches 2100). We also improve their five-angle upper bound from 2.37 to 2.3337.
<div id='section'>Paperid: <span id='pid'>979, <a href='https://arxiv.org/pdf/2407.08383.pdf' target='_blank'>https://arxiv.org/pdf/2407.08383.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elie Abdo, Lihui Chai, Ruimeng Hu, Xu Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08383">Error estimates of physics-informed neural networks for approximating Boltzmann equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Motivated by the recent successful application of physics-informed neural networks (PINNs) to solve Boltzmann-type equations [S. Jin, Z. Ma, and K. Wu, J. Sci. Comput., 94 (2023), pp. 57], we provide a rigorous error analysis for PINNs in approximating the solution of the Boltzmann equation near a global Maxwellian. The challenge arises from the nonlocal quadratic interaction term defined in the unbounded domain of velocity space. Analyzing this term on an unbounded domain requires the inclusion of a truncation function, which demands delicate analysis techniques. As a generalization of this analysis, we also provide proof of the asymptotic preserving property when using micro-macro decomposition-based neural networks.
<div id='section'>Paperid: <span id='pid'>980, <a href='https://arxiv.org/pdf/2407.06727.pdf' target='_blank'>https://arxiv.org/pdf/2407.06727.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abeer Banerjee, Sanjay Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06727">Towards Physics-informed Cyclic Adversarial Multi-PSF Lensless Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Lensless imaging has emerged as a promising field within inverse imaging, offering compact, cost-effective solutions with the potential to revolutionize the computational camera market. By circumventing traditional optical components like lenses and mirrors, novel approaches like mask-based lensless imaging eliminate the need for conventional hardware. However, advancements in lensless image reconstruction, particularly those leveraging Generative Adversarial Networks (GANs), are hindered by the reliance on data-driven training processes, resulting in network specificity to the Point Spread Function (PSF) of the imaging system. This necessitates a complete retraining for minor PSF changes, limiting adaptability and generalizability across diverse imaging scenarios. In this paper, we introduce a novel approach to multi-PSF lensless imaging, employing a dual discriminator cyclic adversarial framework. We propose a unique generator architecture with a sparse convolutional PSF-aware auxiliary branch, coupled with a forward model integrated into the training loop to facilitate physics-informed learning to handle the substantial domain gap between lensless and lensed images. Comprehensive performance evaluation and ablation studies underscore the effectiveness of our model, offering robust and adaptable lensless image reconstruction capabilities. Our method achieves comparable performance to existing PSF-agnostic generative methods for single PSF cases and demonstrates resilience to PSF changes without the need for retraining.
<div id='section'>Paperid: <span id='pid'>981, <a href='https://arxiv.org/pdf/2407.06099.pdf' target='_blank'>https://arxiv.org/pdf/2407.06099.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manaswin Oddiraju, Zaki Hasnain, Saptarshi Bandyopadhyay, Eric Sunada, Souma Chowdhury
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06099">Physics-Informed Machine Learning Towards A Real-Time Spacecraft Thermal Simulator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling thermal states for complex space missions, such as the surface exploration of airless bodies, requires high computation, whether used in ground-based analysis for spacecraft design or during onboard reasoning for autonomous operations. For example, a finite-element thermal model with hundreds of elements can take significant time to simulate, which makes it unsuitable for onboard reasoning during time-sensitive scenarios such as descent and landing, proximity operations, or in-space assembly. Further, the lack of fast and accurate thermal modeling drives thermal designs to be more conservative and leads to spacecraft with larger mass and higher power budgets. The emerging paradigm of physics-informed machine learning (PIML) presents a class of hybrid modeling architectures that address this challenge by combining simplified physics models with machine learning (ML) models resulting in models which maintain both interpretability and robustness. Such techniques enable designs with reduced mass and power through onboard thermal-state estimation and control and may lead to improved onboard handling of off-nominal states, including unplanned down-time. The PIML model or hybrid model presented here consists of a neural network which predicts reduced nodalizations (distribution and size of coarse mesh) given on-orbit thermal load conditions, and subsequently a (relatively coarse) finite-difference model operates on this mesh to predict thermal states. We compare the computational performance and accuracy of the hybrid model to a data-driven neural net model, and a high-fidelity finite-difference model of a prototype Earth-orbiting small spacecraft. The PIML based active nodalization approach provides significantly better generalization than the neural net model and coarse mesh model, while reducing computing cost by up to 1.7x compared to the high-fidelity model.
<div id='section'>Paperid: <span id='pid'>982, <a href='https://arxiv.org/pdf/2407.04617.pdf' target='_blank'>https://arxiv.org/pdf/2407.04617.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifei Zong, David Barajas-Solano, Alexandre M. Tartakovsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04617">Randomized Physics-Informed Neural Networks for Bayesian Data Assimilation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a randomized physics-informed neural network (PINN) or rPINN method for uncertainty quantification in inverse partial differential equation (PDE) problems with noisy data. This method is used to quantify uncertainty in the inverse PDE PINN solutions. Recently, the Bayesian PINN (BPINN) method was proposed, where the posterior distribution of the PINN parameters was formulated using the Bayes' theorem and sampled using approximate inference methods such as the Hamiltonian Monte Carlo (HMC) and variational inference (VI) methods. In this work, we demonstrate that HMC fails to converge for non-linear inverse PDE problems. As an alternative to HMC, we sample the distribution by solving the stochastic optimization problem obtained by randomizing the PINN loss function. The effectiveness of the rPINN method is tested for linear and non-linear Poisson equations, and the diffusion equation with a high-dimensional space-dependent diffusion coefficient. The rPINN method provides informative distributions for all considered problems. For the linear Poisson equation, HMC and rPINN produce similar distributions, but rPINN is on average 27 times faster than HMC. For the non-linear Poison and diffusion equations, the HMC method fails to converge because a single HMC chain cannot sample multiple modes of the posterior distribution of the PINN parameters in a reasonable amount of time.
<div id='section'>Paperid: <span id='pid'>983, <a href='https://arxiv.org/pdf/2407.03476.pdf' target='_blank'>https://arxiv.org/pdf/2407.03476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shamil Mamedov, A. RenÃ© Geist, Ruan Viljoen, Sebastian Trimpe, Jan Swevers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03476">Learning deformable linear object dynamics from a single trajectory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The manipulation of deformable linear objects (DLOs) via model-based control requires an accurate and computationally efficient dynamics model. Yet, data-driven DLO dynamics models require large training data sets while their predictions often do not generalize, whereas physics-based models rely on good approximations of physical phenomena and often lack accuracy. To address these challenges, we propose a physics-informed neural ODE capable of predicting agile movements with significantly less data and hyper-parameter tuning. In particular, we model DLOs as serial chains of rigid bodies interconnected by passive elastic joints in which interaction forces are predicted by neural networks. The proposed model accurately predicts the motion of an robotically-actuated aluminium rod and an elastic foam cylinder after being trained on only thirty seconds of data.
  The project code and data are available at: \url{https://tinyurl.com/neuralprba}
<div id='section'>Paperid: <span id='pid'>984, <a href='https://arxiv.org/pdf/2407.02508.pdf' target='_blank'>https://arxiv.org/pdf/2407.02508.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Zhou, Yihao Qin, Dan Xu, Yiding Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02508">Physics-informed Imitative Reinforcement Learning for Real-world Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in imitative reinforcement learning (IRL) have considerably enhanced the ability of autonomous agents to assimilate expert demonstrations, leading to rapid skill acquisition in a range of demanding tasks. However, such learning-based agents face significant challenges when transferring knowledge to highly dynamic closed-loop environments. Their performance is significantly impacted by the conflicting optimization objectives of imitation learning (IL) and reinforcement learning (RL), sample inefficiency, and the complexity of uncovering the hidden world model and physics. To address this challenge, we propose a physics-informed IRL that is entirely data-driven. It leverages both expert demonstration data and exploratory data with a joint optimization objective, allowing the underlying physical principles of vehicle dynamics to emerge naturally from the training process. The performance is evaluated through empirical experiments and results exceed popular IL, RL and IRL algorithms in closed-loop settings on Waymax benchmark. Our approach exhibits 37.8% reduction in collision rate and 22.2% reduction in off-road rate compared to the baseline method.
<div id='section'>Paperid: <span id='pid'>985, <a href='https://arxiv.org/pdf/2407.02217.pdf' target='_blank'>https://arxiv.org/pdf/2407.02217.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zakariae El Asri, Olivier Sigaud, Nicolas Thome
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02217">Physics-Informed Model and Hybrid Planning for Efficient Dyna-Style Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Applying reinforcement learning (RL) to real-world applications requires addressing a trade-off between asymptotic performance, sample efficiency, and inference time. In this work, we demonstrate how to address this triple challenge by leveraging partial physical knowledge about the system dynamics. Our approach involves learning a physics-informed model to boost sample efficiency and generating imaginary trajectories from this model to learn a model-free policy and Q-function. Furthermore, we propose a hybrid planning strategy, combining the learned policy and Q-function with the learned model to enhance time efficiency in planning. Through practical demonstrations, we illustrate that our method improves the compromise between sample efficiency, time efficiency, and performance over state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>986, <a href='https://arxiv.org/pdf/2406.19831.pdf' target='_blank'>https://arxiv.org/pdf/2406.19831.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefano Berrone, Moreno Pintore
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.19831">Meshfree Variational Physics Informed Neural Networks (MF-VPINN): an adaptive training strategy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce a Meshfree Variational-Physics-Informed Neural Network. It is a Variational-Physics-Informed Neural Network that does not require the generation of the triangulation of the entire domain and that can be trained with an adaptive set of test functions. In order to generate the test space, we exploit an a posteriori error indicator and add test functions only where the error is higher. Four training strategies are proposed and compared. Numerical results show that the accuracy is higher than the one of a Variational-Physics-Informed Neural Network trained with the same number of test functions but defined on a quasi-uniform mesh.
<div id='section'>Paperid: <span id='pid'>987, <a href='https://arxiv.org/pdf/2406.15959.pdf' target='_blank'>https://arxiv.org/pdf/2406.15959.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chang-Ock Lee, Youngkyu Lee, Byungeun Ryoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.15959">A Nonoverlapping Domain Decomposition Method for Extreme Learning Machines: Elliptic Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Extreme learning machine (ELM) is a methodology for solving partial differential equations (PDEs) using a single hidden layer feed-forward neural network. It presets the weight/bias coefficients in the hidden layer with random values, which remain fixed throughout the computation, and uses a linear least squares method for training the parameters of the output layer of the neural network. It is known to be much faster than Physics informed neural networks. However, classical ELM is still computationally expensive when a high level of representation is desired in the solution as this requires solving a large least squares system. In this paper, we propose a nonoverlapping domain decomposition method (DDM) for ELMs that not only reduces the training time of ELMs, but is also suitable for parallel computation. In numerical analysis, DDMs have been widely studied to reduce the time to obtain finite element solutions for elliptic PDEs through parallel computation. Among these approaches, nonoverlapping DDMs are attracting the most attention. Motivated by these methods, we introduce local neural networks, which are valid only at corresponding subdomains, and an auxiliary variable at the interface. We construct a system on the variable and the parameters of local neural networks. A Schur complement system on the interface can be derived by eliminating the parameters of the output layer. The auxiliary variable is then directly obtained by solving the reduced system after which the parameters for each local neural network are solved in parallel. A method for initializing the hidden layer parameters suitable for high approximation quality in large systems is also proposed. Numerical results that verify the acceleration performance of the proposed method with respect to the number of subdomains are presented.
<div id='section'>Paperid: <span id='pid'>988, <a href='https://arxiv.org/pdf/2406.10242.pdf' target='_blank'>https://arxiv.org/pdf/2406.10242.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christopher Koh, Laurent Pagnier, Michael Chertkov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10242">Physics-Guided Actor-Critic Reinforcement Learning for Swimming in Turbulence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Turbulent diffusion causes particles placed in proximity to separate. We investigate the required swimming efforts to maintain an active particle close to its passively advected counterpart. We explore optimally balancing these efforts by developing a novel physics-informed reinforcement learning strategy and comparing it with prescribed control and physics-agnostic reinforcement learning strategies. Our scheme, coined the actor-physicist, is an adaptation of the actor-critic algorithm in which the neural network parameterized critic is replaced with an analytically derived physical heuristic function, the physicist. We validate the proposed physics-informed reinforcement learning approach through extensive numerical experiments in both synthetic BK and more realistic Arnold-Beltrami-Childress flow environments, demonstrating its superiority in controlling particle dynamics when compared to standard reinforcement learning methods.
<div id='section'>Paperid: <span id='pid'>989, <a href='https://arxiv.org/pdf/2406.05108.pdf' target='_blank'>https://arxiv.org/pdf/2406.05108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dinh Viet Cuong, Branislava LaliÄ, Mina PetriÄ, Binh Nguyen, Mark Roantree
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.05108">Adapting Physics-Informed Neural Networks to Improve ODE Optimization in Mosquito Population Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics informed neural networks have been gaining popularity due to their unique ability to incorporate physics laws into data-driven models, ensuring that the predictions are not only consistent with empirical data but also align with domain-specific knowledge in the form of physics equations. The integration of physics principles enables the method to require less data while maintaining the robustness of deep learning in modelling complex dynamical systems. However, current PINN frameworks are not sufficiently mature for real-world ODE systems, especially those with extreme multi-scale behavior such as mosquito population dynamical modelling. In this research, we propose a PINN framework with several improvements for forward and inverse problems for ODE systems with a case study application in modelling the dynamics of mosquito populations. The framework tackles the gradient imbalance and stiff problems posed by mosquito ordinary differential equations. The method offers a simple but effective way to resolve the time causality issue in PINNs by gradually expanding the training time domain until it covers entire domain of interest. As part of a robust evaluation, we conduct experiments using simulated data to evaluate the effectiveness of the approach. Preliminary results indicate that physics-informed machine learning holds significant potential for advancing the study of ecological systems.
<div id='section'>Paperid: <span id='pid'>990, <a href='https://arxiv.org/pdf/2406.04170.pdf' target='_blank'>https://arxiv.org/pdf/2406.04170.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Feilong Jiang, Xiaonan Hou, Min Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04170">Element-wise Multiplication Based Deeper Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a promising framework for resolving partial differential equations (PDEs), Physics-Informed Neural Networks (PINNs) have received widespread attention from industrial and scientific fields. However, lack of expressive ability and initialization pathology issues are found to prevent the application of PINNs in complex PDEs. In this work, we propose Deeper Physics-Informed Neural Network (Deeper-PINN) to resolve these issues. The element-wise multiplication operation is adopted to transform features into high-dimensional, non-linear spaces. Benefiting from element-wise multiplication operation, Deeper-PINNs can alleviate the initialization pathologies of PINNs and enhance the expressive capability of PINNs. The proposed structure is verified on various benchmarks. The results show that Deeper-PINNs can effectively resolve the initialization pathology and exhibit strong expressive ability.
<div id='section'>Paperid: <span id='pid'>991, <a href='https://arxiv.org/pdf/2406.03172.pdf' target='_blank'>https://arxiv.org/pdf/2406.03172.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhao Si, Ming Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03172">Initialization-enhanced Physics-Informed Neural Network with Domain Decomposition (IDPINN)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a new physics-informed neural network framework, IDPINN, based on the enhancement of initialization and domain decomposition to improve prediction accuracy. We train a PINN using a small dataset to obtain an initial network structure, including the weighted matrix and bias, which initializes the PINN for each subdomain. Moreover, we leverage the smoothness condition on the interface to enhance the prediction performance. We numerically evaluated it on several forward problems and demonstrated the benefits of IDPINN in terms of accuracy.
<div id='section'>Paperid: <span id='pid'>992, <a href='https://arxiv.org/pdf/2406.01539.pdf' target='_blank'>https://arxiv.org/pdf/2406.01539.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simone Brugiapaglia, Nick Dexter, Samir Karam, Weiqi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01539">Physics-informed deep learning and compressive collocation for high-dimensional diffusion-reaction equations: practical existence theory and numerics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>On the forefront of scientific computing, Deep Learning (DL), i.e., machine learning with Deep Neural Networks (DNNs), has emerged a powerful new tool for solving Partial Differential Equations (PDEs). It has been observed that DNNs are particularly well suited to weakening the effect of the curse of dimensionality, a term coined by Richard E. Bellman in the late `50s to describe challenges such as the exponential dependence of the sample complexity, i.e., the number of samples required to solve an approximation problem, on the dimension of the ambient space. However, although DNNs have been used to solve PDEs since the `90s, the literature underpinning their mathematical efficiency in terms of numerical analysis (i.e., stability, accuracy, and sample complexity), is only recently beginning to emerge. In this paper, we leverage recent advancements in function approximation using sparsity-based techniques and random sampling to develop and analyze an efficient high-dimensional PDE solver based on DL. We show, both theoretically and numerically, that it can compete with a novel stable and accurate compressive spectral collocation method. In particular, we demonstrate a new practical existence theorem, which establishes the existence of a class of trainable DNNs with suitable bounds on the network architecture and a sufficient condition on the sample complexity, with logarithmic or, at worst, linear scaling in dimension, such that the resulting networks stably and accurately approximate a diffusion-reaction PDE with high probability.
<div id='section'>Paperid: <span id='pid'>993, <a href='https://arxiv.org/pdf/2406.00276.pdf' target='_blank'>https://arxiv.org/pdf/2406.00276.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengyu Tao, Mengtian Zhang, Zixi Zhao, Haoyang Li, Ruifei Ma, Yunhong Che, Xin Sun, Lin Su, Xiangyu Chen, Zihao Zhou, Heng Chang, Tingwei Cao, Xiao Xiao, Yaojun Liu, Wenjun Yu, Zhongling Xu, Yang Li, Han Hao, Xuan Zhang, Xiaosong Hu, Guangmin ZHou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00276">Non-destructive Degradation Pattern Decoupling for Ultra-early Battery Prototype Verification Using Physics-informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Manufacturing complexities and uncertainties have impeded the transition from material prototypes to commercial batteries, making prototype verification critical to quality assessment. A fundamental challenge involves deciphering intertwined chemical processes to characterize degradation patterns and their quantitative relationship with battery performance. Here we show that a physics-informed machine learning approach can quantify and visualize temporally resolved losses concerning thermodynamics and kinetics only using electric signals. Our method enables non-destructive degradation pattern characterization, expediting temperature-adaptable predictions of entire lifetime trajectories, rather than end-of-life points. The verification speed is 25 times faster yet maintaining 95.1% accuracy across temperatures. Such advances facilitate more sustainable management of defective prototypes before massive production, establishing a 19.76 billion USD scrap material recycling market by 2060 in China. By incorporating stepwise charge acceptance as a measure of the initial manufacturing variability of normally identical batteries, we can immediately identify long-term degradation variations. We attribute the predictive power to interpreting machine learning insights using material-agnostic featurization taxonomy for degradation pattern decoupling. Our findings offer new possibilities for dynamic system analysis, such as battery prototype degradation, demonstrating that complex pattern evolutions can be accurately predicted in a non-destructive and data-driven fashion by integrating physics-informed machine learning.
<div id='section'>Paperid: <span id='pid'>994, <a href='https://arxiv.org/pdf/2405.15603.pdf' target='_blank'>https://arxiv.org/pdf/2405.15603.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felix Dangel, Johannes MÃ¼ller, Marius Zeinhofer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.15603">Kronecker-Factored Approximate Curvature for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are infamous for being hard to train. Recently, second-order methods based on natural gradient and Gauss-Newton methods have shown promising performance, improving the accuracy achieved by first-order methods by several orders of magnitude. While promising, the proposed methods only scale to networks with a few thousand parameters due to the high computational cost to evaluate, store, and invert the curvature matrix. We propose Kronecker-factored approximate curvature (KFAC) for PINN losses that greatly reduces the computational cost and allows scaling to much larger networks. Our approach goes beyond the established KFAC for traditional deep learning problems as it captures contributions from a PDE's differential operator that are crucial for optimization. To establish KFAC for such losses, we use Taylor-mode automatic differentiation to describe the differential operator's computation graph as a forward network with shared weights. This allows us to apply KFAC thanks to a recently-developed general formulation for networks with weight sharing. Empirically, we find that our KFAC-based optimizers are competitive with expensive second-order methods on small problems, scale more favorably to higher-dimensional neural networks and PDEs, and consistently outperform first-order methods and LBFGS.
<div id='section'>Paperid: <span id='pid'>995, <a href='https://arxiv.org/pdf/2405.12377.pdf' target='_blank'>https://arxiv.org/pdf/2405.12377.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Feilong Jiang, Xiaonan Hou, Min Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.12377">Spatio-temporal Attention-based Hidden Physics-informed Neural Network for Remaining Useful Life Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the Remaining Useful Life (RUL) is essential in Prognostic Health Management (PHM) for industrial systems. Although deep learning approaches have achieved considerable success in predicting RUL, challenges such as low prediction accuracy and interpretability pose significant challenges, hindering their practical implementation. In this work, we introduce a Spatio-temporal Attention-based Hidden Physics-informed Neural Network (STA-HPINN) for RUL prediction, which can utilize the associated physics of the system degradation. The spatio-temporal attention mechanism can extract important features from the input data. With the self-attention mechanism on both the sensor dimension and time step dimension, the proposed model can effectively extract degradation information. The hidden physics-informed neural network is utilized to capture the physics mechanisms that govern the evolution of RUL. With the constraint of physics, the model can achieve higher accuracy and reasonable predictions. The approach is validated on a benchmark dataset, demonstrating exceptional performance when compared to cutting-edge methods, especially in the case of complex conditions.
<div id='section'>Paperid: <span id='pid'>996, <a href='https://arxiv.org/pdf/2405.09428.pdf' target='_blank'>https://arxiv.org/pdf/2405.09428.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gil Serrano, Marcelo Jacinto, Jose Ribeiro-Gomes, Joao Pinto, Bruno J. Guerreiro, Alexandre Bernardino, Rita Cunha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.09428">Physics-Informed Neural Network for Multirotor Slung Load Systems Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in aerial robotics have enabled the use of multirotor vehicles for autonomous payload transportation. Resorting only to classical methods to reliably model a quadrotor carrying a cable-slung load poses significant challenges. On the other hand, purely data-driven learning methods do not comply by design with the problem's physical constraints, especially in states that are not densely represented in training data. In this work, we explore the use of physics informed neural networks to learn an end-to-end model of the multirotor-slung-load system and, at a given time, estimate a sequence of the future system states. An LSTM encoder decoder with an attention mechanism is used to capture the dynamics of the system. To guarantee the cohesiveness between the multiple predicted states of the system, we propose the use of a physics-based term in the loss function, which includes a discretized physical model derived from first principles together with slack variables that allow for a small mismatch between expected and predicted values. To train the model, a dataset using a real-world quadrotor carrying a slung load was curated and is made available. Prediction results are presented and corroborate the feasibility of the approach. The proposed method outperforms both the first principles physical model and a comparable neural network model trained without the physics regularization proposed.
<div id='section'>Paperid: <span id='pid'>997, <a href='https://arxiv.org/pdf/2405.08406.pdf' target='_blank'>https://arxiv.org/pdf/2405.08406.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tarik Sahin, Daniel Wolff, Max von Danwitz, Alexander Popp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08406">Towards a Hybrid Digital Twin: Physics-Informed Neural Networks as Surrogate Model of a Reinforced Concrete Beam</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we investigate the potential of fast-to-evaluate surrogate modeling techniques for developing a hybrid digital twin of a steel-reinforced concrete beam, serving as a representative example of a civil engineering structure. As surrogates, two distinct models are developed utilizing physics-informed neural networks, which integrate experimental data with given governing laws of physics. The experimental data (sensor data) is obtained from a previously conducted four-point bending test. The first surrogate model predicts strains at fixed locations along the center line of the beam for various time instances. This time-dependent surrogate model is inspired by the motion of a harmonic oscillator. For this study, we further compare the physics-based approach with a purely data-driven method, revealing the significance of physical laws for the extrapolation capabilities of models in scenarios with limited access to experimental data. Furthermore, we identify the natural frequency of the system by utilizing the physics-based model as an inverse solver. For the second surrogate model, we then focus on a fixed instance in time and combine the sensor data with the equations of linear elasticity to predict the strain distribution within the beam. This example reveals the importance of balancing different loss components through the selection of suitable loss weights.
<div id='section'>Paperid: <span id='pid'>998, <a href='https://arxiv.org/pdf/2405.08111.pdf' target='_blank'>https://arxiv.org/pdf/2405.08111.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lena Podina, Mahdi Torabi Rad, Mohammad Kohandel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08111">Conformalized Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are an influential method of solving differential equations and estimating their parameters given data. However, since they make use of neural networks, they provide only a point estimate of differential equation parameters, as well as the solution at any given point, without any measure of uncertainty. Ensemble and Bayesian methods have been previously applied to quantify the uncertainty of PINNs, but these methods may require making strong assumptions on the data-generating process, and can be computationally expensive. Here, we introduce Conformalized PINNs (C-PINNs) that, without making any additional assumptions, utilize the framework of conformal prediction to quantify the uncertainty of PINNs by providing intervals that have finite-sample, distribution-free statistical validity.
<div id='section'>Paperid: <span id='pid'>999, <a href='https://arxiv.org/pdf/2405.02131.pdf' target='_blank'>https://arxiv.org/pdf/2405.02131.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Federica Fieramosca, Vittorio Rampa, Michele D'Amico, Stefano Savazzi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02131">Physics-informed generative neural networks for RF propagation prediction with application to indoor body perception</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electromagnetic (EM) body models designed to predict Radio-Frequency (RF) propagation are time-consuming methods which prevent their adoption in strict real-time computational imaging problems, such as human body localization and sensing. Physics-informed Generative Neural Network (GNN) models have been recently proposed to reproduce EM effects, namely to simulate or reconstruct missing data or samples by incorporating relevant EM principles and constraints. The paper discusses a Variational Auto-Encoder (VAE) model which is trained to reproduce the effects of human motions on the EM field and incorporate EM body diffraction principles. Proposed physics-informed generative neural network models are verified against both classical diffraction-based EM tools and full-wave EM body simulations.
<div id='section'>Paperid: <span id='pid'>1000, <a href='https://arxiv.org/pdf/2404.15341.pdf' target='_blank'>https://arxiv.org/pdf/2404.15341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing-Xiao Liao, Chao He, Jipu Li, Jinwei Sun, Shiping Zhang, Xiaoge Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.15341">Classifier-guided neural blind deconvolution: a physics-informed denoising module for bearing fault diagnosis under heavy noise</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Blind deconvolution (BD) has been demonstrated as an efficacious approach for extracting bearing fault-specific features from vibration signals under strong background noise. Despite BD's desirable feature in adaptability and mathematical interpretability, a significant challenge persists: How to effectively integrate BD with fault-diagnosing classifiers? This issue arises because the traditional BD method is solely designed for feature extraction with its own optimizer and objective function. When BD is combined with downstream deep learning classifiers, the different learning objectives will be in conflict. To address this problem, this paper introduces classifier-guided BD (ClassBD) for joint learning of BD-based feature extraction and deep learning-based fault classification. Firstly, we present a time and frequency neural BD that employs neural networks to implement conventional BD, thereby facilitating the seamless integration of BD and the deep learning classifier for co-optimization of model parameters. Subsequently, we develop a unified framework to use a deep learning classifier to guide the learning of BD filters. In addition, we devise a physics-informed loss function composed of kurtosis, $l_2/l_4$ norm, and a cross-entropy loss to jointly optimize the BD filters and deep learning classifier. Consequently, the fault labels provide useful information to direct BD to extract features that distinguish classes amidst strong noise. To the best of our knowledge, this is the first of its kind that BD is successfully applied to bearing fault diagnosis. Experimental results from three datasets demonstrate that ClassBD outperforms other state-of-the-art methods under noisy conditions.
<div id='section'>Paperid: <span id='pid'>1001, <a href='https://arxiv.org/pdf/2404.12282.pdf' target='_blank'>https://arxiv.org/pdf/2404.12282.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose Florido, He Wang, Amirul Khan, Peter K. Jimack
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.12282">Investigating Guiding Information for Adaptive Collocation Point Sampling in PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) provide a means of obtaining approximate solutions of partial differential equations and systems through the minimisation of an objective function which includes the evaluation of a residual function at a set of collocation points within the domain. The quality of a PINNs solution depends upon numerous parameters, including the number and distribution of these collocation points. In this paper we consider a number of strategies for selecting these points and investigate their impact on the overall accuracy of the method. In particular, we suggest that no single approach is likely to be "optimal" but we show how a number of important metrics can have an impact in improving the quality of the results obtained when using a fixed number of residual evaluations. We illustrate these approaches through the use of two benchmark test problems: Burgers' equation and the Allen-Cahn equation.
<div id='section'>Paperid: <span id='pid'>1002, <a href='https://arxiv.org/pdf/2404.08412.pdf' target='_blank'>https://arxiv.org/pdf/2404.08412.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siming Shan, Pengkai Wang, Song Chen, Jiaxu Liu, Chao Xu, Shengze Cai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08412">PiRD: Physics-informed Residual Diffusion for Flow Field Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The use of machine learning in fluid dynamics is becoming more common to expedite the computation when solving forward and inverse problems of partial differential equations. Yet, a notable challenge with existing convolutional neural network (CNN)-based methods for data fidelity enhancement is their reliance on specific low-fidelity data patterns and distributions during the training phase. In addition, the CNN-based method essentially treats the flow reconstruction task as a computer vision task that prioritizes the element-wise precision which lacks a physical and mathematical explanation. This dependence can dramatically affect the models' effectiveness in real-world scenarios, especially when the low-fidelity input deviates from the training data or contains noise not accounted for during training. The introduction of diffusion models in this context shows promise for improving performance and generalizability. Unlike direct mapping from a specific low-fidelity to a high-fidelity distribution, diffusion models learn to transition from any low-fidelity distribution towards a high-fidelity one. Our proposed model - Physics-informed Residual Diffusion, demonstrates the capability to elevate the quality of data from both standard low-fidelity inputs, to low-fidelity inputs with injected Gaussian noise, and randomly collected samples. By integrating physics-based insights into the objective function, it further refines the accuracy and the fidelity of the inferred high-quality data. Experimental results have shown that our approach can effectively reconstruct high-quality outcomes for two-dimensional turbulent flows from a range of low-fidelity input conditions without requiring retraining.
<div id='section'>Paperid: <span id='pid'>1003, <a href='https://arxiv.org/pdf/2404.08019.pdf' target='_blank'>https://arxiv.org/pdf/2404.08019.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lena Podina, Ali Ghodsi, Mohammad Kohandel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08019">Learning Chemotherapy Drug Action via Universal Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantitative systems pharmacology (QSP) is widely used to assess drug effects and toxicity before the drug goes to clinical trial. However, significant manual distillation of the literature is needed in order to construct a QSP model. Parameters may need to be fit, and simplifying assumptions of the model need to be made. In this work, we apply Universal Physics-Informed Neural Networks (UPINNs) to learn unknown components of various differential equations that model chemotherapy pharmacodynamics. We learn three commonly employed chemotherapeutic drug actions (log-kill, Norton-Simon, and E_max) from synthetic data. Then, we use the UPINN method to fit the parameters for several synthetic datasets simultaneously. Finally, we learn the net proliferation rate in a model of doxorubicin (a chemotherapeutic) pharmacodynamics. As these are only toy examples, we highlight the usefulness of UPINNs in learning unknown terms in pharmacodynamic and pharmacokinetic models.
<div id='section'>Paperid: <span id='pid'>1004, <a href='https://arxiv.org/pdf/2404.06036.pdf' target='_blank'>https://arxiv.org/pdf/2404.06036.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuantong Zhang, Hanyou Zheng, Daiqin Yang, Zhenzhong Chen, Haichuan Ma, Wenpeng Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06036">Space-Time Video Super-resolution with Neural Operator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the task of space-time video super-resolution (ST-VSR). Existing methods generally suffer from inaccurate motion estimation and motion compensation (MEMC) problems for large motions. Inspired by recent progress in physics-informed neural networks, we model the challenges of MEMC in ST-VSR as a mapping between two continuous function spaces. Specifically, our approach transforms independent low-resolution representations in the coarse-grained continuous function space into refined representations with enriched spatiotemporal details in the fine-grained continuous function space. To achieve efficient and accurate MEMC, we design a Galerkin-type attention function to perform frame alignment and temporal interpolation. Due to the linear complexity of the Galerkin-type attention mechanism, our model avoids patch partitioning and offers global receptive fields, enabling precise estimation of large motions. The experimental results show that the proposed method surpasses state-of-the-art techniques in both fixed-size and continuous space-time video super-resolution tasks.
<div id='section'>Paperid: <span id='pid'>1005, <a href='https://arxiv.org/pdf/2404.03240.pdf' target='_blank'>https://arxiv.org/pdf/2404.03240.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zakaria Elabid, Daniel Busby, Abdenour Hadid
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.03240">Knowledge-Based Convolutional Neural Network for the Simulation and Prediction of Two-Phase Darcy Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have gained significant prominence as a powerful tool in the field of scientific computing and simulations. Their ability to seamlessly integrate physical principles into deep learning architectures has revolutionized the approaches to solving complex problems in physics and engineering. However, a persistent challenge faced by mainstream PINNs lies in their handling of discontinuous input data, leading to inaccuracies in predictions. This study addresses these challenges by incorporating the discretized forms of the governing equations into the PINN framework. We propose to combine the power of neural networks with the dynamics imposed by the discretized differential equations. By discretizing the governing equations, the PINN learns to account for the discontinuities and accurately capture the underlying relationships between inputs and outputs, improving the accuracy compared to traditional interpolation techniques. Moreover, by leveraging the power of neural networks, the computational cost associated with numerical simulations is substantially reduced. We evaluate our model on a large-scale dataset for the prediction of pressure and saturation fields demonstrating high accuracies compared to non-physically aware models.
<div id='section'>Paperid: <span id='pid'>1006, <a href='https://arxiv.org/pdf/2403.14404.pdf' target='_blank'>https://arxiv.org/pdf/2403.14404.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan-Hendrik Bastek, WaiChing Sun, Dennis M. Kochmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14404">Physics-Informed Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Generative models such as denoising diffusion models are quickly advancing their ability to approximate highly complex data distributions. They are also increasingly leveraged in scientific machine learning, where samples from the implied data distribution are expected to adhere to specific governing equations. We present a framework that unifies generative modeling and partial differential equation fulfillment by introducing a first-principle-based loss term that enforces generated samples to fulfill the underlying physical constraints. Our approach reduces the residual error by up to two orders of magnitude compared to previous work in a fluid flow case study and outperforms task-specific frameworks in relevant metrics for structural topology optimization. We also present numerical evidence that our extended training objective acts as a natural regularization mechanism against overfitting. Our framework is simple to implement and versatile in its applicability for imposing equality and inequality constraints as well as auxiliary optimization objectives.
<div id='section'>Paperid: <span id='pid'>1007, <a href='https://arxiv.org/pdf/2403.13040.pdf' target='_blank'>https://arxiv.org/pdf/2403.13040.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Jung Ling, SalomÃ© Bru, Julia Puig, Florian VixÃ¨ge, Simon Mendez, Franck Nicoud, Pierre-Yves Courand, Olivier Bernard, Damien Garcia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.13040">Physics-Guided Neural Networks for Intraventricular Vector Flow Mapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Intraventricular vector flow mapping (iVFM) seeks to enhance and quantify color Doppler in cardiac imaging. In this study, we propose novel alternatives to the traditional iVFM optimization scheme by utilizing physics-informed neural networks (PINNs) and a physics-guided nnU-Net-based supervised approach. When evaluated on simulated color Doppler images derived from a patient-specific computational fluid dynamics model and in vivo Doppler acquisitions, both approaches demonstrate comparable reconstruction performance to the original iVFM algorithm. The efficiency of PINNs is boosted through dual-stage optimization and pre-optimized weights. On the other hand, the nnU-Net method excels in generalizability and real-time capabilities. Notably, nnU-Net shows superior robustness on sparse and truncated Doppler data while maintaining independence from explicit boundary conditions. Overall, our results highlight the effectiveness of these methods in reconstructing intraventricular vector blood flow. The study also suggests potential applications of PINNs in ultrafast color Doppler imaging and the incorporation of fluid dynamics equations to derive biomarkers for cardiovascular diseases based on blood flow.
<div id='section'>Paperid: <span id='pid'>1008, <a href='https://arxiv.org/pdf/2403.01820.pdf' target='_blank'>https://arxiv.org/pdf/2403.01820.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongyan Li, Song Jiang, Wenjun Sun, Liwei Xu, Guanyu Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01820">Macroscopic auxiliary asymptotic preserving neural networks for the linear radiative transfer equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a Macroscopic Auxiliary Asymptotic-Preserving Neural Network (MA-APNN) method to solve the time-dependent linear radiative transfer equations (LRTEs), which have a multi-scale nature and high dimensionality. To achieve this, we utilize the Physics-Informed Neural Networks (PINNs) framework and design a new adaptive exponentially weighted Asymptotic-Preserving (AP) loss function, which incorporates the macroscopic auxiliary equation that is derived from the original transfer equation directly and explicitly contains the information of the diffusion limit equation. Thus, as the scale parameter tends to zero, the loss function gradually transitions from the transport state to the diffusion limit state. In addition, the initial data, boundary conditions, and conservation laws serve as the regularization terms for the loss. We present several numerical examples to demonstrate the effectiveness of MA-APNNs.
<div id='section'>Paperid: <span id='pid'>1009, <a href='https://arxiv.org/pdf/2402.18886.pdf' target='_blank'>https://arxiv.org/pdf/2402.18886.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lingfeng Li, Xue-Cheng Tai, Raymond Chan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18886">BP-DeepONet: A new method for cuffless blood pressure estimation using the physcis-informed DeepONet</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cardiovascular diseases (CVDs) are the leading cause of death worldwide, with blood pressure serving as a crucial indicator. Arterial blood pressure (ABP) waveforms provide continuous pressure measurements throughout the cardiac cycle and offer valuable diagnostic insights. Consequently, there is a significant demand for non-invasive and cuff-less methods to measure ABP waveforms continuously. Accurate prediction of ABP waveforms can also improve the estimation of mean blood pressure, an essential cardiovascular health characteristic.
  This study proposes a novel framework based on the physics-informed DeepONet approach to predict ABP waveforms. Unlike previous methods, our approach requires the predicted ABP waveforms to satisfy the Navier-Stokes equation with a time-periodic condition and a Windkessel boundary condition. Notably, our framework is the first to predict ABP waveforms continuously, both with location and time, within the part of the artery that is being simulated. Furthermore, our method only requires ground truth data at the outlet boundary and can handle periodic conditions with varying periods. Incorporating the Windkessel boundary condition in our solution allows for generating natural physical reflection waves, which closely resemble measurements observed in real-world cases. Moreover, accurately estimating the hyper-parameters in the Navier-Stokes equation for our simulations poses a significant challenge. To overcome this obstacle, we introduce the concept of meta-learning, enabling the neural networks to learn these parameters during the training process.
<div id='section'>Paperid: <span id='pid'>1010, <a href='https://arxiv.org/pdf/2402.17346.pdf' target='_blank'>https://arxiv.org/pdf/2402.17346.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahul Sundar, Didier Lucor, Sunetra Sarkar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17346">Understanding the training of PINNs for unsteady flow past a plunging foil through the lens of input subdomain level loss function gradients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently immersed boundary method-inspired physics-informed neural networks (PINNs) including the moving boundary-enabled PINNs (MB-PINNs) have shown the ability to accurately reconstruct velocity and recover pressure as a hidden variable for unsteady flow past moving bodies. Considering flow past a plunging foil, MB-PINNs were trained with global physics loss relaxation and also in conjunction with a physics-based undersampling method, obtaining good accuracy. The purpose of this study was to investigate which input spatial subdomain contributes to the training under the effect of physics loss relaxation and physics-based undersampling. In the context of MB-PINNs training, three spatial zones: the moving body, wake, and outer zones were defined. To quantify which spatial zone drives the training, two novel metrics are computed from the zonal loss component gradient statistics and the proportion of sample points in each zone. Results confirm that the learning indeed depends on the combined effect of the zonal loss component gradients and the proportion of points in each zone. Moreover, the dominant input zones are also the ones that have the strongest solution gradients in some sense.
<div id='section'>Paperid: <span id='pid'>1011, <a href='https://arxiv.org/pdf/2402.11283.pdf' target='_blank'>https://arxiv.org/pdf/2402.11283.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xili Wang, Kejun Tang, Jiayu Zhai, Xiaoliang Wan, Chao Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11283">Deep adaptive sampling for surrogate modeling without labeled data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Surrogate modeling is of great practical significance for parametric differential equation systems. In contrast to classical numerical methods, using physics-informed deep learning methods to construct simulators for such systems is a promising direction due to its potential to handle high dimensionality, which requires minimizing a loss over a training set of random samples. However, the random samples introduce statistical errors, which may become the dominant errors for the approximation of low-regularity and high-dimensional problems. In this work, we present a deep adaptive sampling method for surrogate modeling ($\text{DAS}^2$), where we generalize the deep adaptive sampling (DAS) method [62] [Tang, Wan and Yang, 2023] to build surrogate models for low-regularity parametric differential equations. In the parametric setting, the residual loss function can be regarded as an unnormalized probability density function (PDF) of the spatial and parametric variables. This PDF is approximated by a deep generative model, from which new samples are generated and added to the training set. Since the new samples match the residual-induced distribution, the refined training set can further reduce the statistical error in the current approximate solution. We demonstrate the effectiveness of $\text{DAS}^2$ with a series of numerical experiments, including the parametric lid-driven 2D cavity flow problem with a continuous range of Reynolds numbers from 100 to 1000.
<div id='section'>Paperid: <span id='pid'>1012, <a href='https://arxiv.org/pdf/2402.10926.pdf' target='_blank'>https://arxiv.org/pdf/2402.10926.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tim De Ryck, Siddhartha Mishra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10926">Numerical analysis of physics-informed neural networks and related models in physics-informed machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) and their variants have been very popular in recent years as algorithms for the numerical simulation of both forward and inverse problems for partial differential equations. This article aims to provide a comprehensive review of currently available results on the numerical analysis of PINNs and related models that constitute the backbone of physics-informed machine learning. We provide a unified framework in which analysis of the various components of the error incurred by PINNs in approximating PDEs can be effectively carried out. A detailed review of available results on approximation, generalization and training errors and their behavior with respect to the type of the PDE and the dimension of the underlying domain is presented. In particular, the role of the regularity of the solutions and their stability to perturbations in the error analysis is elucidated. Numerical results are also presented to illustrate the theory. We identify training errors as a key bottleneck which can adversely affect the overall performance of various models in physics-informed machine learning.
<div id='section'>Paperid: <span id='pid'>1013, <a href='https://arxiv.org/pdf/2402.07514.pdf' target='_blank'>https://arxiv.org/pdf/2402.07514.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nathan DoumÃ¨che, Francis Bach, GÃ©rard Biau, Claire Boyer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.07514">Physics-informed machine learning as a kernel method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning combines the expressiveness of data-based approaches with the interpretability of physical models. In this context, we consider a general regression problem where the empirical risk is regularized by a partial differential equation that quantifies the physical inconsistency. We prove that for linear differential priors, the problem can be formulated as a kernel regression task. Taking advantage of kernel theory, we derive convergence rates for the minimizer of the regularized risk and show that it converges at least at the Sobolev minimax rate. However, faster rates can be achieved, depending on the physical error. This principle is illustrated with a one-dimensional example, supporting the claim that regularizing the empirical risk with physical information can be beneficial to the statistical performance of estimators.
<div id='section'>Paperid: <span id='pid'>1014, <a href='https://arxiv.org/pdf/2402.04390.pdf' target='_blank'>https://arxiv.org/pdf/2402.04390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Feilong Jiang, Xiaonan Hou, Min Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.04390">Densely Multiplied Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although physics-informed neural networks (PINNs) have shown great potential in dealing with nonlinear partial differential equations (PDEs), it is common that PINNs will suffer from the problem of insufficient precision or obtaining incorrect outcomes. Unlike most of the existing solutions trying to enhance the ability of PINN by optimizing the training process, this paper improved the neural network architecture to improve the performance of PINN. We propose a densely multiply PINN (DM-PINN) architecture, which multiplies the output of a hidden layer with the outputs of all the behind hidden layers. Without introducing more trainable parameters, this effective mechanism can significantly improve the accuracy of PINNs. The proposed architecture is evaluated on four benchmark examples (Allan-Cahn equation, Helmholtz equation, Burgers equation and 1D convection equation). Comparisons between the proposed architecture and different PINN structures demonstrate the superior performance of the DM-PINN in both accuracy and efficiency.
<div id='section'>Paperid: <span id='pid'>1015, <a href='https://arxiv.org/pdf/2402.03559.pdf' target='_blank'>https://arxiv.org/pdf/2402.03559.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jacob K Christopher, Stephen Baek, Ferdinando Fioretto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03559">Constrained Synthesis with Projected Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces an approach to endow generative diffusion processes the ability to satisfy and certify compliance with constraints and physical principles. The proposed method recast the traditional sampling process of generative diffusion models as a constrained optimization problem, steering the generated data distribution to remain within a specified region to ensure adherence to the given constraints. These capabilities are validated on applications featuring both convex and challenging, non-convex, constraints as well as ordinary differential equations, in domains spanning from synthesizing new materials with precise morphometric properties, generating physics-informed motion, optimizing paths in planning scenarios, and human motion synthesis.
<div id='section'>Paperid: <span id='pid'>1016, <a href='https://arxiv.org/pdf/2401.14609.pdf' target='_blank'>https://arxiv.org/pdf/2401.14609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aina Wang, Pan Qin, Xi-Ming Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.14609">Physically Informed Synchronic-adaptive Learning for Industrial Systems Modeling in Heterogeneous Media with Unavailable Time-varying Interface</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial differential equations (PDEs) are commonly employed to model complex industrial systems characterized by multivariable dependence. Existing physics-informed neural networks (PINNs) excel in solving PDEs in a homogeneous medium. However, their feasibility is diminished when PDE parameters are unknown due to a lack of physical attributions and time-varying interface is unavailable arising from heterogeneous media. To this end, we propose a data-physics-hybrid method, physically informed synchronic-adaptive learning (PISAL), to solve PDEs for industrial systems modeling in heterogeneous media. First, Net1, Net2, and NetI, are constructed to approximate the solutions satisfying PDEs and the interface. Net1 and Net2 are utilized to synchronously learn each solution satisfying PDEs with diverse parameters, while NetI is employed to adaptively learn the unavailable time-varying interface. Then, a criterion combined with NetI is introduced to adaptively distinguish the attributions of measurements and collocation points. Furthermore, NetI is integrated into a data-physics-hybrid loss function. Accordingly, a synchronic-adaptive learning (SAL) strategy is proposed to decompose and optimize each subdomain. Besides, we theoretically prove the approximation capability of PISAL. Extensive experimental results verify that the proposed PISAL can be used for industrial systems modeling in heterogeneous media, which faces the challenges of lack of physical attributions and unavailable time-varying interface.
<div id='section'>Paperid: <span id='pid'>1017, <a href='https://arxiv.org/pdf/2401.05815.pdf' target='_blank'>https://arxiv.org/pdf/2401.05815.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan Kaiser, Chenran Xu, Annika Eichler, Andrea Santamaria Garcia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05815">Cheetah: Bridging the Gap Between Machine Learning and Particle Accelerator Physics with High-Speed, Differentiable Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning has emerged as a powerful solution to the modern challenges in accelerator physics. However, the limited availability of beam time, the computational cost of simulations, and the high-dimensionality of optimisation problems pose significant challenges in generating the required data for training state-of-the-art machine learning models. In this work, we introduce Cheetah, a PyTorch-based high-speed differentiable linear-beam dynamics code. Cheetah enables the fast collection of large data sets by reducing computation times by multiple orders of magnitude and facilitates efficient gradient-based optimisation for accelerator tuning and system identification. This positions Cheetah as a user-friendly, readily extensible tool that integrates seamlessly with widely adopted machine learning tools. We showcase the utility of Cheetah through five examples, including reinforcement learning training, gradient-based beamline tuning, gradient-based system identification, physics-informed Bayesian optimisation priors, and modular neural network surrogate modelling of space charge effects. The use of such a high-speed differentiable simulation code will simplify the development of machine learning-based methods for particle accelerators and fast-track their integration into everyday operations of accelerator facilities.
<div id='section'>Paperid: <span id='pid'>1018, <a href='https://arxiv.org/pdf/2401.05439.pdf' target='_blank'>https://arxiv.org/pdf/2401.05439.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Biao Yuan, Ana Heitor, He Wang, Xiaohui Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05439">Physics-informed Deep Learning to Solve Three-dimensional Terzaghi Consolidation Equation: Forward and Inverse Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The emergence of neural networks constrained by physical governing equations has sparked a new trend in deep learning research, which is known as Physics-Informed Neural Networks (PINNs). However, solving high-dimensional problems with PINNs is still a substantial challenge, the space complexity brings difficulty to solving large multidirectional problems. In this paper, a novel PINN framework to quickly predict several three-dimensional Terzaghi consolidation cases under different conditions is proposed. Meanwhile, the loss functions for different cases are introduced, and their differences in three-dimensional consolidation problems are highlighted. The tuning strategies for the PINNs framework for three-dimensional consolidation problems are introduced. Then, the performance of PINNs is tested and compared with traditional numerical methods adopted in forward problems, and the coefficients of consolidation and the impact of noisy data in inverse problems are identified. Finally, the results are summarized and presented from three-dimensional simulations of PINNs, which show an accuracy rate of over 99% compared with ground truth for both forward and inverse problems. These results are desirable with good accuracy and can be used for soil settlement prediction, which demonstrates that the proposed PINNs framework can learn the three-dimensional consolidation PDE well. Keywords: Three-dimensional Terzaghi consolidation; Physics-informed neural networks (PINNs); Forward problems; Inverse problems; soil settlement
<div id='section'>Paperid: <span id='pid'>1019, <a href='https://arxiv.org/pdf/2401.03708.pdf' target='_blank'>https://arxiv.org/pdf/2401.03708.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Svenja Ehlers, Niklas A. Wagner, Annamaria Scherzl, Marco Klein, Norbert Hoffmann, Merten Stender
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.03708">Data assimilation and parameter identification for water waves using the nonlinear SchrÃ¶dinger equation and physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The measurement of deep water gravity wave elevations using in-situ devices, such as wave gauges, typically yields spatially sparse data. This sparsity arises from the deployment of a limited number of gauges due to their installation effort and high operational costs. The reconstruction of the spatio-temporal extent of surface elevation poses an ill-posed data assimilation problem, challenging to solve with conventional numerical techniques. To address this issue, we propose the application of a physics-informed neural network (PINN), aiming to reconstruct physically consistent wave fields between two designated measurement locations several meters apart.
  Our method ensures this physical consistency by integrating residuals of the hydrodynamic nonlinear SchrÃ¶dinger equation (NLSE) into the PINN's loss function. Using synthetic wave elevation time series from distinct locations within a wave tank, we initially achieve successful reconstruction quality by employing constant, predetermined NLSE coefficients. However, the reconstruction quality is further improved by introducing NLSE coefficients as additional identifiable variables during PINN training. The results not only showcase a technically relevant application of the PINN method but also represent a pioneering step towards improving the initialization of deterministic wave prediction methods.
<div id='section'>Paperid: <span id='pid'>1020, <a href='https://arxiv.org/pdf/2401.03390.pdf' target='_blank'>https://arxiv.org/pdf/2401.03390.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Majd Al Aawar, Srikar Mutnuri, Mansooreh Montazerin, Ajitesh Srivastava
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.03390">Global Prediction of COVID-19 Variant Emergence Using Dynamics-Informed Graph Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>During the COVID-19 pandemic, a major driver of new surges has been the emergence of new variants. When a new variant emerges in one or more countries, other nations monitor its spread in preparation for its potential arrival. The impact of the new variant and the timings of epidemic peaks in a country highly depend on when the variant arrives. The current methods for predicting the spread of new variants rely on statistical modeling, however, these methods work only when the new variant has already arrived in the region of interest and has a significant prevalence. Can we predict when a variant existing elsewhere will arrive in a given region? To address this question, we propose a variant-dynamics-informed Graph Neural Network (GNN) approach. First, we derive the dynamics of variant prevalence across pairs of regions (countries) that apply to a large class of epidemic models. The dynamics motivate the introduction of certain features in the GNN. We demonstrate that our proposed dynamics-informed GNN outperforms all the baselines, including the currently pervasive framework of Physics-Informed Neural Networks (PINNs). To advance research in this area, we introduce a benchmarking tool to assess a user-defined model's prediction performance across 87 countries and 36 variants.
<div id='section'>Paperid: <span id='pid'>1021, <a href='https://arxiv.org/pdf/2312.17336.pdf' target='_blank'>https://arxiv.org/pdf/2312.17336.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Malik Hassanaly, Peter J. Weddle, Ryan N. King, Subhayan De, Alireza Doostan, Corey R. Randall, Eric J. Dufek, Andrew M. Colclasure, Kandler Smith
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.17336">PINN surrogate of Li-ion battery models for parameter inference. Part II: Regularization and application of the pseudo-2D model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian parameter inference is useful to improve Li-ion battery diagnostics and can help formulate battery aging models. However, it is computationally intensive and cannot be easily repeated for multiple cycles, multiple operating conditions, or multiple replicate cells. To reduce the computational cost of Bayesian calibration, numerical solvers for physics-based models can be replaced with faster surrogates. A physics-informed neural network (PINN) is developed as a surrogate for the pseudo-2D (P2D) battery model calibration. For the P2D surrogate, additional training regularization was needed as compared to the PINN single-particle model (SPM) developed in Part I. Both the PINN SPM and P2D surrogate models are exercised for parameter inference and compared to data obtained from a direct numerical solution of the governing equations. A parameter inference study highlights the ability to use these PINNs to calibrate scaling parameters for the cathode Li diffusion and the anode exchange current density. By realizing computational speed-ups of 2250x for the P2D model, as compared to using standard integrating methods, the PINN surrogates enable rapid state-of-health diagnostics. In the low-data availability scenario, the testing error was estimated to 2mV for the SPM surrogate and 10mV for the P2D surrogate which could be mitigated with additional data.
<div id='section'>Paperid: <span id='pid'>1022, <a href='https://arxiv.org/pdf/2312.06278.pdf' target='_blank'>https://arxiv.org/pdf/2312.06278.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gung-Min Gie, Youngjoon Hong, Chang-Yeol Jung, Tselmuun Munkhjin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.06278">Semi-analytic PINN methods for boundary layer problems in a rectangular domain</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Singularly perturbed boundary value problems pose a significant challenge for their numerical approximations because of the presence of sharp boundary layers. These sharp boundary layers are responsible for the stiffness of solutions, which leads to large computational errors, if not properly handled. It is well-known that the classical numerical methods as well as the Physics-Informed Neural Networks (PINNs) require some special treatments near the boundary, e.g., using extensive mesh refinements or finer collocation points, in order to obtain an accurate approximate solution especially inside of the stiff boundary layer. In this article, we modify the PINNs and construct our new semi-analytic SL-PINNs suitable for singularly perturbed boundary value problems. Performing the boundary layer analysis, we first find the corrector functions describing the singular behavior of the stiff solutions inside boundary layers. Then we obtain the SL-PINN approximations of the singularly perturbed problems by embedding the explicit correctors in the structure of PINNs or by training the correctors together with the PINN approximations. Our numerical experiments confirm that our new SL-PINN methods produce stable and accurate approximations for stiff solutions.
<div id='section'>Paperid: <span id='pid'>1023, <a href='https://arxiv.org/pdf/2312.06177.pdf' target='_blank'>https://arxiv.org/pdf/2312.06177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifei Zong, David Barajas-Solano, Alexandre M. Tartakovsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.06177">Randomized Physics-Informed Machine Learning for Uncertainty Quantification in High-Dimensional Inverse Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a physics-informed machine learning method for uncertainty quantification in high-dimensional inverse problems. In this method, the states and parameters of partial differential equations (PDEs) are approximated with truncated conditional Karhunen-LoÃ¨ve expansions (CKLEs), which, by construction, match the measurements of the respective variables. The maximum a posteriori (MAP) solution of the inverse problem is formulated as a minimization problem over CKLE coefficients where the loss function is the sum of the norm of PDE residuals and the $\ell_2$ regularization term. This MAP formulation is known as the physics-informed CKLE (PICKLE) method. Uncertainty in the inverse solution is quantified in terms of the posterior distribution of CKLE coefficients, and we sample the posterior by solving a randomized PICKLE minimization problem, formulated by adding zero-mean Gaussian perturbations in the PICKLE loss function. We call the proposed approach the randomized PICKLE (rPICKLE) method.
  For linear and low-dimensional nonlinear problems (15 CKLE parameters), we show analytically and through comparison with Hamiltonian Monte Carlo (HMC) that the rPICKLE posterior converges to the true posterior given by the Bayes rule. For high-dimensional non-linear problems with 2000 CKLE parameters, we numerically demonstrate that rPICKLE posteriors are highly informative--they provide mean estimates with an accuracy comparable to the estimates given by the MAP solution and the confidence interval that mostly covers the reference solution. We are not able to obtain the HMC posterior to validate rPICKLE's convergence to the true posterior due to the HMC's prohibitive computational cost for the considered high-dimensional problems. Our results demonstrate the advantages of rPICKLE over HMC for approximately sampling high-dimensional posterior distributions subject to physics constraints.
<div id='section'>Paperid: <span id='pid'>1024, <a href='https://arxiv.org/pdf/2312.05601.pdf' target='_blank'>https://arxiv.org/pdf/2312.05601.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Han Zhang, Raymond Chan, Xue-Cheng Tai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.05601">A Meshless Solver for Blood Flow Simulations in Elastic Vessels Using Physics-Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Investigating blood flow in the cardiovascular system is crucial for assessing cardiovascular health. Computational approaches offer some non-invasive alternatives to measure blood flow dynamics. Numerical simulations based on traditional methods such as finite-element and other numerical discretizations have been extensively studied and have yielded excellent results. However, adapting these methods to real-life simulations remains a complex task. In this paper, we propose a method that offers flexibility and can efficiently handle real-life simulations. We suggest utilizing the physics-informed neural network (PINN) to solve the Navier-Stokes equation in a deformable domain, specifically addressing the simulation of blood flow in elastic vessels. Our approach models blood flow using an incompressible, viscous Navier-Stokes equation in an Arbitrary Lagrangian-Eulerian form. The mechanical model for the vessel wall structure is formulated by an equation of Newton's second law of momentum and linear elasticity to the force exerted by the fluid flow. Our method is a mesh-free approach that eliminates the need for discretization and meshing of the computational domain. This makes it highly efficient in solving simulations involving complex geometries. Additionally, with the availability of well-developed open-source machine learning framework packages and parallel modules, our method can easily be accelerated through GPU computing and parallel computing. To evaluate our approach, we conducted experiments on regular cylinder vessels as well as vessels with plaque on their walls. We compared our results to a solution calculated by Finite Element Methods using a dense grid and small time steps, which we considered as the ground truth solution. We report the relative error and the time consumed to solve the problem, highlighting the advantages of our method.
<div id='section'>Paperid: <span id='pid'>1025, <a href='https://arxiv.org/pdf/2312.03295.pdf' target='_blank'>https://arxiv.org/pdf/2312.03295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gung-Min Gie, Youngjoon Hong, Chang-Yeol Jung, Dongseok Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.03295">Singular Layer Physics-Informed Neural Network Method for Convection-Dominated Boundary Layer Problems in Two Dimensions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This research explores neural network-based numerical approximation of two-dimensional convection-dominated singularly perturbed problems on square, circular, and elliptic domains. Singularly perturbed boundary value problems pose significant challenges due to sharp boundary layers in their solutions. Additionally, the characteristic points of these domains give rise to degenerate boundary layer problems. The stiffness of these problems, caused by sharp singular layers, can lead to substantial computational errors if not properly addressed. Conventional neural network-based approaches often fail to capture these sharp transitions accurately, highlighting a critical flaw in machine learning methods. To address these issues, we conduct a thorough boundary layer analysis to enhance our understanding of sharp transitions within the boundary layers, guiding the application of numerical methods. Specifically, we employ physics-informed neural networks (PINNs) to better handle these boundary layer problems. However, PINNs may struggle with rapidly varying singularly perturbed solutions in small domain regions, leading to inaccurate or unstable results. To overcome this limitation, we introduce a semi-analytic method that augments PINNs with singular layers or corrector functions. Our numerical experiments demonstrate significant improvements in both accuracy and stability, showcasing the effectiveness of our proposed approach.
<div id='section'>Paperid: <span id='pid'>1026, <a href='https://arxiv.org/pdf/2312.02235.pdf' target='_blank'>https://arxiv.org/pdf/2312.02235.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiakai Zhang, Qihe Chen, Yan Zeng, Wenyuan Gao, Xuming He, Zhijie Liu, Jingyi Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.02235">CryoGEM: Physics-Informed Generative Cryo-Electron Microscopy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the past decade, deep conditional generative models have revolutionized the generation of realistic images, extending their application from entertainment to scientific domains. Single-particle cryo-electron microscopy (cryo-EM) is crucial in resolving near-atomic resolution 3D structures of proteins, such as the SARS- COV-2 spike protein. To achieve high-resolution reconstruction, a comprehensive data processing pipeline has been adopted. However, its performance is still limited as it lacks high-quality annotated datasets for training. To address this, we introduce physics-informed generative cryo-electron microscopy (CryoGEM), which for the first time integrates physics-based cryo-EM simulation with a generative unpaired noise translation to generate physically correct synthetic cryo-EM datasets with realistic noises. Initially, CryoGEM simulates the cryo-EM imaging process based on a virtual specimen. To generate realistic noises, we leverage an unpaired noise translation via contrastive learning with a novel mask-guided sampling scheme. Extensive experiments show that CryoGEM is capable of generating authentic cryo-EM images. The generated dataset can used as training data for particle picking and pose estimation models, eventually improving the reconstruction resolution.
<div id='section'>Paperid: <span id='pid'>1027, <a href='https://arxiv.org/pdf/2311.15304.pdf' target='_blank'>https://arxiv.org/pdf/2311.15304.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Teng-Yuan Chang, Gung-Min Gie, Youngjoon Hong, Chang-Yeol Jung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.15304">Singular layer Physics Informed Neural Network method for Plane Parallel Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We construct in this article the semi-analytic Physics Informed Neural Networks (PINNs), called {\em singular layer PINNs} (or {\em sl-PINNs}), that are suitable to predict the stiff solutions of plane-parallel flows at a small viscosity. Recalling the boundary layer analysis, we first find the corrector for the problem which describes the singular behavior of the viscous flow inside boundary layers. Then, using the components of the corrector and its curl, we build our new {\em sl-PINN} predictions for the velocity and the vorticity by either embedding the explicit expression of the corrector (or its curl) in the structure of PINNs or by training the implicit parts of the corrector (or its curl) together with the PINN predictions. Numerical experiments confirm that our new {\em sl-PINNs} produce stable and accurate predicted solutions for the plane-parallel flows at a small viscosity.
<div id='section'>Paperid: <span id='pid'>1028, <a href='https://arxiv.org/pdf/2311.13949.pdf' target='_blank'>https://arxiv.org/pdf/2311.13949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Li, Alexander Kies, Kai Zhou, Markus Schlott, Omar El Sayed, Mariia Bilousova, Horst Stoecker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13949">Optimal Power Flow in Highly Renewable Power System Based on Attention Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Optimal Power Flow (OPF) problem is pivotal for power system operations, guiding generator output and power distribution to meet demand at minimized costs, while adhering to physical and engineering constraints. The integration of renewable energy sources, like wind and solar, however, poses challenges due to their inherent variability. This variability, driven largely by changing weather conditions, demands frequent recalibrations of power settings, thus necessitating recurrent OPF resolutions. This task is daunting using traditional numerical methods, particularly for extensive power systems. In this work, we present a cutting-edge, physics-informed machine learning methodology, trained using imitation learning and historical European weather datasets. Our approach directly correlates electricity demand and weather patterns with power dispatch and generation, circumventing the iterative requirements of traditional OPF solvers. This offers a more expedient solution apt for real-time applications. Rigorous evaluations on aggregated European power systems validate our method's superiority over existing data-driven techniques in OPF solving. By presenting a quick, robust, and efficient solution, this research sets a new standard in real-time OPF resolution, paving the way for more resilient power systems in the era of renewable energy.
<div id='section'>Paperid: <span id='pid'>1029, <a href='https://arxiv.org/pdf/2311.12915.pdf' target='_blank'>https://arxiv.org/pdf/2311.12915.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Honghui Du, QiZhi He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12915">Neural-Integrated Meshfree (NIM) Method: A differentiable programming-based hybrid solver for computational mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present the neural-integrated meshfree (NIM) method, a differentiable programming-based hybrid meshfree approach within the field of computational mechanics. NIM seamlessly integrates traditional physics-based meshfree discretization techniques with deep learning architectures. It employs a hybrid approximation scheme, NeuroPU, to effectively represent the solution by combining continuous DNN representations with partition of unity (PU) basis functions associated with the underlying spatial discretization. This neural-numerical hybridization not only enhances the solution representation through functional space decomposition but also reduces both the size of DNN model and the need for spatial gradient computations based on automatic differentiation, leading to a significant improvement in training efficiency. Under the NIM framework, we propose two truly meshfree solvers: the strong form-based NIM (S-NIM) and the local variational form-based NIM (V-NIM). In the S-NIM solver, the strong-form governing equation is directly considered in the loss function, while the V-NIM solver employs a local Petrov-Galerkin approach that allows the construction of variational residuals based on arbitrary overlapping subdomains. This ensures both the satisfaction of underlying physics and the preservation of meshfree property. We perform extensive numerical experiments on both stationary and transient benchmark problems to assess the effectiveness of the proposed NIM methods in terms of accuracy, scalability, generalizability, and convergence properties. Moreover, comparative analysis with other physics-informed machine learning methods demonstrates that NIM, especially V-NIM, significantly enhances both accuracy and efficiency in end-to-end predictive capabilities.
<div id='section'>Paperid: <span id='pid'>1030, <a href='https://arxiv.org/pdf/2311.00860.pdf' target='_blank'>https://arxiv.org/pdf/2311.00860.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kuangdai Leng, Mallikarjun Shankar, Jeyan Thiyagalingam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.00860">Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic differentiation (AD) is a critical step in physics-informed machine learning, required for computing the high-order derivatives of network output w.r.t. coordinates of collocation points. In this paper, we present a novel and lightweight algorithm to conduct AD for physics-informed operator learning, which we call the trick of Zero Coordinate Shift (ZCS). Instead of making all sampled coordinates as leaf variables, ZCS introduces only one scalar-valued leaf variable for each spatial or temporal dimension, simplifying the wanted derivatives from "many-roots-many-leaves" to "one-root-many-leaves" whereby reverse-mode AD becomes directly utilisable. It has led to an outstanding performance leap by avoiding the duplication of the computational graph along the dimension of functions (physical parameters). ZCS is easy to implement with current deep learning libraries; our own implementation is achieved by extending the DeepXDE package. We carry out a comprehensive benchmark analysis and several case studies, training physics-informed DeepONets to solve partial differential equations (PDEs) without data. The results show that ZCS has persistently reduced GPU memory consumption and wall time for training by an order of magnitude, and such reduction factor scales with the number of functions. As a low-level optimisation technique, ZCS imposes no restrictions on data, physics (PDE) or network architecture and does not compromise training results from any aspect.
<div id='section'>Paperid: <span id='pid'>1031, <a href='https://arxiv.org/pdf/2311.00578.pdf' target='_blank'>https://arxiv.org/pdf/2311.00578.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taniya Kapoor, Hongrui Wang, Alfredo Nunez, Rolf Dollevoet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.00578">Transfer learning for improved generalizability in causal physics-informed neural networks for beam simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel methodology for simulating the dynamics of beams on elastic foundations. Specifically, Euler-Bernoulli and Timoshenko beam models on the Winkler foundation are simulated using a transfer learning approach within a causality-respecting physics-informed neural network (PINN) framework. Conventional PINNs encounter challenges in handling large space-time domains, even for problems with closed-form analytical solutions. A causality-respecting PINN loss function is employed to overcome this limitation, effectively capturing the underlying physics. However, it is observed that the causality-respecting PINN lacks generalizability. We propose using solutions to similar problems instead of training from scratch by employing transfer learning while adhering to causality to accelerate convergence and ensure accurate results across diverse scenarios. Numerical experiments on the Euler-Bernoulli beam highlight the efficacy of the proposed approach for various initial conditions, including those with noise in the initial data. Furthermore, the potential of the proposed method is demonstrated for the Timoshenko beam in an extended spatial and temporal domain. Several comparisons suggest that the proposed method accurately captures the inherent dynamics, outperforming the state-of-the-art physics-informed methods under standard $L^2$-norm metric and accelerating convergence.
<div id='section'>Paperid: <span id='pid'>1032, <a href='https://arxiv.org/pdf/2311.00224.pdf' target='_blank'>https://arxiv.org/pdf/2311.00224.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Will Snyder, Irina Tezaur, Christopher Wentland
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.00224">Domain decomposition-based coupling of physics-informed neural networks via the Schwarz alternating method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are appealing data-driven tools for solving and inferring solutions to nonlinear partial differential equations (PDEs). Unlike traditional neural networks (NNs), which train only on solution data, a PINN incorporates a PDE's residual into its loss function and trains to minimize the said residual at a set of collocation points in the solution domain. This paper explores the use of the Schwarz alternating method as a means to couple PINNs with each other and with conventional numerical models (i.e., full order models, or FOMs, obtained via the finite element, finite difference or finite volume methods) following a decomposition of the physical domain. It is well-known that training a PINN can be difficult when the PDE solution has steep gradients. We investigate herein the use of domain decomposition and the Schwarz alternating method as a means to accelerate the PINN training phase. Within this context, we explore different approaches for imposing Dirichlet boundary conditions within each subdomain PINN: weakly through the loss and/or strongly through a solution transformation. As a numerical example, we consider the one-dimensional steady state advection-diffusion equation in the advection-dominated (high Peclet) regime. Our results suggest that the convergence of the Schwarz method is strongly linked to the choice of boundary condition implementation within the PINNs being coupled. Surprisingly, strong enforcement of the Schwarz boundary conditions does not always lead to a faster convergence of the method. While it is not clear from our preliminary study that the PINN-PINN coupling via the Schwarz alternating method accelerates PINN convergence in the advection-dominated regime, it reveals that PINN training can be improved substantially for Peclet numbers as high as 1e6 by performing a PINN-FOM coupling.
<div id='section'>Paperid: <span id='pid'>1033, <a href='https://arxiv.org/pdf/2310.13937.pdf' target='_blank'>https://arxiv.org/pdf/2310.13937.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Laura Boca de Giuli, Alessio La Bella, Riccardo Scattolini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.13937">Physics-informed Neural Network Modelling and Predictive Control of District Heating Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the data-based modelling and optimal control of District Heating Systems (DHSs). Physical models of such large-scale networked systems are governed by complex nonlinear equations that require a large amount of parameters, leading to potential computational issues in optimizing their operation. A novel methodology is hence proposed, exploiting operational data and available physical knowledge to attain accurate and computationally efficient DHSs dynamic models. The proposed idea consists in leveraging multiple Recurrent Neural Networks (RNNs) and in embedding the physical topology of the DHS network in their interconnections. With respect to standard RNN approaches, the resulting modelling methodology, denoted as Physics-Informed RNN (PI-RNN), enables to achieve faster training procedures and higher modelling accuracy, even when reduced-dimension models are exploited. The developed PI-RNN modelling technique paves the way for the design of a Nonlinear Model Predictive Control (NMPC) regulation strategy, enabling, with limited computational time, to minimize production costs, to increase system efficiency and to respect operative constraints over the whole DHS network. The proposed methods are tested in simulation on a DHS benchmark referenced in the literature, showing promising results from the modelling and control perspective.
<div id='section'>Paperid: <span id='pid'>1034, <a href='https://arxiv.org/pdf/2310.13270.pdf' target='_blank'>https://arxiv.org/pdf/2310.13270.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomoharu Iwata, Yusuke Tanaka, Naonori Ueda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.13270">Meta-learning of Physics-informed Neural Networks for Efficiently Solving Newly Given PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a neural network-based meta-learning method to efficiently solve partial differential equation (PDE) problems. The proposed method is designed to meta-learn how to solve a wide variety of PDE problems, and uses the knowledge for solving newly given PDE problems. We encode a PDE problem into a problem representation using neural networks, where governing equations are represented by coefficients of a polynomial function of partial derivatives, and boundary conditions are represented by a set of point-condition pairs. We use the problem representation as an input of a neural network for predicting solutions, which enables us to efficiently predict problem-specific solutions by the forwarding process of the neural network without updating model parameters. To train our model, we minimize the expected error when adapted to a PDE problem based on the physics-informed neural network framework, by which we can evaluate the error even when solutions are unknown. We demonstrate that our proposed method outperforms existing methods in predicting solutions of PDE problems.
<div id='section'>Paperid: <span id='pid'>1035, <a href='https://arxiv.org/pdf/2310.06319.pdf' target='_blank'>https://arxiv.org/pdf/2310.06319.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jungang Chen, Eduardo Gildin, John E. Killough
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06319">Transfer learning-based physics-informed convolutional neural network for simulating flow in porous media with time-varying controls</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A physics-informed convolutional neural network is proposed to simulate two phase flow in porous media with time-varying well controls. While most of PICNNs in existing literatures worked on parameter-to-state mapping, our proposed network parameterizes the solution with time-varying controls to establish a control-to-state regression. Firstly, finite volume scheme is adopted to discretize flow equations and formulate loss function that respects mass conservation laws. Neumann boundary conditions are seamlessly incorporated into the semi-discretized equations so no additional loss term is needed. The network architecture comprises two parallel U-Net structures, with network inputs being well controls and outputs being the system states. To capture the time-dependent relationship between inputs and outputs, the network is well designed to mimic discretized state space equations. We train the network progressively for every timestep, enabling it to simultaneously predict oil pressure and water saturation at each timestep. After training the network for one timestep, we leverage transfer learning techniques to expedite the training process for subsequent timestep. The proposed model is used to simulate oil-water porous flow scenarios with varying reservoir gridblocks and aspects including computation efficiency and accuracy are compared against corresponding numerical approaches. The results underscore the potential of PICNN in effectively simulating systems with numerous grid blocks, as computation time does not scale with model dimensionality. We assess the temporal error using 10 different testing controls with variation in magnitude and another 10 with higher alternation frequency with proposed control-to-state architecture. Our observations suggest the need for a more robust and reliable model when dealing with controls that exhibit significant variations in magnitude or frequency.
<div id='section'>Paperid: <span id='pid'>1036, <a href='https://arxiv.org/pdf/2310.05801.pdf' target='_blank'>https://arxiv.org/pdf/2310.05801.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tim De Ryck, Florent Bonnet, Siddhartha Mishra, Emmanuel de BÃ©zenac
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05801">An operator preconditioning perspective on training in physics-informed machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we investigate the behavior of gradient descent algorithms in physics-informed machine learning methods like PINNs, which minimize residuals connected to partial differential equations (PDEs). Our key result is that the difficulty in training these models is closely related to the conditioning of a specific differential operator. This operator, in turn, is associated to the Hermitian square of the differential operator of the underlying PDE. If this operator is ill-conditioned, it results in slow or infeasible training. Therefore, preconditioning this operator is crucial. We employ both rigorous mathematical analysis and empirical evaluations to investigate various strategies, explaining how they better condition this critical operator, and consequently improve training.
<div id='section'>Paperid: <span id='pid'>1037, <a href='https://arxiv.org/pdf/2309.12211.pdf' target='_blank'>https://arxiv.org/pdf/2309.12211.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akshay J. Dave, Richard B. Vilim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.12211">Physics-informed State-space Neural Networks for Transport Phenomena</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces Physics-informed State-space neural network Models (PSMs), a novel solution to achieving real-time optimization, flexibility, and fault tolerance in autonomous systems, particularly in transport-dominated systems such as chemical, biomedical, and power plants. Traditional data-driven methods fall short due to a lack of physical constraints like mass conservation; PSMs address this issue by training deep neural networks with sensor data and physics-informing using components' Partial Differential Equations (PDEs), resulting in a physics-constrained, end-to-end differentiable forward dynamics model. Through two in silico experiments -- a heated channel and a cooling system loop -- we demonstrate that PSMs offer a more accurate approach than a purely data-driven model. In the former experiment, PSMs demonstrated significantly lower average root-mean-square errors across test datasets compared to a purely data-driven neural network, with reductions of 44 %, 48 %, and 94 % in predicting pressure, velocity, and temperature, respectively.
  Beyond accuracy, PSMs demonstrate a compelling multitask capability, making them highly versatile. In this work, we showcase two: supervisory control of a nonlinear system through a sequentially updated state-space representation and the proposal of a diagnostic algorithm using residuals from each of the PDEs. The former demonstrates PSMs' ability to handle constant and time-dependent constraints, while the latter illustrates their value in system diagnostics and fault detection. We further posit that PSMs could serve as a foundation for Digital Twins, constantly updated digital representations of physical systems.
<div id='section'>Paperid: <span id='pid'>1038, <a href='https://arxiv.org/pdf/2309.05404.pdf' target='_blank'>https://arxiv.org/pdf/2309.05404.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nat Wannawas, A. Aldo Faisal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.05404">Physics-informed reinforcement learning via probabilistic co-adjustment functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reinforcement learning of real-world tasks is very data inefficient, and extensive simulation-based modelling has become the dominant approach for training systems. However, in human-robot interaction and many other real-world settings, there is no appropriate one-model-for-all due to differences in individual instances of the system (e.g. different people) or necessary oversimplifications in the simulation models. This requires two approaches: 1. either learning the individual system's dynamics approximately from data which requires data-intensive training or 2. using a complete digital twin of the instances, which may not be realisable in many cases. We introduce two approaches: co-kriging adjustments (CKA) and ridge regression adjustment (RRA) as novel ways to combine the advantages of both approaches. Our adjustment methods are based on an auto-regressive AR1 co-kriging model that we integrate with GP priors. This yield a data- and simulation-efficient way of using simplistic simulation models (e.g., simple two-link model) and rapidly adapting them to individual instances (e.g., biomechanics of individual people). Using CKA and RRA, we obtain more accurate uncertainty quantification of the entire system's dynamics than pure GP-based and AR1 methods. We demonstrate the efficiency of co-kriging adjustment with an interpretable reinforcement learning control example, learning to control a biomechanical human arm using only a two-link arm simulation model (offline part) and CKA derived from a small amount of interaction data (on-the-fly online). Our method unlocks an efficient and uncertainty-aware way to implement reinforcement learning methods in real world complex systems for which only imperfect simulation models exist.
<div id='section'>Paperid: <span id='pid'>1039, <a href='https://arxiv.org/pdf/2309.01697.pdf' target='_blank'>https://arxiv.org/pdf/2309.01697.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>LukÃ¡Å¡ NovÃ¡k, Himanshu Sharma, Michael D. Shields
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.01697">Physics-Informed Polynomial Chaos Expansions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Surrogate modeling of costly mathematical models representing physical systems is challenging since it is typically not possible to create a large experimental design. Thus, it is beneficial to constrain the approximation to adhere to the known physics of the model. This paper presents a novel methodology for the construction of physics-informed polynomial chaos expansions (PCE) that combines the conventional experimental design with additional constraints from the physics of the model. Physical constraints investigated in this paper are represented by a set of differential equations and specified boundary conditions. A computationally efficient means for construction of physically constrained PCE is proposed and compared to standard sparse PCE. It is shown that the proposed algorithms lead to superior accuracy of the approximation and does not add significant computational burden. Although the main purpose of the proposed method lies in combining data and physical constraints, we show that physically constrained PCEs can be constructed from differential equations and boundary conditions alone without requiring evaluations of the original model. We further show that the constrained PCEs can be easily applied for uncertainty quantification through analytical post-processing of a reduced PCE filtering out the influence of all deterministic space-time variables. Several deterministic examples of increasing complexity are provided and the proposed method is applied for uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>1040, <a href='https://arxiv.org/pdf/2308.09605.pdf' target='_blank'>https://arxiv.org/pdf/2308.09605.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guanhang Lei, Zhen Lei, Lei Shi, Chenyu Zeng, Ding-Xuan Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09605">Solving PDEs on Spheres with Physics-Informed Convolutional Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have been demonstrated to be efficient in solving partial differential equations (PDEs) from a variety of experimental perspectives. Some recent studies have also proposed PINN algorithms for PDEs on surfaces, including spheres. However, theoretical understanding of the numerical performance of PINNs, especially PINNs on surfaces or manifolds, is still lacking. In this paper, we establish rigorous analysis of the physics-informed convolutional neural network (PICNN) for solving PDEs on the sphere. By using and improving the latest approximation results of deep convolutional neural networks and spherical harmonic analysis, we prove an upper bound for the approximation error with respect to the Sobolev norm. Subsequently, we integrate this with innovative localization complexity analysis to establish fast convergence rates for PICNN. Our theoretical results are also confirmed and supplemented by our experiments. In light of these findings, we explore potential strategies for circumventing the curse of dimensionality that arises when solving high-dimensional PDEs.
<div id='section'>Paperid: <span id='pid'>1041, <a href='https://arxiv.org/pdf/2308.07352.pdf' target='_blank'>https://arxiv.org/pdf/2308.07352.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shikhar Nilabh, Fidel Grandia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07352">Bayesian Physics-Informed Neural Network for the Forward and Inverse Simulation of Engineered Nano-particles Mobility in a Contaminated Aquifer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Globally, there are many polluted groundwater sites that need an active remediation plan for the restoration of local ecosystem and environment. Engineered nanoparticles (ENPs) have proven to be an effective reactive agent for the in-situ degradation of pollutants in groundwater. While the performance of these ENPs has been highly promising on the laboratory scale, their application in real field case conditions is still limited. The complex transport and retention mechanisms of ENPs hinder the development of an efficient remediation strategy. Therefore, a predictive tool to comprehend the transport and retention behavior of ENPs is highly required. The existing tools in the literature are dominated with numerical simulators, which have limited flexibility and accuracy in the presence of sparse datasets and the aquifer heterogeneity. This work uses a Bayesian Physics-Informed Neural Network (B-PINN) framework to model the nano-particles mobility within an aquifer. The result from the forward model demonstrates the effective capability of B-PINN in accurately predicting the ENPs mobility and quantifying the uncertainty. The inverse model output is then used to predict the governing parameters for the ENPs mobility in a small-scale aquifer. The research demonstrates the capability of the tool to provide predictive insights for developing an efficient groundwater remediation strategy.
<div id='section'>Paperid: <span id='pid'>1042, <a href='https://arxiv.org/pdf/2308.06436.pdf' target='_blank'>https://arxiv.org/pdf/2308.06436.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiyuan Piao, Hong Gu, Aina Wang, Pan Qin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06436">A Domain-adaptive Physics-informed Neural Network for Inverse Problems of Maxwell's Equations in Heterogeneous Media</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Maxwell's equations are a collection of coupled partial differential equations (PDEs) that, together with the Lorentz force law, constitute the basis of classical electromagnetism and electric circuits. Effectively solving Maxwell's equations is crucial in various fields, like electromagnetic scattering and antenna design optimization. Physics-informed neural networks (PINNs) have shown powerful ability in solving PDEs. However, PINNs still struggle to solve Maxwell's equations in heterogeneous media. To this end, we propose a domain-adaptive PINN (da-PINN) to solve inverse problems of Maxwell's equations in heterogeneous media. First, we propose a location parameter of media interface to decompose the whole domain into several sub-domains. Furthermore, the electromagnetic interface conditions are incorporated into a loss function to improve the prediction performance near the interface. Then, we propose a domain-adaptive training strategy for da-PINN. Finally, the effectiveness of da-PINN is verified with two case studies.
<div id='section'>Paperid: <span id='pid'>1043, <a href='https://arxiv.org/pdf/2308.06132.pdf' target='_blank'>https://arxiv.org/pdf/2308.06132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aina Wang, Pan Qin, Xi-Ming Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06132">PDE Discovery for Soft Sensors Using Coupled Physics-Informed Neural Network with Akaike's Information Criterion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Soft sensors have been extensively used to monitor key variables using easy-to-measure variables and mathematical models. Partial differential equations (PDEs) are model candidates for soft sensors in industrial processes with spatiotemporal dependence. However, gaps often exist between idealized PDEs and practical situations. Discovering proper structures of PDEs, including the differential operators and source terms, can remedy the gaps. To this end, a coupled physics-informed neural network with Akaike's criterion information (CPINN-AIC) is proposed for PDE discovery of soft sensors. First, CPINN is adopted for obtaining solutions and source terms satisfying PDEs. Then, we propose a data-physics-hybrid loss function for training CPINN, in which undetermined combinations of differential operators are involved. Consequently, AIC is used to discover the proper combination of differential operators. Finally, the artificial and practical datasets are used to verify the feasibility and effectiveness of CPINN-AIC for soft sensors. The proposed CPINN-AIC is a data-driven method to discover proper PDE structures and neural network-based solutions for soft sensors.
<div id='section'>Paperid: <span id='pid'>1044, <a href='https://arxiv.org/pdf/2307.14675.pdf' target='_blank'>https://arxiv.org/pdf/2307.14675.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alfonso GijÃ³n, Ainhoa Pujana-Goitia, Eugenio Perea, Miguel Molina-Solana, Juan GÃ³mez-Romero
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.14675">Prediction of wind turbines power with physics-informed neural networks and evidential uncertainty quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ever-growing use of wind energy makes necessary the optimization of turbine operations through pitch angle controllers and their maintenance with early fault detection. It is crucial to have accurate and robust models imitating the behavior of wind turbines, especially to predict the generated power as a function of the wind speed. Existing empirical and physics-based models have limitations in capturing the complex relations between the input variables and the power, aggravated by wind variability. Data-driven methods offer new opportunities to enhance wind turbine modeling of large datasets by improving accuracy and efficiency. In this study, we used physics-informed neural networks to reproduce historical data coming from 4 turbines in a wind farm, while imposing certain physical constraints to the model. The developed models for regression of the power, torque, and power coefficient as output variables showed great accuracy for both real data and physical equations governing the system. Lastly, introducing an efficient evidential layer provided uncertainty estimations of the predictions, proved to be consistent with the absolute error, and made possible the definition of a confidence interval in the power curve.
<div id='section'>Paperid: <span id='pid'>1045, <a href='https://arxiv.org/pdf/2307.13869.pdf' target='_blank'>https://arxiv.org/pdf/2307.13869.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Takashi Matsubara, Takaharu Yaguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.13869">Number Theoretic Accelerated Learning of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks solve partial differential equations by training neural networks. Since this method approximates infinite-dimensional PDE solutions with finite collocation points, minimizing discretization errors by selecting suitable points is essential for accelerating the learning process. Inspired by number theoretic methods for numerical analysis, we introduce good lattice training and periodization tricks, which ensure the conditions required by the theory. Our experiments demonstrate that GLT requires 2-7 times fewer collocation points, resulting in lower computational cost, while achieving competitive performance compared to typical sampling methods.
<div id='section'>Paperid: <span id='pid'>1046, <a href='https://arxiv.org/pdf/2307.12304.pdf' target='_blank'>https://arxiv.org/pdf/2307.12304.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>R. Sharma, W. Grace Guo, M. Raissi, Y. B. Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.12304">Physics-Informed Machine Learning of Argon Gas-Driven Melt Pool Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Melt pool dynamics in metal additive manufacturing (AM) is critical to process stability, microstructure formation, and final properties of the printed materials. Physics-based simulation including computational fluid dynamics (CFD) is the dominant approach to predict melt pool dynamics. However, the physics-based simulation approaches suffer from the inherent issue of very high computational cost. This paper provides a physics-informed machine learning (PIML) method by integrating neural networks with the governing physical laws to predict the melt pool dynamics such as temperature, velocity, and pressure without using any training data on velocity. This approach avoids solving the highly non-linear Navier-Stokes equation numerically, which significantly reduces the computational cost. The difficult-to-determine model constants of the governing equations of the melt pool can also be inferred through data-driven discovery. In addition, the physics-informed neural network (PINN) architecture has been optimized for efficient model training. The data-efficient PINN model is attributed to the soft penalty by incorporating governing partial differential equations (PDEs), initial conditions, and boundary conditions in the PINN model.
<div id='section'>Paperid: <span id='pid'>1047, <a href='https://arxiv.org/pdf/2307.09236.pdf' target='_blank'>https://arxiv.org/pdf/2307.09236.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu-Hau Tseng, Ming-Chih Lai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.09236">A discontinuity and cusp capturing PINN for Stokes interface problems with discontinuous viscosity and singular forces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present a discontinuity and cusp capturing physics-informed neural network (PINN) to solve Stokes equations with a piecewise-constant viscosity and singular force along an interface. We first reformulate the governing equations in each fluid domain separately and replace the singular force effect with the traction balance equation between solutions in two sides along the interface. Since the pressure is discontinuous and the velocity has discontinuous derivatives across the interface, we hereby use a network consisting of two fully-connected sub-networks that approximate the pressure and velocity, respectively. The two sub-networks share the same primary coordinate input arguments but with different augmented feature inputs. These two augmented inputs provide the interface information, so we assume that a level set function is given and its zero level set indicates the position of the interface. The pressure sub-network uses an indicator function as an augmented input to capture the function discontinuity, while the velocity sub-network uses a cusp-enforced level set function to capture the derivative discontinuities via the traction balance equation. We perform a series of numerical experiments to solve two- and three-dimensional Stokes interface problems and perform an accuracy comparison with the augmented immersed interface methods in literature. Our results indicate that even a shallow network with a moderate number of neurons and sufficient training data points can achieve prediction accuracy comparable to that of immersed interface methods.
<div id='section'>Paperid: <span id='pid'>1048, <a href='https://arxiv.org/pdf/2307.07975.pdf' target='_blank'>https://arxiv.org/pdf/2307.07975.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shamil Mamedov, A. RenÃ© Geist, Jan Swevers, Sebastian Trimpe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.07975">Pseudo-rigid body networks: learning interpretable deformable object dynamics from partial observations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting deformable linear object (DLO) dynamics is challenging, especially when the task requires a model that is both human-interpretable and computationally efficient. In this work, we draw inspiration from the pseudo-rigid body method (PRB) and model a DLO as a serial chain of rigid bodies whose internal state is unrolled through time by a dynamics network. This dynamics network is trained jointly with a physics-informed encoder that maps observed motion variables to the DLO's hidden state. To encourage the state to acquire a physically meaningful representation, we leverage the forward kinematics of the PRB model as a decoder. We demonstrate in robot experiments that the proposed DLO dynamics model provides physically interpretable predictions from partial observations while being on par with black-box models regarding prediction accuracy. The project code is available at: http://tinyurl.com/prb-networks
<div id='section'>Paperid: <span id='pid'>1049, <a href='https://arxiv.org/pdf/2307.01066.pdf' target='_blank'>https://arxiv.org/pdf/2307.01066.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seokhyun Moon, Sang-Yeon Hwang, Jaechang Lim, Woo Youn Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.01066">PIGNet2: A Versatile Deep Learning-based Protein-Ligand Interaction Prediction Model for Binding Affinity Scoring and Virtual Screening</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prediction of protein-ligand interactions (PLI) plays a crucial role in drug discovery as it guides the identification and optimization of molecules that effectively bind to target proteins. Despite remarkable advances in deep learning-based PLI prediction, the development of a versatile model capable of accurately scoring binding affinity and conducting efficient virtual screening remains a challenge. The main obstacle in achieving this lies in the scarcity of experimental structure-affinity data, which limits the generalization ability of existing models. Here, we propose a viable solution to address this challenge by introducing a novel data augmentation strategy combined with a physics-informed graph neural network. The model showed significant improvements in both scoring and screening, outperforming task-specific deep learning models in various tests including derivative benchmarks, and notably achieving results comparable to the state-of-the-art performance based on distance likelihood learning. This demonstrates the potential of this approach to drug discovery.
<div id='section'>Paperid: <span id='pid'>1050, <a href='https://arxiv.org/pdf/2306.13395.pdf' target='_blank'>https://arxiv.org/pdf/2306.13395.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahul Sundar, Dipanjan Majumdar, Didier Lucor, Sunetra Sarkar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13395">Physics-informed neural networks modeling for systems with moving immersed boundaries: application to an unsteady flow past a plunging foil</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, physics informed neural networks (PINNs) have been explored extensively for solving various forward and inverse problems and facilitating querying applications in fluid mechanics applications. However, work on PINNs for unsteady flows past moving bodies, such as flapping wings is scarce. Earlier studies mostly relied on transferring to a body attached frame of reference which is restrictive towards handling multiple moving bodies or deforming structures. Hence, in the present work, an immersed boundary aware framework has been explored for developing surrogate models for unsteady flows past moving bodies. Specifically, simultaneous pressure recovery and velocity reconstruction from Immersed boundary method (IBM) simulation data has been investigated. While, efficacy of velocity reconstruction has been tested against the fine resolution IBM data, as a step further, the pressure recovered was compared with that of an arbitrary Lagrange Eulerian (ALE) based solver. Under this framework, two PINN variants, (i) a moving-boundary-enabled standard Navier-Stokes based PINN (MB-PINN), and, (ii) a moving-boundary-enabled IBM based PINN (MB-IBM-PINN) have been formulated. A fluid-solid partitioning of the physics losses in MB-IBM-PINN has been allowed, in order to investigate the effects of solid body points while training. This enables MB-IBM-PINN to match with the performance of MB-PINN under certain loss weighting conditions. MB-PINN is found to be superior to MB-IBM-PINN when {\it a priori} knowledge of the solid body position and velocity are available. To improve the data efficiency of MB-PINN, a physics based data sampling technique has also been investigated. It is observed that a suitable combination of physics constraint relaxation and physics based sampling can achieve a model performance comparable to the case of using all the data points, under a fixed training budget.
<div id='section'>Paperid: <span id='pid'>1051, <a href='https://arxiv.org/pdf/2306.11023.pdf' target='_blank'>https://arxiv.org/pdf/2306.11023.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felix F Zimmermann, Christoph Kolbitsch, Patrick Schuenke, Andreas Kofler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.11023">PINQI: An End-to-End Physics-Informed Approach to Learned Quantitative MRI Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantitative Magnetic Resonance Imaging (qMRI) enables the reproducible measurement of biophysical parameters in tissue. The challenge lies in solving a nonlinear, ill-posed inverse problem to obtain the desired tissue parameter maps from acquired raw data. While various learned and non-learned approaches have been proposed, the existing learned methods fail to fully exploit the prior knowledge about the underlying MR physics, i.e. the signal model and the acquisition model. In this paper, we propose PINQI, a novel qMRI reconstruction method that integrates the knowledge about the signal, acquisition model, and learned regularization into a single end-to-end trainable neural network. Our approach is based on unrolled alternating optimization, utilizing differentiable optimization blocks to solve inner linear and non-linear optimization tasks, as well as convolutional layers for regularization of the intermediate qualitative images and parameter maps. This design enables PINQI to leverage the advantages of both the signal model and learned regularization. We evaluate the performance of our proposed network by comparing it with recently published approaches in the context of highly undersampled $T_1$-mapping, using both a simulated brain dataset, as well as real scanner data acquired from a physical phantom and in-vivo data from healthy volunteers. The results demonstrate the superiority of our proposed solution over existing methods and highlight the effectiveness of our method in real-world scenarios.
<div id='section'>Paperid: <span id='pid'>1052, <a href='https://arxiv.org/pdf/2306.08293.pdf' target='_blank'>https://arxiv.org/pdf/2306.08293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shikhar Nilabh, Fidel Grandia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.08293">Efficient Training of Physics-Informed Neural Networks with Direct Grid Refinement Algorithm</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This research presents the development of an innovative algorithm tailored for the adaptive sampling of residual points within the framework of Physics-Informed Neural Networks (PINNs). By addressing the limitations inherent in existing adaptive sampling techniques, our proposed methodology introduces a direct mesh refinement approach that effectively ensures both computational efficiency and adaptive point placement. Verification studies were conducted to evaluate the performance of our algorithm, showcasing reasonable agreement between the model based on our novel approach and benchmark model results. Comparative analyses with established adaptive resampling techniques demonstrated the superior performance of our approach, particularly when implemented with higher refinement factor. Overall, our findings highlight the enhancement of simulation accuracy achievable through the application of our adaptive sampling algorithm for Physics-Informed Neural Networks.
<div id='section'>Paperid: <span id='pid'>1053, <a href='https://arxiv.org/pdf/2306.06034.pdf' target='_blank'>https://arxiv.org/pdf/2306.06034.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shinjan Ghosh, Amit Chakraborty, Georgia Olympia Brikis, Biswadip Dey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06034">RANS-PINN based Simulation Surrogates for Predicting Turbulent Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) provide a framework to build surrogate models for dynamical systems governed by differential equations. During the learning process, PINNs incorporate a physics-based regularization term within the loss function to enhance generalization performance. Since simulating dynamics controlled by partial differential equations (PDEs) can be computationally expensive, PINNs have gained popularity in learning parametric surrogates for fluid flow problems governed by Navier-Stokes equations. In this work, we introduce RANS-PINN, a modified PINN framework, to predict flow fields (i.e., velocity and pressure) in high Reynolds number turbulent flow regimes. To account for the additional complexity introduced by turbulence, RANS-PINN employs a 2-equation eddy viscosity model based on a Reynolds-averaged Navier-Stokes (RANS) formulation. Furthermore, we adopt a novel training approach that ensures effective initialization and balance among the various components of the loss function. The effectiveness of the RANS-PINN framework is then demonstrated using a parametric PINN.
<div id='section'>Paperid: <span id='pid'>1054, <a href='https://arxiv.org/pdf/2306.05554.pdf' target='_blank'>https://arxiv.org/pdf/2306.05554.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jassem Abbasi, PÃ¥l ÃstebÃ¸ Andersen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.05554">Simulation and Prediction of Countercurrent Spontaneous Imbibition at Early and Late Times Using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The application of Physics-Informed Neural Networks (PINNs) is investigated for the first time in solving the one-dimensional Countercurrent spontaneous imbibition (COUCSI) problem at both early and late time (i.e., before and after the imbibition front meets the no-flow boundary). We introduce utilization of Change-of-Variables as a technique for improving performance of PINNs. We formulated the COUCSI problem in three equivalent forms by changing the independent variables. The first describes saturation as function of normalized position X and time T; the second as function of X and Y=T^0.5; and the third as a sole function of Z=X/T^0.5 (valid only at early time). The PINN model was generated using a feed-forward neural network and trained based on minimizing a weighted loss function, including the physics-informed loss term and terms corresponding to the initial and boundary conditions. All three formulations could closely approximate the correct solutions, with water saturation mean absolute errors around 0.019 and 0.009 for XT and XY formulations and 0.012 for the Z formulation at early time. The Z formulation perfectly captured the self-similarity of the system at early time. This was less captured by XT and XY formulations. The total variation of saturation was preserved in the Z formulation, and it was better preserved with XY- than XT formulation. Redefining the problem based on the physics-inspired variables reduced the non-linearity of the problem and allowed higher solution accuracies, a higher degree of loss-landscape convexity, a lower number of required collocation points, smaller network sizes, and more computationally efficient solutions.
<div id='section'>Paperid: <span id='pid'>1055, <a href='https://arxiv.org/pdf/2306.05486.pdf' target='_blank'>https://arxiv.org/pdf/2306.05486.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Victorita Dolean, Alexander Heinlein, Siddhartha Mishra, Ben Moseley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.05486">Multilevel domain decomposition-based architectures for physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are a powerful approach for solving problems involving differential equations, yet they often struggle to solve problems with high frequency and/or multi-scale solutions. Finite basis physics-informed neural networks (FBPINNs) improve the performance of PINNs in this regime by combining them with an overlapping domain decomposition approach. In this work, FBPINNs are extended by adding multiple levels of domain decompositions to their solution ansatz, inspired by classical multilevel Schwarz domain decomposition methods (DDMs). Analogous to typical tests for classical DDMs, we assess how the accuracy of PINNs, FBPINNs and multilevel FBPINNs scale with respect to computational effort and solution complexity by carrying out strong and weak scaling tests. Our numerical results show that the proposed multilevel FBPINNs consistently and significantly outperform PINNs across a range of problems with high frequency and multi-scale solutions. Furthermore, as expected in classical DDMs, we show that multilevel FBPINNs improve the accuracy of FBPINNs when using large numbers of subdomains by aiding global communication between subdomains.
<div id='section'>Paperid: <span id='pid'>1056, <a href='https://arxiv.org/pdf/2305.15111.pdf' target='_blank'>https://arxiv.org/pdf/2305.15111.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elise Ãzalp, Georgios Margazoglou, Luca Magri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.15111">Reconstruction, forecasting, and stability of chaotic dynamics from partial data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The forecasting and computation of the stability of chaotic systems from partial observations are tasks for which traditional equation-based methods may not be suitable. In this computational paper, we propose data-driven methods to (i) infer the dynamics of unobserved (hidden) chaotic variables (full-state reconstruction); (ii) time forecast the evolution of the full state; and (iii) infer the stability properties of the full state. The tasks are performed with long short-term memory (LSTM) networks, which are trained with observations (data) limited to only part of the state: (i) the low-to-high resolution LSTM (LH-LSTM), which takes partial observations as training input, and requires access to the full system state when computing the loss; and (ii) the physics-informed LSTM (PI-LSTM), which is designed to combine partial observations with the integral formulation of the dynamical system's evolution equations. First, we derive the Jacobian of the LSTMs. Second, we analyse a chaotic partial differential equation, the Kuramoto-Sivashinsky (KS), and the Lorenz-96 system. We show that the proposed networks can forecast the hidden variables, both time-accurately and statistically. The Lyapunov exponents and covariant Lyapunov vectors, which characterize the stability of the chaotic attractors, are correctly inferred from partial observations. Third, the PI-LSTM outperforms the LH-LSTM by successfully reconstructing the hidden chaotic dynamics when the input dimension is smaller or similar to the Kaplan-Yorke dimension of the attractor. This work opens new opportunities for reconstructing the full state, inferring hidden variables, and computing the stability of chaotic systems from partial data.
<div id='section'>Paperid: <span id='pid'>1057, <a href='https://arxiv.org/pdf/2305.09056.pdf' target='_blank'>https://arxiv.org/pdf/2305.09056.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jungang Chen, Eduardo Gildin, John E. Killough
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09056">Physics-informed Convolutional Recurrent Surrogate Model for Reservoir Simulation with Well Controls</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel surrogate model for modeling subsurface fluid flow with well controls using a physics-informed convolutional recurrent neural network (PICRNN). The model uses a convolutional long-short term memory (ConvLSTM) to capture the spatiotemporal dependencies of the state evolution dynamics in the porous flow. The ConvLSTM is linked to the state space equations, enabling the incorporation of a discrete-time sequence of well control. The model requires initial state condition and a sequence of well controls as inputs, and predicts the state variables of the system, such as pressure, as output. By minimizing the residuals of reservoir flow state-space equations, the network is trained without the need for labeled data. The model is designed to serve as a surrogate model for predicting future reservoir states based on the initial reservoir state and input engineering controls. Boundary conditions are enforced into the state-space equations so no additional loss term is needed. Three numerical cases are studied, demonstrating the model's effectiveness in predicting reservoir dynamics based on future well/system controls. The proposed model provides a new approach for efficient and accurate prediction of subsurface fluid flow, with potential applications in optimal control design for reservoir engineering.
<div id='section'>Paperid: <span id='pid'>1058, <a href='https://arxiv.org/pdf/2305.07524.pdf' target='_blank'>https://arxiv.org/pdf/2305.07524.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hoai Nam Dang, Vladimir Golkov, Thomas Wimmer, Daniel Cremers, Andreas Maier, Moritz Zaiss
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.07524">Joint MR sequence optimization beats pure neural network approaches for spin-echo MRI super-resolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current MRI super-resolution (SR) methods only use existing contrasts acquired from typical clinical sequences as input for the neural network (NN). In turbo spin echo sequences (TSE) the sequence parameters can have a strong influence on the actual resolution of the acquired image and have consequently a considera-ble impact on the performance of the NN. We propose a known-operator learning approach to perform an end-to-end optimization of MR sequence and neural net-work parameters for SR-TSE. This MR-physics-informed training procedure jointly optimizes the radiofrequency pulse train of a proton density- (PD-) and T2-weighted TSE and a subsequently applied convolutional neural network to predict the corresponding PDw and T2w super-resolution TSE images. The found radiofrequency pulse train designs generate an optimal signal for the NN to perform the SR task. Our method generalizes from the simulation-based optimi-zation to in vivo measurements and the acquired physics-informed SR images show higher correlation with a time-consuming segmented high-resolution TSE sequence compared to a pure network training approach.
<div id='section'>Paperid: <span id='pid'>1059, <a href='https://arxiv.org/pdf/2305.04107.pdf' target='_blank'>https://arxiv.org/pdf/2305.04107.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aditya Joglekar, Hongrui Chen, Levent Burak Kara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.04107">DMF-TONN: Direct Mesh-free Topology Optimization using Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a direct mesh-free method for performing topology optimization by integrating a density field approximation neural network with a displacement field approximation neural network. We show that this direct integration approach can give comparable results to conventional topology optimization techniques, with an added advantage of enabling seamless integration with post-processing software, and a potential of topology optimization with objectives where meshing and Finite Element Analysis (FEA) may be expensive or not suitable. Our approach (DMF-TONN) takes in as inputs the boundary conditions and domain coordinates and finds the optimum density field for minimizing the loss function of compliance and volume fraction constraint violation. The mesh-free nature is enabled by a physics-informed displacement field approximation neural network to solve the linear elasticity partial differential equation and replace the FEA conventionally used for calculating the compliance. We show that using a suitable Fourier Features neural network architecture and hyperparameters, the density field approximation neural network can learn the weights to represent the optimal density field for the given domain and boundary conditions, by directly backpropagating the loss gradient through the displacement field approximation neural network, and unlike prior work there is no requirement of a sensitivity filter, optimality criterion method, or a separate training of density network in each topology optimization iteration.
<div id='section'>Paperid: <span id='pid'>1060, <a href='https://arxiv.org/pdf/2304.13897.pdf' target='_blank'>https://arxiv.org/pdf/2304.13897.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kshitiz Upadhyay, Jan N. Fuhg, Nikolaos Bouklas, K. T. Ramesh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.13897">Physics-informed Data-driven Discovery of Constitutive Models with Application to Strain-Rate-sensitive Soft Materials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A novel data-driven constitutive modeling approach is proposed, which combines the physics-informed nature of modeling based on continuum thermodynamics with the benefits of machine learning. This approach is demonstrated on strain-rate-sensitive soft materials. This model is based on the viscous dissipation-based visco-hyperelasticity framework where the total stress is decomposed into volumetric, isochoric hyperelastic, and isochoric viscous overstress contributions. It is shown that each of these stress components can be written as linear combinations of the components of an irreducible integrity basis. Three Gaussian process regression-based surrogate models are trained (one per stress component) between principal invariants of strain and strain rate tensors and the corresponding coefficients of the integrity basis components. It is demonstrated that this type of model construction enforces key physics-based constraints on the predicted responses: the second law of thermodynamics, the principles of local action and determinism, objectivity, the balance of angular momentum, an assumed reference state, isotropy, and limited memory. The three surrogate models that constitute our constitutive model are evaluated by training them on small-size numerically generated data sets corresponding to a single deformation mode and then analyzing their predictions over a much wider testing regime comprising multiple deformation modes. Our physics-informed data-driven constitutive model predictions are compared with the corresponding predictions of classical continuum thermodynamics-based and purely data-driven models. It is shown that our surrogate models can reasonably capture the stress-strain-strain rate responses in both training and testing regimes, and provide improvements in terms of prediction accuracy, generalizability to multiple deformation modes, and compatibility with limited data.
<div id='section'>Paperid: <span id='pid'>1061, <a href='https://arxiv.org/pdf/2304.13799.pdf' target='_blank'>https://arxiv.org/pdf/2304.13799.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kamaljyoti Nath, Xuhui Meng, Daniel J Smith, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.13799">Physics-informed neural networks for predicting gas flow dynamics and unknown parameters in diesel engines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a physics-informed neural network (PINN) approach for monitoring the health of diesel engines. The aim is to evaluate the engine dynamics, identify unknown parameters in a "mean value" model, and anticipate maintenance requirements. The PINN model is applied to diesel engines with a variable-geometry turbocharger and exhaust gas recirculation, using measurement data of selected state variables. The results demonstrate the ability of the PINN model to predict simultaneously both unknown parameters and dynamics accurately with both clean and noisy data, and the importance of the self-adaptive weight in the loss function for faster convergence. The input data for these simulations are derived from actual engine running conditions, while the outputs are simulated data, making this a practical case study of PINN's ability to predict real-world dynamical systems. The mean value model of the diesel engine incorporates empirical formulae to represent certain states, but these formulae may not be generalizable to other engines. To address this, the study considers the use of deep neural networks (DNNs) in addition to the PINN model. The DNNs are trained using laboratory test data and are used to model the engine-specific empirical formulae in the mean value model, allowing for a more flexible and adaptive representation of the engine's states. In other words, the mean value model uses both the PINN model and the DNNs to represent the engine's states, with the PINN providing a physics-based understanding of the engine's overall dynamics and the DNNs offering a more engine-specific and adaptive representation of the empirical formulae. By combining these two approaches, the study aims to offer a comprehensive and versatile approach to monitoring the health and performance of diesel engines.
<div id='section'>Paperid: <span id='pid'>1062, <a href='https://arxiv.org/pdf/2304.03552.pdf' target='_blank'>https://arxiv.org/pdf/2304.03552.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hamid El Bahja, Jan Christian Hauffen, Peter Jung, Bubacarr Bah, Issa Karambal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.03552">A physics-informed neural network framework for modeling obstacle-related equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has been highly successful in some applications. Nevertheless, its use for solving partial differential equations (PDEs) has only been of recent interest with current state-of-the-art machine learning libraries, e.g., TensorFlow or PyTorch. Physics-informed neural networks (PINNs) are an attractive tool for solving partial differential equations based on sparse and noisy data. Here extend PINNs to solve obstacle-related PDEs which present a great computational challenge because they necessitate numerical methods that can yield an accurate approximation of the solution that lies above a given obstacle. The performance of the proposed PINNs is demonstrated in multiple scenarios for linear and nonlinear PDEs subject to regular and irregular obstacles.
<div id='section'>Paperid: <span id='pid'>1063, <a href='https://arxiv.org/pdf/2304.00369.pdf' target='_blank'>https://arxiv.org/pdf/2304.00369.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taniya Kapoor, Hongrui Wang, Alfredo NÃºÃ±ez, Rolf Dollevoet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.00369">Physics-informed machine learning for moving load problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a new approach to simulate forward and inverse problems of moving loads using physics-informed machine learning (PIML). Physics-informed neural networks (PINNs) utilize the underlying physics of moving load problems and aim to predict the deflection of beams and the magnitude of the loads. The mathematical representation of the moving load considered in this work involves a Dirac delta function, to capture the effect of the load moving across the structure. Approximating the Dirac delta function with PINNs is challenging because of its instantaneous change of output at a single point, causing difficulty in the convergence of the loss function. We propose to approximate the Dirac delta function with a Gaussian function. The incorporated Gaussian function physical equations are used in the physics-informed neural architecture to simulate beam deflections and to predict the magnitude of the load. Numerical results show that PIML is an effective method for simulating the forward and inverse problems for the considered model of a moving load.
<div id='section'>Paperid: <span id='pid'>1064, <a href='https://arxiv.org/pdf/2303.13634.pdf' target='_blank'>https://arxiv.org/pdf/2303.13634.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Kashefi, Leonidas J. Guibas, Tapan Mukerji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.13634">Physics-informed PointNet: On how many irregular geometries can it solve an inverse problem simultaneously? Application to linear elasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Regular physics-informed neural networks (PINNs) predict the solution of partial differential equations using sparse labeled data but only over a single domain. On the other hand, fully supervised learning models are first trained usually over a few thousand domains with known solutions (i.e., labeled data) and then predict the solution over a few hundred unseen domains. Physics-informed PointNet (PIPN) is primarily designed to fill this gap between PINNs (as weakly supervised learning models) and fully supervised learning models. In this article, we demonstrate that PIPN predicts the solution of desired partial differential equations over a few hundred domains simultaneously, while it only uses sparse labeled data. This framework benefits fast geometric designs in the industry when only sparse labeled data are available. Particularly, we show that PIPN predicts the solution of a plane stress problem over more than 500 domains with different geometries, simultaneously. Moreover, we pioneer implementing the concept of remarkable batch size (i.e., the number of geometries fed into PIPN at each sub-epoch) into PIPN. Specifically, we try batch sizes of 7, 14, 19, 38, 76, and 133. Additionally, the effect of the PIPN size, symmetric function in the PIPN architecture, and static and dynamic weights for the component of the sparse labeled data in the loss function are investigated.
<div id='section'>Paperid: <span id='pid'>1065, <a href='https://arxiv.org/pdf/2303.12093.pdf' target='_blank'>https://arxiv.org/pdf/2303.12093.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Kashefi, Tapan Mukerji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.12093">ChatGPT for Programming Numerical Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>ChatGPT is a large language model recently released by the OpenAI company. In this technical report, we explore for the first time the capability of ChatGPT for programming numerical algorithms. Specifically, we examine the capability of GhatGPT for generating codes for numerical algorithms in different programming languages, for debugging and improving written codes by users, for completing missed parts of numerical codes, rewriting available codes in other programming languages, and for parallelizing serial codes. Additionally, we assess if ChatGPT can recognize if given codes are written by humans or machines. To reach this goal, we consider a variety of mathematical problems such as the Poisson equation, the diffusion equation, the incompressible Navier-Stokes equations, compressible inviscid flow, eigenvalue problems, solving linear systems of equations, storing sparse matrices, etc. Furthermore, we exemplify scientific machine learning such as physics-informed neural networks and convolutional neural networks with applications to computational physics. Through these examples, we investigate the successes, failures, and challenges of ChatGPT. Examples of failures are producing singular matrices, operations on arrays with incompatible sizes, programming interruption for relatively long codes, etc. Our outcomes suggest that ChatGPT can successfully program numerical algorithms in different programming languages, but certain limitations and challenges exist that require further improvement of this machine learning model.
<div id='section'>Paperid: <span id='pid'>1066, <a href='https://arxiv.org/pdf/2303.02542.pdf' target='_blank'>https://arxiv.org/pdf/2303.02542.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zilin Li, Jinshuai Bai, Huajing Ouyang, Saulo Martelli, Jun Zhao, Ming Tang, Yang Yang, Hongtao Wei, Pan Liu, Wei-Ron Han, Yuantong Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02542">Physics-informed neural network for friction-involved nonsmooth dynamics problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Friction-induced vibration (FIV) is very common in engineering areas. Analysing the dynamic behaviour of systems containing a multiple-contact point frictional interface is an important topic. However, accurately simulating nonsmooth/discontinuous dynamic behaviour due to friction is challenging. This paper presents a new physics-informed neural network approach for solving nonsmooth friction-induced vibration or friction-involved vibration problems. Compared with schemes of the conventional time-stepping methodology, in this new computational framework, the theoretical formulations of nonsmooth multibody dynamics are transformed and embedded in the training process of the neural network. Major findings include that the new framework not only can perform accurate simulation of nonsmooth dynamic behaviour, but also eliminate the need for extremely small time steps typically associated with the conventional time-stepping methodology for multibody systems, thus saving much computation work while maintaining high accuracy. Specifically, four kinds of high-accuracy PINN-based methods are proposed: (1) single PINN; (2) dual PINN; (3) advanced single PINN; (4) advanced dual PINN. Two typical dynamics problems with nonsmooth contact are tested: one is a 1-dimensional contact problem with stick-slip, and the other is a 2-dimensional contact problem considering separation-reattachment and stick-slip oscillation. Both single and dual PINN methods show their advantages in dealing with the 1-dimensional stick-slip problem, which outperforms conventional methods across friction models that are difficult to simulate by the conventional time-stepping method. For the 2-dimensional problem, the capability of the advanced single and advanced dual PINN on accuracy improvement is shown, and they provide good results even in the cases when conventional methods fail.
<div id='section'>Paperid: <span id='pid'>1067, <a href='https://arxiv.org/pdf/2303.01055.pdf' target='_blank'>https://arxiv.org/pdf/2303.01055.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taniya Kapoor, Hongrui Wang, Alfredo Nunez, Rolf Dollevoet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01055">Physics-informed neural networks for solving forward and inverse problems in complex beam systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a new framework using physics-informed neural networks (PINNs) to simulate complex structural systems that consist of single and double beams based on Euler-Bernoulli and Timoshenko theory, where the double beams are connected with a Winkler foundation. In particular, forward and inverse problems for the Euler-Bernoulli and Timoshenko partial differential equations (PDEs) are solved using nondimensional equations with the physics-informed loss function. Higher-order complex beam PDEs are efficiently solved for forward problems to compute the transverse displacements and cross-sectional rotations with less than 1e-3 percent error. Furthermore, inverse problems are robustly solved to determine the unknown dimensionless model parameters and applied force in the entire space-time domain, even in the case of noisy data. The results suggest that PINNs are a promising strategy for solving problems in engineering structures and machines involving beam systems.
<div id='section'>Paperid: <span id='pid'>1068, <a href='https://arxiv.org/pdf/2302.13163.pdf' target='_blank'>https://arxiv.org/pdf/2302.13163.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Johannes MÃ¼ller, Marius Zeinhofer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.13163">Achieving High Accuracy with PINNs via Energy Natural Gradients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose energy natural gradient descent, a natural gradient method with respect to a Hessian-induced Riemannian metric as an optimization algorithm for physics-informed neural networks (PINNs) and the deep Ritz method. As a main motivation we show that the update direction in function space resulting from the energy natural gradient corresponds to the Newton direction modulo an orthogonal projection onto the model's tangent space. We demonstrate experimentally that energy natural gradient descent yields highly accurate solutions with errors several orders of magnitude smaller than what is obtained when training PINNs with standard optimizers like gradient descent or Adam, even when those are allowed significantly more computation time.
<div id='section'>Paperid: <span id='pid'>1069, <a href='https://arxiv.org/pdf/2302.10779.pdf' target='_blank'>https://arxiv.org/pdf/2302.10779.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elise Ãzalp, Georgios Margazoglou, Luca Magri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10779">Physics-Informed Long Short-Term Memory for Forecasting and Reconstruction of Chaos</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present the Physics-Informed Long Short-Term Memory (PI-LSTM) network to reconstruct and predict the evolution of unmeasured variables in a chaotic system. The training is constrained by a regularization term, which penalizes solutions that violate the system's governing equations. The network is showcased on the Lorenz-96 model, a prototypical chaotic dynamical system, for a varying number of variables to reconstruct. First, we show the PI-LSTM architecture and explain how to constrain the differential equations, which is a non-trivial task in LSTMs. Second, the PI-LSTM is numerically evaluated in the long-term autonomous evolution to study its ergodic properties. We show that it correctly predicts the statistics of the unmeasured variables, which cannot be achieved without the physical constraint. Third, we compute the Lyapunov exponents of the network to infer the key stability properties of the chaotic system. For reconstruction purposes, adding the physics-informed loss qualitatively enhances the dynamical behaviour of the network, compared to a data-driven only training. This is quantified by the agreement of the Lyapunov exponents. This work opens up new opportunities for state reconstruction and learning of the dynamics of nonlinear systems.
<div id='section'>Paperid: <span id='pid'>1070, <a href='https://arxiv.org/pdf/2301.08618.pdf' target='_blank'>https://arxiv.org/pdf/2301.08618.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aina Wang, Pan Qin, Xi-Ming Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.08618">Solving PDEs with Unmeasurable Source Terms Using Coupled Physics-Informed Neural Network with Recurrent Prediction for Soft Sensors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial differential equations (PDEs) are a model candidate for soft sensors in industrial processes with spatiotemporal dependence. Although physics-informed neural networks (PINNs) are a promising machine learning method for solving PDEs, they are infeasible for the nonhomogeneous PDEs with unmeasurable source terms. To this end, a coupled PINN (CPINN) with a recurrent prediction (RP) learning strategy (CPINN- RP) is proposed. First, CPINN composed of NetU and NetG is proposed. NetU is for approximating PDEs solutions and NetG is for regularizing the training of NetU. The two networks are integrated into a data-physics-hybrid loss function. Then, we theoretically prove that the proposed CPINN has a satisfying approximation capability for solutions to nonhomogeneous PDEs with unmeasurable source terms. Besides the theoretical aspects, we propose a hierarchical training strategy to optimize and couple NetU and NetG. Secondly, NetU-RP is proposed for compensating information loss in data sampling to improve the prediction performance, in which RP is the recurrently delayed outputs of well-trained CPINN and hard sensors. Finally, the artificial and practical datasets are used to verify the feasibility and effectiveness of CPINN-RP for soft sensors.
<div id='section'>Paperid: <span id='pid'>1071, <a href='https://arxiv.org/pdf/2301.04887.pdf' target='_blank'>https://arxiv.org/pdf/2301.04887.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan-Esteban Suarez Cardona, Phil-Alexander Hofmann, Michael Hecht
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.04887">Learning Partial Differential Equations by Spectral Approximates of General Sobolev Spaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel spectral, finite-dimensional approximation of general Sobolev spaces in terms of Chebyshev polynomials. Based on this polynomial surrogate model (PSM), we realise a variational formulation, solving a vast class of linear and non-linear partial differential equations (PDEs). The PSMs are as flexible as the physics-informed neural nets (PINNs) and provide an alternative for addressing inverse PDE problems, such as PDE-parameter inference. In contrast to PINNs, the PSMs result in a convex optimisation problem for a vast class of PDEs, including all linear ones, in which case the PSM-approximate is efficiently computable due to the exponential convergence rate of the underlying variational gradient descent.
  As a practical consequence prominent PDE problems were resolved by the PSMs without High Performance Computing (HPC) on a local machine. This gain in efficiency is complemented by an increase of approximation power, outperforming PINN alternatives in both accuracy and runtime.
  Beyond the empirical evidence we give here, the translation of classic PDE theory in terms of the Sobolev space approximates suggests the PSMs to be universally applicable to well-posed, regular forward and inverse PDE problems.
<div id='section'>Paperid: <span id='pid'>1072, <a href='https://arxiv.org/pdf/2212.07723.pdf' target='_blank'>https://arxiv.org/pdf/2212.07723.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Anton, Henning Wessels
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.07723">Physics-Informed Neural Networks for Material Model Calibration from Full-Field Displacement Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The identification of material parameters occurring in constitutive models has a wide range of applications in practice. One of these applications is the monitoring and assessment of the actual condition of infrastructure buildings, as the material parameters directly reflect the resistance of the structures to external impacts. Physics-informed neural networks (PINNs) have recently emerged as a suitable method for solving inverse problems. The advantages of this method are a straightforward inclusion of observation data. Unlike grid-based methods, such as the least square finite element method (LS-FEM) approach, no computational grid and no interpolation of the data is required. In the current work, we propose PINNs for the calibration of constitutive models from full-field displacement and global force data in a realistic regime on the example of linear elasticity. We show that conditioning and reformulation of the optimization problem play a crucial role in real-world applications. Therefore, among others, we identify the material parameters from initial estimates and balance the individual terms in the loss function. In order to reduce the dependency of the identified material parameters on local errors in the displacement approximation, we base the identification not on the stress boundary conditions but instead on the global balance of internal and external work. We demonstrate that the enhanced PINNs are capable of identifying material parameters from both experimental one-dimensional data and synthetic full-field displacement data in a realistic regime. Since displacement data measured by, e.g., a digital image correlation (DIC) system is noisy, we additionally investigate the robustness of the method to different levels of noise.
<div id='section'>Paperid: <span id='pid'>1073, <a href='https://arxiv.org/pdf/2212.05523.pdf' target='_blank'>https://arxiv.org/pdf/2212.05523.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongyan Li, Song Jiang, Wenjun Sun, Liwei Xu, Guanyu Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.05523">A model-data asymptotic-preserving neural network method based on micro-macro decomposition for gray radiative transfer equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a model-data asymptotic-preserving neural network(MD-APNN) method to solve the nonlinear gray radiative transfer equations(GRTEs). The system is challenging to be simulated with both the traditional numerical schemes and the vanilla physics-informed neural networks(PINNs) due to the multiscale characteristics. Under the framework of PINNs, we employ a micro-macro decomposition technique to construct a new asymptotic-preserving(AP) loss function, which includes the residual of the governing equations in the micro-macro coupled form, the initial and boundary conditions with additional diffusion limit information, the conservation laws, and a few labeled data. A convergence analysis is performed for the proposed method, and a number of numerical examples are presented to illustrate the efficiency of MD-APNNs, and particularly, the importance of the AP property in the neural networks for the diffusion dominating problems. The numerical results indicate that MD-APNNs lead to a better performance than APNNs or pure data-driven networks in the simulation of the nonlinear non-stationary GRTEs.
<div id='section'>Paperid: <span id='pid'>1074, <a href='https://arxiv.org/pdf/2212.03857.pdf' target='_blank'>https://arxiv.org/pdf/2212.03857.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew Ricci, Noa Moriel, Zoe Piran, Mor Nitzan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.03857">Phase2vec: Dynamical systems embedding with a physics-informed convolutional network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamical systems are found in innumerable forms across the physical and biological sciences, yet all these systems fall naturally into universal equivalence classes: conservative or dissipative, stable or unstable, compressible or incompressible. Predicting these classes from data remains an essential open challenge in computational physics at which existing time-series classification methods struggle. Here, we propose, \texttt{phase2vec}, an embedding method that learns high-quality, physically-meaningful representations of 2D dynamical systems without supervision. Our embeddings are produced by a convolutional backbone that extracts geometric features from flow data and minimizes a physically-informed vector field reconstruction loss. In an auxiliary training period, embeddings are optimized so that they robustly encode the equations of unseen data over and above the performance of a per-equation fitting method. The trained architecture can not only predict the equations of unseen data, but also, crucially, learns embeddings that respect the underlying semantics of the embedded physical systems. We validate the quality of learned embeddings investigating the extent to which physical categories of input data can be decoded from embeddings compared to standard blackbox classifiers and state-of-the-art time series classification techniques. We find that our embeddings encode important physical properties of the underlying data, including the stability of fixed points, conservation of energy, and the incompressibility of flows, with greater fidelity than competing methods. We finally apply our embeddings to the analysis of meteorological data, showing we can detect climatically meaningful features. Collectively, our results demonstrate the viability of embedding approaches for the discovery of dynamical features in physical systems.
<div id='section'>Paperid: <span id='pid'>1075, <a href='https://arxiv.org/pdf/2212.02861.pdf' target='_blank'>https://arxiv.org/pdf/2212.02861.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixue Xiang, Wei Peng, Wen Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.02861">RBF-MGN:Solving spatiotemporal PDEs with Physics-informed Graph Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have lately received significant attention as a representative deep learning-based technique for solving partial differential equations (PDEs). Most fully connected network-based PINNs use automatic differentiation to construct loss functions that suffer from slow convergence and difficult boundary enforcement. In addition, although convolutional neural network (CNN)-based PINNs can significantly improve training efficiency, CNNs have difficulty in dealing with irregular geometries with unstructured meshes. Therefore, we propose a novel framework based on graph neural networks (GNNs) and radial basis function finite difference (RBF-FD). We introduce GNNs into physics-informed learning to better handle irregular domains with unstructured meshes. RBF-FD is used to construct a high-precision difference format of the differential equations to guide model training. Finally, we perform numerical experiments on Poisson and wave equations on irregular domains. We illustrate the generalizability, accuracy, and efficiency of the proposed algorithms on different PDE parameters, numbers of collection points, and several types of RBFs.
<div id='section'>Paperid: <span id='pid'>1076, <a href='https://arxiv.org/pdf/2212.00970.pdf' target='_blank'>https://arxiv.org/pdf/2212.00970.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joel Janek Dabrowski, Daniel Edward Pagendam, James Hilton, Conrad Sanderson, Daniel MacKinlay, Carolyn Huston, Andrew Bolt, Petra Kuhnert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.00970">Bayesian Physics Informed Neural Networks for Data Assimilation and Spatio-Temporal Modelling of Wildfires</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We apply the Physics Informed Neural Network (PINN) to the problem of wildfire fire-front modelling. We use the PINN to solve the level-set equation, which is a partial differential equation that models a fire-front through the zero-level-set of a level-set function. The result is a PINN that simulates a fire-front as it propagates through the spatio-temporal domain. We show that popular optimisation cost functions used in the literature can result in PINNs that fail to maintain temporal continuity in modelled fire-fronts when there are extreme changes in exogenous forcing variables such as wind direction. We thus propose novel additions to the optimisation cost function that improves temporal continuity under these extreme changes. Furthermore, we develop an approach to perform data assimilation within the PINN such that the PINN predictions are drawn towards observations of the fire-front. Finally, we incorporate our novel approaches into a Bayesian PINN (B-PINN) to provide uncertainty quantification in the fire-front predictions. This is significant as the standard solver, the level-set method, does not naturally offer the capability for data assimilation and uncertainty quantification. Our results show that, with our novel approaches, the B-PINN can produce accurate predictions with high quality uncertainty quantification on real-world data.
<div id='section'>Paperid: <span id='pid'>1077, <a href='https://arxiv.org/pdf/2212.00270.pdf' target='_blank'>https://arxiv.org/pdf/2212.00270.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kuangdai Leng, Jeyan Thiyagalingam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.00270">On the Compatibility between Neural Networks and Partial Differential Equations for Physics-informed Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We shed light on a pitfall and an opportunity in physics-informed neural networks (PINNs). We prove that a multilayer perceptron (MLP) only with ReLU (Rectified Linear Unit) or ReLU-like Lipschitz activation functions will always lead to a vanished Hessian. Such a network-imposed constraint contradicts any second- or higher-order partial differential equations (PDEs). Therefore, a ReLU-based MLP cannot form a permissible function space for the approximation of their solutions. Inspired by this pitfall, we prove that a linear PDE up to the $n$-th order can be strictly satisfied by an MLP with $C^n$ activation functions when the weights of its output layer lie on a certain hyperplane, as called the out-layer-hyperplane. An MLP equipped with the out-layer-hyperplane becomes "physics-enforced", no longer requiring a loss function for the PDE itself (but only those for the initial and boundary conditions). Such a hyperplane exists not only for MLPs but for any network architecture tailed by a fully-connected hidden layer. To our knowledge, this should be the first PINN architecture that enforces point-wise correctness of PDEs. We show a closed-form expression of the out-layer-hyperplane for second-order linear PDEs, which can be generalised to higher-order nonlinear PDEs.
<div id='section'>Paperid: <span id='pid'>1078, <a href='https://arxiv.org/pdf/2211.15498.pdf' target='_blank'>https://arxiv.org/pdf/2211.15498.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Philipp Pilar, Niklas WahlstrÃ¶m
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.15498">Physics-informed Neural Networks with Unknown Measurement Noise</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) constitute a flexible approach to both finding solutions and identifying parameters of partial differential equations. Most works on the topic assume noiseless data, or data contaminated with weak Gaussian noise. We show that the standard PINN framework breaks down in case of non-Gaussian noise. We give a way of resolving this fundamental issue and we propose to jointly train an energy-based model (EBM) to learn the correct noise distribution. We illustrate the improved performance of our approach using multiple examples.
<div id='section'>Paperid: <span id='pid'>1079, <a href='https://arxiv.org/pdf/2211.05560.pdf' target='_blank'>https://arxiv.org/pdf/2211.05560.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Victorita Dolean, Alexander Heinlein, Siddhartha Mishra, Ben Moseley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.05560">Finite basis physics-informed neural networks as a Schwarz domain decomposition method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) [4, 10] are an approach for solving boundary value problems based on differential equations (PDEs). The key idea of PINNs is to use a neural network to approximate the solution to the PDE and to incorporate the residual of the PDE as well as boundary conditions into its loss function when training it. This provides a simple and mesh-free approach for solving problems relating to PDEs. However, a key limitation of PINNs is their lack of accuracy and efficiency when solving problems with larger domains and more complex, multi-scale solutions. In a more recent approach, finite basis physics-informed neural networks (FBPINNs) [8] use ideas from domain decomposition to accelerate the learning process of PINNs and improve their accuracy. In this work, we show how Schwarz-like additive, multiplicative, and hybrid iteration methods for training FBPINNs can be developed. We present numerical experiments on the influence of these different training strategies on convergence and accuracy. Furthermore, we propose and evaluate a preliminary implementation of coarse space correction for FBPINNs.
<div id='section'>Paperid: <span id='pid'>1080, <a href='https://arxiv.org/pdf/2211.05520.pdf' target='_blank'>https://arxiv.org/pdf/2211.05520.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abishek Thangamuthu, Gunjan Kumar, Suresh Bishnoi, Ravinder Bhattoo, N M Anoop Krishnan, Sayan Ranu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.05520">Unravelling the Performance of Physics-informed Graph Neural Networks for Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, graph neural networks have been gaining a lot of attention to simulate dynamical systems due to their inductive nature leading to zero-shot generalizability. Similarly, physics-informed inductive biases in deep-learning frameworks have been shown to give superior performance in learning the dynamics of physical systems. There is a growing volume of literature that attempts to combine these two approaches. Here, we evaluate the performance of thirteen different graph neural networks, namely, Hamiltonian and Lagrangian graph neural networks, graph neural ODE, and their variants with explicit constraints and different architectures. We briefly explain the theoretical formulation highlighting the similarities and differences in the inductive biases and graph architecture of these systems. We evaluate these models on spring, pendulum, gravitational, and 3D deformable solid systems to compare the performance in terms of rollout error, conserved quantities such as energy and momentum, and generalizability to unseen system sizes. Our study demonstrates that GNNs with additional inductive biases, such as explicit constraints and decoupling of kinetic and potential energies, exhibit significantly enhanced performance. Further, all the physics-informed GNNs exhibit zero-shot generalizability to system sizes an order of magnitude larger than the training system, thus providing a promising route to simulate large-scale realistic systems.
<div id='section'>Paperid: <span id='pid'>1081, <a href='https://arxiv.org/pdf/2209.07138.pdf' target='_blank'>https://arxiv.org/pdf/2209.07138.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Suman Rath, Lam Duc Nguyen, Subham Sahoo, Petar Popovski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.07138">Self-Healing Secure Blockchain Framework in Microgrids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Blockchain has recently been depicted as a secure protocol for information exchange in cyber-physical microgrids. However, it is still found vulnerable to consensus manipulation attacks. These stealth attacks are often difficult to detect as they use kernel-level access to mask their actions. In this paper, we firstly build a trusted and secured peer-to-peer network mechanism for physical DC microgrids' validation of transactions over Distributed Ledger. Secondly, we leverage from a physics-informed approach for detecting malware-infected nodes and then recovering from stealth attacks using a self-healing recovery scheme augmented into the microgrid Blockchain network. This scheme allows compromised nodes to adapt to a reconstructed trustworthy signal in a multi-hop manner using corresponding measurements from the reliable nodes in the network. Additionally, recognizing the possible threat of denial-of-service attacks and random time delays (where information sharing via communication channels is blocked), we also integrate a model-free predictive controller with the proposed system that can locally reconstruct an expected version of the attacked/delayed signals. This supplements the capabilities of Blockchain, enabling it to detect and mitigate consensus manipulation attempts, and network latencies.
<div id='section'>Paperid: <span id='pid'>1082, <a href='https://arxiv.org/pdf/2209.03837.pdf' target='_blank'>https://arxiv.org/pdf/2209.03837.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joshua Ziegler, Florian Luthi, Mick Ramsey, Felix Borjans, Guoji Zheng, Justyna P. Zwolak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.03837">Tuning arrays with rays: Physics-informed tuning of quantum dot charge states</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantum computers based on gate-defined quantum dots (QDs) are expected to scale. However, as the number of qubits increases, the burden of manually calibrating these systems becomes unreasonable and autonomous tuning must be used. There has been a range of recent demonstrations of automated tuning of various QD parameters such as coarse gate ranges, global state topology (e.g. single QD, double QD), charge, and tunnel coupling with a variety of methods. Here, we demonstrate an intuitive, reliable, and data-efficient set of tools for an automated global state and charge tuning in a framework deemed physics-informed tuning (PIT). The first module of PIT is an action-based algorithm that combines a machine learning classifier with physics knowledge to navigate to a target global state. The second module uses a series of one-dimensional measurements to tune to a target charge state by first emptying the QDs of charge, followed by calibrating capacitive couplings and navigating to the target charge state. The success rate for the action-based tuning consistently surpasses 95 % on both simulated and experimental data suitable for off-line testing. The success rate for charge setting is comparable when testing with simulated data, at 95.5(5.4) %, and only slightly worse for off-line experimental tests, with an average of 89.7(17.4) % (median 97.5 %). It is noteworthy that the high performance is demonstrated both on data from samples fabricated in an academic cleanroom as well as on an industrial 300 mm} process line, further underlining the device agnosticism of PIT. Together, these tests on a range of simulated and experimental devices demonstrate the effectiveness and robustness of PIT.
<div id='section'>Paperid: <span id='pid'>1083, <a href='https://arxiv.org/pdf/2208.08635.pdf' target='_blank'>https://arxiv.org/pdf/2208.08635.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifei Zong, QiZhi He, Alexandre M. Tartakovsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.08635">Physics-Informed Neural Network Method for Parabolic Differential Equations with Sharply Perturbed Initial Conditions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we develop a physics-informed neural network (PINN) model for parabolic problems with a sharply perturbed initial condition. As an example of a parabolic problem, we consider the advection-dispersion equation (ADE) with a point (Gaussian) source initial condition. In the $d$-dimensional ADE, perturbations in the initial condition decay with time $t$ as $t^{-d/2}$, which can cause a large approximation error in the PINN solution. Localized large gradients in the ADE solution make the (common in PINN) Latin hypercube sampling of the equation's residual highly inefficient. Finally, the PINN solution of parabolic equations is sensitive to the choice of weights in the loss function. We propose a normalized form of ADE where the initial perturbation of the solution does not decrease in amplitude and demonstrate that this normalization significantly reduces the PINN approximation error. We propose criteria for weights in the loss function that produce a more accurate PINN solution than those obtained with the weights selected via other methods. Finally, we proposed an adaptive sampling scheme that significantly reduces the PINN solution error for the same number of the sampling (residual) points. We demonstrate the accuracy of the proposed PINN model for forward, inverse, and backward ADEs.
<div id='section'>Paperid: <span id='pid'>1084, <a href='https://arxiv.org/pdf/2208.08626.pdf' target='_blank'>https://arxiv.org/pdf/2208.08626.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhikang Dong, Pawel Polak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.08626">CP-PINNs: Data-Driven Changepoints Detection in PDEs Using Online Optimized Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate the inverse problem for Partial Differential Equations (PDEs) in scenarios where the parameters of the given PDE dynamics may exhibit changepoints at random time. We employ Physics-Informed Neural Networks (PINNs) - universal approximators capable of estimating the solution of any physical law described by a system of PDEs, which serves as a regularization during neural network training, restricting the space of admissible solutions and enhancing function approximation accuracy. We demonstrate that when the system exhibits sudden changes in the PDE dynamics, this regularization is either insufficient to accurately estimate the true dynamics, or it may result in model miscalibration and failure. Consequently, we propose a PINNs extension using a Total-Variation penalty, which allows to accommodate multiple changepoints in the PDE dynamics and significantly improves function approximation. These changepoints can occur at random locations over time and are estimated concurrently with the solutions. Additionally, we introduce an online learning method for re-weighting loss function terms dynamically. Through empirical analysis using examples of various equations with parameter changes, we showcase the advantages of our proposed model. In the absence of changepoints, the model reverts to the original PINNs model. However, when changepoints are present, our approach yields superior parameter estimation, improved model fitting, and reduced training error compared to the original PINNs model.
<div id='section'>Paperid: <span id='pid'>1085, <a href='https://arxiv.org/pdf/2207.14291.pdf' target='_blank'>https://arxiv.org/pdf/2207.14291.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan-Hendrik Bastek, Dennis M. Kochmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.14291">Physics-Informed Neural Networks for Shell Structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The numerical modeling of thin shell structures is a challenge, which has been met by a variety of finite element (FE) and other formulations -- many of which give rise to new challenges, from complex implementations to artificial locking. As a potential alternative, we use machine learning and present a Physics-Informed Neural Network (PINN) to predict the small-strain response of arbitrarily curved shells. To this end, the shell midsurface is described by a chart, from which the mechanical fields are derived in a curvilinear coordinate frame by adopting Naghdi's shell theory. Unlike in typical PINN applications, the corresponding strong or weak form must therefore be solved in a non-Euclidean domain. We investigate the performance of the proposed PINN in three distinct scenarios, including the well-known Scordelis-Lo roof setting widely used to test FE shell elements against locking. Results show that the PINN can accurately identify the solution field in all three benchmarks if the equations are presented in their weak form, while it may fail to do so when using the strong form. In the thin-thickness limit, where classical methods are susceptible to locking, training time notably increases as the differences in scaling of the membrane, shear, and bending energies lead to adverse numerical stiffness in the gradient flow dynamics. Nevertheless, the PINN can accurately match the ground truth and performs well in the Scordelis-Lo roof benchmark, highlighting its potential for a drastically simplified alternative to designing locking-free shell FE formulations.
<div id='section'>Paperid: <span id='pid'>1086, <a href='https://arxiv.org/pdf/2206.12901.pdf' target='_blank'>https://arxiv.org/pdf/2206.12901.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pongpisit Thanasutives, Takashi Morita, Masayuki Numao, Ken-ichi Fukui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.12901">Noise-aware Physics-informed Machine Learning for Robust PDE Discovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work is concerned with discovering the governing partial differential equation (PDE) of a physical system. Existing methods have demonstrated the PDE identification from finite observations but failed to maintain satisfying results against noisy data, partly owing to suboptimal estimated derivatives and found PDE coefficients. We address the issues by introducing a noise-aware physics-informed machine learning (nPIML) framework to discover the governing PDE from data following arbitrary distributions. We propose training a couple of neural networks, namely solver and preselector, in a multi-task learning paradigm, which yields important scores of basis candidates that constitute the hidden physical constraint. After they are jointly trained, the solver network estimates potential candidates, e.g., partial derivatives, for the sparse regression algorithm to initially unveil the most likely parsimonious PDE, decided according to the information criterion. We also propose the denoising physics-informed neural networks (dPINNs), based on Discrete Fourier Transform (DFT), to deliver a set of the optimal finetuned PDE coefficients respecting the noise-reduced variables. The denoising PINNs are structured into forefront projection networks and a PINN, by which the formerly learned solver initializes. Our extensive experiments on five canonical PDEs affirm that the proposed framework presents a robust and interpretable approach for PDE discovery, applicable to a wide range of systems, possibly complicated by noise.
<div id='section'>Paperid: <span id='pid'>1087, <a href='https://arxiv.org/pdf/2206.12625.pdf' target='_blank'>https://arxiv.org/pdf/2206.12625.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giulia Bertaglia, Chuan Lu, Lorenzo Pareschi, Xueyu Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.12625">Asymptotic-Preserving Neural Networks for multiscale hyperbolic models of epidemic spread</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When investigating epidemic dynamics through differential models, the parameters needed to understand the phenomenon and to simulate forecast scenarios require a delicate calibration phase, often made even more challenging by the scarcity and uncertainty of the observed data reported by official sources. In this context, Physics-Informed Neural Networks (PINNs), by embedding the knowledge of the differential model that governs the physical phenomenon in the learning process, can effectively address the inverse and forward problem of data-driven learning and solving the corresponding epidemic problem. In many circumstances, however, the spatial propagation of an infectious disease is characterized by movements of individuals at different scales governed by multiscale PDEs. This reflects the heterogeneity of a region or territory in relation to the dynamics within cities and in neighboring zones. In presence of multiple scales, a direct application of PINNs generally leads to poor results due to the multiscale nature of the differential model in the loss function of the neural network. To allow the neural network to operate uniformly with respect to the small scales, it is desirable that the neural network satisfies an Asymptotic-Preservation (AP) property in the learning process. To this end, we consider a new class of AP Neural Networks (APNNs) for multiscale hyperbolic transport models of epidemic spread that, thanks to an appropriate AP formulation of the loss function, is capable to work uniformly at the different scales of the system. A series of numerical tests for different epidemic scenarios confirms the validity of the proposed approach, highlighting the importance of the AP property in the neural network when dealing with multiscale problems especially in presence of sparse and partially observed systems.
<div id='section'>Paperid: <span id='pid'>1088, <a href='https://arxiv.org/pdf/2206.03864.pdf' target='_blank'>https://arxiv.org/pdf/2206.03864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Li Liu, Shengping Liu, Hui Xie, Fansheng Xiong, Tengchao Yu, Mengjuan Xiao, Lufeng Liu, Heng Yong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.03864">Discontinuity Computing using Physics-Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulating discontinuities is a long standing problem especially for shock waves with strong nonlinear feather. Despite being a promising method, the recently developed physics-informed neural network (PINN) is still weak for calculating discontinuities compared with traditional shock-capturing methods. In this paper, we intend to improve the shock-capturing ability of the PINN. The primary strategy of this work is to weaken the expression of the network near discontinuities by adding a gradient-weight into the governing equations locally at each residual point. This strategy allows the network to focus on training smooth parts of the solutions. Then, automatically affected by the compressible property near shock waves, a sharp discontinuity appears with wrong inside shock transition-points compressed into well-trained smooth regions as passive particles. We study the solutions of one-dimensional Burgers equation and one- and two-dimensional Euler equations. Compared with the traditional high-order WENO-Z method in numerical examples, the proposed method can substantially improve discontinuity computing.
<div id='section'>Paperid: <span id='pid'>1089, <a href='https://arxiv.org/pdf/2205.14630.pdf' target='_blank'>https://arxiv.org/pdf/2205.14630.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jassem Abbasi, PÃ¥l ÃstebÃ¸ Andersen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.14630">Physical Activation Functions (PAFs): An Approach for More Efficient Induction of Physics into Physics-Informed Neural Networks (PINNs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, the gap between Deep Learning (DL) methods and analytical or numerical approaches in scientific computing is tried to be filled by the evolution of Physics-Informed Neural Networks (PINNs). However, still, there are many complications in the training of PINNs and optimal interleaving of physical models. Here, we introduced the concept of Physical Activation Functions (PAFs). This concept offers that instead of using general activation functions (AFs) such as ReLU, tanh, and sigmoid for all the neurons, one can use generic AFs that their mathematical expression is inherited from the physical laws of the investigating phenomena. The formula of PAFs may be inspired by the terms in the analytical solution of the problem. We showed that the PAFs can be inspired by any mathematical formula related to the investigating phenomena such as the initial or boundary conditions of the PDE system. We validated the advantages of PAFs for several PDEs including the harmonic oscillations, Burgers, Advection-Convection equation, and the heterogeneous diffusion equations. The main advantage of PAFs was in the more efficient constraining and interleaving of PINNs with the investigating physical phenomena and their underlying mathematical models. This added constraint significantly improved the predictions of PINNs for the testing data that was out-of-training distribution. Furthermore, the application of PAFs reduced the size of the PINNs up to 75% in different cases. Also, the value of loss terms was reduced by 1 to 2 orders of magnitude in some cases which is noteworthy for upgrading the training of the PINNs. The iterations required for finding the optimum values were also significantly reduced. It is concluded that using the PAFs helps in generating PINNs with less complexity and much more validity for longer ranges of prediction.
<div id='section'>Paperid: <span id='pid'>1090, <a href='https://arxiv.org/pdf/2203.09346.pdf' target='_blank'>https://arxiv.org/pdf/2203.09346.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tim De Ryck, Ameya D. Jagtap, Siddhartha Mishra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.09346">Error estimates for physics informed neural networks approximating the Navier-Stokes equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We prove rigorous bounds on the errors resulting from the approximation of the incompressible Navier-Stokes equations with (extended) physics informed neural networks. We show that the underlying PDE residual can be made arbitrarily small for tanh neural networks with two hidden layers. Moreover, the total error can be estimated in terms of the training error, network size and number of quadrature points. The theory is illustrated with numerical experiments.
<div id='section'>Paperid: <span id='pid'>1091, <a href='https://arxiv.org/pdf/2202.06941.pdf' target='_blank'>https://arxiv.org/pdf/2202.06941.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Murnane, Savannah Thais, Jason Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.06941">Semi-Equivariant GNN Architectures for Jet Tagging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Composing Graph Neural Networks (GNNs) of operations that respect physical symmetries has been suggested to give better model performance with a smaller number of learnable parameters. However, real-world applications, such as in high energy physics have not born this out. We present the novel architecture VecNet that combines both symmetry-respecting and unconstrained operations to study and tune the degree of physics-informed GNNs. We introduce a novel metric, the \textit{ant factor}, to quantify the resource-efficiency of each configuration in the search-space. We find that a generalized architecture such as ours can deliver optimal performance in resource-constrained applications.
<div id='section'>Paperid: <span id='pid'>1092, <a href='https://arxiv.org/pdf/2202.02710.pdf' target='_blank'>https://arxiv.org/pdf/2202.02710.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingtao Xia, Lucas BÃ¶ttcher, Tom Chou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.02710">Spectrally Adapted Physics-Informed Neural Networks for Solving Unbounded Domain Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving analytically intractable partial differential equations (PDEs) that involve at least one variable defined on an unbounded domain arises in numerous physical applications. Accurately solving unbounded domain PDEs requires efficient numerical methods that can resolve the dependence of the PDE on the unbounded variable over at least several orders of magnitude. We propose a solution to such problems by combining two classes of numerical methods: (i) adaptive spectral methods and (ii) physics-informed neural networks (PINNs). The numerical approach that we develop takes advantage of the ability of physics-informed neural networks to easily implement high-order numerical schemes to efficiently solve PDEs and extrapolate numerical solutions at any point in space and time. We then show how recently introduced adaptive techniques for spectral methods can be integrated into PINN-based PDE solvers to obtain numerical solutions of unbounded domain problems that cannot be efficiently approximated by standard PINNs. Through a number of examples, we demonstrate the advantages of the proposed spectrally adapted PINNs in solving PDEs and estimating model parameters from noisy observations in unbounded domains.
<div id='section'>Paperid: <span id='pid'>1093, <a href='https://arxiv.org/pdf/2112.09831.pdf' target='_blank'>https://arxiv.org/pdf/2112.09831.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Shan, Zhichao Lin, Xiaoqian Song, Maokun Li, Fan Yang, Zhensheng Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.09831">Neural Born Iteration Method For Solving Inverse Scattering Problems: 2D Cases</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose the neural Born iterative method (NeuralBIM) for solving 2D inverse scattering problems (ISPs) by drawing on the scheme of physics-informed supervised residual learning (PhiSRL) to emulate the computing process of the traditional Born iterative method (TBIM). NeuralBIM employs independent convolutional neural networks (CNNs) to learn the alternate update rules of two different candidate solutions regarding the residuals. Two different schemes are presented in this paper, including the supervised and unsupervised learning schemes. With the data set generated by the method of moments (MoM), supervised NeuralBIM are trained with the knowledge of total fields and contrasts. Unsupervised NeuralBIM is guided by the physics-embedded objective function founding on the governing equations of ISPs, which results in no requirement of total fields and contrasts for training. Numerical and experimental results further validate the efficacy of NeuralBIM.
<div id='section'>Paperid: <span id='pid'>1094, <a href='https://arxiv.org/pdf/2112.03754.pdf' target='_blank'>https://arxiv.org/pdf/2112.03754.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kexin Jin, Jonas Latz, Chenguang Liu, Carola-Bibiane SchÃ¶nlieb
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.03754">A Continuous-time Stochastic Gradient Descent Method for Continuous Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optimization problems with continuous data appear in, e.g., robust machine learning, functional data analysis, and variational inference. Here, the target function is given as an integral over a family of (continuously) indexed target functions - integrated with respect to a probability measure. Such problems can often be solved by stochastic optimization methods: performing optimization steps with respect to the indexed target function with randomly switched indices. In this work, we study a continuous-time variant of the stochastic gradient descent algorithm for optimization problems with continuous data. This so-called stochastic gradient process consists in a gradient flow minimizing an indexed target function that is coupled with a continuous-time index process determining the index. Index processes are, e.g., reflected diffusions, pure jump processes, or other LÃ©vy processes on compact spaces. Thus, we study multiple sampling patterns for the continuous data space and allow for data simulated or streamed at runtime of the algorithm. We analyze the approximation properties of the stochastic gradient process and study its longtime behavior and ergodicity under constant and decreasing learning rates. We end with illustrating the applicability of the stochastic gradient process in a polynomial regression problem with noisy functional data, as well as in a physics-informed neural network.
<div id='section'>Paperid: <span id='pid'>1095, <a href='https://arxiv.org/pdf/2012.02334.pdf' target='_blank'>https://arxiv.org/pdf/2012.02334.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2012.02334">Benchmarking Energy-Conserving Neural Networks for Learning Dynamics from Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The last few years have witnessed an increased interest in incorporating physics-informed inductive bias in deep learning frameworks. In particular, a growing volume of literature has been exploring ways to enforce energy conservation while using neural networks for learning dynamics from observed time-series data. In this work, we survey ten recently proposed energy-conserving neural network models, including HNN, LNN, DeLaN, SymODEN, CHNN, CLNN and their variants. We provide a compact derivation of the theory behind these models and explain their similarities and differences. Their performance are compared in 4 physical systems. We point out the possibility of leveraging some of these energy-conserving models to design energy-based controllers.
<div id='section'>Paperid: <span id='pid'>1096, <a href='https://arxiv.org/pdf/1909.12077.pdf' target='_blank'>https://arxiv.org/pdf/1909.12077.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty
</span></div><div id="title">Title: <a href="https://arxiv.org/html/1909.12077">Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learning framework which can infer the dynamics of a physical system, given by an ordinary differential equation (ODE), from observed state trajectories. To achieve better generalization with fewer training samples, SymODEN incorporates appropriate inductive bias by designing the associated computation graph in a physics-informed manner. In particular, we enforce Hamiltonian dynamics with control to learn the underlying dynamics in a transparent way, which can then be leveraged to draw insight about relevant physical aspects of the system, such as mass and potential energy. In addition, we propose a parametrization which can enforce this Hamiltonian formalism even when the generalized coordinate data is embedded in a high-dimensional space or we can only access velocity data instead of generalized momentum. This framework, by offering interpretable, physically-consistent models for physical systems, opens up new possibilities for synthesizing model-based control strategies.
<div id='section'>Paperid: <span id='pid'>1097, <a href='https://arxiv.org/pdf/2510.05433.pdf' target='_blank'>https://arxiv.org/pdf/2510.05433.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nazanin Ahmadi, Qianying Cao, Jay D. Humphrey, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05433">Physics-Informed Machine Learning in Biomedical Science and Engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning (PIML) is emerging as a potentially transformative paradigm for modeling complex biomedical systems by integrating parameterized physical laws with data-driven methods. Here, we review three main classes of PIML frameworks: physics-informed neural networks (PINNs), neural ordinary differential equations (NODEs), and neural operators (NOs), highlighting their growing role in biomedical science and engineering. We begin with PINNs, which embed governing equations into deep learning models and have been successfully applied to biosolid and biofluid mechanics, mechanobiology, and medical imaging among other areas. We then review NODEs, which offer continuous-time modeling, especially suited to dynamic physiological systems, pharmacokinetics, and cell signaling. Finally, we discuss deep NOs as powerful tools for learning mappings between function spaces, enabling efficient simulations across multiscale and spatially heterogeneous biological domains. Throughout, we emphasize applications where physical interpretability, data scarcity, or system complexity make conventional black-box learning insufficient. We conclude by identifying open challenges and future directions for advancing PIML in biomedical science and engineering, including issues of uncertainty quantification, generalization, and integration of PIML and large language models.
<div id='section'>Paperid: <span id='pid'>1098, <a href='https://arxiv.org/pdf/2510.01519.pdf' target='_blank'>https://arxiv.org/pdf/2510.01519.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Han Chen, Yuchen Liu, Alexiy Buynitsky, Ahmed H. Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.01519">Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robot navigation in large, complex, and unknown indoor environments is a challenging problem. The existing approaches, such as traditional sampling-based methods, struggle with resolution control and scalability, while imitation learning-based methods require a large amount of demonstration data. Active Neural Time Fields (ANTFields) have recently emerged as a promising solution by using local observations to learn cost-to-go functions without relying on demonstrations. Despite their potential, these methods are hampered by challenges such as spectral bias and catastrophic forgetting, which diminish their effectiveness in complex scenarios. To address these issues, our approach decomposes the planning problem into a hierarchical structure. At the high level, a sparse graph captures the environment's global connectivity, while at the low level, a planner based on neural fields navigates local obstacles by solving the Eikonal PDE. This physics-informed strategy overcomes common pitfalls like spectral bias and neural field fitting difficulties, resulting in a smooth and precise representation of the cost landscape. We validate our framework in large-scale environments, demonstrating its enhanced adaptability and precision compared to previous methods, and highlighting its potential for online exploration, mapping, and real-world navigation.
<div id='section'>Paperid: <span id='pid'>1099, <a href='https://arxiv.org/pdf/2510.01039.pdf' target='_blank'>https://arxiv.org/pdf/2510.01039.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vikas Dwivedi, Enrico Schiassi, Monica Sigovan, Bruno Sixou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.01039">Gated X-TFC: Soft Domain Decomposition for Forward and Inverse Problems in Sharp-Gradient PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) and related methods struggle to resolve sharp gradients in singularly perturbed boundary value problems without resorting to some form of domain decomposition, which often introduce complex interface penalties. While the Extreme Theory of Functional Connections (X-TFC) avoids multi-objective optimization by employing exact boundary condition enforcement, it remains computationally inefficient for boundary layers and incompatible with decomposition. We propose Gated X-TFC, a novel framework for both forward and inverse problems, that overcomes these limitations through a soft, learned domain decomposition. Our method replaces hard interfaces with a differentiable logistic gate that dynamically adapts radial basis function (RBF) kernel widths across the domain, eliminating the need for interface penalties. This approach yields not only superior accuracy but also dramatic improvements in computational efficiency: on a benchmark one dimensional (1D) convection-diffusion, Gated X-TFC achieves an order-of-magnitude lower error than standard X-TFC while using 80 percent fewer collocation points and reducing training time by 66 percent. In addition, we introduce an operator-conditioned meta-learning layer that learns a probabilistic mapping from PDE parameters to optimal gate configurations, enabling fast, uncertainty-aware warm-starting for new problem instances. We further demonstrate scalability to multiple subdomains and higher dimensions by solving a twin boundary-layer equation and a 2D Poisson problem with a sharp Gaussian source. Overall, Gated X-TFC delivers a simple alternative alternative to PINNs that is both accurate and computationally efficient for challenging boundar-layer regimes. Future work will focus on nonlinear problems.
<div id='section'>Paperid: <span id='pid'>1100, <a href='https://arxiv.org/pdf/2509.26358.pdf' target='_blank'>https://arxiv.org/pdf/2509.26358.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ling-Zhe Zai, Lei-Lei Guo, Zhi-Yong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.26358">HANN: Homotopy auxiliary neural network for solving nonlinear algebraic equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving nonlinear algebraic equations is a fundamental but challenging problem in scientific computations and also has many applications in system engineering. Though traditional iterative methods and modern optimization algorithms have exerted effective roles in addressing certain specific problems, there still exist certain weaknesses such as the initial value sensitivity, limited accuracy and slow convergence rate, particulary without flexible input for the neural network methods. In this paper, we propose a homotopy auxiliary neural network (HANN) for solving nonlinear algebraic equations which integrates the classical homotopy continuation method and popular physics-informed neural network. Consequently, the HANN-1 has strong learning ability and can rapidly give an acceptable solution for the problem which outperforms some known methods, while the HANN-2 can further improve its accuracy. Numerical results on the benchmark problems confirm that the HANN method can effectively solve the problems of determining the total number of solutions of a single equation, finding solutions of transcendental systems involving the absolute value function or trigonometric function, ill-conditioned and normal high-dimensional nonlinear systems and time-varying nonlinear problems, for which the Python's built-in Fsolve function exhibits significant limitations, even fails to work.
<div id='section'>Paperid: <span id='pid'>1101, <a href='https://arxiv.org/pdf/2509.25450.pdf' target='_blank'>https://arxiv.org/pdf/2509.25450.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moritz von Tresckow, Ion Gabriel Ion, Dimitrios Loukrezis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25450">Multi-patch isogeometric neural solver for partial differential equations on computer-aided design domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work develops a computational framework that combines physics-informed neural networks with multi-patch isogeometric analysis to solve partial differential equations on complex computer-aided design geometries. The method utilizes patch-local neural networks that operate on the reference domain of isogeometric analysis. A custom output layer enables the strong imposition of Dirichlet boundary conditions. Solution conformity across interfaces between non-uniform rational B-spline patches is enforced using dedicated interface neural networks. Training is performed using the variational framework by minimizing the energy functional derived after the weak form of the partial differential equation. The effectiveness of the suggested method is demonstrated on two highly non-trivial and practically relevant use-cases, namely, a 2D magnetostatics model of a quadrupole magnet and a 3D nonlinear solid and contact mechanics model of a mechanical holder. The results show excellent agreement to reference solutions obtained with high-fidelity finite element solvers, thus highlighting the potential of the suggested neural solver to tackle complex engineering problems given the corresponding computer-aided design models.
<div id='section'>Paperid: <span id='pid'>1102, <a href='https://arxiv.org/pdf/2509.20733.pdf' target='_blank'>https://arxiv.org/pdf/2509.20733.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiming Huang, Yajie Hao, Jing Zhou, Xiao Yuan, Xiaoting Wang, Yuxuan Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.20733">PALQO: Physics-informed Model for Accelerating Large-scale Quantum Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Variational quantum algorithms (VQAs) are leading strategies to reach practical utilities of near-term quantum devices. However, the no-cloning theorem in quantum mechanics precludes standard backpropagation, leading to prohibitive quantum resource costs when applying VQAs to large-scale tasks. To address this challenge, we reformulate the training dynamics of VQAs as a nonlinear partial differential equation and propose a novel protocol that leverages physics-informed neural networks (PINNs) to model this dynamical system efficiently. Given a small amount of training trajectory data collected from quantum devices, our protocol predicts the parameter updates of VQAs over multiple iterations on the classical side, dramatically reducing quantum resource costs. Through systematic numerical experiments, we demonstrate that our method achieves up to a 30x speedup compared to conventional methods and reduces quantum resource costs by as much as 90\% for tasks involving up to 40 qubits, including ground state preparation of different quantum systems, while maintaining competitive accuracy. Our approach complements existing techniques aimed at improving the efficiency of VQAs and further strengthens their potential for practical applications.
<div id='section'>Paperid: <span id='pid'>1103, <a href='https://arxiv.org/pdf/2509.18483.pdf' target='_blank'>https://arxiv.org/pdf/2509.18483.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhijit Sen, Illya V. Lukin, Kurt Jacobs, Lev Kaplan, Andrii G. Sotnikov, Denys I. Bondar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18483">Physics-informed time series analysis with Kolmogorov-Arnold Networks under Ehrenfest constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The prediction of quantum dynamical responses lies at the heart of modern physics. Yet, modeling these time-dependent behaviors remains a formidable challenge because quantum systems evolve in high-dimensional Hilbert spaces, often rendering traditional numerical methods computationally prohibitive. While large language models have achieved remarkable success in sequential prediction, quantum dynamics presents a fundamentally different challenge: forecasting the entire temporal evolution of quantum systems rather than merely the next element in a sequence. Existing neural architectures such as recurrent and convolutional networks often require vast training datasets and suffer from spurious oscillations that compromise physical interpretability. In this work, we introduce a fundamentally new approach: Kolmogorov Arnold Networks (KANs) augmented with physics-informed loss functions that enforce the Ehrenfest theorems. Our method achieves superior accuracy with significantly less training data: it requires only 5.4 percent of the samples (200) compared to Temporal Convolution Networks (3,700). We further introduce the Chain of KANs, a novel architecture that embeds temporal causality directly into the model design, making it particularly well-suited for time series modeling. Our results demonstrate that physics-informed KANs offer a compelling advantage over conventional black-box models, maintaining both mathematical rigor and physical consistency while dramatically reducing data requirements.
<div id='section'>Paperid: <span id='pid'>1104, <a href='https://arxiv.org/pdf/2509.17354.pdf' target='_blank'>https://arxiv.org/pdf/2509.17354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiazhao Shi, Yichen Lin, Yiheng Hua, Ziyu Wang, Zijian Zhang, Wenjia Zheng, Yun Song, Kuan Lu, Shoufeng Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17354">Multi-Scenario Highway Lane-Change Intention Prediction: A Physics-Informed AI Framework for Three-Class Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Lane-change maneuvers are a leading cause of highway accidents, underscoring the need for accurate intention prediction to improve the safety and decision-making of autonomous driving systems. While prior studies using machine learning and deep learning methods (e.g., SVM, CNN, LSTM, Transformers) have shown promise, most approaches remain limited by binary classification, lack of scenario diversity, and degraded performance under longer prediction horizons. In this study, we propose a physics-informed AI framework that explicitly integrates vehicle kinematics, interaction feasibility, and traffic-safety metrics (e.g., distance headway, time headway, time-to-collision, closing gap time) into the learning process. lane-change prediction is formulated as a three-class problem that distinguishes left change, right change, and no change, and is evaluated across both straight highway segments (highD) and complex ramp scenarios (exiD). By integrating vehicle kinematics with interaction features, our machine learning models, particularly LightGBM, achieve state-of-the-art accuracy and strong generalization. Results show up to 99.8% accuracy and 93.6% macro F1 on highD, and 96.1% accuracy and 88.7% macro F1 on exiD at a 1-second horizon, outperforming a two-layer stacked LSTM baseline. These findings demonstrate the practical advantages of a physics-informed and feature-rich machine learning framework for real-time lane-change intention prediction in autonomous driving systems.
<div id='section'>Paperid: <span id='pid'>1105, <a href='https://arxiv.org/pdf/2509.17354.pdf' target='_blank'>https://arxiv.org/pdf/2509.17354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiazhao Shi, Yichen Lin, Yiheng Hua, Ziyu Wang, Zijian Zhang, Wenjia Zheng, Yun Song, Kuan Lu, Shoufeng Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17354">Multi-Scenario Highway Lane-Change Intention Prediction: A Physics-Informed AI Framework for Three-Class Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Lane-change maneuvers are a leading cause of highway accidents, underscoring the need for accurate intention prediction to improve the safety and decision-making of autonomous driving systems. While prior studies using machine learning and deep learning methods (e.g., SVM, CNN, LSTM, Transformers) have shown promise, most approaches remain limited by binary classification, lack of scenario diversity, and degraded performance under longer prediction horizons. In this study, we propose a physics-informed AI framework that explicitly integrates vehicle kinematics, interaction feasibility, and traffic-safety metrics (e.g., distance headway, time headway, time-to-collision, closing gap time) into the learning process. lane-change prediction is formulated as a three-class problem that distinguishes left change, right change, and no change, and is evaluated across both straight highway segments (highD) and complex ramp scenarios (exiD). By integrating vehicle kinematics with interaction features, our machine learning models, particularly LightGBM, achieve state-of-the-art accuracy and strong generalization. Results show up to 99.8% accuracy and 93.6% macro F1 on highD, and 96.1% accuracy and 88.7% macro F1 on exiD at a 1-second horizon, outperforming a two-layer stacked LSTM baseline. These findings demonstrate the practical advantages of a physics-informed and feature-rich machine learning framework for real-time lane-change intention prediction in autonomous driving systems.
<div id='section'>Paperid: <span id='pid'>1106, <a href='https://arxiv.org/pdf/2509.15933.pdf' target='_blank'>https://arxiv.org/pdf/2509.15933.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ibai Ramirez, Jokin Alcibar, Joel Pino, Mikel Sanz, David Pardo, Jose I. Aizpurua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15933">Bayesian Physics Informed Neural Networks for Reliable Transformer Prognostics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific Machine Learning (SciML) integrates physics and data into the learning process, offering improved generalization compared with purely data-driven models. Despite its potential, applications of SciML in prognostics remain limited, partly due to the complexity of incorporating partial differential equations (PDEs) for ageing physics and the scarcity of robust uncertainty quantification methods. This work introduces a Bayesian Physics-Informed Neural Network (B-PINN) framework for probabilistic prognostics estimation. By embedding Bayesian Neural Networks into the PINN architecture, the proposed approach produces principled, uncertainty-aware predictions. The method is applied to a transformer ageing case study, where insulation degradation is primarily driven by thermal stress. The heat diffusion PDE is used as the physical residual, and different prior distributions are investigated to examine their impact on predictive posterior distributions and their ability to encode a priori physical knowledge. The framework is validated against a finite element model developed and tested with real measurements from a solar power plant. Results, benchmarked against a dropout-PINN baseline, show that the proposed B-PINN delivers more reliable prognostic predictions by accurately quantifying predictive uncertainty. This capability is crucial for supporting robust and informed maintenance decision-making in critical power assets.
<div id='section'>Paperid: <span id='pid'>1107, <a href='https://arxiv.org/pdf/2509.10866.pdf' target='_blank'>https://arxiv.org/pdf/2509.10866.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Koji Hashimoto, Koichi Kyo, Masaki Murata, Gakuto Ogiwara, Norihiro Tanahashi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10866">Physics-informed neural network solves minimal surfaces in curved spacetime</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a flexible framework based on physics-informed neural networks (PINNs) for solving boundary value problems involving minimal surfaces in curved spacetimes, with a particular emphasis on singularities and moving boundaries. By encoding the underlying physical laws into the loss function and designing network architectures that incorporate the singular behavior and dynamic boundaries, our approach enables robust and accurate solutions to both ordinary and partial differential equations with complex boundary conditions. We demonstrate the versatility of this framework through applications to minimal surface problems in anti-de Sitter (AdS) spacetime, including examples relevant to the AdS/CFT correspondence (e.g. Wilson loops and gluon scattering amplitudes) popularly used in the context of string theory in theoretical physics. Our methods efficiently handle singularities at boundaries, and also support both "soft" (loss-based) and "hard" (formulation-based) imposition of boundary conditions, including cases where the position of a boundary is promoted to a trainable parameter. The techniques developed here are not limited to high-energy theoretical physics but are broadly applicable to boundary value problems encountered in mathematics, engineering, and the natural sciences, wherever singularities and moving boundaries play a critical role.
<div id='section'>Paperid: <span id='pid'>1108, <a href='https://arxiv.org/pdf/2509.10363.pdf' target='_blank'>https://arxiv.org/pdf/2509.10363.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Benjamin David Shaffer, Brooks Kinch, Joseph Klobusicky, M. Ani Hsieh, Nathaniel Trask
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10363">Physics-informed sensor coverage through structure preserving machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a machine learning framework for adaptive source localization in which agents use a structure-preserving digital twin of a coupled hydrodynamic-transport system for real-time trajectory planning and data assimilation. The twin is constructed with conditional neural Whitney forms (CNWF), coupling the numerical guarantees of finite element exterior calculus (FEEC) with transformer-based operator learning. The resulting model preserves discrete conservation, and adapts in real time to streaming sensor data. It employs a conditional attention mechanism to identify: a reduced Whitney-form basis; reduced integral balance equations; and a source field, each compatible with given sensor measurements. The induced reduced-order environmental model retains the stability and consistency of standard finite-element simulation, yielding a physically realizable, regular mapping from sensor data to the source field. We propose a staggered scheme that alternates between evaluating the digital twin and applying Lloyd's algorithm to guide sensor placement, with analysis providing conditions for monotone improvement of a coverage functional. Using the predicted source field as an importance function within an optimal-recovery scheme, we demonstrate recovery of point sources under continuity assumptions, highlighting the role of regularity as a sufficient condition for localization. Experimental comparisons with physics-agnostic transformer architectures show improved accuracy in complex geometries when physical constraints are enforced, indicating that structure preservation provides an effective inductive bias for source identification.
<div id='section'>Paperid: <span id='pid'>1109, <a href='https://arxiv.org/pdf/2509.07687.pdf' target='_blank'>https://arxiv.org/pdf/2509.07687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Schaffer, Lukas Exl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07687">Physics-informed low-rank neural operators with application to parametric elliptic PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present the Physics-Informed Low-Rank Neural Operator (PILNO), a neural operator framework for efficiently approximating solution operators of partial differential equations (PDEs) on point cloud data. PILNO combines low-rank kernel approximations with an encoder--decoder architecture, enabling fast, continuous one-shot predictions while remaining independent of specific discretizations. The model is trained using a physics-informed penalty framework, ensuring that PDE constraints and boundary conditions are satisfied in both supervised and unsupervised settings. We demonstrate its effectiveness on diverse problems, including function fitting, the Poisson equation, the screened Poisson equation with variable coefficients, and parameterized Darcy flow. The low-rank structure provides computational efficiency in high-dimensional parameter spaces, establishing PILNO as a scalable and flexible surrogate modeling tool for PDEs.
<div id='section'>Paperid: <span id='pid'>1110, <a href='https://arxiv.org/pdf/2509.00663.pdf' target='_blank'>https://arxiv.org/pdf/2509.00663.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Binghang Lu, Changhong Mou, Guang Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.00663">An Evolutionary Multi-objective Optimization for Replica-Exchange-based Physics-informed Operator Learning Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose an evolutionary Multi-objective Optimization for Replica-Exchange-based Physics-informed Operator learning Network, which is a novel operator learning network to efficiently solve parametric partial differential equations. In forward and inverse settings, this operator learning network only admits minimum requirement of noisy observational data. While physics-informed neural networks and operator learning approaches such as Deep Operator Networks and Fourier Neural Operators offer promising alternatives to traditional numerical solvers, they struggle with balancing operator and physics losses, maintaining robustness under noisy or sparse data, and providing uncertainty quantification. The proposed framework addresses these limitations by integrating: (i) evolutionary multi-objective optimization to adaptively balance operator and physics-based losses in the Pareto front; (ii) replica exchange stochastic gradient Langevin dynamics to improve global parameter-space exploration and accelerate convergence; and (iii) built-in Bayesian uncertainty quantification from stochastic sampling. The proposed operator learning method is tested numerically on several different problems including one-dimensional Burgers equation and the time-fractional mixed diffusion-wave equation. The results indicate that our framework consistently outperforms the general operator learning methods in accuracy, noise robustness, and the ability to quantify uncertainty.
<div id='section'>Paperid: <span id='pid'>1111, <a href='https://arxiv.org/pdf/2509.00203.pdf' target='_blank'>https://arxiv.org/pdf/2509.00203.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuyang Li, Mahdi Masmoudi, Rami Gharbi, Nizar Lajnef, Vishnu Naresh Boddeti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.00203">Estimating Parameter Fields in Multi-Physics PDEs from Scarce Measurements</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Parameterized partial differential equations (PDEs) underpin the mathematical modeling of complex systems in diverse domains, including engineering, healthcare, and physics. A central challenge in using PDEs for real-world applications is to accurately infer the parameters, particularly when the parameters exhibit non-linear and spatiotemporal variations. Existing parameter estimation methods, such as sparse identification and physics-informed neural networks (PINNs), struggle in such cases, especially with nonlinear dynamics, multiphysics interactions, or limited observations of the system response. To address these challenges, we introduce Neptune, a general-purpose method capable of inferring parameter fields from sparse measurements of system responses. Neptune employs independent coordinate neural networks to continuously represent each parameter field in physical space or in state variables. Across various physical and biomedical problems, where direct parameter measurements are prohibitively expensive or unattainable, Neptune significantly outperforms existing methods, achieving robust parameter estimation from as few as 50 observations, reducing parameter estimation errors by two orders of magnitude and dynamic response prediction errors by a factor of ten compared to PINNs. Furthermore, Neptune exhibits superior extrapolation capabilities, enabling accurate predictions in regimes beyond training data where PINN fail. By facilitating reliable and data-efficient parameter inference, Neptune promises broad transformative impacts in engineering, healthcare, and beyond.
<div id='section'>Paperid: <span id='pid'>1112, <a href='https://arxiv.org/pdf/2508.21559.pdf' target='_blank'>https://arxiv.org/pdf/2508.21559.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julen Cestero, Carmine Delle Femine, Kenji S. Muro, Marco Quartulli, Marcello Restelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21559">Limitations of Physics-Informed Neural Networks: a Study on Smart Grid Surrogation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) present a transformative approach for smart grid modeling by integrating physical laws directly into learning frameworks, addressing critical challenges of data scarcity and physical consistency in conventional data-driven methods. This paper evaluates PINNs' capabilities as surrogate models for smart grid dynamics, comparing their performance against XGBoost, Random Forest, and Linear Regression across three key experiments: interpolation, cross-validation, and episodic trajectory prediction. By training PINNs exclusively through physics-based loss functions (enforcing power balance, operational constraints, and grid stability) we demonstrate their superior generalization, outperforming data-driven models in error reduction. Notably, PINNs maintain comparatively lower MAE in dynamic grid operations, reliably capturing state transitions in both random and expert-driven control scenarios, while traditional models exhibit erratic performance. Despite slight degradation in extreme operational regimes, PINNs consistently enforce physical feasibility, proving vital for safety-critical applications. Our results contribute to establishing PINNs as a paradigm-shifting tool for smart grid surrogation, bridging data-driven flexibility with first-principles rigor. This work advances real-time grid control and scalable digital twins, emphasizing the necessity of physics-aware architectures in mission-critical energy systems.
<div id='section'>Paperid: <span id='pid'>1113, <a href='https://arxiv.org/pdf/2508.21559.pdf' target='_blank'>https://arxiv.org/pdf/2508.21559.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julen Cestero, Carmine Delle Femine, Kenji S. Muro, Marco Quartulli, Marcello Restelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21559">Limitations of Physics-Informed Neural Networks: a Study on Smart Grid Surrogation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) present a transformative approach for smart grid modeling by integrating physical laws directly into learning frameworks, addressing critical challenges of data scarcity and physical consistency in conventional data-driven methods. This paper evaluates PINNs' capabilities as surrogate models for smart grid dynamics, comparing their performance against XGBoost, Random Forest, and Linear Regression across three key experiments: interpolation, cross-validation, and episodic trajectory prediction. By training PINNs exclusively through physics-based loss functions (enforcing power balance, operational constraints, and grid stability) we demonstrate their superior generalization, outperforming data-driven models in error reduction. Notably, PINNs maintain comparatively lower MAE in dynamic grid operations, reliably capturing state transitions in both random and expert-driven control scenarios, while traditional models exhibit erratic performance. Despite slight degradation in extreme operational regimes, PINNs consistently enforce physical feasibility, proving vital for safety-critical applications. Our results contribute to establishing PINNs as a paradigm-shifting tool for smart grid surrogation, bridging data-driven flexibility with first-principles rigor. This work advances real-time grid control and scalable digital twins, emphasizing the necessity of physics-aware architectures in mission-critical energy systems.
<div id='section'>Paperid: <span id='pid'>1114, <a href='https://arxiv.org/pdf/2508.17687.pdf' target='_blank'>https://arxiv.org/pdf/2508.17687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexandre Magueresse, Santiago Badia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17687">A convergence framework for energy minimisation of linear self-adjoint elliptic PDEs in nonlinear approximation spaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent years have seen the emergence of nonlinear methods for solving partial differential equations (PDEs), such as physics-informed neural networks (PINNs). While these approaches often perform well in practice, their theoretical analysis remains limited, especially regarding convergence guarantees. This work develops a general optimisation framework for energy minimisation problems arising from linear self-adjoint elliptic PDEs, formulated over nonlinear but analytically tractable approximation spaces. The framework accommodates a natural split between linear and nonlinear parameters and supports hybrid optimisation strategies: linear variables are updated via linear solves or steepest descent, while nonlinear variables are handled using constrained projected descent. We establish both local and global convergence of the resulting algorithm under modular structural assumptions on the discrete energy functional, including differentiability, boundedness, regularity, and directional convexity. These assumptions are stated in an abstract form, allowing the framework to apply to a broad class of nonlinear approximation manifolds. In a companion paper [Magueresse, Badia (2025, arXiv:2508.17705)], we introduce a concrete instance of such a space based on overlapping free-knot tensor-product B-splines, which satisfies the required assumptions and enables geometrically adaptive solvers with rigorous convergence guarantees.
<div id='section'>Paperid: <span id='pid'>1115, <a href='https://arxiv.org/pdf/2508.16554.pdf' target='_blank'>https://arxiv.org/pdf/2508.16554.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karan Shah, Attila Cangi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16554">Machine Learning Time Propagators for Time-Dependent Density Functional Theory Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time-dependent density functional theory (TDDFT) is a widely used method to investigate electron dynamics under external time-dependent perturbations such as laser fields. In this work, we present a machine learning approach to accelerate electron dynamics simulations based on real time TDDFT using autoregressive neural operators as time-propagators for the electron density. By leveraging physics-informed constraints and featurization, and high-resolution training data, our model achieves superior accuracy and computational speed compared to traditional numerical solvers. We demonstrate the effectiveness of our model on a class of one-dimensional diatomic molecules under the influence of a range of laser parameters. This method has potential in enabling on-the-fly modeling of laser-irradiated molecules and materials by utilizing fast machine learning predictions in a large space of varying experimental parameters of the laser.
<div id='section'>Paperid: <span id='pid'>1116, <a href='https://arxiv.org/pdf/2508.16032.pdf' target='_blank'>https://arxiv.org/pdf/2508.16032.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yan Shen, Jingrun Chen, Keke Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16032">A Hybrid Discontinuous Galerkin Neural Network Method for Solving Hyperbolic Conservation Laws with Temporal Progressive Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For hyperbolic conservation laws, traditional methods and physics-informed neural networks (PINNs) often encounter difficulties in capturing sharp discontinuities and maintaining temporal consistency. To address these challenges, we introduce a hybrid computational framework by coupling discontinuous Galerkin (DG) discretizations with a temporally progressive neural network architecture. Our method incorporates a structure-preserving weak-form loss -- combining DG residuals and Rankine-Hugoniot jump conditions -- with a causality-respecting progressive training strategy. The proposed framework trains neural networks sequentially across temporally decomposed subintervals, leveraging pseudo-label supervision to ensure temporal coherence and solution continuity. This approach mitigates error accumulation and enhances the model's capacity to resolve shock waves and steep gradients without explicit limiters. Besides, a theoretical analysis establishes error bounds for the proposed framework, demonstrating convergence toward the physical solution under mesh refinement and regularized training. Numerical experiments on Burgers and Euler equations show that our method consistently outperforms standard PINNs, PINNs-WE, and first-order DG schemes in both accuracy and robustness, particularly in capturing shocks and steep gradients. These results highlight the promise of combining classical discretization techniques with machine learning to develop robust and accurate solvers for nonlinear hyperbolic systems.
<div id='section'>Paperid: <span id='pid'>1117, <a href='https://arxiv.org/pdf/2508.10126.pdf' target='_blank'>https://arxiv.org/pdf/2508.10126.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arvind K. Saibaba, Misha E. Kilmer, Khalil Hall-Hooper, Fan Tian, Alex Mize
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10126">A tensor-based dynamic mode decomposition based on the $\star_{\boldsymbol{M}}$-product</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamic mode decomposition (DMD) is a data-driven method for estimating the dynamics of a discrete dynamical system. This paper proposes a tensor-based approach to DMD for applications in which the states can be viewed as tensors. Specifically, we use the $\star_{\boldsymbol{M}}$-product framework for tensor decompositions which we demonstrate offers excellent compression compared to matrix-based methods and can be implemented in a computationally efficient manner. We show how the proposed approach is connected to the traditional DMD and physics-informed DMD frameworks. We give a computational framework for computing the tensor-based DMD and detail the computational costs. We also give a randomized algorithm that enables efficient $\star_{\boldsymbol{M}}$-DMD computations in the streaming setting. The numerical results show that the proposed method achieves equal or better accuracy for the same storage compared to the standard DMD on these examples and is more efficient to compute.
<div id='section'>Paperid: <span id='pid'>1118, <a href='https://arxiv.org/pdf/2508.08114.pdf' target='_blank'>https://arxiv.org/pdf/2508.08114.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Tong, Hao Chen, Shaorui Guo, Dong Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.08114">Learned Regularization for Microwave Tomography</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Microwave Tomography (MWT) aims to reconstruct the dielectric properties of tissues from measured scattered electromagnetic fields. This inverse problem is highly nonlinear and ill-posed, posing significant challenges for conventional optimization-based methods, which, despite being grounded in physical models, often fail to recover fine structural details. Recent deep learning strategies, including end-to-end and post-processing networks, have improved reconstruction quality but typically require large paired training datasets and may struggle to generalize. To overcome these limitations, we propose a physics-informed hybrid framework that integrates diffusion models as learned regularization within a data-consistency-driven variational scheme. Specifically, we introduce Single-Step Diffusion Regularization (SSD-Reg), a novel approach that embeds diffusion priors into the iterative reconstruction process, enabling the recovery of complex anatomical structures without the need for paired data. SSD-Reg maintains fidelity to both the governing physics and learned structural distributions, improving accuracy, stability, and robustness. Extensive experiments demonstrate that SSD-Reg, implemented as a Plug-and-Play (PnP) module, provides a flexible and effective solution for tackling the ill-posedness inherent in functional image reconstruction.
<div id='section'>Paperid: <span id='pid'>1119, <a href='https://arxiv.org/pdf/2508.07994.pdf' target='_blank'>https://arxiv.org/pdf/2508.07994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Birgit Hillebrecht, Benjamin Unger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07994">Prediction error certification for PINNs: Theory, computation, and application to Stokes flow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rigorous error estimation is a fundamental topic in numerical analysis. With the increasing use of physics-informed neural networks (PINNs) for solving partial differential equations, several approaches have been developed to quantify the associated prediction error. In this work, we build upon a semigroup-based framework previously introduced by the authors for estimating the PINN error. While this estimator has so far been limited to academic examples - due to the need to compute quantities related to input-to-state stability - we extend its applicability to a significantly broader class of problems. This is accomplished by modifying the error bound and proposing numerical strategies to approximate the required stability parameters. The extended framework enables the certification of PINN predictions in more realistic scenarios, as demonstrated by a numerical study of Stokes flow around a cylinder.
<div id='section'>Paperid: <span id='pid'>1120, <a href='https://arxiv.org/pdf/2508.06634.pdf' target='_blank'>https://arxiv.org/pdf/2508.06634.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Zhao, Jin Wei-Kocsis, Adel Heidari Akhijahani, Karen L Butler-Purry
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06634">Dual-Head Physics-Informed Graph Decision Transformer for Distribution System Restoration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Driven by recent advances in sensing and computing, deep reinforcement learning (DRL) technologies have shown great potential for addressing distribution system restoration (DSR) under uncertainty. However, their data-intensive nature and reliance on the Markov Decision Process (MDP) assumption limit their ability to handle scenarios that require long-term temporal dependencies or few-shot and zero-shot decision making. Emerging Decision Transformers (DTs), which leverage causal transformers for sequence modeling in DRL tasks, offer a promising alternative. However, their reliance on return-to-go (RTG) cloning and limited generalization capacity restricts their effectiveness in dynamic power system environments. To address these challenges, we introduce an innovative Dual-Head Physics-informed Graph Decision Transformer (DH-PGDT) that integrates physical modeling, structural reasoning, and subgoal-based guidance to enable scalable and robust DSR even in zero-shot or few-shot scenarios. DH-PGDT features a dual-head physics-informed causal transformer architecture comprising Guidance Head, which generates subgoal representations, and Action Head, which uses these subgoals to generate actions independently of RTG. It also incorporates an operational constraint-aware graph reasoning module that encodes power system topology and operational constraints to generate a confidence-weighted action vector for refining DT trajectories. This design effectively improves generalization and enables robust adaptation to unseen scenarios. While this work focuses on DSR, the underlying computing model of the proposed PGDT is broadly applicable to sequential decision making across various power system operations and other complex engineering domains.
<div id='section'>Paperid: <span id='pid'>1121, <a href='https://arxiv.org/pdf/2508.05190.pdf' target='_blank'>https://arxiv.org/pdf/2508.05190.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis Mandl, Dibyajyoti Nayak, Tim Ricken, Somdatta Goswami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05190">Physics-Informed Time-Integrated DeepONet: Temporal Tangent Space Operator Learning for High-Accuracy Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately modeling and inferring solutions to time-dependent partial differential equations (PDEs) over extended horizons remains a core challenge in scientific machine learning. Traditional full rollout (FR) methods, which predict entire trajectories in one pass, often fail to capture the causal dependencies and generalize poorly outside the training time horizon. Autoregressive (AR) approaches, evolving the system step by step, suffer from error accumulation, limiting long-term accuracy. These shortcomings limit the long-term accuracy and reliability of both strategies. To address these issues, we introduce the Physics-Informed Time-Integrated Deep Operator Network (PITI-DeepONet), a dual-output architecture trained via fully physics-informed or hybrid physics- and data-driven objectives to ensure stable, accurate long-term evolution well beyond the training horizon. Instead of forecasting future states, the network learns the time-derivative operator from the current state, integrating it using classical time-stepping schemes to advance the solution in time. Additionally, the framework can leverage residual monitoring during inference to estimate prediction quality and detect when the system transitions outside the training domain. Applied to benchmark problems, PITI-DeepONet shows improved accuracy over extended inference time horizons when compared to traditional methods. Mean relative $\mathcal{L}_2$ errors reduced by 84% (vs. FR) and 79% (vs. AR) for the one-dimensional heat equation; by 87% (vs. FR) and 98% (vs. AR) for the one-dimensional Burgers equation; and by 42% (vs. FR) and 89% (vs. AR) for the two-dimensional Allen-Cahn equation. By moving beyond classic FR and AR schemes, PITI-DeepONet paves the way for more reliable, long-term integration of complex, time-dependent PDEs.
<div id='section'>Paperid: <span id='pid'>1122, <a href='https://arxiv.org/pdf/2507.21710.pdf' target='_blank'>https://arxiv.org/pdf/2507.21710.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongwei Ma, Junbin Gao, Minh-Ngoc Tran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21710">PREIG: Physics-informed and Reinforcement-driven Interpretable GRU for Commodity Demand Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately forecasting commodity demand remains a critical challenge due to volatile market dynamics, nonlinear dependencies, and the need for economically consistent predictions. This paper introduces PREIG, a novel deep learning framework tailored for commodity demand forecasting. The model uniquely integrates a Gated Recurrent Unit (GRU) architecture with physics-informed neural network (PINN) principles by embedding a domain-specific economic constraint: the negative elasticity between price and demand. This constraint is enforced through a customized loss function that penalizes violations of the physical rule, ensuring that model predictions remain interpretable and aligned with economic theory. To further enhance predictive performance and stability, PREIG incorporates a hybrid optimization strategy that couples NAdam and L-BFGS with Population-Based Training (POP). Experiments across multiple commodities datasets demonstrate that PREIG significantly outperforms traditional econometric models (ARIMA,GARCH) and deep learning baselines (BPNN,RNN) in both RMSE and MAPE. When compared with GRU,PREIG maintains good explainability while still performing well in prediction. By bridging domain knowledge, optimization theory and deep learning, PREIG provides a robust, interpretable, and scalable solution for high-dimensional nonlinear time series forecasting in economy.
<div id='section'>Paperid: <span id='pid'>1123, <a href='https://arxiv.org/pdf/2507.19701.pdf' target='_blank'>https://arxiv.org/pdf/2507.19701.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haichuan Li, Tomi Westerlund
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19701">PhysVarMix: Physics-Informed Variational Mixture Model for Multi-Modal Trajectory Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of future agent trajectories is a critical challenge for ensuring safe and efficient autonomous navigation, particularly in complex urban environments characterized by multiple plausible future scenarios. In this paper, we present a novel hybrid approach that integrates learning-based with physics-based constraints to address the multi-modality inherent in trajectory prediction. Our method employs a variational Bayesian mixture model to effectively capture the diverse range of potential future behaviors, moving beyond traditional unimodal assumptions. Unlike prior approaches that predominantly treat trajectory prediction as a data-driven regression task, our framework incorporates physical realism through sector-specific boundary conditions and Model Predictive Control (MPC)-based smoothing. These constraints ensure that predicted trajectories are not only data-consistent but also physically plausible, adhering to kinematic and dynamic principles. Furthermore, our method produces interpretable and diverse trajectory predictions, enabling enhanced downstream decision-making and planning in autonomous driving systems. We evaluate our approach on two benchmark datasets, demonstrating superior performance compared to existing methods. Comprehensive ablation studies validate the contributions of each component and highlight their synergistic impact on prediction accuracy and reliability. By balancing data-driven insights with physics-informed constraints, our approach offers a robust and scalable solution for navigating the uncertainties of real-world urban environments.
<div id='section'>Paperid: <span id='pid'>1124, <a href='https://arxiv.org/pdf/2507.15678.pdf' target='_blank'>https://arxiv.org/pdf/2507.15678.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amine Mohamed Aboussalah, Abdessalam Ed-dib
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.15678">GeoHNNs: Geometric Hamiltonian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The fundamental laws of physics are intrinsically geometric, dictating the evolution of systems through principles of symmetry and conservation. While modern machine learning offers powerful tools for modeling complex dynamics from data, common methods often ignore this underlying geometric fabric. Physics-informed neural networks, for instance, can violate fundamental physical principles, leading to predictions that are unstable over long periods, particularly for high-dimensional and chaotic systems. Here, we introduce \textit{Geometric Hamiltonian Neural Networks (GeoHNN)}, a framework that learns dynamics by explicitly encoding the geometric priors inherent to physical laws. Our approach enforces two fundamental structures: the Riemannian geometry of inertia, by parameterizing inertia matrices in their natural mathematical space of symmetric positive-definite matrices, and the symplectic geometry of phase space, using a constrained autoencoder to ensure the preservation of phase space volume in a reduced latent space. We demonstrate through experiments on systems ranging from coupled oscillators to high-dimensional deformable objects that GeoHNN significantly outperforms existing models. It achieves superior long-term stability, accuracy, and energy conservation, confirming that embedding the geometry of physics is not just a theoretical appeal but a practical necessity for creating robust and generalizable models of the physical world.
<div id='section'>Paperid: <span id='pid'>1125, <a href='https://arxiv.org/pdf/2507.15259.pdf' target='_blank'>https://arxiv.org/pdf/2507.15259.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kyung-Bin Kwon, Sayak Mukherjee, Ramij R. Hossain, Marcelo Elizondo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.15259">Physics-Informed Learning of Proprietary Inverter Models for Grid Dynamic Studies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This letter develops a novel physics-informed neural ordinary differential equations-based framework to emulate the proprietary dynamics of the inverters -- essential for improved accuracy in grid dynamic simulations. In current industry practice, the original equipment manufacturers (OEMs) often do not disclose the exact internal controls and parameters of the inverters, posing significant challenges in performing accurate dynamic simulations and other relevant studies, such as gain tunings for stability analysis and controls. To address this, we propose a Physics-Informed Latent Neural ODE Model (PI-LNM) that integrates system physics with neural learning layers to capture the unmodeled behaviors of proprietary units. The proposed method is validated using a grid-forming inverter (GFM) case study, demonstrating improved dynamic simulation accuracy over approaches that rely solely on data-driven learning without physics-based guidance.
<div id='section'>Paperid: <span id='pid'>1126, <a href='https://arxiv.org/pdf/2507.14341.pdf' target='_blank'>https://arxiv.org/pdf/2507.14341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan Zanardi, Simone Venturi, Marco Panesi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14341">MENO: Hybrid Matrix Exponential-based Neural Operator for Stiff ODEs. Application to Thermochemical Kinetics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce MENO (''Matrix Exponential-based Neural Operator''), a hybrid surrogate modeling framework for efficiently solving stiff systems of ordinary differential equations (ODEs) that exhibit a sparse nonlinear structure. In such systems, only a few variables contribute nonlinearly to the dynamics, while the majority influence the equations linearly. MENO exploits this property by decomposing the system into two components: the low-dimensional nonlinear part is modeled using conventional neural operators, while the linear time-varying subsystem is integrated using a novel neural matrix exponential formulation. This approach combines the exact solution of linear time-invariant systems with learnable, time-dependent graph-based corrections applied to the linear operators. Unlike black-box or soft-constrained physics-informed (PI) models, MENO embeds the governing equations directly into its architecture, ensuring physical consistency (e.g., steady states), improved robustness, and more efficient training. We validate MENO on three complex thermochemical systems: the POLLU atmospheric chemistry model, an oxygen mixture in thermochemical nonequilibrium, and a collisional-radiative argon plasma in one- and two-dimensional shock-tube simulations. MENO achieves relative errors below 2% in trained zero-dimensional settings and maintains good accuracy in extrapolatory multidimensional regimes. It also delivers substantial computational speedups, achieving up to 4 800$\times$ on GPU and 185$\times$ on CPU compared to standard implicit ODE solvers. Although intrusive by design, MENO's physics-based architecture enables superior generalization and reliability, offering a scalable path for real-time simulation of stiff reactive systems.
<div id='section'>Paperid: <span id='pid'>1127, <a href='https://arxiv.org/pdf/2507.11962.pdf' target='_blank'>https://arxiv.org/pdf/2507.11962.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Tang, Jiang Yang, Yuxiang Zhao, Quanhui Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11962">Structured First-Layer Initialization Pre-Training Techniques to Accelerate Training Process Based on $\varepsilon$-Rank</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training deep neural networks for scientific computing remains computationally expensive due to the slow formation of diverse feature representations in early training stages. Recent studies identify a staircase phenomenon in training dynamics, where loss decreases are closely correlated with increases in $\varepsilon$-rank, reflecting the effective number of linearly independent neuron functions. Motivated by this observation, this work proposes a structured first-layer initialization (SFLI) pre-training method to enhance the diversity of neural features at initialization by constructing $\varepsilon$-linearly independent neurons in the input layer. We present systematic initialization schemes compatible with various activation functions and integrate the strategy into multiple neural architectures, including modified multi-layer perceptrons and physics-informed residual adaptive networks. Extensive numerical experiments on function approximation and PDE benchmarks, demonstrate that SFLI significantly improves the initial $\varepsilon$-rank, accelerates convergence, mitigates spectral bias, and enhances prediction accuracy. With the help of SILP, we only need to add one line of code to conventional existing algorithms.
<div id='section'>Paperid: <span id='pid'>1128, <a href='https://arxiv.org/pdf/2507.10884.pdf' target='_blank'>https://arxiv.org/pdf/2507.10884.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyunwoo Cho, Hyeontae Jo, Hyung Ju Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10884">Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>System inference for nonlinear dynamic models, represented by ordinary differential equations (ODEs), remains a significant challenge in many fields, particularly when the data are noisy, sparse, or partially observable. In this paper, we propose a Simulation-based Generative Model for Imperfect Data (SiGMoID) that enables precise and robust inference for dynamic systems. The proposed approach integrates two key methods: (1) physics-informed neural networks with hyper-networks that constructs an ODE solver, and (2) Wasserstein generative adversarial networks that estimates ODE parameters by effectively capturing noisy data distributions. We demonstrate that SiGMoID quantifies data noise, estimates system parameters, and infers unobserved system components. Its effectiveness is validated validated through realistic experimental examples, showcasing its broad applicability in various domains, from scientific research to engineered systems, and enabling the discovery of full system dynamics.
<div id='section'>Paperid: <span id='pid'>1129, <a href='https://arxiv.org/pdf/2507.06712.pdf' target='_blank'>https://arxiv.org/pdf/2507.06712.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ayoub Farkane, Mohamed Boutayeb, Mustapha Oudani, Mounir Ghogho
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06712">PINN-Obs: Physics-Informed Neural Network-Based Observer for Nonlinear Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State estimation for nonlinear dynamical systems is a critical challenge in control and engineering applications, particularly when only partial and noisy measurements are available. This paper introduces a novel Adaptive Physics-Informed Neural Network-based Observer (PINN-Obs) for accurate state estimation in nonlinear systems. Unlike traditional model-based observers, which require explicit system transformations or linearization, the proposed framework directly integrates system dynamics and sensor data into a physics-informed learning process. The observer adaptively learns an optimal gain matrix, ensuring convergence of the estimated states to the true system states. A rigorous theoretical analysis establishes formal convergence guarantees, demonstrating that the proposed approach achieves uniform error minimization under mild observability conditions. The effectiveness of PINN-Obs is validated through extensive numerical simulations on diverse nonlinear systems, including an induction motor model, a satellite motion system, and benchmark academic examples. Comparative experimental studies against existing observer designs highlight its superior accuracy, robustness, and adaptability.
<div id='section'>Paperid: <span id='pid'>1130, <a href='https://arxiv.org/pdf/2507.03521.pdf' target='_blank'>https://arxiv.org/pdf/2507.03521.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georgios Grekas, Charalambos G. Makridakis, Tristan Pryer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.03521">PINN-DG: Residual neural network methods trained with Finite Elements</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Over the past few years, neural network methods have evolved in various directions for approximating partial differential equations (PDEs). A promising new development is the integration of neural networks with classical numerical techniques such as finite elements and finite differences. In this paper, we introduce a new class of Physics-Informed Neural Networks (PINNs) trained using discontinuous Galerkin finite element methods. Unlike standard collocation-based PINNs that rely on pointwise gradient evaluations and Monte Carlo quadrature, our approach computes the loss functional using finite element interpolation and integration. This avoids costly pointwise derivative computations, particularly advantageous for elliptic PDEs requiring second-order derivatives, and inherits key stability and accuracy benefits from the finite element framework. We present a convergence analysis based on variational arguments and support our theoretical findings with numerical experiments that demonstrate improved efficiency and robustness.
<div id='section'>Paperid: <span id='pid'>1131, <a href='https://arxiv.org/pdf/2507.02887.pdf' target='_blank'>https://arxiv.org/pdf/2507.02887.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alejandro Polo-Molina, Jose Portela, Luis Alberto Herrero Rozas, RomÃ¡n Cicero GonzÃ¡lez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02887">Modeling Membrane Degradation in PEM Electrolyzers with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Proton exchange membrane (PEM) electrolyzers are pivotal for sustainable hydrogen production, yet their long-term performance is hindered by membrane degradation, which poses reliability and safety challenges. Therefore, accurate modeling of this degradation is essential for optimizing durability and performance. To address these concerns, traditional physics-based models have been developed, offering interpretability but requiring numerous parameters that are often difficult to measure and calibrate. Conversely, data-driven approaches, such as machine learning, offer flexibility but may lack physical consistency and generalizability. To address these limitations, this study presents the first application of Physics-Informed Neural Networks (PINNs) to model membrane degradation in PEM electrolyzers. The proposed PINN framework couples two ordinary differential equations, one modeling membrane thinning via a first-order degradation law and another governing the time evolution of the cell voltage under membrane degradation. Results demonstrate that the PINN accurately captures the long-term system's degradation dynamics while preserving physical interpretability with limited noisy data. Consequently, this work introduces a novel hybrid modeling approach for estimating and understanding membrane degradation mechanisms in PEM electrolyzers, offering a foundation for more robust predictive tools in electrochemical system diagnostics.
<div id='section'>Paperid: <span id='pid'>1132, <a href='https://arxiv.org/pdf/2507.02106.pdf' target='_blank'>https://arxiv.org/pdf/2507.02106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Semih Kacmaz, E. A. Huerta, Roland Haas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02106">Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a hybrid machine learning framework that combines Physics-Informed Neural Operators (PINOs) with score-based generative diffusion models to simulate the full spatio-temporal evolution of two-dimensional, incompressible, resistive magnetohydrodynamic (MHD) turbulence across a broad range of Reynolds numbers ($\mathrm{Re}$). The framework leverages the equation-constrained generalization capabilities of PINOs to predict coherent, low-frequency dynamics, while a conditional diffusion model stochastically corrects high-frequency residuals, enabling accurate modeling of fully developed turbulence. Trained on a comprehensive ensemble of high-fidelity simulations with $\mathrm{Re} \in \{100, 250, 500, 750, 1000, 3000, 10000\}$, the approach achieves state-of-the-art accuracy in regimes previously inaccessible to deterministic surrogates. At $\mathrm{Re}=1000$ and $3000$, the model faithfully reconstructs the full spectral energy distributions of both velocity and magnetic fields late into the simulation, capturing non-Gaussian statistics, intermittent structures, and cross-field correlations with high fidelity. At extreme turbulence levels ($\mathrm{Re}=10000$), it remains the first surrogate capable of recovering the high-wavenumber evolution of the magnetic field, preserving large-scale morphology and enabling statistically meaningful predictions.
<div id='section'>Paperid: <span id='pid'>1133, <a href='https://arxiv.org/pdf/2507.01841.pdf' target='_blank'>https://arxiv.org/pdf/2507.01841.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihang Gao, Vincent Y. F. Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01841">Automatic Rank Determination for Low-Rank Adaptation via Submodular Function Maximization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose SubLoRA, a rank determination method for Low-Rank Adaptation (LoRA) based on submodular function maximization. In contrast to prior approaches, such as AdaLoRA, that rely on first-order (linearized) approximations of the loss function, SubLoRA utilizes second-order information to capture the potentially complex loss landscape by incorporating the Hessian matrix. We show that the linearization becomes inaccurate and ill-conditioned when the LoRA parameters have been well optimized, motivating the need for a more reliable and nuanced second-order formulation. To this end, we reformulate the rank determination problem as a combinatorial optimization problem with a quadratic objective. However, solving this problem exactly is NP-hard in general. To overcome the computational challenge, we introduce a submodular function maximization framework and devise a greedy algorithm with approximation guarantees. We derive a sufficient and necessary condition under which the rank-determination objective becomes submodular, and construct a closed-form projection of the Hessian matrix that satisfies this condition while maintaining computational efficiency. Our method combines solid theoretical foundations, second-order accuracy, and practical computational efficiency. We further extend SubLoRA to a joint optimization setting, alternating between LoRA parameter updates and rank determination under a rank budget constraint. Extensive experiments on fine-tuning physics-informed neural networks (PINNs) for solving partial differential equations (PDEs) demonstrate the effectiveness of our approach. Results show that SubLoRA outperforms existing methods in both rank determination and joint training performance.
<div id='section'>Paperid: <span id='pid'>1134, <a href='https://arxiv.org/pdf/2506.20696.pdf' target='_blank'>https://arxiv.org/pdf/2506.20696.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyu Mu, Wei Xuan Chan, Choon Hwai Yap
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.20696">IMC-PINN-FE: A Physics-Informed Neural Network for Patient-Specific Left Ventricular Finite Element Modeling with Image Motion Consistency and Biomechanical Parameter Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Elucidating the biomechanical behavior of the myocardium is crucial for understanding cardiac physiology, but cannot be directly inferred from clinical imaging and typically requires finite element (FE) simulations. However, conventional FE methods are computationally expensive and often fail to reproduce observed cardiac motions. We propose IMC-PINN-FE, a physics-informed neural network (PINN) framework that integrates imaged motion consistency (IMC) with FE modeling for patient-specific left ventricular (LV) biomechanics. Cardiac motion is first estimated from MRI or echocardiography using either a pre-trained attention-based network or an unsupervised cyclic-regularized network, followed by extraction of motion modes. IMC-PINN-FE then rapidly estimates myocardial stiffness and active tension by fitting clinical pressure measurements, accelerating computation from hours to seconds compared to traditional inverse FE. Based on these parameters, it performs FE modeling across the cardiac cycle at 75x speedup. Through motion constraints, it matches imaged displacements more accurately, improving average Dice from 0.849 to 0.927, while preserving realistic pressure-volume behavior. IMC-PINN-FE advances previous PINN-FE models by introducing back-computation of material properties and better motion fidelity. Using motion from a single subject to reconstruct shape modes also avoids the need for large datasets and improves patient specificity. IMC-PINN-FE offers a robust and efficient approach for rapid, personalized, and image-consistent cardiac biomechanical modeling.
<div id='section'>Paperid: <span id='pid'>1135, <a href='https://arxiv.org/pdf/2506.20441.pdf' target='_blank'>https://arxiv.org/pdf/2506.20441.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Antoine Caradot, RÃ©mi Emonet, Amaury Habrard, Abdel-Rahim Mezidi, Marc Sebban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.20441">MÃ©thode de quadrature pour les PINNs fondÃ©e thÃ©oriquement sur la hessienne des rÃ©siduels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Neural Networks (PINNs) have emerged as an efficient way to learn surrogate neural solvers of PDEs by embedding the physical model in the loss function and minimizing its residuals using automatic differentiation at so-called collocation points. Originally uniformly sampled, the choice of the latter has been the subject of recent advances leading to adaptive sampling refinements. In this paper, we propose a new quadrature method for approximating definite integrals based on the hessian of the considered function, and that we leverage to guide the selection of the collocation points during the training process of PINNs.
<div id='section'>Paperid: <span id='pid'>1136, <a href='https://arxiv.org/pdf/2506.17994.pdf' target='_blank'>https://arxiv.org/pdf/2506.17994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minh Trinh, Andreas RenÃ© Geist, Josefine Monnet, Stefan Vilceanu, Sebastian Trimpe, Christian Brecher
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17994">Newtonian and Lagrangian Neural Networks: A Comparison Towards Efficient Inverse Dynamics Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate inverse dynamics models are essential tools for controlling industrial robots. Recent research combines neural network regression with inverse dynamics formulations of the Newton-Euler and the Euler-Lagrange equations of motion, resulting in so-called Newtonian neural networks and Lagrangian neural networks, respectively. These physics-informed models seek to identify unknowns in the analytical equations from data. Despite their potential, current literature lacks guidance on choosing between Lagrangian and Newtonian networks. In this study, we show that when motor torques are estimated instead of directly measuring joint torques, Lagrangian networks prove less effective compared to Newtonian networks as they do not explicitly model dissipative torques. The performance of these models is compared to neural network regression on data of a MABI MAX 100 industrial robot.
<div id='section'>Paperid: <span id='pid'>1137, <a href='https://arxiv.org/pdf/2506.17453.pdf' target='_blank'>https://arxiv.org/pdf/2506.17453.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Naveen Sudharsan, Manmeet Singh, Harsh Kamath, Hassan Dashtian, Clint Dawson, Zong-Liang Yang, Dev Niyogi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17453">UT-GraphCast Hindcast Dataset: A Global AI Forecast Archive from UT Austin for Weather and Climate Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The UT GraphCast Hindcast Dataset from 1979 to 2024 is a comprehensive global weather forecast archive generated using the Google DeepMind GraphCast Operational model. Developed by researchers at The University of Texas at Austin under the WCRP umbrella, this dataset provides daily 15 day deterministic forecasts at 00UTC on an approximately 25 km global grid for a 45 year period. GraphCast is a physics informed graph neural network that was trained on ECMWF ERA5 reanalysis. It predicts more than a dozen key atmospheric and surface variables on 37 vertical levels, delivering a full medium range forecast in under one minute on modern hardware.
<div id='section'>Paperid: <span id='pid'>1138, <a href='https://arxiv.org/pdf/2506.17345.pdf' target='_blank'>https://arxiv.org/pdf/2506.17345.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Changwen Xu, Shang Zhu, Venkatasubramanian Viswanathan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17345">CLOUD: A Scalable and Physics-Informed Foundation Model for Crystal Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The prediction of crystal properties is essential for understanding structure-property relationships and accelerating the discovery of functional materials. However, conventional approaches relying on experimental measurements or density functional theory (DFT) calculations are often resource-intensive, limiting their scalability. Machine learning (ML) models offer a promising alternative by learning complex structure-property relationships from data, enabling faster predictions. Yet, existing ML models often rely on labeled data, adopt representations that poorly capture essential structural characteristics, and lack integration with physical principles--factors that limit their generalizability and interpretability. Here, we introduce CLOUD (Crystal Language mOdel for Unified and Differentiable materials modeling), a transformer-based framework trained on a novel Symmetry-Consistent Ordered Parameter Encoding (SCOPE) that encodes crystal symmetry, Wyckoff positions, and composition in a compact, coordinate-free string representation. Pre-trained on over six million crystal structures, CLOUD is fine-tuned on multiple downstream tasks and achieves competitive performance in predicting a wide range of material properties, demonstrating strong scaling performance. Furthermore, as proof of concept of differentiable materials modeling, CLOUD is applied to predict the phonon internal energy and heat capacity, which integrates the Debye model to preserve thermodynamic consistency. The CLOUD-DEBYE framework enforces thermodynamic consistency and enables temperature-dependent property prediction without requiring additional data. These results demonstrate the potential of CLOUD as a scalable and physics-informed foundation model for crystalline materials, unifying symmetry-consistent representations with physically grounded learning for property prediction and materials discovery.
<div id='section'>Paperid: <span id='pid'>1139, <a href='https://arxiv.org/pdf/2506.09721.pdf' target='_blank'>https://arxiv.org/pdf/2506.09721.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guglielmo Padula, Gianluigi Rozza
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09721">Generative Models for Parameter Space Reduction applied to Reduced Order Modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving and optimising Partial Differential Equations (PDEs) in geometrically parameterised domains often requires iterative methods, leading to high computational and time complexities. One potential solution is to learn a direct mapping from the parameters to the PDE solution. Two prominent methods for this are Data-driven Non-Intrusive Reduced Order Models (DROMs) and Parametrised Physics Informed Neural Networks (PPINNs). However, their accuracy tends to degrade as the number of geometric parameters increases. To address this, we propose adopting Generative Models to create new geometries, effectively reducing the number of parameters, and improving the performance of DROMs and PPINNs. The first section briefly reviews the general theory of Generative Models and provides some examples, whereas the second focusses on their application to geometries with fixed or variable points, emphasising their integration with DROMs and PPINNs. DROMs trained on geometries generated by these models demonstrate enhanced accuracy due to reduced parameter dimensionality. For PPINNs, we introduce a methodology that leverages Generative Models to reduce the parameter dimensions and improve convergence. This approach is tested on a Poisson equation defined over deformed Stanford Bunny domains.
<div id='section'>Paperid: <span id='pid'>1140, <a href='https://arxiv.org/pdf/2506.04375.pdf' target='_blank'>https://arxiv.org/pdf/2506.04375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Conor Rowan, John Evans, Kurt Maute, Alireza Doostan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.04375">Solving engineering eigenvalue problems with neural networks using the Rayleigh quotient</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>From characterizing the speed of a thermal system's response to computing natural modes of vibration, eigenvalue analysis is ubiquitous in engineering. In spite of this, eigenvalue problems have received relatively little treatment compared to standard forward and inverse problems in the physics-informed machine learning literature. In particular, neural network discretizations of solutions to eigenvalue problems have seen only a handful of studies. Owing to their nonlinearity, neural network discretizations prevent the conversion of the continuous eigenvalue differential equation into a standard discrete eigenvalue problem. In this setting, eigenvalue analysis requires more specialized techniques. Using a neural network discretization of the eigenfunction, we show that a variational form of the eigenvalue problem called the "Rayleigh quotient" in tandem with a Gram-Schmidt orthogonalization procedure is a particularly simple and robust approach to find the eigenvalues and their corresponding eigenfunctions. This method is shown to be useful for finding sets of harmonic functions on irregular domains, parametric and nonlinear eigenproblems, and high-dimensional eigenanalysis. We also discuss the utility of harmonic functions as a spectral basis for approximating solutions to partial differential equations. Through various examples from engineering mechanics, the combination of the Rayleigh quotient objective, Gram-Schmidt procedure, and the neural network discretization of the eigenfunction is shown to offer unique advantages for handling continuous eigenvalue problems.
<div id='section'>Paperid: <span id='pid'>1141, <a href='https://arxiv.org/pdf/2506.03173.pdf' target='_blank'>https://arxiv.org/pdf/2506.03173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoyi Liu, Hao Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.03173">FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physical intelligence -- anticipating and shaping the world from partial, multisensory observations -- is critical for next-generation world models. We propose FOLIAGE, a physics-informed multimodal world model for unbounded accretive surface growth. In its Action-Perception loop, a unified context encoder maps images, mesh connectivity, and point clouds to a shared latent state. A physics-aware predictor, conditioned on physical control actions, advances this latent state in time to align with the target latent of the surface, yielding a Modality-Agnostic Growth Embedding (MAGE) that interfaces with critic heads for downstream objectives. FOLIAGE's Accretive Graph Network (AGN) captures dynamic connectivity through Age Positional Encoding and Energy-Gated Message-Passing. Geometry-Correspondence Fusion and Cross-Patch Masking enhance MAGE's expressiveness, while Hierarchical Pooling balances global context with local dynamics. We create SURF-GARDEN, a world model learning platform comprising a Counterfactual Physics Simulator, a Multimodal Correspondence Extractor, and Evolution Tracing, which generates 7,200 diverse surface-growth sequences. SURF-BENCH, our physical-intelligence evaluation suite, evaluates six core tasks -- topology recognition, inverse material estimation, growth-stage classification, latent roll-out, cross-modal retrieval, and dense correspondence -- and four stress tests -- sensor dropout, zero-shot modality transfer, long-horizon prediction, and physics ablation -- to probe resilience. FOLIAGE outperforms specialized baselines while remaining robust across dynamic environments, establishing a new world-model based, multimodal pathway to physical intelligence.
<div id='section'>Paperid: <span id='pid'>1142, <a href='https://arxiv.org/pdf/2506.02489.pdf' target='_blank'>https://arxiv.org/pdf/2506.02489.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Zhong, Jonah Buchanan, Christine Allen-Blanchette
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02489">Grasp2Grasp: Vision-Based Dexterous Grasp Translation via SchrÃ¶dinger Bridges</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a new approach to vision-based dexterous grasp translation, which aims to transfer grasp intent across robotic hands with differing morphologies. Given a visual observation of a source hand grasping an object, our goal is to synthesize a functionally equivalent grasp for a target hand without requiring paired demonstrations or hand-specific simulations. We frame this problem as a stochastic transport between grasp distributions using the SchrÃ¶dinger Bridge formalism. Our method learns to map between source and target latent grasp spaces via score and flow matching, conditioned on visual observations. To guide this translation, we introduce physics-informed cost functions that encode alignment in base pose, contact maps, wrench space, and manipulability. Experiments across diverse hand-object pairs demonstrate our approach generates stable, physically grounded grasps with strong generalization. This work enables semantic grasp transfer for heterogeneous manipulators and bridges vision-based grasping with probabilistic generative modeling.
<div id='section'>Paperid: <span id='pid'>1143, <a href='https://arxiv.org/pdf/2506.01445.pdf' target='_blank'>https://arxiv.org/pdf/2506.01445.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kamal Basha S, Anukul Kiran B, Athira Nambiar, Suresh Rajendran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01445">A Novel Context-Adaptive Fusion of Shadow and Highlight Regions for Efficient Sonar Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sonar imaging is fundamental to underwater exploration, with critical applications in defense, navigation, and marine research. Shadow regions, in particular, provide essential cues for object detection and classification, yet existing studies primarily focus on highlight-based analysis, leaving shadow-based classification underexplored. To bridge this gap, we propose a Context-adaptive sonar image classification framework that leverages advanced image processing techniques to extract and integrate discriminative shadow and highlight features. Our framework introduces a novel shadow-specific classifier and adaptive shadow segmentation, enabling effective classification based on the dominant region. This approach ensures optimal feature representation, improving robustness against noise and occlusions. In addition, we introduce a Region-aware denoising model that enhances sonar image quality by preserving critical structural details while suppressing noise. This model incorporates an explainability-driven optimization strategy, ensuring that denoising is guided by feature importance, thereby improving interpretability and classification reliability. Furthermore, we present S3Simulator+, an extended dataset incorporating naval mine scenarios with physics-informed noise specifically tailored for the underwater sonar domain, fostering the development of robust AI models. By combining novel classification strategies with an enhanced dataset, our work addresses key challenges in sonar image analysis, contributing
  to the advancement of autonomous underwater perception.
<div id='section'>Paperid: <span id='pid'>1144, <a href='https://arxiv.org/pdf/2506.00731.pdf' target='_blank'>https://arxiv.org/pdf/2506.00731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Binghang Lu, Changhong Mou, Guang Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00731">MoPINNEnKF: Iterative Model Inference using generic-PINN-based ensemble Kalman filter</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a powerful tool for solving forward and inverse problems involving partial differential equations (PDEs) by incorporating physical laws into the training process. However, the performance of PINNs is often hindered in real-world scenarios involving noisy observational data and missing physics, particularly in inverse problems. In this work, we propose an iterative multi-objective PINN ensemble Kalman filter (MoPINNEnKF) framework that improves the robustness and accuracy of PINNs in both forward and inverse problems by using the \textit{ensemble Kalman filter} and the \textit{non-dominated sorting genetic algorithm} III (NSGA-III). Specifically, NSGA-III is used as a multi-objective optimizer that can generate various ensemble members of PINNs along the optimal Pareto front, while accounting the model uncertainty in the solution space. These ensemble members are then utilized within the EnKF to assimilate noisy observational data. The EnKF's analysis is subsequently used to refine the data loss component for retraining the PINNs, thereby iteratively updating their parameters. The iterative procedure generates improved solutions to the PDEs. The proposed method is tested on two benchmark problems: the one-dimensional viscous Burgers equation and the time-fractional mixed diffusion-wave equation (TFMDWE). The numerical results show it outperforms standard PINNs in handling noisy data and missing physics.
<div id='section'>Paperid: <span id='pid'>1145, <a href='https://arxiv.org/pdf/2505.22391.pdf' target='_blank'>https://arxiv.org/pdf/2505.22391.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Zhang, Difan Zou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22391">Physics-Informed Distillation of Diffusion Models for PDE-Constrained Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling physical systems in a generative manner offers several advantages, including the ability to handle partial observations, generate diverse solutions, and address both forward and inverse problems. Recently, diffusion models have gained increasing attention in the modeling of physical systems, particularly those governed by partial differential equations (PDEs). However, diffusion models only access noisy data $\boldsymbol{x}_t$ at intermediate steps, making it infeasible to directly enforce constraints on the clean sample $\boldsymbol{x}_0$ at each noisy level. As a workaround, constraints are typically applied to the expectation of clean samples $\mathbb{E}[\boldsymbol{x}_0|\boldsymbol{x}_t]$, which is estimated using the learned score network. However, imposing PDE constraints on the expectation does not strictly represent the one on the true clean data, known as Jensen's Gap. This gap creates a trade-off: enforcing PDE constraints may come at the cost of reduced accuracy in generative modeling. To address this, we propose a simple yet effective post-hoc distillation approach, where PDE constraints are not injected directly into the diffusion process, but instead enforced during a post-hoc distillation stage. We term our method as Physics-Informed Distillation of Diffusion Models (PIDDM). This distillation not only facilitates single-step generation with improved PDE satisfaction, but also support both forward and inverse problem solving and reconstruction from randomly partial observation. Extensive experiments across various PDE benchmarks demonstrate that PIDDM significantly improves PDE satisfaction over several recent and competitive baselines, such as PIDM, DiffusionPDE, and ECI-sampling, with less computation overhead. Our approach can shed light on more efficient and effective strategies for incorporating physical constraints into diffusion models.
<div id='section'>Paperid: <span id='pid'>1146, <a href='https://arxiv.org/pdf/2505.21994.pdf' target='_blank'>https://arxiv.org/pdf/2505.21994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Josef Dick, Seungchan Ko, Kassem Mustapha, Sanghyeon Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21994">Locking-Free Training of Physics-Informed Neural Network for Solving Nearly Incompressible Elasticity Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to divergence instability, the accuracy of low-order conforming finite element methods for nearly incompressible homogeneous elasticity equations deteriorates as the LamÃ© coefficient $Î»\to\infty$, or equivalently as the Poisson ratio $Î½\to1/2$. This phenomenon, known as locking or non-robustness, remains not fully understood despite extensive investigation. In this paper, we propose a robust method based on a fundamentally different, machine-learning-driven approach. Leveraging recently developed Physics-Informed Neural Networks (PINNs), we address the numerical solution of linear elasticity equations governing nearly incompressible materials. The core idea of our method is to appropriately decompose the given equations to alleviate the extreme imbalance in the coefficients, while simultaneously solving both the forward and inverse problems to recover the solutions of the decomposed systems as well as the associated external conditions. Through various numerical experiments, including constant, variable and parametric LamÃ© coefficients, we illustrate the efficiency of the proposed methodology.
<div id='section'>Paperid: <span id='pid'>1147, <a href='https://arxiv.org/pdf/2505.21842.pdf' target='_blank'>https://arxiv.org/pdf/2505.21842.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Filippos Fotiadis, Kyriakos G. Vamvoudakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21842">A Physics-Informed Learning Framework to Solve the Infinite-Horizon Optimal Control Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a physics-informed neural networks (PINNs) framework to solve the infinite-horizon optimal control problem of nonlinear systems. In particular, since PINNs are generally able to solve a class of partial differential equations (PDEs), they can be employed to learn the value function of the infinite-horizon optimal control problem via solving the associated steady-state Hamilton-Jacobi-Bellman (HJB) equation. However, an issue here is that the steady-state HJB equation generally yields multiple solutions; hence if PINNs are directly employed to it, they may end up approximating a solution that is different from the optimal value function of the problem. We tackle this by instead applying PINNs to a finite-horizon variant of the steady-state HJB that has a unique solution, and which uniformly approximates the optimal value function as the horizon increases. An algorithm to verify if the chosen horizon is large enough is also given, as well as a method to extend it -- with reduced computations and robustness to approximation errors -- in case it is not. Unlike many existing methods, the proposed technique works well with non-polynomial basis functions, does not require prior knowledge of a stabilizing controller, and does not perform iterative policy evaluations. Simulations are performed, which verify and clarify theoretical findings.
<div id='section'>Paperid: <span id='pid'>1148, <a href='https://arxiv.org/pdf/2505.19320.pdf' target='_blank'>https://arxiv.org/pdf/2505.19320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michail Spitieris, Massimiliano Ruocco, Abdulmajid Murad, Alessandro Nocente
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19320">PIGPVAE: Physics-Informed Gaussian Process Variational Autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in generative AI offer promising solutions for synthetic data generation but often rely on large datasets for effective training. To address this limitation, we propose a novel generative model that learns from limited data by incorporating physical constraints to enhance performance. Specifically, we extend the VAE architecture by incorporating physical models in the generative process, enabling it to capture underlying dynamics more effectively. While physical models provide valuable insights, they struggle to capture complex temporal dependencies present in real-world data. To bridge this gap, we introduce a discrepancy term to account for unmodeled dynamics, represented within a latent Gaussian Process VAE (GPVAE). Furthermore, we apply regularization to ensure the generated data aligns closely with observed data, enhancing both the diversity and accuracy of the synthetic samples. The proposed method is applied to indoor temperature data, achieving state-of-the-art performance. Additionally, we demonstrate that PIGPVAE can produce realistic samples beyond the observed distribution, highlighting its robustness and usefulness under distribution shifts.
<div id='section'>Paperid: <span id='pid'>1149, <a href='https://arxiv.org/pdf/2505.17919.pdf' target='_blank'>https://arxiv.org/pdf/2505.17919.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingquan Feng, Yifan Fu, Tongcheng Zhang, Yu Jiang, Yixin Huang, Junchi Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17919">KITINet: Kinetics Theory Inspired Network Architectures with PDE Simulation Approaches</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the widely recognized success of residual connections in modern neural networks, their design principles remain largely heuristic. This paper introduces KITINet (Kinetics Theory Inspired Network), a novel architecture that reinterprets feature propagation through the lens of non-equilibrium particle dynamics and partial differential equation (PDE) simulation. At its core, we propose a residual module that models feature updates as the stochastic evolution of a particle system, numerically simulated via a discretized solver for the Boltzmann transport equation (BTE). This formulation mimics particle collisions and energy exchange, enabling adaptive feature refinement via physics-informed interactions. Additionally, we reveal that this mechanism induces network parameter condensation during training, where parameters progressively concentrate into a sparse subset of dominant channels. Experiments on scientific computation (PDE operator), image classification (CIFAR-10/100), and text classification (IMDb/SNLI) show consistent improvements over classic network baselines, with negligible increase of FLOPs.
<div id='section'>Paperid: <span id='pid'>1150, <a href='https://arxiv.org/pdf/2505.14252.pdf' target='_blank'>https://arxiv.org/pdf/2505.14252.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mouad Elaarabi, Domenico Borzacchiello, Philippe Le Bot, Nathan Lauzeral, Sebastien Comas-Cardona
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14252">Hybrid Adaptive Modeling in Process Monitoring: Leveraging Sequence Encoders and Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we explore the integration of Sequence Encoding for Online Parameter Identification with Physics-Informed Neural Networks to create a model that, once trained, can be utilized for real time applications with variable parameters, boundary conditions, and initial conditions. Recently, the combination of PINNs with Sparse Regression has emerged as a method for performing dynamical system identification through supervised learning and sparse regression optimization, while also solving the dynamics using PINNs. However, this approach can be limited by variations in parameters or boundary and initial conditions, requiring retraining of the model whenever changes occur. In this work, we introduce an architecture that employs Deep Sets or Sequence Encoders to encode dynamic parameters, boundary conditions, and initial conditions, using these encoded features as inputs for the PINN, enabling the model to adapt to changes in parameters, BCs, and ICs. We apply this approach to three different problems. First, we analyze the Rossler ODE system, demonstrating the robustness of the model with respect to noise and its ability to generalize. Next, we explore the model's capability in a 2D Navier-Stokes PDE problem involving flow past a cylinder with a parametric sinusoidal inlet velocity function, showing that the model can encode pressure data from a few points to identify the inlet velocity profile and utilize physics to compute velocity and pressure throughout the domain. Finally, we address a 1D heat monitoring problem using real data from the heating of glass fiber and thermoplastic composite plates.
<div id='section'>Paperid: <span id='pid'>1151, <a href='https://arxiv.org/pdf/2505.12149.pdf' target='_blank'>https://arxiv.org/pdf/2505.12149.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>AndrÃ©s GuzmÃ¡n-Cordero, Felix Dangel, Gil Goldshlager, Marius Zeinhofer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12149">Improving Energy Natural Gradient Descent through Woodbury, Momentum, and Randomization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Natural gradient methods significantly accelerate the training of Physics-Informed Neural Networks (PINNs), but are often prohibitively costly. We introduce a suite of techniques to improve the accuracy and efficiency of energy natural gradient descent (ENGD) for PINNs. First, we leverage the Woodbury formula to dramatically reduce the computational complexity of ENGD. Second, we adapt the Subsampled Projected-Increment Natural Gradient Descent algorithm from the variational Monte Carlo literature to accelerate the convergence. Third, we explore the use of randomized algorithms to further reduce the computational cost in the case of large batch sizes. We find that randomization accelerates progress in the early stages of training for low-dimensional problems, and we identify key barriers to attaining acceleration in other scenarios. Our numerical experiments demonstrate that our methods outperform previous approaches, achieving the same $L^2$ error as the original ENGD up to $75\times$ faster.
<div id='section'>Paperid: <span id='pid'>1152, <a href='https://arxiv.org/pdf/2505.09899.pdf' target='_blank'>https://arxiv.org/pdf/2505.09899.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Binesh Sadanandan, Vahid Behzadan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.09899">Promise of Data-Driven Modeling and Decision Support for Precision Oncology and Theranostics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cancer remains a leading cause of death worldwide, necessitating personalized treatment approaches to improve outcomes. Theranostics, combining molecular-level imaging with targeted therapy, offers potential for precision oncology but requires optimized, patient-specific care plans. This paper investigates state-of-the-art data-driven decision support applications with a reinforcement learning focus in precision oncology. We review current applications, training environments, state-space representation, performance evaluation criteria, and measurement of risk and reward, highlighting key challenges. We propose a framework integrating data-driven modeling with reinforcement learning-based decision support to optimize radiopharmaceutical therapy dosing, addressing identified challenges and setting directions for future research. The framework leverages Neural Ordinary Differential Equations and Physics-Informed Neural Networks to enhance Physiologically Based Pharmacokinetic models while applying reinforcement learning algorithms to iteratively refine treatment policies based on patient-specific data.
<div id='section'>Paperid: <span id='pid'>1153, <a href='https://arxiv.org/pdf/2505.04875.pdf' target='_blank'>https://arxiv.org/pdf/2505.04875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Conor Rowan, Kurt Maute, Alireza Doostan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04875">Physics-informed solution reconstruction in elasticity and heat transfer using the explicit constraint force method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One use case of ``physics-informed neural networks'' (PINNs) is solution reconstruction, which aims to estimate the full-field state of a physical system from sparse measurements. Parameterized governing equations of the system are used in tandem with the measurements to regularize the regression problem. However, in real-world solution reconstruction problems, the parameterized governing equation may be inconsistent with the physical phenomena that give rise to the measurement data. We show that due to assuming consistency between the true and parameterized physics, PINNs-based approaches may fail to satisfy three basic criteria of interpretability, robustness, and data consistency. As we argue, these criteria ensure that (i) the quality of the reconstruction can be assessed, (ii) the reconstruction does not depend strongly on the choice of physics loss, and (iii) that in certain situations, the physics parameters can be uniquely recovered. In the context of elasticity and heat transfer, we demonstrate how standard formulations of the physics loss and techniques for constraining the solution to respect the measurement data lead to different ``constraint forces" -- which we define as additional source terms arising from the constraints -- and that these constraint forces can significantly influence the reconstructed solution. To avoid the potentially substantial influence of the choice of physics loss and method of constraint enforcement on the reconstructed solution, we propose the ``explicit constraint force method'' (ECFM) to gain control of the source term introduced by the constraint. We then show that by satisfying the criteria of interpretability, robustness, and data consistency, this approach leads to more predictable and customizable reconstructions from noisy measurement data, even when the parameterization of the missing physics is inconsistent with the measured system.
<div id='section'>Paperid: <span id='pid'>1154, <a href='https://arxiv.org/pdf/2505.04627.pdf' target='_blank'>https://arxiv.org/pdf/2505.04627.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jean-Michel Tucny, Mihir Durve, Sauro Succi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04627">Is the end of Insight in Sight ?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rise of deep learning challenges the longstanding scientific ideal of insight - the human capacity to understand phenomena by uncovering underlying mechanisms. In many modern applications, accurate predictions no longer require interpretable models, prompting debate about whether explainability is a realistic or even meaningful goal. From our perspective in physics, we examine this tension through a concrete case study: a physics-informed neural network (PINN) trained on a rarefied gas dynamics problem governed by the Boltzmann equation. Despite the system's clear structure and well-understood governing laws, the trained network's weights resemble Gaussian-distributed random matrices, with no evident trace of the physical principles involved. This suggests that deep learning and traditional simulation may follow distinct cognitive paths to the same outcome - one grounded in mechanistic insight, the other in statistical interpolation. Our findings raise critical questions about the limits of explainable AI and whether interpretability can - or should-remain a universal standard in artificial reasoning.
<div id='section'>Paperid: <span id='pid'>1155, <a href='https://arxiv.org/pdf/2505.04263.pdf' target='_blank'>https://arxiv.org/pdf/2505.04263.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan Blechschmidt, Tom-Christian Riemer, Max Winkler, Martin Stoll, Jan-F. Pietschmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04263">Physics-Informed DeepONets for drift-diffusion on metric graphs: simulation and parameter identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a novel physics informed deep learning approach for solving nonlinear drift-diffusion equations on metric graphs. These models represent an important model class with a large number of applications in areas ranging from transport in biological cells to the motion of human crowds. While traditional numerical schemes require a large amount of tailoring, especially in the case of model design or parameter identification problems, physics informed deep operator networks (DeepONet) have emerged as a versatile tool for the solution of partial differential equations with the particular advantage that they easily incorporate parameter identification questions. We here present an approach where we first learn three DeepONet models for representative inflow, inner and outflow edges, resp., and then subsequently couple these models for the solution of the drift-diffusion metric graph problem by relying on an edge-based domain decomposition approach. We illustrate that our framework is applicable for the accurate evaluation of graph-coupled physics models and is well suited for solving optimization or inverse problems on these coupled networks.
<div id='section'>Paperid: <span id='pid'>1156, <a href='https://arxiv.org/pdf/2504.20241.pdf' target='_blank'>https://arxiv.org/pdf/2504.20241.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kamirul Kamirul, Odysseas Pappas, Alin Achim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.20241">Physics-Informed Diffusion Models for SAR Ship Wake Generation from Text Prompts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting ship presence via wake signatures in SAR imagery is attracting considerable research interest, but limited annotated data availability poses significant challenges for supervised learning. Physics-based simulations are commonly used to address this data scarcity, although they are slow and constrain end-to-end learning. In this work, we explore a new direction for more efficient and end-to-end SAR ship wake simulation using a diffusion model trained on data generated by a physics-based simulator. The training dataset is built by pairing images produced by the simulator with text prompts derived from simulation parameters. Experimental result show that the model generates realistic Kelvin wake patterns and achieves significantly faster inference than the physics-based simulator. These results highlight the potential of diffusion models for fast and controllable wake image generation, opening new possibilities for end-to-end downstream tasks in maritime SAR analysis.
<div id='section'>Paperid: <span id='pid'>1157, <a href='https://arxiv.org/pdf/2504.20019.pdf' target='_blank'>https://arxiv.org/pdf/2504.20019.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdelhakim Amer, David Felsager, Yury Brodskiy, Andriy Sarabakha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.20019">Modelling of Underwater Vehicles using Physics-Informed Neural Networks with Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) integrate physical laws with data-driven models to improve generalization and sample efficiency. This work introduces an open-source implementation of the Physics-Informed Neural Network with Control (PINC) framework, designed to model the dynamics of an underwater vehicle. Using initial states, control actions, and time inputs, PINC extends PINNs to enable physically consistent transitions beyond the training domain. Various PINC configurations are tested, including differing loss functions, gradient-weighting schemes, and hyperparameters. Validation on a simulated underwater vehicle demonstrates more accurate long-horizon predictions compared to a non-physics-informed baseline
<div id='section'>Paperid: <span id='pid'>1158, <a href='https://arxiv.org/pdf/2504.19372.pdf' target='_blank'>https://arxiv.org/pdf/2504.19372.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weishi Wang, Mark K. Transtrum, Vincenzo Lordi, Vasily V. Bulatov, Amit Samanta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.19372">Composable and adaptive design of machine learning interatomic potentials guided by Fisher-information analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An adaptive physics-informed model design strategy for machine-learning interatomic potentials (MLIPs) is proposed. This strategy follows an iterative reconfiguration of composite models from single-term models, followed by a unified training procedure. A model evaluation method based on the Fisher information matrix (FIM) and multiple-property error metrics is proposed to guide model reconfiguration and hyperparameter optimization. Combining the model reconfiguration and the model evaluation subroutines, we provide an adaptive MLIP design strategy that balances flexibility and extensibility. In a case study of designing models against a structurally diverse niobium dataset, we managed to obtain an optimal configuration with 75 parameters generated by our framework that achieved a force RMSE of 0.172 eV/Ã and an energy RMSE of 0.013 eV/atom.
<div id='section'>Paperid: <span id='pid'>1159, <a href='https://arxiv.org/pdf/2504.17966.pdf' target='_blank'>https://arxiv.org/pdf/2504.17966.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaiyuan Tan, Peilun Li, Jun Wang, Thomas Beckers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.17966">Plug-and-Play Physics-informed Learning using Uncertainty Quantified Port-Hamiltonian Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to predict trajectories of surrounding agents and obstacles is a crucial component in many robotic applications. Data-driven approaches are commonly adopted for state prediction in scenarios where the underlying dynamics are unknown. However, the performance, reliability, and uncertainty of data-driven predictors become compromised when encountering out-of-distribution observations relative to the training data. In this paper, we introduce a Plug-and-Play Physics-Informed Machine Learning (PnP-PIML) framework to address this challenge. Our method employs conformal prediction to identify outlier dynamics and, in that case, switches from a nominal predictor to a physics-consistent model, namely distributed Port-Hamiltonian systems (dPHS). We leverage Gaussian processes to model the energy function of the dPHS, enabling not only the learning of system dynamics but also the quantification of predictive uncertainty through its Bayesian nature. In this way, the proposed framework produces reliable physics-informed predictions even for the out-of-distribution scenarios.
<div id='section'>Paperid: <span id='pid'>1160, <a href='https://arxiv.org/pdf/2504.17771.pdf' target='_blank'>https://arxiv.org/pdf/2504.17771.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haochen Wang, Zhiwei Shi, Chengxi Zhu, Yafei Qiao, Cheng Zhang, Fan Yang, Pengjie Ren, Lan Lu, Dong Xuan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.17771">Integrating Learning-Based Manipulation and Physics-Based Locomotion for Whole-Body Badminton Robot Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning-based methods, such as imitation learning (IL) and reinforcement learning (RL), can produce excel control policies over challenging agile robot tasks, such as sports robot. However, no existing work has harmonized learning-based policy with model-based methods to reduce training complexity and ensure the safety and stability for agile badminton robot control. In this paper, we introduce Hamlet, a novel hybrid control system for agile badminton robots. Specifically, we propose a model-based strategy for chassis locomotion which provides a base for arm policy. We introduce a physics-informed "IL+RL" training framework for learning-based arm policy. In this train framework, a model-based strategy with privileged information is used to guide arm policy training during both IL and RL phases. In addition, we train the critic model during IL phase to alleviate the performance drop issue when transitioning from IL to RL. We present results on our self-engineered badminton robot, achieving 94.5% success rate against the serving machine and 90.7% success rate against human players. Our system can be easily generalized to other agile mobile manipulation tasks such as agile catching and table tennis. Our project website: https://dreamstarring.github.io/HAMLET/.
<div id='section'>Paperid: <span id='pid'>1161, <a href='https://arxiv.org/pdf/2504.17210.pdf' target='_blank'>https://arxiv.org/pdf/2504.17210.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junfei Wang, Darshana Upadhyay, Marzia Zaman, Pirathayini Srikantha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.17210">Synthetic Power Flow Data Generation Using Physics-Informed Denoising Diffusion Probabilistic Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many data-driven modules in smart grid rely on access to high-quality power flow data; however, real-world data are often limited due to privacy and operational constraints. This paper presents a physics-informed generative framework based on Denoising Diffusion Probabilistic Models (DDPMs) for synthesizing feasible power flow data. By incorporating auxiliary training and physics-informed loss functions, the proposed method ensures that the generated data exhibit both statistical fidelity and adherence to power system feasibility. We evaluate the approach on the IEEE 14-bus and 30-bus benchmark systems, demonstrating its ability to capture key distributional properties and generalize to out-of-distribution scenarios. Comparative results show that the proposed model outperforms three baseline models in terms of feasibility, diversity, and accuracy of statistical features. This work highlights the potential of integrating generative modelling into data-driven power system applications.
<div id='section'>Paperid: <span id='pid'>1162, <a href='https://arxiv.org/pdf/2504.16447.pdf' target='_blank'>https://arxiv.org/pdf/2504.16447.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeesuk Shin, Cheolwoong Kim, Sunwoong Yang, Minseo Lee, Sung Joong Kim, Joongoo Jeon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16447">Node Assigned physics-informed neural networks for thermal-hydraulic system simulation: CVH/FL module</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Severe accidents (SAs) in nuclear power plants have been analyzed using thermal-hydraulic (TH) system codes such as MELCOR and MAAP. These codes efficiently simulate the progression of SAs, while they still have inherent limitations due to their inconsistent finite difference schemes. The use of empirical schemes incorporating both implicit and explicit formulations inherently induces unidirectional coupling in multi-physics analyses. The objective of this study is to develop a novel numerical method for TH system codes using physics-informed neural network (PINN). They have shown strength in solving multi-physics due to the innate feature of neural networks-automatic differentiation. We propose a node-assigned PINN (NA-PINN) that is suitable for the control volume approach-based system codes. NA-PINN addresses the issue of spatial governing equation variation by assigning an individual network to each nodalization of the system code, such that spatial information is excluded from both the input and output domains, and each subnetwork learns to approximate a purely temporal solution. In this phase, we evaluated the accuracy of the PINN methods for the hydrodynamic module. In the 6 water tank simulation, PINN and NA-PINN showed maximum absolute errors of 1.678 and 0.007, respectively. It should be noted that only NA-PINN demonstrated acceptable accuracy. To the best of the authors' knowledge, this is the first study to successfully implement a system code using PINN. Our future work involves extending NA-PINN to a multi-physics solver and developing it in a surrogate manner.
<div id='section'>Paperid: <span id='pid'>1163, <a href='https://arxiv.org/pdf/2504.12159.pdf' target='_blank'>https://arxiv.org/pdf/2504.12159.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ting-Ju Wei, Wen-Ning Wan, Chuin-Shan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.12159">Deep Material Network: Overview, applications and current directions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Material Network (DMN) has emerged as a powerful framework for multiscale material modeling, enabling efficient and accurate predictions of material behavior across different length scales. Unlike traditional machine learning approaches, the trainable parameters in DMN have direct physical interpretations, capturing the geometric characteristics of the microstructure rather than serving as purely statistical fitting parameters. Its hierarchical tree structure effectively encodes microstructural interactions and deformation mechanisms, allowing DMN to achieve a balance between accuracy and computational efficiency. This physics-informed architecture significantly reduces computational costs compared to direct numerical simulations while preserving essential microstructural physics. Furthermore, DMN can be trained solely on a linear elastic dataset while effectively extrapolating nonlinear responses during online prediction, making it a highly efficient and scalable approach for multiscale material modeling. This article provides a comprehensive review of DMN, detailing its motivation, underlying methodology, and recent advancements. We discuss key modeling aspects, including its hierarchical structure, training process, and the role of physics-based constraints in enhancing predictive accuracy. Furthermore, we highlight its applications in component-scale multiscale analysis and inverse parameter identification, demonstrating its capability to bridge microscale material behavior with macroscale engineering predictions. Finally, we discuss challenges and future directions in improving DMN's generalization capabilities and its potential extensions for broader applications in multiscale modeling.
<div id='section'>Paperid: <span id='pid'>1164, <a href='https://arxiv.org/pdf/2504.10539.pdf' target='_blank'>https://arxiv.org/pdf/2504.10539.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Li, Lihong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.10539">Physics-Informed Neural Networks for Enhanced Interface Preservation in Lattice Boltzmann Multiphase Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents an improved approach for preserving sharp interfaces in multiphase Lattice Boltzmann Method (LBM) simulations using Physics-Informed Neural Networks (PINNs). Interface diffusion is a common challenge in multiphase LBM, leading to reduced accuracy in simulating phenomena where interfacial dynamics are critical. We propose a coupled PINN-LBM framework that maintains interface sharpness while preserving the physical accuracy of the simulation. Our approach is validated through droplet simulations, with quantitative metrics measuring interface width, maximum gradient, phase separation, effective interface width, and interface energy. The enhanced visualization techniques employed in this work clearly demonstrate the superior performance of PINN-LBM over standard LBM for multiphase simulations, particularly in maintaining well-defined interfaces throughout the simulation. We provide a comprehensive analysis of the results, showcasing how the neural network integration effectively counteracts numerical diffusion, while maintaining physical consistency with the underlying fluid dynamics.
<div id='section'>Paperid: <span id='pid'>1165, <a href='https://arxiv.org/pdf/2504.05397.pdf' target='_blank'>https://arxiv.org/pdf/2504.05397.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixin Jiang, Xuezheng Wang, Bing Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.05397">Physics-informed Modularized Neural Network for Advanced Building Control by Deep Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning (PIML) provides a promising solution for building energy modeling and can serve as a virtual environment to enable reinforcement learning (RL) agents to interact and learn. However, challenges remain in efficiently integrating physics priors, evaluating the effectiveness of physics constraints, balancing model accuracy and physics consistency, and enabling real-world implementation. To address these gaps, this study introduces a Physics-Informed Modularized Neural Network (PI-ModNN), which incorporates physics priors through a physics-informed model structure, loss functions, and hard constraints. A new evaluation metric called "temperature response violation" is developed to quantify the physical consistency of data-driven building dynamic models under varying control inputs and training data sizes. Additionally, a physics prior evaluation framework based on rule importance is proposed to assess the contribution of each individual physics prior, offering guidance on selecting appropriate PIML techniques. Results indicate that incorporating physical priors does not always improve model performance; inappropriate priors may decrease model accuracy and consistency. However, hard constraints are effective in enforcing model consistency. Furthermore, we present a general workflow for developing control-oriented PIML models and integrating them with deep reinforcement learning (DRL). Following this framework, a case study implementing DRL in an office space over three months demonstrates potential energy savings of 31.4%. Finally, we provide a general guideline for integrating data-driven models with advanced building control through a four-step evaluation framework, paving the way for reliable and scalable deployment of advanced building controls.
<div id='section'>Paperid: <span id='pid'>1166, <a href='https://arxiv.org/pdf/2504.02918.pdf' target='_blank'>https://arxiv.org/pdf/2504.02918.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenyu Zhang, Daniil Cherniavskii, Andrii Zadaianchuk, Antonios Tragoudaras, Antonios Vozikis, Thijmen Nijdam, Derck W. E. Prinzhorn, Mark Bodracska, Nicu Sebe, Efstratios Gavves
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02918">Morpheus: Benchmarking Physical Reasoning of Video Generative Models with Real Physical Experiments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in image and video generation raise hopes that these models possess world modeling capabilities, the ability to generate realistic, physically plausible videos. This could revolutionize applications in robotics, autonomous driving, and scientific simulation. However, before treating these models as world models, we must ask: Do they adhere to physical conservation laws? To answer this, we introduce Morpheus, a benchmark for evaluating video generation models on physical reasoning. It features 80 real-world videos capturing physical phenomena, guided by conservation laws. Since artificial generations lack ground truth, we assess physical plausibility using physics-informed metrics evaluated with respect to infallible conservation laws known per physical setting, leveraging advances in physics-informed neural networks and vision-language foundation models. Our findings reveal that even with advanced prompting and video conditioning, current models struggle to encode physical principles despite generating aesthetically pleasing videos. All data, leaderboard, and code are open-sourced at our project page.
<div id='section'>Paperid: <span id='pid'>1167, <a href='https://arxiv.org/pdf/2504.00937.pdf' target='_blank'>https://arxiv.org/pdf/2504.00937.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixin Jiang, Xuezheng Wang, Han Li, Tianzhen Hong, Fengqi You, JÃ¡n DrgoÅa, Draguna Vrabie, Bing Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.00937">Physics-informed machine learning for building performance simulation-A review of a nascent field</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Building performance simulation (BPS) is critical for understanding building dynamics and behavior, analyzing performance of the built environment, optimizing energy efficiency, improving demand flexibility, and enhancing building resilience. However, conducting BPS is not trivial. Traditional BPS relies on an accurate building energy model, mostly physics-based, which depends heavily on detailed building information, expert knowledge, and case-by-case model calibrations, thereby significantly limiting their scalability. With the development of sensing technology and increased data availability, there is a growing attention and interest in data-driven BPS. However, purely data-driven models often suffer from limited generalization ability and a lack of physical consistency, resulting in poor performance in real-world applications. To address these limitations, recent studies have started to incorporate physics priors into data-driven models, a methodology called physics-informed machine learning (PIML). PIML is an emerging field with the definitions, methodologies, evaluation criteria, application scenarios, and future directions that remain open. To bridge those gaps, this study systematically reviews the state-of-art PIML for BPS, offering a comprehensive definition of PIML, and comparing it to traditional BPS approaches regarding data requirements, modeling effort, performance and computation cost. We also summarize the commonly used methodologies, validation approaches, application domains, available data sources, open-source packages and testbeds. In addition, this study provides a general guideline for selecting appropriate PIML models based on BPS applications. Finally, this study identifies key challenges and outlines future research directions, providing a solid foundation and valuable insights to advance R&D of PIML in BPS.
<div id='section'>Paperid: <span id='pid'>1168, <a href='https://arxiv.org/pdf/2504.00910.pdf' target='_blank'>https://arxiv.org/pdf/2504.00910.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Antoine Caradot, RÃ©mi Emonet, Amaury Habrard, Abdel-Rahim Mezidi, Marc Sebban
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.00910">Provably Accurate Adaptive Sampling for Collocation Points in Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite considerable scientific advances in numerical simulation, efficiently solving PDEs remains a complex and often expensive problem. Physics-informed Neural Networks (PINN) have emerged as an efficient way to learn surrogate solvers by embedding the PDE in the loss function and minimizing its residuals using automatic differentiation at so-called collocation points. Originally uniformly sampled, the choice of the latter has been the subject of recent advances leading to adaptive sampling refinements for PINNs. In this paper, leveraging a new quadrature method for approximating definite integrals, we introduce a provably accurate sampling method for collocation points based on the Hessian of the PDE residuals. Comparative experiments conducted on a set of 1D and 2D PDEs demonstrate the benefits of our method.
<div id='section'>Paperid: <span id='pid'>1169, <a href='https://arxiv.org/pdf/2503.23729.pdf' target='_blank'>https://arxiv.org/pdf/2503.23729.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaodong Feng, Haojiong Shangguan, Tao Tang, Xiaoliang Wan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.23729">Integral regularization PINNs for evolution equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evolution equations, including both ordinary differential equations (ODEs) and partial differential equations (PDEs), play a pivotal role in modeling dynamic systems. However, achieving accurate long-time integration for these equations remains a significant challenge. While physics-informed neural networks (PINNs) provide a mesh-free framework for solving PDEs, they often suffer from temporal error accumulation, which limits their effectiveness in capturing long-time behaviors. To alleviate this issue, we propose integral regularization PINNs (IR-PINNs), a novel approach that enhances temporal accuracy by incorporating an integral-based residual term into the loss function. This method divides the entire time interval into smaller sub-intervals and enforces constraints over these sub-intervals, thereby improving the resolution and correlation of temporal dynamics. Furthermore, IR-PINNs leverage adaptive sampling to dynamically refine the distribution of collocation points based on the evolving solution, ensuring higher accuracy in regions with sharp gradients or rapid variations. Numerical experiments on benchmark problems demonstrate that IR-PINNs outperform original PINNs and other state-of-the-art methods in capturing long-time behaviors, offering a robust and accurate solution for evolution equations.
<div id='section'>Paperid: <span id='pid'>1170, <a href='https://arxiv.org/pdf/2503.17393.pdf' target='_blank'>https://arxiv.org/pdf/2503.17393.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Subed Lamichhane, Haotian Lu, Sheldon X. -D. Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17393">BPINN-EM-Post: Stochastic Electromigration Damage Analysis in the Post-Void Phase based on Bayesian Physics-Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In contrast to the assumptions of most existing Electromigration (EM) analysis tools, the evolution of EM-induced stress is inherently non-deterministic, influenced by factors such as input current fluctuations and manufacturing non-idealities. Traditional approaches for estimating stress variations typically involve computationally expensive and inefficient Monte Carlo simulations with industrial solvers, which quantify variations using mean and variance metrics. In this work, we introduce a novel machine learning-based framework, termed BPINNEM- Post, for efficient stochastic analysis of EM-induced postvoiding aging processes. This new approach integrates closedform analytical solutions with a Bayesian Physics-Informed Neural Network (BPINN) framework to accelerate the analysis for the first time. The closed-form solutions enforce physical laws at the individual wire segment level, while the BPINN ensures that physics constraints at inter-segment junctions are satisfied and stochastic behaviors are accurately modeled. By reducing the number of variables in the loss functions through the use of analytical solutions, our method significantly improves training efficiency without accuracy loss and naturally incorporates variational effects. Additionally, the analytical solutions effectively address the challenge of incorporating initial stress distributions in interconnect structures during post-void stress calculations. Numerical results demonstrate that BPINN-EM-Post achieves over 240x speedup compared to Monte Carlo simulations using the FEM-based COMSOL solver and more than 65x speedup compared to Monte Carlo simulations using the FDM-based EMSpice method.
<div id='section'>Paperid: <span id='pid'>1171, <a href='https://arxiv.org/pdf/2503.17393.pdf' target='_blank'>https://arxiv.org/pdf/2503.17393.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Subed Lamichhane, Haotian Lu, Sheldon X. -D. Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17393">BPINN-EM-Post: Bayesian Physics-Informed Neural Network based Stochastic Electromigration Damage Analysis in the Post-void Phase</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In contrast to the assumptions of most existing Electromigration (EM) analysis tools, the evolution of EM-induced stress is inherently non-deterministic, influenced by factors such as input current fluctuations and manufacturing non-idealities. Traditional approaches for estimating stress variations typically involve computationally expensive and inefficient Monte Carlo simulations with industrial solvers, which quantify variations using mean and variance metrics. In this work, we introduce a novel machine learning-based framework, termed BPINN-EM- Post, for efficient stochastic analysis of EM-induced post-voiding aging processes. For the first time, our new approach integrates closed-form analytical solutions with a Bayesian Physics- Informed Neural Network (BPINN) framework to accelerate the analysis. The closed-form solutions enforce physical laws at the individual wire segment level, while the BPINN ensures that physics constraints at inter-segment junctions are satisfied and stochastic behaviors are accurately modeled. By reducing the number of variables in the loss functions through utilizing analytical solutions, our method significantly improves training efficiency without accuracy loss and naturally incorporates variational effects. Additionally, the analytical solutions effectively address the challenge of incorporating initial stress distributions in interconnect structures during post-void stress calculations. Numerical results demonstrate that BPINN-EM-Post achieves over 240x and more than 67x speedup compared to Monte Carlo simulations using the FEM-based COMSOL solver and FDM-based EMSpice, respectively, with marginal accuracy loss.
<div id='section'>Paperid: <span id='pid'>1172, <a href='https://arxiv.org/pdf/2503.14913.pdf' target='_blank'>https://arxiv.org/pdf/2503.14913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Chen, Yixin Luo, Jingrun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14913">A PINN-enriched finite element method for linear elliptic problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a hybrid method that combines finite element method (FEM) and physics-informed neural network (PINN) for solving linear elliptic problems. This method contains three steps: (1) train a PINN and obtain an approximate solution $u_Î¸$; (2) enrich the finite element space with $u_Î¸$; (3) obtain the final solution by FEM in the enriched space. In the second step, the enriched space is constructed by addition $v + u_Î¸$ or multiplication $v \cdot u_Î¸$, where $v$ belongs to the standard finite element space. We conduct the convergence analysis for the proposed method. Compared to the standard FEM, the same convergence order is obtained and higher accuracy can be achieved when solution derivatives are well approximated in PINN. Numerical examples from one dimension to three dimensions verify these theoretical results. For some examples, the accuracy of the proposed method can be reduced by a couple of orders of magnitude compared to the standard FEM.
<div id='section'>Paperid: <span id='pid'>1173, <a href='https://arxiv.org/pdf/2503.07528.pdf' target='_blank'>https://arxiv.org/pdf/2503.07528.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qasim Khadim, Peter Manzl, Emil Kurvinen, Aki Mikkola, Grzegorz Orzechowski, Johannes Gerstmayr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07528">Real-Time Structural Deflection Estimation in Hydraulically Actuated Systems Using 3D Flexible Multibody Simulation and DNNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The precision, stability, and performance of lightweight high-strength steel structures in heavy machinery is affected by their highly nonlinear dynamics. This, in turn, makes control more difficult, simulation more computationally intensive, and achieving real-time autonomy, using standard approaches, impossible. Machine learning through data-driven, physics-informed and physics-inspired networks, however, promises more computationally efficient and accurate solutions to nonlinear dynamic problems. This study proposes a novel framework that has been developed to estimate real-time structural deflection in hydraulically actuated three-dimensional systems. It is based on SLIDE, a machine-learning-based method to estimate dynamic responses of mechanical systems subjected to forced excitations.~Further, an algorithm is introduced for the data acquisition from a hydraulically actuated system using randomized initial configurations and hydraulic pressures.~The new framework was tested on a hydraulically actuated flexible boom with various sensor combinations and lifting various payloads. The neural network was successfully trained in less time using standard parameters from PyTorch, ADAM optimizer, the various sensor inputs, and minimal output data. The SLIDE-trained neural network accelerated deflection estimation solutions by a factor of $10^7$ in reference to flexible multibody simulation batches and provided reasonable accuracy. These results support the studies goal of providing robust, real-time solutions for control, robotic manipulators, structural health monitoring, and automation problems.
<div id='section'>Paperid: <span id='pid'>1174, <a href='https://arxiv.org/pdf/2503.06347.pdf' target='_blank'>https://arxiv.org/pdf/2503.06347.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vikas Dwivedi, Bruno Sixou, Monica Sigovan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.06347">Curriculum Learning-Driven PIELMs for Fluid Flow Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents two novel, physics-informed extreme learning machine (PIELM)-based algorithms for solving steady and unsteady nonlinear partial differential equations (PDEs) related to fluid flow. Although single-hidden-layer PIELMs outperform deep physics-informed neural networks (PINNs) in speed and accuracy for linear and quasilinear PDEs, their extension to nonlinear problems remains challenging. To address this, we introduce a curriculum learning strategy that reformulates nonlinear PDEs as a sequence of increasingly complex quasilinear PDEs. Additionally, our approach enables a physically interpretable initialization of network parameters by leveraging Radial Basis Functions (RBFs). The performance of the proposed algorithms is validated on two benchmark incompressible flow problems: the viscous Burgers equation and lid-driven cavity flow. To the best of our knowledge, this is the first work to extend PIELM to solving Burgers' shock solution as well as lid-driven cavity flow up to a Reynolds number of 100. As a practical application, we employ PIELM to predict blood flow in a stenotic vessel. The results confirm that PIELM efficiently handles nonlinear PDEs, positioning it as a promising alternative to PINNs for both linear and nonlinear PDEs.
<div id='section'>Paperid: <span id='pid'>1175, <a href='https://arxiv.org/pdf/2503.04123.pdf' target='_blank'>https://arxiv.org/pdf/2503.04123.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Zhong, Christine Allen-Blanchette
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04123">GAGrasp: Geometric Algebra Diffusion for Dexterous Grasping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose GAGrasp, a novel framework for dexterous grasp generation that leverages geometric algebra representations to enforce equivariance to SE(3) transformations. By encoding the SE(3) symmetry constraint directly into the architecture, our method improves data and parameter efficiency while enabling robust grasp generation across diverse object poses. Additionally, we incorporate a differentiable physics-informed refinement layer, which ensures that generated grasps are physically plausible and stable. Extensive experiments demonstrate the model's superior performance in generalization, stability, and adaptability compared to existing methods. Additional details at https://gagrasp.github.io/
<div id='section'>Paperid: <span id='pid'>1176, <a href='https://arxiv.org/pdf/2502.17585.pdf' target='_blank'>https://arxiv.org/pdf/2502.17585.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christopher Zerafa, Pauline Galea, Cristiana Sebu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.17585">Synergizing Deep Learning and Full-Waveform Inversion: Bridging Data-Driven and Theory-Guided Approaches for Enhanced Seismic Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This review explores the integration of deep learning (DL) with full-waveform inversion (FWI) for enhanced seismic imaging and subsurface characterization. It covers FWI and DL fundamentals, geophysical applications (velocity estimation, deconvolution, tomography), and challenges (model complexity, data quality). The review also outlines future research directions, including hybrid, generative, and physics-informed models for improved accuracy, efficiency, and reliability in subsurface property estimation. The synergy between DL and FWI has the potential to transform geophysics, providing new insights into Earth's subsurface.
<div id='section'>Paperid: <span id='pid'>1177, <a href='https://arxiv.org/pdf/2502.15058.pdf' target='_blank'>https://arxiv.org/pdf/2502.15058.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Fang, Ruonan Zheng, Yuanyao, Xiaoxia Gao, Chengxu Zuo, Shihui Guo, Yiyue Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15058">FIP: Endowing Robust Motion Capture on Daily Garment by Fusing Flex and Inertial Sensors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>What if our clothes could capture our body motion accurately? This paper introduces Flexible Inertial Poser (FIP), a novel motion-capturing system using daily garments with two elbow-attached flex sensors and four Inertial Measurement Units (IMUs). To address the inevitable sensor displacements in loose wearables which degrade joint tracking accuracy significantly, we identify the distinct characteristics of the flex and inertial sensor displacements and develop a Displacement Latent Diffusion Model and a Physics-informed Calibrator to compensate for sensor displacements based on such observations, resulting in a substantial improvement in motion capture accuracy. We also introduce a Pose Fusion Predictor to enhance multimodal sensor fusion. Extensive experiments demonstrate that our method achieves robust performance across varying body shapes and motions, significantly outperforming SOTA IMU approaches with a 19.5% improvement in angular error, a 26.4% improvement in elbow angular error, and a 30.1% improvement in positional error. FIP opens up opportunities for ubiquitous human-computer interactions and diverse interactive applications such as Metaverse, rehabilitation, and fitness analysis.
<div id='section'>Paperid: <span id='pid'>1178, <a href='https://arxiv.org/pdf/2502.12177.pdf' target='_blank'>https://arxiv.org/pdf/2502.12177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuheng Liu, Pavlos Protopapas, David Sondak, Feiyu Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12177">Recent Advances of NeuroDiffEq -- An Open-Source Library for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving differential equations is a critical challenge across a host of domains. While many software packages efficiently solve these equations using classical numerical approaches, there has been less effort in developing a library for researchers interested in solving such systems using neural networks. With PyTorch as its backend, NeuroDiffEq is a software library that exploits neural networks to solve differential equations. In this paper, we highlight the latest features of the NeuroDiffEq library since its debut. We show that NeuroDiffEq can solve complex boundary value problems in arbitrary dimensions, tackle boundary conditions at infinity, and maintain flexibility for dynamic injection at runtime.
<div id='section'>Paperid: <span id='pid'>1179, <a href='https://arxiv.org/pdf/2502.11369.pdf' target='_blank'>https://arxiv.org/pdf/2502.11369.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christofer Hardcastle, Ryan O Mullan, Raymundo Arroyave, Brent Vela
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11369">Physics-Informed Gaussian Process Classification for Constraint-Aware Alloy Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Alloy design can be framed as a constraint-satisfaction problem. Building on previous methodologies, we propose equipping Gaussian Process Classifiers (GPCs) with physics-informed prior mean functions to model the boundaries of feasible design spaces. Through three case studies, we highlight the utility of informative priors for handling constraints on continuous and categorical properties. (1) Phase Stability: By incorporating CALPHAD predictions as priors for solid-solution phase stability, we enhance model validation using a publicly available XRD dataset. (2) Phase Stability Prediction Refinement: We demonstrate an in silico active learning approach to efficiently correct phase diagrams. (3) Continuous Property Thresholds: By embedding priors into continuous property models, we accelerate the discovery of alloys meeting specific property thresholds via active learning. In each case, integrating physics-based insights into the classification framework substantially improved model performance, demonstrating an efficient strategy for constraint-aware alloy design.
<div id='section'>Paperid: <span id='pid'>1180, <a href='https://arxiv.org/pdf/2502.09025.pdf' target='_blank'>https://arxiv.org/pdf/2502.09025.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fadi Aldakheel, Elsayed S. Elsayed, Yousef Heider, Oliver Weeger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09025">Physics-based Machine Learning for Computational Fracture Mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study introduces a physics-based machine learning framework for modeling both brittle and ductile fractures. Unlike physics-informed neural networks, which solve partial differential equations by embedding physical laws as soft constraints in loss functions and enforcing boundary conditions via collocation points, our framework integrates physical principles, such as the governing equations and constraints, directly into the neural network architecture. This approach eliminates the dependency on problem-specific retraining for new boundary value problems, ensuring adaptability and consistency. By embedding constitutive behavior into the network's foundational design, our method represents a significant step toward unifying material modeling with machine learning for computational fracture mechanics. Specifically, a feedforward neural network is designed to embed physical laws within its architecture, ensuring thermodynamic consistency. Building on this foundation, synthetic datasets generated from finite element-based phase-field simulations are employed to train the proposed framework, focusing on capturing the homogeneous responses of brittle and ductile fractures. Detailed analyses are performed on the stored elastic energy and the dissipated work due to plasticity and fracture, demonstrating the capability of the framework to predict essential fracture features. The proposed physics-based machine learning framework overcomes the shortcomings of classical machine learning models, which rely heavily on large datasets and lack guarantees of physical principles. By leveraging its physics-integrated design, the physics-based machine learning framework demonstrates exceptional performance in predicting key properties of brittle and ductile fractures with limited training data.
<div id='section'>Paperid: <span id='pid'>1181, <a href='https://arxiv.org/pdf/2502.07129.pdf' target='_blank'>https://arxiv.org/pdf/2502.07129.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Enze Xu, Minghan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07129">Fourier-enhanced Neural Networks For Systems Biology Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of systems biology, differential equations are commonly used to model biological systems, but solving them for large-scale and complex systems can be computationally expensive. Recently, the integration of machine learning and mathematical modeling has offered new opportunities for scientific discoveries in biology and health. The emerging physics-informed neural network (PINN) has been proposed as a solution to this problem. However, PINN can be computationally expensive and unreliable for complex biological systems. To address these issues, we propose the Fourier-enhanced Neural Networks for systems biology (SB-FNN). SB-FNN uses an embedded Fourier neural network with an adaptive activation function and a cyclic penalty function to optimize the prediction of biological dynamics, particularly for biological systems that exhibit oscillatory patterns. Experimental results demonstrate that SB-FNN achieves better performance and is more efficient than PINN for handling complex biological models. Experimental results on cellular and population models demonstrate that SB-FNN outperforms PINN in both accuracy and efficiency, making it a promising alternative approach for handling complex biological models. The proposed method achieved better performance on six biological models and is expected to replace PINN as the most advanced method in systems biology.
<div id='section'>Paperid: <span id='pid'>1182, <a href='https://arxiv.org/pdf/2501.18879.pdf' target='_blank'>https://arxiv.org/pdf/2501.18879.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Takeshi Koshizuka, Issei Sato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18879">Understanding Generalization in Physics Informed Models through Affine Variety Dimensions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning is gaining significant traction for enhancing statistical performance and sample efficiency through the integration of physical knowledge. However, current theoretical analyses often presume complete prior knowledge in non-hybrid settings, overlooking the crucial integration of observational data, and are frequently limited to linear systems, unlike the prevalent nonlinear nature of many real-world applications. To address these limitations, we introduce a unified residual form that unifies collocation and variational methods, enabling the incorporation of incomplete and complex physical constraints in hybrid learning settings. Within this formulation, we establish that the generalization performance of physics-informed regression in such hybrid settings is governed by the dimension of the affine variety associated with the physical constraint, rather than by the number of parameters. This enables a unified analysis that is applicable to both linear and nonlinear equations. We also present a method to approximate this dimension and provide experimental validation of our theoretical findings.
<div id='section'>Paperid: <span id='pid'>1183, <a href='https://arxiv.org/pdf/2501.08428.pdf' target='_blank'>https://arxiv.org/pdf/2501.08428.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sharmila Karumuri, Lori Graham-Brady, Somdatta Goswami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08428">Physics-Informed Latent Neural Operator for Real-time Predictions of Complex Physical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep operator network (DeepONet) has shown significant promise as surrogate models for systems governed by partial differential equations (PDEs), enabling accurate mappings between infinite-dimensional function spaces. However, for complex, high-dimensional systems, these models often require heavily overparameterized networks, leading to long training times and convergence difficulties. Latent DeepONet addresses some of these challenges by introducing a two-step approach: first learning a reduced latent space using a separate model, followed by operator learning within this latent space. While efficient, this method is inherently data-driven and lacks mechanisms for incorporating physical laws, limiting its robustness and generalizability in data-scarce settings. In this work, we propose PI-Latent-NO, a physics-informed latent neural operator framework that integrates governing physics directly into the learning process. Our architecture features two coupled DeepONets trained end-to-end: a Latent-DeepONet that learns a low-dimensional representation of the solution, and a Reconstruction-DeepONet that maps this latent representation back to the physical space. By embedding PDE constraints into the training via automatic differentiation, our method eliminates the need for labeled training data and ensures physics-consistent predictions. The proposed framework is both memory and compute-efficient, exhibiting near-constant scaling with problem size and demonstrating significant speedups over traditional physics-informed operator models. We validate our approach on a range of high-dimensional parametric PDEs, showcasing its accuracy, scalability, and suitability for real-time prediction in complex physical systems.
<div id='section'>Paperid: <span id='pid'>1184, <a href='https://arxiv.org/pdf/2412.18362.pdf' target='_blank'>https://arxiv.org/pdf/2412.18362.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jangseop Park, Namwoo Kang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.18362">Point-DeepONet: A Deep Operator Network Integrating PointNet for Nonlinear Analysis of Non-Parametric 3D Geometries and Load Conditions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nonlinear structural analyses in engineering often require extensive finite element simulations, limiting their applicability in design optimization, uncertainty quantification, and real-time control. Conventional deep learning surrogates, such as convolutional neural networks (CNNs), physics-informed neural networks (PINNs), and fourier neural operators (FNOs), face challenges with complex non-parametric three-dimensional (3D) geometries, directionally varying loads, and high-fidelity predictions on unstructured meshes. This work presents Point-DeepONet, an operator-learning-based surrogate that integrates PointNet into the DeepONet framework. By directly processing non-parametric point clouds and incorporating signed distance functions (SDF) for geometric context, Point-DeepONet accurately predicts three-dimensional displacement and von Mises stress fields without mesh parameterization or retraining. Trained using only about 5,000 nodes (2.5% of the original 200,000-node mesh), Point-DeepONet can still predict the entire mesh at high fidelity, achieving a coefficient of determination reaching 0.987 for displacement and 0.923 for von Mises stress under a horizontal load case. Compared to nonlinear finite element analyses that require about 19.32 minutes per case, Point-DeepONet provides predictions in mere seconds-approximately 400 times faster-while maintaining excellent scalability and accuracy with increasing dataset sizes. These findings highlight the potential of Point-DeepONet to enable rapid, high-fidelity structural analyses, ultimately supporting more effective design exploration and informed decision-making in complex engineering workflows.
<div id='section'>Paperid: <span id='pid'>1185, <a href='https://arxiv.org/pdf/2412.17001.pdf' target='_blank'>https://arxiv.org/pdf/2412.17001.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Van Truong Vo, Samad Noeiaghdam, Denis Sidorov, Aliona Dreglea, Liguo Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.17001">Solving Nonlinear Energy Supply and Demand System Using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nonlinear differential equations and systems play a crucial role in modeling systems where time-dependent factors exhibit nonlinear characteristics. Due to their nonlinear nature, solving such systems often presents significant difficulties and challenges. In this study, we propose a method utilizing Physics-Informed Neural Networks (PINNs) to solve the nonlinear energy supply-demand (ESD) system. We design a neural network with four outputs, where each output approximates a function that corresponds to one of the unknown functions in the nonlinear system of differential equations describing the four-dimensional ESD problem. The neural network model is then trained and the parameters are identified, optimized to achieve a more accurate solution. The solutions obtained from the neural network for this problem are equivalent when we compare and evaluate them against the Runge-Kutta numerical method of order 4/5 (RK45). However, the method utilizing neural networks is considered a modern and promising approach, as it effectively exploits the superior computational power of advanced computer systems, especially in solving complex problems. Another advantage is that the neural network model, after being trained, can solve the nonlinear system of differential equations across a continuous domain. In other words, neural networks are not only trained to approximate the solution functions for the nonlinear ESD system but can also represent the complex dynamic relationships between the system's components. However, this approach requires significant time and computational power due to the need for model training.
<div id='section'>Paperid: <span id='pid'>1186, <a href='https://arxiv.org/pdf/2412.16644.pdf' target='_blank'>https://arxiv.org/pdf/2412.16644.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianghang Gu, Ling Wen, Yuntian Chen, Shiyi Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.16644">An explainable operator approximation framework under the guideline of Green's function</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional numerical methods, such as the finite element method and finite volume method, adress partial differential equations (PDEs) by discretizing them into algebraic equations and solving these iteratively. However, this process is often computationally expensive and time-consuming. An alternative approach involves transforming PDEs into integral equations and solving them using Green's functions, which provide analytical solutions. Nevertheless, deriving Green's functions analytically is a challenging and non-trivial task, particularly for complex systems. In this study, we introduce a novel framework, termed GreensONet, which is constructed based on the strucutre of deep operator networks (DeepONet) to learn embedded Green's functions and solve PDEs via Green's integral formulation. Specifically, the Trunk Net within GreensONet is designed to approximate the unknown Green's functions of the system, while the Branch Net are utilized to approximate the auxiliary gradients of the Green's function. These outputs are subsequently employed to perform surface integrals and volume integrals, incorporating user-defined boundary conditions and source terms, respectively. The effectiveness of the proposed framework is demonstrated on three types of PDEs in bounded domains: 3D heat conduction equations, reaction-diffusion equations, and Stokes equations. Comparative results in these cases demonstrate that GreenONet's accuracy and generalization ability surpass those of existing methods, including Physics-Informed Neural Networks (PINN), DeepONet, Physics-Informed DeepONet (PI-DeepONet), and Fourier Neural Operators (FNO).
<div id='section'>Paperid: <span id='pid'>1187, <a href='https://arxiv.org/pdf/2412.09022.pdf' target='_blank'>https://arxiv.org/pdf/2412.09022.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tarik Sahin, Daniel Wolff, Alexander Popp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09022">Physics-Informed Neural Networks for Solving Contact Problems in Three Dimensions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper explores the application of physics-informed neural networks (PINNs) to tackle forward problems in 3D contact mechanics, focusing on small deformation elasticity. We utilize a mixed-variable formulation, enhanced with output transformations, to enforce Dirichlet and Neumann boundary conditions as hard constraints. The inherent inequality constraints in contact mechanics, particularly the Karush-Kuhn-Tucker (KKT) conditions, are addressed as soft constraints by integrating them into the network's loss function. To enforce the KKT conditions, we leverage the nonlinear complementarity problem (NCP) approach, specifically using the Fischer-Burmeister function, which is known for its advantageous properties in optimization. We investigate two benchmark examples of PINNs in 3D contact mechanics: a single contact patch test and the Hertzian contact problem.
<div id='section'>Paperid: <span id='pid'>1188, <a href='https://arxiv.org/pdf/2412.08650.pdf' target='_blank'>https://arxiv.org/pdf/2412.08650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ganyong Mo, Krishna Kumar Narayanan, David Castells-Rufas, Jordi Carrabina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.08650">Capacitive Touch Sensor Modeling With a Physics-informed Neural Network and Maxwell's Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Maxwell's equations are the fundamental equations for understanding electric and magnetic field interactions and play a crucial role in designing and optimizing sensor systems like capacitive touch sensors, which are widely prevalent in automotive switches and smartphones. Ensuring robust functionality and stability of the sensors in dynamic environments necessitates profound domain expertise and computationally intensive multi-physics simulations. This paper introduces a novel approach using a Physics-Informed Neural Network (PINN) based surrogate model to accelerate the design process. The PINN model solves the governing electrostatic equations describing the interaction between a finger and a capacitive sensor. Inputs include spatial coordinates from a 3D domain encompassing the finger, sensor, and PCB, along with finger distances. By incorporating the electrostatic equations directly into the neural network's loss function, the model captures the underlying physics. The learned model thus serves as a surrogate sensor model on which inference can be carried out in seconds for different experimental setups without the need to run simulations. Efficacy results evaluated on unseen test cases demonstrate the significant potential of PINNs in accelerating the development and design optimization of capacitive touch sensors.
<div id='section'>Paperid: <span id='pid'>1189, <a href='https://arxiv.org/pdf/2412.06158.pdf' target='_blank'>https://arxiv.org/pdf/2412.06158.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zijian Zhou, Zhenya Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.06158">Is the neural tangent kernel of PINNs deep learning general partial differential equations always convergent ?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we study the neural tangent kernel (NTK) for general partial differential equations (PDEs) based on physics-informed neural networks (PINNs). As we all know, the training of an artificial neural network can be converted to the evolution of NTK. We analyze the initialization of NTK and the convergence conditions of NTK during training for general PDEs. The theoretical results show that the homogeneity of differential operators plays a crucial role for the convergence of NTK. Moreover, based on the PINNs, we validate the convergence conditions of NTK using the initial value problems of the sine-Gordon equation and the initial-boundary value problem of the KdV equation.
<div id='section'>Paperid: <span id='pid'>1190, <a href='https://arxiv.org/pdf/2412.05233.pdf' target='_blank'>https://arxiv.org/pdf/2412.05233.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minji Kim, Tianshu Wen, Kookjin Lee, Youngsoo Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05233">Physics-informed reduced order model with conditional neural fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents the conditional neural fields for reduced-order modeling (CNF-ROM) framework to approximate solutions of parametrized partial differential equations (PDEs). The approach combines a parametric neural ODE (PNODE) for modeling latent dynamics over time with a decoder that reconstructs PDE solutions from the corresponding latent states. We introduce a physics-informed learning objective for CNF-ROM, which includes two key components. First, the framework uses coordinate-based neural networks to calculate and minimize PDE residuals by computing spatial derivatives via automatic differentiation and applying the chain rule for time derivatives. Second, exact initial and boundary conditions (IC/BC) are imposed using approximate distance functions (ADFs) [Sukumar and Srivastava, CMAME, 2022]. However, ADFs introduce a trade-off as their second- or higher-order derivatives become unstable at the joining points of boundaries. To address this, we introduce an auxiliary network inspired by [Gladstone et al., NeurIPS ML4PS workshop, 2022]. Our method is validated through parameter extrapolation and interpolation, temporal extrapolation, and comparisons with analytical solutions.
<div id='section'>Paperid: <span id='pid'>1191, <a href='https://arxiv.org/pdf/2412.03949.pdf' target='_blank'>https://arxiv.org/pdf/2412.03949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi-Hung Chiu, Ung Hee Lee, Changseob Song, Manaen Hu, Inseung Kang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03949">Learning Speed-Adaptive Walking Agent Using Imitation Learning with Physics-Informed Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Virtual models of human gait, or digital twins, offer a promising solution for studying mobility without the need for labor-intensive data collection. However, challenges such as the sim-to-real gap and limited adaptability to diverse walking conditions persist. To address these, we developed and validated a framework to create a skeletal humanoid agent capable of adapting to varying walking speeds while maintaining biomechanically realistic motions. The framework combines a synthetic data generator, which produces biomechanically plausible gait kinematics from open-source biomechanics data, and a training system that uses adversarial imitation learning to train the agent's walking policy. We conducted comprehensive analyses comparing the agent's kinematics, synthetic data, and the original biomechanics dataset. The agent achieved a root mean square error of 5.24 +- 0.09 degrees at varying speeds compared to ground-truth kinematics data, demonstrating its adaptability. This work represents a significant step toward developing a digital twin of human locomotion, with potential applications in biomechanics research, exoskeleton design, and rehabilitation.
<div id='section'>Paperid: <span id='pid'>1192, <a href='https://arxiv.org/pdf/2411.18459.pdf' target='_blank'>https://arxiv.org/pdf/2411.18459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emily Williams, Amanda Howard, Brek Meuris, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.18459">What do physics-informed DeepONets learn? Understanding and improving training for scientific computing applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed deep operator networks (DeepONets) have emerged as a promising approach toward numerically approximating the solution of partial differential equations (PDEs). In this work, we aim to develop further understanding of what is being learned by physics-informed DeepONets by assessing the universality of the extracted basis functions and demonstrating their potential toward model reduction with spectral methods. Results provide clarity about measuring the performance of a physics-informed DeepONet through the decays of singular values and expansion coefficients. In addition, we propose a transfer learning approach for improving training for physics-informed DeepONets between parameters of the same PDE as well as across different, but related, PDEs where these models struggle to train well. This approach results in significant error reduction and learned basis functions that are more effective in representing the solution of a PDE.
<div id='section'>Paperid: <span id='pid'>1193, <a href='https://arxiv.org/pdf/2411.14942.pdf' target='_blank'>https://arxiv.org/pdf/2411.14942.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Koji Hashimoto, Koshiro Matsuo, Masaki Murata, Gakuto Ogiwara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14942">Comparative Study of Neural Network Methods for Solving Topological Solitons</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Topological solitons, which are stable, localized solutions of nonlinear differential equations, are crucial in various fields of physics and mathematics, including particle physics and cosmology. However, solving these solitons presents significant challenges due to the complexity of the underlying equations and the computational resources required for accurate solutions. To address this, we have developed a novel method using neural network (NN) to efficiently solve solitons. A similar NN approach is Physics-Informed Neural Networks (PINN). In a comparative analysis between our method and PINN, we find that our method achieves shorter computation times while maintaining the same level of accuracy. This advancement in computational efficiency not only overcomes current limitations but also opens new avenues for studying topological solitons and their dynamical behavior.
<div id='section'>Paperid: <span id='pid'>1194, <a href='https://arxiv.org/pdf/2411.10048.pdf' target='_blank'>https://arxiv.org/pdf/2411.10048.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tymofii Nikolaienko, Harshil Patel, Aniruddha Panda, Subodh Madhav Joshi, Stanislav Jaso, Kaushic Kalyanaraman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.10048">Physics-informed neural networks need a physicist to be accurate: the case of mass and heat transport in Fischer-Tropsch catalyst particles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as an influential technology, merging the swift and automated capabilities of machine learning with the precision and dependability of simulations grounded in theoretical physics. PINNs are often employed to solve algebraic or differential equations to replace some or even all steps of multi-stage computational workflows, leading to their significant speed-up. However, wide adoption of PINNs is still hindered by reliability issues, particularly at extreme ends of the input parameter ranges. In this study, we demonstrate this in the context of a system of coupled non-linear differential reaction-diffusion and heat transfer equations related to Fischer-Tropsch synthesis, which are solved by a finite-difference method with a PINN used in evaluating their source terms. It is shown that the testing strategies traditionally used to assess the accuracy of neural networks as function approximators can overlook the peculiarities which ultimately cause instabilities of the finite-difference solver. We propose a domain knowledge-based modifications to the PINN architecture ensuring its correct asymptotic behavior. When combined with an improved numerical scheme employed as an initial guess generator, the proposed modifications are shown to recover the overall stability of the simulations, while preserving the speed-up brought by PINN as the workflow component. We discuss the possible applications of the proposed hybrid transport equation solver in context of chemical reactors simulations.
<div id='section'>Paperid: <span id='pid'>1195, <a href='https://arxiv.org/pdf/2411.09329.pdf' target='_blank'>https://arxiv.org/pdf/2411.09329.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thivin Anandh, Divij Ghose, Himanshu Jain, Pratham Sunkad, Sashikumaar Ganesan, Volker John
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.09329">Improving hp-Variational Physics-Informed Neural Networks for Steady-State Convection-Dominated Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes and studies two extensions of applying hp-variational physics-informed neural networks, more precisely the FastVPINNs framework, to convection-dominated convection-diffusion-reaction problems. First, a term in the spirit of a SUPG stabilization is included in the loss functional and a network architecture is proposed that predicts spatially varying stabilization parameters. Having observed that the selection of the indicator function in hard-constrained Dirichlet boundary conditions has a big impact on the accuracy of the computed solutions, the second novelty is the proposal of a network architecture that learns good parameters for a class of indicator functions. Numerical studies show that both proposals lead to noticeably more accurate results than approaches that can be found in the literature.
<div id='section'>Paperid: <span id='pid'>1196, <a href='https://arxiv.org/pdf/2411.09237.pdf' target='_blank'>https://arxiv.org/pdf/2411.09237.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yasmine Marani, Israel Filho, Tareq Al-Naffouri, Taous-Meriem Laleg-Kirati
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.09237">Unsupervised Physics-Informed Neural Network-based Nonlinear Observer design for autonomous systems using contraction analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contraction analysis offers, through elegant mathematical developments, a unified way of designing observers for a general class of nonlinear systems, where the observer correction term is obtained by solving an infinite dimensional inequality that guarantees global exponential convergence. However, solving the matrix partial differential inequality involved in contraction analysis design is both analytically and numerically challenging and represents a long-lasting challenge that prevented its wide use. Therefore, the present paper proposes a novel approach that relies on an unsupervised Physics Informed Neural Network (PINN) to design the observer's correction term by enforcing the partial differential inequality in the loss function. The performance of the proposed PINN-based nonlinear observer is assessed in numerical simulation as well as its robustness to measurement noise and neural network approximation error.
<div id='section'>Paperid: <span id='pid'>1197, <a href='https://arxiv.org/pdf/2411.06447.pdf' target='_blank'>https://arxiv.org/pdf/2411.06447.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Finkelstein, Nikita Vladimirov, Moritz Zaiss, Or Perlman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.06447">Multi-Parameter Molecular MRI Quantification using Physics-Informed Self-Supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biophysical model fitting plays a key role in obtaining quantitative parameters from physiological signals and images. However, the model complexity for molecular magnetic resonance imaging (MRI) often translates into excessive computation time, which makes clinical use impractical. Here, we present a generic computational approach for solving the parameter extraction inverse problem posed by ordinary differential equation (ODE) modeling coupled with experimental measurement of the system dynamics. This is achieved by formulating a numerical ODE solver to function as a step-wise analytical one, thereby making it compatible with automatic differentiation-based optimization. This enables efficient gradient-based model fitting, and provides a new approach to parameter quantification based on self-supervised learning from a single data observation. The neural-network-based train-by-fit pipeline was used to quantify semisolid magnetization transfer (MT) and chemical exchange saturation transfer (CEST) amide proton exchange parameters in the human brain, in an in-vivo molecular MRI study (n = 4). The entire pipeline of the first whole brain quantification was completed in 18.3 $\pm$ 8.3 minutes. Reusing the single-subject-trained network for inference in new subjects took 1.0 $\pm$ 0.2 s, to provide results in agreement with literature values and scan-specific fit results.
<div id='section'>Paperid: <span id='pid'>1198, <a href='https://arxiv.org/pdf/2411.00989.pdf' target='_blank'>https://arxiv.org/pdf/2411.00989.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel A. Moore, Brian P. Mann, Boyuan Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00989">Automated Global Analysis of Experimental Dynamics through Low-Dimensional Linear Embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamical systems theory has long provided a foundation for understanding evolving phenomena across scientific domains. Yet, the application of this theory to complex real-world systems remains challenging due to issues in mathematical modeling, nonlinearity, and high dimensionality. In this work, we introduce a data-driven computational framework to derive low-dimensional linear models for nonlinear dynamical systems directly from raw experimental data. This framework enables global stability analysis through interpretable linear models that capture the underlying system structure. Our approach employs time-delay embedding, physics-informed deep autoencoders, and annealing-based regularization to identify novel low-dimensional coordinate representations, unlocking insights across a variety of simulated and previously unstudied experimental dynamical systems. These new coordinate representations enable accurate long-horizon predictions and automatic identification of intricate invariant sets while providing empirical stability guarantees. Our method offers a promising pathway to analyze complex dynamical behaviors across fields such as physics, climate science, and engineering, with broad implications for understanding nonlinear systems in the real world.
<div id='section'>Paperid: <span id='pid'>1199, <a href='https://arxiv.org/pdf/2410.08041.pdf' target='_blank'>https://arxiv.org/pdf/2410.08041.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihang Gao, Vincent Y. F. Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08041">On the Convergence of (Stochastic) Gradient Descent for Kolmogorov--Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kolmogorov--Arnold Networks (KANs), a recently proposed neural network architecture, have gained significant attention in the deep learning community, due to their potential as a viable alternative to multi-layer perceptrons (MLPs) and their broad applicability to various scientific tasks. Empirical investigations demonstrate that KANs optimized via stochastic gradient descent (SGD) are capable of achieving near-zero training loss in various machine learning (e.g., regression, classification, and time series forecasting, etc.) and scientific tasks (e.g., solving partial differential equations). In this paper, we provide a theoretical explanation for the empirical success by conducting a rigorous convergence analysis of gradient descent (GD) and SGD for two-layer KANs in solving both regression and physics-informed tasks. For regression problems, we establish using the neural tangent kernel perspective that GD achieves global linear convergence of the objective function when the hidden dimension of KANs is sufficiently large. We further extend these results to SGD, demonstrating a similar global convergence in expectation. Additionally, we analyze the global convergence of GD and SGD for physics-informed KANs, which unveils additional challenges due to the more complex loss structure. This is the first work establishing the global convergence guarantees for GD and SGD applied to optimize KANs and physics-informed KANs.
<div id='section'>Paperid: <span id='pid'>1200, <a href='https://arxiv.org/pdf/2410.01990.pdf' target='_blank'>https://arxiv.org/pdf/2410.01990.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leonardo Ferreira Guilhoto, Paris Perdikaris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.01990">Deep Learning Alternatives of the Kolmogorov Superposition Theorem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper explores alternative formulations of the Kolmogorov Superposition Theorem (KST) as a foundation for neural network design. The original KST formulation, while mathematically elegant, presents practical challenges due to its limited insight into the structure of inner and outer functions and the large number of unknown variables it introduces. Kolmogorov-Arnold Networks (KANs) leverage KST for function approximation, but they have faced scrutiny due to mixed results compared to traditional multilayer perceptrons (MLPs) and practical limitations imposed by the original KST formulation. To address these issues, we introduce ActNet, a scalable deep learning model that builds on the KST and overcomes many of the drawbacks of Kolmogorov's original formulation. We evaluate ActNet in the context of Physics-Informed Neural Networks (PINNs), a framework well-suited for leveraging KST's strengths in low-dimensional function approximation, particularly for simulating partial differential equations (PDEs). In this challenging setting, where models must learn latent functions without direct measurements, ActNet consistently outperforms KANs across multiple benchmarks and is competitive against the current best MLP-based approaches. These results present ActNet as a promising new direction for KST-based deep learning applications, particularly in scientific computing and PDE simulation tasks.
<div id='section'>Paperid: <span id='pid'>1201, <a href='https://arxiv.org/pdf/2410.01340.pdf' target='_blank'>https://arxiv.org/pdf/2410.01340.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcus Haywood-Alexander, Giacomo Arcieri, Antonios Kamariotis, Eleni Chatzi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.01340">Response Estimation and System Identification of Dynamical Systems via Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The accurate modelling of structural dynamics is crucial across numerous engineering applications, such as Structural Health Monitoring (SHM), seismic analysis, and vibration control. Often, these models originate from physics-based principles and can be derived from corresponding governing equations, often of differential equation form. However, complex system characteristics, such as nonlinearities and energy dissipation mechanisms, often imply that such models are approximative and often imprecise. This challenge is further compounded in SHM, where sensor data is often sparse, making it difficult to fully observe the system's states. To address these issues, this paper explores the use of Physics-Informed Neural Networks (PINNs), a class of physics-enhanced machine learning (PEML) techniques, for the identification and estimation of dynamical systems. PINNs offer a unique advantage by embedding known physical laws directly into the neural network's loss function, allowing for simple embedding of complex phenomena, even in the presence of uncertainties. This study specifically investigates three key applications of PINNs: state estimation in systems with sparse sensing, joint state-parameter estimation, when both system response and parameters are unknown, and parameter estimation within a Bayesian framework to quantify uncertainties. The results demonstrate that PINNs deliver an efficient tool across all aforementioned tasks, even in presence of modelling errors. However, these errors tend to have a more significant impact on parameter estimation, as the optimization process must reconcile discrepancies between the prescribed model and the true system behavior. Despite these challenges, PINNs show promise in dynamical system modeling, offering a robust approach to handling uncertainties.
<div id='section'>Paperid: <span id='pid'>1202, <a href='https://arxiv.org/pdf/2410.00278.pdf' target='_blank'>https://arxiv.org/pdf/2410.00278.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Grigorios Pavliotis, Renato Spacek, Gabriel Stoltz, Urbain Vaes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00278">Neural network approaches for variance reduction in fluctuation formulas</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a method utilizing physics-informed neural networks (PINNs) to solve Poisson equations that serve as control variates in the computation of transport coefficients via fluctuation formulas, such as the Green--Kubo and generalized Einstein-like formulas. By leveraging approximate solutions to the Poisson equation constructed through neural networks, our approach significantly reduces the variance of the estimator at hand. We provide an extensive numerical analysis of the estimators and detail a methodology for training neural networks to solve these Poisson equations. The approximate solutions are then incorporated into Monte Carlo simulations as effective control variates, demonstrating the suitability of the method for moderately high-dimensional problems where fully deterministic solutions are computationally infeasible.
<div id='section'>Paperid: <span id='pid'>1203, <a href='https://arxiv.org/pdf/2409.19081.pdf' target='_blank'>https://arxiv.org/pdf/2409.19081.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wensi Wu, Mitchell Daneker, Christian Herz, Hannah Dewey, Jeffrey A. Weiss, Alison M. Pouch, Lu Lu, Matthew A. Jolley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19081">ADEPT: A Noninvasive Method for Determining Elastic Parameters of Valve Tissue</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computer simulation of "virtual interventions" may inform optimal valve repair for a given patient prior to intervention. However, the paucity of noninvasive methods to determine in vivo mechanical parameters of valves limits the accuracy of computer prediction and their clinical application. To address this, we propose ADEPT: A noninvasive method for Determining Elastic Parameters of valve Tissue. In this work, we demonstrated its application to the tricuspid valve of a child. We first tracked valve displacements from open to closed frames within a 3D echocardiogram time sequence using image registration. Physics-informed neural networks were subsequently applied to estimate the nonlinear mechanical properties from first principles and reference displacements. The simulated model using these patient-specific parameters closely aligned with the reference image segmentation, achieving a mean symmetric distance of less than 1 mm. Our approach doubled the accuracy of the simulated model compared to the generic parameters reported in the literature.
<div id='section'>Paperid: <span id='pid'>1204, <a href='https://arxiv.org/pdf/2409.18426.pdf' target='_blank'>https://arxiv.org/pdf/2409.18426.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youngsik Hwang, Dong-Young Lim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.18426">Dual Cone Gradient Descent for Training Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a prominent approach for solving partial differential equations (PDEs) by minimizing a combined loss function that incorporates both boundary loss and PDE residual loss. Despite their remarkable empirical performance in various scientific computing tasks, PINNs often fail to generate reasonable solutions, and such pathological behaviors remain difficult to explain and resolve. In this paper, we identify that PINNs can be adversely trained when gradients of each loss function exhibit a significant imbalance in their magnitudes and present a negative inner product value. To address these issues, we propose a novel optimization framework, Dual Cone Gradient Descent (DCGD), which adjusts the direction of the updated gradient to ensure it falls within a dual cone region. This region is defined as a set of vectors where the inner products with both the gradients of the PDE residual loss and the boundary loss are non-negative. Theoretically, we analyze the convergence properties of DCGD algorithms in a non-convex setting. On a variety of benchmark equations, we demonstrate that DCGD outperforms other optimization algorithms in terms of various evaluation metrics. In particular, DCGD achieves superior predictive accuracy and enhances the stability of training for failure modes of PINNs and complex PDEs, compared to existing optimally tuned models. Moreover, DCGD can be further improved by combining it with popular strategies for PINNs, including learning rate annealing and the Neural Tangent Kernel (NTK).
<div id='section'>Paperid: <span id='pid'>1205, <a href='https://arxiv.org/pdf/2409.17938.pdf' target='_blank'>https://arxiv.org/pdf/2409.17938.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Miguel Ã. Alejo, Lucrezia Cossetti, Luca Fanelli, Claudio MuÃ±oz, NicolÃ¡s Valenzuela
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17938">Error bounds for Physics Informed Neural Networks in Nonlinear SchrÃ¶dinger equations placed on unbounded domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the subcritical nonlinear SchrÃ¶dinger (NLS) in dimension one posed on the unbounded real line. Several previous works have considered the deep neural network approximation of NLS solutions from the numerical and theoretical point of view in the case of bounded domains. In this paper, we introduce a new PINNs method to treat the case of unbounded domains and show rigorous bounds on the associated approximation error in terms of the energy and Strichartz norms, provided a reasonable integration scheme is available. Applications to traveling waves, breathers and solitons, as well as numerical experiments confirming the validity of the approximation are also presented as well.
<div id='section'>Paperid: <span id='pid'>1206, <a href='https://arxiv.org/pdf/2409.13185.pdf' target='_blank'>https://arxiv.org/pdf/2409.13185.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sen Wang, Peizhi Zhao, Tao Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13185">ASPINN: An asymptotic strategy for solving singularly perturbed differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving Singularly Perturbed Differential Equations (SPDEs) presents challenges due to the rapid change of their solutions at the boundary layer. In this manuscript, We propose Asymptotic Physics-Informed Neural Networks (ASPINN), a generalization of Physics-Informed Neural Networks (PINN) and General-Kindred Physics-Informed Neural Networks (GKPINN) approaches. This is a decomposition method based on the idea of asymptotic analysis. Compared to PINN, the ASPINN method has a strong fitting ability for solving SPDEs due to the placement of exponential layers at the boundary layer. Unlike GKPINN, ASPINN lessens the number of fully connected layers, thereby reducing the training cost more effectively. Moreover, ASPINN theoretically approximates the solution at the boundary layer more accurately, which accuracy is also improved compared to GKPINN. We demonstrate the effect of ASPINN by solving diverse classes of SPDEs, which clearly shows that the ASPINN method is promising in boundary layer problems. Furthermore, we introduce Chebyshev Kolmogorov-Arnold Networks (Chebyshev-KAN) instead of MLP, achieving better performance in various experiments.
<div id='section'>Paperid: <span id='pid'>1207, <a href='https://arxiv.org/pdf/2409.10911.pdf' target='_blank'>https://arxiv.org/pdf/2409.10911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Du, Haochong Li, Qi Liao, Jun Shen, Jianqin Zheng, Yongtu Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10911">A Knowledge-Inspired Hierarchical Physics-Informed Neural Network for Pipeline Hydraulic Transient Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The high-pressure transportation process of pipeline necessitates an accurate hydraulic transient simulation tool to prevent slack line flow and over-pressure, which can endanger pipeline operations. However, current numerical solution methods often face difficulties in balancing computational efficiency and accuracy. Additionally, few studies attempt to reform physics-informed learning architecture for pipeline transient simulation with magnitude different in outputs and imbalanced gradient in loss function. To address these challenges, a Knowledge-Inspired Hierarchical Physics-Informed Neural Network is proposed for hydraulic transient simulation of multi-product pipelines. The proposed model integrates governing equations, boundary conditions, and initial conditions into the training process to ensure consistency with physical laws. Furthermore, magnitude conversion of outputs and equivalent conversion of governing equations are implemented to enhance the training performance of the neural network. To further address the imbalanced gradient of multiple loss terms with fixed weights, a hierarchical training strategy is designed. Numerical simulations demonstrate that the proposed model outperforms state-of-the-art models and can still produce accurate simulation results under complex hydraulic transient conditions, with mean absolute percentage errors reduced by 87.8\% and 92.7 \% in pressure prediction. Thus, the proposed model can conduct accurate and effective hydraulic transient analysis, ensuring the safe operation of pipelines.
<div id='section'>Paperid: <span id='pid'>1208, <a href='https://arxiv.org/pdf/2409.09466.pdf' target='_blank'>https://arxiv.org/pdf/2409.09466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Victor Eeckhout, Hossein Fani, Md Umar Hashmi, Geert Deconinck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.09466">Improved Physics-Informed Neural Network based AC Power Flow for Distribution Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Power flow analysis plays a critical role in the control and operation of power systems. The high computational burden of traditional solution methods led to a shift towards data-driven approaches, exploiting the availability of digital metering data. However, data-driven approaches, such as deep learning, have not yet won the trust of operators as they are agnostic to the underlying physical model and have poor performances in regimes with limited observability. To address these challenges, this paper proposes a new, physics-informed model. More specifically, a novel physics-informed loss function is developed that can be used to train (deep) neural networks aimed at power flow simulation. The loss function is not only based on the theoretical AC power flow equations that govern the problem but also incorporates real physical line losses, resulting in higher loss accuracy and increased learning potential. The proposed model is used to train a Graph Neural Network (GNN) and is evaluated on a small 3-bus test case both against another physics-informed GNN that does not incorporate physical losses and against a model-free technique. The validation results show that the proposed model outperforms the conventional physics-informed network on all used performance metrics. Even more interesting is that the model shows strong prediction capabilities when tested on scenarios outside the training sample set, something that is a substantial deficiency of model-free techniques.
<div id='section'>Paperid: <span id='pid'>1209, <a href='https://arxiv.org/pdf/2409.08799.pdf' target='_blank'>https://arxiv.org/pdf/2409.08799.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maciej Sikora, Albert Oliver-Serra, Leszek Siwik, Natalia LeszczyÅska, Tomasz Maciej Ciesielski, Eirik Valseth, Jacek LeszczyÅski, Anna PaszyÅska, Maciej PaszyÅski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08799">Graph grammars and Physics Informed Neural Networks for simulating of pollution propagation on Spitzbergen</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present two computational methods for performing simulations of pollution propagation described by advection-diffusion equations. The first method employs graph grammars to describe the generation process of the computational mesh used in simulations with the meshless solver of the three-dimensional finite element method. The graph transformation rules express the three-dimensional Rivara longest-edge refinement algorithm. This solver is used for an exemplary application: performing three-dimensional simulations of pollution generation by the coal-burning power plant and its propagation in the city of Longyearbyen, the capital of Spitsbergen. The second computational code is based on the Physics Informed Neural Networks method. It is used to calculate the dissipation of the pollution along the valley in which the city of Longyearbyen is located. We discuss the instantiation and execution of the PINN method using Google Colab implementation. We discuss the benefits and limitations of the PINN implementation.
<div id='section'>Paperid: <span id='pid'>1210, <a href='https://arxiv.org/pdf/2409.04143.pdf' target='_blank'>https://arxiv.org/pdf/2409.04143.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thivin Anandh, Divij Ghose, Ankit Tyagi, Abhineet Gupta, Suranjan Sarkar, Sashikumaar Ganesan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.04143">An efficient hp-Variational PINNs framework for incompressible Navier-Stokes equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are able to solve partial differential equations (PDEs) by incorporating the residuals of the PDEs into their loss functions. Variational Physics-Informed Neural Networks (VPINNs) and hp-VPINNs use the variational form of the PDE residuals in their loss function. Although hp-VPINNs have shown promise over traditional PINNs, they suffer from higher training times and lack a framework capable of handling complex geometries, which limits their application to more complex PDEs. As such, hp-VPINNs have not been applied in solving the Navier-Stokes equations, amongst other problems in CFD, thus far. FastVPINNs was introduced to address these challenges by incorporating tensor-based loss computations, significantly improving the training efficiency. Moreover, by using the bilinear transformation, the FastVPINNs framework was able to solve PDEs on complex geometries. In the present work, we extend the FastVPINNs framework to vector-valued problems, with a particular focus on solving the incompressible Navier-Stokes equations for two-dimensional forward and inverse problems, including problems such as the lid-driven cavity flow, the Kovasznay flow, and flow past a backward-facing step for Reynolds numbers up to 200. Our results demonstrate a 2x improvement in training time while maintaining the same order of accuracy compared to PINNs algorithms documented in the literature. We further showcase the framework's efficiency in solving inverse problems for the incompressible Navier-Stokes equations by accurately identifying the Reynolds number of the underlying flow. Additionally, the framework's ability to handle complex geometries highlights its potential for broader applications in computational fluid dynamics. This implementation opens new avenues for research on hp-VPINNs, potentially extending their applicability to more complex problems.
<div id='section'>Paperid: <span id='pid'>1211, <a href='https://arxiv.org/pdf/2409.01536.pdf' target='_blank'>https://arxiv.org/pdf/2409.01536.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuning Lin, Yong Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01536">Causality-guided adaptive sampling method for physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Compared to purely data-driven methods, a key feature of physics-informed neural networks (PINNs) - a proven powerful tool for solving partial differential equations (PDEs) - is the embedding of PDE constraints into the loss function. The selection and distribution of collocation points for evaluating PDE residuals are critical to the performance of PINNs. Furthermore, the causal training is currently a popular training mode. In this work, we propose the causality-guided adaptive sampling (Causal AS) method for PINNs. Given the characteristics of causal training, we use the weighted PDE residuals as the indicator for the selection of collocation points to focus on areas with larger PDE residuals within the regions being trained. For the hyper-parameter $p$ involved, we develop the temporal alignment driven update (TADU) scheme for its dynamic update beyond simply fixing it as a constant. The collocation points selected at each time will be released before the next adaptive sampling step to avoid the cumulative effects caused by previously chosen collocation points and reduce computational costs. To illustrate the effectiveness of the Causal AS method, we apply it to solve time-dependent equations, including the Allen-Cahn equation, the NLS equation, the KdV equation and the mKdV equation. During the training process, we employe a time-marching technique and strictly impose the periodic boundary conditions by embedding the input coordinates into Fourier expansion to mitigate optimization challenges. Numerical results indicate that the predicted solution achieves an excellent agreement with the ground truth. Compared to a similar work, the causal extension of R3 sampling (Causal R3), our proposed Causal AS method demonstrates a significant advantage in accuracy.
<div id='section'>Paperid: <span id='pid'>1212, <a href='https://arxiv.org/pdf/2408.16553.pdf' target='_blank'>https://arxiv.org/pdf/2408.16553.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhi-Song Liu, Markus Buttner, Vadym Aizinger, Andreas Rupp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16553">Downscaling Neural Network for Coastal Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning the fine-scale details of a coastal ocean simulation from a coarse representation is a challenging task. For real-world applications, high-resolution simulations are necessary to advance understanding of many coastal processes, specifically, to predict flooding resulting from tsunamis and storm surges. We propose a Downscaling Neural Network for Coastal Simulation (DNNCS) for spatiotemporal enhancement to efficiently learn the high-resolution numerical solution. Given images of coastal simulations produced on low-resolution computational meshes using low polynomial order discontinuous Galerkin discretizations and a coarse temporal resolution, the proposed DNNCS learns to produce high-resolution free surface elevation and velocity visualizations in both time and space. To efficiently model the dynamic changes over time and space, we propose grid-aware spatiotemporal attention to project the temporal features to the spatial domain for non-local feature matching. The coordinate information is also utilized via positional encoding. For the final reconstruction, we use the spatiotemporal bilinear operation to interpolate the missing frames and then expand the feature maps to the frequency domain for residual mapping. Besides data-driven losses, the proposed physics-informed loss guarantees gradient consistency and momentum changes. Their combination contributes to the overall 24% improvements in Root Mean Square Error (RMSE). To train the proposed model, we propose a novel coastal simulation dataset and use it for model optimization and evaluation. Our method shows superior downscaling quality and fast computation compared to the state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1213, <a href='https://arxiv.org/pdf/2408.14734.pdf' target='_blank'>https://arxiv.org/pdf/2408.14734.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sen Wang, Peizhi Zhao, Qinglong Ma, Tao Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14734">General-Kindred Physics-Informed Neural Network to the Solutions of Singularly Perturbed Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have become a promising research direction in the field of solving Partial Differential Equations (PDEs). Dealing with singular perturbation problems continues to be a difficult challenge in the field of PINN. The solution of singular perturbation problems often exhibits sharp boundary layers and steep gradients, and traditional PINN cannot achieve approximation of boundary layers. In this manuscript, we propose the General-Kindred Physics-Informed Neural Network (GKPINN) for solving Singular Perturbation Differential Equations (SPDEs). This approach utilizes asymptotic analysis to acquire prior knowledge of the boundary layer from the equation and establishes a novel network to assist PINN in approximating the boundary layer. It is compared with traditional PINN by solving examples of one-dimensional, two-dimensional, and time-varying SPDE equations. The research findings underscore the exceptional performance of our novel approach, GKPINN, which delivers a remarkable enhancement in reducing the $L_2$ error by two to four orders of magnitude compared to the established PINN methodology. This significant improvement is accompanied by a substantial acceleration in convergence rates, without compromising the high precision that is critical for our applications. Furthermore, GKPINN still performs well in extreme cases with perturbation parameters of ${1\times10}^{-38}$, demonstrating its excellent generalization ability.
<div id='section'>Paperid: <span id='pid'>1214, <a href='https://arxiv.org/pdf/2408.14731.pdf' target='_blank'>https://arxiv.org/pdf/2408.14731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shoichi Koyama, Juliano G. C. Ribeiro, Tomohiko Nakamura, Natsuki Ueno, Mirco Pezzoli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14731">Physics-Informed Machine Learning For Sound Field Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The area of study concerning the estimation of spatial sound, i.e., the distribution of a physical quantity of sound such as acoustic pressure, is called sound field estimation, which is the basis for various applied technologies related to spatial audio processing. The sound field estimation problem is formulated as a function interpolation problem in machine learning in a simplified scenario. However, high estimation performance cannot be expected by simply applying general interpolation techniques that rely only on data. The physical properties of sound fields are useful a priori information, and it is considered extremely important to incorporate them into the estimation. In this article, we introduce the fundamentals of physics-informed machine learning (PIML) for sound field estimation and overview current PIML-based sound field estimation methods.
<div id='section'>Paperid: <span id='pid'>1215, <a href='https://arxiv.org/pdf/2408.12198.pdf' target='_blank'>https://arxiv.org/pdf/2408.12198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Victorita Dolean, Serge Gratton, Alexander Heinlein, Valentin Mercier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.12198">Two-level deep domain decomposition method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a two-level Deep Domain Decomposition Method (Deep-DDM) augmented with a coarse-level network for solving boundary value problems using physics-informed neural networks (PINNs). The addition of the coarse level network improves scalability and convergence rates compared to the single level method. Tested on a Poisson equation with Dirichlet boundary conditions, the two-level deep DDM demonstrates superior performance, maintaining efficient convergence regardless of the number of subdomains. This advance provides a more scalable and effective approach to solving complex partial differential equations with machine learning.
<div id='section'>Paperid: <span id='pid'>1216, <a href='https://arxiv.org/pdf/2408.09818.pdf' target='_blank'>https://arxiv.org/pdf/2408.09818.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matteo Salvador, Alison L. Marsden
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09818">Liquid Fourier Latent Dynamics Networks for fast GPU-based numerical simulations in computational cardiology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific Machine Learning (ML) is gaining momentum as a cost-effective alternative to physics-based numerical solvers in many engineering applications. In fact, scientific ML is currently being used to build accurate and efficient surrogate models starting from high-fidelity numerical simulations, effectively encoding the parameterized temporal dynamics underlying Ordinary Differential Equations (ODEs), or even the spatio-temporal behavior underlying Partial Differential Equations (PDEs), in appropriately designed neural networks. We propose an extension of Latent Dynamics Networks (LDNets), namely Liquid Fourier LDNets (LFLDNets), to create parameterized space-time surrogate models for multiscale and multiphysics sets of highly nonlinear differential equations on complex geometries. LFLDNets employ a neurologically-inspired, sparse, liquid neural network for temporal dynamics, relaxing the requirement of a numerical solver for time advancement and leading to superior performance in terms of tunable parameters, accuracy, efficiency and learned trajectories with respect to neural ODEs based on feedforward fully-connected neural networks. Furthermore, in our implementation of LFLDNets, we use a Fourier embedding with a tunable kernel in the reconstruction network to learn high-frequency functions better and faster than using space coordinates directly as input. We challenge LFLDNets in the framework of computational cardiology and evaluate their capabilities on two 3-dimensional test cases arising from multiscale cardiac electrophysiology and cardiovascular hemodynamics. This paper illustrates the capability to run Artificial Intelligence-based numerical simulations on single or multiple GPUs in a matter of minutes and represents a significant step forward in the development of physics-informed digital twins.
<div id='section'>Paperid: <span id='pid'>1217, <a href='https://arxiv.org/pdf/2408.07921.pdf' target='_blank'>https://arxiv.org/pdf/2408.07921.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Albert Lu, Yu Foon Chau, Hiu Yung Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.07921">Physics-Informed Neural Network for Predicting Out-of-Training-Range TCAD Solution with Minimized Domain Expertise</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) is promising in assisting technology computer-aided design (TCAD) simulations to alleviate difficulty in convergence and prolonged simulation time. While ML is widely used in TCAD, they either require access to the internal solver, require extensive domain expertise, are only trained by terminal quantities such as currents and voltages, and/or lack out-of-training-range prediction capability. In this paper, using Si nanowire as an example, we demonstrate that it is possible to use a physics-informed neural network (PINN) to predict out-of-training-range TCAD solutions without accessing the internal solver and with minimal domain expertise. The machine not only can predict a 2.5 times larger range than the training but also can predict the inversion region by only being trained with subthreshold region data. The physics-informed module is also trained with data without the need for human-coded equations making this easier to be extended to more sophisticated systems.
<div id='section'>Paperid: <span id='pid'>1218, <a href='https://arxiv.org/pdf/2408.07104.pdf' target='_blank'>https://arxiv.org/pdf/2408.07104.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Mohammad-Djafari, Ning Chu, Li Wang, Caifang Cai, Liang Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.07104">Model Based and Physics Informed Deep Learning Neural Network Structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Networks (NN) has been used in many areas with great success. When a NN's structure (Model) is given, during the training steps, the parameters of the model are determined using an appropriate criterion and an optimization algorithm (Training). Then, the trained model can be used for the prediction or inference step (Testing). As there are also many hyperparameters, related to the optimization criteria and optimization algorithms, a validation step is necessary before its final use. One of the great difficulties is the choice of the NN's structure. Even if there are many "on the shelf" networks, selecting or proposing a new appropriate network for a given data, signal or image processing, is still an open problem. In this work, we consider this problem using model based signal and image processing and inverse problems methods. We classify the methods in five classes, based on: i) Explicit analytical solutions, ii) Transform domain decomposition, iii) Operator Decomposition, iv) Optimization algorithms unfolding, and v) Physics Informed NN methods (PINN). Few examples in each category are explained.
<div id='section'>Paperid: <span id='pid'>1219, <a href='https://arxiv.org/pdf/2408.02662.pdf' target='_blank'>https://arxiv.org/pdf/2408.02662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ho Jae Lee, Seungwoo Hong, Sangbae Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02662">Integrating Model-Based Footstep Planning with Model-Free Reinforcement Learning for Dynamic Legged Locomotion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we introduce a control framework that combines model-based footstep planning with Reinforcement Learning (RL), leveraging desired footstep patterns derived from the Linear Inverted Pendulum (LIP) dynamics. Utilizing the LIP model, our method forward predicts robot states and determines the desired foot placement given the velocity commands. We then train an RL policy to track the foot placements without following the full reference motions derived from the LIP model. This partial guidance from the physics model allows the RL policy to integrate the predictive capabilities of the physics-informed dynamics and the adaptability characteristics of the RL controller without overfitting the policy to the template model. Our approach is validated on the MIT Humanoid, demonstrating that our policy can achieve stable yet dynamic locomotion for walking and turning. We further validate the adaptability and generalizability of our policy by extending the locomotion task to unseen, uneven terrain. During the hardware deployment, we have achieved forward walking speeds of up to 1.5 m/s on a treadmill and have successfully performed dynamic locomotion maneuvers such as 90-degree and 180-degree turns.
<div id='section'>Paperid: <span id='pid'>1220, <a href='https://arxiv.org/pdf/2407.20560.pdf' target='_blank'>https://arxiv.org/pdf/2407.20560.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhi-Yong Zhang, Jie-Ying Li, Lei-Lei Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.20560">Invariant deep neural networks under the finite group for solving partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Utilizing physics-informed neural networks (PINN) to solve partial differential equations (PDEs) becomes a hot issue and also shows its great powers, but still suffers from the dilemmas of limited predicted accuracy in the sampling domain and poor prediction ability beyond the sampling domain which are usually mitigated by adding the physical properties of PDEs into the loss function or by employing smart techniques to change the form of loss function for special PDEs. In this paper, we design a symmetry-enhanced deep neural network (sDNN) which makes the architecture of neural networks invariant under the finite group through expanding the dimensions of weight matrixes and bias vectors in each hidden layers by the order of finite group if the group has matrix representations, otherwise extending the set of input data and the hidden layers except for the first hidden layer by the order of finite group. However, the total number of training parameters is only about one over the order of finite group of the original PINN size due to the symmetric architecture of sDNN. Furthermore, we give special forms of weight matrixes and bias vectors of sDNN, and rigorously prove that the architecture itself is invariant under the finite group and the sDNN has the universal approximation ability to learn the function keeping the finite group. Numerical results show that the sDNN has strong predicted abilities in and beyond the sampling domain and performs far better than the vanilla PINN with fewer training points and simpler architecture.
<div id='section'>Paperid: <span id='pid'>1221, <a href='https://arxiv.org/pdf/2407.18373.pdf' target='_blank'>https://arxiv.org/pdf/2407.18373.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Subhajit Patra, Sonali Panda, Bikram Keshari Parida, Mahima Arya, Kurt Jacobs, Denys I. Bondar, Abhijit Sen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.18373">Physics Informed Kolmogorov-Arnold Neural Networks for Dynamical Analysis via Efficent-KAN and WAV-KAN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks have proven to be a powerful tool for solving differential equations, leveraging the principles of physics to inform the learning process. However, traditional deep neural networks often face challenges in achieving high accuracy without incurring significant computational costs. In this work, we implement the Physics-Informed Kolmogorov-Arnold Neural Networks (PIKAN) through efficient-KAN and WAV-KAN, which utilize the Kolmogorov-Arnold representation theorem. PIKAN demonstrates superior performance compared to conventional deep neural networks, achieving the same level of accuracy with fewer layers and reduced computational overhead. We explore both B-spline and wavelet-based implementations of PIKAN and benchmark their performance across various ordinary and partial differential equations using unsupervised (data-free) and supervised (data-driven) techniques. For certain differential equations, the data-free approach suffices to find accurate solutions, while in more complex scenarios, the data-driven method enhances the PIKAN's ability to converge to the correct solution. We validate our results against numerical solutions and achieve $99 \%$ accuracy in most scenarios.
<div id='section'>Paperid: <span id='pid'>1222, <a href='https://arxiv.org/pdf/2407.17611.pdf' target='_blank'>https://arxiv.org/pdf/2407.17611.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Spyros Rigas, Michalis Papachristou, Theofilos Papadopoulos, Fotios Anagnostopoulos, Georgios Alexandridis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.17611">Adaptive Training of Grid-Dependent Physics-Informed Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a robust framework for solving Partial Differential Equations (PDEs) by approximating their solutions via neural networks and imposing physics-based constraints on the loss function. Traditionally, Multilayer Perceptrons (MLPs) have been the neural network of choice, with significant progress made in optimizing their training. Recently, Kolmogorov-Arnold Networks (KANs) were introduced as a viable alternative, with the potential of offering better interpretability and efficiency while requiring fewer parameters. In this paper, we present a fast JAX-based implementation of grid-dependent Physics-Informed Kolmogorov-Arnold Networks (PIKANs) for solving PDEs, achieving up to 84 times faster training times than the original KAN implementation. We propose an adaptive training scheme for PIKANs, introducing an adaptive state transition technique to avoid loss function peaks between grid extensions, and a methodology for designing PIKANs with alternative basis functions. Through comparative experiments, we demonstrate that the adaptive features significantly enhance solution accuracy, decreasing the L^2 error relative to the reference solution by up to 43.02%. For the studied PDEs, our methodology approaches or surpasses the results obtained from architectures that utilize up to 8.5 times more parameters, highlighting the potential of adaptive, grid-dependent PIKANs as a superior alternative in scientific and engineering applications.
<div id='section'>Paperid: <span id='pid'>1223, <a href='https://arxiv.org/pdf/2407.11057.pdf' target='_blank'>https://arxiv.org/pdf/2407.11057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seungyeon Choi, Sangmin Seo, Sanghyun Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11057">SPIN: SE(3)-Invariant Physics Informed Network for Binding Affinity Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of protein-ligand binding affinity is crucial for rapid and efficient drug development. Recently, the importance of predicting binding affinity has led to increased attention on research that models the three-dimensional structure of protein-ligand complexes using graph neural networks to predict binding affinity. However, traditional methods often fail to accurately model the complex's spatial information or rely solely on geometric features, neglecting the principles of protein-ligand binding. This can lead to overfitting, resulting in models that perform poorly on independent datasets and ultimately reducing their usefulness in real drug development. To address this issue, we propose SPIN, a model designed to achieve superior generalization by incorporating various inductive biases applicable to this task, beyond merely training on empirical data from datasets. For prediction, we defined two types of inductive biases: a geometric perspective that maintains consistent binding affinity predictions regardless of the complexs rotations and translations, and a physicochemical perspective that necessitates minimal binding free energy along their reaction coordinate for effective protein-ligand binding. These prior knowledge inputs enable the SPIN to outperform comparative models in benchmark sets such as CASF-2016 and CSAR HiQ. Furthermore, we demonstrated the practicality of our model through virtual screening experiments and validated the reliability and potential of our proposed model based on experiments assessing its interpretability.
<div id='section'>Paperid: <span id='pid'>1224, <a href='https://arxiv.org/pdf/2407.09628.pdf' target='_blank'>https://arxiv.org/pdf/2407.09628.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karan Shah, Attila Cangi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.09628">Accelerating Electron Dynamics Simulations through Machine Learned Time Propagators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time-dependent density functional theory (TDDFT) is a widely used method to investigate electron dynamics under various external perturbations such as laser fields. In this work, we present a novel approach to accelerate real time TDDFT based electron dynamics simulations using autoregressive neural operators as time-propagators for the electron density. By leveraging physics-informed constraints and high-resolution training data, our model achieves superior accuracy and computational speed compared to traditional numerical solvers. We demonstrate the effectiveness of our model on a class of one-dimensional diatomic molecules. This method has potential in enabling real-time, on-the-fly modeling of laser-irradiated molecules and materials with varying experimental parameters.
<div id='section'>Paperid: <span id='pid'>1225, <a href='https://arxiv.org/pdf/2407.08134.pdf' target='_blank'>https://arxiv.org/pdf/2407.08134.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Noorizadegan, Y. C. Hon, D. L. Young, C. S. Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08134">Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Surface reconstruction from point clouds is a fundamental challenge in computer graphics and medical imaging. In this paper, we explore the application of advanced neural network architectures for the accurate and efficient reconstruction of surfaces from data points. We introduce a novel variant of the Highway network (Hw) called Square-Highway (SqrHw) within the context of multilayer perceptrons and investigate its performance alongside plain neural networks and a simplified Hw in various numerical examples. These examples include the reconstruction of simple and complex surfaces, such as spheres, human hands, and intricate models like the Stanford Bunny. We analyze the impact of factors such as the number of hidden layers, interior and exterior points, and data distribution on surface reconstruction quality. Our results show that the proposed SqrHw architecture outperforms other neural network configurations, achieving faster convergence and higher-quality surface reconstructions. Additionally, we demonstrate the SqrHw's ability to predict surfaces over missing data, a valuable feature for challenging applications like medical imaging. Furthermore, our study delves into further details, demonstrating that the proposed method based on highway networks yields more stable weight norms and backpropagation gradients compared to the Plain Network architecture. This research not only advances the field of computer graphics but also holds utility for other purposes such as function interpolation and physics-informed neural networks, which integrate multilayer perceptrons into their algorithms.
<div id='section'>Paperid: <span id='pid'>1226, <a href='https://arxiv.org/pdf/2407.07375.pdf' target='_blank'>https://arxiv.org/pdf/2407.07375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Noorizadegan, R. Cavoretto, D. L. Young, C. S. Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.07375">Stable Weight Updating: A Key to Reliable PDE Solutions Using Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Background: Deep learning techniques, particularly neural networks, have revolutionized computational physics, offering powerful tools for solving complex partial differential equations (PDEs). However, ensuring stability and efficiency remains a challenge, especially in scenarios involving nonlinear and time-dependent equations. Methodology: This paper introduces novel residual-based architectures, namely the Simple Highway Network and the Squared Residual Network, designed to enhance stability and accuracy in physics-informed neural networks (PINNs). These architectures augment traditional neural networks by incorporating residual connections, which facilitate smoother weight updates and improve backpropagation efficiency. Results: Through extensive numerical experiments across various examples including linear and nonlinear, time-dependent and independent PDEs we demonstrate the efficacy of the proposed architectures. The Squared Residual Network, in particular, exhibits robust performance, achieving enhanced stability and accuracy compared to conventional neural networks. These findings underscore the potential of residual-based architectures in advancing deep learning for PDEs and computational physics applications.
<div id='section'>Paperid: <span id='pid'>1227, <a href='https://arxiv.org/pdf/2407.06151.pdf' target='_blank'>https://arxiv.org/pdf/2407.06151.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wanyun Zhou, Xiaowen Chu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06151">Auto-PICNN: Automated machine learning for physics-informed convolutional neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in deep learning for solving partial differential equations (PDEs) have introduced physics-informed neural networks (PINNs), which integrate machine learning with physical laws. Physics-informed convolutional neural networks (PICNNs) extend PINNs by leveraging CNNs for enhanced generalization and efficiency. However, current PICNNs depend on manual design, and inappropriate designs may not effectively solve PDEs. Furthermore, due to the diversity of physical problems, the ideal network architectures and loss functions vary across different PDEs. It is impractical to find the optimal PICNN architecture and loss function for each specific physical problem through extensive manual experimentation. To surmount these challenges, this paper uses automated machine learning (AutoML) to automatically and efficiently search for the loss functions and network architectures of PICNNs. We introduce novel search spaces for loss functions and network architectures and propose a two-stage search strategy. The first stage focuses on searching for factors and residual adjustment operations that influence the loss function, while the second stage aims to find the best CNN architecture. Experimental results show that our automatic searching method significantly outperforms the manually-designed model on multiple datasets.
<div id='section'>Paperid: <span id='pid'>1228, <a href='https://arxiv.org/pdf/2407.00808.pdf' target='_blank'>https://arxiv.org/pdf/2407.00808.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Zhao, Jin Wei-Kocsis, Adel Heidari Akhijahani, Karen L Butler-Purry
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.00808">Exploring a Physics-Informed Decision Transformer for Distribution System Restoration: Methodology and Performance Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Driven by advancements in sensing and computing, deep reinforcement learning (DRL)-based methods have demonstrated significant potential in effectively tackling distribution system restoration (DSR) challenges under uncertain operational scenarios. However, the data-intensive nature of DRL poses obstacles in achieving satisfactory DSR solutions for large-scale, complex distribution systems. Inspired by the transformative impact of emerging foundation models, including large language models (LLMs), across various domains, this paper explores an innovative approach harnessing LLMs' powerful computing capabilities to address scalability challenges inherent in conventional DRL methods for solving DSR. To our knowledge, this study represents the first exploration of foundation models, including LLMs, in revolutionizing conventional DRL applications in power system operations. Our contributions are twofold: 1) introducing a novel LLM-powered Physics-Informed Decision Transformer (PIDT) framework that leverages LLMs to transform conventional DRL methods for DSR operations, and 2) conducting comparative studies to assess the performance of the proposed LLM-powered PIDT framework at its initial development stage for solving DSR problems. While our primary focus in this paper is on DSR operations, the proposed PIDT framework can be generalized to optimize sequential decision-making across various power system operations.
<div id='section'>Paperid: <span id='pid'>1229, <a href='https://arxiv.org/pdf/2406.15619.pdf' target='_blank'>https://arxiv.org/pdf/2406.15619.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sriram Nagaraj, Truman Hickok
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.15619">Physics Informed Machine Learning (PIML) methods for estimating the remaining useful lifetime (RUL) of aircraft engines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper is aimed at using the newly developing field of physics informed machine learning (PIML) to develop models for predicting the remaining useful lifetime (RUL) aircraft engines. We consider the well-known benchmark NASA Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) data as the main data for this paper, which consists of sensor outputs in a variety of different operating modes. C-MAPSS is a well-studied dataset with much existing work in the literature that address RUL prediction with classical and deep learning methods. In the absence of published empirical physical laws governing the C-MAPSS data, our approach first uses stochastic methods to estimate the governing physics models from the noisy time series data. In our approach, we model the various sensor readings as being governed by stochastic differential equations, and we estimate the corresponding transition density mean and variance functions of the underlying processes. We then augment LSTM (long-short term memory) models with the learned mean and variance functions during training and inferencing. Our PIML based approach is different from previous methods, and we use the data to first learn the physics. Our results indicate that PIML discovery and solutions methods are well suited for this problem and outperform previous data-only deep learning methods for this data set and task. Moreover, the framework developed herein is flexible, and can be adapted to other situations (other sensor modalities or combined multi-physics environments), including cases where the underlying physics is only partially observed or known.
<div id='section'>Paperid: <span id='pid'>1230, <a href='https://arxiv.org/pdf/2406.12460.pdf' target='_blank'>https://arxiv.org/pdf/2406.12460.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yong Wang, Yanzhong Yao, Zhiming Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12460">An extrapolation-driven network architecture for physics-informed deep learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current PINN implementations with sequential learning strategies often experience some weaknesses, such as the failure to reproduce the previous training results when using a single network, the difficulty to strictly ensure continuity and smoothness at the time interval nodes when using multiple networks, and the increase in complexity and computational overhead. To overcome these shortcomings, we first investigate the extrapolation capability of the PINN method for time-dependent PDEs. Taking advantage of this extrapolation property, we generalize the training result obtained in a specific time subinterval to larger intervals by adding a correction term to the network parameters of the subinterval. The correction term is determined by further training with the sample points in the added subinterval. Secondly, by designing an extrapolation control function with special characteristics and combining it with a correction term, we construct a new neural network architecture whose network parameters are coupled with the time variable, which we call the extrapolation-driven network architecture. Based on this architecture, using a single neural network, we can obtain the overall PINN solution of the whole domain with the following two characteristics: (1) it completely inherits the local solution of the interval obtained from the previous training, (2) at the interval node, it strictly maintains the continuity and smoothness that the true solution has. The extrapolation-driven network architecture allows us to divide a large time domain into multiple subintervals and solve the time-dependent PDEs one by one in a chronological order. This training scheme respects the causality principle and effectively overcomes the difficulties of the conventional PINN method in solving the evolution equation on a large time domain. Numerical experiments verify the performance of our method.
<div id='section'>Paperid: <span id='pid'>1231, <a href='https://arxiv.org/pdf/2406.03472.pdf' target='_blank'>https://arxiv.org/pdf/2406.03472.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bruno Machado Pacheco, Eduardo Camponogara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03472">Solving Differential Equations using Physics-Informed Deep Equilibrium Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces Physics-Informed Deep Equilibrium Models (PIDEQs) for solving initial value problems (IVPs) of ordinary differential equations (ODEs). Leveraging recent advancements in deep equilibrium models (DEQs) and physics-informed neural networks (PINNs), PIDEQs combine the implicit output representation of DEQs with physics-informed training techniques. We validate PIDEQs using the Van der Pol oscillator as a benchmark problem, demonstrating their efficiency and effectiveness in solving IVPs. Our analysis includes key hyperparameter considerations for optimizing PIDEQ performance. By bridging deep learning and physics-based modeling, this work advances computational techniques for solving IVPs, with implications for scientific computing and engineering applications.
<div id='section'>Paperid: <span id='pid'>1232, <a href='https://arxiv.org/pdf/2406.03407.pdf' target='_blank'>https://arxiv.org/pdf/2406.03407.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddharth Nair, Timothy F. Walsh, Greg Pickrell, Fabio Semperlotti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03407">Physics and geometry informed neural operator network with application to acoustic scattering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce a physics and geometry informed neural operator network with application to the forward simulation of acoustic scattering. The development of geometry informed deep learning models capable of learning a solution operator for different computational domains is a problem of general importance for a variety of engineering applications. To this end, we propose a physics-informed deep operator network (DeepONet) capable of predicting the scattered pressure field for arbitrarily shaped scatterers using a geometric parameterization approach based on non-uniform rational B-splines (NURBS). This approach also results in parsimonious representations of non-trivial scatterer geometries. In contrast to existing physics-based approaches that require model re-evaluation when changing the computational domains, our trained model is capable of learning solution operator that can approximate physically-consistent scattered pressure field in just a few seconds for arbitrary rigid scatterer shapes; it follows that the computational time for forward simulations can improve (i.e. be reduced) by orders of magnitude in comparison to the traditional forward solvers. In addition, this approach can evaluate the scattered pressure field without the need for labeled training data. After presenting the theoretical approach, a comprehensive numerical study is also provided to illustrate the remarkable ability of this approach to simulate the acoustic pressure fields resulting from arbitrary combinations of arbitrary scatterer geometries. These results highlight the unique generalization capability of the proposed operator learning approach.
<div id='section'>Paperid: <span id='pid'>1233, <a href='https://arxiv.org/pdf/2406.02927.pdf' target='_blank'>https://arxiv.org/pdf/2406.02927.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehdi Jabbari Zideh, Sarika Khushalani Solanki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02927">Multivariate Physics-Informed Convolutional Autoencoder for Anomaly Detection in Power Distribution Systems with High Penetration of DERs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the relentless progress of deep learning models in analyzing the system conditions under cyber-physical events, their abilities are limited in the power system domain due to data availability issues, cost of data acquisition, and lack of interpretation and extrapolation for the data beyond the training windows. In addition, the integration of distributed energy resources (DERs) such as wind and solar generations increases the complexities and nonlinear nature of power systems. Therefore, an interpretable and reliable methodology is of utmost need to increase the confidence of power system operators and their situational awareness for making reliable decisions. This has led to the development of physics-informed neural network (PINN) models as more interpretable, trustworthy, and robust models where the underlying principled laws are integrated into the training process of neural network models to achieve improved performance. This paper proposes a multivariate physics-informed convolutional autoencoder (PIConvAE) model to detect cyber anomalies in power distribution systems with unbalanced configurations and high penetration of DERs. The physical laws are integrated through a customized loss function that embeds the underlying Kirchhoff's circuit laws into the training process of the autoencoder. The performance of the multivariate PIConvAE model is evaluated on two unbalanced power distribution grids, IEEE 123-bus system and a real-world feeder in Riverside, CA. The results show the exceptional performance of the proposed method in detecting various cyber anomalies in both systems. In addition, the model's effectiveness is evaluated in data scarcity scenarios with different training data ratios. Finally, the model's performance is compared with existing machine learning models where the PIConvAE model surpasses other models with considerably higher detection metrics.
<div id='section'>Paperid: <span id='pid'>1234, <a href='https://arxiv.org/pdf/2406.02581.pdf' target='_blank'>https://arxiv.org/pdf/2406.02581.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Grant Norman, Jacqueline Wentz, Hemanth Kolla, Kurt Maute, Alireza Doostan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02581">Constrained or Unconstrained? Neural-Network-Based Equation Discovery from Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Throughout many fields, practitioners often rely on differential equations to model systems. Yet, for many applications, the theoretical derivation of such equations and/or accurate resolution of their solutions may be intractable. Instead, recently developed methods, including those based on parameter estimation, operator subset selection, and neural networks, allow for the data-driven discovery of both ordinary and partial differential equations (PDEs), on a spectrum of interpretability. The success of these strategies is often contingent upon the correct identification of representative equations from noisy observations of state variables and, as importantly and intertwined with that, the mathematical strategies utilized to enforce those equations. Specifically, the latter has been commonly addressed via unconstrained optimization strategies. Representing the PDE as a neural network, we propose to discover the PDE by solving a constrained optimization problem and using an intermediate state representation similar to a Physics-Informed Neural Network (PINN). The objective function of this constrained optimization problem promotes matching the data, while the constraints require that the PDE is satisfied at several spatial collocation points. We present a penalty method and a widely used trust-region barrier method to solve this constrained optimization problem, and we compare these methods on numerical examples. Our results on the Burgers' and the Korteweg-De Vreis equations demonstrate that the latter constrained method outperforms the penalty method, particularly for higher noise levels or fewer collocation points. For both methods, we solve these discovered neural network PDEs with classical methods, such as finite difference methods, as opposed to PINNs-type methods relying on automatic differentiation. We briefly highlight other small, yet crucial, implementation details.
<div id='section'>Paperid: <span id='pid'>1235, <a href='https://arxiv.org/pdf/2406.00001.pdf' target='_blank'>https://arxiv.org/pdf/2406.00001.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mudit Chopra, Abhinav Barnawal, Harshil Vagadia, Tamajit Banerjee, Shreshth Tuli, Souvik Chakraborty, Rohan Paul
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00001">PhyPlan: Generalizable and Rapid Physical Task Planning with Physics Informed Skill Networks for Robot Manipulators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the task of positioning a ball-like object to a goal region beyond direct reach, humans can often throw, slide, or rebound objects against the wall to attain the goal. However, enabling robots to reason similarly is non-trivial. Existing methods for physical reasoning are data-hungry and struggle with complexity and uncertainty inherent in the real world. This paper presents PhyPlan, a novel physics-informed planning framework that combines physics-informed neural networks (PINNs) with modified Monte Carlo Tree Search (MCTS) to enable embodied agents to perform dynamic physical tasks. PhyPlan leverages PINNs to simulate and predict outcomes of actions in a fast and accurate manner and uses MCTS for planning. It dynamically determines whether to consult a PINN-based simulator (coarse but fast) or engage directly with the actual environment (fine but slow) to determine optimal policy. Given an unseen task, PhyPlan can infer the sequence of actions and learn the latent parameters, resulting in a generalizable approach that can rapidly learn to perform novel physical tasks. Evaluation with robots in simulated 3D environments demonstrates the ability of our approach to solve 3D-physical reasoning tasks involving the composition of dynamic skills. Quantitatively, PhyPlan excels in several aspects: (i) it achieves lower regret when learning novel tasks compared to the state-of-the-art, (ii) it expedites skill learning and enhances the speed of physical reasoning, (iii) it demonstrates higher data efficiency compared to a physics un-informed approach.
<div id='section'>Paperid: <span id='pid'>1236, <a href='https://arxiv.org/pdf/2404.18538.pdf' target='_blank'>https://arxiv.org/pdf/2404.18538.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ye Liu, Jie-Ying Li, Li-Sheng Zhang, Lei-Lei Guo, Zhi-Yong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.18538">Symmetry group based domain decomposition to enhance physics-informed neural networks for solving partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain decomposition provides an effective way to tackle the dilemma of physics-informed neural networks (PINN) which struggle to accurately and efficiently solve partial differential equations (PDEs) in the whole domain, but the lack of efficient tools for dealing with the interfaces between two adjacent sub-domains heavily hinders the training effects, even leads to the discontinuity of the learned solutions. In this paper, we propose a symmetry group based domain decomposition strategy to enhance the PINN for solving the forward and inverse problems of the PDEs possessing a Lie symmetry group. Specifically, for the forward problem, we first deploy the symmetry group to generate the dividing-lines having known solution information which can be adjusted flexibly and are used to divide the whole training domain into a finite number of non-overlapping sub-domains, then utilize the PINN and the symmetry-enhanced PINN methods to learn the solutions in each sub-domain and finally stitch them to the overall solution of PDEs. For the inverse problem, we first utilize the symmetry group acting on the data of the initial and boundary conditions to generate labeled data in the interior domain of PDEs and then find the undetermined parameters as well as the solution by only training the neural networks in a sub-domain. Consequently, the proposed method can predict high-accuracy solutions of PDEs which are failed by the vanilla PINN in the whole domain and the extended physics-informed neural network in the same sub-domains. Numerical results of the Korteweg-de Vries equation with a translation symmetry and the nonlinear viscous fluid equation with a scaling symmetry show that the accuracies of the learned solutions are improved largely.
<div id='section'>Paperid: <span id='pid'>1237, <a href='https://arxiv.org/pdf/2404.16189.pdf' target='_blank'>https://arxiv.org/pdf/2404.16189.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Baoli Hao, Ulisses Braga-Neto, Chun Liu, Lifan Wang, Ming Zhong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.16189">Training PINNs with Hard Constraints and Adaptive Weights: An Ablation Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training Physics-Informed Neural Networks (PINNs) to solve stiff time-dependent partial differential equations (PDEs) remains a significant challenge. The main difficulties lie in precisely enforcing initial conditions and balancing the various loss components. In stiff PDEs, where solutions show rapid transitions or sharp gradients, this balance becomes especially difficult. The wide range of scales in the dynamics can cause certain losses to dominate, leading to unstable or inefficient training. This paper presents a comprehensive ablation study focused on two pivotal training schemes: the enforcement of hard constraints for initial and boundary conditions, and the implementation of adaptive weights. We specifically examine their impact on the performance of PINNs when applied to stiff time-dependent PDEs from materials science and mathematical biology applications. We conduct extensive numerical experiments across a diverse range of time-dependent PDEs from Allen-Cahn, Cahn-Hillard, to Gray-Scott systems. We further discuss the implications of our findings for improving the robustness and efficiency of PINN training, particularly in settings where accurate representation of initial conditions and balanced loss contributions are paramount.
<div id='section'>Paperid: <span id='pid'>1238, <a href='https://arxiv.org/pdf/2404.16189.pdf' target='_blank'>https://arxiv.org/pdf/2404.16189.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Baoli Hao, Ulisses Braga-Neto, Chun Liu, Lifan Wang, Ming Zhong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.16189">Stability in Training PINNs for Stiff PDEs: Why Initial Conditions Matter</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training Physics-Informed Neural Networks (PINNs) on stiff time-dependent PDEs remains highly unstable. Through rigorous ablation studies, we identify a surprisingly critical factor: the enforcement of initial conditions. We present the first systematic ablation of two core strategies, hard initial-condition constraints and adaptive loss weighting. Across challenging benchmarks (sharp transitions, higher-order derivatives, coupled systems, and high frequency modes), we find that exact enforcement of initial conditions (ICs) is not optional but essential. Our study demonstrates that stability and efficiency in PINN training fundamentally depend on ICs, paving the way toward more reliable PINN solvers in stiff regimes.
<div id='section'>Paperid: <span id='pid'>1239, <a href='https://arxiv.org/pdf/2404.12063.pdf' target='_blank'>https://arxiv.org/pdf/2404.12063.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thivin Anandh, Divij Ghose, Himanshu Jain, Sashikumaar Ganesan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.12063">FastVPINNs: Tensor-Driven Acceleration of VPINNs for Complex Geometries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Variational Physics-Informed Neural Networks (VPINNs) utilize a variational loss function to solve partial differential equations, mirroring Finite Element Analysis techniques. Traditional hp-VPINNs, while effective for high-frequency problems, are computationally intensive and scale poorly with increasing element counts, limiting their use in complex geometries. This work introduces FastVPINNs, a tensor-based advancement that significantly reduces computational overhead and improves scalability. Using optimized tensor operations, FastVPINNs achieve a 100-fold reduction in the median training time per epoch compared to traditional hp-VPINNs. With proper choice of hyperparameters, FastVPINNs surpass conventional PINNs in both speed and accuracy, especially in problems with high-frequency solutions. Demonstrated effectiveness in solving inverse problems on complex domains underscores FastVPINNs' potential for widespread application in scientific and engineering challenges, opening new avenues for practical implementations in scientific machine learning.
<div id='section'>Paperid: <span id='pid'>1240, <a href='https://arxiv.org/pdf/2404.09128.pdf' target='_blank'>https://arxiv.org/pdf/2404.09128.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junfei Wang, Pirathayini Srikantha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.09128">Data-driven AC Optimal Power Flow with Physics-informed Learning and Calibrations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The modern power grid is witnessing a shift in operations from traditional control methods to more advanced operational mechanisms. Due to the nonconvex nature of the Alternating Current Optimal Power Flow (ACOPF) problem and the need for operations with better granularity in the modern smart grid, system operators require a more efficient and reliable ACOPF solver. While data-driven ACOPF methods excel in directly inferring the optimal solution based on power grid demand, achieving both feasibility and optimality remains a challenge due to the NP-hardness of the problem. In this paper, we propose a physics-informed machine learning model and a feasibility calibration algorithm to produce solutions for the ACOPF problem. Notably, the machine learning model produces solutions with a 0.5\% and 1.4\% optimality gap for IEEE bus 14 and 118 grids, respectively. The feasibility correction algorithm converges for all test scenarios on bus 14 and achieves a 92.2% convergence rate on bus 118.
<div id='section'>Paperid: <span id='pid'>1241, <a href='https://arxiv.org/pdf/2404.05817.pdf' target='_blank'>https://arxiv.org/pdf/2404.05817.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ming Zhong, Dehao Liu, Raymundo Arroyave, Ulisses Braga-Neto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.05817">Label Propagation Training Schemes for Physics-Informed Neural Networks and Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a semi-supervised methodology for training physics-informed machine learning methods. This includes self-training of physics-informed neural networks and physics-informed Gaussian processes in isolation, and the integration of the two via co-training. We demonstrate via extensive numerical experiments how these methods can ameliorate the issue of propagating information forward in time, which is a common failure mode of physics-informed machine learning.
<div id='section'>Paperid: <span id='pid'>1242, <a href='https://arxiv.org/pdf/2404.04429.pdf' target='_blank'>https://arxiv.org/pdf/2404.04429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sina Navidi, Adam Thelen, Tingkai Li, Chao Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.04429">Physics-Informed Machine Learning for Battery Degradation Diagnostics: A Comparison of State-of-the-Art Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monitoring the health of lithium-ion batteries' internal components as they age is crucial for optimizing cell design and usage control strategies. However, quantifying component-level degradation typically involves aging many cells and destructively analyzing them throughout the aging test, limiting the scope of quantifiable degradation to the test conditions and duration. Fortunately, recent advances in physics-informed machine learning (PIML) for modeling and predicting the battery state of health demonstrate the feasibility of building models to predict the long-term degradation of a lithium-ion battery cell's major components using only short-term aging test data by leveraging physics. In this paper, we present four approaches for building physics-informed machine learning models and comprehensively compare them, considering accuracy, complexity, ease-of-implementation, and their ability to extrapolate to untested conditions. We delve into the details of each physics-informed machine learning method, providing insights specific to implementing them on small battery aging datasets. Our study utilizes long-term cycle aging data from 24 implantable-grade lithium-ion cells subjected to varying temperatures and C-rates over four years. This paper aims to facilitate the selection of an appropriate physics-informed machine learning method for predicting long-term degradation in lithium-ion batteries, using short-term aging data while also providing insights about when to choose which method for general predictive purposes.
<div id='section'>Paperid: <span id='pid'>1243, <a href='https://arxiv.org/pdf/2403.20139.pdf' target='_blank'>https://arxiv.org/pdf/2403.20139.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Miguel Vaquero, David MartÃ­n de Diego, Jorge CortÃ©s
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.20139">Designing Poisson Integrators Through Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a general method to construct Poisson integrators, i.e., integrators that preserve the underlying Poisson geometry. We assume the Poisson manifold is integrable, meaning there is a known local symplectic groupoid for which the Poisson manifold serves as the set of units. Our constructions build upon the correspondence between Poisson diffeomorphisms and Lagrangian bisections, which allows us to reformulate the design of Poisson integrators as solutions to a certain PDE (Hamilton-Jacobi). The main novelty of this work is to understand the Hamilton-Jacobi PDE as an optimization problem, whose solution can be easily approximated using machine learning related techniques. This research direction aligns with the current trend in the PDE and machine learning communities, as initiated by Physics- Informed Neural Networks, advocating for designs that combine both physical modeling (the Hamilton-Jacobi PDE) and data.
<div id='section'>Paperid: <span id='pid'>1244, <a href='https://arxiv.org/pdf/2403.18310.pdf' target='_blank'>https://arxiv.org/pdf/2403.18310.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Betim Bahtiri, Behrouz Arash, Sven Scheffler, Maximilian Jux, Raimund Rolfes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18310">A thermodynamically consistent physics-informed deep learning material model for short fiber/polymer nanocomposites</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work proposes a physics-informed deep learning (PIDL)-based constitutive model for investigating the viscoelastic-viscoplastic behavior of short fiber-reinforced nanoparticle-filled epoxies under various ambient conditions. The deep-learning model is trained to enforce thermodynamic principles, leading to a thermodynamically consistent constitutive model. To accomplish this, a long short-term memory network is combined with a feed-forward neural network to predict internal variables required for characterizing the internal dissipation of the nanocomposite materials. In addition, another feed-forward neural network is used to indicate the free-energy function, which enables defining the thermodynamic state of the entire system. The PIDL model is initially developed for the three-dimensional case by generating synthetic data from a classical constitutive model. The model is then trained by extracting the data directly from cyclic loading-unloading experimental tests. Numerical examples show that the PIDL model can accurately predict the mechanical behavior of epoxy-based nanocomposites for different volume fractions of fibers and nanoparticles under various hygrothermal conditions.
<div id='section'>Paperid: <span id='pid'>1245, <a href='https://arxiv.org/pdf/2403.14763.pdf' target='_blank'>https://arxiv.org/pdf/2403.14763.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yago Bea, Raul Jimenez, David Mateos, Shuheng Liu, Pavlos Protopapas, Pedro TarancÃ³n-Ãlvarez, Pablo Tejerina-PÃ©rez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14763">Gravitational Duals from Equations of State</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Holography relates gravitational theories in five dimensions to four-dimensional quantum field theories in flat space. Under this map, the equation of state of the field theory is encoded in the black hole solutions of the gravitational theory. Solving the five-dimensional Einstein's equations to determine the equation of state is an algorithmic, direct problem. Determining the gravitational theory that gives rise to a prescribed equation of state is a much more challenging, inverse problem. We present a novel approach to solve this problem based on physics-informed neural networks. The resulting algorithm is not only data-driven but also informed by the physics of the Einstein's equations. We successfully apply it to theories with crossovers, first- and second-order phase transitions.
<div id='section'>Paperid: <span id='pid'>1246, <a href='https://arxiv.org/pdf/2403.02536.pdf' target='_blank'>https://arxiv.org/pdf/2403.02536.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Spiridon Kasapis, Irina N. Kitiashvili, Paul Kosovich, Alexander G. Kosovichev, Viacheslav M. Sadykov, Patrick O'Keefe, Vincent Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.02536">Forecasting SEP Events During Solar Cycles 23 and 24 Using Interpretable Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prediction of the Solar Energetic Particle (SEP) events garner increasing interest as space missions extend beyond Earth's protective magnetosphere. These events, which are, in most cases, products of magnetic reconnection-driven processes during solar flares or fast coronal-mass-ejection-driven shock waves, pose significant radiation hazards to aviation, space-based electronics, and particularly, space exploration. In this work, we utilize the recently developed dataset that combines the Solar Dynamics Observatory/Helioseismic and Magnetic Imager's (SDO/HMI) Space weather HMI Active Region Patches (SHARP) and the Solar and Heliospheric Observatory/Michelson Doppler Imager's (SoHO/MDI) Space Weather MDI Active Region Patches (SMARP). We employ a suite of machine learning strategies, including Support Vector Machines (SVM) and regression models, to evaluate the predictive potential of this new data product for a forecast of post-solar flare SEP events. Our study indicates that despite the augmented volume of data, the prediction accuracy reaches 0.7 +- 0.1, which aligns with but does not exceed these published benchmarks. A linear SVM model with training and testing configurations that mimic an operational setting (positive-negative imbalance) reveals a slight increase (+ 0.04 +- 0.05) in the accuracy of a 14-hour SEP forecast compared to previous studies. This outcome emphasizes the imperative for more sophisticated, physics-informed models to better understand the underlying processes leading to SEP events.
<div id='section'>Paperid: <span id='pid'>1247, <a href='https://arxiv.org/pdf/2403.01776.pdf' target='_blank'>https://arxiv.org/pdf/2403.01776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefan Hildebrand, Sandra Klinge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01776">Hybrid data-driven and physics-informed regularized learning of cyclic plasticity with Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An extendable, efficient and explainable Machine Learning approach is proposed to represent cyclic plasticity and replace conventional material models based on the Radial Return Mapping algorithm. High accuracy and stability by means of a limited amount of training data is achieved by implementing physics-informed regularizations and the back stress information. The off-loading of the Neural Network is applied to the maximal extent. The proposed model architecture is simpler and more efficient compared to existing solutions from the literature, while representing a complete three-dimensional material model. The validation of the approach is carried out by means of surrogate data obtained with the Armstrong-Frederick kinematic hardening model. The Mean Squared Error is assumed as the loss function which stipulates several restrictions: deviatoric character of internal variables, compliance with the flow rule, the differentiation of elastic and plastic steps and the associativity of the flow rule. The latter, however, has a minor impact on the accuracy, which implies the generalizability of the model for a broad spectrum of evolution laws for internal variables. Numerical tests simulating several load cases are shown in detail and validated for accuracy and stability.
<div id='section'>Paperid: <span id='pid'>1248, <a href='https://arxiv.org/pdf/2403.01132.pdf' target='_blank'>https://arxiv.org/pdf/2403.01132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chu Wang, Jinhong Wu, Yanzhi Wang, Zhijian Zha, Qi Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01132">MPIPN: A Multi Physics-Informed PointNet for solving parametric acoustic-structure systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning is employed for solving physical systems governed by general nonlinear partial differential equations (PDEs). However, complex multi-physics systems such as acoustic-structure coupling are often described by a series of PDEs that incorporate variable physical quantities, which are referred to as parametric systems. There are lack of strategies for solving parametric systems governed by PDEs that involve explicit and implicit quantities. In this paper, a deep learning-based Multi Physics-Informed PointNet (MPIPN) is proposed for solving parametric acoustic-structure systems. First, the MPIPN induces an enhanced point-cloud architecture that encompasses explicit physical quantities and geometric features of computational domains. Then, the MPIPN extracts local and global features of the reconstructed point-cloud as parts of solving criteria of parametric systems, respectively. Besides, implicit physical quantities are embedded by encoding techniques as another part of solving criteria. Finally, all solving criteria that characterize parametric systems are amalgamated to form distinctive sequences as the input of the MPIPN, whose outputs are solutions of systems. The proposed framework is trained by adaptive physics-informed loss functions for corresponding computational domains. The framework is generalized to deal with new parametric conditions of systems. The effectiveness of the MPIPN is validated by applying it to solve steady parametric acoustic-structure coupling systems governed by the Helmholtz equations. An ablation experiment has been implemented to demonstrate the efficacy of physics-informed impact with a minority of supervised data. The proposed method yields reasonable precision across all computational domains under constant parametric conditions and changeable combinations of parametric conditions for acoustic-structure systems.
<div id='section'>Paperid: <span id='pid'>1249, <a href='https://arxiv.org/pdf/2402.15767.pdf' target='_blank'>https://arxiv.org/pdf/2402.15767.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harshil Vagadia, Mudit Chopra, Abhinav Barnawal, Tamajit Banerjee, Shreshth Tuli, Souvik Chakraborty, Rohan Paul
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.15767">PhyPlan: Compositional and Adaptive Physical Task Reasoning with Physics-Informed Skill Networks for Robot Manipulators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the task of positioning a ball-like object to a goal region beyond direct reach, humans can often throw, slide, or rebound objects against the wall to attain the goal. However, enabling robots to reason similarly is non-trivial. Existing methods for physical reasoning are data-hungry and struggle with complexity and uncertainty inherent in the real world. This paper presents PhyPlan, a novel physics-informed planning framework that combines physics-informed neural networks (PINNs) with modified Monte Carlo Tree Search (MCTS) to enable embodied agents to perform dynamic physical tasks. PhyPlan leverages PINNs to simulate and predict outcomes of actions in a fast and accurate manner and uses MCTS for planning. It dynamically determines whether to consult a PINN-based simulator (coarse but fast) or engage directly with the actual environment (fine but slow) to determine optimal policy. Evaluation with robots in simulated 3D environments demonstrates the ability of our approach to solve 3D-physical reasoning tasks involving the composition of dynamic skills. Quantitatively, PhyPlan excels in several aspects: (i) it achieves lower regret when learning novel tasks compared to state-of-the-art, (ii) it expedites skill learning and enhances the speed of physical reasoning, (iii) it demonstrates higher data efficiency compared to a physics un-informed approach.
<div id='section'>Paperid: <span id='pid'>1250, <a href='https://arxiv.org/pdf/2402.10741.pdf' target='_blank'>https://arxiv.org/pdf/2402.10741.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wensi Wu, Mitchell Daneker, Kevin T. Turner, Matthew A. Jolley, Lu Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10741">Identifying heterogeneous micromechanical properties of biological tissues via physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The heterogeneous micromechanical properties of biological tissues have profound implications across diverse medical and engineering domains. However, identifying full-field heterogeneous elastic properties of soft materials using traditional engineering approaches is fundamentally challenging due to difficulties in estimating local stress fields. Recently, there has been a growing interest in using data-driven models to learn full-field mechanical responses such as displacement and strain from experimental or synthetic data. However, research studies on inferring full-field elastic properties of materials, a more challenging problem, are scarce, particularly for large deformation, hyperelastic materials. Here, we propose a physics-informed machine learning approach to identify the elasticity map in nonlinear, large deformation hyperelastic materials. We evaluate the prediction accuracies and computational efficiency of physics-informed neural networks (PINNs) by inferring the heterogeneous elasticity maps across three materials with structural complexity that closely resemble real tissue patterns, such as brain tissue and tricuspid valve tissue. We further applied our improved architecture to three additional examples of breast cancer tissue and extended our analysis to three hyperelastic constitutive models: Neo-Hookean, Mooney Rivlin, and Gent. Our selected network architecture consistently produced highly accurate estimations of heterogeneous elasticity maps, even when there was up to 10% noise present in the training data.
<div id='section'>Paperid: <span id='pid'>1251, <a href='https://arxiv.org/pdf/2402.05067.pdf' target='_blank'>https://arxiv.org/pdf/2402.05067.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Wang, Zheng Li, Pengyu Lai, Rui Wang, Di Yang, Dewu Yang, Hui Xu, Wen-Quan Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.05067">A Novel Paradigm in Solving Multiscale Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiscale phenomena manifest across various scientific domains, presenting a ubiquitous challenge in accurately and effectively simulating multiscale dynamics in complex systems. In this paper, a novel decoupling solving paradigm is proposed through modelling large-scale dynamics independently and treating small-scale dynamics as a slaved system. A Spectral Physics-informed Neural Network (PINN) is developed to characterize the small-scale system in an efficient and accurate way, addressing the challenges posed by the representation of multiscale dynamics in neural networks. The effectiveness of the method is demonstrated through extensive numerical experiments, including one-dimensional Kuramot-Sivashinsky equation, two- and three-dimensional Navier-Stokes equations, showcasing its versatility in addressing problems of fluid dynamics. Furthermore, we also delve into the application of the proposed approach to more complex problems, including non-uniform meshes, complex geometries, large-scale data with noise, and high-dimensional small-scale dynamics. The discussions about these scenarios contribute to a comprehensive understanding of the method's capabilities and limitations. By enabling the acquisition of large-scale data with minimal computational demands, coupled with the efficient and accurate characterization of small-scale dynamics via Spectral PINN, our approach offers a valuable and promising approach for researchers seeking to tackle multiscale phenomena effectively.
<div id='section'>Paperid: <span id='pid'>1252, <a href='https://arxiv.org/pdf/2401.05629.pdf' target='_blank'>https://arxiv.org/pdf/2401.05629.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lakshmideepakreddy Manda, Shaoru Chen, Mahyar Fazlyab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05629">Learning Performance-Oriented Control Barrier Functions Under Complex Safety Constraints and Limited Actuation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Control Barrier Functions (CBFs) provide an elegant framework for constraining nonlinear control system dynamics to remain within an invariant subset of a designated safe set. However, identifying a CBF that balances performance-by maximizing the control invariant set-and accommodates complex safety constraints, especially in systems with high relative degree and actuation limits, poses a significant challenge. In this work, we introduce a novel self-supervised learning framework to comprehensively address these challenges. Our method begins with a Boolean composition of multiple state constraints that define the safe set. We first construct a smooth function whose zero superlevel set forms an inner approximation of this safe set. This function is then combined with a smooth neural network to parameterize the CBF candidate. To train the CBF and maximize the volume of the resulting control invariant set, we design a physics-informed loss function based on a Hamilton-Jacobi Partial Differential Equation (PDE). We validate the efficacy of our approach on a 2D double integrator (DI) system and a 7D fixed-wing aircraft system (F16).
<div id='section'>Paperid: <span id='pid'>1253, <a href='https://arxiv.org/pdf/2401.04986.pdf' target='_blank'>https://arxiv.org/pdf/2401.04986.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoyu Chu, Yuto Miyatake, Wenjun Cui, Shikui Wei, Daisuke Furihata
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04986">Structure-Preserving Physics-Informed Neural Networks With Energy or Lyapunov Structure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, there has been growing interest in using physics-informed neural networks (PINNs) to solve differential equations. However, the preservation of structure, such as energy and stability, in a suitable manner has yet to be established. This limitation could be a potential reason why the learning process for PINNs is not always efficient and the numerical results may suggest nonphysical behavior. Besides, there is little research on their applications on downstream tasks. To address these issues, we propose structure-preserving PINNs to improve their performance and broaden their applications for downstream tasks. Firstly, by leveraging prior knowledge about the physical system, a structure-preserving loss function is designed to assist the PINN in learning the underlying structure. Secondly, a framework that utilizes structure-preserving PINN for robust image recognition is proposed. Here, preserving the Lyapunov structure of the underlying system ensures the stability of the system. Experimental results demonstrate that the proposed method improves the numerical accuracy of PINNs for partial differential equations. Furthermore, the robustness of the model against adversarial perturbations in image data is enhanced.
<div id='section'>Paperid: <span id='pid'>1254, <a href='https://arxiv.org/pdf/2401.03643.pdf' target='_blank'>https://arxiv.org/pdf/2401.03643.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lin Qiu, Fajie Wang, Wenzhen Qu, Yan Gu, Qing-Hua Qin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.03643">Spectral integrated neural networks (SINNs) for solving forward and inverse dynamic problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a novel neural network framework, denoted as spectral integrated neural networks (SINNs), for resolving three-dimensional forward and inverse dynamic problems. In the SINNs, the spectral integration method is applied to perform temporal discretization, and then a fully connected neural network is adopted to solve resulting partial differential equations (PDEs) in the spatial domain. Specifically, spatial coordinates are employed as inputs in the network architecture, and the output layer is configured with multiple outputs, each dedicated to approximating solutions at different time instances characterized by Gaussian points used in the spectral method. By leveraging the automatic differentiation technique and spectral integration scheme, the SINNs minimize the loss function, constructed based on the governing PDEs and boundary conditions, to obtain solutions for dynamic problems. Additionally, we utilize polynomial basis functions to expand the unknown function, aiming to enhance the performance of SINNs in addressing inverse problems. The conceived framework is tested on six forward and inverse dynamic problems, involving nonlinear PDEs. Numerical results demonstrate the superior performance of SINNs over the popularly used physics-informed neural networks in terms of convergence speed, computational accuracy and efficiency. It is also noteworthy that the SINNs exhibit the capability to deliver accurate and stable solutions for long-time dynamic problems.
<div id='section'>Paperid: <span id='pid'>1255, <a href='https://arxiv.org/pdf/2401.01783.pdf' target='_blank'>https://arxiv.org/pdf/2401.01783.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeyoung Kim, Myungjoo Kang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01783">Approximating Numerical Fluxes Using Fourier Neural Operators for Hyperbolic Conservation Laws</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditionally, classical numerical schemes have been employed to solve partial differential equations (PDEs) using computational methods. Recently, neural network-based methods have emerged. Despite these advancements, neural network-based methods, such as physics-informed neural networks (PINNs) and neural operators, exhibit deficiencies in robustness and generalization. To address these issues, numerous studies have integrated classical numerical frameworks with machine learning techniques, incorporating neural networks into parts of traditional numerical methods. In this study, we focus on hyperbolic conservation laws by replacing traditional numerical fluxes with neural operators. To this end, we developed loss functions inspired by established numerical schemes related to conservation laws and approximated numerical fluxes using Fourier neural operators (FNOs). Our experiments demonstrated that our approach combines the strengths of both traditional numerical schemes and FNOs, outperforming standard FNO methods in several respects. For instance, we demonstrate that our method is robust, has resolution invariance, and is feasible as a data-driven method. In particular, our method can make continuous predictions over time and exhibits superior generalization capabilities with out-of-distribution (OOD) samples, which are challenges that existing neural operator methods encounter.
<div id='section'>Paperid: <span id='pid'>1256, <a href='https://arxiv.org/pdf/2312.14608.pdf' target='_blank'>https://arxiv.org/pdf/2312.14608.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siqi Chen, Bin Shan, Ye Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.14608">Efficient Discrete Physics-informed Neural Networks for Addressing Evolutionary Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have shown promising potential for solving partial differential equations (PDEs) using deep learning. However, PINNs face training difficulties for evolutionary PDEs, particularly for dynamical systems whose solutions exhibit multi-scale or turbulent behavior over time. The reason is that PINNs may violate the temporal causality property since all the temporal features in the PINNs loss are trained simultaneously. This paper proposes to use implicit time differencing schemes to enforce temporal causality, and use transfer learning to sequentially update the PINNs in space as surrogates for PDE solutions in different time frames. The evolving PINNs are better able to capture the varying complexities of the evolutionary equations, while only requiring minor updates between adjacent time frames. Our method is theoretically proven to be convergent if the time step is small and each PINN in different time frames is well-trained. In addition, we provide state-of-the-art (SOTA) numerical results for a variety of benchmarks for which existing PINNs formulations may fail or be inefficient. We demonstrate that the proposed method improves the accuracy of PINNs approximation for evolutionary PDEs and improves efficiency by a factor of 4-40x.
<div id='section'>Paperid: <span id='pid'>1257, <a href='https://arxiv.org/pdf/2312.10243.pdf' target='_blank'>https://arxiv.org/pdf/2312.10243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tyler E. Maltba, Hongli Zhao, D. Adrian Maldonado
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10243">Data-driven Closures & Assimilation for Stiff Multiscale Random Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a data-driven and physics-informed framework for propagating uncertainty in stiff, multiscale random ordinary differential equations (RODEs) driven by correlated (colored) noise. Unlike systems subjected to Gaussian white noise, a deterministic equation for the joint probability density function (PDF) of RODE state variables does not exist in closed form. Moreover, such an equation would require as many phase-space variables as there are states in the RODE system. To alleviate this curse of dimensionality, we instead derive exact, albeit unclosed, reduced-order PDF (RoPDF) equations for low-dimensional observables/quantities of interest. The unclosed terms take the form of state-dependent conditional expectations, which are directly estimated from data at sparse observation times. However, for systems exhibiting stiff, multiscale dynamics, data sparsity introduces regression discrepancies that compound during RoPDF evolution. This is overcome by introducing a kinetic-like defect term to the RoPDF equation, which is learned by assimilating in sparse, low-fidelity RoPDF estimates. Two assimilation methods are considered, namely nudging and deep neural networks, which are successfully tested against Monte Carlo simulations.
<div id='section'>Paperid: <span id='pid'>1258, <a href='https://arxiv.org/pdf/2312.07003.pdf' target='_blank'>https://arxiv.org/pdf/2312.07003.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianyi Li, Alexander Halatsis, Raphael Stern
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.07003">RACER: Rational Artificial Intelligence Car-following-model Enhanced by Reality</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces RACER, the Rational Artificial Intelligence Car-following model Enhanced by Reality, a cutting-edge deep learning car-following model, that satisfies partial derivative constraints, designed to predict Adaptive Cruise Control (ACC) driving behavior while staying theoretically feasible. Unlike conventional models, RACER effectively integrates Rational Driving Constraints (RDCs), crucial tenets of actual driving, resulting in strikingly accurate and realistic predictions. Against established models like the Optimal Velocity Relative Velocity (OVRV), a car-following Neural Network (NN), and a car-following Physics-Informed Neural Network (PINN), RACER excels across key metrics, such as acceleration, velocity, and spacing. Notably, it displays a perfect adherence to the RDCs, registering zero violations, in stark contrast to other models. This study highlights the immense value of incorporating physical constraints within AI models, especially for augmenting safety measures in transportation. It also paves the way for future research to test these models against human driving data, with the potential to guide safer and more rational driving behavior. The versatility of the proposed model, including its potential to incorporate additional derivative constraints and broader architectural applications, enhances its appeal and broadens its impact within the scientific community.
<div id='section'>Paperid: <span id='pid'>1259, <a href='https://arxiv.org/pdf/2312.06715.pdf' target='_blank'>https://arxiv.org/pdf/2312.06715.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuning Lin, Yong Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.06715">The improved backward compatible physics-informed neural networks for reducing error accumulation and applications in data-driven higher-order rogue waves</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the dynamic characteristics of instantaneity and steepness, employing domain decomposition techniques for simulating rogue wave solutions is highly appropriate. Wherein, the backward compatible PINN (bc-PINN) is a temporally sequential scheme to solve PDEs over successive time segments while satisfying all previously obtained solutions. In this work, we propose improvements to the original bc-PINN algorithm in two aspects based on the characteristics of error propagation. One is to modify the loss term for ensuring backward compatibility by selecting the earliest learned solution for each sub-domain as pseudo reference solution. The other is to adopt the concatenation of solutions obtained from individual subnetworks as the final form of the predicted solution. The improved backward compatible PINN (Ibc-PINN) is applied to study data-driven higher-order rogue waves for the nonlinear SchrÃ¶dinger (NLS) equation and the AB system to demonstrate the effectiveness and advantages. Transfer learning and initial condition guided learning (ICGL) techniques are also utilized to accelerate the training. Moreover, the error analysis is conducted on each sub-domain and it turns out that the slowdown of Ibc-PINN in error accumulation speed can yield greater advantages in accuracy. In short, numerical results fully indicate that Ibc-PINN significantly outperforms bc-PINN in terms of accuracy and stability without sacrificing efficiency.
<div id='section'>Paperid: <span id='pid'>1260, <a href='https://arxiv.org/pdf/2312.04758.pdf' target='_blank'>https://arxiv.org/pdf/2312.04758.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehdi Jabbari Zideh, Sarika Khushalani Solanki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.04758">Physics-Informed Convolutional Autoencoder for Cyber Anomaly Detection in Power Distribution Grids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing trend toward the modernization of power distribution systems has facilitated the installation of advanced measurement units and promotion of the cyber communication systems. However, these infrastructures are still prone to stealth cyber attacks. The existing data-driven anomaly detection methods suffer from a lack of knowledge about the system's physics, lack of interpretability, and scalability issues hindering their practical applications in real-world scenarios. To address these concerns, physics-informed neural networks (PINNs) were introduced. This paper proposes a multivariate physics-informed convolutional autoencoder (PIConvAE) to detect stealthy cyber-attacks in power distribution grids. The proposed model integrates the physical principles into the loss function of the neural network by applying Kirchhoff's law. Simulations are performed on the modified IEEE 13-bus and 123-bus systems using OpenDSS software to validate the efficacy of the proposed model for stealth attacks. The numerical results prove the superior performance of the proposed PIConvAE in three aspects: a) it provides more accurate results compared to the data-driven ConvAE model, b) it requires less training time to converge c) the model excels in effectively detecting a wide range of attack magnitudes making it powerful in detecting stealth attacks.
<div id='section'>Paperid: <span id='pid'>1261, <a href='https://arxiv.org/pdf/2311.16410.pdf' target='_blank'>https://arxiv.org/pdf/2311.16410.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianshu Wen, Kookjin Lee, Youngsoo Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16410">Reduced-order modeling for parameterized PDEs via implicit neural representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a new data-driven reduced-order modeling approach to efficiently solve parametrized partial differential equations (PDEs) for many-query problems. This work is inspired by the concept of implicit neural representation (INR), which models physics signals in a continuous manner and independent of spatial/temporal discretization. The proposed framework encodes PDE and utilizes a parametrized neural ODE (PNODE) to learn latent dynamics characterized by multiple PDE parameters. PNODE can be inferred by a hypernetwork to reduce the potential difficulties in learning PNODE due to a complex multilayer perceptron (MLP). The framework uses an INR to decode the latent dynamics and reconstruct accurate PDE solutions. Further, a physics-informed loss is also introduced to correct the prediction of unseen parameter instances. Incorporating the physics-informed loss also enables the model to be fine-tuned in an unsupervised manner on unseen PDE parameters. A numerical experiment is performed on a two-dimensional Burgers equation with a large variation of PDE parameters. We evaluate the proposed method at a large Reynolds number and obtain up to speedup of O(10^3) and ~1% relative error to the ground truth values.
<div id='section'>Paperid: <span id='pid'>1262, <a href='https://arxiv.org/pdf/2311.16374.pdf' target='_blank'>https://arxiv.org/pdf/2311.16374.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuichi Kajiura, Jorge Espin, Dong Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16374">Physics-Informed Neural Network for Discovering Systems with Unmeasurable States with Application to Lithium-Ion Batteries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Combining machine learning with physics is a trending approach for discovering unknown dynamics, and one of the most intensively studied frameworks is the physics-informed neural network (PINN). However, PINN often fails to optimize the network due to its difficulty in concurrently minimizing multiple losses originating from the system's governing equations. This problem can be more serious when the system's states are unmeasurable, like lithium-ion batteries (LiBs). In this work, we introduce a robust method for training PINN that uses fewer loss terms and thus constructs a less complex landscape for optimization. In particular, instead of having loss terms from each differential equation, this method embeds the dynamics into a loss function that quantifies the error between observed and predicted system outputs. This is accomplished by numerically integrating the predicted states from the neural network(NN) using known dynamics and transforming them to obtain a sequence of predicted outputs. Minimizing such a loss optimizes the NN to predict states consistent with observations given the physics. Further, the system's parameters can be added to the optimization targets. To demonstrate the ability of this method to perform various modeling and control tasks, we apply it to a battery model to concurrently estimate its states and parameters.
<div id='section'>Paperid: <span id='pid'>1263, <a href='https://arxiv.org/pdf/2311.15216.pdf' target='_blank'>https://arxiv.org/pdf/2311.15216.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingtao Qin, Nanpeng Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.15216">Solve Large-scale Unit Commitment Problems by Physics-informed Graph Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unit commitment (UC) problems are typically formulated as mixed-integer programs (MIP) and solved by the branch-and-bound (B&B) scheme. The recent advances in graph neural networks (GNN) enable it to enhance the B&B algorithm in modern MIP solvers by learning to dive and branch. Existing GNN models that tackle MIP problems are mostly constructed from mathematical formulation, which is computationally expensive when dealing with large-scale UC problems. In this paper, we propose a physics-informed hierarchical graph convolutional network (PI-GCN) for neural diving that leverages the underlying features of various components of power systems to find high-quality variable assignments. Furthermore, we adopt the MIP model-based graph convolutional network (MB-GCN) for neural branching to select the optimal variables for branching at each node of the B&B tree. Finally, we integrate neural diving and neural branching into a modern MIP solver to establish a novel neural MIP solver designed for large-scale UC problems. Numeral studies show that PI-GCN has better performance and scalability than the baseline MB-GCN on neural diving. Moreover, the neural MIP solver yields the lowest operational cost and outperforms a modern MIP solver for all testing days after combining it with our proposed neural diving model and the baseline neural branching model.
<div id='section'>Paperid: <span id='pid'>1264, <a href='https://arxiv.org/pdf/2311.12947.pdf' target='_blank'>https://arxiv.org/pdf/2311.12947.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ren Wang, Ming Zhong, Kaidi Xu, Lola GirÃ¡ldez SÃ¡nchez-CortÃ©s, Ignacio de Cominges Guerra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12947">PINNs-Based Uncertainty Quantification for Transient Stability Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the challenge of transient stability in power systems with missing parameters and uncertainty propagation in swing equations. We introduce a novel application of Physics-Informed Neural Networks (PINNs), specifically an Ensemble of PINNs (E-PINNs), to estimate critical parameters like rotor angle and inertia coefficient with enhanced accuracy and reduced computational load. E-PINNs capitalize on the underlying physical principles of swing equations to provide a robust solution. Our approach not only facilitates efficient parameter estimation but also quantifies uncertainties, delivering probabilistic insights into the system behavior. The efficacy of E-PINNs is demonstrated through the analysis of $1$-bus and $2$-bus systems, highlighting the model's ability to handle parameter variability and data scarcity. The study advances the application of machine learning in power system stability, paving the way for reliable and computationally efficient transient stability analysis.
<div id='section'>Paperid: <span id='pid'>1265, <a href='https://arxiv.org/pdf/2311.10456.pdf' target='_blank'>https://arxiv.org/pdf/2311.10456.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harshil Patel, Aniruddha Panda, Tymofii Nikolaienko, Stanislav Jaso, Alejandro Lopez, Kaushic Kalyanaraman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.10456">Accurate and Fast Fischer-Tropsch Reaction Microkinetics using PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Microkinetics allows detailed modelling of chemical transformations occurring in many industrially relevant reactions. Traditional way of solving the microkinetics model for Fischer-Tropsch synthesis (FTS) becomes inefficient when it comes to more advanced real-time applications. In this work, we address these challenges by using physics-informed neural networks(PINNs) for modelling FTS microkinetics. We propose a computationally efficient and accurate method, enabling the ultra-fast solution of the existing microkinetics models in realistic process conditions. The proposed PINN model computes the fraction of vacant catalytic sites, a key quantity in FTS microkinetics, with median relative error (MRE) of 0.03%, and the FTS product formation rates with MRE of 0.1%. Compared to conventional equation solvers, the model achieves up to 1E+06 times speed-up when running on GPUs, thus being fast enough for multi-scale and multi-physics reactor modelling and enabling its applications in real-time process control and optimization.
<div id='section'>Paperid: <span id='pid'>1266, <a href='https://arxiv.org/pdf/2311.07613.pdf' target='_blank'>https://arxiv.org/pdf/2311.07613.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mason Ma, Jiajie Wu, Chase Post, Tony Shi, Jingang Yi, Tony Schmitz, Hong Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.07613">A Physics-informed Machine Learning-based Control Method for Nonlinear Dynamic Systems with Highly Noisy Measurements</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a physics-informed machine learning-based control method for nonlinear dynamic systems with highly noisy measurements. Existing data-driven control methods that use machine learning for system identification cannot effectively cope with highly noisy measurements, resulting in unstable control performance. To address this challenge, the present study extends current physics-informed machine learning capabilities for modeling nonlinear dynamics with control and integrates them into a model predictive control framework. To demonstrate the capability of the proposed method we test and validate with two noisy nonlinear dynamic systems: the chaotic Lorenz 3 system, and turning machine tool. Analysis of the results illustrate that the proposed method outperforms state-of-the-art benchmarks as measured by both modeling accuracy and control performance for nonlinear dynamic systems under high-noise conditions.
<div id='section'>Paperid: <span id='pid'>1267, <a href='https://arxiv.org/pdf/2311.00529.pdf' target='_blank'>https://arxiv.org/pdf/2311.00529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marius Zeinhofer, Rami Masri, Kent-AndrÃ© Mardal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.00529">A Unified Framework for the Error Analysis of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We prove a priori and a posteriori error estimates for physics-informed neural networks (PINNs) for linear PDEs. We analyze elliptic equations in primal and mixed form, elasticity, parabolic, hyperbolic and Stokes equations; and a PDE constrained optimization problem. For the analysis, we propose an abstract framework in the common language of bilinear forms, and we show that coercivity and continuity lead to error estimates. The obtained estimates are sharp and reveal that the $L^2$ penalty approach for initial and boundary conditions in the PINN formulation weakens the norm of the error decay. Finally, utilizing recent advances in PINN optimization, we present numerical examples that illustrate the ability of the method to achieve accurate solutions.
<div id='section'>Paperid: <span id='pid'>1268, <a href='https://arxiv.org/pdf/2310.05169.pdf' target='_blank'>https://arxiv.org/pdf/2310.05169.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dibyakanti Kumar, Anirbit Mukherjee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05169">Investigating the Ability of PINNs To Solve Burgers' PDE Near Finite-Time BlowUp</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics Informed Neural Networks (PINNs) have been achieving ever newer feats of solving complicated PDEs numerically while offering an attractive trade-off between accuracy and speed of inference. A particularly challenging aspect of PDEs is that there exist simple PDEs which can evolve into singular solutions in finite time starting from smooth initial conditions. In recent times some striking experiments have suggested that PINNs might be good at even detecting such finite-time blow-ups. In this work, we embark on a program to investigate this stability of PINNs from a rigorous theoretical viewpoint. Firstly, we derive generalization bounds for PINNs for Burgers' PDE, in arbitrary dimensions, under conditions that allow for a finite-time blow-up. Then we demonstrate via experiments that our bounds are significantly correlated to the $\ell_2$-distance of the neurally found surrogate from the true blow-up solution, when computed on sequences of PDEs that are getting increasingly close to a blow-up.
<div id='section'>Paperid: <span id='pid'>1269, <a href='https://arxiv.org/pdf/2310.03049.pdf' target='_blank'>https://arxiv.org/pdf/2310.03049.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hasindu Kariyawasam, Ramith Hettiarachchi, Quansan Yang, Alex Matlock, Takahiro Nambara, Hiroyuki Kusaka, Yuichiro Kunai, Peter T C So, Edward S Boyden, Dushan Wadduwage
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03049">QuATON: Quantization Aware Training of Optical Neurons</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optical processors, built with "optical neurons", can efficiently perform high-dimensional linear operations at the speed of light. Thus they are a promising avenue to accelerate large-scale linear computations. With the current advances in micro-fabrication, such optical processors can now be 3D fabricated, but with a limited precision. This limitation translates to quantization of learnable parameters in optical neurons, and should be handled during the design of the optical processor in order to avoid a model mismatch. Specifically, optical neurons should be trained or designed within the physical-constraints at a predefined quantized precision level. To address this critical issues we propose a physics-informed quantization-aware training framework. Our approach accounts for physical constraints during the training process, leading to robust designs. We demonstrate that our approach can design state of the art optical processors using diffractive networks for multiple physics based tasks despite quantized learnable parameters. We thus lay the foundation upon which improved optical processors may be 3D fabricated in the future.
<div id='section'>Paperid: <span id='pid'>1270, <a href='https://arxiv.org/pdf/2310.03001.pdf' target='_blank'>https://arxiv.org/pdf/2310.03001.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felipe de Castro Teixeira Carvalho, Kamaljyoti Nath, Alberto Luiz Serpa, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03001">Learning characteristic parameters and dynamics of centrifugal pumps under multiphase flow using physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electrical submersible pumps (ESPs) are prevalently utilized as artificial lift systems in the oil and gas industry. These pumps frequently encounter multiphase flows comprising a complex mixture of hydrocarbons, water, and sediments. Such mixtures lead to the formation of emulsions, characterized by an effective viscosity distinct from that of the individual phases. Traditional multiphase flow meters, employed to assess these conditions, are burdened by high operational costs and susceptibility to degradation. To this end, this study introduces a physics-informed neural network (PINN) model designed to indirectly estimate the fluid properties, dynamic states, and crucial parameters of an ESP system. A comprehensive structural and practical identifiability analysis was performed to delineate the subset of parameters that can be reliably estimated through the use of intake and discharge pressure measurements from the pump. The efficacy of the PINN model was validated by estimating the unknown states and parameters using these pressure measurements as input data. Furthermore, the performance of the PINN model was benchmarked against the particle filter method utilizing both simulated and experimental data across varying water content scenarios. The comparative analysis suggests that the PINN model holds significant potential as a viable alternative to conventional multiphase flow meters, offering a promising avenue for enhancing operational efficiency and reducing costs in ESP applications.
<div id='section'>Paperid: <span id='pid'>1271, <a href='https://arxiv.org/pdf/2309.15294.pdf' target='_blank'>https://arxiv.org/pdf/2309.15294.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong Shen Wong, Wei Xuan Chan, Bing Huan Li, Choon Hwai Yap
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.15294">Multiple Case Physics-Informed Neural Network for Biomedical Tube Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fluid dynamics computations for tube-like geometries are important for biomedical evaluation of vascular and airway fluid dynamics. Physics-Informed Neural Networks (PINNs) have recently emerged as a good alternative to traditional computational fluid dynamics (CFD) methods. The vanilla PINN, however, requires much longer training time than the traditional CFD methods for each specific flow scenario and thus does not justify its mainstream use. Here, we explore the use of the multi-case PINN approach for calculating biomedical tube flows, where varied geometry cases are parameterized and pre-trained on the PINN, such that results for unseen geometries can be obtained in real time. Our objective is to identify network architecture, tube-specific, and regularization strategies that can optimize this, via experiments on a series of idealized 2D stenotic tube flows.
<div id='section'>Paperid: <span id='pid'>1272, <a href='https://arxiv.org/pdf/2309.05863.pdf' target='_blank'>https://arxiv.org/pdf/2309.05863.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Shi, Shuhao Ma, Yihui Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.05863">The bionic neural network for external simulation of human locomotor system</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Muscle forces and joint kinematics estimated with musculoskeletal (MSK) modeling techniques offer useful metrics describing movement quality. Model-based computational MSK models can interpret the dynamic interaction between the neural drive to muscles, muscle dynamics, body and joint kinematics, and kinetics. Still, such a set of solutions suffers from high computational time and muscle recruitment problems, especially in complex modeling. In recent years, data-driven methods have emerged as a promising alternative due to the benefits of flexibility and adaptability. However, a large amount of labeled training data is not easy to be acquired. This paper proposes a physics-informed deep learning method based on MSK modeling to predict joint motion and muscle forces. The MSK model is embedded into the neural network as an ordinary differential equation (ODE) loss function with physiological parameters of muscle activation dynamics and muscle contraction dynamics to be identified. These parameters are automatically estimated during the training process which guides the prediction of muscle forces combined with the MSK forward dynamics model. Experimental validations on two groups of data, including one benchmark dataset and one self-collected dataset from six healthy subjects, are performed. The results demonstrate that the proposed deep learning method can effectively identify subject-specific MSK physiological parameters and the trained physics-informed forward-dynamics surrogate yields accurate motion and muscle forces predictions.
<div id='section'>Paperid: <span id='pid'>1273, <a href='https://arxiv.org/pdf/2309.04434.pdf' target='_blank'>https://arxiv.org/pdf/2309.04434.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Antonio Ferrer-SÃ¡nchez, Carlos Flores-Garrigos, Carlos Hernani-Morales, JosÃ© J. OrquÃ­n-MarquÃ©s, Narendra N. Hegade, Alejandro Gomez Cadavid, Iraitz Montalban, Enrique Solano, Yolanda Vives-Gilabert, JosÃ© D. MartÃ­n-Guerrero
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.04434">Physics-Informed Neural Networks for an optimal counterdiabatic quantum computation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel methodology that leverages the strength of Physics-Informed Neural Networks (PINNs) to address the counterdiabatic (CD) protocol in the optimization of quantum circuits comprised of systems with $N_{Q}$ qubits. The primary objective is to utilize physics-inspired deep learning techniques to accurately solve the time evolution of the different physical observables within the quantum system. To accomplish this objective, we embed the necessary physical information into an underlying neural network to effectively tackle the problem. In particular, we impose the hermiticity condition on all physical observables and make use of the principle of least action, guaranteeing the acquisition of the most appropriate counterdiabatic terms based on the underlying physics. The proposed approach offers a dependable alternative to address the CD driving problem, free from the constraints typically encountered in previous methodologies relying on classical numerical approximations. Our method provides a general framework to obtain optimal results from the physical observables relevant to the problem, including the external parameterization in time known as scheduling function, the gauge potential or operator involving the non-adiabatic terms, as well as the temporal evolution of the energy levels of the system, among others. The main applications of this methodology have been the $\mathrm{H_{2}}$ and $\mathrm{LiH}$ molecules, represented by a 2-qubit and 4-qubit systems employing the STO-3G basis. The presented results demonstrate the successful derivation of a desirable decomposition for the non-adiabatic terms, achieved through a linear combination utilizing Pauli operators. This attribute confers significant advantages to its practical implementation within quantum computing algorithms.
<div id='section'>Paperid: <span id='pid'>1274, <a href='https://arxiv.org/pdf/2309.03374.pdf' target='_blank'>https://arxiv.org/pdf/2309.03374.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saakaar Bhatnagar, Andrew Comerford, Araz Banaeizadeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.03374">Physics Informed Neural Networks for Modeling of 3D Flow-Thermal Problems with Sparse Domain Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Successfully training Physics Informed Neural Networks (PINNs) for highly nonlinear PDEs on complex 3D domains remains a challenging task. In this paper, PINNs are employed to solve the 3D incompressible Navier-Stokes (NS) equations at moderate to high Reynolds numbers for complex geometries. The presented method utilizes very sparsely distributed solution data in the domain. A detailed investigation on the effect of the amount of supplied data and the PDE-based regularizers is presented. Additionally, a hybrid data-PINNs approach is used to generate a surrogate model of a realistic flow-thermal electronics design problem. This surrogate model provides near real-time sampling and was found to outperform standard data-driven neural networks when tested on unseen query points. The findings of the paper show how PINNs can be effective when used in conjunction with sparse data for solving 3D nonlinear PDEs or for surrogate modeling of design spaces governed by them.
<div id='section'>Paperid: <span id='pid'>1275, <a href='https://arxiv.org/pdf/2309.02615.pdf' target='_blank'>https://arxiv.org/pdf/2309.02615.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bryan Shaddy, Deep Ray, Angel Farguell, Valentina Calaza, Jan Mandel, James Haley, Kyle Hilburn, Derek V. Mallia, Adam Kochanski, Assad Oberai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02615">Generative Algorithms for Fusion of Physics-Based Wildfire Spread Models with Satellite Data for Initializing Wildfire Forecasts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Increases in wildfire activity and the resulting impacts have prompted the development of high-resolution wildfire behavior models for forecasting fire spread. Recent progress in using satellites to detect fire locations further provides the opportunity to use measurements to improve fire spread forecasts from numerical models through data assimilation. This work develops a method for inferring the history of a wildfire from satellite measurements, providing the necessary information to initialize coupled atmosphere-wildfire models from a measured wildfire state in a physics-informed approach. The fire arrival time, which is the time the fire reaches a given spatial location, acts as a succinct representation of the history of a wildfire. In this work, a conditional Wasserstein Generative Adversarial Network (cWGAN), trained with WRF-SFIRE simulations, is used to infer the fire arrival time from satellite active fire data. The cWGAN is used to produce samples of likely fire arrival times from the conditional distribution of arrival times given satellite active fire detections. Samples produced by the cWGAN are further used to assess the uncertainty of predictions. The cWGAN is tested on four California wildfires occurring between 2020 and 2022, and predictions for fire extent are compared against high resolution airborne infrared measurements. Further, the predicted ignition times are compared with reported ignition times. An average Sorensen's coefficient of 0.81 for the fire perimeters and an average ignition time error of 32 minutes suggest that the method is highly accurate.
<div id='section'>Paperid: <span id='pid'>1276, <a href='https://arxiv.org/pdf/2309.02446.pdf' target='_blank'>https://arxiv.org/pdf/2309.02446.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jihong Wang, Xin Wang, Jing Li, Bin Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02446">Data Generation-based Operator Learning for Solving Partial Differential Equations on Unbounded Domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wave propagation problems are typically formulated as partial differential equations (PDEs) on unbounded domains to be solved. The classical approach to solving such problems involves truncating them to problems on bounded domains by designing the artificial boundary conditions or perfectly matched layers, which typically require significant effort, and the presence of nonlinearity in the equation makes such designs even more challenging. Emerging deep learning-based methods for solving PDEs, with the physics-informed neural networks (PINNs) method as a representative, still face significant challenges when directly used to solve PDEs on unbounded domains. Calculations performed in a bounded domain of interest without imposing boundary constraints can lead to a lack of unique solutions thus causing the failure of PINNs. In light of this, this paper proposes a novel and effective operator learning-based method for solving PDEs on unbounded domains. The key idea behind this method is to generate high-quality training data. Specifically, we construct a family of approximate analytical solutions to the target PDE based on its initial condition and source term. Then, using these constructed data comprising exact solutions, initial conditions, and source terms, we train an operator learning model called MIONet, which is capable of handling multiple inputs, to learn the mapping from the initial condition and source term to the PDE solution on a bounded domain of interest. Finally, we utilize the generalization ability of this model to predict the solution of the target PDE. The effectiveness of this method is exemplified by solving the wave equation and the Schrodinger equation defined on unbounded domains. More importantly, the proposed method can deal with nonlinear problems, which has been demonstrated by solving Burger's equation and Korteweg-de Vries (KdV) equation.
<div id='section'>Paperid: <span id='pid'>1277, <a href='https://arxiv.org/pdf/2308.16910.pdf' target='_blank'>https://arxiv.org/pdf/2308.16910.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sergio Rojas, PaweÅ Maczuga, Judit MuÃ±oz-Matute, David Pardo, Maciej Paszynski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16910">Robust Variational Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a Robust version of the Variational Physics-Informed Neural Networks method (RVPINNs). As in VPINNs, we define the quadratic loss functional in terms of a Petrov-Galerkin-type variational formulation of the PDE problem: the trial space is a (Deep) Neural Network (DNN) manifold, while the test space is a finite-dimensional vector space. Whereas the VPINN's loss depends upon the selected basis functions of a given test space, herein, we minimize a loss based on the discrete dual norm of the residual. The main advantage of such a loss definition is that it provides a reliable and efficient estimator of the true error in the energy norm under the assumption of the existence of a local Fortin operator. We test the performance and robustness of our algorithm in several advection-diffusion problems. These numerical results perfectly align with our theoretical findings, showing that our estimates are sharp.
<div id='section'>Paperid: <span id='pid'>1278, <a href='https://arxiv.org/pdf/2308.14258.pdf' target='_blank'>https://arxiv.org/pdf/2308.14258.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arthur Feeney, Zitong Li, Ramin Bostanabad, Aparna Chandramowlishwaran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.14258">Breaking Boundaries: Distributed Domain Decomposition with Scalable Physics-Informed Neural PDE Solvers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mosaic Flow is a novel domain decomposition method designed to scale physics-informed neural PDE solvers to large domains. Its unique approach leverages pre-trained networks on small domains to solve partial differential equations on large domains purely through inference, resulting in high reusability. This paper presents an end-to-end parallelization of Mosaic Flow, combining data parallel training and domain parallelism for inference on large-scale problems. By optimizing the network architecture and data parallel training, we significantly reduce the training time for learning the Laplacian operator to minutes on 32 GPUs. Moreover, our distributed domain decomposition algorithm enables scalable inferences for solving the Laplace equation on domains 4096 times larger than the training domain, demonstrating strong scaling while maintaining accuracy on 32 GPUs. The reusability of Mosaic Flow, combined with the improved performance achieved through the distributed-memory algorithms, makes it a promising tool for modeling complex physical phenomena and accelerating scientific discovery.
<div id='section'>Paperid: <span id='pid'>1279, <a href='https://arxiv.org/pdf/2308.11818.pdf' target='_blank'>https://arxiv.org/pdf/2308.11818.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Archie J. Huang, Animesh Biswas, Shaurya Agarwal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.11818">Incorporating Nonlocal Traffic Flow Model in Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This research contributes to the advancement of traffic state estimation methods by leveraging the benefits of the nonlocal LWR model within a physics-informed deep learning framework. The classical LWR model, while useful, falls short of accurately representing real-world traffic flows. The nonlocal LWR model addresses this limitation by considering the speed as a weighted mean of the downstream traffic density. In this paper, we propose a novel PIDL framework that incorporates the nonlocal LWR model. We introduce both fixed-length and variable-length kernels and develop the required mathematics. The proposed PIDL framework undergoes a comprehensive evaluation, including various convolutional kernels and look-ahead windows, using data from the NGSIM and CitySim datasets. The results demonstrate improvements over the baseline PIDL approach using the local LWR model. The findings highlight the potential of the proposed approach to enhance the accuracy and reliability of traffic state estimation, enabling more effective traffic management strategies.
<div id='section'>Paperid: <span id='pid'>1280, <a href='https://arxiv.org/pdf/2308.11503.pdf' target='_blank'>https://arxiv.org/pdf/2308.11503.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziad Aldirany, RÃ©gis Cottereau, Marc Laforest, Serge Prudhomme
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.11503">Multi-level Neural Networks for Accurate Solutions of Boundary-Value Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The solution to partial differential equations using deep learning approaches has shown promising results for several classes of initial and boundary-value problems. However, their ability to surpass, particularly in terms of accuracy, classical discretization methods such as the finite element methods, remains a significant challenge. Deep learning methods usually struggle to reliably decrease the error in their approximate solution. A new methodology to better control the error for deep learning methods is presented here. The main idea consists in computing an initial approximation to the problem using a simple neural network and in estimating, in an iterative manner, a correction by solving the problem for the residual error with a new network of increasing complexity. This sequential reduction of the residual of the partial differential equation allows one to decrease the solution error, which, in some cases, can be reduced to machine precision. The underlying explanation is that the method is able to capture at each level smaller scales of the solution using a new network. Numerical examples in 1D and 2D are presented to demonstrate the effectiveness of the proposed approach. This approach applies not only to physics informed neural networks but to other neural network solvers based on weak or strong formulations of the residual.
<div id='section'>Paperid: <span id='pid'>1281, <a href='https://arxiv.org/pdf/2308.07051.pdf' target='_blank'>https://arxiv.org/pdf/2308.07051.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bilal Thonnam Thodi, Sai Venkata Ramana Ambadipudi, Saif Eddin Jabari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07051">Fourier neural operator for learning solutions to macroscopic traffic flow models: Application to the forward and inverse problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning methods are emerging as popular computational tools for solving forward and inverse problems in traffic flow. In this paper, we study a neural operator framework for learning solutions to nonlinear hyperbolic partial differential equations with applications in macroscopic traffic flow models. In this framework, an operator is trained to map heterogeneous and sparse traffic input data to the complete macroscopic traffic state in a supervised learning setting. We chose a physics-informed Fourier neural operator ($Ï$-FNO) as the operator, where an additional physics loss based on a discrete conservation law regularizes the problem during training to improve the shock predictions. We also propose to use training data generated from random piecewise constant input data to systematically capture the shock and rarefied solutions. From experiments using the LWR traffic flow model, we found superior accuracy in predicting the density dynamics of a ring-road network and urban signalized road. We also found that the operator can be trained using simple traffic density dynamics, e.g., consisting of $2-3$ vehicle queues and $1-2$ traffic signal cycles, and it can predict density dynamics for heterogeneous vehicle queue distributions and multiple traffic signal cycles $(\geq 2)$ with an acceptable error. The extrapolation error grew sub-linearly with input complexity for a proper choice of the model architecture and training data. Adding a physics regularizer aided in learning long-term traffic density dynamics, especially for problems with periodic boundary data.
<div id='section'>Paperid: <span id='pid'>1282, <a href='https://arxiv.org/pdf/2308.06709.pdf' target='_blank'>https://arxiv.org/pdf/2308.06709.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ming-Chih Lai, Yongcun Song, Xiaoming Yuan, Hangrui Yue, Tianyou Zeng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06709">The Hard-Constraint PINNs for Interface Optimal Control Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We show that the physics-informed neural networks (PINNs), in combination with some recently developed discontinuity capturing neural networks, can be applied to solve optimal control problems subject to partial differential equations (PDEs) with interfaces and some control constraints. The resulting algorithm is mesh-free and scalable to different PDEs, and it ensures the control constraints rigorously. Since the boundary and interface conditions, as well as the PDEs, are all treated as soft constraints by lumping them into a weighted loss function, it is necessary to learn them simultaneously and there is no guarantee that the boundary and interface conditions can be satisfied exactly. This immediately causes difficulties in tuning the weights in the corresponding loss function and training the neural networks. To tackle these difficulties and guarantee the numerical accuracy, we propose to impose the boundary and interface conditions as hard constraints in PINNs by developing a novel neural network architecture. The resulting hard-constraint PINNs approach guarantees that both the boundary and interface conditions can be satisfied exactly or with a high degree of accuracy, and they are decoupled from the learning of the PDEs. Its efficiency is promisingly validated by some elliptic and parabolic interface optimal control problems.
<div id='section'>Paperid: <span id='pid'>1283, <a href='https://arxiv.org/pdf/2308.06672.pdf' target='_blank'>https://arxiv.org/pdf/2308.06672.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yong Wang, Yanzhong Yao, Jiawei Guo, Zhiming Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06672">A practical PINN framework for multi-scale problems with multi-magnitude loss terms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For multi-scale problems, the conventional physics-informed neural networks (PINNs) face some challenges in obtaining available predictions. In this paper, based on PINNs, we propose a practical deep learning framework for multi-scale problems by reconstructing the loss function and associating it with special neural network architectures. New PINN methods derived from the improved PINN framework differ from the conventional PINN method mainly in two aspects. First, the new methods use a novel loss function by modifying the standard loss function through a (grouping) regularization strategy. The regularization strategy implements a different power operation on each loss term so that all loss terms composing the loss function are of approximately the same order of magnitude, which makes all loss terms be optimized synchronously during the optimization process. Second, for the multi-frequency or high-frequency problems, in addition to using the modified loss function, new methods upgrade the neural network architecture from the common fully-connected neural network to special network architectures such as the Fourier feature architecture, and the integrated architecture developed by us. The combination of the above two techniques leads to a significant improvement in the computational accuracy of multi-scale problems. Several challenging numerical examples demonstrate the effectiveness of the proposed methods. The proposed methods not only significantly outperform the conventional PINN method in terms of computational efficiency and computational accuracy, but also compare favorably with the state-of-the-art methods in the recent literature. The improved PINN framework facilitates better application of PINNs to multi-scale problems.
<div id='section'>Paperid: <span id='pid'>1284, <a href='https://arxiv.org/pdf/2308.05650.pdf' target='_blank'>https://arxiv.org/pdf/2308.05650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shi Jin, Zheng Ma, Tian-ai Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.05650">Asymptotic-preserving neural networks for multiscale Vlasov-Poisson-Fokker-Planck system in the high-field regime</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Vlasov-Poisson-Fokker-Planck (VPFP) system is a fundamental model in plasma physics that describes the Brownian motion of a large ensemble of particles within a surrounding bath. Under the high-field scaling, both collision and field are dominant. This paper introduces two Asymptotic-Preserving Neural Network (APNN) methods within a physics-informed neural network (PINN) framework for solving the VPFP system in the high-field regime. These methods aim to overcome the computational challenges posed by high dimensionality and multiple scales of the system. The first APNN method leverages the micro-macro decomposition model of the original VPFP system, while the second is based on the mass conservation law. Both methods ensure that the loss function of the neural networks transitions naturally from the kinetic model to the high-field limit model, thereby preserving the correct asymptotic behavior. Through extensive numerical experiments, these APNN methods demonstrate their effectiveness in solving multiscale and high dimensional uncertain problems, as well as their broader applicability for problems with long time duration and non-equilibrium initial data.
<div id='section'>Paperid: <span id='pid'>1285, <a href='https://arxiv.org/pdf/2307.11289.pdf' target='_blank'>https://arxiv.org/pdf/2307.11289.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruisong Gao, Yufeng Wang, Min Yang, Chuanjun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.11289">PI-VEGAN: Physics Informed Variational Embedding Generative Adversarial Networks for Stochastic Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a new category of physics-informed neural networks called physics informed variational embedding generative adversarial network (PI-VEGAN), that effectively tackles the forward, inverse, and mixed problems of stochastic differential equations. In these scenarios, the governing equations are known, but only a limited number of sensor measurements of the system parameters are available. We integrate the governing physical laws into PI-VEGAN with automatic differentiation, while introducing a variational encoder for approximating the latent variables of the actual distribution of the measurements. These latent variables are integrated into the generator to facilitate accurate learning of the characteristics of the stochastic partial equations. Our model consists of three components, namely the encoder, generator, and discriminator, each of which is updated alternatively employing the stochastic gradient descent algorithm. We evaluate the effectiveness of PI-VEGAN in addressing forward, inverse, and mixed problems that require the concurrent calculation of system parameters and solutions. Numerical results demonstrate that the proposed method achieves satisfactory stability and accuracy in comparison with the previous physics-informed generative adversarial network (PI-WGAN).
<div id='section'>Paperid: <span id='pid'>1286, <a href='https://arxiv.org/pdf/2307.10521.pdf' target='_blank'>https://arxiv.org/pdf/2307.10521.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenzhen Qu, Yan Gu, Shengdong Zhao, Fajie wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.10521">Boundary integrated neural networks (BINNs) for acoustic radiation and scattering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel approach called the boundary integrated neural networks (BINNs) for analyzing acoustic radiation and scattering. The method introduces fundamental solutions of the time-harmonic wave equation to encode the boundary integral equations (BIEs) within the neural networks, replacing the conventional use of the governing equation in physics-informed neural networks (PINNs). This approach offers several advantages. Firstly, the input data for the neural networks in the BINNs only require the coordinates of "boundary" collocation points, making it highly suitable for analyzing acoustic fields in unbounded domains. Secondly, the loss function of the BINNs is not a composite form, and has a fast convergence. Thirdly, the BINNs achieve comparable precision to the PINNs using fewer collocation points and hidden layers/neurons. Finally, the semi-analytic characteristic of the BIEs contributes to the higher precision of the BINNs. Numerical examples are presented to demonstrate the performance of the proposed method.
<div id='section'>Paperid: <span id='pid'>1287, <a href='https://arxiv.org/pdf/2307.08934.pdf' target='_blank'>https://arxiv.org/pdf/2307.08934.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongji Wang, Ching-Yao Lai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.08934">Multi-stage Neural Networks: Function Approximator of Machine Precision</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning techniques are increasingly applied to scientific problems, where the precision of networks is crucial. Despite being deemed as universal function approximators, neural networks, in practice, struggle to reduce the prediction errors below $O(10^{-5})$ even with large network size and extended training iterations. To address this issue, we developed the multi-stage neural networks that divides the training process into different stages, with each stage using a new network that is optimized to fit the residue from the previous stage. Across successive stages, the residue magnitudes decreases substantially and follows an inverse power-law relationship with the residue frequencies. The multi-stage neural networks effectively mitigate the spectral biases associated with regular neural networks, enabling them to capture the high frequency feature of target functions. We demonstrate that the prediction error from the multi-stage training for both regression problems and physics-informed neural networks can nearly reach the machine-precision $O(10^{-16})$ of double-floating point within a finite number of iterations. Such levels of accuracy are rarely attainable using single neural networks alone.
<div id='section'>Paperid: <span id='pid'>1288, <a href='https://arxiv.org/pdf/2307.05361.pdf' target='_blank'>https://arxiv.org/pdf/2307.05361.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Shi, Shuhao Ma, Yihui Zhao, Zhiqiang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.05361">A Physics-Informed Low-Shot Learning For sEMG-Based Estimation of Muscle Force and Joint Kinematics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Muscle force and joint kinematics estimation from surface electromyography (sEMG) are essential for real-time biomechanical analysis of the dynamic interplay among neural muscle stimulation, muscle dynamics, and kinetics. Recent advances in deep neural networks (DNNs) have shown the potential to improve biomechanical analysis in a fully automated and reproducible manner. However, the small sample nature and physical interpretability of biomechanical analysis limit the applications of DNNs. This paper presents a novel physics-informed low-shot learning method for sEMG-based estimation of muscle force and joint kinematics. This method seamlessly integrates Lagrange's equation of motion and inverse dynamic muscle model into the generative adversarial network (GAN) framework for structured feature decoding and extrapolated estimation from the small sample data. Specifically, Lagrange's equation of motion is introduced into the generative model to restrain the structured decoding of the high-level features following the laws of physics. And a physics-informed policy gradient is designed to improve the adversarial learning efficiency by rewarding the consistent physical representation of the extrapolated estimations and the physical references. Experimental validations are conducted on two scenarios (i.e. the walking trials and wrist motion trials). Results indicate that the estimations of the muscle forces and joint kinematics are unbiased compared to the physics-based inverse dynamics, which outperforms the selected benchmark methods, including physics-informed convolution neural network (PI-CNN), vallina generative adversarial network (GAN), and multi-layer extreme learning machine (ML-ELM).
<div id='section'>Paperid: <span id='pid'>1289, <a href='https://arxiv.org/pdf/2307.04301.pdf' target='_blank'>https://arxiv.org/pdf/2307.04301.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adnan Eghtesad, Jan Niklas Fuhg, Nikolaos Bouklas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.04301">NN-EVP: A physics informed neural network-based elasto-viscoplastic framework for predictions of grain size-aware flow response under large deformations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a physics informed, neural network-based elasto-viscoplasticity (NN-EVP) constitutive modeling framework for predicting the flow response in metals as a function of underlying grain size. The developed NN-EVP algorithm is based on input convex neural networks as a means to strictly enforce thermodynamic consistency, while allowing high expressivity towards model discovery from limited data. It utilizes state-of-the-art machine learning tools within PyTorch's high-performance library providing a flexible tool for data-driven, automated constitutive modeling. To test the performance of the framework, we generate synthetic stress-strain curves using a power law-based model with phenomenological hardening at small strains and test the trained model for strain amplitudes beyond the training data. Next, experimentally measured flow responses obtained from uniaxial deformations are used to train the framework under large plastic deformations. Ultimately, the Hall-Petch relationship corresponding to grain size strengthening is discovered by training flow response as a function of grain size, also leading to efficient extrapolation. The present work demonstrates a successful integration of neural networks into elasto-viscoplastic constitutive laws, providing a robust automated framework for constitutive model discovery that can efficiently generalize, while also providing insights into predictions of flow response and grain size-property relationships in metals and metallic alloys under large plastic deformations.
<div id='section'>Paperid: <span id='pid'>1290, <a href='https://arxiv.org/pdf/2307.03920.pdf' target='_blank'>https://arxiv.org/pdf/2307.03920.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bo Wang, A. K. Qin, Sajjad Shafiei, Hussein Dia, Adriana-Simona Mihaita, Hanna Grzybowska
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.03920">Training Physics-Informed Neural Networks via Multi-Task Optimization for Traffic Density Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are a newly emerging research frontier in machine learning, which incorporate certain physical laws that govern a given data set, e.g., those described by partial differential equations (PDEs), into the training of the neural network (NN) based on such a data set. In PINNs, the NN acts as the solution approximator for the PDE while the PDE acts as the prior knowledge to guide the NN training, leading to the desired generalization performance of the NN when facing the limited availability of training data. However, training PINNs is a non-trivial task largely due to the complexity of the loss composed of both NN and physical law parts. In this work, we propose a new PINN training framework based on the multi-task optimization (MTO) paradigm. Under this framework, multiple auxiliary tasks are created and solved together with the given (main) task, where the useful knowledge from solving one task is transferred in an adaptive mode to assist in solving some other tasks, aiming to uplift the performance of solving the main task. We implement the proposed framework and apply it to train the PINN for addressing the traffic density prediction problem. Experimental results demonstrate that our proposed training framework leads to significant performance improvement in comparison to the traditional way of training the PINN.
<div id='section'>Paperid: <span id='pid'>1291, <a href='https://arxiv.org/pdf/2306.13345.pdf' target='_blank'>https://arxiv.org/pdf/2306.13345.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Olga Klimanova, Timofei Miryashkin, Alexander Shapeev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13345">Accurate melting point prediction through autonomous physics-informed learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present an algorithm for computing melting points by autonomously learning from coexistence simulations in the NPT ensemble. Given the interatomic interaction model, the method makes decisions regarding the number of atoms and temperature at which to conduct simulations, and based on the collected data predicts the melting point along with the uncertainty, which can be systematically improved with more data. We demonstrate how incorporating physical models of the solid-liquid coexistence evolution enhances the algorithm's accuracy and enables optimal decision-making to effectively reduce predictive uncertainty. To validate our approach, we compare the results of 20 melting point calculations from the literature to the results of our calculations, all conducted with same interatomic potentials. Remarkably, we observe significant deviations in about one-third of the cases, underscoring the need for accurate and reliable algorithms for materials property calculations.
<div id='section'>Paperid: <span id='pid'>1292, <a href='https://arxiv.org/pdf/2306.03786.pdf' target='_blank'>https://arxiv.org/pdf/2306.03786.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuheng Liu, Xiyue Huang, Pavlos Protopapas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03786">Residual-based error bound for physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks are universal approximators and are studied for their use in solving differential equations. However, a major criticism is the lack of error bounds for obtained solutions. This paper proposes a technique to rigorously evaluate the error bound of Physics-Informed Neural Networks (PINNs) on most linear ordinary differential equations (ODEs), certain nonlinear ODEs, and first-order linear partial differential equations (PDEs). The error bound is based purely on equation structure and residual information and does not depend on assumptions of how well the networks are trained. We propose algorithms that bound the error efficiently. Some proposed algorithms provide tighter bounds than others at the cost of longer run time.
<div id='section'>Paperid: <span id='pid'>1293, <a href='https://arxiv.org/pdf/2305.14477.pdf' target='_blank'>https://arxiv.org/pdf/2305.14477.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Serge Gratton, Valentin Mercier, Elisa Riccietti, Philippe L. Toint
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.14477">A Block-Coordinate Approach of Multi-level Optimization with an Application to Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-level methods are widely used for the solution of large-scale problems, because of their computational advantages and exploitation of the complementarity between the involved sub-problems. After a re-interpretation of multi-level methods from a block-coordinate point of view, we propose a multi-level algorithm for the solution of nonlinear optimization problems and analyze its evaluation complexity. We apply it to the solution of partial differential equations using physics-informed neural networks (PINNs) and show on a few test problems that the approach results in better solutions and significant computational savings
<div id='section'>Paperid: <span id='pid'>1294, <a href='https://arxiv.org/pdf/2305.09125.pdf' target='_blank'>https://arxiv.org/pdf/2305.09125.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanzhong Yao, Jiawei Guo, Tongxiang Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09125">A deep learning method for multi-material diffusion problems based on physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the facts of the extensiveness of multi-material diffusion problems and the inability of the standard PINN(Physics-Informed Neural Networks) method for such problems, in this paper we present a novel PINN method that can accurately solve the multi-material diffusion equation. The new method applies continuity conditions at the material interface derived from the property of the diffusion equation, and combines the distinctive spatial separation strategy and the loss term normalization strategy to solve the problem that the residual points cannot be arranged at the material interface, the problem that it is difficult to express non-smooth functions with a single neural network, and the problem that the neural network is difficult to optimize the loss function with different magnitudes of loss terms, which finally provides the available prediction function for a class of multi-material diffusion problems. Numerical experiments verify the robustness and effectiveness of the new method.
<div id='section'>Paperid: <span id='pid'>1295, <a href='https://arxiv.org/pdf/2305.09017.pdf' target='_blank'>https://arxiv.org/pdf/2305.09017.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thomas Beckers, Jacob Seidman, Paris Perdikaris, George J. Pappas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09017">Gaussian Process Port-Hamiltonian Systems: Bayesian Learning with Physics Prior</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven approaches achieve remarkable results for the modeling of complex dynamics based on collected data. However, these models often neglect basic physical principles which determine the behavior of any real-world system. This omission is unfavorable in two ways: The models are not as data-efficient as they could be by incorporating physical prior knowledge, and the model itself might not be physically correct. We propose Gaussian Process Port-Hamiltonian systems (GP-PHS) as a physics-informed Bayesian learning approach with uncertainty quantification. The Bayesian nature of GP-PHS uses collected data to form a distribution over all possible Hamiltonians instead of a single point estimate. Due to the underlying physics model, a GP-PHS generates passive systems with respect to designated inputs and outputs. Further, the proposed approach preserves the compositional nature of Port-Hamiltonian systems.
<div id='section'>Paperid: <span id='pid'>1296, <a href='https://arxiv.org/pdf/2305.08310.pdf' target='_blank'>https://arxiv.org/pdf/2305.08310.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuning Lin, Yong Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.08310">Gradient-enhanced physics-informed neural networks based on transfer learning for inverse problems of the variable coefficient differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose gradient-enhanced PINNs based on transfer learning (TL-gPINNs) for inverse problems of the function coefficient discovery in order to overcome deficiency of the discrete characterization of the PDE loss in neural networks and improve accuracy of function feature description, which offers a new angle of view for gPINNs. The TL-gPINN algorithm is applied to infer the unknown variable coefficients of various forms (the polynomial, trigonometric function, hyperbolic function and fractional polynomial) and multiple variable coefficients simultaneously with abundant soliton solutions for the well-known variable coefficient nonlinear SchrÃ¶odinger equation. Compared with the PINN and gPINN, TL-gPINN yields considerable improvement in accuracy. Moreover, our method leverages the advantage of the transfer learning technique, which can help to mitigate the problem of inefficiency caused by extra loss terms of the gradient. Numerical results fully demonstrate the effectiveness of the TL-gPINN method in significant accuracy enhancement, and it also outperforms gPINN in efficiency even when the training data was corrupted with different levels of noise or hyper-parameters of neural networks are arbitrarily changed.
<div id='section'>Paperid: <span id='pid'>1297, <a href='https://arxiv.org/pdf/2305.06000.pdf' target='_blank'>https://arxiv.org/pdf/2305.06000.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Deqing Jiang, Justin Sirignano, Samuel N. Cohen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.06000">Global Convergence of Deep Galerkin and PINNs Methods for Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Numerically solving high-dimensional partial differential equations (PDEs) is a major challenge. Conventional methods, such as finite difference methods, are unable to solve high-dimensional PDEs due to the curse-of-dimensionality. A variety of deep learning methods have been recently developed to try and solve high-dimensional PDEs by approximating the solution using a neural network. In this paper, we prove global convergence for one of the commonly-used deep learning algorithms for solving PDEs, the Deep Galerkin Method (DGM). DGM trains a neural network approximator to solve the PDE using stochastic gradient descent. We prove that, as the number of hidden units in the single-layer network goes to infinity (i.e., in the ``wide network limit"), the trained neural network converges to the solution of an infinite-dimensional linear ordinary differential equation (ODE). The PDE residual of the limiting approximator converges to zero as the training time $\rightarrow \infty$. Under mild assumptions, this convergence also implies that the neural network approximator converges to the solution of the PDE. A closely related class of deep learning methods for PDEs is Physics Informed Neural Networks (PINNs). Using the same mathematical techniques, we can prove a similar global convergence result for the PINN neural network approximators. Both proofs require analyzing a kernel function in the limit ODE governing the evolution of the limit neural network approximator. A key technical challenge is that the kernel function, which is a composition of the PDE operator and the neural tangent kernel (NTK) operator, lacks a spectral gap, therefore requiring a careful analysis of its properties.
<div id='section'>Paperid: <span id='pid'>1298, <a href='https://arxiv.org/pdf/2305.05375.pdf' target='_blank'>https://arxiv.org/pdf/2305.05375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyue Liu, Pablo Borja, Cosimo Della Santina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.05375">Physics-informed Neural Networks to Model and Control Robots: a Theoretical and Experimental Investigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work concerns the application of physics-informed neural networks to the modeling and control of complex robotic systems. Achieving this goal required extending Physics Informed Neural Networks to handle non-conservative effects. We propose to combine these learned models with model-based controllers originally developed with first-principle models in mind. By combining standard and new techniques, we can achieve precise control performance while proving theoretical stability bounds. These validations include real-world experiments of motion prediction with a soft robot and of trajectory tracking with a Franka Emika manipulator.
<div id='section'>Paperid: <span id='pid'>1299, <a href='https://arxiv.org/pdf/2304.12541.pdf' target='_blank'>https://arxiv.org/pdf/2304.12541.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaofei Guan, Xintong Wang, Hao Wu, Zihao Yang, Peng Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.12541">Efficient Bayesian inference using physics-informed invertible neural networks for inverse problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce an innovative approach for addressing Bayesian inverse problems through the utilization of physics-informed invertible neural networks (PI-INN). The PI-INN framework encompasses two sub-networks: an invertible neural network (INN) and a neural basis network (NB-Net). The primary role of the NB-Net lies in modeling the spatial basis functions characterizing the solution to the forward problem dictated by the underlying partial differential equation. Simultaneously, the INN is designed to partition the parameter vector linked to the input physical field into two distinct components: the expansion coefficients representing the forward problem solution and the Gaussian latent noise. If the forward mapping is precisely estimated, and the statistical independence between expansion coefficients and latent noise is well-maintained, the PI-INN offers a precise and efficient generative model for Bayesian inverse problems, yielding tractable posterior density estimates. As a particular physics-informed deep learning model, the primary training challenge for PI-INN centers on enforcing the independence constraint, which we tackle by introducing a novel independence loss based on estimated density. We support the efficacy and precision of the proposed PI-INN through a series of numerical experiments, including inverse kinematics, 1-dimensional and 2-dimensional diffusion equations, and seismic traveltime tomography. Specifically, our experimental results showcase the superior performance of the proposed independence loss in comparison to the commonly used but computationally demanding kernel-based maximum mean discrepancy loss.
<div id='section'>Paperid: <span id='pid'>1300, <a href='https://arxiv.org/pdf/2304.10242.pdf' target='_blank'>https://arxiv.org/pdf/2304.10242.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fanny Lehmann, Filippo Gatti, MichaÃ«l Bertin, Didier Clouteau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10242">Fourier Neural Operator Surrogate Model to Predict 3D Seismic Waves Propagation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the recent rise of neural operators, scientific machine learning offers new solutions to quantify uncertainties associated with high-fidelity numerical simulations. Traditional neural networks, such as Convolutional Neural Networks (CNN) or Physics-Informed Neural Networks (PINN), are restricted to the prediction of solutions in a predefined configuration. With neural operators, one can learn the general solution of Partial Differential Equations, such as the elastic wave equation, with varying parameters. There have been very few applications of neural operators in seismology. All of them were limited to two-dimensional settings, although the importance of three-dimensional (3D) effects is well known.
  In this work, we apply the Fourier Neural Operator (FNO) to predict ground motion time series from a 3D geological description. We used a high-fidelity simulation code, SEM3D, to build an extensive database of ground motions generated by 30,000 different geologies. With this database, we show that the FNO can produce accurate ground motion even when the underlying geology exhibits large heterogeneities. Intensity measures at moderate and large periods are especially well reproduced.
  We present the first seismological application of Fourier Neural Operators in 3D. Thanks to the generalizability of our database, we believe that our model can be used to assess the influence of geological features such as sedimentary basins on ground motion, which is paramount to evaluating site effects.
<div id='section'>Paperid: <span id='pid'>1301, <a href='https://arxiv.org/pdf/2304.09835.pdf' target='_blank'>https://arxiv.org/pdf/2304.09835.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Letzgus, Klaus-Robert MÃ¼ller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.09835">An XAI framework for robust and transparent data-driven wind turbine power curve models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wind turbine power curve models translate ambient conditions into turbine power output. They are essential for energy yield prediction and turbine performance monitoring. In recent years, increasingly complex machine learning methods have become state-of-the-art for this task. Nevertheless, they frequently encounter criticism due to their apparent lack of transparency, which raises concerns regarding their performance in non-stationary environments, such as those faced by wind turbines. We, therefore, introduce an explainable artificial intelligence (XAI) framework to investigate and validate strategies learned by data-driven power curve models from operational wind turbine data. With the help of simple, physics-informed baseline models it enables an automated evaluation of machine learning models beyond standard error metrics. Alongside this novel tool, we present its efficacy for a more informed model selection. We show, for instance, that learned strategies can be meaningful indicators for a model's generalization ability in addition to test set errors, especially when only little data is available. Moreover, the approach facilitates an understanding of how decisions along the machine learning pipeline, such as data selection, pre-processing, or training parameters, affect learned strategies. In a practical example, we demonstrate the framework's utilisation to obtain more physically meaningful models, a prerequisite not only for robustness but also for insights into turbine operation by domain experts. The latter, we demonstrate in the context of wind turbine performance monitoring. Alongside this paper, we publish a Python implementation of the presented framework and hope this can guide researchers and practitioners alike toward training, selecting and utilizing more transparent and robust data-driven wind turbine power curve models.
<div id='section'>Paperid: <span id='pid'>1302, <a href='https://arxiv.org/pdf/2304.06727.pdf' target='_blank'>https://arxiv.org/pdf/2304.06727.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shimiao Li, Amritanshu Pandey, Larry Pileggi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06727">Contingency Analyses with Warm Starter using Probabilistic Graphical Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cyberthreats are an increasingly common risk to the power grid and can thwart secure grid operations. We propose to extend contingency analysis to include cyberthreat evaluations. However, unlike the traditional N-1 or N-2 contingencies, cyberthreats (e.g., MadIoT) require simulating hard-to-solve N-k (with k >> 2) contingencies in a practical amount of time. Purely physics-based power flow solvers, while being accurate, are slow and may not solve N-k contingencies in a timely manner, whereas the emerging data-driven alternatives are fast but not sufficiently generalizable, interpretable, and scalable. To address these challenges, we propose a novel conditional Gaussian Random Field-based data-driven method that performs fast and accurate evaluation of cyberthreats. It achieves speedup of contingency analysis by warm-starting simulations, i.e., improving starting points, for the physical solvers. To improve the physical interpretability and generalizability, the proposed method incorporates domain knowledge by considering the graphical nature of the grid topology. To improve scalability, the method applies physics-informed regularization that reduces model complexity. Experiments validate that simulating MadIoT-induced attacks with our warm starter becomes approximately 5x faster on a realistic 2000-bus system.
<div id='section'>Paperid: <span id='pid'>1303, <a href='https://arxiv.org/pdf/2304.04000.pdf' target='_blank'>https://arxiv.org/pdf/2304.04000.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maximilian Kleissl, Lukas Drews, Benedict B. Heyder, Julian Zabbarov, Pascal Iversen, Simon Witzke, Bernhard Y. Renard, Katharina Baum
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04000">SimbaML: Connecting Mechanistic Models and Machine Learning with Augmented Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training sophisticated machine learning (ML) models requires large datasets that are difficult or expensive to collect for many applications. If prior knowledge about system dynamics is available, mechanistic representations can be used to supplement real-world data. We present SimbaML (Simulation-Based ML), an open-source tool that unifies realistic synthetic dataset generation from ordinary differential equation-based models and the direct analysis and inclusion in ML pipelines. SimbaML conveniently enables investigating transfer learning from synthetic to real-world data, data augmentation, identifying needs for data collection, and benchmarking physics-informed ML approaches. SimbaML is available from https://pypi.org/project/simba-ml/.
<div id='section'>Paperid: <span id='pid'>1304, <a href='https://arxiv.org/pdf/2304.03894.pdf' target='_blank'>https://arxiv.org/pdf/2304.03894.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda Howard, Yucheng Fu, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.03894">A multifidelity approach to continual learning for physical systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel continual learning method based on multifidelity deep neural networks. This method learns the correlation between the output of previously trained models and the desired output of the model on the current training dataset, limiting catastrophic forgetting. On its own the multifidelity continual learning method shows robust results that limit forgetting across several datasets. Additionally, we show that the multifidelity method can be combined with existing continual learning methods, including replay and memory aware synapses, to further limit catastrophic forgetting. The proposed continual learning method is especially suited for physical problems where the data satisfy the same physical laws on each domain, or for physics-informed neural networks, because in these cases we expect there to be a strong correlation between the output of the previous model and the model on the current training domain.
<div id='section'>Paperid: <span id='pid'>1305, <a href='https://arxiv.org/pdf/2304.03689.pdf' target='_blank'>https://arxiv.org/pdf/2304.03689.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ayoub Farkane, Mounir Ghogho, Mustapha Oudani, Mohamed Boutayeb
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.03689">EPINN-NSE: Enhanced Physics-Informed Neural Networks for Solving Navier-Stokes Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fluid mechanics is a fundamental field in engineering and science. Solving the Navier-Stokes equation (NSE) is critical for understanding the behavior of fluids. However, the NSE is a complex partial differential equation that is difficult to solve, and classical numerical methods can be computationally expensive. In this paper, we present an innovative approach for solving the NSE using Physics Informed Neural Networks (PINN) and several novel techniques that improve their performance. The first model is based on an assumption that involves approximating the velocity component by employing the derivative of a stream function. This assumption serves to simplify the system and guarantees that the velocity adheres to the divergence-free equation. We also developed a second more flexible model that approximates the solution without any assumptions. The proposed models can effectively solve two-dimensional NSE. Moreover, we successfully applied the second model to solve the three-dimensional NSE. The results show that the models can efficiently and accurately solve the NSE in three dimensions. These approaches offer several advantages, including high trainability, flexibility, and efficiency.
<div id='section'>Paperid: <span id='pid'>1306, <a href='https://arxiv.org/pdf/2304.00909.pdf' target='_blank'>https://arxiv.org/pdf/2304.00909.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiong-Bin Yan, Zhi-Qin John Xu, Zheng Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.00909">Laplace-fPINNs: Laplace-based fractional physics-informed neural networks for solving forward and inverse problems of subdiffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The use of Physics-informed neural networks (PINNs) has shown promise in solving forward and inverse problems of fractional diffusion equations. However, due to the fact that automatic differentiation is not applicable for fractional derivatives, solving fractional diffusion equations using PINNs requires addressing additional challenges. To address this issue, this paper proposes an extension to PINNs called Laplace-based fractional physics-informed neural networks (Laplace-fPINNs), which can effectively solve the forward and inverse problems of fractional diffusion equations. This approach avoids introducing a mass of auxiliary points and simplifies the loss function. We validate the effectiveness of the Laplace-fPINNs approach using several examples. Our numerical results demonstrate that the Laplace-fPINNs method can effectively solve both the forward and inverse problems of high-dimensional fractional diffusion equations.
<div id='section'>Paperid: <span id='pid'>1307, <a href='https://arxiv.org/pdf/2303.11617.pdf' target='_blank'>https://arxiv.org/pdf/2303.11617.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexandre Magueresse, Santiago Badia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.11617">Adaptive quadratures for nonlinear approximation of low-dimensional PDEs using smooth neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) and their variants have recently emerged as alternatives to traditional partial differential equation (PDE) solvers, but little literature has focused on devising accurate numerical integration methods for neural networks (NNs), which is essential for getting accurate solutions. In this work, we propose adaptive quadratures for the accurate integration of neural networks and apply them to loss functions appearing in low-dimensional PDE discretisations. We show that at opposite ends of the spectrum, continuous piecewise linear (CPWL) activation functions enable one to bound the integration error, while smooth activations ease the convergence of the optimisation problem. We strike a balance by considering a CPWL approximation of a smooth activation function. The CPWL activation is used to obtain an adaptive decomposition of the domain into regions where the network is almost linear, and we derive an adaptive global quadrature from this mesh. The loss function is then obtained by evaluating the smooth network (together with other quantities, e.g., the forcing term) at the quadrature points. We propose a method to approximate a class of smooth activations by CPWL functions and show that it has a quadratic convergence rate. We then derive an upper bound for the overall integration error of our proposed adaptive quadrature. The benefits of our quadrature are evaluated on a strong and weak formulation of the Poisson equation in dimensions one and two. Our numerical experiments suggest that compared to Monte-Carlo integration, our adaptive quadrature makes the convergence of NNs quicker and more robust to parameter initialisation while needing significantly fewer integration points and keeping similar training times.
<div id='section'>Paperid: <span id='pid'>1308, <a href='https://arxiv.org/pdf/2303.07138.pdf' target='_blank'>https://arxiv.org/pdf/2303.07138.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zijian Feng, Xin Chen, Zijian Lv, Peiyuan Sun, Kai Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.07138">Transferable Deep Learning Power System Short-Term Voltage Stability Assessment with Physics-Informed Topological Feature Engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning (DL) algorithms have been widely applied to short-term voltage stability (STVS) assessment in power systems. However, transferring the knowledge learned in one power grid to other power grids with topology changes is still a challenging task. This paper proposed a transferable DL-based model for STVS assessment by constructing the topology-aware voltage dynamic features from raw PMU data. Since the reactive power flow and grid topology are essential to voltage stability, the topology-aware and physics-informed voltage dynamic features are utilized to effectively represent the topological and temporal patterns from post-disturbance system dynamic trajectories. The proposed DL-based STVS assessment model is tested under random operating conditions on the New England 39-bus system. It has 99.99\% classification accuracy of the short-term voltage stability status using the topology-aware and physics-informed voltage dynamic features. In addition to high accuracy, the experiments show good adaptability to PMU errors. Moreover, The proposed STVS assessment method has outstanding performance on new grid topologies after fine-tuning. In particular, the highest accuracy reaches 99.68\% in evaluation, which demonstrates a good knowledge transfer ability of the proposed model for power grid topology change.
<div id='section'>Paperid: <span id='pid'>1309, <a href='https://arxiv.org/pdf/2303.05300.pdf' target='_blank'>https://arxiv.org/pdf/2303.05300.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>N. V. Jagtap, M. K. Mudunuru, K. B. Nakshatrala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.05300">CoolPINNs: A Physics-informed Neural Network Modeling of Active Cooling in Vascular Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Emerging technologies like hypersonic aircraft, space exploration vehicles, and batteries avail fluid circulation in embedded microvasculatures for efficient thermal regulation. Modeling is vital during these engineered systems' design and operational phases. However, many challenges exist in developing a modeling framework. What is lacking is an accurate framework that (i) captures sharp jumps in the thermal flux across complex vasculature layouts, (ii) deals with oblique derivatives (involving tangential and normal components), (iii) handles nonlinearity because of radiative heat transfer, (iv) provides a high-speed forecast for real-time monitoring, and (v) facilitates robust inverse modeling. This paper addresses these challenges by availing the power of physics-informed neural networks (PINNs). We develop a fast, reliable, and accurate Scientific Machine Learning (SciML) framework for vascular-based thermal regulation -- called CoolPINNs: a PINNs-based modeling framework for active cooling. The proposed mesh-less framework elegantly overcomes all the mentioned challenges. The significance of the reported research is multi-fold. First, the framework is valuable for real-time monitoring of thermal regulatory systems because of rapid forecasting. Second, researchers can address complex thermoregulation designs inasmuch as the approach is mesh-less. Finally, the framework facilitates systematic parameter identification and inverse modeling studies, perhaps the current framework's most significant utility.
<div id='section'>Paperid: <span id='pid'>1310, <a href='https://arxiv.org/pdf/2303.02219.pdf' target='_blank'>https://arxiv.org/pdf/2303.02219.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Binghang Lu, Christian B. Moya, Guang Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02219">NSGA-PINN: A Multi-Objective Optimization Method for Physics-Informed Neural Network Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents NSGA-PINN, a multi-objective optimization framework for effective training of Physics-Informed Neural Networks (PINNs). The proposed framework uses the Non-dominated Sorting Genetic Algorithm (NSGA-II) to enable traditional stochastic gradient optimization algorithms (e.g., ADAM) to escape local minima effectively. Additionally, the NSGA-II algorithm enables satisfying the initial and boundary conditions encoded into the loss function during physics-informed training precisely. We demonstrate the effectiveness of our framework by applying NSGA-PINN to several ordinary and partial differential equation problems. In particular, we show that the proposed framework can handle challenging inverse problems with noisy data.
<div id='section'>Paperid: <span id='pid'>1311, <a href='https://arxiv.org/pdf/2303.00935.pdf' target='_blank'>https://arxiv.org/pdf/2303.00935.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaohai Hu, Aparajit Venkatesh, Yusen Wan, Guiliang Zheng, Neel Jawale, Navneet Kaur, Xu Chen, Paul Birkmeyer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.00935">Learning to Detect Slip through Tactile Estimation of the Contact Force Field and its Entropy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detection of slip during object grasping and manipulation plays a vital role in object handling. Existing solutions primarily rely on visual information to devise a strategy for grasping. However, for robotic systems to attain a level of proficiency comparable to humans, especially in consistently handling and manipulating unfamiliar objects, integrating artificial tactile sensing is increasingly essential. We introduce a novel physics-informed, data-driven approach to detect slip continuously in real time. We employ the GelSight Mini, an optical tactile sensor, attached to custom-designed grippers to gather tactile data. Our work leverages the inhomogeneity of tactile sensor readings during slip events to develop distinctive features and formulates slip detection as a classification problem. To evaluate our approach, we test multiple data-driven models on 10 common objects under different loading conditions, textures, and materials. Our results show that the best classification algorithm achieves a high average accuracy of 95.61%. We further illustrate the practical application of our research in dynamic robotic manipulation tasks, where our real-time slip detection and prevention algorithm is implemented.
<div id='section'>Paperid: <span id='pid'>1312, <a href='https://arxiv.org/pdf/2302.12337.pdf' target='_blank'>https://arxiv.org/pdf/2302.12337.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Archie J. Huang, Shaurya Agarwal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12337">On the Limitations of Physics-informed Deep Learning: Illustrations Using First Order Hyperbolic Conservation Law-based Traffic Flow Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since its introduction in 2017, physics-informed deep learning (PIDL) has garnered growing popularity in understanding the evolution of systems governed by physical laws in terms of partial differential equations (PDEs). However, empirical evidence points to the limitations of PIDL for learning certain types of PDEs. In this paper, we (a) present the challenges in training PIDL architecture, (b) contrast the performance of PIDL architecture in learning a first order scalar hyperbolic conservation law and its parabolic counterpart, (c) investigate the effect of training data sampling, which corresponds to various sensing scenarios in traffic networks, (d) comment on the implications of PIDL limitations for traffic flow estimation and prediction in practice. Detailed in the case study, we present the contradistinction in PIDL results between learning the traffic flow model (LWR PDE) and its variation with diffusion. The outcome indicates that PIDL experiences significant challenges in learning the hyperbolic LWR equation due to the non-smoothness of its solution. On the other hand, the architecture with parabolic PDE, augmented with the diffusion term, leads to the successful reassembly of the density data even with the shockwaves present.
<div id='section'>Paperid: <span id='pid'>1313, <a href='https://arxiv.org/pdf/2302.12336.pdf' target='_blank'>https://arxiv.org/pdf/2302.12336.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Archie J. Huang, Shaurya Agarwal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12336">Physics Informed Deep Learning: Applications in Transportation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A recent development in machine learning - physics-informed deep learning (PIDL) - presents unique advantages in transportation applications such as traffic state estimation. Consolidating the benefits of deep learning (DL) and the governing physical equations, it shows the potential to complement traditional sensing methods in obtaining traffic states. In this paper, we first explain the conservation law from the traffic flow theory as ``physics'', then present the architecture of a PIDL neural network and demonstrate its effectiveness in learning traffic conditions of unobserved areas. In addition, we also exhibit the data collection scenario using fog computing infrastructure. A case study on estimating the vehicle velocity is presented and the result shows that PIDL surpasses the performance of a regular DL neural network with the same learning architecture, in terms of convergence time and reconstruction accuracy. The encouraging results showcase the broad potential of PIDL for real-time applications in transportation with a low amount of training data.
<div id='section'>Paperid: <span id='pid'>1314, <a href='https://arxiv.org/pdf/2302.10891.pdf' target='_blank'>https://arxiv.org/pdf/2302.10891.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthieu Nastorg, Michele Alessandro Bucci, Thibault Faney, Jean-Marc Gratien, Guillaume Charpiat, Marc Schoenauer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10891">An Implicit GNN Solver for Poisson-like problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents $Î¨$-GNN, a novel Graph Neural Network (GNN) approach for solving the ubiquitous Poisson PDE problems with mixed boundary conditions. By leveraging the Implicit Layer Theory, $Î¨$-GNN models an "infinitely" deep network, thus avoiding the empirical tuning of the number of required Message Passing layers to attain the solution. Its original architecture explicitly takes into account the boundary conditions, a critical prerequisite for physical applications, and is able to adapt to any initially provided solution. $Î¨$-GNN is trained using a "physics-informed" loss, and the training process is stable by design, and insensitive to its initialization. Furthermore, the consistency of the approach is theoretically proven, and its flexibility and generalization efficiency are experimentally demonstrated: the same learned model can accurately handle unstructured meshes of various sizes, as well as different boundary conditions. To the best of our knowledge, $Î¨$-GNN is the first physics-informed GNN-based method that can handle various unstructured domains, boundary conditions and initial solutions while also providing convergence guarantees.
<div id='section'>Paperid: <span id='pid'>1315, <a href='https://arxiv.org/pdf/2302.08835.pdf' target='_blank'>https://arxiv.org/pdf/2302.08835.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Escapil-InchauspÃ©, Gonzalo A. Ruz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08835">h-analysis and data-parallel physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We explore the data-parallel acceleration of physics-informed machine learning (PIML) schemes, with a focus on physics-informed neural networks (PINNs) for multiple graphics processing units (GPUs) architectures. In order to develop scale-robust and high-throughput PIML models for sophisticated applications which may require a large number of training points (e.g., involving complex and high-dimensional domains, non-linear operators or multi-physics), we detail a novel protocol based on $h$-analysis and data-parallel acceleration through the Horovod training framework. The protocol is backed by new convergence bounds for the generalization error and the train-test gap. We show that the acceleration is straightforward to implement, does not compromise training, and proves to be highly efficient and controllable, paving the way towards generic scale-robust PIML. Extensive numerical experiments with increasing complexity illustrate its robustness and consistency, offering a wide range of possibilities for real-world simulations.
<div id='section'>Paperid: <span id='pid'>1316, <a href='https://arxiv.org/pdf/2302.08309.pdf' target='_blank'>https://arxiv.org/pdf/2302.08309.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongcun Song, Xiaoming Yuan, Hangrui Yue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08309">The ADMM-PINNs Algorithmic Framework for Nonsmooth PDE-Constrained Optimization: A Deep Learning Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the combination of the alternating direction method of multipliers (ADMM) with physics-informed neural networks (PINNs) for a general class of nonsmooth partial differential equation (PDE)-constrained optimization problems, where additional regularization can be employed for constraints on the control or design variables. The resulting ADMM-PINNs algorithmic framework substantially enlarges the applicable range of PINNs to nonsmooth cases of PDE-constrained optimization problems. The application of the ADMM makes it possible to untie the PDE constraints and the nonsmooth regularization terms for iterations. Accordingly, at each iteration, one of the resulting subproblems is a smooth PDE-constrained optimization which can be efficiently solved by PINNs, and the other is a simple nonsmooth optimization problem which usually has a closed-form solution or can be efficiently solved by various standard optimization algorithms or pre-trained neural networks. The ADMM-PINNs algorithmic framework does not require to solve PDEs repeatedly, and it is mesh-free, easy to implement, and scalable to different PDE settings. We validate the efficiency of the ADMM-PINNs algorithmic framework by different prototype applications, including inverse potential problems, source identification in elliptic equations, control constrained optimal control of the Burgers equation, and sparse optimal control of parabolic equations.
<div id='section'>Paperid: <span id='pid'>1317, <a href='https://arxiv.org/pdf/2302.08144.pdf' target='_blank'>https://arxiv.org/pdf/2302.08144.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bilal Thonnam Thodi, Sai Venkata Ramana Ambadipudi, Saif Eddin Jabari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08144">Learning-based solutions to nonlinear hyperbolic PDEs: Empirical insights on generalization errors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study learning weak solutions to nonlinear hyperbolic partial differential equations (H-PDE), which have been difficult to learn due to discontinuities in their solutions. We use a physics-informed variant of the Fourier Neural Operator ($Ï$-FNO) to learn the weak solutions. We empirically quantify the generalization/out-of-sample error of the $Ï$-FNO solver as a function of input complexity, i.e., the distributions of initial and boundary conditions. Our testing results show that $Ï$-FNO generalizes well to unseen initial and boundary conditions. We find that the generalization error grows linearly with input complexity. Further, adding a physics-informed regularizer improved the prediction of discontinuities in the solution. We use the Lighthill-Witham-Richards (LWR) traffic flow model as a guiding example to illustrate the results.
<div id='section'>Paperid: <span id='pid'>1318, <a href='https://arxiv.org/pdf/2302.04107.pdf' target='_blank'>https://arxiv.org/pdf/2302.04107.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tamara G. Grossmann, Urszula Julia Komorowska, Jonas Latz, Carola-Bibiane SchÃ¶nlieb
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.04107">Can Physics-Informed Neural Networks beat the Finite Element Method?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial differential equations play a fundamental role in the mathematical modelling of many processes and systems in physical, biological and other sciences. To simulate such processes and systems, the solutions of PDEs often need to be approximated numerically. The finite element method, for instance, is a usual standard methodology to do so. The recent success of deep neural networks at various approximation tasks has motivated their use in the numerical solution of PDEs. These so-called physics-informed neural networks and their variants have shown to be able to successfully approximate a large range of partial differential equations. So far, physics-informed neural networks and the finite element method have mainly been studied in isolation of each other. In this work, we compare the methodologies in a systematic computational study. Indeed, we employ both methods to numerically solve various linear and nonlinear partial differential equations: Poisson in 1D, 2D, and 3D, Allen-Cahn in 1D, semilinear SchrÃ¶dinger in 1D and 2D. We then compare computational costs and approximation accuracies. In terms of solution time and accuracy, physics-informed neural networks have not been able to outperform the finite element method in our study. In some experiments, they were faster at evaluating the solved PDE.
<div id='section'>Paperid: <span id='pid'>1319, <a href='https://arxiv.org/pdf/2301.02428.pdf' target='_blank'>https://arxiv.org/pdf/2301.02428.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>John M. Hanna, JosÃ© V. Aguado, Sebastien Comas-Cardona, Ramzi Askri, Domenico Borzacchiello
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.02428">Sensitivity analysis using Physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of this paper is to provide a simple approach to perform local sensitivity analysis using Physics-informed neural networks (PINN). The main idea lies in adding a new term in the loss function that regularizes the solution in a small neighborhood near the nominal value of the parameter of interest. The added term represents the derivative of the loss function with respect to the parameter of interest. The result of this modification is a solution to the problem along with the derivative of the solution with respect to the parameter of interest (the sensitivity). We call the new technique SA-PNN which stands for sensitivity analysis in PINN. The effectiveness of the technique is shown using four examples: the first one is a simple one-dimensional advection-diffusion problem to show the methodology, the second is a two-dimensional Poisson's problem with nine parameters of interest, and the third and fourth examples are one and two-dimensional transient two-phase flow in porous media problem.
<div id='section'>Paperid: <span id='pid'>1320, <a href='https://arxiv.org/pdf/2301.02378.pdf' target='_blank'>https://arxiv.org/pdf/2301.02378.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Xu, Fatemeh Pourahmadian, Jian Song, Conglin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.02378">Deep learning for full-field ultrasonic characterization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study takes advantage of recent advances in machine learning to establish a physics-based data analytic platform for distributed reconstruction of mechanical properties in layered components from full waveform data. In this vein, two logics, namely the direct inversion and physics-informed neural networks (PINNs), are explored. The direct inversion entails three steps: (i) spectral denoising and differentiation of the full-field data, (ii) building appropriate neural maps to approximate the profile of unknown physical and regularization parameters on their respective domains, and (iii) simultaneous training of the neural networks by minimizing the Tikhonov-regularized PDE loss using data from (i). PINNs furnish efficient surrogate models of complex systems with predictive capabilities via multitask learning where the field variables are modeled by neural maps endowed with (scaler or distributed) auxiliary parameters such as physical unknowns and loss function weights. PINNs are then trained by minimizing a measure of data misfit subject to the underlying physical laws as constraints. In this study, to facilitate learning from ultrasonic data, the PINNs loss adopts (a) wavenumber-dependent Sobolev norms to compute the data misfit, and (b) non-adaptive weights in a specific scaling framework to naturally balance the loss objectives by leveraging the form of PDEs germane to elastic-wave propagation. Both paradigms are examined via synthetic and laboratory test data. In the latter case, the reconstructions are performed at multiple frequencies and the results are verified by a set of complementary experiments highlighting the importance of verification and validation in data-driven modeling.
<div id='section'>Paperid: <span id='pid'>1321, <a href='https://arxiv.org/pdf/2301.02033.pdf' target='_blank'>https://arxiv.org/pdf/2301.02033.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elena MartÃ­n-GonzÃ¡lez, Ebraham Alskaf, Amedeo Chiribiri, Pablo Casaseca-de-la-Higuera, Carlos Alberola-LÃ³pez, Rita G Nunes, Teresa M Correia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.02033">Physics-informed self-supervised deep learning reconstruction for accelerated first-pass perfusion cardiac MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>First-pass perfusion cardiac magnetic resonance (FPP-CMR) is becoming an essential non-invasive imaging method for detecting deficits of myocardial blood flow, allowing the assessment of coronary heart disease. Nevertheless, acquisitions suffer from relatively low spatial resolution and limited heart coverage. Compressed sensing (CS) methods have been proposed to accelerate FPP-CMR and achieve higher spatial resolution. However, the long reconstruction times have limited the widespread clinical use of CS in FPP-CMR. Deep learning techniques based on supervised learning have emerged as alternatives for speeding up reconstructions. However, these approaches require fully sampled data for training, which is not possible to obtain, particularly high-resolution FPP-CMR images. Here, we propose a physics-informed self-supervised deep learning FPP-CMR reconstruction approach for accelerating FPP-CMR scans and hence facilitate high spatial resolution imaging. The proposed method provides high-quality FPP-CMR images from 10x undersampled data without using fully sampled reference data.
<div id='section'>Paperid: <span id='pid'>1322, <a href='https://arxiv.org/pdf/2212.00798.pdf' target='_blank'>https://arxiv.org/pdf/2212.00798.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Guo, Yanzhong Yao, Han Wang, Tongxiang Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.00798">Pre-training strategy for solving evolution equations based on physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The physics informed neural network (PINN) is a promising method for solving time-evolution partial differential equations (PDEs). However, the standard PINN method may fail to solve the PDEs with strongly nonlinear characteristics or those with high-frequency solutions. The physics informed neural network (PINN) is a promising method for solving time-evolution partial differential equations (PDEs). However, the standard PINN method may fail to solve the PDEs with strongly nonlinear characteristics or those with high-frequency solutions. The PT-PINN method transforms the difficult problem on the entire time domain to relatively simple problems defined on small subdomains. The neural network trained on small subdomains provides the neural network initialization and extra supervised learning data for the problems on larger subdomains or on the entire time-domain. By numerical experiments, we demonstrate that the PT-PINN succeeds in solving the evolution PDEs with strong non-linearity and/or high frequency solutions, including the strongly nonlinear heat equation, the Allen-Cahn equation, the convection equation with high-frequency solutions and so on, and that the convergence and accuracy of the PT-PINN is superior to the standard PINN method. The PT-PINN method is a competitive method for solving the time-evolution PDEs.
<div id='section'>Paperid: <span id='pid'>1323, <a href='https://arxiv.org/pdf/2211.10344.pdf' target='_blank'>https://arxiv.org/pdf/2211.10344.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Escapil-InchauspÃ©, Gonzalo A. Ruz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.10344">Physics-informed neural networks for operator equations with stochastic data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the computation of statistical moments to operator equations with stochastic data. We remark that application of PINNs -- referred to as TPINNs -- allows to solve the induced tensor operator equations under minimal changes of existing PINNs code, and enabling handling of non-linear and time-dependent operators. We propose two types of architectures, referred to as vanilla and multi-output TPINNs, and investigate their benefits and limitations. Exhaustive numerical experiments are performed; demonstrating applicability and performance; raising a variety of new promising research avenues.
<div id='section'>Paperid: <span id='pid'>1324, <a href='https://arxiv.org/pdf/2211.04539.pdf' target='_blank'>https://arxiv.org/pdf/2211.04539.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fiona Lippert, Bart Kranstauber, E. Emiel van Loon, Patrick ForrÃ©
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.04539">Physics-informed inference of aerial animal movements from weather radar data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Studying animal movements is essential for effective wildlife conservation and conflict mitigation. For aerial movements, operational weather radars have become an indispensable data source in this respect. However, partial measurements, incomplete spatial coverage, and poor understanding of animal behaviours make it difficult to reconstruct complete spatio-temporal movement patterns from available radar data. We tackle this inverse problem by learning a mapping from high-dimensional radar measurements to low-dimensional latent representations using a convolutional encoder. Under the assumption that the latent system dynamics are well approximated by a locally linear Gaussian transition model, we perform efficient posterior estimation using the classical Kalman smoother. A convolutional decoder maps the inferred latent system states back to the physical space in which the known radar observation model can be applied, enabling fully unsupervised training. To encourage physical consistency, we additionally introduce a physics-informed loss term that leverages known mass conservation constraints. Our experiments on synthetic radar data show promising results in terms of reconstruction quality and data-efficiency.
<div id='section'>Paperid: <span id='pid'>1325, <a href='https://arxiv.org/pdf/2210.15799.pdf' target='_blank'>https://arxiv.org/pdf/2210.15799.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan Zanardi, Simone Venturi, Marco Panesi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.15799">Adaptive physics-informed neural operator for coarse-grained non-equilibrium flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work proposes a new machine learning (ML)-based paradigm aiming to enhance the computational efficiency of non-equilibrium reacting flow simulations while ensuring compliance with the underlying physics. The framework combines dimensionality reduction and neural operators through a hierarchical and adaptive deep learning strategy to learn the solution of multi-scale coarse-grained governing equations for chemical kinetics. The proposed surrogate's architecture is structured as a tree, with leaf nodes representing separate neural operator blocks where physics is embedded in the form of multiple soft and hard constraints. The hierarchical attribute has two advantages: i) It allows the simplification of the training phase via transfer learning, starting from the slowest temporal scales; ii) It accelerates the prediction step by enabling adaptivity as the surrogate's evaluation is limited to the necessary leaf nodes based on the local degree of non-equilibrium of the gas. The model is applied to the study of chemical kinetics relevant for application to hypersonic flight, and it is tested here on pure oxygen gas mixtures. In 0-D scenarios, the proposed ML framework can adaptively predict the dynamics of almost thirty species with a maximum relative error of 4.5% for a wide range of initial conditions. Furthermore, when employed in 1-D shock simulations, the approach shows accuracy ranging from 1% to 4.5% and a speedup of one order of magnitude compared to conventional implicit schemes employed in an operator-splitting integration framework. Given the results presented in the paper, this work lays the foundation for constructing an efficient ML-based surrogate coupled with reactive Navier-Stokes solvers for accurately characterizing non-equilibrium phenomena in multi-dimensional computational fluid dynamics simulations.
<div id='section'>Paperid: <span id='pid'>1326, <a href='https://arxiv.org/pdf/2210.12685.pdf' target='_blank'>https://arxiv.org/pdf/2210.12685.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufeng Wang, Cong Xu, Min Yang, Jin Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.12685">Less Emphasis on Difficult Layer Regions: Curriculum Learning for Singularly Perturbed Convection-Diffusion-Reaction Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although Physics-Informed Neural Networks (PINNs) have been successfully applied in a wide variety of science and engineering fields, they can fail to accurately predict the underlying solution in slightly challenging convection-diffusion-reaction problems. In this paper, we investigate the reason of this failure from a domain distribution perspective, and identify that learning multi-scale fields simultaneously makes the network unable to advance its training and easily get stuck in poor local minima. We show that the widespread experience of sampling more collocation points in high-loss layer regions hardly help optimize and may even worsen the results. These findings motivate the development of a novel curriculum learning method that encourages neural networks to prioritize learning on easier non-layer regions while downplaying learning on harder layer regions. The proposed method helps PINNs automatically adjust the learning emphasis and thereby facilitate the optimization procedure. Numerical results on typical benchmark equations show that the proposed curriculum learning approach mitigates the failure modes of PINNs and can produce accurate results for very sharp boundary and interior layers. Our work reveals that for equations whose solutions have large scale differences, paying less attention to high-loss regions can be an effective strategy for learning them accurately.
<div id='section'>Paperid: <span id='pid'>1327, <a href='https://arxiv.org/pdf/2210.03426.pdf' target='_blank'>https://arxiv.org/pdf/2210.03426.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Birgit Hillebrecht, Benjamin Unger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.03426">Certified machine learning: Rigorous a posteriori error bounds for PDE defined PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prediction error quantification in machine learning has been left out of most methodological investigations of neural networks, for both purely data-driven and physics-informed approaches. Beyond statistical investigations and generic results on the approximation capabilities of neural networks, we present a rigorous upper bound on the prediction error of physics-informed neural networks. This bound can be calculated without the knowledge of the true solution and only with a priori available information about the characteristics of the underlying dynamical system governed by a partial differential equation. We apply this a posteriori error bound exemplarily to four problems: the transport equation, the heat equation, the Navier-Stokes equation and the Klein-Gordon equation.
<div id='section'>Paperid: <span id='pid'>1328, <a href='https://arxiv.org/pdf/2210.01476.pdf' target='_blank'>https://arxiv.org/pdf/2210.01476.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Umar B. Niazi, John Cao, Xudong Sun, Amritam Das, Karl Henrik Johansson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.01476">Learning-based Design of Luenberger Observers for Autonomous Nonlinear Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing Luenberger observers for nonlinear systems involves the challenging task of transforming the state to an alternate coordinate system, possibly of higher dimensions, where the system is asymptotically stable and linear up to output injection. The observer then estimates the system's state in the original coordinates by inverting the transformation map. However, finding a suitable injective transformation whose inverse can be derived remains a primary challenge for general nonlinear systems. We propose a novel approach that uses supervised physics-informed neural networks to approximate both the transformation and its inverse. Our method exhibits superior generalization capabilities to contemporary methods and demonstrates robustness to both neural network's approximation errors and system uncertainties.
<div id='section'>Paperid: <span id='pid'>1329, <a href='https://arxiv.org/pdf/2210.00279.pdf' target='_blank'>https://arxiv.org/pdf/2210.00279.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Gao, Liang Yan, Tao Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.00279">Failure-informed adaptive sampling for PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as an effective technique for solving PDEs in a wide range of domains. It is noticed, however, the performance of PINNs can vary dramatically with different sampling procedures. For instance, a fixed set of (prior chosen) training points may fail to capture the effective solution region (especially for problems with singularities). To overcome this issue, we present in this work an adaptive strategy, termed the failure-informed PINNs (FI-PINNs), which is inspired by the viewpoint of reliability analysis. The key idea is to define an effective failure probability based on the residual, and then, with the aim of placing more samples in the failure region, the FI-PINNs employs a failure-informed enrichment technique to adaptively add new collocation points to the training set, such that the numerical accuracy is dramatically improved. In short, similar as adaptive finite element methods, the proposed FI-PINNs adopts the failure probability as the posterior error indicator to generate new training points. We prove rigorous error bounds of FI-PINNs and illustrate its performance through several problems.
<div id='section'>Paperid: <span id='pid'>1330, <a href='https://arxiv.org/pdf/2209.15609.pdf' target='_blank'>https://arxiv.org/pdf/2209.15609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Glyn-Davies, Connor Duffin, Ã. Deniz Akyildiz, Mark Girolami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.15609">$Î¦$-DVAE: Physics-Informed Dynamical Variational Autoencoders for Unstructured Data Assimilation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Incorporating unstructured data into physical models is a challenging problem that is emerging in data assimilation. Traditional approaches focus on well-defined observation operators whose functional forms are typically assumed to be known. This prevents these methods from achieving a consistent model-data synthesis in configurations where the mapping from data-space to model-space is unknown. To address these shortcomings, in this paper we develop a physics-informed dynamical variational autoencoder ($Î¦$-DVAE) to embed diverse data streams into time-evolving physical systems described by differential equations. Our approach combines a standard, possibly nonlinear, filter for the latent state-space model and a VAE, to assimilate the unstructured data into the latent dynamical system. Unstructured data, in our example systems, comes in the form of video data and velocity field measurements, however the methodology is suitably generic to allow for arbitrary unknown observation operators. A variational Bayesian framework is used for the joint estimation of the encoding, latent states, and unknown system parameters. To demonstrate the method, we provide case studies with the Lorenz-63 ordinary differential equation, and the advection and Korteweg-de Vries partial differential equations. Our results, with synthetic data, show that $Î¦$-DVAE provides a data efficient dynamics encoding methodology which is competitive with standard approaches. Unknown parameters are recovered with uncertainty quantification, and unseen data are accurately predicted.
<div id='section'>Paperid: <span id='pid'>1331, <a href='https://arxiv.org/pdf/2209.13091.pdf' target='_blank'>https://arxiv.org/pdf/2209.13091.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Advaith Venkatramanan Sethuraman, Manikandasriram Srinivasan Ramanagopal, Katherine A. Skinner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.13091">WaterNeRF: Neural Radiance Fields for Underwater Scenes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Underwater imaging is a critical task performed by marine robots for a wide range of applications including aquaculture, marine infrastructure inspection, and environmental monitoring. However, water column effects, such as attenuation and backscattering, drastically change the color and quality of imagery captured underwater. Due to varying water conditions and range-dependency of these effects, restoring underwater imagery is a challenging problem. This impacts downstream perception tasks including depth estimation and 3D reconstruction. In this paper, we advance state-of-the-art in neural radiance fields (NeRFs) to enable physics-informed dense depth estimation and color correction. Our proposed method, WaterNeRF, estimates parameters of a physics-based model for underwater image formation, leading to a hybrid data-driven and model-based solution. After determining the scene structure and radiance field, we can produce novel views of degraded as well as corrected underwater images, along with dense depth of the scene. We evaluate the proposed method qualitatively and quantitatively on a real underwater dataset.
<div id='section'>Paperid: <span id='pid'>1332, <a href='https://arxiv.org/pdf/2206.08750.pdf' target='_blank'>https://arxiv.org/pdf/2206.08750.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yan Gu, Chuanzeng Zhang, Peijun Zhang, Mikhail V. Golub
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.08750">Enriched physics-informed neural networks for in-plane crack problems: Theory and MATLAB codes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, a method based on the physics-informed neural networks (PINNs) is presented to model in-plane crack problems in the linear elastic fracture mechanics. Instead of forming a mesh, the PINNs is meshless and can be trained on batches of randomly sampled collocation points. In order to capture the theoretical singular behavior of the near-tip stress and strain fields, the standard PINNs formulation is enriched here by including the crack-tip asymptotic functions such that the singular solutions at the crack-tip region can be modeled accurately without a high degree of nodal refinement. The learnable parameters of the enriched PINNs are trained to satisfy the governing equations of the cracked body and the corresponding boundary conditions. It was found that the incorporation of the crack-tip enrichment functions in PINNs is substantially simpler and more trouble-free than in the finite element (FEM) or boundary element (BEM) methods. The present algorithm is tested on a class of representative benchmarks with different modes of loading types. Results show that the present method allows the calculation of accurate stress intensity factors (SIFs) with far fewer degrees of freedom. A self-contained MATLAB code and data-sets accompanying this manuscript are also provided.
<div id='section'>Paperid: <span id='pid'>1333, <a href='https://arxiv.org/pdf/2206.06817.pdf' target='_blank'>https://arxiv.org/pdf/2206.06817.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joongoo Jeon, Juhyeong Lee, Ricardo Vinuesa, Sung Joong Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.06817">Residual-based physics-informed transfer learning: A hybrid method for accelerating long-term CFD simulations via deep learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While a big wave of artificial intelligence (AI) has propagated to the field of computational fluid dynamics (CFD) acceleration studies, recent research has highlighted that the development of AI techniques that reconciles the following goals remains our primary task: (1) accurate prediction of unseen (future) time series in long-term CFD simulations (2) acceleration of simulations (3) an acceptable amount of training data and time (4) within a multiple PDEs condition. In this study, we propose a residual-based physics-informed transfer learning (RePIT) strategy to achieve these four objectives using ML-CFD hybrid computation. Our hypothesis is that long-term CFD simulation is feasible with the hybrid method where CFD and AI alternately calculate time series while monitoring the first principle's residuals. The feasibility of RePIT strategy was verified through a CFD case study on natural convection. In a single training approach, a residual scale change occurred around 100th timestep, resulting in predicted time series exhibiting non-physical patterns as well as a significant deviations from the ground truth. Conversely, RePIT strategy maintained the residuals within the defined range and demonstrated good accuracy throughout the entire simulation period. The maximum error from the ground truth was below 0.4 K for temperature and 0.024 m/s for x-axis velocity. Furthermore, the average time for 1 timestep by the ML-GPU and CFD-CPU calculations was 0.171 s and 0.015 s, respectively. Including the parameter-updating time, the simulation was accelerated by a factor of 1.9. In conclusion, our RePIT strategy is a promising technique to reduce the cost of CFD simulations in industry. However, more vigorous optimization and improvement studies are still necessary.
<div id='section'>Paperid: <span id='pid'>1334, <a href='https://arxiv.org/pdf/2205.11359.pdf' target='_blank'>https://arxiv.org/pdf/2205.11359.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pulkit Gopalani, Sayar Karmakar, Dibyakanti Kumar, Anirbit Mukherjee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.11359">Towards Size-Independent Generalization Bounds for Deep Operator Nets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent times machine learning methods have made significant advances in becoming a useful tool for analyzing physical systems. A particularly active area in this theme has been "physics-informed machine learning" which focuses on using neural nets for numerically solving differential equations. In this work, we aim to advance the theory of measuring out-of-sample error while training DeepONets - which is among the most versatile ways to solve P.D.E systems in one-shot. Firstly, for a class of DeepONets, we prove a bound on their Rademacher complexity which does not explicitly scale with the width of the nets involved. Secondly, we use this to show how the Huber loss can be chosen so that for these DeepONet classes generalization error bounds can be obtained that have no explicit dependence on the size of the nets. The effective capacity measure for DeepONets that we thus derive is also shown to correlate with the behavior of generalization error in experiments.
<div id='section'>Paperid: <span id='pid'>1335, <a href='https://arxiv.org/pdf/2205.07731.pdf' target='_blank'>https://arxiv.org/pdf/2205.07731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chen Xu, Ba Trung Cao, Yong Yuan, GÃ¼nther Meschke
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.07731">Transfer learning based physics-informed neural networks for solving inverse problems in engineering structures under different loading scenarios</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, a class of machine learning methods called physics-informed neural networks (PINNs) has been proposed and gained prevalence in solving various scientific computing problems. This approach enables the solution of partial differential equations (PDEs) via embedding physical laws into the loss function. Many inverse problems can be tackled by simply combining the data from real life scenarios with existing PINN algorithms. In this paper, we present a multi-task learning method using uncertainty weighting to improve the training efficiency and accuracy of PINNs for inverse problems in linear elasticity and hyperelasticity. Furthermore, we demonstrate an application of PINNs to a practical inverse problem in structural analysis: prediction of external loads of diverse engineering structures based on limited displacement monitoring points. To this end, we first determine a simplified loading scenario at the offline stage. By setting unknown boundary conditions as learnable parameters, PINNs can predict the external loads with the support of measured data. When it comes to the online stage in real engineering projects, transfer learning is employed to fine-tune the pre-trained model from offline stage. Our results show that, even with noisy gappy data, satisfactory results can still be obtained from the PINN model due to the dual regularization of physics laws and prior knowledge, which exhibits better robustness compared to traditional analysis methods. Our approach is capable of bridging the gap between various structures with geometric scaling and under different loading scenarios, and the convergence of training is also greatly accelerated through not only the layer freezing but also the multi-task weight inheritance from pre-trained models, thus making it possible to be applied as surrogate models in actual engineering projects.
<div id='section'>Paperid: <span id='pid'>1336, <a href='https://arxiv.org/pdf/2205.06704.pdf' target='_blank'>https://arxiv.org/pdf/2205.06704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paul Escapil-InchauspÃ©, Gonzalo A. Ruz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.06704">Hyper-parameter tuning of physics-informed neural networks: Application to Helmholtz problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider physics-informed neural networks (PINNs) [Raissi et al., J.~Comput. Phys. 278 (2019) 686-707] for forward physical problems. In order to find optimal PINNs configuration, we introduce a hyper-parameter optimization (HPO) procedure via Gaussian processes-based Bayesian optimization. We apply the HPO to Helmholtz equation for bounded domains and conduct a thorough study, focusing on: (i) performance, (ii) the collocation points density $r$ and (iii) the frequency $Îº$, confirming the applicability and necessity of the method. Numerical experiments are performed in two and three dimensions, including comparison to finite element methods.
<div id='section'>Paperid: <span id='pid'>1337, <a href='https://arxiv.org/pdf/2204.05108.pdf' target='_blank'>https://arxiv.org/pdf/2204.05108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Katsiaryna Haitsiukevich, Alexander Ilin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.05108">Improved Training of Physics-Informed Neural Networks with Model Ensembles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning the solution of partial differential equations (PDEs) with a neural network is an attractive alternative to traditional solvers due to its elegance, greater flexibility and the ease of incorporating observed data. However, training such physics-informed neural networks (PINNs) is notoriously difficult in practice since PINNs often converge to wrong solutions. In this paper, we address this problem by training an ensemble of PINNs. Our approach is motivated by the observation that individual PINN models find similar solutions in the vicinity of points with targets (e.g., observed data or initial conditions) while their solutions may substantially differ farther away from such points. Therefore, we propose to use the ensemble agreement as the criterion for gradual expansion of the solution interval, that is including new points for computing the loss derived from differential equations. Due to the flexibility of the domain expansion, our algorithm can easily incorporate measurements in arbitrary locations. In contrast to the existing PINN algorithms with time-adaptive strategies, the proposed algorithm does not need a pre-defined schedule of interval expansion and it treats time and space equally. We experimentally show that the proposed algorithm can stabilize PINN training and yield performance competitive to the recent variants of PINNs trained with time adaptation.
<div id='section'>Paperid: <span id='pid'>1338, <a href='https://arxiv.org/pdf/2203.17055.pdf' target='_blank'>https://arxiv.org/pdf/2203.17055.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Birgit Hillebrecht, Benjamin Unger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.17055">Certified machine learning: A posteriori error estimation for physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are one popular approach to incorporate a priori knowledge about physical systems into the learning framework. PINNs are known to be robust for smaller training sets, derive better generalization problems, and are faster to train. In this paper, we show that using PINNs in comparison with purely data-driven neural networks is not only favorable for training performance but allows us to extract significant information on the quality of the approximated solution. Assuming that the underlying differential equation for the PINN training is an ordinary differential equation, we derive a rigorous upper limit on the PINN prediction error. This bound is applicable even for input data not included in the training phase and without any prior knowledge about the true solution. Therefore, our a posteriori error estimation is an essential step to certify the PINN. We apply our error estimator exemplarily to two academic toy problems, whereof one falls in the category of model-predictive control and thereby shows the practical use of the derived results.
<div id='section'>Paperid: <span id='pid'>1339, <a href='https://arxiv.org/pdf/2203.15402.pdf' target='_blank'>https://arxiv.org/pdf/2203.15402.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hamidreza Eivazi, Yuning Wang, Ricardo Vinuesa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.15402">Physics-informed deep-learning applications to experimental fluid mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-resolution reconstruction of flow-field data from low-resolution and noisy measurements is of interest due to the prevalence of such problems in experimental fluid mechanics, where the measurement data are in general sparse, incomplete and noisy. Deep-learning approaches have been shown suitable for such super-resolution tasks. However, a high number of high-resolution examples is needed, which may not be available for many cases. Moreover, the obtained predictions may lack in complying with the physical principles, e.g. mass and momentum conservation. Physics-informed deep learning provides frameworks for integrating data and physical laws for learning. In this study, we apply physics-informed neural networks (PINNs) for super-resolution of flow-field data both in time and space from a limited set of noisy measurements without having any high-resolution reference data. Our objective is to obtain a continuous solution of the problem, providing a physically-consistent prediction at any point in the solution domain. We demonstrate the applicability of PINNs for the super-resolution of flow-field data in time and space through three canonical cases: Burgers' equation, two-dimensional vortex shedding behind a circular cylinder and the minimal turbulent channel flow. The robustness of the models is also investigated by adding synthetic Gaussian noise. Furthermore, we show the capabilities of PINNs to improve the resolution and reduce the noise in a real experimental dataset consisting of hot-wire-anemometry measurements. Our results show the adequate capabilities of PINNs in the context of data augmentation for experiments in fluid mechanics.
<div id='section'>Paperid: <span id='pid'>1340, <a href='https://arxiv.org/pdf/2201.06780.pdf' target='_blank'>https://arxiv.org/pdf/2201.06780.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongji Wang, Ching-Yao Lai, Javier GÃ³mez-Serrano, Tristan Buckmaster
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.06780">Asymptotic self-similar blow-up profile for three-dimensional axisymmetric Euler equations using neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Whether there exist finite time blow-up solutions for the 2-D Boussinesq and the 3-D Euler equations are of fundamental importance to the field of fluid mechanics. We develop a new numerical framework, employing physics-informed neural networks (PINNs), that discover, for the first time, a smooth self-similar blow-up profile for both equations. The solution itself could form the basis of a future computer-assisted proof of blow-up for both equations. In addition, we demonstrate PINNs could be successfully applied to find unstable self-similar solutions to fluid equations by constructing the first example of an unstable self-similar solution to the CÃ³rdoba-CÃ³rdoba-Fontelos equation. We show that our numerical framework is both robust and adaptable to various other equations.
<div id='section'>Paperid: <span id='pid'>1341, <a href='https://arxiv.org/pdf/2112.03749.pdf' target='_blank'>https://arxiv.org/pdf/2112.03749.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikolas NÃ¼sken, Lorenz Richter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.03749">Interpolating between BSDEs and PINNs: deep learning for elliptic and parabolic boundary value problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving high-dimensional partial differential equations is a recurrent challenge in economics, science and engineering. In recent years, a great number of computational approaches have been developed, most of them relying on a combination of Monte Carlo sampling and deep learning based approximation. For elliptic and parabolic problems, existing methods can broadly be classified into those resting on reformulations in terms of $\textit{backward stochastic differential equations}$ (BSDEs) and those aiming to minimize a regression-type $L^2$-error ($\textit{physics-informed neural networks}$, PINNs). In this paper, we review the literature and suggest a methodology based on the novel $\textit{diffusion loss}$ that interpolates between BSDEs and PINNs. Our contribution opens the door towards a unified understanding of numerical approaches for high-dimensional PDEs, as well as for implementations that combine the strengths of BSDEs and PINNs. The diffusion loss furthermore bears close similarities to $\textit{(least squares) temporal difference}$ objectives found in reinforcement learning. We also discuss eigenvalue problems and perform extensive numerical studies, including calculations of the ground state for nonlinear SchrÃ¶dinger operators and committor functions relevant in molecular dynamics.
<div id='section'>Paperid: <span id='pid'>1342, <a href='https://arxiv.org/pdf/2110.13311.pdf' target='_blank'>https://arxiv.org/pdf/2110.13311.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Woodward, Yifeng Tian, Criston Hyett, Chris Fryer, Daniel Livescu, Mikhail Stepanov, Michael Chertkov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.13311">Physics informed machine learning with Smoothed Particle Hydrodynamics: Hierarchy of reduced Lagrangian models of turbulence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Building efficient, accurate and generalizable reduced order models of developed turbulence remains a major challenge. This manuscript approaches this problem by developing a hierarchy of parameterized reduced Lagrangian models for turbulent flows, and investigates the effects of enforcing physical structure through Smoothed Particle Hydrodynamics (SPH) versus relying on neural networks (NN)s as universal function approximators. Starting from Neural Network (NN) parameterizations of a Lagrangian acceleration operator, this hierarchy of models gradually incorporates a weakly compressible and parameterized SPH framework, which enforces physical symmetries, such as Galilean, rotational and translational invariances. Within this hierarchy, two new parameterized smoothing kernels are developed in order to increase the flexibility of the learn-able SPH simulators. For each model we experiment with different loss functions which are minimized using gradient based optimization, where efficient computations of gradients are obtained by using Automatic Differentiation (AD) and Sensitivity Analysis (SA). Each model within the hierarchy is trained on two data sets associated with weekly compressible Homogeneous Isotropic Turbulence (HIT): (1) a validation set using weakly compressible SPH; and (2) a high fidelity set from Direct Numerical Simulations (DNS). Numerical evidence shows that encoding more SPH structure improves generalizability to different turbulent Mach numbers and time shifts, and that including the novel parameterized smoothing kernels improves the accuracy of SPH at the resolved scales.
<div id='section'>Paperid: <span id='pid'>1343, <a href='https://arxiv.org/pdf/2107.04466.pdf' target='_blank'>https://arxiv.org/pdf/2107.04466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan W. Siegel, Qingguo Hong, Xianlin Jin, Wenrui Hao, Jinchao Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2107.04466">Greedy Training Algorithms for Neural Networks and Applications to PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, neural networks have been widely applied for solving partial differential equations (PDEs). Although such methods have been proven remarkably successful on practical engineering problems, they have not been shown, theoretically or empirically, to converge to the underlying PDE solution with arbitrarily high accuracy. The primary difficulty lies in solving the highly non-convex optimization problems resulting from the neural network discretization, which are difficult to treat both theoretically and practically. It is our goal in this work to take a step toward remedying this. For this purpose, we develop a novel greedy training algorithm for shallow neural networks. Our method is applicable to both the variational formulation of the PDE and also to the residual minimization formulation pioneered by physics informed neural networks (PINNs). We analyze the method and obtain a priori error bounds when solving PDEs from the function class defined by shallow networks, which rigorously establishes the convergence of the method as the network size increases. Finally, we test the algorithm on several benchmark examples, including high dimensional PDEs, to confirm the theoretical convergence rate. Although the method is expensive relative to traditional approaches such as finite element methods, we view this work as a proof of concept for neural network-based methods, which shows that numerical methods based upon neural networks can be shown to rigorously converge.
<div id='section'>Paperid: <span id='pid'>1344, <a href='https://arxiv.org/pdf/2105.03332.pdf' target='_blank'>https://arxiv.org/pdf/2105.03332.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joongoo Jeon, Juhyeong Lee, Sung Joong Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2105.03332">Finite volume method network for acceleration of unsteady computational fluid dynamics: non-reacting and reacting flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite rapid improvements in the performance of central processing unit (CPU), the calculation cost of simulating chemically reacting flow using CFD remains infeasible in many cases. The application of the convolutional neural networks (CNNs) specialized in image processing in flow field prediction has been studied, but the need to develop a neural netweork design fitted for CFD is recently emerged. In this study, a neural network model introducing the finite volume method (FVM) with a unique network architecture and physics-informed loss function was developed to accelerate CFD simulations. The developed network model, considering the nature of the CFD flow field where the identical governing equations are applied to all grids, can predict the future fields with only two previous fields unlike the CNNs requiring many field images (>10,000). The performance of this baseline model was evaluated using CFD time series data from non-reacting flow and reacting flow simulation; counterflow and hydrogen flame with 20 detailed chemistries. Consequently, we demonstrated that (1) the FVM-based network architecture provided improved accuracy of multistep time series prediction compared to the previous MLP model (2) the physic-informed loss function prevented non-physical overfitting problem and ultimately reduced the error in time series prediction (3) observing the calculated residuals in an unsupervised manner could indirectly estimate the network accuracy. Additionally, under the reacting flow dataset, the computational speed of this network model was measured to be about 10 times faster than that of the CFD solver.
<div id='section'>Paperid: <span id='pid'>1345, <a href='https://arxiv.org/pdf/2009.11990.pdf' target='_blank'>https://arxiv.org/pdf/2009.11990.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youngkyu Kim, Youngsoo Choi, David Widemann, Tarek Zohdi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2009.11990">A fast and accurate physics-informed neural network reduced order model with shallow masked autoencoder</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional linear subspace reduced order models (LS-ROMs) are able to accelerate physical simulations, in which the intrinsic solution space falls into a subspace with a small dimension, i.e., the solution space has a small Kolmogorov n-width. However, for physical phenomena not of this type, e.g., any advection-dominated flow phenomena, such as in traffic flow, atmospheric flows, and air flow over vehicles, a low-dimensional linear subspace poorly approximates the solution. To address cases such as these, we have developed a fast and accurate physics-informed neural network ROM, namely nonlinear manifold ROM (NM-ROM), which can better approximate high-fidelity model solutions with a smaller latent space dimension than the LS-ROMs. Our method takes advantage of the existing numerical methods that are used to solve the corresponding full order models. The efficiency is achieved by developing a hyper-reduction technique in the context of the NM-ROM. Numerical results show that neural networks can learn a more efficient latent space representation on advection-dominated data from 1D and 2D Burgers' equations. A speedup of up to 2.6 for 1D Burgers' and a speedup of 11.7 for 2D Burgers' equations are achieved with an appropriate treatment of the nonlinear terms through a hyper-reduction technique. Finally, a posteriori error bounds for the NM-ROMs are derived that take account of the hyper-reduced operators.
<div id='section'>Paperid: <span id='pid'>1346, <a href='https://arxiv.org/pdf/2510.04459.pdf' target='_blank'>https://arxiv.org/pdf/2510.04459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel A. Verburg, Efren Fernandez-Grande, Peter Gerstoft
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04459">Differentiable physics for sound field reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sound field reconstruction involves estimating sound fields from a limited number of spatially distributed observations. This work introduces a differentiable physics approach for sound field reconstruction, where the initial conditions of the wave equation are approximated with a neural network, and the differential operator is computed with a differentiable numerical solver. The use of a numerical solver enables a stable network training while enforcing the physics as a strong constraint, in contrast to conventional physics-informed neural networks, which include the physics as a constraint in the loss function. We introduce an additional sparsity-promoting constraint to achieve meaningful solutions even under severe undersampling conditions. Experiments demonstrate that the proposed approach can reconstruct sound fields under extreme data scarcity, achieving higher accuracy and better convergence compared to physics-informed neural networks.
<div id='section'>Paperid: <span id='pid'>1347, <a href='https://arxiv.org/pdf/2510.02414.pdf' target='_blank'>https://arxiv.org/pdf/2510.02414.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lin Chen, Jun Chen, Minghui Qiu, Shuxin Zhong, Binghong Chen, Kaishun Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.02414">RainSeer: Fine-Grained Rainfall Reconstruction via Physics-Guided Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reconstructing high-resolution rainfall fields is essential for flood forecasting, hydrological modeling, and climate analysis. However, existing spatial interpolation methods-whether based on automatic weather station (AWS) measurements or enhanced with satellite/radar observations often over-smooth critical structures, failing to capture sharp transitions and localized extremes. We introduce RainSeer, a structure-aware reconstruction framework that reinterprets radar reflectivity as a physically grounded structural prior-capturing when, where, and how rain develops. This shift, however, introduces two fundamental challenges: (i) translating high-resolution volumetric radar fields into sparse point-wise rainfall observations, and (ii) bridging the physical disconnect between aloft hydro-meteors and ground-level precipitation. RainSeer addresses these through a physics-informed two-stage architecture: a Structure-to-Point Mapper performs spatial alignment by projecting mesoscale radar structures into localized ground-level rainfall, through a bidirectional mapping, and a Geo-Aware Rain Decoder captures the semantic transformation of hydro-meteors through descent, melting, and evaporation via a causal spatiotemporal attention mechanism. We evaluate RainSeer on two public datasets-RAIN-F (Korea, 2017-2019) and MeteoNet (France, 2016-2018)-and observe consistent improvements over state-of-the-art baselines, reducing MAE by over 13.31% and significantly enhancing structural fidelity in reconstructed rainfall fields.
<div id='section'>Paperid: <span id='pid'>1348, <a href='https://arxiv.org/pdf/2510.00698.pdf' target='_blank'>https://arxiv.org/pdf/2510.00698.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fu-Chen Guo, Pei-Zhi Zhuang, Fei Ren, Hong-Ya Yue, He Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00698">Physics-Informed Extreme Learning Machine (PIELM) for Tunnelling-Induced Soil-Pile Interactions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning has been a promising data-driven and physics-informed approach in geotechnical engineering. This study proposes a physics-informed extreme learning machine (PIELM) framework for analyzing tunneling-induced soil-pile interactions. The pile foundation is modeled as an Euler-Bernoulli beam, and the surrounding soil is modeled as a Pasternak foundation. The soil-pile interaction is formulated into a fourth-order ordinary differential equation (ODE) that constitutes the physics-informed component, while measured data are incorporated into PIELM as the data-driven component. Combining physics and data yields a loss vector of the extreme learning machine (ELM) network, which is trained within 1 second by the least squares method. After validating the PIELM approach by the boundary element method (BEM) and finite difference method (FDM), parametric studies are carried out to examine the effects of ELM network architecture, data monitoring locations and numbers on the performance of PIELM. The results indicate that monitored data should be placed at positions where the gradients of pile deflections are significant, such as at the pile tip/top and near tunneling zones. Two application examples highlight the critical role of physics-informed and data-driven approach for tunnelling-induced soil-pile interactions. The proposed approach shows great potential for real-time monitoring and safety assessment of pile foundations, and benefits for intelligent early-warning systems in geotechnical engineering.
<div id='section'>Paperid: <span id='pid'>1349, <a href='https://arxiv.org/pdf/2509.25222.pdf' target='_blank'>https://arxiv.org/pdf/2509.25222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yutong Liang, Chang Hou, Guy Y. Cornejo Maceda, Andrea Ianiro, Stefano Discetti, Andrea Meilán-Vila, Didier Sornette, Sandro Claudio Lera, Jialong Chen, Xiaozhou He, Bernd R. Noack
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25222">Sensor optimization for urban wind estimation with cluster-based probabilistic framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a physics-informed machine-learned framework for sensor-based flow estimation for drone trajectories in complex urban terrain. The input is a rich set of flow simulations at many wind conditions. The outputs are velocity and uncertainty estimates for a target domain and subsequent sensor optimization for minimal uncertainty. The framework has three innovations compared to traditional flow estimators. First, the algorithm scales proportionally to the domain complexity, making it suitable for flows that are too complex for any monolithic reduced-order representation. Second, the framework extrapolates beyond the training data, e.g., smaller and larger wind velocities. Last, and perhaps most importantly, the sensor location is a free input, significantly extending the vast majority of the literature. The key enablers are (1) a Reynolds number-based scaling of the flow variables, (2) a physics-based domain decomposition, (3) a cluster-based flow representation for each subdomain, (4) an information entropy correlating the subdomains, and (5) a multi-variate probability function relating sensor input and targeted velocity estimates. This framework is demonstrated using drone flight paths through a three-building cluster as a simple example. We anticipate adaptations and applications for estimating complete cities and incorporating weather input.
<div id='section'>Paperid: <span id='pid'>1350, <a href='https://arxiv.org/pdf/2509.25104.pdf' target='_blank'>https://arxiv.org/pdf/2509.25104.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Albert Vong, Steven Henke, Oliver Hoidn, Hanna Ruth, Junjing Deng, Alexander Hexemer, Apurva Mehta, Arianna Gleason, Levi Hancock, Nicholas Schwarz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25104">Towards generalizable deep ptychography neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>X-ray ptychography is a data-intensive imaging technique expected to become ubiquitous at next-generation light sources delivering many-fold increases in coherent flux. The need for real-time feedback under accelerated acquisition rates motivates surrogate reconstruction models like deep neural networks, which offer orders-of-magnitude speedup over conventional methods. However, existing deep learning approaches lack robustness across diverse experimental conditions. We propose an unsupervised training workflow emphasizing probe learning by combining experimentally-measured probes with synthetic, procedurally generated objects. This probe-centric approach enables a single physics-informed neural network to reconstruct unseen experiments across multiple beamlines; among the first demonstrations of multi-probe generalization. We find probe learning is equally important as in-distribution learning; models trained using this synthetic workflow achieve reconstruction fidelity comparable to those trained exclusively on experimental data, even when changing the type of synthetic training object. The proposed approach enables training of experiment-steering models that provide real-time feedback under dynamic experimental conditions.
<div id='section'>Paperid: <span id='pid'>1351, <a href='https://arxiv.org/pdf/2509.25097.pdf' target='_blank'>https://arxiv.org/pdf/2509.25097.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jesús Roche, Eduardo Sebastián, Eduardo Montijano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25097">Curriculum Imitation Learning of Distributed Multi-Robot Policies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning control policies for multi-robot systems (MRS) remains a major challenge due to long-term coordination and the difficulty of obtaining realistic training data. In this work, we address both limitations within an imitation learning framework. First, we shift the typical role of Curriculum Learning in MRS, from scalability with the number of robots, to focus on improving long-term coordination. We propose a curriculum strategy that gradually increases the length of expert trajectories during training, stabilizing learning and enhancing the accuracy of long-term behaviors. Second, we introduce a method to approximate the egocentric perception of each robot using only third-person global state demonstrations. Our approach transforms idealized trajectories into locally available observations by filtering neighbors, converting reference frames, and simulating onboard sensor variability. Both contributions are integrated into a physics-informed technique to produce scalable, distributed policies from observations. We conduct experiments across two tasks with varying team sizes and noise levels. Results show that our curriculum improves long-term accuracy, while our perceptual estimation method yields policies that are robust to realistic uncertainty. Together, these strategies enable the learning of robust, distributed controllers from global demonstrations, even in the absence of expert actions or onboard measurements.
<div id='section'>Paperid: <span id='pid'>1352, <a href='https://arxiv.org/pdf/2509.19588.pdf' target='_blank'>https://arxiv.org/pdf/2509.19588.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adrien Goldszal, Diego Calanzone, Vincent Taboga, Pierre-Luc Bacon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.19588">Discovery of Sustainable Refrigerants through Physics-Informed RL Fine-Tuning of Sequence Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most refrigerants currently used in air-conditioning systems, such as hydrofluorocarbons, are potent greenhouse gases and are being phased down. Large-scale molecular screening has been applied to the search for alternatives, but in practice only about 300 refrigerants are known, and only a few additional candidates have been suggested without experimental validation. This scarcity of reliable data limits the effectiveness of purely data-driven methods. We present Refgen, a generative pipeline that integrates machine learning with physics-grounded inductive biases. Alongside fine-tuning for valid molecular generation, Refgen incorporates predictive models for critical properties, equations of state, thermochemical polynomials, and full vapor compression cycle simulations. These models enable reinforcement learning fine-tuning under thermodynamic constraints, enforcing consistency and guiding discovery toward molecules that balance efficiency, safety, and environmental impact. By embedding physics into the learning process, Refgen leverages scarce data effectively and enables de novo refrigerant discovery beyond the known set of compounds.
<div id='section'>Paperid: <span id='pid'>1353, <a href='https://arxiv.org/pdf/2509.19233.pdf' target='_blank'>https://arxiv.org/pdf/2509.19233.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Milad Leyli-abadi, Antoine Marot, Jérôme Picault
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.19233">Study Design and Demystification of Physics Informed Neural Networks for Power Flow Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the context of the energy transition, with increasing integration of renewable sources and cross-border electricity exchanges, power grids are encountering greater uncertainty and operational risk. Maintaining grid stability under varying conditions is a complex task, and power flow simulators are commonly used to support operators by evaluating potential actions before implementation. However, traditional physical solvers, while accurate, are often too slow for near real-time use. Machine learning models have emerged as fast surrogates, and to improve their adherence to physical laws (e.g., Kirchhoff's laws), they are often trained with embedded constraints which are also known as physics-informed or hybrid models. This paper presents an ablation study to demystify hybridization strategies, ranging from incorporating physical constraints as regularization terms or unsupervised losses, and exploring model architectures from simple multilayer perceptrons to advanced graph-based networks enabling the direct optimization of physics equations. Using our custom benchmarking pipeline for hybrid models called LIPS, we evaluate these models across four dimensions: accuracy, physical compliance, industrial readiness, and out-of-distribution generalization. The results highlight how integrating physical knowledge impacts performance across these criteria. All the implementations are reproducible and provided in the corresponding Github page.
<div id='section'>Paperid: <span id='pid'>1354, <a href='https://arxiv.org/pdf/2509.14559.pdf' target='_blank'>https://arxiv.org/pdf/2509.14559.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Paolo Torrado, Anders Pearson, Jason Klein, Alexander Moscibroda, Joshua Smith
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14559">Radiolunadiff: Estimation of wireless network signal strength in lunar terrain</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a novel physics-informed deep learning architecture for predicting radio maps over lunar terrain. Our approach integrates a physics-based lunar terrain generator, which produces realistic topography informed by publicly available NASA data, with a ray-tracing engine to create a high-fidelity dataset of radio propagation scenarios. Building on this dataset, we introduce a triplet-UNet architecture, consisting of two standard UNets and a diffusion network, to model complex propagation effects. Experimental results demonstrate that our method outperforms existing deep learning approaches on our terrain dataset across various metrics.
<div id='section'>Paperid: <span id='pid'>1355, <a href='https://arxiv.org/pdf/2509.13686.pdf' target='_blank'>https://arxiv.org/pdf/2509.13686.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bingsheng Peng, Shutao Zhang, Xi Zheng, Ye Xue, Xinyu Qin, Tsung-Hui Chang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13686">RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate localized wireless channel modeling is a cornerstone of cellular network optimization, enabling reliable prediction of network performance during parameter tuning. Localized statistical channel modeling (LSCM) is the state-of-the-art channel modeling framework tailored for cellular network optimization. However, traditional LSCM methods, which infer the channel's Angular Power Spectrum (APS) from Reference Signal Received Power (RSRP) measurements, suffer from critical limitations: they are typically confined to single-cell, single-grid and single-carrier frequency analysis and fail to capture complex cross-domain interactions. To overcome these challenges, we propose RF-LSCM, a novel framework that models the channel APS by jointly representing large-scale signal attenuation and multipath components within a radiance field. RF-LSCM introduces a multi-domain LSCM formulation with a physics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the cross frequency generalization as well as a point-cloud-aided environment enhanced method to enable multi-cell and multi-grid channel modeling. Furthermore, to address the computational inefficiency of typical neural radiance fields, RF-LSCM leverages a low-rank tensor representation, complemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm. This efficient design significantly reduces GPU memory requirements and training time while preserving fine-grained accuracy. Extensive experiments on real-world multi-cell datasets demonstrate that RF-LSCM significantly outperforms state-of-the-art methods, achieving up to a 30% reduction in mean absolute error (MAE) for coverage prediction and a 22% MAE improvement by effectively fusing multi-frequency data.
<div id='section'>Paperid: <span id='pid'>1356, <a href='https://arxiv.org/pdf/2509.13425.pdf' target='_blank'>https://arxiv.org/pdf/2509.13425.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julian Evan Chrisnanto, Salsabila Rahma Alia, Yulison Herry Chrisnanto, Ferry Faizal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13425">Unified Spatiotemporal Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ecological systems exhibit complex multi-scale dynamics that challenge traditional modeling. New methods must capture temporal oscillations and emergent spatiotemporal patterns while adhering to conservation principles. We present the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework, a deep learning architecture integrating physics-informed neural networks (PINNs) and conservation laws to model predator-prey dynamics across dimensional scales. The framework provides a unified solution for both ordinary (ODE) and partial (PDE) differential equation systems, describing temporal cycles and reaction-diffusion patterns within a single neural network architecture. Our methodology uses automatic differentiation to enforce physics constraints and adaptive loss weighting to balance data fidelity with physical consistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9% correlation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures complex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94). Validation confirms conservation law adherence within 0.5% and shows a 10-50x computational speedup for inference compared to numerical solvers. USPIL also enables mechanistic understanding through interpretable physics constraints, facilitating parameter discovery and sensitivity analysis not possible with purely data-driven methods. Its ability to transition between dimensional formulations opens new avenues for multi-scale ecological modeling. These capabilities make USPIL a transformative tool for ecological forecasting, conservation planning, and understanding ecosystem resilience, establishing physics-informed deep learning as a powerful and scientifically rigorous paradigm.
<div id='section'>Paperid: <span id='pid'>1357, <a href='https://arxiv.org/pdf/2509.09135.pdf' target='_blank'>https://arxiv.org/pdf/2509.09135.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuefeng Wang, Lei Zhang, Henglin Pu, Ahmed H. Qureshi, Husheng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.09135">Continuous-Time Value Iteration for Multi-Agent Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing reinforcement learning (RL) methods struggle with complex dynamical systems that demand interactions at high frequencies or irregular time intervals. Continuous-time RL (CTRL) has emerged as a promising alternative by replacing discrete-time Bellman recursion with differential value functions defined as viscosity solutions of the Hamilton--Jacobi--Bellman (HJB) equation. While CTRL has shown promise, its applications have been largely limited to the single-agent domain. This limitation stems from two key challenges: (i) conventional solution methods for HJB equations suffer from the curse of dimensionality (CoD), making them intractable in high-dimensional systems; and (ii) even with HJB-based learning approaches, accurately approximating centralized value functions in multi-agent settings remains difficult, which in turn destabilizes policy training. In this paper, we propose a CT-MARL framework that uses physics-informed neural networks (PINNs) to approximate HJB-based value functions at scale. To ensure the value is consistent with its differential structure, we align value learning with value-gradient learning by introducing a Value Gradient Iteration (VGI) module that iteratively refines value gradients along trajectories. This improves gradient fidelity, in turn yielding more accurate values and stronger policy learning. We evaluate our method using continuous-time variants of standard benchmarks, including multi-agent particle environment (MPE) and multi-agent MuJoCo. Our results demonstrate that our approach consistently outperforms existing continuous-time RL baselines and scales to complex multi-agent dynamics.
<div id='section'>Paperid: <span id='pid'>1358, <a href='https://arxiv.org/pdf/2509.07245.pdf' target='_blank'>https://arxiv.org/pdf/2509.07245.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shalev Manor, Mohammad Kohandel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07245">IP-Basis PINNs: Efficient Multi-Query Inverse Parameter Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving inverse problems with Physics-Informed Neural Networks (PINNs) is computationally expensive for multi-query scenarios, as each new set of observed data requires a new, expensive training procedure. We present Inverse-Parameter Basis PINNs (IP-Basis PINNs), a meta-learning framework that extends the foundational work of Desai et al. (2022) to enable rapid and efficient inference for inverse problems. Our method employs an offline-online decomposition: a deep network is first trained offline to produce a rich set of basis functions that span the solution space of a parametric differential equation. For each new inverse problem online, this network is frozen, and solutions and parameters are inferred by training only a lightweight linear output layer against observed data. Key innovations that make our approach effective for inverse problems include: (1) a novel online loss formulation for simultaneous solution reconstruction and parameter identification, (2) a significant reduction in computational overhead via forward-mode automatic differentiation for PDE loss evaluation, and (3) a non-trivial validation and early-stopping mechanism for robust offline training. We demonstrate the efficacy of IP-Basis PINNs on three diverse benchmarks, including an extension to universal PINNs for unknown functional terms-showing consistent performance across constant and functional parameter estimation, a significant speedup per query over standard PINNs, and robust operation with scarce and noisy data.
<div id='section'>Paperid: <span id='pid'>1359, <a href='https://arxiv.org/pdf/2509.06574.pdf' target='_blank'>https://arxiv.org/pdf/2509.06574.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sadra Saremi, Amirhossein Ahmadkhan Kordbacheh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06574">Topological Regularization for Force Prediction in Active Particle Suspension with EGNN and Persistent Homology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Capturing the dynamics of active particles, i.e., small self-propelled agents that both deform and are deformed by a fluid in which they move is a formidable problem as it requires coupling fine scale hydrodynamics with large scale collective effects. So we present a multi-scale framework that combines the three learning-driven tools to learn in concert within one pipeline. We use high-resolution Lattice Boltzmann snapshots of fluid velocity and particle stresses in a periodic box as input to the learning pipeline. the second step takes the morphology and positions orientations of particles to predict pairwise interaction forces between them with a E(2)-equivariant graph neural network that necessarily respect flat symmetries. Then, a physics-informed neural network further updates these local estimates by summing over them with a stress data using Fourier feature mappings and residual blocks that is additionally regularized with a topological term (introduced by persistent homology) to penalize unrealistically tangled or spurious connections. In concert, these stages deliver an holistic highly-data driven full force network prediction empathizing on the physical underpinnings together with emerging multi-scale structure typical for active matter.
<div id='section'>Paperid: <span id='pid'>1360, <a href='https://arxiv.org/pdf/2509.04966.pdf' target='_blank'>https://arxiv.org/pdf/2509.04966.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arthur Bizzi, Leonardo M. Moreira, Márcio Marques, Leonardo Mendonça, Christian Júnior de Oliveira, Vitor Balestro, Lucas dos Santos Fernandez, Daniel Yukimura, Pavel Petrov, João M. Pereira, Tiago Novello, Lucas Nissenbaum
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.04966">Neuro-Spectral Architectures for Causal Physics-Informed Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful neural framework for solving partial differential equations (PDEs). However, standard MLP-based PINNs often fail to converge when dealing with complex initial-value problems, leading to solutions that violate causality and suffer from a spectral bias towards low-frequency components. To address these issues, we introduce NeuSA (Neuro-Spectral Architectures), a novel class of PINNs inspired by classical spectral methods, designed to solve linear and nonlinear PDEs with variable coefficients. NeuSA learns a projection of the underlying PDE onto a spectral basis, leading to a finite-dimensional representation of the dynamics which is then integrated with an adapted Neural ODE (NODE). This allows us to overcome spectral bias, by leveraging the high-frequency components enabled by the spectral representation; to enforce causality, by inheriting the causal structure of NODEs, and to start training near the target solution, by means of an initialization scheme based on classical methods. We validate NeuSA on canonical benchmarks for linear and nonlinear wave equations, demonstrating strong performance as compared to other architectures, with faster convergence, improved temporal consistency and superior predictive accuracy. Code and pretrained models will be released.
<div id='section'>Paperid: <span id='pid'>1361, <a href='https://arxiv.org/pdf/2509.04402.pdf' target='_blank'>https://arxiv.org/pdf/2509.04402.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tingyou Li, Zixin Xu, Zirui Gao, Hanfei Yan, Xiaojing Huang, Jizhou Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.04402">Learning neural representations for X-ray ptychography reconstruction with unknown probes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>X-ray ptychography provides exceptional nanoscale resolution and is widely applied in materials science, biology, and nanotechnology. However, its full potential is constrained by the critical challenge of accurately reconstructing images when the illuminating probe is unknown. Conventional iterative methods and deep learning approaches are often suboptimal, particularly under the low-signal conditions inherent to low-dose and high-speed experiments. These limitations compromise reconstruction fidelity and restrict the broader adoption of the technique. In this work, we introduce the Ptychographic Implicit Neural Representation (PtyINR), a self-supervised framework that simultaneously addresses the object and probe recovery problem. By parameterizing both as continuous neural representations, PtyINR performs end-to-end reconstruction directly from raw diffraction patterns without requiring any pre-characterization of the probe. Extensive evaluations demonstrate that PtyINR achieves superior reconstruction quality on both simulated and experimental data, with remarkable robustness under challenging low-signal conditions. Furthermore, PtyINR offers a generalizable, physics-informed framework for addressing probe-dependent inverse problems, making it applicable to a wide range of computational microscopy problems.
<div id='section'>Paperid: <span id='pid'>1362, <a href='https://arxiv.org/pdf/2509.03084.pdf' target='_blank'>https://arxiv.org/pdf/2509.03084.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Derek Jones, Yue Yang, Felice C. Lightstone, Niema Moshiri, Jonathan E. Allen, Tajana S. Rosing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03084">SurGBSA: Learning Representations From Molecular Dynamics Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised pretraining from static structures of drug-like compounds and proteins enable powerful learned feature representations. Learned features demonstrate state of the art performance on a range of predictive tasks including molecular properties, structure generation, and protein-ligand interactions. The majority of approaches are limited by their use of static structures and it remains an open question, how best to use atomistic molecular dynamics (MD) simulations to develop more generalized models to improve prediction accuracy for novel molecular structures. We present SURrogate mmGBSA (SurGBSA) as a new modeling approach for MD-based representation learning, which learns a surrogate function of the Molecular Mechanics Generalized Born Surface Area (MMGBSA). We show for the first time the benefits of physics-informed pre-training to train a surrogate MMGBSA model on a collection of over 1.4 million 3D trajectories collected from MD simulations of the CASF-2016 benchmark. SurGBSA demonstrates a dramatic 27,927x speedup versus a traditional physics-based single-point MMGBSA calculation while nearly matching single-point MMGBSA accuracy on the challenging pose ranking problem for identification of the correct top pose (-0.4% difference). Our work advances the development of molecular foundation models by showing model improvements when training on MD simulations. Models, code and training data are made publicly available.
<div id='section'>Paperid: <span id='pid'>1363, <a href='https://arxiv.org/pdf/2509.02091.pdf' target='_blank'>https://arxiv.org/pdf/2509.02091.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weiheng Zeng, Kun Wang, Ruoxi Lu, Tiegang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02091">CLINN: Conservation Law Informed Neural Network for Approximating Discontinuous Solutions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Neural Network (PINN) faces significant challenges when approximating solutions to conservation laws, particularly in ensuring conservation and accurately resolving discontinuities. To address these limitations, we propose Conservation Law-informed Neural Network (CLINN), a novel framework that incorporates the boundedness constraint, implicit solution form, and Rankine-Hugoniot condition of scalar conservation laws into the loss function, thereby enforcing exact conservation properties. Furthermore, we integrate a residual-based adaptive refinement (RAR) strategy to dynamically prioritize training near discontinuities, substantially improving the network's ability to capture sharp gradients. Numerical experiments are conducted on benchmark problems, including the inviscid Burgers equation, the Lighthill-Whitham-Richards (LWR) traffic flow model, and the Buckley-Leverett problem. Results demonstrate that CLINN achieves superior accuracy in resolving solution profiles and discontinuity locations while reducing numeral oscillations. Compared to conventional PINN, CLINN yields a maximum reduction of 99.2% in mean squared error (MSE).
<div id='section'>Paperid: <span id='pid'>1364, <a href='https://arxiv.org/pdf/2508.21618.pdf' target='_blank'>https://arxiv.org/pdf/2508.21618.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zuzanna Gawrysiak, Krzysztof Krawiec
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21618">Physics-Informed Spectral Modeling for Hyperspectral Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present PhISM, a physics-informed deep learning architecture that learns without supervision to explicitly disentangle hyperspectral observations and model them with continuous basis functions. \mname outperforms prior methods on several classification and regression benchmarks, requires limited labeled data, and provides additional insights thanks to interpretable latent representation.
<div id='section'>Paperid: <span id='pid'>1365, <a href='https://arxiv.org/pdf/2508.21618.pdf' target='_blank'>https://arxiv.org/pdf/2508.21618.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zuzanna Gawrysiak, Krzysztof Krawiec
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21618">Physics-Informed Spectral Modeling for Hyperspectral Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present PhISM, a physics-informed deep learning architecture that learns without supervision to explicitly disentangle hyperspectral observations and model them with continuous basis functions. \mname outperforms prior methods on several classification and regression benchmarks, requires limited labeled data, and provides additional insights thanks to interpretable latent representation.
<div id='section'>Paperid: <span id='pid'>1366, <a href='https://arxiv.org/pdf/2508.21571.pdf' target='_blank'>https://arxiv.org/pdf/2508.21571.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bangti Jin, Longjun Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21571">Convergence of Stochastic Gradient Methods for Wide Two-Layer Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics informed neural networks (PINNs) represent a very popular class of neural solvers for partial differential equations. In practice, one often employs stochastic gradient descent type algorithms to train the neural network. Therefore, the convergence guarantee of stochastic gradient descent is of fundamental importance. In this work, we establish the linear convergence of stochastic gradient descent / flow in training over-parameterized two layer PINNs for a general class of activation functions in the sense of high probability. These results extend the existing result [18] in which gradient descent was analyzed. The challenge of the analysis lies in handling the dynamic randomness introduced by stochastic optimization methods. The key of the analysis lies in ensuring the positive definiteness of suitable Gram matrices during the training. The analysis sheds insight into the dynamics of the optimization process, and provides guarantees on the neural networks trained by stochastic algorithms.
<div id='section'>Paperid: <span id='pid'>1367, <a href='https://arxiv.org/pdf/2508.21571.pdf' target='_blank'>https://arxiv.org/pdf/2508.21571.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bangti Jin, Longjun Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.21571">Convergence of Stochastic Gradient Methods for Wide Two-Layer Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics informed neural networks (PINNs) represent a very popular class of neural solvers for partial differential equations. In practice, one often employs stochastic gradient descent type algorithms to train the neural network. Therefore, the convergence guarantee of stochastic gradient descent is of fundamental importance. In this work, we establish the linear convergence of stochastic gradient descent / flow in training over-parameterized two layer PINNs for a general class of activation functions in the sense of high probability. These results extend the existing result [18] in which gradient descent was analyzed. The challenge of the analysis lies in handling the dynamic randomness introduced by stochastic optimization methods. The key of the analysis lies in ensuring the positive definiteness of suitable Gram matrices during the training. The analysis sheds insight into the dynamics of the optimization process, and provides guarantees on the neural networks trained by stochastic algorithms.
<div id='section'>Paperid: <span id='pid'>1368, <a href='https://arxiv.org/pdf/2508.19398.pdf' target='_blank'>https://arxiv.org/pdf/2508.19398.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junkai Wang, Yuxuan Zhao, Mi Zhou, Fumin Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19398">Learning Robust Regions of Attraction Using Rollout-Enhanced Physics-Informed Neural Networks with Policy Iteration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The region of attraction is a key metric of the robustness of systems. This paper addresses the numerical solution of the generalized Zubov's equation, which produces a special Lyapunov function characterizing the robust region of attraction for perturbed systems. To handle the highly nonlinear characteristic of the generalized Zubov's equation, we propose a physics-informed neural network framework that employs a policy iteration training scheme with rollout to approximate the viscosity solution. In addition to computing the optimal disturbance during the policy improvement process, we incorporate neural network-generated value estimates as anchor points to facilitate the training procedure to prevent singularities in both low- and high-dimensional systems. Numerical simulations validate the effectiveness of the proposed approach.
<div id='section'>Paperid: <span id='pid'>1369, <a href='https://arxiv.org/pdf/2508.19031.pdf' target='_blank'>https://arxiv.org/pdf/2508.19031.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vemula Sreenath, Filippo Gatti, Pierre Jehel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19031">Breaking the Black Box: Inherently Interpretable Physics-Informed Machine Learning for Imbalanced Seismic Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ground motion models (GMMs) predict how strongly the ground will shake during an earthquake. They are essential for structural analysis, seismic design, and seismic risk assessment studies. Traditional machine learning (ML) approaches are popular to develop GMMs, due to large earthquake databases worldwide. However, they operate as "black boxes," which are hard to interpret and trust, limiting their use in high-stake decisions. Additionally, these databases suffer from significant data imbalances: fewer large, critically damaging records near the fault compared to abundant, less severely damaging distant records. These two limitations are addressed in this work by developing a transparent ML architecture using the HazBinLoss function. Each input (e.g., magnitude, distance, their interaction term, etc.) is processed separately and added linearly to obtain the output, resulting in exact contribution of each term. The HazBinLoss function assigns higher weights to critical near-field large magnitude records and lower weights to less-critical far-field smaller magnitude records, during training to prevent underprediction of the most damaging scenarios. Our model captures known seismological principles and achieves comparable performance with established GMMs while maintaining transparency. This framework enables broader adoption of ML-based approaches for risk assessment studies and disaster planning.
<div id='section'>Paperid: <span id='pid'>1370, <a href='https://arxiv.org/pdf/2508.17902.pdf' target='_blank'>https://arxiv.org/pdf/2508.17902.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuzhen Li, Liang Li, StÃ©phane Lanteri, Bin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17902">Spectral-Prior Guided Multistage Physics-Informed Neural Networks for Highly Accurate PDE Solutions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are becoming a popular method for solving PDEs, due to their mesh-free nature and their ability to handle high-dimensional problems where traditional numerical solvers often struggle. Despite their promise, the practical application of PINNs is still constrained by several fac- tors, a primary one being their often-limited accuracy. This paper is dedicated to enhancing the accuracy of PINNs by introducing spectral-prior guided multistage strategy. We propose two methods: Spectrum- Informed Multistage Physics-Informed Neural Networks (SI-MSPINNs) and Multistage Physics-Informed Neural Networks with Spectrum Weighted Random Fourier Features (RFF-MSPINNs). The SI-MSPINNs integrate the core mechanism of Spectrum-Informed Multistage Neural Network (SI-MSNNs) and PINNs, in which we extract the Dominant Spectral Pattern (DSP) of residuals by the discrete Fourier transform. This DSP guides the network initialization to alleviate spectral bias, and gradually optimizes the resolution accuracy using a multistage strategy. The RFF-MSPINNs combines random Fourier features with spectral weighting methods, dynamically adjusting the frequency sampling distribution based on the residual power spectral density, allowing the network to prioritize learning high-energy physical modes. Through experimental verification of the Burgers equation and the Helmholtz equation, we show that both models significantly improve the accuracy of the original PINNs.
<div id='section'>Paperid: <span id='pid'>1371, <a href='https://arxiv.org/pdf/2508.15530.pdf' target='_blank'>https://arxiv.org/pdf/2508.15530.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaogang Yang, Dawit Hailu, VojtÄch Kulvait, Thomas Jentschke, Silja Flenner, Imke Greving, Stuart I. Campbell, Johannes Hagemann, Christian G. Schroer, Tak Ming Wong, Julian Moosmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15530">Self-supervised physics-informed generative networks for phase retrieval from a single X-ray hologram</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>X-ray phase contrast imaging significantly improves the visualization of structures with weak or uniform absorption, broadening its applications across a wide range of scientific disciplines. Propagation-based phase contrast is particularly suitable for time- or dose-critical in vivo/in situ/operando (tomography) experiments because it requires only a single intensity measurement. However, the phase information of the wave field is lost during the measurement and must be recovered. Conventional algebraic and iterative methods often rely on specific approximations or boundary conditions that may not be met by many samples or experimental setups. In addition, they require manual tuning of reconstruction parameters by experts, making them less adaptable for complex or variable conditions. Here we present a self-learning approach for solving the inverse problem of phase retrieval in the near-field regime of Fresnel theory using a single intensity measurement (hologram). A physics-informed generative adversarial network is employed to reconstruct both the phase and absorbance of the unpropagated wave field in the sample plane from a single hologram. Unlike most deep learning approaches for phase retrieval, our approach does not require paired, unpaired, or simulated training data. This significantly broadens the applicability of our approach, as acquiring or generating suitable training data remains a major challenge due to the wide variability in sample types and experimental configurations. The algorithm demonstrates robust and consistent performance across diverse imaging conditions and sample types, delivering quantitative, high-quality reconstructions for both simulated data and experimental datasets acquired at beamline P05 at PETRA III (DESY, Hamburg), operated by Helmholtz-Zentrum Hereon. Furthermore, it enables the simultaneous retrieval of both phase and absorption information.
<div id='section'>Paperid: <span id='pid'>1372, <a href='https://arxiv.org/pdf/2508.15343.pdf' target='_blank'>https://arxiv.org/pdf/2508.15343.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rishi Mishra, Smriti, Ganapathy Krishnamurthi, Balaji Srinivasan, Sundararajan Natarajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15343">Eig-PIELM: A Mesh-Free Approach for Efficient Eigen-Analysis with Physics-Informed Extreme Learning Machines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, a novel Eig-PIELM framework is proposed that extends physics-informed extreme learning machine for an efficient and accurate solution of linear eigenvalue problems. The method reformulates the governing differential equations into a compact algebraic system solvable in a single step. Boundary conditions are enforced exactly via an algebraic projection onto the boundary-admissible subspace, eliminating the computational overhead of penalty parameters, and backpropagation while preserving the computational advantages of extreme learning machines. The proposed framework is mesh-free and yields both eigenvalues and mode shapes simultaneously in one linear solve. The robustness and accuracy of the proposed framework is demonstrated through a range of benchmark problems. We believe that the mesh-free nature, solution structure and accuracy of Eig-PIELM makes it particularly valuable for parametric studies in mechanical, acoustic, and electromechanical systems where rapid frequency spectrum analysis is critical.
<div id='section'>Paperid: <span id='pid'>1373, <a href='https://arxiv.org/pdf/2508.14137.pdf' target='_blank'>https://arxiv.org/pdf/2508.14137.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amalie Roark, Serio Agriesti, Francisco Camara Pereira, Guido Cantelmo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14137">Learning to Learn the Macroscopic Fundamental Diagram using Physics-Informed and meta Machine Learning techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Macroscopic Fundamental Diagram is a popular tool used to describe traffic dynamics in an aggregated way, with applications ranging from traffic control to incident analysis. However, estimating the MFD for a given network requires large numbers of loop detectors, which is not always available in practice. This article proposes a framework harnessing meta-learning, a subcategory of machine learning that trains models to understand and adapt to new tasks on their own, to alleviate the data scarcity challenge. The developed model is trained and tested by leveraging data from multiple cities and exploiting it to model the MFD of other cities with different shares of detectors and topological structures. The proposed meta-learning framework is applied to an ad-hoc Multi-Task Physics-Informed Neural Network, specifically designed to estimate the MFD. Results show an average MSE improvement in flow prediction ranging between ~ 17500 and 36000 (depending on the subset of loop detectors tested). The meta-learning framework thus successfully generalizes across diverse urban settings and improves performance on cities with limited data, demonstrating the potential of using meta-learning when a limited number of detectors is available. Finally, the proposed framework is validated against traditional transfer learning approaches and tested with FitFun, a non-parametric model from the literature, to prove its transferability.
<div id='section'>Paperid: <span id='pid'>1374, <a href='https://arxiv.org/pdf/2508.12593.pdf' target='_blank'>https://arxiv.org/pdf/2508.12593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhihao Li, Ting Wang, Guojian Zou, Ruofei Wang, Ye Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12593">Physics-informed deep operator network for traffic state estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traffic state estimation (TSE) fundamentally involves solving high-dimensional spatiotemporal partial differential equations (PDEs) governing traffic flow dynamics from limited, noisy measurements. While Physics-Informed Neural Networks (PINNs) enforce PDE constraints point-wise, this paper adopts a physics-informed deep operator network (PI-DeepONet) framework that reformulates TSE as an operator learning problem. Our approach trains a parameterized neural operator that maps sparse input data to the full spatiotemporal traffic state field, governed by the traffic flow conservation law. Crucially, unlike PINNs that enforce PDE constraints point-wise, PI-DeepONet integrates traffic flow conservation model and the fundamental diagram directly into the operator learning process, ensuring physical consistency while capturing congestion propagation, spatial correlations, and temporal evolution. Experiments on the NGSIM dataset demonstrate superior performance over state-of-the-art baselines. Further analysis reveals insights into optimal function generation strategies and branch network complexity. Additionally, the impact of input function generation methods and the number of functions on model performance is explored, highlighting the robustness and efficacy of proposed framework.
<div id='section'>Paperid: <span id='pid'>1375, <a href='https://arxiv.org/pdf/2508.11542.pdf' target='_blank'>https://arxiv.org/pdf/2508.11542.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicole Aretz, Karen Willcox
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.11542">Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a data-driven, nested Operator Inference (OpInf) approach for learning physics-informed reduced-order models (ROMs) from snapshot data of high-dimensional dynamical systems. The approach exploits the inherent hierarchy within the reduced space to iteratively construct initial guesses for the OpInf learning problem that prioritize the interactions of the dominant modes. The initial guess computed for any target reduced dimension corresponds to a ROM with provably smaller or equal snapshot reconstruction error than with standard OpInf. Moreover, our nested OpInf algorithm can be warm-started from previously learned models, enabling versatile application scenarios involving dynamic basis and model form updates. We demonstrate the performance of our algorithm on a cubic heat conduction problem, with nested OpInf achieving a four times smaller error than standard OpInf at a comparable offline time. Further, we apply nested OpInf to a large-scale, parameterized model of the Greenland ice sheet where, despite model form approximation errors, it learns a ROM with, on average, 3% error and computational speed-up factor above 19,000.
<div id='section'>Paperid: <span id='pid'>1376, <a href='https://arxiv.org/pdf/2508.10718.pdf' target='_blank'>https://arxiv.org/pdf/2508.10718.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Shan Lee, I Hang Kwok, Kam Ian Leong, Chi Kiu Althina Chau, Kei Chon Sio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.10718">Symmetry-Constrained Multi-Scale Physics-Informed Neural Networks for Graphene Electronic Band Structure Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of electronic band structures in two-dimensional materials remains a fundamental challenge, with existing methods struggling to balance computational efficiency and physical accuracy. We present the Symmetry-Constrained Multi-Scale Physics-Informed Neural Network (SCMS-PINN) v35, which directly learns graphene band structures while rigorously enforcing crystallographic symmetries through a multi-head architecture. Our approach introduces three specialized ResNet-6 pathways -- K-head for Dirac physics, M-head for saddle points, and General head for smooth interpolation -- operating on 31 physics-informed features extracted from k-points. Progressive Dirac constraint scheduling systematically increases the weight parameter from 5.0 to 25.0, enabling hierarchical learning from global topology to local critical physics. Training on 10,000 k-points over 300 epochs achieves 99.99\% reduction in training loss (34.597 to 0.003) with validation loss of 0.0085. The model predicts Dirac point gaps within 30.3 $Î¼$eV of theoretical zero and achieves average errors of 53.9 meV (valence) and 40.5 meV (conduction) across the Brillouin zone. All twelve C$_{6v}$ operations are enforced through systematic averaging, guaranteeing exact symmetry preservation. This framework establishes a foundation for extending physics-informed learning to broader two-dimensional materials for accelerated discovery.
<div id='section'>Paperid: <span id='pid'>1377, <a href='https://arxiv.org/pdf/2508.09627.pdf' target='_blank'>https://arxiv.org/pdf/2508.09627.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Subhankar Sarkar, Souvik Chakraborty
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.09627">Physics- and geometry-aware spatio-spectral graph neural operator for time-independent and time-dependent PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving partial differential equations (PDEs) efficiently and accurately remains a cornerstone challenge in science and engineering, especially for problems involving complex geometries and limited labeled data. We introduce a Physics- and Geometry- Aware Spatio-Spectral Graph Neural Operator ($Ï$G-Sp$^2$GNO) for learning the solution operators of time-independent and time-dependent PDEs. The proposed approach first improves upon the recently developed Sp$^2$GNO by enabling geometry awareness and subsequently exploits the governing physics to learn the underlying solution operator in a simulation-free setup. While the spatio-spectral structure present in the proposed architecture allows multiscale learning, two separate strategies for enabling geometry awareness is introduced in this paper. For time dependent problems, we also introduce a novel hybrid physics informed loss function that combines higher-order time-marching scheme with upscaled theory inspired stochastic projection scheme. This allows accurate integration of the physics-information into the loss function. The performance of the proposed approach is illustrated on number of benchmark examples involving regular and complex domains, variation in geometry during inference, and time-independent and time-dependent problems. The results obtained illustrate the efficacy of the proposed approach as compared to the state-of-the-art physics-informed neural operator algorithms in the literature.
<div id='section'>Paperid: <span id='pid'>1378, <a href='https://arxiv.org/pdf/2508.06122.pdf' target='_blank'>https://arxiv.org/pdf/2508.06122.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ting-Shuo Yo, Shih-Hao Su, Chien-Ming Wu, Wei-Ting Chen, Jung-Lien Chu, Chiao-Wei Chang, Hung-Chi Kuo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06122">Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study applied representation learning algorithms to satellite images and evaluated the learned latent spaces with classifications of various weather events. The algorithms investigated include the classical linear transformation, i.e., principal component analysis (PCA), state-of-the-art deep learning method, i.e., convolutional autoencoder (CAE), and a residual network pre-trained with large image datasets (PT). The experiment results indicated that the latent space learned by CAE consistently showed higher threat scores for all classification tasks. The classifications with PCA yielded high hit rates but also high false-alarm rates. In addition, the PT performed exceptionally well at recognizing tropical cyclones but was inferior in other tasks. Further experiments suggested that representations learned from higher-resolution datasets are superior in all classification tasks for deep-learning algorithms, i.e., CAE and PT. We also found that smaller latent space sizes had minor impact on the classification task's hit rate. Still, a latent space dimension smaller than 128 caused a significantly higher false alarm rate. Though the CAE can learn latent spaces effectively and efficiently, the interpretation of the learned representation lacks direct connections to physical attributions. Therefore, developing a physics-informed version of CAE can be a promising outlook for the current work.
<div id='section'>Paperid: <span id='pid'>1379, <a href='https://arxiv.org/pdf/2508.03730.pdf' target='_blank'>https://arxiv.org/pdf/2508.03730.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kefei Wu, Baihua Zheng, Weiwei Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03730">PILOT-C: Physics-Informed Low-Distortion Optimal Trajectory Compression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Location-aware devices continuously generate massive volumes of trajectory data, creating demand for efficient compression. Line simplification is a common solution but typically assumes 2D trajectories and ignores time synchronization and motion continuity. We propose PILOT-C, a novel trajectory compression framework that integrates frequency-domain physics modeling with error-bounded optimization. Unlike existing line simplification methods, PILOT-C supports trajectories in arbitrary dimensions, including 3D, by compressing each spatial axis independently. Evaluated on four real-world datasets, PILOT-C achieves superior performance across multiple dimensions. In terms of compression ratio, PILOT-C outperforms CISED-W, the current state-of-the-art SED-based line simplification algorithm, by an average of 19.2%. For trajectory fidelity, PILOT-C achieves an average of 32.6% reduction in error compared to CISED-W. Additionally, PILOT-C seamlessly extends to three-dimensional trajectories while maintaining the same computational complexity, achieving a 49% improvement in compression ratios over SQUISH-E, the most efficient line simplification algorithm on 3D datasets.
<div id='section'>Paperid: <span id='pid'>1380, <a href='https://arxiv.org/pdf/2508.03326.pdf' target='_blank'>https://arxiv.org/pdf/2508.03326.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moises Sierpe, Ernesto Castillo, Hernan Mella, Felipe Galarce
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03326">Estimation of Hemodynamic Parameters via Physics Informed Neural Networks including Hematocrit Dependent Rheology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) show significant potential for solving inverse problems, especially when observations are limited and sparse, provided that the relevant physical equations are known. We use PINNs to estimate smooth velocity and pressure fields from synthetic 4D flow Magnetic Resonance Imaging (MRI) data. We analyze five non-Newtonian dynamic 3D blood flow cases within a realistic aortic model, covering a range of hematocrit values from anemic to polycythemic conditions. To enhance state estimation results, we consider various design and training techniques for PINNs, including adaptive loss balancing, curriculum training, and a realistic measurement operator. Regarding blood rheology, the PINN approach accurately estimates viscosity globally and locally under peak systolic conditions. It also provides a clear pattern recognition for diastolic stages. Regarding mass conservation, PINN estimations effectively reproduce the bifurcation of flow through the different branches of the aorta, demonstrate an excellent representation of the non-slip conditions at the walls, and accurately estimate pressure drops with relative errors below the 5% in the whole pressure field. We test our pressure drop estimations against the state of the art Virtual Work Energy Relative Pressure (vWERP) estimator, and we observe how our results outperform vWERP in terms of both accuracy and time resolution. Additionally, we find that the best results are achieved by computing the velocity field using the PINN, which is then integrated into the vWERP framework, leading to time super-sampled and high-order approximations, with a clinically admissible accuracy.
<div id='section'>Paperid: <span id='pid'>1381, <a href='https://arxiv.org/pdf/2508.03120.pdf' target='_blank'>https://arxiv.org/pdf/2508.03120.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiangyou Zhu, Hongyu Deng, He Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03120">Can Large Language Models Identify Materials from Radar Signals?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately identifying the material composition of objects is a critical capability for AI robots powered by large language models (LLMs) to perform context-aware manipulation. Radar technologies offer a promising sensing modality for material recognition task. When combined with deep learning, radar technologies have demonstrated strong potential in identifying the material of various objects. However, existing radar-based solutions are often constrained to closed-set object categories and typically require task-specific data collection to train deep learning models, largely limiting their practical applicability. This raises an important question: Can we leverage the powerful reasoning capabilities of pre-trained LLMs to directly infer material composition from raw radar signals? Answering this question is non-trivial due to the inherent redundancy of radar signals and the fact that pre-trained LLMs have no prior exposure to raw radar data during training. To address this, we introduce LLMaterial, the first study to investigate the feasibility of using LLM to identify materials directly from radar signals. First, we introduce a physics-informed signal processing pipeline that distills high-redundancy radar raw data into a set of compact intermediate parameters that encapsulate the material's intrinsic characteristics. Second, we adopt a retrieval-augmented generation (RAG) strategy to provide the LLM with domain-specific knowledge, enabling it to interpret and reason over the extracted intermediate parameters. Leveraging this integration, the LLM is empowered to perform step-by-step reasoning on the condensed radar features, achieving open-set material recognition directly from raw radar signals. Preliminary results show that LLMaterial can effectively distinguish among a variety of common materials, highlighting its strong potential for real-world material identification applications.
<div id='section'>Paperid: <span id='pid'>1382, <a href='https://arxiv.org/pdf/2508.02712.pdf' target='_blank'>https://arxiv.org/pdf/2508.02712.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pallock Halder, Satyajit Mojumder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02712">Physics-guided denoiser network for enhanced additive manufacturing data quality</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern engineering systems are increasingly equipped with sensors for real-time monitoring and decision-making. However, the data collected by these sensors is often noisy and difficult to interpret, limiting its utility for control and diagnostics. In this work, we propose a physics-informed denoising framework that integrates energy-based model and Fisher score regularization to jointly reduce data noise and enforce physical consistency with a physics-based model. The approach is first validated on benchmark problems, including the simple harmonic oscillator, Burgers' equation, and Laplace's equation, across varying noise levels. We then apply the denoising framework to real thermal emission data from laser powder bed fusion (LPBF) additive manufacturing experiments, using a trained Physics-Informed Neural Network (PINN) surrogate model of the LPBF process to guide denoising. Results show that the proposed method outperforms baseline neural network denoisers, effectively reducing noise under a range of LPBF processing conditions. This physics-guided denoising strategy enables robust, real-time interpretation of low-cost sensor data, facilitating predictive control and improved defect mitigation in additive manufacturing.
<div id='section'>Paperid: <span id='pid'>1383, <a href='https://arxiv.org/pdf/2508.01463.pdf' target='_blank'>https://arxiv.org/pdf/2508.01463.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ran Bi, Weibing Deng, Yameng Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.01463">Extended Interface Physics-Informed Neural Networks Method for Moving Interface Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful class of mesh-free numerical methods for solving partial differential equations (PDEs), particularly those involving complex geometries. In this work, we present an innovative Extended Interface Physics-Informed Neural Network (XI-PINN) framework specifically designed to solve parabolic moving interface problems. The proposed approach incorporates a level set function to characterize the interface, which can be obtained either directly or through a neural network solution. We conduct a rigorous a priori error analysis for the XI-PINN method, providing error bounds for the approximation. Leveraging the Neural Tangent Kernel (NTK) theory, we further demonstrate that XI-PINN achieves a faster training convergence rate compared to conventional PINN approaches. The method's versatility is further demonstrated by its application to the Oseen equations. We perform comprehensive numerical experiments to validate the efficacy, accuracy, and robustness of the proposed framework.
<div id='section'>Paperid: <span id='pid'>1384, <a href='https://arxiv.org/pdf/2508.00918.pdf' target='_blank'>https://arxiv.org/pdf/2508.00918.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Herman, Olivia J. Pinon Fischer, Dimitri N. Mavris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00918">Predictive calibration for digital sun sensors using sparse submanifold convolutional neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent developments in AI techniques for space applications mirror the success achieved in terrestrial applications. Machine learning, which excels in data rich environments, is particularly well suited to space-based computer vision applications, such as space optical attitude sensing. Of these sensors, digital sun sensors (DSS) are one of the most common and important sensors for spacecraft attitude determination. The main challenge in using the DSS for attitude estimation are sensor errors, which limit the overall achievable estimation accuracy. However, the traditional sun sensor calibration process is costly, slow, labor-intensive and inefficient. These limitations motivate the use of AI techniques to enable more accurate and efficient DSS calibration.
  The objective of this work is to develop an end-to-end predictive calibration methodology for digital sun sensors to solve 2-axis state estimates utilizing a sparse submanifold convolutional neural network (SSCNN). We find that the proposed framework can achieve state-of-the-art performance on synthetic data with a mean accuracy of 0.005Â° for the two sun angle estimates. Furthermore, the model is highly capable of implicitly learning complex noise patterns and handling mixed noise types, thereby greatly improving the model robustness and accuracy to real-world applications. The main contributions of this work are: (1) the first application (to our knowledge) of a CNN regression model to the problem of DSS predictive calibration, (2) the introduction of a fused end-to-end training approach for DSS calibration, (3) the creation of a publicly available physics-informed synthetic dataset and simulation for DSS training images, and (4) the evaluation of the performance of the deep learning approach for various mask configurations.
<div id='section'>Paperid: <span id='pid'>1385, <a href='https://arxiv.org/pdf/2507.22959.pdf' target='_blank'>https://arxiv.org/pdf/2507.22959.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Salah A. Faroughi, Farinaz Mostajeran, Amin Hamed Mashhadzadeh, Shirko Faroughi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.22959">Scientific Machine Learning with Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The field of scientific machine learning, which originally utilized multilayer perceptrons (MLPs), is increasingly adopting Kolmogorov-Arnold Networks (KANs) for data encoding. This shift is driven by the limitations of MLPs, including poor interpretability, fixed activation functions, and difficulty capturing localized or high-frequency features. KANs address these issues with enhanced interpretability and flexibility, enabling more efficient modeling of complex nonlinear interactions and effectively overcoming the constraints associated with conventional MLP architectures. This review categorizes recent progress in KAN-based models across three distinct perspectives: (i) data-driven learning, (ii) physics-informed modeling, and (iii) deep operator learning. Each perspective is examined through the lens of architectural design, training strategies, application efficacy, and comparative evaluation against MLP-based counterparts. By benchmarking KANs against MLPs, we highlight consistent improvements in accuracy, convergence, and spectral representation, clarifying KANs' advantages in capturing complex dynamics while learning more effectively. Finally, this review identifies critical challenges and open research questions in KAN development, particularly regarding computational efficiency, theoretical guarantees, hyperparameter tuning, and algorithm complexity. We also outline future research directions aimed at improving the robustness, scalability, and physical consistency of KAN-based frameworks.
<div id='section'>Paperid: <span id='pid'>1386, <a href='https://arxiv.org/pdf/2507.22279.pdf' target='_blank'>https://arxiv.org/pdf/2507.22279.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Timothy Jacob Huber, Madhur Tiwari, Camilo A. Riano-Rios
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.22279">Physics-Informed EvolveGCN: Satellite Prediction for Multi Agent Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the rapidly evolving domain of autonomous systems, interaction among agents within a shared environment is both inevitable and essential for enhancing overall system capabilities. A key requirement in such multi-agent systems is the ability of each agent to reliably predict the future positions of its nearest neighbors. Traditionally, graphs and graph theory have served as effective tools for modeling inter agent communication and relationships. While this approach is widely used, the present work proposes a novel method that leverages dynamic graphs in a forward looking manner. Specifically, the employment of EvolveGCN, a dynamic graph convolutional network, to forecast the evolution of inter-agent relationships over time. To improve prediction accuracy and ensure physical plausibility, this research incorporates physics constrained loss functions based on the Clohessy-Wiltshire equations of motion. This integrated approach enhances the reliability of future state estimations in multi-agent scenarios.
<div id='section'>Paperid: <span id='pid'>1387, <a href='https://arxiv.org/pdf/2507.20929.pdf' target='_blank'>https://arxiv.org/pdf/2507.20929.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Shan Lee, Chi Kiu Althina Chau, Kei Chon Sio, Kam Ian Leong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.20929">Breaking the Precision Ceiling in Physics-Informed Neural Networks: A Hybrid Fourier-Neural Architecture for Ultra-High Accuracy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have plateaued at errors of $10^{-3}$-$10^{-4}$ for fourth-order partial differential equations, creating a perceived precision ceiling that limits their adoption in engineering applications. We break through this barrier with a hybrid Fourier-neural architecture for the Euler-Bernoulli beam equation, achieving unprecedented L2 error of $1.94 \times 10^{-7}$-a 17-fold improvement over standard PINNs and \(15-500\times\) better than traditional numerical methods. Our approach synergistically combines a truncated Fourier series capturing dominant modal behavior with a deep neural network providing adaptive residual corrections. A systematic harmonic optimization study revealed a counter-intuitive discovery: exactly 10 harmonics yield optimal performance, with accuracy catastrophically degrading from $10^{-7}$ to $10^{-1}$ beyond this threshold. The two-phase optimization strategy (Adam followed by L-BFGS) and adaptive weight balancing enable stable ultra-precision convergence. GPU-accelerated implementation achieves sub-30-minute training despite fourth-order derivative complexity. By addressing 12 critical gaps in existing approaches-from architectural rigidity to optimization landscapes-this work demonstrates that ultra-precision is achievable through proper design, opening new paradigms for scientific computing where machine learning can match or exceed traditional numerical methods.
<div id='section'>Paperid: <span id='pid'>1388, <a href='https://arxiv.org/pdf/2507.18346.pdf' target='_blank'>https://arxiv.org/pdf/2507.18346.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Etienne Zeudong, Elsa Cardoso-Bihlo, Alex Bihlo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18346">Low-rank adaptive physics-informed HyperDeepONets for solving differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>HyperDeepONets were introduced in Lee, Cho and Hwang [ICLR, 2023] as an alternative architecture for operator learning, in which a hypernetwork generates the weights for the trunk net of a DeepONet. While this improves expressivity, it incurs high memory and computational costs due to the large number of output parameters required. In this work we introduce, in the physics-informed machine learning setting, a variation, PI-LoRA-HyperDeepONets, which leverage low-rank adaptation (LoRA) to reduce complexity by decomposing the hypernetwork's output layer weight matrix into two smaller low-rank matrices. This reduces the number of trainable parameters while introducing an extra regularization of the trunk networks' weights. Through extensive experiments on both ordinary and partial differential equations we show that PI-LoRA-HyperDeepONets achieve up to 70\% reduction in parameters and consistently outperform regular HyperDeepONets in terms of predictive accuracy and generalization.
<div id='section'>Paperid: <span id='pid'>1389, <a href='https://arxiv.org/pdf/2507.11640.pdf' target='_blank'>https://arxiv.org/pdf/2507.11640.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Veronika TrÃ¡vnÃ­kovÃ¡, Eric von Lieres, Marek Behr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11640">Quantifying data needs in surrogate modeling for flow fields in two-dimensional stirred tanks with physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Stirred tanks are vital in chemical and biotechnological processes, particularly as bioreactors. Although computational fluid dynamics (CFD) is widely used to model the flow in stirred tanks, its high computational cost$-$especially in multi-query scenarios for process design and optimization$-$drives the need for efficient data-driven surrogate models. However, acquiring sufficiently large datasets can be costly. Physics-informed neural networks (PINNs) offer a promising solution to reduce data requirements while maintaining accuracy by embedding underlying physics into neural network (NN) training. This study quantifies the data requirements of vanilla PINNs for developing surrogate models of a flow field in a 2D stirred tank. We compare these requirements with classical supervised neural networks and boundary-informed neural networks (BINNs). Our findings demonstrate that surrogate models can achieve prediction errors around 3% across Reynolds numbers from 50 to 5000 using as few as six datapoints. Moreover, employing an approximation of the velocity profile in place of real data labels leads to prediction errors of around 2.5%. These results indicate that even with limited or approximate datasets, PINNs can be effectively trained to deliver high accuracy comparable to high-fidelity data.
<div id='section'>Paperid: <span id='pid'>1390, <a href='https://arxiv.org/pdf/2507.09757.pdf' target='_blank'>https://arxiv.org/pdf/2507.09757.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chunyan Li, Wenkai Yu, Qi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09757">Energy Dissipation Rate Guided Adaptive Sampling for Physics-Informed Neural Networks: Resolving Surface-Bulk Dynamics in Allen-Cahn Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce the Energy Dissipation Rate guided Adaptive Sampling (EDRAS) strategy, a novel method that substantially enhances the performance of Physics-Informed Neural Networks (PINNs) in solving thermodynamically consistent partial differential equations (PDEs) over arbitrary domains. EDRAS leverages the local energy dissipation rate density as a guiding metric to identify and adaptively re-sample critical collocation points from both the interior and boundary of the computational domain. This dynamical sampling approach improves the accuracy of residual-based PINNs by aligning the training process with the underlying physical structure of the system. In this study, we demonstrate the effectiveness of EDRAS using the Allen-Cahn phase field model in irregular geometries, achieving up to a sixfold reduction in the relative mean square error compared to traditional residual-based adaptive refinement (RAR) methods. Moreover, we compare EDRAS with other residual-based adaptive sampling approaches and show that EDRAS is not only computationally more efficient but also more likely to identify high-impact collocation points. Through numerical solutions of the Allen-Cahn equation with both static (Neumann) and dynamic boundary conditions in 2D disk- and ellipse-shaped domains solved using PINN coupled with EDRAS, we gain significant insights into how dynamic boundary conditions influence bulk phase evolution and thermodynamic behavior. The proposed approach offers an effective, physically informed enhancement to PINN frameworks for solving thermodynamically consistent models, making PINN a robust and versatile computational tool for investigating complex thermodynamic processes in arbitrary geometries.
<div id='section'>Paperid: <span id='pid'>1391, <a href='https://arxiv.org/pdf/2507.08124.pdf' target='_blank'>https://arxiv.org/pdf/2507.08124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashfaq Iftakher, Rahul Golder, Bimol Nath Roy, M. M. Faruque Hasan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08124">Physics-Informed Neural Networks with Hard Nonlinear Equality and Inequality Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional physics-informed neural networks (PINNs) do not guarantee strict constraint satisfaction. This is problematic in engineering systems where minor violations of governing laws can degrade the reliability and consistency of model predictions. In this work, we introduce KKT-Hardnet, a neural network architecture that enforces linear and nonlinear equality and inequality constraints up to machine precision. It leverages a differentiable projection onto the feasible region by solving Karush-Kuhn-Tucker (KKT) conditions of a distance minimization problem. Furthermore, we reformulate the nonlinear KKT conditions via a log-exponential transformation to construct a sparse system with linear and exponential terms. We apply KKT-Hardnet to nonconvex pooling problem and a real-world chemical process simulation. Compared to multilayer perceptrons and PINNs, KKT-Hardnet achieves strict constraint satisfaction. It also circumvents the need to balance data and physics residuals in PINN training. This enables the integration of domain knowledge into machine learning towards reliable hybrid modeling of complex systems.
<div id='section'>Paperid: <span id='pid'>1392, <a href='https://arxiv.org/pdf/2507.07237.pdf' target='_blank'>https://arxiv.org/pdf/2507.07237.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erfan Hamdi, Emma Lejeune
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07237">Towards Robust Surrogate Models: Benchmarking Machine Learning Approaches to Expediting Phase Field Simulations of Brittle Fracture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data driven approaches have the potential to make modeling complex, nonlinear physical phenomena significantly more computationally tractable. For example, computational modeling of fracture is a core challenge where machine learning techniques have the potential to provide a much needed speedup that would enable progress in areas such as mutli-scale modeling and uncertainty quantification. Currently, phase field modeling (PFM) of fracture is one such approach that offers a convenient variational formulation to model crack nucleation, branching and propagation. To date, machine learning techniques have shown promise in approximating PFM simulations. However, most studies rely on overly simple benchmarks that do not reflect the true complexity of the fracture processes where PFM excels as a method. To address this gap, we introduce a challenging dataset based on PFM simulations designed to benchmark and advance ML methods for fracture modeling. This dataset includes three energy decomposition methods, two boundary conditions, and 1,000 random initial crack configurations for a total of 6,000 simulations. Each sample contains 100 time steps capturing the temporal evolution of the crack field. Alongside this dataset, we also implement and evaluate Physics Informed Neural Networks (PINN), Fourier Neural Operators (FNO) and UNet models as baselines, and explore the impact of ensembling strategies on prediction accuracy. With this combination of our dataset and baseline models drawn from the literature we aim to provide a standardized and challenging benchmark for evaluating machine learning approaches to solid mechanics. Our results highlight both the promise and limitations of popular current models, and demonstrate the utility of this dataset as a testbed for advancing machine learning in fracture mechanics research.
<div id='section'>Paperid: <span id='pid'>1393, <a href='https://arxiv.org/pdf/2507.07237.pdf' target='_blank'>https://arxiv.org/pdf/2507.07237.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Erfan Hamdi, Emma Lejeune
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07237">Towards Robust Surrogate Models: Benchmarking Machine Learning Approaches to Expediting Phase Field Simulations of Brittle Fracture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data driven approaches have the potential to make modeling complex, nonlinear physical phenomena significantly more computationally tractable. For example, computational modeling of fracture is a core challenge where machine learning techniques have the potential to provide a much needed speedup that would enable progress in areas such as mutli-scale modeling and uncertainty quantification. Currently, phase field modeling (PFM) of fracture is one such approach that offers a convenient variational formulation to model crack nucleation, branching and propagation. To date, machine learning techniques have shown promise in approximating PFM simulations. However, most studies rely on overly simple benchmarks that do not reflect the true complexity of the fracture processes where PFM excels as a method. To address this gap, we introduce a challenging dataset based on PFM simulations designed to benchmark and advance ML methods for fracture modeling. This dataset includes three energy decomposition methods, two boundary conditions, and 1,000 random initial crack configurations for a total of 6,000 simulations. Each sample contains 100 time steps capturing the temporal evolution of the crack field. Alongside this dataset, we also implement and evaluate Physics Informed Neural Networks (PINN), Fourier Neural Operators (FNO) and UNet models as baselines, and explore the impact of ensembling strategies on prediction accuracy. With this combination of our dataset and baseline models drawn from the literature we aim to provide a standardized and challenging benchmark for evaluating machine learning approaches to solid mechanics. Our results highlight both the promise and limitations of popular current models, and demonstrate the utility of this dataset as a testbed for advancing machine learning in fracture mechanics research.
<div id='section'>Paperid: <span id='pid'>1394, <a href='https://arxiv.org/pdf/2507.05874.pdf' target='_blank'>https://arxiv.org/pdf/2507.05874.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Solon Falas, Markos Asprou, Charalambos Konstantinou, Maria K. Michael
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05874">Robust Power System State Estimation using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern power systems face significant challenges in state estimation and real-time monitoring, particularly regarding response speed and accuracy under faulty conditions or cyber-attacks. This paper proposes a hybrid approach using physics-informed neural networks (PINNs) to enhance the accuracy and robustness, of power system state estimation. By embedding physical laws into the neural network architecture, PINNs improve estimation accuracy for transmission grid applications under both normal and faulty conditions, while also showing potential in addressing security concerns such as data manipulation attacks. Experimental results show that the proposed approach outperforms traditional machine learning models, achieving up to 83% higher accuracy on unseen subsets of the training dataset and 65% better performance on entirely new, unrelated datasets. Experiments also show that during a data manipulation attack against a critical bus in a system, the PINN can be up to 93% more accurate than an equivalent neural network.
<div id='section'>Paperid: <span id='pid'>1395, <a href='https://arxiv.org/pdf/2507.05783.pdf' target='_blank'>https://arxiv.org/pdf/2507.05783.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Comte Valentin, Gemma Piella, Mario Ceresa, Miguel A. Gonzalez Ballester
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05783">From Motion to Meaning: Biomechanics-Informed Neural Network for Explainable Cardiovascular Disease Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cardiac diseases are among the leading causes of morbidity and mortality worldwide, which requires accurate and timely diagnostic strategies. In this study, we introduce an innovative approach that combines deep learning image registration with physics-informed regularization to predict the biomechanical properties of moving cardiac tissues and extract features for disease classification. We utilize the energy strain formulation of Neo-Hookean material to model cardiac tissue deformations, optimizing the deformation field while ensuring its physical and biomechanical coherence. This explainable approach not only improves image registration accuracy, but also provides insights into the underlying biomechanical processes of the cardiac tissues. Evaluation on the Automated Cardiac Diagnosis Challenge (ACDC) dataset achieved Dice scores of 0.945 for the left ventricular cavity, 0.908 for the right ventricular cavity, and 0.905 for the myocardium. Subsequently, we estimate the local strains within the moving heart and extract a detailed set of features used for cardiovascular disease classification. We evaluated five classification algorithms, Logistic Regression, Multi-Layer Perceptron, Support Vector Classifier, Random Forest, and Nearest Neighbour, and identified the most relevant features using a feature selection algorithm. The best performing classifier obtained a classification accuracy of 98% in the training set and 100% in the test set of the ACDC dataset. By integrating explainable artificial intelligence, this method empowers clinicians with a transparent understanding of the model's predictions based on cardiac mechanics, while also significantly improving the accuracy and reliability of cardiac disease diagnosis, paving the way for more personalized and effective patient care.
<div id='section'>Paperid: <span id='pid'>1396, <a href='https://arxiv.org/pdf/2507.04419.pdf' target='_blank'>https://arxiv.org/pdf/2507.04419.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ryan A. McCarthy, You Zhang, Samuel A. Verburg, William F. Jenkins, Peter Gerstoft
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04419">Machine Learning in Acoustics: A Review and Open-Source Repository</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Acoustic data provide scientific and engineering insights in fields ranging from bioacoustics and communications to ocean and earth sciences. In this review, we survey recent advances and the transformative potential of machine learning (ML) in acoustics, including deep learning (DL). Using the Python high-level programming language, we demonstrate a broad collection of ML techniques to detect and find patterns for classification, regression, and generation in acoustics data automatically. We have ML examples including acoustic data classification, generative modeling for spatial audio, and physics-informed neural networks. This work includes AcousticsML, a set of practical Jupyter notebook examples on GitHub demonstrating ML benefits and encouraging researchers and practitioners to apply reproducible data-driven approaches to acoustic challenges.
<div id='section'>Paperid: <span id='pid'>1397, <a href='https://arxiv.org/pdf/2506.23024.pdf' target='_blank'>https://arxiv.org/pdf/2506.23024.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jerry Liu, Yasa Baig, Denise Hui Jean Lee, Rajat Vadiraj Dwaraknath, Atri Rudra, Chris RÃ©
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23024">BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) offer a flexible way to solve partial differential equations (PDEs) with machine learning, yet they still fall well short of the machine-precision accuracy many scientific tasks demand. In this work, we investigate whether the precision ceiling comes from the ill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP) architecture. We introduce the Barycentric Weight Layer (BWLer), which models the PDE solution through barycentric polynomial interpolation. A BWLer can be added on top of an existing MLP (a BWLer-hat) or replace it completely (explicit BWLer), cleanly separating how we represent the solution from how we take derivatives for the PDE loss. Using BWLer, we identify fundamental precision limitations within the MLP: on a simple 1-D interpolation task, even MLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above float64 machine precision -- before any PDE terms are added. In PDE learning, adding a BWLer lifts this ceiling and exposes a tradeoff between achievable accuracy and the conditioning of the PDE loss. For linear PDEs we fully characterize this tradeoff with an explicit error decomposition and navigate it during training with spectral derivatives and preconditioning. Across five benchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for convection, 10x for reaction, and 1800x for wave equations while remaining compatible with first-order optimizers. Replacing the MLP entirely lets an explicit BWLer reach near-machine-precision on convection, reaction, and wave problems (up to 10 billion times better than prior results) and match the performance of standard PINNs on stiff Burgers' and irregular-geometry Poisson problems. Together, these findings point to a practical path for combining the flexibility of PINNs with the precision of classical spectral solvers.
<div id='section'>Paperid: <span id='pid'>1398, <a href='https://arxiv.org/pdf/2506.15405.pdf' target='_blank'>https://arxiv.org/pdf/2506.15405.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Roshan Antony Gomez, Julien StÃ¶cker, BarÄ±Å CansÄ±z, Michael Kaliske
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.15405">Simulation of parametrized cardiac electrophysiology in three dimensions using physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are extensively used to represent various physical systems across multiple scientific domains. The same can be said for cardiac electrophysiology, wherein fully-connected neural networks (FCNNs) have been employed to predict the evolution of an action potential in a 2D space following the two-parameter phenomenological Aliev-Panfilov (AP) model. In this paper, the training behaviour of PINNs is investigated to determine optimal hyperparameters to predict the electrophysiological activity of the myocardium in 3D according to the AP model, with the inclusion of boundary and material parameters. An FCNN architecture is employed with the governing partial differential equations in their strong form, which are scaled consistently with normalization of network inputs. The finite element (FE) method is used to generate training data for the network. Numerical examples with varying spatial dimensions and parameterizations are generated using the trained models. The network predicted fields for both the action potential and the recovery variable are compared with the respective FE simulations. Network losses are weighed with individual scalar values. Their effect on training and prediction is studied to arrive at a method of controlling losses during training.
<div id='section'>Paperid: <span id='pid'>1399, <a href='https://arxiv.org/pdf/2506.14036.pdf' target='_blank'>https://arxiv.org/pdf/2506.14036.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tatthapong Srikitrungruang, Matthew Lemon, Sina Aghaee Dabaghan Fard, Jaesung Lee, Yuxiao Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14036">Robust Physics-Informed Neural Network Approach for Estimating Heterogeneous Elastic Properties from Noisy Displacement Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately estimating spatially heterogeneous elasticity parameters, particularly Young's modulus and Poisson's ratio, from noisy displacement measurements remains significantly challenging in inverse elasticity problems. Existing inverse estimation techniques are often limited by instability, pronounced sensitivity to measurement noise, and difficulty in recovering absolute-scale Young's modulus. This work presents a novel Inverse Elasticity Physics-Informed Neural Network (IE-PINN) specifically designed to robustly reconstruct heterogeneous distributions of elasticity parameters from noisy displacement data based on linear elasticity physics. IE-PINN integrates three distinct neural network architectures dedicated to separately modeling displacement fields, strain fields, and elasticity distributions, thereby significantly enhancing stability and accuracy against measurement noise. Additionally, a two-phase estimation strategy is introduced: the first phase recovers relative spatial distributions of Young's modulus and Poisson's ratio, and the second phase calibrates the absolute scale of Young's modulus using imposed loading boundary conditions. Additional methodological innovations, including positional encoding, sine activation functions, and a sequential pretraining protocol, further enhance the model's performance and robustness. Extensive numerical experiments demonstrate that IE-PINN effectively overcomes critical limitations encountered by existing methods, delivering accurate absolute-scale elasticity estimations even under severe noise conditions. This advancement holds substantial potential for clinical imaging diagnostics and mechanical characterization, where measurements typically encounter substantial noise.
<div id='section'>Paperid: <span id='pid'>1400, <a href='https://arxiv.org/pdf/2506.11786.pdf' target='_blank'>https://arxiv.org/pdf/2506.11786.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Markus Gambietz, Eva Dorschky, Altan Akat, Marcel SchÃ¶ckel, JÃ¶rg Miehling, Anne D. Koelewijn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.11786">SSPINNpose: A Self-Supervised PINN for Inertial Pose and Dynamics Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate real-time estimation of human movement dynamics, including internal joint moments and muscle forces, is essential for applications in clinical diagnostics and sports performance monitoring. Inertial measurement units (IMUs) provide a minimally intrusive solution for capturing motion data, particularly when used in sparse sensor configurations. However, current real-time methods rely on supervised learning, where a ground truth dataset needs to be measured with laboratory measurement systems, such as optical motion capture. These systems are known to introduce measurement and processing errors and often fail to generalize to real-world or previously unseen movements, necessitating new data collection efforts that are time-consuming and impractical. To overcome these limitations, we propose SSPINNpose, a self-supervised, physics-informed neural network that estimates joint kinematics and kinetics directly from IMU data, without requiring ground truth labels for training. We run the network output through a physics model of the human body to optimize physical plausibility and generate virtual measurement data. Using this virtual sensor data, the network is trained directly on the measured sensor data instead of a ground truth. When compared to optical motion capture, SSPINNpose is able to accurately estimate joint angles and joint moments at an RMSD of 8.7 deg and 4.9 BWBH%, respectively, for walking and running at speeds up to 4.9 m/s at a latency of 3.5 ms. Furthermore, the framework demonstrates robustness across sparse sensor configurations and can infer the anatomical locations of the sensors. These results underscore the potential of SSPINNpose as a scalable and adaptable solution for real-time biomechanical analysis in both laboratory and field environments.
<div id='section'>Paperid: <span id='pid'>1401, <a href='https://arxiv.org/pdf/2506.11518.pdf' target='_blank'>https://arxiv.org/pdf/2506.11518.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Li, Zhengqi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.11518">Transformed Diffusion-Wave fPINNs: Enhancing Computing Efficiency for PINNs Solving Time-Fractional Diffusion-Wave Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose transformed Diffsuion-Wave fractional Physics-Informed Neural Networks (tDWfPINNs) for efficiently solving time-fractional diffusion-wave equations with fractional order $Î±\in(1,2)$. Conventional numerical methods for these equations often compromise the mesh-free advantage of Physics-Informed Neural Networks (PINNs) or impose high computational costs when computing fractional derivatives. The proposed method avoids first-order derivative calculations at quadrature points by introducing an integrand transformation technique, significantly reducing computational costs associated with fractional derivative evaluation while preserving accuracy. We conduct a comprehensive comparative analysis applying this integrand transformation in conjunction with both Monte Carlo integration and Gauss-Jacobi quadrature schemes across various time-fractional PDEs. Our results demonstrate that tDWfPINNs achieve superior computational efficiency without sacrificing accuracy. Furthermore, we incorporate the proposed approach into adaptive sampling approaches such as the residual-based adaptive distribution (RAD) for the time-fractional Burgers equation with order $Î±\in(1,2)$, which exhibits complex solution dynamics. The experiments show that the Gauss-Jacobi method typically outperforms the Monte Carlo approach; however, careful consideration is required when selecting the number of quadrature points. Overall, the proposed tDWfPINNs offer a significant advancement in the numerical solution of time-fractional diffusion-wave equations, providing an accurate and scalable mesh-free alternative for challenging fractional models.
<div id='section'>Paperid: <span id='pid'>1402, <a href='https://arxiv.org/pdf/2506.08563.pdf' target='_blank'>https://arxiv.org/pdf/2506.08563.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyuan Yang, Cheng Song, Zhilu Lai, Wenjia Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08563">KP-PINNs: Kernel Packet Accelerated Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Differential equations are involved in modeling many engineering problems. Many efforts have been devoted to solving differential equations. Due to the flexibility of neural networks, Physics Informed Neural Networks (PINNs) have recently been proposed to solve complex differential equations and have demonstrated superior performance in many applications. While the L2 loss function is usually a default choice in PINNs, it has been shown that the corresponding numerical solution is incorrect and unstable for some complex equations. In this work, we propose a new PINNs framework named Kernel Packet accelerated PINNs (KP-PINNs), which gives a new expression of the loss function using the reproducing kernel Hilbert space (RKHS) norm and uses the Kernel Packet (KP) method to accelerate the computation. Theoretical results show that KP-PINNs can be stable across various differential equations. Numerical experiments illustrate that KP-PINNs can solve differential equations effectively and efficiently. This framework provides a promising direction for improving the stability and accuracy of PINNs-based solvers in scientific computing.
<div id='section'>Paperid: <span id='pid'>1403, <a href='https://arxiv.org/pdf/2506.08381.pdf' target='_blank'>https://arxiv.org/pdf/2506.08381.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>He Yang, Fei Ren, Hai-Sui Yu, Xueyu Geng, Pei-Zhi Zhuang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08381">TS-PIELM: Time-Stepping Physics-Informed Extreme Learning Machine Facilitates Soil Consolidation Analyses</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accuracy and efficiency of the conventional physics-informed neural network (PINN) need to be improved before it can be a competitive alternative for soil consolidation analyses. This paper aims to overcome these limitations by proposing a highly accurate and efficient physics-informed machine learning (PIML) approach, termed time-stepping physics-informed extreme learning machine (TS-PIELM). In the TS-PIELM framework the consolidation process is divided into numerous time intervals, which helps overcome the limitation of PIELM in solving differential equations with sharp gradients. To accelerate network training, the solution is approximated by a single-layer feedforward extreme learning machine (ELM), rather than using a fully connected neural network in PINN. The input layer weights of the ELM network are generated randomly and fixed during the training process. Subsequently, the output layer weights are directly computed by solving a system of linear equations, which significantly enhances the training efficiency compared to the time-consuming gradient descent method in PINN. Finally, the superior performance of TS-PIELM is demonstrated by solving three typical Terzaghi consolidation problems. Compared to PINN, results show that the computational efficiency and accuracy of the novel TS-PIELM framework are improved by more than 1000 times and 100 times for one-dimensional cases, respectively. This paper provides compelling evidence that PIML can be a powerful tool for computational geotechnics.
<div id='section'>Paperid: <span id='pid'>1404, <a href='https://arxiv.org/pdf/2506.07958.pdf' target='_blank'>https://arxiv.org/pdf/2506.07958.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Salah A. Faroughi, Farinaz Mostajeran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.07958">Neural Tangent Kernel Analysis to Probe Convergence in Physics-informed Neural Solvers: PIKANs vs. PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Kolmogorov-Arnold Networks (PIKANs), and in particular their Chebyshev-based variants (cPIKANs), have recently emerged as promising models for solving partial differential equations (PDEs). However, their training dynamics and convergence behavior remain largely unexplored both theoretically and numerically. In this work, we aim to advance the theoretical understanding of cPIKANs by analyzing them using Neural Tangent Kernel (NTK) theory. Our objective is to discern the evolution of kernel structure throughout gradient-based training and its subsequent impact on learning efficiency. We first derive the NTK of standard cKANs in a supervised setting, and then extend the analysis to the physics-informed context. We analyze the spectral properties of NTK matrices, specifically their eigenvalue distributions and spectral bias, for four representative PDEs: the steady-state Helmholtz equation, transient diffusion and Allen-Cahn equations, and forced vibrations governed by the Euler-Bernoulli beam equation. We also conduct an investigation into the impact of various optimization strategies, e.g., first-order, second-order, and hybrid approaches, on the evolution of the NTK and the resulting learning dynamics. Results indicate a tractable behavior for NTK in the context of cPIKANs, which exposes learning dynamics that standard physics-informed neural networks (PINNs) cannot capture. Spectral trends also reveal when domain decomposition improves training, directly linking kernel behavior to convergence rates under different setups. To the best of our knowledge, this is the first systematic NTK study of cPIKANs, providing theoretical insight that clarifies and predicts their empirical performance.
<div id='section'>Paperid: <span id='pid'>1405, <a href='https://arxiv.org/pdf/2506.04354.pdf' target='_blank'>https://arxiv.org/pdf/2506.04354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elmira Mirzabeigi, Rezvan Salehi, Kourosh Parand
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.04354">BridgeNet: A Hybrid, Physics-Informed Machine Learning Framework for Solving High-Dimensional Fokker-Planck Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>BridgeNet is a novel hybrid framework that integrates convolutional neural networks with physics-informed neural networks to efficiently solve non-linear, high-dimensional Fokker-Planck equations (FPEs). Traditional PINNs, which typically rely on fully connected architectures, often struggle to capture complex spatial hierarchies and enforce intricate boundary conditions. In contrast, BridgeNet leverages adaptive CNN layers for effective local feature extraction and incorporates a dynamically weighted loss function that rigorously enforces physical constraints. Extensive numerical experiments across various test cases demonstrate that BridgeNet not only achieves significantly lower error metrics and faster convergence compared to conventional PINN approaches but also maintains robust stability in high-dimensional settings. This work represents a substantial advancement in computational physics, offering a scalable and accurate solution methodology with promising applications in fields ranging from financial mathematics to complex system dynamics.
<div id='section'>Paperid: <span id='pid'>1406, <a href='https://arxiv.org/pdf/2506.00858.pdf' target='_blank'>https://arxiv.org/pdf/2506.00858.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qianchao Wang, Peng Sha, Leena Heistrene, Yuxuan Ding, Yaping Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00858">Interpretable Spatio-Temporal Features Extraction based Industrial Process Modeling and Monitoring by Soft Sensor</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven soft sensors have been widely applied in complex industrial processes. However, the interpretable spatio-temporal features extraction by soft sensors remains a challenge. In this light, this work introduces a novel method termed spatio-temporal consistent and interpretable model (STCIM). First, temporal and spatial features are captured and aligned by a far topological spatio-temporal consistency extraction block. Then, the features are mapped into an interpretable latent space for further prediction by explicitly giving physical meanings to latent variables. The efficacy of the proposed STCIM is demonstrated through the modeling of two generated datasets and a real-life dataset of coal-fired power plants. The corresponding experiments show: 1) The generalization of STCIM outperforms other methods, especially in different operation situations. 2) The far topological spatio-temporal consistency is vital for feature alignment. 3) The hyper-parameters of physics-informed interpretable latent space loss decide the performance of STCIM.
<div id='section'>Paperid: <span id='pid'>1407, <a href='https://arxiv.org/pdf/2505.20769.pdf' target='_blank'>https://arxiv.org/pdf/2505.20769.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanpei Shi, Bo Feng, Yuxin Zhong, Haochen Guo, Bangcheng Han, Rui Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20769">Physics-Informed Neural Network for Cross-Domain Predictive Control of Tapered Amplifier Thermal Stabilization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Thermally induced laser noise poses a critical limitation to the sensitivity of quantum sensor arrays employing ultra-stable amplified lasers, primarily stemming from nonlinear gain-temperature coupling effects in tapered amplifiers (TAs). To address this challenge, we present a robust intelligent control strategy that synergistically integrates an encoder-decoder physics-informed gated recurrent unit (PI-GRU) network with a model predictive control (MPC) framework. Our methodology incorporates physical soft constraints into the neural network architecture, yielding a predictive model with enhanced physical consistency that demonstrates robust extrapolation capabilities beyond the training data distribution. Leveraging the PI-GRU model's accurate multi-step predictive performance, we implement a hierarchical parallel MPC architecture capable of real-time thermal instability compensation. This hybrid approach achieves cross-domain consistent thermal stabilization in TAs under diverse laser power operations. Remarkably, while trained exclusively on low-power operational data, our system demonstrates exceptional generalization, improving prediction accuracy by 58.2% and temperature stability by 69.1% in previously unseen high-power operating regimes, as experimentally validated. The novel synchronization of physics-informed neural networks with advanced MPC frameworks presented in this work establishes a groundbreaking paradigm for addressing robustness challenges in cross-domain predictive control applications, overcoming conventional modeling limitations.
<div id='section'>Paperid: <span id='pid'>1408, <a href='https://arxiv.org/pdf/2505.19136.pdf' target='_blank'>https://arxiv.org/pdf/2505.19136.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Frank Shih, Zhenghao Jiang, Faming Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19136">Uncertainty Quantification for Physics-Informed Neural Networks with Extended Fiducial Inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification (UQ) in scientific machine learning is increasingly critical as neural networks are widely adopted to tackle complex problems across diverse scientific disciplines. For physics-informed neural networks (PINNs), a prominent model in scientific machine learning, uncertainty is typically quantified using Bayesian or dropout methods. However, both approaches suffer from a fundamental limitation: the prior distribution or dropout rate required to construct honest confidence sets cannot be determined without additional information. In this paper, we propose a novel method within the framework of extended fiducial inference (EFI) to provide rigorous uncertainty quantification for PINNs. The proposed method leverages a narrow-neck hyper-network to learn the parameters of the PINN and quantify their uncertainty based on imputed random errors in the observations. This approach overcomes the limitations of Bayesian and dropout methods, enabling the construction of honest confidence sets based solely on observed data. This advancement represents a significant breakthrough for PINNs, greatly enhancing their reliability, interpretability, and applicability to real-world scientific and engineering challenges. Moreover, it establishes a new theoretical framework for EFI, extending its application to large-scale models, eliminating the need for sparse hyper-networks, and significantly improving the automaticity and robustness of statistical inference.
<div id='section'>Paperid: <span id='pid'>1409, <a href='https://arxiv.org/pdf/2505.19036.pdf' target='_blank'>https://arxiv.org/pdf/2505.19036.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanfei Zhou, Lei Shi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19036">Weak Physics Informed Neural Networks for Geometry Compatible Hyperbolic Conservation Laws on Manifolds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs), owing to their mesh-free nature, offer a powerful approach for solving high-dimensional partial differential equations (PDEs) in complex geometries, including irregular domains. This capability effectively circumvents the challenges of mesh generation that traditional numerical methods face in high-dimensional or geometrically intricate settings. While recent studies have extended PINNs to manifolds, the theoretical foundations remain scarce. Existing theoretical analyses of PINNs in Euclidean space often rely on smoothness assumptions for the solutions. However, recent empirical evidence indicates that PINNs may struggle to approximate solutions with low regularity, such as those arising from nonlinear hyperbolic equations. In this paper, we develop a framework for PINNs tailored to the efficient approximation of weak solutions, particularly nonlinear hyperbolic equations defined on manifolds. We introduce a novel weak PINN (wPINN) formulation on manifolds that leverages the well-posedness theory to approximate entropy solutions of geometry-compatible hyperbolic conservation laws on manifolds. Employing tools from approximation theory, we establish a convergence analysis of the algorithm, including an analysis of approximation errors for time-dependent entropy solutions. This analysis provides insight into the accumulation of approximation errors over long time horizons. Notably, the network complexity depends only on the intrinsic dimension, independent of the ambient space dimension. Our results match the minimax rate in the d-dimensional Euclidean space, demonstrating that PINNs can alleviate the curse of dimensionality in the context of low-dimensional manifolds. Finally, we validate the performance of the proposed wPINN framework through numerical experiments, confirming its ability to efficiently approximate entropy solutions on manifolds.
<div id='section'>Paperid: <span id='pid'>1410, <a href='https://arxiv.org/pdf/2505.16996.pdf' target='_blank'>https://arxiv.org/pdf/2505.16996.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shalev Manor, Mohammad Kohandel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16996">A Unified Framework for Simultaneous Parameter and Function Discovery in Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse problems involving differential equations often require identifying unknown parameters or functions from data. Existing approaches, such as Physics-Informed Neural Networks (PINNs), Universal Differential Equations (UDEs) and Universal Physics-Informed Neural Networks (UPINNs), are effective at isolating either parameters or functions but can face challenges when applied simultaneously due to solution non-uniqueness. In this work, we introduce a framework that addresses these limitations by establishing conditions under which unique solutions can be guaranteed. To illustrate, we apply it to examples from biological systems and ecological dynamics, demonstrating accurate and interpretable results. Our approach significantly enhances the potential of machine learning techniques in modeling complex systems in science and engineering.
<div id='section'>Paperid: <span id='pid'>1411, <a href='https://arxiv.org/pdf/2505.15972.pdf' target='_blank'>https://arxiv.org/pdf/2505.15972.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haojin Guo, Zongyi Guo, Jianguo Guo, Tiago Roux Oliveira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15972">Extremum Seeking for PDE Systems using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Extremum Seeking (ES) is an effective real-time optimization method for PDE systems in cascade with nonlinear quadratic maps. To address PDEs in the feedback loop, a boundary control law and a re-design of the additive probing signal are mandatory. The latter, commonly called "trajectory generation" or "motion planning," involves designing perturbation signals that anticipate their propagation through PDEs. Specifically, this requires solving motion planning problems for systems governed by parabolic and hyperbolic PDEs. Physics-Informed Neural Networks (PINN) is a powerful tool for solving PDEs by embedding physical laws as constraints in the neural network's loss function, enabling efficient solutions for high-dimensional, nonlinear, and complex problems. This paper proposes a novel construction integrating PINN and ES, automating the motion planning process for specific PDE systems and eliminating the need for case-by-case analytical derivations. The proposed strategy efficiently extracts perturbation signals, optimizing the PDE system.
<div id='section'>Paperid: <span id='pid'>1412, <a href='https://arxiv.org/pdf/2505.14595.pdf' target='_blank'>https://arxiv.org/pdf/2505.14595.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nima Hosseini Dashtbayaz, Hesam Salehipour, Adrian Butscher, Nigel Morris
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14595">Physics-informed Reduced Order Modeling of Time-dependent PDEs via Differentiable Solvers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reduced-order modeling (ROM) of time-dependent and parameterized differential equations aims to accelerate the simulation of complex high-dimensional systems by learning a compact latent manifold representation that captures the characteristics of the solution fields and their time-dependent dynamics. Although high-fidelity numerical solvers generate the training datasets, they have thus far been excluded from the training process, causing the learned latent dynamics to drift away from the discretized governing physics. This mismatch often limits generalization and forecasting capabilities. In this work, we propose Physics-informed ROM ($Î¦$-ROM) by incorporating differentiable PDE solvers into the training procedure. Specifically, the latent space dynamics and its dependence on PDE parameters are shaped directly by the governing physics encoded in the solver, ensuring a strong correspondence between the full and reduced systems. Our model outperforms state-of-the-art data-driven ROMs and other physics-informed strategies by accurately generalizing to new dynamics arising from unseen parameters, enabling long-term forecasting beyond the training horizon, maintaining continuity in both time and space, and reducing the data cost. Furthermore, $Î¦$-ROM learns to recover and forecast the solution fields even when trained or evaluated with sparse and irregular observations of the fields, providing a flexible framework for field reconstruction and data assimilation. We demonstrate the framework's robustness across different PDE solvers and highlight its broad applicability by providing an open-source JAX implementation readily extensible to other PDE systems and differentiable solvers.
<div id='section'>Paperid: <span id='pid'>1413, <a href='https://arxiv.org/pdf/2505.14002.pdf' target='_blank'>https://arxiv.org/pdf/2505.14002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Zhao, Tao Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14002">Convergence Guarantees for Gradient-Based Training of Neural PDE Solvers: From Linear to Nonlinear PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a unified convergence theory for gradient-based training of neural network methods for partial differential equations (PDEs), covering both physics-informed neural networks (PINNs) and the Deep Ritz method. For linear PDEs, we extend the neural tangent kernel (NTK) framework for PINNs to establish global convergence guarantees for a broad class of linear operators. For nonlinear PDEs, we prove convergence to critical points via the Åojasiewicz inequality under the random feature model, eliminating the need for strong over-parameterization and encompassing both gradient flow and implicit gradient descent dynamics. Our results further reveal that the random feature model exhibits an implicit regularization effect, preventing parameter divergence to infinity. Theoretical findings are corroborated by numerical experiments, providing new insights into the training dynamics and robustness of neural network PDE solvers.
<div id='section'>Paperid: <span id='pid'>1414, <a href='https://arxiv.org/pdf/2505.14002.pdf' target='_blank'>https://arxiv.org/pdf/2505.14002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Zhao, Tao Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14002">Convergence Guarantees for Gradient-Based Training of Neural PDE Solvers: From Linear to Nonlinear PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a unified convergence theory for gradient-based training of neural network methods for partial differential equations (PDEs), covering both physics-informed neural networks (PINNs) and the Deep Ritz method. For linear PDEs, we extend the neural tangent kernel (NTK) framework for PINNs to establish global convergence guarantees for a broad class of linear operators. For nonlinear PDEs, we prove convergence to critical points via the Łojasiewicz inequality under the random feature model, eliminating the need for strong over-parameterization and encompassing both gradient flow and implicit gradient descent dynamics. Our results further reveal that the random feature model exhibits an implicit regularization effect, preventing parameter divergence to infinity. Theoretical findings are corroborated by numerical experiments, providing new insights into the training dynamics and robustness of neural network PDE solvers.
<div id='section'>Paperid: <span id='pid'>1415, <a href='https://arxiv.org/pdf/2505.12389.pdf' target='_blank'>https://arxiv.org/pdf/2505.12389.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Su Yeong Jo, Sanghyeon Park, Seungchan Ko, Jongcheon Park, Hosung Kim, Sangseung Lee, Joongoo Jeon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12389">Engineering application of physics-informed neural networks for Saint-Venant torsion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Saint-Venant torsion theory is a classical theory for analyzing the torsional behavior of structural components, and it remains critically important in modern computational design workflows. Conventional numerical methods, including the finite element method (FEM), typically rely on mesh-based approaches to obtain approximate solutions. However, these methods often require complex and computationally intensive techniques to overcome the limitations of approximation, leading to significant increases in computational cost. The objective of this study is to develop a series of novel numerical methods based on physics-informed neural networks (PINN) for solving the Saint-Venant torsion equations. Utilizing the expressive power and the automatic differentiation capability of neural networks, the PINN can solve partial differential equations (PDEs) along with boundary conditions without the need for intricate computational techniques. First, a PINN solver was developed to compute the torsional constant for bars with arbitrary cross-sectional geometries. This was followed by the development of a solver capable of handling cases with sharp geometric transitions; variable-scaling PINN (VS-PINN). Finally, a parametric PINN was constructed to address the limitations of conventional single-instance PINN. The results from all three solvers showed good agreement with reference solutions, demonstrating their accuracy and robustness. Each solver can be selectively utilized depending on the specific requirements of torsional behavior analysis.
<div id='section'>Paperid: <span id='pid'>1416, <a href='https://arxiv.org/pdf/2505.10894.pdf' target='_blank'>https://arxiv.org/pdf/2505.10894.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yishuo Wang, Feng Zhou, Muping Zhou, Qicheng Meng, Zhijun Hu, Yi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.10894">CTP: A hybrid CNN-Transformer-PINN model for ocean front forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes CTP, a novel deep learning framework that integrates convolutional neural network(CNN), Transformer architectures, and physics-informed neural network(PINN) for ocean front prediction. Ocean fronts, as dynamic interfaces between distinct water masses, play critical roles in marine biogeochemical and physical processes. Existing methods such as LSTM, ConvLSTM, and AttentionConv often struggle to maintain spatial continuity and physical consistency over multi-step forecasts. CTP addresses these challenges by combining localized spatial encoding, long-range temporal attention, and physical constraint enforcement. Experimental results across south China sea(SCS) and Kuroshio(KUR) regions from 1993 to 2020 demonstrate that CTP achieves state-of-the-art(SOTA) performance in both single-step and multi-step predictions, significantly outperforming baseline models in accuracy, $F_1$ score, and temporal stability.
<div id='section'>Paperid: <span id='pid'>1417, <a href='https://arxiv.org/pdf/2505.08687.pdf' target='_blank'>https://arxiv.org/pdf/2505.08687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hangwei Zhang, Zhimu Huang, Yan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.08687">AC-PKAN: Attention-Enhanced and Chebyshev Polynomial-Based Physics-Informed Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kolmogorov-Arnold Networks (KANs) have recently shown promise for solving partial differential equations (PDEs). Yet their original formulation is computationally and memory intensive, motivating the introduction of Chebyshev Type-I-based KANs (Chebyshev1KANs). Although Chebyshev1KANs have outperformed the vanilla KANs architecture, our rigorous theoretical analysis reveals that they still suffer from rank collapse, ultimately limiting their expressive capacity. To overcome these limitations, we enhance Chebyshev1KANs by integrating wavelet-activated MLPs with learnable parameters and an internal attention mechanism. We prove that this design preserves a full-rank Jacobian and is capable of approximating solutions to PDEs of arbitrary order. Furthermore, to alleviate the loss instability and imbalance introduced by the Chebyshev polynomial basis, we externally incorporate a Residual Gradient Attention (RGA) mechanism that dynamically re-weights individual loss terms according to their gradient norms and residual magnitudes. By jointly leveraging internal and external attention, we present AC-PKAN, a novel architecture that constitutes an enhancement to weakly supervised Physics-Informed Neural Networks (PINNs) and extends the expressive power of KANs. Experimental results from nine benchmark tasks across three domains show that AC-PKAN consistently outperforms or matches state-of-the-art models such as PINNsFormer, establishing it as a highly effective tool for solving complex real-world engineering problems in zero-data or data-sparse regimes. The code will be made publicly available upon acceptance.
<div id='section'>Paperid: <span id='pid'>1418, <a href='https://arxiv.org/pdf/2505.05691.pdf' target='_blank'>https://arxiv.org/pdf/2505.05691.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruiqi Ni, Zherong Pan, Ahmed H Qureshi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.05691">Physics-informed Temporal Difference Metric Learning for Robot Motion Planning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The motion planning problem involves finding a collision-free path from a robot's starting to its target configuration. Recently, self-supervised learning methods have emerged to tackle motion planning problems without requiring expensive expert demonstrations. They solve the Eikonal equation for training neural networks and lead to efficient solutions. However, these methods struggle in complex environments because they fail to maintain key properties of the Eikonal equation, such as optimal value functions and geodesic distances. To overcome these limitations, we propose a novel self-supervised temporal difference metric learning approach that solves the Eikonal equation more accurately and enhances performance in solving complex and unseen planning tasks. Our method enforces Bellman's principle of optimality over finite regions, using temporal difference learning to avoid spurious local minima while incorporating metric learning to preserve the Eikonal equation's essential geodesic properties. We demonstrate that our approach significantly outperforms existing self-supervised learning methods in handling complex environments and generalizing to unseen environments, with robot configurations ranging from 2 to 12 degrees of freedom (DOF).
<div id='section'>Paperid: <span id='pid'>1419, <a href='https://arxiv.org/pdf/2505.01438.pdf' target='_blank'>https://arxiv.org/pdf/2505.01438.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tengfei Xing, Xiaodan Ren, Jie Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.01438">Global Stress Generation and Spatiotemporal Super-Resolution Physics-Informed Operator under Dynamic Loading for Two-Phase Random Materials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Material stress analysis is a critical aspect of material design and performance optimization. Under dynamic loading, the global stress evolution in materials exhibits complex spatiotemporal characteristics, especially in two-phase random materials (TRMs). Such kind of material failure is often associated with stress concentration, and the phase boundaries are key locations where stress concentration occurs. In practical engineering applications, the spatiotemporal resolution of acquired microstructural data and its dynamic stress evolution is often limited. This poses challenges for deep learning methods in generating high-resolution spatiotemporal stress fields, particularly for accurately capturing stress concentration regions. In this study, we propose a framework for global stress generation and spatiotemporal super-resolution in TRMs under dynamic loading. First, we introduce a diffusion model-based approach, named as Spatiotemporal Stress Diffusion (STS-diffusion), for generating global spatiotemporal stress data. This framework incorporates Space-Time U-Net (STU-net), and we systematically investigate the impact of different attention positions on model accuracy. Next, we develop a physics-informed network for spatiotemporal super-resolution, termed as Spatiotemporal Super-Resolution Physics-Informed Operator (ST-SRPINN). The proposed ST-SRPINN is an unsupervised learning method. The influence of data-driven and physics-informed loss function weights on model accuracy is explored in detail. Benefiting from physics-based constraints, ST-SRPINN requires only low-resolution stress field data during training and can upscale the spatiotemporal resolution of stress fields to arbitrary magnifications.
<div id='section'>Paperid: <span id='pid'>1420, <a href='https://arxiv.org/pdf/2505.01159.pdf' target='_blank'>https://arxiv.org/pdf/2505.01159.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pradanya Boro, Aayushman Raina, Srinivasan Natesan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.01159">A Parameter-Driven Physics-Informed Neural Network Framework for Solving Two-Parameter Singular Perturbation Problems Involving Boundary Layers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this article, our goal is to solve two-parameter singular perturbation problems (SPPs) in one- and two-dimensions using an adapted Physics-Informed Neural Networks (PINNs) approach. Such problems are of major importance in engineering and sciences as it appears in control theory, fluid and gas dynamics, financial modelling and so on. Solutions of such problems exhibit boundary and/or interior layers, which make them difficult to handle. It has been validated in the literature that standard PINNs have low accuracy and can't handle such problems efficiently. Recently Cao et. al \cite{cao2023physics} proposed a new parameter asymptotic PINNs (PA-PINNs) to solve one-parameter singularly perturbed convection-dominated problems. It was observed that PA-PINNs works better than standard PINNs and gPINNs in terms of accuracy, convergence and stability. In this article, for the first time robustness of PA-PINNs will be validated for solving two-parameter SPPs.
<div id='section'>Paperid: <span id='pid'>1421, <a href='https://arxiv.org/pdf/2505.01047.pdf' target='_blank'>https://arxiv.org/pdf/2505.01047.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Letian Yi, Siyuan Yang, Ying Cui, Zhilu Lai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.01047">Transforming physics-informed machine learning to convex optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Machine Learning (PIML) offers a powerful paradigm of integrating data with physical laws to address important scientific problems, such as parameter estimation, inferring hidden physics, equation discovery, and state prediction, etc. However, PIML still faces many serious optimization challenges that significantly restrict its applications. In this study, we propose a comprehensive framework that transforms PIML to convex optimization to overcome all these limitations, referred to as Convex-PIML. The linear combination of B-splines is utilized to approximate the data, promoting the convexity of the loss function. By replacing the non-convex components of the loss function with convex approximations, the problem is further converted into a sequence of successively refined approximated convex optimization problems. This conversion allows the use of well-established convex optimization algorithms, obtaining solutions effectively and efficiently. Furthermore, an adaptive knot optimization method based on error estimate is introduced to mitigate the spectral bias issue of PIML, further improving the performance. The proposed theoretically guaranteed framework is tested in scenarios with distinct types of physical prior. The results indicate that optimization problems are effectively solved in these scenarios, highlighting the potential of the framework for broad applications.
<div id='section'>Paperid: <span id='pid'>1422, <a href='https://arxiv.org/pdf/2504.21501.pdf' target='_blank'>https://arxiv.org/pdf/2504.21501.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yaru Liu, Yiqi Gu, Michael K. Ng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.21501">Deep Learning Optimization Using Self-Adaptive Weighted Auxiliary Variables</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we develop a new optimization framework for the least squares learning problem via fully connected neural networks or physics-informed neural networks. The gradient descent sometimes behaves inefficiently in deep learning because of the high non-convexity of loss functions and the vanishing gradient issue. Our idea is to introduce auxiliary variables to separate the layers of the deep neural networks and reformulate the loss functions for ease of optimization. We design the self-adaptive weights to preserve the consistency between the reformulated loss and the original mean squared loss, which guarantees that optimizing the new loss helps optimize the original problem. Numerical experiments are presented to verify the consistency and show the effectiveness and robustness of our models over gradient descent.
<div id='section'>Paperid: <span id='pid'>1423, <a href='https://arxiv.org/pdf/2504.21377.pdf' target='_blank'>https://arxiv.org/pdf/2504.21377.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adrian Lepp, JÃ¶rn Tebbe, Andreas Besginow
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.21377">Physics-informed Gaussian Processes for Model Predictive Control of Nonlinear Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, a novel linear model predictive control algorithm based on a physics-informed Gaussian Process has been introduced, whose realizations strictly follow a system of underlying linear ordinary differential equations with constant coefficients. The control task is formulated as an inference problem by conditioning the Gaussian process prior on the setpoints and incorporating pointwise soft-constraints as further virtual setpoints. We apply this method to systems of nonlinear differential equations, obtaining a local approximation through the linearization around an equilibrium point. In the case of an asymptotically stable equilibrium point convergence is given through the Bayesian inference schema of the Gaussian Process. Results for this are demonstrated in a numerical example.
<div id='section'>Paperid: <span id='pid'>1424, <a href='https://arxiv.org/pdf/2504.18854.pdf' target='_blank'>https://arxiv.org/pdf/2504.18854.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tengfei Xing, Xiaodan Ren, Jie Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.18854">Predicting Stress in Two-phase Random Materials and Super-Resolution Method for Stress Images by Embedding Physical Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Stress analysis is an important part of material design. For materials with complex microstructures, such as two-phase random materials (TRMs), material failure is often accompanied by stress concentration. Phase interfaces in two-phase materials are critical for stress concentration. Therefore, the prediction error of stress at phase boundaries is crucial. In practical engineering, the pixels of the obtained material microstructure images are limited, which limits the resolution of stress images generated by deep learning methods, making it difficult to observe stress concentration regions. Existing Image Super-Resolution (ISR) technologies are all based on data-driven supervised learning. However, stress images have natural physical constraints, which provide new ideas for new ISR technologies. In this study, we constructed a stress prediction framework for TRMs. First, the framework uses a proposed Multiple Compositions U-net (MC U-net) to predict stress in low-resolution material microstructures. By considering the phase interface information of the microstructure, the MC U-net effectively reduces the problem of excessive prediction errors at phase boundaries. Secondly, a Mixed Physics-Informed Neural Network (MPINN) based method for stress ISR (SRPINN) was proposed. By introducing the constraints of physical information, the new method does not require paired stress images for training and can increase the resolution of stress images to any multiple. This enables a multiscale analysis of the stress concentration regions at phase boundaries. Finally, we performed stress analysis on TRMs with different phase volume fractions and loading states through transfer learning. The results show the proposed stress prediction framework has satisfactory accuracy and generalization ability.
<div id='section'>Paperid: <span id='pid'>1425, <a href='https://arxiv.org/pdf/2504.16553.pdf' target='_blank'>https://arxiv.org/pdf/2504.16553.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Mahdi Abedi, David Pardo, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16553">Least-Squares-Embedded Optimization for Accelerated Convergence of PINNs in Acoustic Wavefield Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have shown promise in solving partial differential equations (PDEs), including the frequency-domain Helmholtz equation. However, standard training of PINNs using gradient descent (GD) suffers from slow convergence and instability, particularly for high-frequency wavefields. For scattered acoustic wavefield simulation based on Helmholtz equation, we derive a hybrid optimization framework that accelerates training convergence by embedding a least-squares (LS) solver directly into the GD loss function. This formulation enables optimal updates for the linear output layer. Our method is applicable with or without perfectly matched layers (PML), and we provide practical tensor-based implementations for both scenarios. Numerical experiments on benchmark velocity models demonstrate that our approach achieves faster convergence, higher accuracy, and improved stability compared to conventional PINN training. In particular, our results show that the LS-enhanced method converges rapidly even in cases where standard GD-based training fails. The LS solver operates on a small normal matrix, ensuring minimal computational overhead and making the method scalable for large-scale wavefield simulations.
<div id='section'>Paperid: <span id='pid'>1426, <a href='https://arxiv.org/pdf/2504.15806.pdf' target='_blank'>https://arxiv.org/pdf/2504.15806.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai Luo, Juan Tang, Mingchao Cai, Xiaoqing Zeng, Manqi Xie, Ming Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15806">DAE-KAN: A Kolmogorov-Arnold Network Model for High-Index Differential-Algebraic Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-layer Perceptrons (MLPs) due to their superior function-fitting abilities in data-driven modeling. In this paper, we propose a novel framework, DAE-KAN, for solving high-index differential-algebraic equations (DAEs) by integrating KANs with Physics-Informed Neural Networks (PINNs). This framework not only preserves the ability of traditional PINNs to model complex systems governed by physical laws but also enhances their performance by leveraging the function-fitting strengths of KANs. Numerical experiments demonstrate that for DAE systems ranging from index-1 to index-3, DAE-KAN reduces the absolute errors of both differential and algebraic variables by 1 to 2 orders of magnitude compared to traditional PINNs. To assess the effectiveness of this approach, we analyze the drift-off error and find that both PINNs and DAE-KAN outperform classical numerical methods in controlling this phenomenon. Our results highlight the potential of neural network methods, particularly DAE-KAN, in solving high-index DAEs with substantial computational accuracy and generalization, offering a promising solution for challenging partial differential-algebraic equations.
<div id='section'>Paperid: <span id='pid'>1427, <a href='https://arxiv.org/pdf/2504.12441.pdf' target='_blank'>https://arxiv.org/pdf/2504.12441.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Asutay Ozmen, JoÃ£o P. Hespanha, Katie Byl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.12441">Learning Transferable Friction Models and LuGre Identification via Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately modeling friction in robotics remains a core challenge, as robotics simulators like Mujoco and PyBullet use simplified friction models or heuristics to balance computational efficiency with accuracy, where these simplifications and approximations can lead to substantial differences between simulated and physical performance. In this paper, we present a physics-informed friction estimation framework that enables the integration of well-established friction models with learnable components-requiring only minimal, generic measurement data. Our approach enforces physical consistency yet retains the flexibility to adapt to real-world complexities. We demonstrate, on an underactuated and nonlinear system, that the learned friction models, trained solely on small and noisy datasets, accurately simulate dynamic friction properties and reduce the sim-to-real gap. Crucially, we show that our approach enables the learned models to be transferable to systems they are not trained on. This ability to generalize across multiple systems streamlines friction modeling for complex, underactuated tasks, offering a scalable and interpretable path toward bridging the sim-to-real gap in robotics and control.
<div id='section'>Paperid: <span id='pid'>1428, <a href='https://arxiv.org/pdf/2504.11383.pdf' target='_blank'>https://arxiv.org/pdf/2504.11383.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Wang, Maryam Hakimzadeh, Haihui Ruan, Somdatta Goswami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11383">Time Marching Neural Operator FE Coupling: AI Accelerated Physics Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Numerical solvers for PDEs often struggle to balance computational cost with accuracy, especially in multiscale and time-dependent systems. Neural operators offer a promising way to accelerate simulations, but their practical deployment is hindered by several challenges: they typically require large volumes of training data generated from high-fidelity solvers, tend to accumulate errors over time in dynamical settings, and often exhibit poor generalization in multiphysics scenarios. This work introduces a novel hybrid framework that integrates physics-informed deep operator network with FEM through domain decomposition and leverages numerical analysis for time marching. Our innovation lies in efficient coupling FE and DeepONet subdomains via a Schwarz method, expecting to solve complex and nonlinear regions by a pretrained DeepONet, while the remainder is handled by conventional FE. To address the challenges of dynamic systems, we embed a time stepping scheme directly into the DeepONet, substantially reducing long-term error propagation. Furthermore, an adaptive subdomain evolution strategy enables the ML-resolved region to expand dynamically, capturing fine-scale features without remeshing. Our framework shows accelerated convergence rates (up to 20% improvement in convergence rates compared to conventional FE coupling approaches) while preserving solution fidelity with error margins consistently below 3%. Our study shows that our proposed hybrid solver: (1) reduces computational costs by eliminating fine mesh requirements, (2) mitigates error accumulation in time-dependent simulations, and (3) enables automatic adaptation to evolving physical phenomena. This work establishes a new paradigm for coupling state of the art physics based and machine learning solvers in a unified framework, offering a robust, reliable, and scalable pathway for high fidelity multiscale simulations.
<div id='section'>Paperid: <span id='pid'>1429, <a href='https://arxiv.org/pdf/2504.09804.pdf' target='_blank'>https://arxiv.org/pdf/2504.09804.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Zhang, Liang Li, StÃ©phane Lanteri, Hao Kang, Jiaqi Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.09804">BO-SA-PINNs: Self-adaptive physics-informed neural networks based on Bayesian optimization for automatically designing PDE solvers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) is becoming a popular alternative method for solving partial differential equations (PDEs). However, they require dedicated manual modifications to the hyperparameters of the network, the sampling methods and loss function weights for different PDEs, which reduces the efficiency of the solvers. In this paper, we pro- pose a general multi-stage framework, i.e. BO-SA-PINNs to alleviate this issue. In the first stage, Bayesian optimization (BO) is used to select hyperparameters for the training process, and based on the results of the pre-training, the network architecture, learning rate, sampling points distribution and loss function weights suitable for the PDEs are automatically determined. The proposed hyperparameters search space based on experimental results can enhance the efficiency of BO in identifying optimal hyperparameters. After selecting the appropriate hyperparameters, we incorporate a global self-adaptive (SA) mechanism the second stage. Using the pre-trained model and loss information in the second-stage training, the exponential moving average (EMA) method is employed to optimize the loss function weights, and residual-based adaptive refinement with distribution (RAR-D) is used to optimize the sampling points distribution. In the third stage, L-BFGS is used for stable training. In addition, we introduce a new activation function that enables BO-SA-PINNs to achieve higher accuracy. In numerical experiments, we conduct comparative and ablation experiments to verify the performance of the model on Helmholtz, Maxwell, Burgers and high-dimensional Poisson equations. The comparative experiment results show that our model can achieve higher accuracy and fewer iterations in test cases, and the ablation experiments demonstrate the positive impact of every improvement.
<div id='section'>Paperid: <span id='pid'>1430, <a href='https://arxiv.org/pdf/2504.08484.pdf' target='_blank'>https://arxiv.org/pdf/2504.08484.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Martina Vanelli, Julien M. Hendrickx
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08484">Physics-informed data-driven control without persistence of excitation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We show that data that is not sufficiently informative to allow for system re-identification can still provide meaningful information when combined with external or physical knowledge of the system, such as bounded system matrix norms. We then illustrate how this information can be leveraged for safety and energy minimization problems and to enhance predictions in unmodelled dynamics. This preliminary work outlines key ideas toward using limited data for effective control by integrating physical knowledge of the system and exploiting interpolation conditions.
<div id='section'>Paperid: <span id='pid'>1431, <a href='https://arxiv.org/pdf/2504.08341.pdf' target='_blank'>https://arxiv.org/pdf/2504.08341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jin Woo Jang, Jae Yong Lee, Liu Liu, Zhenyi Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08341">Deep learning-based moment closure for multi-phase computation of semiclassical limit of the SchrÃ¶dinger equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a deep learning approach for computing multi-phase solutions to the semiclassical limit of the SchrÃ¶dinger equation. Traditional methods require deriving a multi-phase ansatz to close the moment system of the Liouville equation, a process that is often computationally intensive and impractical. Our method offers an efficient alternative by introducing a novel two-stage neural network framework to close the $2N\times 2N$ moment system, where $N$ represents the number of phases in the solution ansatz. In the first stage, we train neural networks to learn the mapping between higher-order moments and lower-order moments (along with their derivatives). The second stage incorporates physics-informed neural networks (PINNs), where we substitute the learned higher-order moments to systematically close the system. We provide theoretical guarantees for the convergence of both the loss functions and the neural network approximations. Numerical experiments demonstrate the effectiveness of our method for one- and two-dimensional problems with various phase numbers $N$ in the multi-phase solutions. The results confirm the accuracy and computational efficiency of the proposed approach compared to conventional techniques.
<div id='section'>Paperid: <span id='pid'>1432, <a href='https://arxiv.org/pdf/2504.08136.pdf' target='_blank'>https://arxiv.org/pdf/2504.08136.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kapil Chawla, William Holmes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08136">A physics informed neural network approach to simulating ice dynamics governed by the shallow ice approximation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this article we develop a Physics Informed Neural Network (PINN) approach to simulate ice sheet dynamics governed by the Shallow Ice Approximation. This problem takes the form of a time-dependent parabolic obstacle problem. Prior work has used this approach to address the stationary obstacle problem and here we extend it to the time dependent problem. Through comprehensive 1D and 2D simulations, we validate the model's effectiveness in capturing complex free-boundary conditions. By merging traditional mathematical modeling with cutting-edge deep learning methods, this approach provides a scalable and robust solution for predicting temporal variations in ice thickness. To illustrate this approach in a real world setting, we simulate the dynamics of the Devon Ice Cap, incorporating aerogeophysical data from 2000 and 2018.
<div id='section'>Paperid: <span id='pid'>1433, <a href='https://arxiv.org/pdf/2504.07058.pdf' target='_blank'>https://arxiv.org/pdf/2504.07058.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>K. Murari, P. Roul, S. Sundar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07058">A residual weighted physics informed neural network for forward and inverse problems of reaction diffusion equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we propose the Residual-Weighted Physics-Informed Neural Network (RW-PINN), a new method designed to enhance the accuracy of Physics-Informed Neural Network (PINN) based algorithms. We construct a deep learning framework with two residual-weighting schemes to solve reaction diffusion equations and evaluate its performance on both forward and inverse problems. The approach computes weights proportional to the PDE residuals, rescales them, and incorporates these scaled residuals into the loss function, leading to more stable training. Furthermore, we establish generalized error bounds that account for training and quadrature errors, and we analyze the convergence and stability of the method. The proposed algorithms are validated through numerical experiments on nonlinear equations, supported by statistical error analysis. To further demonstrate the effectiveness of our methodology, we implemented PINN-based forward and inverse frameworks for the nonlinear equations and conducted a comparative analysis with the proposed RW-PINN approach.
<div id='section'>Paperid: <span id='pid'>1434, <a href='https://arxiv.org/pdf/2504.04665.pdf' target='_blank'>https://arxiv.org/pdf/2504.04665.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Laurens R. Lueg, Victor Alves, Daniel Schicksnus, John R. Kitchin, Carl D. Laird, Lorenz T. Biegler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04665">A Simultaneous Approach for Training Neural Differential-Algebraic Systems of Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific machine learning is an emerging field that broadly describes the combination of scientific computing and machine learning to address challenges in science and engineering. Within the context of differential equations, this has produced highly influential methods, such as neural ordinary differential equations (NODEs). Recent works extend this line of research to consider neural differential-algebraic systems of equations (DAEs), where some unknown relationships within the DAE are learned from data. Training neural DAEs, similarly to neural ODEs, is computationally expensive, as it requires the solution of a DAE for every parameter update. Further, the rigorous consideration of algebraic constraints is difficult within common deep learning training algorithms such as stochastic gradient descent. In this work, we apply the simultaneous approach to neural DAE problems, resulting in a fully discretized nonlinear optimization problem, which is solved to local optimality and simultaneously obtains the neural network parameters and the solution to the corresponding DAE. We extend recent work demonstrating the simultaneous approach for neural ODEs, by presenting a general framework to solve neural DAEs, with explicit consideration of hybrid models, where some components of the DAE are known, e.g. physics-informed constraints. Furthermore, we present a general strategy for improving the performance and convergence of the nonlinear programming solver, based on solving an auxiliary problem for initialization and approximating Hessian terms. We achieve promising results in terms of accuracy, model generalizability and computational cost, across different problem settings such as sparse data, unobserved states and multiple trajectories. Lastly, we provide several promising future directions to improve the scalability and robustness of our approach.
<div id='section'>Paperid: <span id='pid'>1435, <a href='https://arxiv.org/pdf/2504.03244.pdf' target='_blank'>https://arxiv.org/pdf/2504.03244.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qinjiao Gao, Zuowei Wang, Ran Zhang, Dongjiang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03244">Adaptive Movement Sampling Physics-Informed Residual Network (AM-PIRN) for Solving Nonlinear Option Pricing models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose the Adaptive Movement Sampling Physics-Informed Residual Network (AM-PIRN) to address challenges in solving nonlinear option pricing PDE models, where solutions often exhibit significant curvature or shock waves over time. The AM-PIRN architecture is designed to concurrently minimize PDE residuals and achieve high-fidelity option price approximations by dynamically redistributing training points based on evolving PDE residuals, while maintaining a fixed total number of points. To enhance stability and training efficiency, we integrate a ResNet backbone, replacing conventional fully connected neural networks used in Physics-Informed Neural Networks (PINNs). Numerical experiments across nonlinear option pricing models demonstrate that AM-PIRN outperforms PINN, RAM-PINN, and WAM-PINN in both resolving PDE constraints and accurately estimating option prices. The method's advantages are particularly pronounced in complex or multi-dimensional models, where its adaptive sampling and robust architecture effectively mitigate challenges posed by sharp gradients and high nonlinearity.
<div id='section'>Paperid: <span id='pid'>1436, <a href='https://arxiv.org/pdf/2504.03209.pdf' target='_blank'>https://arxiv.org/pdf/2504.03209.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinwei Liu, Wang Yao, Xiao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03209">PIONM: A Generalized Approach to Solving Density-Constrained Mean-Field Games Equilibrium under Modified Boundary Conditions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural network-based methods are effective for solving equilibria in Mean-Field Games (MFGs), particularly in high-dimensional settings. However, solving the coupled partial differential equations (PDEs) in MFGs limits their applicability since solving coupled PDEs is computationally expensive. Additionally, modifying boundary conditions, such as the initial state distribution or terminal value function, necessitates extensive retraining, reducing scalability. To address these challenges, we propose a generalized framework, PIONM (Physics-Informed Neural Operator NF-MKV Net), which leverages physics-informed neural operators to solve MFGs equations. PIONM utilizes neural operators to compute MFGs equilibria for arbitrary boundary conditions. The method encodes boundary conditions as input features and trains the model to align them with density evolution, modeled using discrete-time normalizing flows. Once trained, the algorithm efficiently computes the density distribution at any time step for modified boundary condition, ensuring efficient adaptation to different boundary conditions in MFGs equilibria. Unlike traditional MFGs methods constrained by fixed coefficients, PIONM efficiently computes equilibria under varying boundary conditions, including obstacles, diffusion coefficients, initial densities, and terminal functions. PIONM can adapt to modified conditions while preserving density distribution constraints, demonstrating superior scalability and generalization capabilities compared to existing methods.
<div id='section'>Paperid: <span id='pid'>1437, <a href='https://arxiv.org/pdf/2504.01093.pdf' target='_blank'>https://arxiv.org/pdf/2504.01093.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christopher Straub, Philipp Brendel, Vlad Medvedev, Andreas Rosskopf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01093">Hard-constraining Neumann boundary conditions in physics-informed neural networks via Fourier feature embeddings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel approach to hard-constrain Neumann boundary conditions in physics-informed neural networks (PINNs) using Fourier feature embeddings. Neumann boundary conditions are used to described critical processes in various application, yet they are more challenging to hard-constrain in PINNs than Dirichlet conditions. Our method employs specific Fourier feature embeddings to directly incorporate Neumann boundary conditions into the neural network's architecture instead of learning them. The embedding can be naturally extended by high frequency modes to better capture high frequency phenomena. We demonstrate the efficacy of our approach through experiments on a diffusion problem, for which our method outperforms existing hard-constraining methods and classical PINNs, particularly in multiscale and high frequency scenarios.
<div id='section'>Paperid: <span id='pid'>1438, <a href='https://arxiv.org/pdf/2503.22396.pdf' target='_blank'>https://arxiv.org/pdf/2503.22396.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Josu Yeregui, Iker Lopetegi, Sergio Fernandez, Erik Garayalde, Unai Iraola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22396">On-site estimation of battery electrochemical parameters via transfer learning based physics-informed neural network approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel physical parameter estimation framework for on-site model characterization, using a two-phase modelling strategy with Physics-Informed Neural Networks (PINNs) and transfer learning (TL). In the first phase, a PINN is trained using only the physical principles of the single particle model (SPM) equations. In the second phase, the majority of the PINN parameters are frozen, while critical electrochemical parameters are set as trainable and adjusted using real-world voltage profile data. The proposed approach significantly reduces computational costs, making it suitable for real-time implementation on Battery Management Systems (BMS). Additionally, as the initial phase does not require field data, the model is easy to deploy with minimal setup requirements. With the proposed methodology, we have been able to effectively estimate relevant electrochemical parameters with operating data. This has been proved estimating diffusivities and active material volume fractions with charge data in different degradation conditions. The methodology is experimentally validated in a Raspberry Pi device using data from a standard charge profile with a 3.89\% relative accuracy estimating the active material volume fractions of a NMC cell with 82.09\% of its nominal capacity.
<div id='section'>Paperid: <span id='pid'>1439, <a href='https://arxiv.org/pdf/2503.20144.pdf' target='_blank'>https://arxiv.org/pdf/2503.20144.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seyedeh Azadeh Fallah Mortezanejad, Ruochen Wang, Ali Mohammad-Djafari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.20144">Physics-Informed Neural Networks with Unknown Partial Differential Equations: an Application in Multivariate Time Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A significant advancement in Neural Network (NN) research is the integration of domain-specific knowledge through custom loss functions. This approach addresses a crucial challenge: how can models utilize physics or mathematical principles to enhance predictions when dealing with sparse, noisy, or incomplete data? Physics-Informed Neural Networks (PINNs) put this idea into practice by incorporating physical equations, such as Partial Differential Equations (PDEs), as soft constraints. This guidance helps the networks find solutions that align with established laws. Recently, researchers have expanded this framework to include Bayesian NNs (BNNs), which allow for uncertainty quantification while still adhering to physical principles. But what happens when the governing equations of a system are not known? In this work, we introduce methods to automatically extract PDEs from historical data. We then integrate these learned equations into three different modeling approaches: PINNs, Bayesian-PINNs (B-PINNs), and Bayesian Linear Regression (BLR). To assess these frameworks, we evaluate them on a real-world Multivariate Time Series (MTS) dataset. We compare their effectiveness in forecasting future states under different scenarios: with and without PDE constraints and accuracy considerations. This research aims to bridge the gap between data-driven discovery and physics-guided learning, providing valuable insights for practical applications.
<div id='section'>Paperid: <span id='pid'>1440, <a href='https://arxiv.org/pdf/2503.16310.pdf' target='_blank'>https://arxiv.org/pdf/2503.16310.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingdong Ru, Lipeng Zhuang, Zhuo He, Florent P. Audonnet, Gerardo Aragon-Caramasa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16310">Can Real-to-Sim Approaches Capture Dynamic Fabric Behavior for Robotic Fabric Manipulation?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a rigorous evaluation of Real-to-Sim parameter estimation approaches for fabric manipulation in robotics. The study systematically assesses three state-of-the-art approaches, namely two differential pipelines and a data-driven approach. We also devise a novel physics-informed neural network approach for physics parameter estimation. These approaches are interfaced with two simulations across multiple Real-to-Sim scenarios (lifting, wind blowing, and stretching) for five different fabric types and evaluated on three unseen scenarios (folding, fling, and shaking). We found that the simulation engines and the choice of Real-to-Sim approaches significantly impact fabric manipulation performance in our evaluation scenarios. Moreover, PINN observes superior performance in quasi-static tasks but shows limitations in dynamic scenarios.
<div id='section'>Paperid: <span id='pid'>1441, <a href='https://arxiv.org/pdf/2503.13123.pdf' target='_blank'>https://arxiv.org/pdf/2503.13123.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xintian Yuan, Yunke Ao, Boqi Chen, Philipp Fuernstahl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13123">MIXPINN: Mixed-Material Simulations by Physics-Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulating the complex interactions between soft tissues and rigid anatomy is critical for applications in surgical training, planning, and robotic-assisted interventions. Traditional Finite Element Method (FEM)-based simulations, while accurate, are computationally expensive and impractical for real-time scenarios. Learning-based approaches have shown promise in accelerating predictions but have fallen short in modeling soft-rigid interactions effectively. We introduce MIXPINN, a physics-informed Graph Neural Network (GNN) framework for mixed-material simulations, explicitly capturing soft-rigid interactions using graph-based augmentations. Our approach integrates Virtual Nodes (VNs) and Virtual Edges (VEs) to enhance rigid body constraint satisfaction while preserving computational efficiency. By leveraging a graph-based representation of biomechanical structures, MIXPINN learns high-fidelity deformations from FEM-generated data and achieves real-time inference with sub-millimeter accuracy. We validate our method in a realistic clinical scenario, demonstrating superior performance compared to baseline GNN models and traditional FEM methods. Our results show that MIXPINN reduces computational cost by an order of magnitude while maintaining high physical accuracy, making it a viable solution for real-time surgical simulation and robotic-assisted procedures.
<div id='section'>Paperid: <span id='pid'>1442, <a href='https://arxiv.org/pdf/2503.10032.pdf' target='_blank'>https://arxiv.org/pdf/2503.10032.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chang-Ock Lee, Byungeun Ryoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.10032">A Neumann-Neumann Acceleration with Coarse Space for Domain Decomposition of Extreme Learning Machines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Extreme learning machines (ELMs), which preset hidden layer parameters and solve for last layer coefficients via a least squares method, can typically solve partial differential equations faster and more accurately than Physics Informed Neural Networks. However, they remain computationally expensive when high accuracy requires large least squares problems to be solved. Domain decomposition methods (DDMs) for ELMs have allowed parallel computation to reduce training times of large systems. This paper constructs a coarse space for ELMs, which enables further acceleration of their training. By partitioning interface variables into coarse and non-coarse variables, selective elimination introduces a Schur complement system on the non-coarse variables with the coarse problem embedded. Key to the performance of the proposed method is a Neumann-Neumann acceleration that utilizes the coarse space. Numerical experiments demonstrate significant speedup compared to a previous DDM method for ELMs.
<div id='section'>Paperid: <span id='pid'>1443, <a href='https://arxiv.org/pdf/2503.05009.pdf' target='_blank'>https://arxiv.org/pdf/2503.05009.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Divakar Vashisth, Rohan Sharma, Tapan Mukerji, Mrinal K. Sen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05009">Seismic inversion using hybrid quantum neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantum computing leverages qubits, exploiting superposition and entanglement to solve problems intractable for classical computers, offering significant computational advantages. Quantum machine learning (QML), which integrates quantum computing with machine learning, holds immense potential across various fields but remains largely unexplored in geosciences. However, its progress is hindered by the limitations of current NISQ hardware. To address these challenges, hybrid quantum neural networks (HQNNs) have emerged, combining quantum layers within classical neural networks to leverage the strengths of both paradigms. To the best of our knowledge, this study presents the first application of QML to subsurface imaging through the development of hybrid quantum physics-informed neural networks (HQ-PINNs) for seismic inversion. We apply the HQ-PINN framework to invert pre-stack and post-stack seismic datasets, estimating P- and S-impedances. The proposed HQ-PINN architecture follows an encoder-decoder structure, where the encoder (HQNN), processes seismic data to estimate elastic parameters, while the decoder utilizes these parameters to generate the corresponding seismic data based on geophysical relationships. The HQ-PINN model is trained by minimizing the misfit between the input and predicted seismic data generated by the decoder. We systematically evaluate various quantum layer configurations, differentiation methods, and quantum device simulators on the inversion performance, and demonstrate real-world applicability through the individual and simultaneous inversion cases of the Sleipner dataset. The HQ-PINN framework consistently and efficiently estimated accurate subsurface impedances across the synthetic and field case studies, establishing the feasibility of leveraging QML for seismic inversion, thereby paving the way for broader applications of quantum computing in geosciences.
<div id='section'>Paperid: <span id='pid'>1444, <a href='https://arxiv.org/pdf/2503.02267.pdf' target='_blank'>https://arxiv.org/pdf/2503.02267.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sourav Mishra, Shreya Hallikeri, Suresh Sundaram
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.02267">REAct: Rational Exponential Activation for Better Learning and Generalization in PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) offer a promising approach to simulating physical systems. Still, their application is limited by optimization challenges, mainly due to the lack of activation functions that generalize well across several physical systems. Existing activation functions often lack such flexibility and generalization power. To address this issue, we introduce Rational Exponential Activation (REAct), a generalized form of tanh consisting of four learnable shape parameters. Experiments show that REAct outperforms many standard and benchmark activations, achieving an MSE three orders of magnitude lower than tanh on heat problems and generalizing well to finer grids and points beyond the training domain. It also excels at function approximation tasks and improves noise rejection in inverse problems, leading to more accurate parameter estimates across varying noise levels.
<div id='section'>Paperid: <span id='pid'>1445, <a href='https://arxiv.org/pdf/2503.00814.pdf' target='_blank'>https://arxiv.org/pdf/2503.00814.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Min Wang, Haisheng Li, Haoxuan Zhang, Xiaoqun Wu, Nan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00814">PINN-MG: A physics-informed neural network for mesh generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In numerical simulation, structured mesh generation often requires a lot of time and manpower investment. The general scheme for structured quad mesh generation is to find a mapping between the computational domain and the physical domain. This mapping can be obtained by solving partial differential equations. However, existing structured mesh generation methods are difficult to ensure both efficiency and mesh quality. In this paper, we propose a structured mesh generation method based on physics-informed neural network, PINN-MG. It takes boundary curves as input and then utilizes an attention network to capture the potential mapping between computational and physical domains, generating structured meshes for the input physical domain. PINN-MG introduces the Navier-LamÃ© equation in linear elastic as a partial differential equation term in the loss function, ensuring that the neural network conforms to the law of elastic body deformation when optimizing the loss value. The training process of PINN-MG is completely unsupervised and does not require any prior knowledge or datasets, which greatly reduces the previous workload of producing structured mesh datasets. Experimental results show that PINN-MG can generate higher quality structured quad meshes than other methods, and has the advantages of traditional algebraic methods and differential methods.
<div id='section'>Paperid: <span id='pid'>1446, <a href='https://arxiv.org/pdf/2503.00213.pdf' target='_blank'>https://arxiv.org/pdf/2503.00213.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Alberts, Ilias Bilionis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00213">An interpretation of the Brownian bridge as a physics-informed prior for the Poisson equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning is one of the most commonly used methods for fusing physical knowledge in the form of partial differential equations with experimental data. The idea is to construct a loss function where the physical laws take the place of a regularizer and minimize it to reconstruct the underlying physical fields and any missing parameters. However, there is a noticeable lack of a direct connection between physics-informed loss functions and an overarching Bayesian framework. In this work, we demonstrate that Brownian bridge Gaussian processes can be viewed as a softly-enforced physics-constrained prior for the Poisson equation. We first show equivalence between the variational form of the physics-informed loss function for the Poisson equation and a kernel ridge regression objective. Then, through the connection between Gaussian process regression and kernel methods, we identify a Gaussian process for which the posterior mean function and physics-informed loss function minimizer agree. This connection allows us to probe different theoretical questions, such as convergence and behavior of inverse problems. We also connect the method to the important problem of identifying model-form error in applications.
<div id='section'>Paperid: <span id='pid'>1447, <a href='https://arxiv.org/pdf/2502.19056.pdf' target='_blank'>https://arxiv.org/pdf/2502.19056.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Iliana Loi, Konstantinos Moustakas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19056">Fatigue-PINN: Physics-Informed Fatigue-Driven Motion Modulation and Synthesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fatigue modeling is essential for motion synthesis tasks to model human motions under fatigued conditions and biomechanical engineering applications, such as investigating the variations in movement patterns and posture due to fatigue, defining injury risk mitigation and prevention strategies, formulating fatigue minimization schemes and creating improved ergonomic designs. Nevertheless, employing data-driven methods for synthesizing the impact of fatigue on motion, receives little to no attention in the literature. In this work, we present Fatigue-PINN, a deep learning framework based on Physics-Informed Neural Networks, for modeling fatigued human movements, while providing joint-specific fatigue configurations for adaptation and mitigation of motion artifacts on a joint level, resulting in more realistic animations. To account for muscle fatigue, we simulate the fatigue-induced fluctuations in the maximum exerted joint torques by leveraging a PINN adaptation of the Three-Compartment Controller model to exploit physics-domain knowledge for improving accuracy. This model also introduces parametric motion alignment with respect to joint-specific fatigue, hence avoiding sharp frame transitions. Our results indicate that Fatigue-PINN accurately simulates the effects of externally perceived fatigue on open-type human movements being consistent with findings from real-world experimental fatigue studies. Since fatigue is incorporated in torque space, Fatigue-PINN provides an end-to-end encoder-decoder-like architecture, to ensure transforming joint angles to joint torques and vice-versa, thus, being compatible with motion synthesis frameworks operating on joint angles.
<div id='section'>Paperid: <span id='pid'>1448, <a href='https://arxiv.org/pdf/2502.17134.pdf' target='_blank'>https://arxiv.org/pdf/2502.17134.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Mahdi Abedi, David Pardo, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.17134">Gabor-Enhanced Physics-Informed Neural Networks for Fast Simulations of Acoustic Wavefields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have gained increasing attention for solving partial differential equations, including the Helmholtz equation, due to their flexibility and mesh-free formulation. However, their low-frequency bias limits their accuracy and convergence speed for high-frequency wavefield simulations. To alleviate these problems, we propose a simplified PINN framework that incorporates Gabor functions, designed to capture the oscillatory and localized nature of wavefields more effectively. Unlike previous attempts that rely on auxiliary networks to learn Gabor parameters, we redefine the network's task to map input coordinates to a custom Gabor coordinate system, simplifying the training process without increasing the number of trainable parameters compared to a simple PINN. We validate the proposed method across multiple velocity models, including the complex Marmousi and Overthrust models, and demonstrate its superior accuracy, faster convergence, and better robustness features compared to both traditional PINNs and earlier Gabor-based PINNs. Additionally, we propose an efficient integration of a Perfectly Matched Layer (PML) to enhance wavefield behavior near the boundaries. These results suggest that our approach offers an efficient and accurate alternative for scattered wavefield modeling and lays the groundwork for future improvements in PINN-based seismic applications.
<div id='section'>Paperid: <span id='pid'>1449, <a href='https://arxiv.org/pdf/2502.07325.pdf' target='_blank'>https://arxiv.org/pdf/2502.07325.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuan Guo, Zhuojia Fu, Jian Min, Shiyu Lin, Xiaoting Liu, Youssef F. Rashed, Xiaoying Zhuang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07325">Long-term simulation of physical and mechanical behaviors using curriculum-transfer-learning based physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a Curriculum-Transfer-Learning based physics-informed neural network (CTL-PINN) for long-term simulation of physical and mechanical behaviors. The main innovation of CTL-PINN lies in decomposing long-term problems into a sequence of short-term subproblems. Initially, the standard PINN is employed to solve the first sub-problem. As the simulation progresses, subsequent time-domain problems are addressed using a curriculum learning approach that integrates information from previous steps. Furthermore, transfer learning techniques are incorporated, allowing the model to effectively utilize prior training data and solve sequential time domain transfer problems. CTL-PINN combines the strengths of curriculum learning and transfer learning, overcoming the limitations of standard PINNs, such as local optimization issues, and addressing the inaccuracies over extended time domains encountered in CL-PINN and the low computational efficiency of TL-PINN. The efficacy and robustness of CTL-PINN are demonstrated through applications to nonlinear wave propagation, Kirchhoff plate dynamic response, and the hydrodynamic model of the Three Gorges Reservoir Area, showcasing its superior capability in addressing long-term computational challenges.
<div id='section'>Paperid: <span id='pid'>1450, <a href='https://arxiv.org/pdf/2502.07293.pdf' target='_blank'>https://arxiv.org/pdf/2502.07293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanxiao Hu, Ye Sheng, Jing Huang, Xiaoxin Xu, Yuyan Yang, Mingqiang Zhang, Yabei Wu, Caichao Ye, Jiong Yang, Wenqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07293">Global Universal Scaling and Ultra-Small Parameterization in Machine Learning Interatomic Potentials with Super-Linearity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Using machine learning (ML) to construct interatomic interactions and thus potential energy surface (PES) has become a common strategy for materials design and simulations. However, those current models of machine learning interatomic potential (MLIP) provide no relevant physical constrains, and thus may owe intrinsic out-of-domain difficulty which underlies the challenges of model generalizability and physical scalability. Here, by incorporating physics-informed Universal-Scaling law and nonlinearity-embedded interaction function, we develop a Super-linear MLIP with both Ultra-Small parameterization and greatly expanded expressive capability, named SUS2-MLIP. Due to the global scaling rooting in universal equation of state (UEOS), SUS2-MLIP not only has significantly-reduced parameters by decoupling the element space from coordinate space, but also naturally outcomes the out-of-domain difficulty and endows the potentials with inherent generalizability and scalability even with relatively small training dataset. The nonlinearity-enbeding transformation for interaction function expands the expressive capability and make the potentials super-linear. The SUS2-MLIP outperforms the state-of-the-art MLIP models with its exceptional computational efficiency especially for multiple-element materials and physical scalability in property prediction. This work not only presents a highly-efficient universal MLIP model but also sheds light on incorporating physical constraints into artificial-intelligence-aided materials simulation.
<div id='section'>Paperid: <span id='pid'>1451, <a href='https://arxiv.org/pdf/2502.07093.pdf' target='_blank'>https://arxiv.org/pdf/2502.07093.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahadevan Ganesh, Stuart C. Hawkins, Darko Volkov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07093">Machine learning on manifolds for inverse scattering: Lipschitz stability analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Establishing Lipschitz stability estimates is crucial for ensuring the mathematical robustness of neural network (NN) approximations in machine learning (ML)-based parameter estimation, particularly in physics-informed settings. In this work, we derive such estimates for the inverse of a nonlinear map defined on a manifold that captures both unknown parameters and the nonlinear physical processes they influence. Our analysis is based on finite-dimensional, learnable representations of the manifold and provides Lipschitz stability estimates on the manifold-based subspaces, for a class of inverse maps associated with parameter dependent linear compact operators. Such operators model scattered and far-field data that can be used to detect structures such as cracks. We apply our theoretical ML manifold framework to inverse Helmholtz problems in unbounded regions exterior to cracks, addressing the scattered-field data-driven inverse problem while ensuring injectivity conditions on the manifold, a requirement for the Lipschitz stability. Our method accurately recovers crack-defining parameters without requiring prior knowledge of inputs such as incident wave types or external forces on the crack. Numerical experiments using NN approximations confirm the accuracy, efficiency, and robustness of the proposed approach.
<div id='section'>Paperid: <span id='pid'>1452, <a href='https://arxiv.org/pdf/2502.03670.pdf' target='_blank'>https://arxiv.org/pdf/2502.03670.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ãsak PÃ©tursson, MarÃ­a ÃskarsdÃ³ttir
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03670">Chaos into Order: Neural Framework for Expected Value Estimation of Stochastic Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Stochastic partial differential equations (SPDEs) describe the evolution of random processes over space and time, but their solutions are often analytically intractable and computationally expensive to estimate. In this paper, we propose the Learned Expectation Collapser (LEC), a physics-informed neural framework designed to approximate the expected value of linear SPDE solutions without requiring domain discretization. By leveraging randomized sampling of both space-time coordinates and noise realizations during training, LEC trains standard feedforward neural networks to minimize residual loss across multiple stochastic samples. We hypothesize and empirically confirm that this training regime drives the network to converge toward the expected value of the solution of the SPDE. Using the stochastic heat equation as a testbed, we evaluate performance across a diverse set of 144 experimental configurations that span multiple spatial dimensions, noise models, and forcing functions. The results show that the model consistently learns accurate approximations of the expected value of the solution in lower dimensions and a predictable decrease in accuracy with increased spatial dimensions, with improved stability and robustness under increased Monte Carlo sampling. Our findings offer new insight into how neural networks implicitly learn statistical structure from stochastic differential operators and suggest a pathway toward scalable, simulator-free SPDE solvers.
<div id='section'>Paperid: <span id='pid'>1453, <a href='https://arxiv.org/pdf/2501.17281.pdf' target='_blank'>https://arxiv.org/pdf/2501.17281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emilien Seiler, Wanzhou Lei, Pavlos Protopapas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.17281">Stiff Transfer Learning for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Stiff differential equations are prevalent in various scientific domains, posing significant challenges due to the disparate time scales of their components. As computational power grows, physics-informed neural networks (PINNs) have led to significant improvements in modeling physical processes described by differential equations. Despite their promising outcomes, vanilla PINNs face limitations when dealing with stiff systems, known as failure modes. In response, we propose a novel approach, stiff transfer learning for physics-informed neural networks (STL-PINNs), to effectively tackle stiff ordinary differential equations (ODEs) and partial differential equations (PDEs). Our methodology involves training a Multi-Head-PINN in a low-stiff regime, and obtaining the final solution in a high stiff regime by transfer learning. This addresses the failure modes related to stiffness in PINNs while maintaining computational efficiency by computing "one-shot" solutions. The proposed approach demonstrates superior accuracy and speed compared to PINNs-based methods, as well as comparable computational efficiency with implicit numerical methods in solving stiff-parameterized linear and polynomial nonlinear ODEs and PDEs under stiff conditions. Furthermore, we demonstrate the scalability of such an approach and the superior speed it offers for simulations involving initial conditions and forcing function reparametrization.
<div id='section'>Paperid: <span id='pid'>1454, <a href='https://arxiv.org/pdf/2501.16370.pdf' target='_blank'>https://arxiv.org/pdf/2501.16370.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahdi Movahedian Moghaddam, Kourosh Parand, Saeed Reza Kheradpisheh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16370">Advanced Physics-Informed Neural Network with Residuals for Solving Complex Integral Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present the Residual Integral Solver Network (RISN), a novel neural network architecture designed to solve a wide range of integral and integro-differential equations, including one-dimensional, multi-dimensional, ordinary and partial integro-differential, systems, fractional types, and Helmholtz-type integral equations involving oscillatory kernels. RISN integrates residual connections with high-accuracy numerical methods such as Gaussian quadrature and fractional derivative operational matrices, enabling it to achieve higher accuracy and stability than traditional Physics-Informed Neural Networks (PINN). The residual connections help mitigate vanishing gradient issues, allowing RISN to handle deeper networks and more complex kernels, particularly in multi-dimensional problems. Through extensive experiments, we demonstrate that RISN consistently outperforms not only classical PINNs but also advanced variants such as Auxiliary PINN (A-PINN) and Self-Adaptive PINN (SA-PINN), achieving significantly lower Mean Absolute Errors (MAE) across various types of equations. These results highlight RISN's robustness and efficiency in solving challenging integral and integro-differential problems, making it a valuable tool for real-world applications where traditional methods often struggle.
<div id='section'>Paperid: <span id='pid'>1455, <a href='https://arxiv.org/pdf/2501.15849.pdf' target='_blank'>https://arxiv.org/pdf/2501.15849.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingzhou Yin, Matthias A. MÃ¼ller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.15849">Gaussian Process-Based Prediction and Control of Hammerstein-Wiener Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work investigates data-driven prediction and control of Hammerstein-Wiener systems using physics-informed Gaussian process models. Data-driven prediction algorithms have been developed for structured nonlinear systems based on Willems' fundamental lemma. However, existing frameworks cannot treat output nonlinearities and require a dictionary of basis functions for Hammerstein systems. In this work, an implicit predictor structure is considered, leveraging the multi-step-ahead ARX structure for the linear part of the model. This implicit function is learned by Gaussian process regression with kernel functions designed from Gaussian process priors for the nonlinearities. The linear model parameters are estimated as hyperparameters by assuming a stable spline hyperprior. The implicit Gaussian process model provides explicit output prediction by optimizing selected optimality criteria. The model is also applied to receding horizon control with the expected control cost and chance constraint satisfaction guarantee. Numerical results demonstrate that the proposed prediction and control algorithms are superior to black-box Gaussian process models.
<div id='section'>Paperid: <span id='pid'>1456, <a href='https://arxiv.org/pdf/2501.13271.pdf' target='_blank'>https://arxiv.org/pdf/2501.13271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peiqi Li, Jie Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.13271">Hybrid Two-Stage Reconstruction of Multiscale Subsurface Flow with Physics-informed Residual Connected Neural Operator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The novel neural networks show great potential in solving partial differential equations. For single-phase flow problems in subsurface porous media with high-contrast coefficients, the key is to develop neural operators with accurate reconstruction capability and strict adherence to physical laws. In this study, we proposed a hybrid two-stage framework that uses multiscale basis functions and physics-guided deep learning to solve the Darcy flow problem in high-contrast fractured porous media. In the first stage, a data-driven model is used to reconstruct the multiscale basis function based on the permeability field to achieve effective dimensionality reduction while preserving the necessary multiscale features. In the second stage, the physics-informed neural network, together with Transformer-based global information extractor is used to reconstruct the pressure field by integrating the physical constraints derived from the Darcy equation, ensuring consistency with the physical laws of the real world. The model was evaluated on datasets with different combinations of permeability and basis functions and performed well in terms of reconstruction accuracy. Specifically, the framework achieves R2 values above 0.9 in terms of basis function fitting and pressure reconstruction, and the residual indicator is on the order of $1\times 10^{-4}$. These results validate the ability of the proposed framework to achieve accurate reconstruction while maintaining physical consistency.
<div id='section'>Paperid: <span id='pid'>1457, <a href='https://arxiv.org/pdf/2501.12116.pdf' target='_blank'>https://arxiv.org/pdf/2501.12116.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro TarancÃ³n-Ãlvarez, Pablo Tejerina-PÃ©rez, Raul Jimenez, Pavlos Protopapas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12116">Efficient PINNs via Multi-Head Unimodular Regularization of the Solutions Space</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Non-linear differential equations are a fundamental tool to describe different phenomena in nature. However, we still lack a well-established method to tackle stiff differential equations. Here we present a machine learning framework to facilitate the solution of nonlinear multiscale differential equations and, especially, inverse problems using Physics-Informed Neural Networks (PINNs). This framework is based on what is called \textit{multi-head} (MH) training, which involves training the network to learn a general space of all solutions for a given set of equations with certain variability, rather than learning a specific solution of the system. This setup is used with a second novel technique that we call Unimodular Regularization (UR) of the latent space of solutions. We show that the multi-head approach, combined with Unimodular Regularization, significantly improves the efficiency of PINNs by facilitating the transfer learning process thereby enabling the finding of solutions for nonlinear, coupled, and multiscale differential equations.
<div id='section'>Paperid: <span id='pid'>1458, <a href='https://arxiv.org/pdf/2501.11323.pdf' target='_blank'>https://arxiv.org/pdf/2501.11323.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhen Zhang, Jun Hui Qiu, Jun Wei Zhang, Hui Dong Li, Dong Tang, Qiang Cheng, Wei Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.11323">Physics-Informed Machine Learning for Efficient Reconfigurable Intelligent Surface Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reconfigurable intelligent surface (RIS) is a two-dimensional periodic structure integrated with a large number of reflective elements, which can manipulate electromagnetic waves in a digital way, offering great potentials for wireless communication and radar detection applications. However, conventional RIS designs highly rely on extensive full-wave EM simulations that are extremely time-consuming. To address this challenge, we propose a machine-learning-assisted approach for efficient RIS design. An accurate and fast model to predict the reflection coefficient of RIS element is developed by combining a multi-layer perceptron neural network (MLP) and a dual-port network, which can significantly reduce tedious EM simulations in the network training. A RIS has been practically designed based on the proposed method. To verify the proposed method, the RIS has also been fabricated and measured. The experimental results are in good agreement with the simulation results, which validates the efficacy of the proposed method in RIS design.
<div id='section'>Paperid: <span id='pid'>1459, <a href='https://arxiv.org/pdf/2501.10162.pdf' target='_blank'>https://arxiv.org/pdf/2501.10162.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexandre Caboussat, Anna Peruso
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.10162">Convex Physics Informed Neural Networks for the Monge-AmpÃ¨re Optimal Transport Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optimal transportation of raw material from suppliers to customers is an issue arising in logistics that is addressed here with a continuous model relying on optimal transport theory. A physics informed neuralnetwork method is advocated here for the solution of the corresponding generalized Monge-Amp`ere equation. Convex neural networks are advocated to enforce the convexity of the solution to the Monge-AmpÃ¨re equation and obtain a suitable approximation of the optimal transport map. A particular focus is set on the enforcement of transport boundary conditions in the loss function. Numerical experiments illustrate the solution to the optimal transport problem in several configurations, and sensitivity analyses are performed.
<div id='section'>Paperid: <span id='pid'>1460, <a href='https://arxiv.org/pdf/2501.09298.pdf' target='_blank'>https://arxiv.org/pdf/2501.09298.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ying Qian, Kui Zhang, Ãric Marty, Avranil Basu, Eamon B. O'Dea, Xianqiao Wang, Spencer Fox, Pejman Rohani, John M. Drake, He Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.09298">Physics-informed deep learning for infectious disease forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate forecasting of contagious diseases is critical for public health policymaking and pandemic preparedness. We propose a new infectious disease forecasting model based on physics-informed neural networks (PINNs), an emerging scientific machine learning approach. By embedding a compartmental model into the loss function, our method integrates epidemiological theory with data, helping to prevent model overfitting. We further enhance the model with a sub-network that accounts for covariates such as mobility and cumulative vaccine doses, which influence the transmission rate. Using state-level COVID-19 data from California, we demonstrate that the PINN model accurately predicts cases, deaths, and hospitalizations, aligning well with existing benchmarks. Notably, the PINN model outperforms naive baseline forecasts and several sequence deep learning models, including Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, Gated Recurrent Units (GRUs), and Transformers. It also achieves performance comparable to a sophisticated Gaussian infection state forecasting model that combines compartmental dynamics, a data observation model, and parameter regression. However, the PINN model features a simpler structure and is easier to implement. In summary, we systematically evaluate the PINN model's ability to forecast infectious disease dynamics, demonstrating its potential as an efficient computational tool to strengthen forecasting capabilities.
<div id='section'>Paperid: <span id='pid'>1461, <a href='https://arxiv.org/pdf/2501.09034.pdf' target='_blank'>https://arxiv.org/pdf/2501.09034.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>C. P. Batuwatta-Gamage, H. Jeong, HCP Karunasena, M. A. Karim, C. M. Rathnayaka, Y. T. Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.09034">Physics-Informed Machine Learning for Microscale Drying of Plant-Based Foods: A Systematic Review of Computational Models and Experimental Insights</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This review examines the current state of research on microscale cellular changes during the drying of plant-based food materials (PBFM), with particular emphasis on computational modelling approaches. The review addresses the critical need for advanced computational methods in microscale investigations. We systematically analyse experimental studies in PBFM drying, highlighting their contributions and limitations in capturing cellular-level phenomena, including challenges in data acquisition and measurement accuracy under varying drying conditions. The evolution of computational models for microstructural investigations is thoroughly examined, from traditional numerical methods to contemporary state-of-the-art approaches, with specific focus on their ability to handle the complex, nonlinear properties of plant cellular materials. Special attention is given to the emergence of data-driven models and their limitations in predicting microscale cellular behaviour during PBFM drying, particularly addressing challenges in dataset acquisition and model generalization. The review provides an in-depth analysis of Physics-Informed Machine Learning (PIML) frameworks, examining their theoretical foundations, current applications in related fields, and unique advantages in combining physical principles with neural network architectures. Through this comprehensive assessment, we identify critical gaps in existing methodologies, evaluate the trade-offs between different modelling approaches, and provide insights into future research directions for improving our understanding of cellular-level transformations during PBFM drying processes. The review concludes with recommendations for integrating experimental and computational approaches to advance the field of food preservation technology.
<div id='section'>Paperid: <span id='pid'>1462, <a href='https://arxiv.org/pdf/2501.08501.pdf' target='_blank'>https://arxiv.org/pdf/2501.08501.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiwei Gao, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08501">Scalable Bayesian Physics-Informed Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Uncertainty quantification (UQ) plays a pivotal role in scientific machine learning, especially when surrogate models are used to approximate complex systems. Although multilayer perceptions (MLPs) are commonly employed as surrogates, they often suffer from overfitting due to their large number of parameters. Kolmogorov-Arnold networks (KANs) offer an alternative solution with fewer parameters. However, gradient-based inference methods, such as Hamiltonian Monte Carlo (HMC), may result in computational inefficiency when applied to KANs, especially for large-scale datasets, due to the high cost of back-propagation. To address these challenges, we propose a novel approach, combining the dropout Tikhonov ensemble Kalman inversion (DTEKI) with Chebyshev KANs. This gradient-free method effectively mitigates overfitting and enhances numerical stability. Additionally, we incorporate the active subspace method to reduce the parameter-space dimensionality, allowing us to improve the accuracy of predictions and obtain more reliable uncertainty estimates. Extensive experiments demonstrate the efficacy of our approach in various test cases, including scenarios with large datasets and high noise levels. Our results show that the new method achieves comparable or better accuracy, much higher efficiency as well as stability compared to HMC, in addition to scalability. Moreover, by leveraging the low-dimensional parameter subspace, our method preserves prediction accuracy while substantially reducing further the computational cost.
<div id='section'>Paperid: <span id='pid'>1463, <a href='https://arxiv.org/pdf/2501.03911.pdf' target='_blank'>https://arxiv.org/pdf/2501.03911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabio V. Difonzo, Luciano Lopez, Sabrina F. Pellegrino
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.03911">Physics Informed Neural Networks for Learning the Horizon Size in Bond-Based Peridynamic Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper broaches the peridynamic inverse problem of determining the horizon size of the kernel function in a one-dimensional model of a linear microelastic material. We explore different kernel functions, including V-shaped, distributed, and tent kernels. The paper presents numerical experiments using PINNs to learn the horizon parameter for problems in one and two spatial dimensions. The results demonstrate the effectiveness of PINNs in solving the peridynamic inverse problem, even in the presence of challenging kernel functions. We observe and prove a one-sided convergence behavior of the Stochastic Gradient Descent method towards a global minimum of the loss function, suggesting that the true value of the horizon parameter is an unstable equilibrium point for the PINN's gradient flow dynamics.
<div id='section'>Paperid: <span id='pid'>1464, <a href='https://arxiv.org/pdf/2501.02762.pdf' target='_blank'>https://arxiv.org/pdf/2501.02762.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Farinaz Mostajeran, Salah A Faroughi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.02762">Scaled-cPIKANs: Domain Scaling in Chebyshev-based Physics-informed Kolmogorov-Arnold Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial Differential Equations (PDEs) are integral to modeling many scientific and engineering problems. Physics-informed Neural Networks (PINNs) have emerged as promising tools for solving PDEs by embedding governing equations into the neural network loss function. However, when dealing with PDEs characterized by strong oscillatory dynamics over large computational domains, PINNs based on Multilayer Perceptrons (MLPs) often exhibit poor convergence and reduced accuracy. To address these challenges, this paper introduces Scaled-cPIKAN, a physics-informed architecture rooted in Kolmogorov-Arnold Networks (KANs). Scaled-cPIKAN integrates Chebyshev polynomial representations with a domain scaling approach that transforms spatial variables in PDEs into the standardized domain \([-1,1]^d\), as intrinsically required by Chebyshev polynomials. By combining the flexibility of Chebyshev-based KANs (cKANs) with the physics-driven principles of PINNs, and the spatial domain transformation, Scaled-cPIKAN enables efficient representation of oscillatory dynamics across extended spatial domains while improving computational performance. We demonstrate Scaled-cPIKAN efficacy using four benchmark problems: the diffusion equation, the Helmholtz equation, the Allen-Cahn equation, as well as both forward and inverse formulations of the reaction-diffusion equation (with and without noisy data). Our results show that Scaled-cPIKAN significantly outperforms existing methods in all test cases. In particular, it achieves several orders of magnitude higher accuracy and faster convergence rate, making it a highly efficient tool for approximating PDE solutions that feature oscillatory behavior over large spatial domains.
<div id='section'>Paperid: <span id='pid'>1465, <a href='https://arxiv.org/pdf/2501.00780.pdf' target='_blank'>https://arxiv.org/pdf/2501.00780.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyuan Li, Wei Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.00780">Solving McKean-Vlasov Equation by deep learning particle method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel meshless simulation method for the McKean-Vlasov Stochastic Differential Equation (MV-SDE) utilizing deep learning, applicable to both self-interaction and interaction scenarios. Traditionally, numerical methods for this equation rely on the interacting particle method combined with techniques based on the ItÃ´-Taylor expansion. The convergence rate of this approach is determined by two parameters: the number of particles $N$ and the time step size $h$ for each Euler iteration. However, for extended time horizons or equations with larger Lipschitz coefficients, this method is often limited, as it requires a significant increase in Euler iterations to achieve the desired precision $Îµ$. To overcome the challenges posed by the difficulty of parallelizing the simulation of continuous interacting particle systems, which involve solving high-dimensional coupled SDEs, we propose a meshless MV-SDE solver grounded in Physics-Informed Neural Networks (PINNs) that does not rely on the propagation of chaos result. Our method constructs a pseudo MV-SDE using ItÃ´ calculus, then quantifies the discrepancy between this equation and the original MV-SDE, with the error minimized through a loss function. This loss is controlled via an optimization algorithm, independent of the time step size, and we provide an error estimate for the loss function. The advantages of our approach are demonstrated through corresponding simulations.
<div id='section'>Paperid: <span id='pid'>1466, <a href='https://arxiv.org/pdf/2412.14699.pdf' target='_blank'>https://arxiv.org/pdf/2412.14699.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>K. Murari, S. Sundar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.14699">Physics informed neural network for forward and inverse radiation heat transfer in graded-index medium</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Radiation heat transfer in a graded-index medium often suffers accuracy problems due to the gradual changes in the refractive index. The finite element method, meshfree, and other numerical methods often struggle to maintain accuracy when applied to this medium. To address this issue, we apply physics-informed neural networks (PINNs)-based machine learning algorithms to simulate forward and inverse problems for this medium. We also provide the theoretical upper bounds. This theoretical framework is validated through numerical experiments of predefined and newly developed models that demonstrate the accuracy and robustness of the algorithms in solving radiation transport problems in the medium. The simulations show that the novel algorithm goes on with numerical stability and effectively mitigates oscillatory errors, even in cases with more pronounced variations in the refractive index.
<div id='section'>Paperid: <span id='pid'>1467, <a href='https://arxiv.org/pdf/2412.13993.pdf' target='_blank'>https://arxiv.org/pdf/2412.13993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>John M. Hanna, Hugues Talbot, Irene E. Vignon-Clementel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.13993">Improved Physics-informed neural networks loss function regularization with a variance-based term</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In machine learning and statistical modeling, the mean square or absolute error is commonly used as an error metric, also called a "loss function." While effective in reducing the average error, this approach may fail to address localized outliers, leading to significant inaccuracies in regions with sharp gradients or discontinuities. This issue is particularly evident in physics-informed neural networks (PINNs), where such localized errors are expected and affect the overall solution. To overcome this limitation, we propose a novel loss function that combines the mean and the standard deviation of the chosen error metric. By minimizing this combined loss function, the method ensures a more uniform error distribution and reduces the impact of localized high-error regions. The proposed loss function is easy to implement and tested on problems of varying complexity: the 1D Poisson equation, the unsteady Burgers' equation, 2D linear elastic solid mechanics, and 2D steady Navier-Stokes equations. Results demonstrate improved solution quality and lower maximum error compared to the standard mean-based loss, with minimal impact on computational time.
<div id='section'>Paperid: <span id='pid'>1468, <a href='https://arxiv.org/pdf/2412.12709.pdf' target='_blank'>https://arxiv.org/pdf/2412.12709.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Irham T. Andika, Stefan Schuldt, Sherry H. Suyu, Satadru Bag, Raoul CaÃ±ameras, Alejandra Melo, Claudio Grillo, James H. H. Chan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12709">Accelerating lensed quasar discovery and modeling with physics-informed variational autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Strongly lensed quasars provide valuable insights into the rate of cosmic expansion, the distribution of dark matter in foreground deflectors, and the characteristics of quasar hosts. However, detecting them in astronomical images is difficult due to the prevalence of non-lensing objects. To address this challenge, we developed a generative deep learning model called VariLens, built upon a physics-informed variational autoencoder. This model seamlessly integrates three essential modules: image reconstruction, object classification, and lens modeling, offering a fast and comprehensive approach to strong lens analysis. VariLens is capable of rapidly determining both (1) the probability that an object is a lens system and (2) key parameters of a singular isothermal ellipsoid (SIE) mass model -- including the Einstein radius ($Î¸_\mathrm{E}$), lens center, and ellipticity -- in just milliseconds using a single CPU. A direct comparison of VariLens estimates with traditional lens modeling for 20 known lensed quasars within the Subaru Hyper Suprime-Cam (HSC) footprint shows good agreement, with both results consistent within $2Ï$ for systems with $Î¸_\mathrm{E}<3$ arcsecs. To identify new lensed quasar candidates, we begin with an initial sample of approximately 80 million sources, combining HSC data with multiwavelength information from various surveys. After applying a photometric preselection aimed at locating $z>1.5$ sources, the number of candidates was reduced to 710,966. Subsequently, VariLens highlights 13,831 sources, each showing a high likelihood of being a lens. A visual assessment of these objects results in 42 promising candidates that await spectroscopic confirmation. These results underscore the potential of automated deep learning pipelines to efficiently detect and model strong lenses in large datasets.
<div id='section'>Paperid: <span id='pid'>1469, <a href='https://arxiv.org/pdf/2412.09453.pdf' target='_blank'>https://arxiv.org/pdf/2412.09453.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haolin Li, Yuyang Miao, Zahra Sharif Khodaei, M. H. Aliabadi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09453">Finite-PINN: A Physics-Informed Neural Network with Finite Geometric Encoding for Solid Mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>PINN models have demonstrated capabilities in addressing fluid PDE problems, and their potential in solid mechanics is beginning to emerge. This study identifies two key challenges when using PINN to solve general solid mechanics problems. These challenges become evident when comparing the limitations of PINN with the well-established numerical methods commonly used in solid mechanics, such as the finite element method (FEM). Specifically: a) PINN models generate solutions over an infinite domain, which conflicts with the finite boundaries typical of most solid structures; and b) the solution space utilised by PINN is Euclidean, which is inadequate for addressing the complex geometries often present in solid structures.
  This work presents a PINN architecture for general solid mechanics problems, referred to as the Finite-PINN model. The model is designed to effectively tackle two key challenges, while retaining as much of the original PINN framework as possible. To this end, the Finite-PINN incorporates finite geometric encoding into the neural network inputs, thereby transforming the solution space from a conventional Euclidean space into a hybrid Euclidean-topological space. The model is comprehensively trained using both strong-form and weak-form loss formulations, enabling its application to a wide range of forward and inverse problems in solid mechanics. For forward problems, the Finite-PINN model efficiently approximates solutions to solid mechanics problems when the geometric information of a given structure has been preprocessed. For inverse problems, it effectively reconstructs full-field solutions from very sparse observations by embedding both physical laws and geometric information within its architecture.
<div id='section'>Paperid: <span id='pid'>1470, <a href='https://arxiv.org/pdf/2412.05133.pdf' target='_blank'>https://arxiv.org/pdf/2412.05133.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vijay Kag, Dibakar Roy Sarkar, Birupaksha Pal, Somdatta Goswami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05133">Learning Hidden Physics and System Parameters with Deep Operator Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Big data is transforming scientific progress by enabling the discovery of novel models, enhancing existing frameworks, and facilitating precise uncertainty quantification, while advancements in scientific machine learning complement this by providing powerful tools to solve inverse problems to identify the complex systems where traditional methods falter due to sparse or noisy data. We introduce two innovative neural operator frameworks tailored for discovering hidden physics and identifying unknown system parameters from sparse measurements. The first framework integrates a popular neural operator, DeepONet, and a physics-informed neural network to capture the relationship between sparse data and the underlying physics, enabling the accurate discovery of a family of governing equations. The second framework focuses on system parameter identification, leveraging a DeepONet pre-trained on sparse sensor measurements to initialize a physics-constrained inverse model. Both frameworks excel in handling limited data and preserving physical consistency. Benchmarking on the Burgers' equation and reaction-diffusion system demonstrates state-of-the-art performance, achieving average $L_2$ errors of $\mathcal{O}(10^{-2})$ for hidden physics discovery and absolute errors of $\mathcal{O}(10^{-3})$ for parameter identification. These results underscore the frameworks' robustness, efficiency, and potential for solving complex scientific problems with minimal observational data.
<div id='section'>Paperid: <span id='pid'>1471, <a href='https://arxiv.org/pdf/2412.04502.pdf' target='_blank'>https://arxiv.org/pdf/2412.04502.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>JÃ¶rn Tebbe, Andreas Besginow, Markus Lange-Hegermann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04502">Physics-informed Gaussian Processes as Linear Model Predictive Controller</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel algorithm for controlling linear time invariant systems in a tracking problem. The controller is based on a Gaussian Process (GP) whose realizations satisfy a system of linear ordinary differential equations with constant coefficients. Control inputs for tracking are determined by conditioning the prior GP on the setpoints, i.e. control as inference. The resulting Model Predictive Control scheme incorporates pointwise soft constraints by introducing virtual setpoints to the posterior Gaussian process. We show theoretically that our controller satisfies open-loop stability for the optimal control problem by leveraging general results from Bayesian inference and demonstrate this result in a numerical example.
<div id='section'>Paperid: <span id='pid'>1472, <a href='https://arxiv.org/pdf/2412.04213.pdf' target='_blank'>https://arxiv.org/pdf/2412.04213.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuhao Ma, Jie Zhang, Chaoyang Shi, Pei Di, Ian D. Robertson, Zhi-Qiang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.04213">Physics-informed Deep Learning for Muscle Force Prediction with Unlabeled sEMG Signals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Computational biomechanical analysis plays a pivotal role in understanding and improving human movements and physical functions. Although physics-based modeling methods can interpret the dynamic interaction between the neural drive to muscle dynamics and joint kinematics, they suffer from high computational latency. In recent years, data-driven methods have emerged as a promising alternative due to their fast execution speed, but label information is still required during training, which is not easy to acquire in practice. To tackle these issues, this paper presents a novel physics-informed deep learning method to predict muscle forces without any label information during model training. In addition, the proposed method could also identify personalized muscle-tendon parameters. To achieve this, the Hill muscle model-based forward dynamics is embedded into the deep neural network as the additional loss to further regulate the behavior of the deep neural network. Experimental validations on the wrist joint from six healthy subjects are performed, and a fully connected neural network (FNN) is selected to implement the proposed method. The predicted results of muscle forces show comparable or even lower root mean square error (RMSE) and higher coefficient of determination compared with baseline methods, which have to use the labeled surface electromyography (sEMG) signals, and it can also identify muscle-tendon parameters accurately, demonstrating the effectiveness of the proposed physics-informed deep learning method.
<div id='section'>Paperid: <span id='pid'>1473, <a href='https://arxiv.org/pdf/2412.03161.pdf' target='_blank'>https://arxiv.org/pdf/2412.03161.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sung Woong Cho, Hwijae Son
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03161">Physics-Informed Deep Inverse Operator Networks for Solving PDE Inverse Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse problems involving partial differential equations (PDEs) can be seen as discovering a mapping from measurement data to unknown quantities, often framed within an operator learning approach. However, existing methods typically rely on large amounts of labeled training data, which is impractical for most real-world applications. Moreover, these supervised models may fail to capture the underlying physical principles accurately. To address these limitations, we propose a novel architecture called Physics-Informed Deep Inverse Operator Networks (PI-DIONs), which can learn the solution operator of PDE-based inverse problems without labeled training data. We extend the stability estimates established in the inverse problem literature to the operator learning framework, thereby providing a robust theoretical foundation for our method. These estimates guarantee that the proposed model, trained on a finite sample and grid, generalizes effectively across the entire domain and function space. Extensive experiments are conducted to demonstrate that PI-DIONs can effectively and accurately learn the solution operators of the inverse problems without the need for labeled data.
<div id='section'>Paperid: <span id='pid'>1474, <a href='https://arxiv.org/pdf/2412.00113.pdf' target='_blank'>https://arxiv.org/pdf/2412.00113.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kart-Leong Lim, Rahul Dutta, Mihai Rotaru
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00113">Boundary-Decoder network for inverse prediction of capacitor electrostatic analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional electrostatic simulation are meshed-based methods which convert partial differential equations into an algebraic system of equations and their solutions are approximated through numerical methods. These methods are time consuming and any changes in their initial or boundary conditions will require solving the numerical problem again. Newer computational methods such as the physics informed neural net (PINN) similarly require re-training when boundary conditions changes. In this work, we propose an end-to-end deep learning approach to model parameter changes to the boundary conditions. The proposed method is demonstrated on the test problem of a long air-filled capacitor structure. The proposed approach is compared to plain vanilla deep learning (NN) and PINN. It is shown that our method can significantly outperform both NN and PINN under dynamic boundary condition as well as retaining its full capability as a forward model.
<div id='section'>Paperid: <span id='pid'>1475, <a href='https://arxiv.org/pdf/2412.00087.pdf' target='_blank'>https://arxiv.org/pdf/2412.00087.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cong Wang, Weizhe Yang, Haiping Wang, Renjie Yang, Jing Li, Zhijun Wang, Yixiong Wei, Xianli Huang, Chenshu Hu, Zhaoyang Liu, Xinyao Yu, Changqing Zou, Zhifeng Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00087">Physics-Informed Deep Learning Model for Line-integral Diagnostics Across Fusion Devices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rapid reconstruction of 2D plasma profiles from line-integral measurements is important in nuclear fusion. This paper introduces a physics-informed model architecture called Onion, that can enhance the performance of models and be adapted to various backbone networks. The model under Onion incorporates physical information by a multiplication process and applies the physics-informed loss function according to the principle of line integration. Prediction results demonstrate that the additional input of physical information improves the deep learning model's ability, leading to a reduction in the average relative error E_1 between the reconstruction profiles and the target profiles by approximately 0.84x10^(-2) on synthetic datasets and about 0.06x10^(-2) on experimental datasets. Furthermore, the implementation of the Softplus activation function in the final two fully connected layers improves model performance. This enhancement results in a reduction in the E_1 by approximately 1.06x10^(-2) on synthetic datasets and about 0.11x10^(-2) on experimental datasets. The incorporation of the physics-informed loss function has been shown to correct the model's predictions, bringing the back-projections closer to the actual inputs and reducing the errors associated with inversion algorithms. Besides, we have developed a synthetic data model to generate customized line-integral diagnostic datasets and have also collected soft x-ray diagnostic datasets from EAST and HL-2A. This study achieves reductions in reconstruction errors, and accelerates the development of surrogate models in fusion research.
<div id='section'>Paperid: <span id='pid'>1476, <a href='https://arxiv.org/pdf/2411.16698.pdf' target='_blank'>https://arxiv.org/pdf/2411.16698.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aycan Deniz Vit, Ujal Rzayev, Bahrem Serhat Danis, Ali Najjar Amiri, Kazim Gorgulu, Emir Salih Magden
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16698">Universal on-chip polarization handling with deep photonic networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel design paradigm for arbitrarily capable deep photonic networks of cascaded Mach-Zehnder Interferometers (MZIs) for on-chip universal polarization handling. Using a device architecture made of cascaded Mach-Zehnder interferometers, we modify and train the phase difference between interferometer arms for both polarizations through wide operation bandwidths. Three proof-of-concept polarization handling devices are illustrated using a software-defined, physics-informed neural framework, to achieve user-specified target device responses as functions of polarization and wavelength. These devices include a polarization splitter, a polarization-independent power splitter, and an arbitrary polarization-dependent splitter to illustrate the capabilities of the design framework. The performance for all three devices is optimized using transfer matrix calculations; and their final responses are verified through 3D-FDTD simulations. All devices demonstrate state-of-the-art performance metrics with over 20 dB extinction, and flat-top transmission bands through bandwidths of 120 nm. In addition to the functional diversity enabled, the optimization for each device is completed in under a minute, highlighting the computational efficiency of the design paradigm presented. These results demonstrate the versatility of the deep photonic network design ecosystem in polarization management, unveiling promising prospects for advanced on-chip applications in optical communications, sensing, and computing.
<div id='section'>Paperid: <span id='pid'>1477, <a href='https://arxiv.org/pdf/2411.11801.pdf' target='_blank'>https://arxiv.org/pdf/2411.11801.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashish Pal, Satish Nagarajaiah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11801">KAN/MultKAN with Physics-Informed Spline fitting (KAN-PISF) for ordinary/partial differential equation discovery of nonlinear dynamic systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning for scientific discovery is increasingly becoming popular because of its ability to extract and recognize the nonlinear characteristics from the data. The black-box nature of deep learning methods poses difficulties in interpreting the identified model. There is a dire need to interpret the machine learning models to develop a physical understanding of dynamic systems. An interpretable form of neural network called Kolmogorov-Arnold networks (KAN) or Multiplicative KAN (MultKAN) offers critical features that help recognize the nonlinearities in the governing ordinary/partial differential equations (ODE/PDE) of various dynamic systems and find their equation structures. In this study, an equation discovery framework is proposed that includes i) sequentially regularized derivatives for denoising (SRDD) algorithm to denoise the measure data to obtain accurate derivatives, ii) KAN to identify the equation structure and suggest relevant nonlinear functions that are used to create a small overcomplete library of functions, and iii) physics-informed spline fitting (PISF) algorithm to filter the excess functions from the library and converge to the correct equation. The framework was tested on the forced Duffing oscillator, Van der Pol oscillator (stiff ODE), Burger's equation, and Bouc-Wen model (coupled ODE). The proposed method converged to the true equation for the first three systems. It provided an approximate model for the Bouc-Wen model that could acceptably capture the hysteresis response. Using KAN maintains low complexity, which helps the user interpret the results throughout the process and avoid the black-box-type nature of machine learning methods.
<div id='section'>Paperid: <span id='pid'>1478, <a href='https://arxiv.org/pdf/2411.11467.pdf' target='_blank'>https://arxiv.org/pdf/2411.11467.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amaury Wei, Olga Fink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11467">Integrating Physics and Topology in Neural Networks for Learning Rigid Body Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rigid body interactions are fundamental to numerous scientific disciplines, but remain challenging to simulate due to their abrupt nonlinear nature and sensitivity to complex, often unknown environmental factors. These challenges call for adaptable learning-based methods capable of capturing complex interactions beyond explicit physical models and simulations. While graph neural networks can handle simple scenarios, they struggle with complex scenes and long-term predictions. We introduce a novel framework for modeling rigid body dynamics and learning collision interactions, addressing key limitations of existing graph-based methods. Our approach extends the traditional representation of meshes by incorporating higher-order topology complexes, offering a physically consistent representation. Additionally, we propose a physics-informed message-passing neural architecture, embedding physical laws directly in the model. Our method demonstrates superior accuracy, even during long rollouts, and exhibits strong generalization to unseen scenarios. Importantly, this work addresses the challenge of multi-entity dynamic interactions, with applications spanning diverse scientific and engineering domains.
<div id='section'>Paperid: <span id='pid'>1479, <a href='https://arxiv.org/pdf/2411.08326.pdf' target='_blank'>https://arxiv.org/pdf/2411.08326.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arthur Bizzi, Lucas Nissenbaum, JoÃ£o M. Pereira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08326">Neural Conjugate Flows: Physics-informed architectures with flow structure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Neural Conjugate Flows (NCF), a class of neural network architectures equipped with exact flow structure. By leveraging topological conjugation, we prove that these networks are not only naturally isomorphic to a continuous group, but are also universal approximators for flows of ordinary differential equation (ODEs). Furthermore, topological properties of these flows can be enforced by the architecture in an interpretable manner. We demonstrate in numerical experiments how this topological group structure leads to concrete computational gains over other physics informed neural networks in estimating and extrapolating latent dynamics of ODEs, while training up to five times faster than other flow-based architectures.
<div id='section'>Paperid: <span id='pid'>1480, <a href='https://arxiv.org/pdf/2411.04714.pdf' target='_blank'>https://arxiv.org/pdf/2411.04714.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Teppei Kurita, Yuhi Kondo, Legong Sun, Takayuki Sasaki, Sho Nitta, Yasuhiro Hashimoto, Yoshinori Muramatsu, Yusuke Moriuchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.04714">Revisiting Disparity from Dual-Pixel Images: Physics-Informed Lightweight Depth Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we propose a high-performance disparity (depth) estimation method using dual-pixel (DP) images with few parameters. Conventional end-to-end deep-learning methods have many parameters but do not fully exploit disparity constraints, which limits their performance. Therefore, we propose a lightweight disparity estimation method based on a completion-based network that explicitly constrains disparity and learns the physical and systemic disparity properties of DP. By modeling the DP-specific disparity error parametrically and using it for sampling during training, the network acquires the unique properties of DP and enhances robustness. This learning also allows us to use a common RGB-D dataset for training without a DP dataset, which is labor-intensive to acquire. Furthermore, we propose a non-learning-based refinement framework that efficiently handles inherent disparity expansion errors by appropriately refining the confidence map of the network output. As a result, the proposed method achieved state-of-the-art results while reducing the overall system size to 1/5 of that of the conventional method, even without using the DP dataset for training, thereby demonstrating its effectiveness. The code and dataset are available on our project site.
<div id='section'>Paperid: <span id='pid'>1481, <a href='https://arxiv.org/pdf/2410.21025.pdf' target='_blank'>https://arxiv.org/pdf/2410.21025.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weidong Wu, Yong Zhang, Lili Hao, Yang Chen, Xiaoyan Sun, Dunwei Gong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.21025">Physics-informed Partitioned Coupled Neural Operator for Complex Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Operators provide efficient, high-fidelity simulations for systems governed by partial differential equations (PDEs). However, most existing studies focus only on multi-scale, multi-physics systems within a single spatial region, neglecting the case with multiple interconnected sub-regions, such as gas and thermal systems. To address this, this paper proposes a Physics-Informed Partitioned Coupled Neural Operator (PCNO) to enhance the simulation performance of such networks. Compared to the existing Fourier Neural Operator (FNO), this method designs a joint convolution operator within the Fourier layer, enabling global integration capturing all sub-regions. Additionally, grid alignment layers are introduced outside the Fourier layer to help the joint convolution operator accurately learn the coupling relationship between sub-regions in the frequency domain. Experiments on gas networks demonstrate that the proposed operator not only accurately simulates complex systems but also shows good generalization and low model complexity.
<div id='section'>Paperid: <span id='pid'>1482, <a href='https://arxiv.org/pdf/2410.20212.pdf' target='_blank'>https://arxiv.org/pdf/2410.20212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Wang, Tang Paai Wong, Haihui Ruan, Somdatta Goswami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20212">Causality-Respecting Adaptive Refinement for PINNs: Enabling Precise Interface Evolution in Phase Field Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a powerful tool for solving physical systems described by partial differential equations (PDEs). However, their accuracy in dynamical systems, particularly those involving sharp moving boundaries with complex initial morphologies, remains a challenge. This study introduces an approach combining residual-based adaptive refinement (RBAR) with causality-informed training to enhance the performance of PINNs in solving spatio-temporal PDEs. Our method employs a three-step iterative process: initial causality-based training, RBAR-guided domain refinement, and subsequent causality training on the refined mesh. Applied to the Allen-Cahn equation, a widely-used model in phase field simulations, our approach demonstrates significant improvements in solution accuracy and computational efficiency over traditional PINNs. Notably, we observe an 'overshoot and relocate' phenomenon in dynamic cases with complex morphologies, showcasing the method's adaptive error correction capabilities. This synergistic interaction between RBAR and causality training enables accurate capture of interface evolution, even in challenging scenarios where traditional PINNs fail. Our framework not only resolves the limitations of uniform refinement strategies but also provides a generalizable methodology for solving a broad range of spatio-temporal PDEs. The simplicity and effectiveness of our RBAR-causality combined PINN offer promising potential for applications across various physical systems characterized by complex, evolving interfaces.
<div id='section'>Paperid: <span id='pid'>1483, <a href='https://arxiv.org/pdf/2410.14216.pdf' target='_blank'>https://arxiv.org/pdf/2410.14216.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bahae-Eddine Madir, Francky Luddens, Corentin LothodÃ©, Ionut Danaila
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14216">Physics Informed Neural Networks for heat conduction with phase change</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study numerical algorithms to solve a specific Partial Differential Equation (PDE), namely the Stefan problem, using Physics Informed Neural Networks (PINNs). This problem describes the heat propagation in a liquid-solid phase change system. It implies a heat equation and a discontinuity at the interface where the phase change occurs. In the context of PINNs, this model leads to difficulties in the learning process, especially near the interface of phase change. We present different strategies that can be used in this context. We illustrate our results and compare with classical solvers for PDEs (finite differences).
<div id='section'>Paperid: <span id='pid'>1484, <a href='https://arxiv.org/pdf/2410.13141.pdf' target='_blank'>https://arxiv.org/pdf/2410.13141.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Handi Zhang, Langchen Liu, Lu Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13141">Federated scientific machine learning for approximating functions and solving differential equations with data heterogeneity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>By leveraging neural networks, the emerging field of scientific machine learning (SciML) offers novel approaches to address complex problems governed by partial differential equations (PDEs). In practical applications, challenges arise due to the distributed essence of data, concerns about data privacy, or the impracticality of transferring large volumes of data. Federated learning (FL), a decentralized framework that enables the collaborative training of a global model while preserving data privacy, offers a solution to the challenges posed by isolated data pools and sensitive data issues. Here, this paper explores the integration of FL and SciML to approximate complex functions and solve differential equations. We propose two novel models: federated physics-informed neural networks (FedPINN) and federated deep operator networks (FedDeepONet). We further introduce various data generation methods to control the degree of non-independent and identically distributed (non-iid) data and utilize the 1-Wasserstein distance to quantify data heterogeneity in function approximation and PDE learning. We systematically investigate the relationship between data heterogeneity and federated model performance. Additionally, we propose a measure of weight divergence and develop a theoretical framework to establish growth bounds for weight divergence in federated learning compared to traditional centralized learning. To demonstrate the effectiveness of our methods, we conducted 10 experiments, including 2 on function approximation, 5 PDE problems on FedPINN, and 3 PDE problems on FedDeepONet. These experiments demonstrate that proposed federated methods surpass the models trained only using local data and achieve competitive accuracy of centralized models trained using all data.
<div id='section'>Paperid: <span id='pid'>1485, <a href='https://arxiv.org/pdf/2410.10897.pdf' target='_blank'>https://arxiv.org/pdf/2410.10897.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Farinaz Mostajeran, Salah A Faroughi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10897">EPi-cKANs: Elasto-Plasticity Informed Kolmogorov-Arnold Networks Using Chebyshev Polynomials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multilayer perceptron (MLP) networks are predominantly used to develop data-driven constitutive models for granular materials. They offer a compelling alternative to traditional physics-based constitutive models in predicting nonlinear responses of these materials, e.g., elasto-plasticity, under various loading conditions. To attain the necessary accuracy, MLPs often need to be sufficiently deep or wide, owing to the curse of dimensionality inherent in these problems. To overcome this limitation, we present an elasto-plasticity informed Chebyshev-based Kolmogorov-Arnold network (EPi-cKAN) in this study. This architecture leverages the benefits of KANs and augmented Chebyshev polynomials, as well as integrates physical principles within both the network structure and the loss function. The primary objective of EPi-cKAN is to provide an accurate and generalizable function approximation for non-linear stress-strain relationships, using fewer parameters compared to standard MLPs. To evaluate the efficiency, accuracy, and generalization capabilities of EPi-cKAN in modeling complex elasto-plastic behavior, we initially compare its performance with other cKAN-based models, which include purely data-driven parallel and serial architectures. Furthermore, to differentiate EPi-cKAN's distinct performance, we also compare it against purely data-driven and physics-informed MLP-based methods. Lastly, we test EPi-cKAN's ability to predict blind strain-controlled paths that extend beyond the training data distribution to gauge its generalization and predictive capabilities. Our findings indicate that, even with limited data and fewer parameters compared to other approaches, EPi-cKAN provides superior accuracy in predicting stress components and demonstrates better generalization when used to predict sand elasto-plastic behavior under blind triaxial axisymmetric strain-controlled loading paths.
<div id='section'>Paperid: <span id='pid'>1486, <a href='https://arxiv.org/pdf/2410.10023.pdf' target='_blank'>https://arxiv.org/pdf/2410.10023.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashish Pal, Sutanu Bhowmick, Satish Nagarajaiah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10023">Physics-informed AI and ML-based sparse system identification algorithm for discovery of PDE's representing nonlinear dynamic systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sparse system identification of nonlinear dynamic systems is still challenging, especially for stiff and high-order differential equations for noisy measurement data. The use of highly correlated functions makes distinguishing between true and false functions difficult, which limits the choice of functions. In this study, an equation discovery method has been proposed to tackle these problems. The key elements include a) use of B-splines for data fitting to get analytical derivatives superior to numerical derivatives, b) sequentially regularized derivatives for denoising (SRDD) algorithm, highly effective in removing noise from signal without system information loss, c) uncorrelated component analysis (UCA) algorithm that identifies and eliminates highly correlated functions while retaining the true functions, and d) physics-informed spline fitting (PISF) where the spline fitting is updated gradually while satisfying the governing equation with a dictionary of candidate functions to converge to the correct equation sequentially. The complete framework is built on a unified deep-learning architecture that eases the optimization process. The proposed method is demonstrated to discover various differential equations at various noise levels, including three-dimensional, fourth-order, and stiff equations. The parameter estimation converges accurately to the true values with a small coefficient of variation, suggesting robustness to the noise.
<div id='section'>Paperid: <span id='pid'>1487, <a href='https://arxiv.org/pdf/2410.02819.pdf' target='_blank'>https://arxiv.org/pdf/2410.02819.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marien Chenaud, FrÃ©dÃ©ric MagoulÃ¨s, JosÃ© Alves
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.02819">Physics-Informed Graph-Mesh Networks for PDEs: A hybrid approach for complex problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent rise of deep learning has led to numerous applications, including solving partial differential equations using Physics-Informed Neural Networks. This approach has proven highly effective in several academic cases. However, their lack of physical invariances, coupled with other significant weaknesses, such as an inability to handle complex geometries or their lack of generalization capabilities, make them unable to compete with classical numerical solvers in industrial settings. In this work, a limitation regarding the use of automatic differentiation in the context of physics-informed learning is highlighted. A hybrid approach combining physics-informed graph neural networks with numerical kernels from finite elements is introduced. After studying the theoretical properties of our model, we apply it to complex geometries, in two and three dimensions. Our choices are supported by an ablation study, and we evaluate the generalisation capacity of the proposed approach.
<div id='section'>Paperid: <span id='pid'>1488, <a href='https://arxiv.org/pdf/2410.00288.pdf' target='_blank'>https://arxiv.org/pdf/2410.00288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeda Xu, John Liechty, Sebastian Benthall, Nicholas Skar-Gislinge, Christopher McComb
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00288">GARCH-Informed Neural Networks for Volatility Prediction in Financial Markets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Volatility, which indicates the dispersion of returns, is a crucial measure of risk and is hence used extensively for pricing and discriminating between different financial investments. As a result, accurate volatility prediction receives extensive attention. The Generalized Autoregressive Conditional Heteroscedasticity (GARCH) model and its succeeding variants are well established models for stock volatility forecasting. More recently, deep learning models have gained popularity in volatility prediction as they demonstrated promising accuracy in certain time series prediction tasks. Inspired by Physics-Informed Neural Networks (PINN), we constructed a new, hybrid Deep Learning model that combines the strengths of GARCH with the flexibility of a Long Short-Term Memory (LSTM) Deep Neural Network (DNN), thus capturing and forecasting market volatility more accurately than either class of models are capable of on their own. We refer to this novel model as a GARCH-Informed Neural Network (GINN). When compared to other time series models, GINN showed superior out-of-sample prediction performance in terms of the Coefficient of Determination ($R^2$), Mean Squared Error (MSE), and Mean Absolute Error (MAE).
<div id='section'>Paperid: <span id='pid'>1489, <a href='https://arxiv.org/pdf/2409.18223.pdf' target='_blank'>https://arxiv.org/pdf/2409.18223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiayin Zhao, Zhifeng Zhao, Jiamin Wu, Tao Yu, Hui Qiao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.18223">PNR: Physics-informed Neural Representation for high-resolution LFM reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Light field microscopy (LFM) has been widely utilized in various fields for its capability to efficiently capture high-resolution 3D scenes. Despite the rapid advancements in neural representations, there are few methods specifically tailored for microscopic scenes. Existing approaches often do not adequately address issues such as the loss of high-frequency information due to defocus and sample aberration, resulting in suboptimal performance. In addition, existing methods, including RLD, INR, and supervised U-Net, face challenges such as sensitivity to initial estimates, reliance on extensive labeled data, and low computational efficiency, all of which significantly diminish the practicality in complex biological scenarios. This paper introduces PNR (Physics-informed Neural Representation), a method for high-resolution LFM reconstruction that significantly enhances performance. Our method incorporates an unsupervised and explicit feature representation approach, resulting in a 6.1 dB improvement in PSNR than RLD. Additionally, our method employs a frequency-based training loss, enabling better recovery of high-frequency details, which leads to a reduction in LPIPS by at least half compared to SOTA methods (1.762 V.S. 3.646 of DINER). Moreover, PNR integrates a physics-informed aberration correction strategy that optimizes Zernike polynomial parameters during optimization, thereby reducing the information loss caused by aberrations and improving spatial resolution. These advancements make PNR a promising solution for long-term high-resolution biological imaging applications. Our code and dataset will be made publicly available.
<div id='section'>Paperid: <span id='pid'>1490, <a href='https://arxiv.org/pdf/2409.16826.pdf' target='_blank'>https://arxiv.org/pdf/2409.16826.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ãlvaro FernÃ¡ndez Corral, NicolÃ¡s Mendoza, Armin Iske, Andrey Yachmenev, Jochen KÃ¼pper
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.16826">Learning phase-space flows using time-discrete implicit Runge-Kutta PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a computational framework for obtaining multidimensional phase-space solutions of systems of non-linear coupled differential equations, using high-order implicit Runge-Kutta Physics- Informed Neural Networks (IRK-PINNs) schemes. Building upon foundational work originally solving differential equations for fields depending on coordinates [J. Comput. Phys. 378, 686 (2019)], we adapt the scheme to a context where the coordinates are treated as functions. This modification enables us to efficiently solve equations of motion for a particle in an external field. Our scheme is particularly useful for explicitly time-independent and periodic fields. We apply this approach to successfully solve the equations of motion for a mass particle placed in a central force field and a charged particle in a periodic electric field.
<div id='section'>Paperid: <span id='pid'>1491, <a href='https://arxiv.org/pdf/2409.13876.pdf' target='_blank'>https://arxiv.org/pdf/2409.13876.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Oliver Hamelijnck, Arno Solin, Theodoros Damoulas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13876">Physics-Informed Variational State-Space Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Differential equations are important mechanistic models that are integral to many scientific and engineering applications. With the abundance of available data there has been a growing interest in data-driven physics-informed models. Gaussian processes (GPs) are particularly suited to this task as they can model complex, non-linear phenomena whilst incorporating prior knowledge and quantifying uncertainty. Current approaches have found some success but are limited as they either achieve poor computational scalings or focus only on the temporal setting. This work addresses these issues by introducing a variational spatio-temporal state-space GP that handles linear and non-linear physical constraints while achieving efficient linear-in-time computation costs. We demonstrate our methods in a range of synthetic and real-world settings and outperform the current state-of-the-art in both predictive and computational performance.
<div id='section'>Paperid: <span id='pid'>1492, <a href='https://arxiv.org/pdf/2409.11743.pdf' target='_blank'>https://arxiv.org/pdf/2409.11743.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amir-Mohammad Esmaieeli-Sikaroudi, Boris Goikhman, Dmitri Chubarov, Hung Dinh Nguyen, Michael Chertkov, Petr Vorobev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11743">Physics-Informed Building Occupancy Detection: a Switching Process with Markov Regime</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Energy efficiency of buildings is considered to be one of the major means of achieving the net-zero carbon goal around the world. The big part of the energy savings are supposed to be coming from optimizing the operation of the building heating, ventilation, and air conditioning (HVAC) systems. There is a natural trade-off between the energy efficiency and the indoor comfort level, and finding an optimal operating schedule/regime requires knowing the occupancy of different spaces inside of the building. Moreover, the COVID-19 pandemic has also revealed the need to sustain the high quality of the indoor air in order to reduce the risk of spread of infection. Occupancy detection from indoor sensors is thus an important practical problem. In the present paper, we propose detection of occupancy based on the carbon dioxide measurements inside the building. In particular, a new approach based on the, so-called, switching auto-regressive process with Markov regime is presented and justified by the physical model of the carbon dioxide concentration dynamics. We demonstrate the efficiency of the method compared to simple Hidden Markov approaches on simulated and real-life data. We also show that the model is flexible and can be generalized to account for different ventilation regimes, simultaneously detecting the occupancy and the ventilation rate.
<div id='section'>Paperid: <span id='pid'>1493, <a href='https://arxiv.org/pdf/2409.05569.pdf' target='_blank'>https://arxiv.org/pdf/2409.05569.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andreas Langer, Sara Behnamian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.05569">DeepTV: A neural network approach for total variation minimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural network approaches have been demonstrated to work quite well to solve partial differential equations in practice. In this context approaches like physics-informed neural networks and the Deep Ritz method have become popular. In this paper, we propose a similar approach to solve an infinite-dimensional total variation minimization problem using neural networks. We illustrate that the resulting neural network problem does not have a solution in general. To circumvent this theoretic issue, we consider an auxiliary neural network problem, which indeed has a solution, and show that it converges in the sense of $Γ$-convergence to the original problem. For computing a numerical solution we further propose a discrete version of the auxiliary neural network problem and again show its $Γ$-convergence to the original infinite-dimensional problem. In particular, the $Γ$-convergence proof suggests a particular discretization of the total variation. Moreover, we connect the discrete neural network problem to a finite difference discretization of the infinite-dimensional total variation minimization problem. Numerical experiments are presented supporting our theoretical findings.
<div id='section'>Paperid: <span id='pid'>1494, <a href='https://arxiv.org/pdf/2409.03239.pdf' target='_blank'>https://arxiv.org/pdf/2409.03239.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jamshaid Ul Rahman, Nimra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03239">DiffGrad for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are regarded as state-of-the-art tools for addressing highly nonlinear problems based on partial differential equations. Despite their broad range of applications, PINNs encounter several performance challenges, including issues related to efficiency, minimization of computational cost, and enhancement of accuracy. Burgers' equation, a fundamental equation in fluid dynamics that is extensively used in PINNs, provides flexible results with the Adam optimizer that does not account for past gradients. This paper introduces a novel strategy for solving Burgers' equation by incorporating DiffGrad with PINNs, a method that leverages the difference between current and immediately preceding gradients to enhance performance. A comprehensive computational analysis is conducted using optimizers such as Adam, Adamax, RMSprop, and DiffGrad to evaluate and compare their effectiveness. Our approach includes visualizing the solutions over space at various time intervals to demonstrate the accuracy of the network. The results show that DiffGrad not only improves the accuracy of the solution but also reduces training time compared to the other optimizers.
<div id='section'>Paperid: <span id='pid'>1495, <a href='https://arxiv.org/pdf/2409.03160.pdf' target='_blank'>https://arxiv.org/pdf/2409.03160.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hikaru Hoshino, Jiaxing Li, Arnav Menon, John M. Dolan, Yorie Nakahira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03160">Autonomous Drifting Based on Maximal Safety Probability Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a novel learning-based framework for autonomous driving based on the concept of maximal safety probability. Efficient learning requires rewards that are informative of desirable/undesirable states, but such rewards are challenging to design manually due to the difficulty of differentiating better states among many safe states. On the other hand, learning policies that maximize safety probability does not require laborious reward shaping but is numerically challenging because the algorithms must optimize policies based on binary rewards sparse in time. Here, we show that physics-informed reinforcement learning can efficiently learn this form of maximally safe policy. Unlike existing drift control methods, our approach does not require a specific reference trajectory or complex reward shaping, and can learn safe behaviors only from sparse binary rewards. This is enabled by the use of the physics loss that plays an analogous role to reward shaping. The effectiveness of the proposed approach is demonstrated through lane keeping in a normal cornering scenario and safe drifting in a high-speed racing scenario.
<div id='section'>Paperid: <span id='pid'>1496, <a href='https://arxiv.org/pdf/2409.00644.pdf' target='_blank'>https://arxiv.org/pdf/2409.00644.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ting Wang, Ye Li, Rongjun Cheng, Guojian Zou, Takao Dantsujic, Dong Ngoduy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.00644">Knowledge-data fusion oriented traffic state estimation: A stochastic physics-informed deep learning approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed deep learning (PIDL)-based models have recently garnered remarkable success in traffic state estimation (TSE). However, the prior knowledge used to guide regularization training in current mainstream architectures is based on deterministic physical models. The drawback is that a solely deterministic model fails to capture the universally observed traffic flow dynamic scattering effect, thereby yielding unreliable outcomes for traffic control. This study, for the first time, proposes stochastic physics-informed deep learning (SPIDL) for traffic state estimation. The idea behind such SPIDL is simple and is based on the fact that a stochastic fundamental diagram provides the entire range of possible speeds for any given density with associated probabilities. Specifically, we select percentile-based fundamental diagram and distribution-based fundamental diagram as stochastic physics knowledge, and design corresponding physics-uninformed neural networks for effective fusion, thereby realizing two specific SPIDL models, namely \text{$Î±$}-SPIDL and \text{$\cal B$}-SPIDL. The main contribution of SPIDL lies in addressing the "overly centralized guidance" caused by the one-to-one speed-density relationship in deterministic models during neural network training, enabling the network to digest more reliable knowledge-based constraints.Experiments on the real-world dataset indicate that proposed SPIDL models achieve accurate traffic state estimation in sparse data scenarios. More importantly, as expected, SPIDL models reproduce well the scattering effect of field observations, demonstrating the effectiveness of fusing stochastic physics model knowledge with deep learning frameworks.
<div id='section'>Paperid: <span id='pid'>1497, <a href='https://arxiv.org/pdf/2408.17246.pdf' target='_blank'>https://arxiv.org/pdf/2408.17246.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthieu Barreau, Nicola Bastianello
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.17246">(Un)supervised Learning of Maximal Lyapunov Functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we address the problem of discovering maximal Lyapunov functions, as a means of determining the region of attraction of a dynamical system. To this end, we design a novel neural network architecture, which we prove to be a universal approximator of (maximal) Lyapunov functions. The architecture combines a local quadratic approximation with the output of a neural network, which models global higher-order terms in the Taylor expansion. We formulate the problem of training the Lyapunov function as an unsupervised optimization problem with dynamical constraints, which can be solved leveraging techniques from physics-informed learning. We propose and analyze a tailored training algorithm, based on the primal-dual algorithm, that can efficiently solve the problem. Additionally, we show how the learning problem formulation can be adapted to integrate data, when available. We apply the proposed approach to different classes of systems, showing that it matches or outperforms state-of-the-art alternatives in the accuracy of the approximated regions of attraction.
<div id='section'>Paperid: <span id='pid'>1498, <a href='https://arxiv.org/pdf/2408.16806.pdf' target='_blank'>https://arxiv.org/pdf/2408.16806.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maziar Raissi, Paris Perdikaris, Nazanin Ahmadi, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16806">Physics-Informed Neural Networks and Extensions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we review the new method Physics-Informed Neural Networks (PINNs) that has become the main pillar in scientific machine learning, we present recent practical extensions, and provide a specific example in data-driven discovery of governing differential equations.
<div id='section'>Paperid: <span id='pid'>1499, <a href='https://arxiv.org/pdf/2408.06650.pdf' target='_blank'>https://arxiv.org/pdf/2408.06650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Shuai, Fangxing Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.06650">Physics-Informed Kolmogorov-Arnold Networks for Power System Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents, for the first time, a framework for Kolmogorov-Arnold Networks (KANs) in power system applications. Inspired by the recently proposed KAN architecture, this paper proposes physics-informed Kolmogorov-Arnold Networks (PIKANs), a novel KAN-based physics-informed neural network (PINN) tailored to efficiently and accurately learn dynamics within power systems. The PIKANs present a promising alternative to conventional Multi-Layer Perceptrons (MLPs) based PINNs, achieving superior accuracy in predicting power system dynamics while employing a smaller network size. Simulation results on a single-machine infinite bus system and a 4-bus 2- generator system underscore the accuracy of the PIKANs in predicting rotor angle and frequency with fewer learnable parameters than conventional PINNs. Furthermore, the simulation results demonstrate PIKANs capability to accurately identify uncertain inertia and damping coefficients. This work opens up a range of opportunities for the application of KANs in power systems, enabling efficient determination of grid dynamics and precise parameter identification.
<div id='section'>Paperid: <span id='pid'>1500, <a href='https://arxiv.org/pdf/2408.01914.pdf' target='_blank'>https://arxiv.org/pdf/2408.01914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Loc Vu-Quoc, Alexander Humer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.01914">Partial-differential-algebraic equations of nonlinear dynamics by Physics-Informed Neural-Network: (I) Operator splitting and framework assessment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Several forms for constructing novel physics-informed neural-networks (PINN) for the solution of partial-differential-algebraic equations based on derivative operator splitting are proposed, using the nonlinear Kirchhoff rod as a prototype for demonstration. The open-source DeepXDE is likely the most well documented framework with many examples. Yet, we encountered some pathological problems and proposed novel methods to resolve them. Among these novel methods are the PDE forms, which evolve from the lower-level form with fewer unknown dependent variables to higher-level form with more dependent variables, in addition to those from lower-level forms. Traditionally, the highest-level form, the balance-of-momenta form, is the starting point for (hand) deriving the lowest-level form through a tedious (and error prone) process of successive substitutions. The next step in a finite element method is to discretize the lowest-level form upon forming a weak form and linearization with appropriate interpolation functions, followed by their implementation in a code and testing. The time-consuming tedium in all of these steps could be bypassed by applying the proposed novel PINN directly to the highest-level form. We developed a script based on JAX. While our JAX script did not show the pathological problems of DDE-T (DDE with TensorFlow backend), it is slower than DDE-T. That DDE-T itself being more efficient in higher-level form than in lower-level form makes working directly with higher-level form even more attractive in addition to the advantages mentioned further above. Since coming up with an appropriate learning-rate schedule for a good solution is more art than science, we systematically codified in detail our experience running optimization through a normalization/standardization of the network-training process so readers can reproduce our results.
<div id='section'>Paperid: <span id='pid'>1501, <a href='https://arxiv.org/pdf/2407.17721.pdf' target='_blank'>https://arxiv.org/pdf/2407.17721.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuanxuan Yang, Yangming Zhang, Haofeng Chen, Gang Ma, Xiaojie Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.17721">A Two-Stage Imaging Framework Combining CNN and Physics-Informed Neural Networks for Full-Inverse Tomography: A Case Study in Electrical Impedance Tomography (EIT)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electrical Impedance Tomography (EIT) is a highly ill-posed inverse problem, with the challenge of reconstructing internal conductivities using only boundary voltage measurements. Although Physics-Informed Neural Networks (PINNs) have shown potential in solving inverse problems, existing approaches are limited in their applicability to EIT, as they often rely on impractical prior knowledge and assumptions that cannot be satisfied in real-world scenarios. To address these limitations, we propose a two-stage hybrid learning framework that combines Convolutional Neural Networks (CNNs) and PINNs. This framework integrates data-driven and model-driven paradigms, blending supervised and unsupervised learning to reconstruct conductivity distributions while ensuring adherence to the underlying physical laws, thereby overcoming the constraints of existing methods.
<div id='section'>Paperid: <span id='pid'>1502, <a href='https://arxiv.org/pdf/2407.15887.pdf' target='_blank'>https://arxiv.org/pdf/2407.15887.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis Mandl, Somdatta Goswami, Lena Lambers, Tim Ricken
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.15887">Separable DeepONet: Breaking the Curse of Dimensionality in Physics-Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The deep operator network (DeepONet) is a popular neural operator architecture that has shown promise in solving partial differential equations (PDEs) by using deep neural networks to map between infinite-dimensional function spaces. In the absence of labeled datasets, we utilize the PDE residual loss to learn the physical system, an approach known as physics-informed DeepONet. This method faces significant computational challenges, primarily due to the curse of dimensionality, as the computational cost increases exponentially with finer discretization. In this paper, we introduce the Separable DeepONet framework to address these challenges and improve scalability for high-dimensional PDEs. Our approach involves a factorization technique where sub-networks handle individual one-dimensional coordinates, thereby reducing the number of forward passes and the size of the Jacobian matrix. By using forward-mode automatic differentiation, we further optimize the computational cost related to the Jacobian matrix. As a result, our modifications lead to a linear scaling of computational cost with discretization density, making Separable DeepONet suitable for high-dimensional PDEs. We validate the effectiveness of the separable architecture through three benchmark PDE models: the viscous Burgers equation, Biot's consolidation theory, and a parametrized heat equation. In all cases, our proposed framework achieves comparable or improved accuracy while significantly reducing computational time compared to conventional DeepONet. These results demonstrate the potential of Separable DeepONet in efficiently solving complex, high-dimensional PDEs, advancing the field of physics-informed machine learning.
<div id='section'>Paperid: <span id='pid'>1503, <a href='https://arxiv.org/pdf/2407.09496.pdf' target='_blank'>https://arxiv.org/pdf/2407.09496.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sukirt Thakur, Harsa Mitra, Arezoo M. Ardekani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.09496">Physics-Informed Neural Network based inverse framework for time-fractional differential equations for rheology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time-fractional differential equations offer a robust framework for capturing intricate phenomena characterized by memory effects, particularly in fields like biotransport and rheology. However, solving inverse problems involving fractional derivatives presents notable challenges, including issues related to stability and uniqueness. While Physics-Informed Neural Networks (PINNs) have emerged as effective tools for solving inverse problems, most existing PINN frameworks primarily focus on integer-ordered derivatives.
  In this study, we extend the application of PINNs to address inverse problems involving time-fractional derivatives, specifically targeting two problems: 1) anomalous diffusion and 2) fractional viscoelastic constitutive equation. Leveraging both numerically generated datasets and experimental data, we calibrate the concentration-dependent generalized diffusion coefficient and parameters for the fractional Maxwell model. We devise a tailored residual loss function that scales with the standard deviation of observed data.
  We rigorously test our framework's efficacy in handling anomalous diffusion. Even after introducing 25% Gaussian noise to the concentration dataset, our framework demonstrates remarkable robustness. Notably, the relative error in predicting the generalized diffusion coefficient and the order of the fractional derivative is less than 10% for all cases, underscoring the resilience and accuracy of our approach. In another test case, we predict relaxation moduli for three pig tissue samples, consistently achieving relative errors below 10%. Furthermore, our framework exhibits promise in modeling anomalous diffusion and non-linear fractional viscoelasticity.
<div id='section'>Paperid: <span id='pid'>1504, <a href='https://arxiv.org/pdf/2407.06785.pdf' target='_blank'>https://arxiv.org/pdf/2407.06785.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashok Dahal, Luigi Lombardo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06785">Towards physics-informed neural networks for landslide prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For decades, solutions to regional scale landslide prediction have mostly relied on data-driven models, by definition, disconnected from the physics of the failure mechanism. The success and spread of such tools came from the ability to exploit proxy variables rather than explicit geotechnical ones, as the latter are prohibitive to acquire over broad landscapes. Our work implements a Physics Informed Neural Network (PINN) approach, thereby adding to a standard data-driven architecture, an intermediate constraint to solve for the permanent deformation typical of Newmark slope stability methods. This translates into a neural network tasked with explicitly retrieving geotechnical parameters from common proxy variables and then minimize a loss function with respect to the available coseismic landside inventory. The results are very promising, because our model not only produces excellent predictive performance in the form of standard susceptibility output, but in the process, also generates maps of the expected geotechnical properties at a regional scale. Such architecture is therefore framed to tackle coseismic landslide prediction, something that, if confirmed in other studies, could open up towards PINN-based near-real-time predictions.
<div id='section'>Paperid: <span id='pid'>1505, <a href='https://arxiv.org/pdf/2407.03372.pdf' target='_blank'>https://arxiv.org/pdf/2407.03372.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sumanta Roy, Chandrasekhar Annavarapu, Pratanu Roy, Dakshina Murthy Valiveti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03372">Physics-informed Neural Networks for Heterogeneous Poroelastic Media</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a novel physics-informed neural network (PINN) framework for modeling poroelasticity in heterogeneous media with material interfaces. The approach introduces a composite neural network (CoNN) where separate neural networks predict displacement and pressure variables for each material. While sharing identical activation functions, these networks are independently trained for all other parameters. To address challenges posed by heterogeneous material interfaces, the CoNN is integrated with the Interface-PINNs or I-PINNs framework (Sarma et al. 2024, https://dx.doi.org/10.1016/j.cma.2024.117135), allowing different activation functions across material interfaces. This ensures accurate approximation of discontinuous solution fields and gradients. Performance and accuracy of this combined architecture were evaluated against the conventional PINNs approach, a single neural network (SNN) architecture, and the eXtended PINNs (XPINNs) framework through two one-dimensional benchmark examples with discontinuous material properties. The results show that the proposed CoNN with I-PINNs architecture achieves an RMSE that is two orders of magnitude better than the conventional PINNs approach and is at least 40 times faster than the SNN framework. Compared to XPINNs, the proposed method achieves an RMSE at least one order of magnitude better and is 40% faster.
<div id='section'>Paperid: <span id='pid'>1506, <a href='https://arxiv.org/pdf/2407.03347.pdf' target='_blank'>https://arxiv.org/pdf/2407.03347.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pengsong Yin, Shuo Ling, Wenjun Ying
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03347">Chebyshev Spectral Neural Networks for Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The purpose of this study is to utilize the Chebyshev spectral method neural network(CSNN) model to solve differential equations. This approach employs a single-layer neural network wherein Chebyshev spectral methods are used to construct neurons satisfying boundary conditions. The study uses a feedforward neural network model and error backpropagation principles, utilizing automatic differentiation (AD) to compute the loss function. This method avoids the need to solve non-sparse linear systems, making it convenient for algorithm implementation and solving high-dimensional problems. The unique sampling method and neuron architecture significantly enhance the training efficiency and accuracy of the neural network. Furthermore, multiple networks enables the Chebyshev spectral method to handle equations on more complex domains. The numerical efficiency and accuracy of the CSNN model are investigated through testing on elliptic partial differential equations, and it is compared with the well-known Physics-Informed Neural Network(PINN) method.
<div id='section'>Paperid: <span id='pid'>1507, <a href='https://arxiv.org/pdf/2407.01088.pdf' target='_blank'>https://arxiv.org/pdf/2407.01088.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matteo CalafÃ, Emil Hovad, Allan P. Engsig-Karup, Tito Andriollo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.01088">Physics-Informed Holomorphic Neural Networks (PIHNNs): Solving Linear Elasticity Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose physics-informed holomorphic neural networks (PIHNNs) as a method to solve boundary value problems where the solution can be represented via holomorphic functions. Specifically, we consider the case of plane linear elasticity and, by leveraging the Kolosov-Muskhelishvili representation of the solution in terms of holomorphic potentials, we train a complex-valued neural network to fulfill stress and displacement boundary conditions while automatically satisfying the governing equations. This is achieved by designing the network to return only approximations that inherently satisfy the Cauchy-Riemann conditions through specific choices of layers and activation functions. To ensure generality, we provide a universal approximation theorem guaranteeing that, under basic assumptions, the proposed holomorphic neural networks can approximate any holomorphic function. Furthermore, we suggest a new tailored weight initialization technique to mitigate the issue of vanishing/exploding gradients. Compared to the standard PINN approach, noteworthy benefits of the proposed method for the linear elasticity problem include a more efficient training, as evaluations are needed solely on the boundary of the domain, lower memory requirements, due to the reduced number of training points, and $C^\infty$ regularity of the learned solution. Several benchmark examples are used to verify the correctness of the obtained PIHNN approximations, the substantial benefits over traditional PINNs, and the possibility to deal with non-trivial, multiply-connected geometries via a domain-decomposition strategy.
<div id='section'>Paperid: <span id='pid'>1508, <a href='https://arxiv.org/pdf/2406.19817.pdf' target='_blank'>https://arxiv.org/pdf/2406.19817.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tobias Nagel, Marco F. Huber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.19817">Identifying Ordinary Differential Equations for Data-efficient Model-based Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The identification of a mathematical dynamics model is a crucial step in the designing process of a controller. However, it is often very difficult to identify the system's governing equations, especially in complex environments that combine physical laws of different disciplines. In this paper, we present a new approach that allows identifying an ordinary differential equation by means of a physics-informed machine learning algorithm. Our method introduces a special neural network that allows exploiting prior human knowledge to a certain degree and extends it autonomously, so that the resulting differential equations describe the system as accurately as possible. We validate the method on a Duffing oscillator with simulation data and, additionally, on a cascaded tank example with real-world data. Subsequently, we use the developed algorithm in a model-based reinforcement learning framework by alternately identifying and controlling a system to a target state. We test the performance by swinging-up an inverted pendulum on a cart.
<div id='section'>Paperid: <span id='pid'>1509, <a href='https://arxiv.org/pdf/2406.11119.pdf' target='_blank'>https://arxiv.org/pdf/2406.11119.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazuya Yokota, Masataka Ogura, Masajiro Abe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11119">Identification of Physical Properties in Acoustic Tubes Using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Neural Networks (PINNs) is a method for numerical simulation that incorporates a loss function corresponding to the governing equations into a neural network. While PINNs have been explored for their utility in inverse analysis, their application in acoustic analysis remains limited. This study presents a method to identify loss parameters in acoustic tubes using PINNs. We categorized the loss parameters into two groups: one dependent on the tube's diameter and another constant, independent of it. The latter were set as the trainable parameters of the neural network. The problem of identifying the loss parameter was formulated as an optimization problem, with the physical properties being determined through this process. The neural network architecture employed was based on our previously proposed ResoNet, which is designed for analyzing acoustic resonance. The efficacy of the proposed method is assessed through both forward and inverse analysis, specifically through the identification of loss parameters. The findings demonstrate that it is feasible to accurately identify parameters that significantly impact the sound field under analysis. By merely altering the governing equations in the loss function, this method could be adapted to various sound fields, suggesting its potential for broad application.
<div id='section'>Paperid: <span id='pid'>1510, <a href='https://arxiv.org/pdf/2406.11023.pdf' target='_blank'>https://arxiv.org/pdf/2406.11023.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammadreza Kavianpour, Parisa Kavianpour, Amin Ramezani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11023">Physics-Informed Deep Learning and Partial Transfer Learning for Bearing Fault Diagnosis in the Presence of Highly Missing Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One of the most significant obstacles in bearing fault diagnosis is a lack of labeled data for various fault types. Also, sensor-acquired data frequently lack labels and have a large amount of missing data. This paper tackles these issues by presenting the PTPAI method, which uses a physics-informed deep learning-based technique to generate synthetic labeled data. Labeled synthetic data makes up the source domain, whereas unlabeled data with missing data is present in the target domain. Consequently, imbalanced class problems and partial-set fault diagnosis hurdles emerge. To address these challenges, the RF-Mixup approach is used to handle imbalanced classes. As domain adaptation strategies, the MK-MMSD and CDAN are employed to mitigate the disparity in distribution between synthetic and actual data. Furthermore, the partial-set challenge is tackled by applying weighting methods at the class and instance levels. Experimental outcomes on the CWRU and JNU datasets indicate that the proposed approach effectively addresses these problems.
<div id='section'>Paperid: <span id='pid'>1511, <a href='https://arxiv.org/pdf/2406.10433.pdf' target='_blank'>https://arxiv.org/pdf/2406.10433.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Renukanandan Tumu, Wenceslao Shaw Cortez, JÃ¡n DrgoÅa, Draguna L. Vrabie, Sonja Glavaski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10433">Differentiable Predictive Control for Large-Scale Urban Road Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transportation is a major contributor to CO2 emissions, making it essential to optimize traffic networks to reduce energy-related emissions. This paper presents a novel approach to traffic network control using Differentiable Predictive Control (DPC), a physics-informed machine learning methodology. We base our model on the Macroscopic Fundamental Diagram (MFD) and the Networked Macroscopic Fundamental Diagram (NMFD), offering a simplified representation of citywide traffic networks. Our approach ensures compliance with system constraints by construction. In empirical comparisons with existing state-of-the-art Model Predictive Control (MPC) methods, our approach demonstrates a 4 order of magnitude reduction in computation time and an up to 37% improvement in traffic performance. Furthermore, we assess the robustness of our controller to scenario shifts and find that it adapts well to changes in traffic patterns. This work proposes more efficient traffic control methods, particularly in large-scale urban networks, and aims to mitigate emissions and alleviate congestion in the future.
<div id='section'>Paperid: <span id='pid'>1512, <a href='https://arxiv.org/pdf/2406.09194.pdf' target='_blank'>https://arxiv.org/pdf/2406.09194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Honam Wong, Wendao Wu, Fanghui Liu, Yiping Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.09194">Benign overfitting in Fixed Dimension via Physics-Informed Learning with Smooth Inductive Bias</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in machine learning have inspired a surge of research into reconstructing specific quantities of interest from measurements that comply with certain physical laws. These efforts focus on inverse problems that are governed by partial differential equations (PDEs). In this work, we develop an asymptotic Sobolev norm learning curve for kernel ridge(less) regression when addressing (elliptical) linear inverse problems. Our results show that the PDE operators in the inverse problem can stabilize the variance and even behave benign overfitting for fixed-dimensional problems, exhibiting different behaviors from regression problems. Besides, our investigation also demonstrates the impact of various inductive biases introduced by minimizing different Sobolev norms as a form of implicit regularization. For the regularized least squares estimator, we find that all considered inductive biases can achieve the optimal convergence rate, provided the regularization parameter is appropriately chosen. The convergence rate is actually independent to the choice of (smooth enough) inductive bias for both ridge and ridgeless regression. Surprisingly, our smoothness requirement recovered the condition found in Bayesian setting and extend the conclusion to the minimum norm interpolation estimators.
<div id='section'>Paperid: <span id='pid'>1513, <a href='https://arxiv.org/pdf/2406.06350.pdf' target='_blank'>https://arxiv.org/pdf/2406.06350.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yianxia Qian, Yongchao Zhang, Suchuan Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.06350">Error Analysis and Numerical Algorithm for PDE Approximation with Hidden-Layer Concatenated Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present the hidden-layer concatenated physics informed neural network (HLConcPINN) method, which combines hidden-layer concatenated feed-forward neural networks, a modified block time marching strategy, and a physics informed approach for approximating partial differential equations (PDEs). We analyze the convergence properties and establish the error bounds of this method for two types of PDEs: parabolic (exemplified by the heat and Burgers' equations) and hyperbolic (exemplified by the wave and nonlinear Klein-Gordon equations). We show that its approximation error of the solution can be effectively controlled by the training loss for dynamic simulations with long time horizons. The HLConcPINN method in principle allows an arbitrary number of hidden layers not smaller than two and any of the commonly-used smooth activation functions for the hidden layers beyond the first two, with theoretical guarantees. This generalizes several recent neural-network techniques, which have theoretical guarantees but are confined to two hidden layers in the network architecture and the $\tanh$ activation function. Our theoretical analyses subsequently inform the formulation of appropriate training loss functions for these PDEs, leading to physics informed neural network (PINN) type computational algorithms that differ from the standard PINN formulation. Ample numerical experiments are presented based on the proposed algorithm to validate the effectiveness of this method and confirm aspects of the theoretical analyses.
<div id='section'>Paperid: <span id='pid'>1514, <a href='https://arxiv.org/pdf/2406.05290.pdf' target='_blank'>https://arxiv.org/pdf/2406.05290.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhiram Anand Thiruthummal, Sergiy Shelyag, Eun-jin Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.05290">Extremization to Fine Tune Physics Informed Neural Networks for Solving Boundary Value Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel method for fast and accurate training of physics-informed neural networks (PINNs) to find solutions to boundary value problems (BVPs) and initial boundary value problems (IBVPs). By combining the methods of training deep neural networks (DNNs) and Extreme Learning Machines (ELMs), we develop a model which has the expressivity of DNNs with the fine-tuning ability of ELMs. We showcase the superiority of our proposed method by solving several BVPs and IBVPs which include linear and non-linear ordinary differential equations (ODEs), partial differential equations (PDEs) and coupled PDEs. The examples we consider include a stiff coupled ODE system where traditional numerical methods fail, a 3+1D non-linear PDE, Kovasznay flow and Taylor-Green vortex solutions to incompressible Navier-Stokes equations and pure advection solution of 1+1 D compressible Euler equation.
  The Theory of Functional Connections (TFC) is used to exactly impose initial and boundary conditions (IBCs) of (I)BVPs on PINNs. We propose a modification to the TFC framework named Reduced TFC and show a significant improvement in the training and inference time of PINNs compared to IBCs imposed using TFC. Furthermore, Reduced TFC is shown to be able to generalize to more complex boundary geometries which is not possible with TFC. We also introduce a method of applying boundary conditions at infinity for BVPs and numerically solve the pure advection in 1+1 D Euler equations using these boundary conditions.
<div id='section'>Paperid: <span id='pid'>1515, <a href='https://arxiv.org/pdf/2406.04626.pdf' target='_blank'>https://arxiv.org/pdf/2406.04626.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sumanta Roy, Chandrasekhar Annavarapu, Pratanu Roy, Antareep Kumar Sarma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04626">Adaptive Interface-PINNs (AdaI-PINNs): An Efficient Physics-informed Neural Networks Framework for Interface Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present an efficient physics-informed neural networks (PINNs) framework, termed Adaptive Interface-PINNs (AdaI-PINNs), to improve the modeling of interface problems with discontinuous coefficients and/or interfacial jumps. This framework is an enhanced version of its predecessor, Interface PINNs or I-PINNs (Sarma et al.; https://dx.doi.org/10.2139/ssrn.4766623), which involves domain decomposition and assignment of different predefined activation functions to the neural networks in each subdomain across a sharp interface, while keeping all other parameters of the neural networks identical. In AdaI-PINNs, the activation functions vary solely in their slopes, which are trained along with the other parameters of the neural networks. This makes the AdaI-PINNs framework fully automated without requiring preset activation functions. Comparative studies on one-dimensional, two-dimensional, and three-dimensional benchmark elliptic interface problems reveal that AdaI-PINNs outperform I-PINNs, reducing computational costs by 2-6 times while producing similar or better accuracy.
<div id='section'>Paperid: <span id='pid'>1516, <a href='https://arxiv.org/pdf/2406.03711.pdf' target='_blank'>https://arxiv.org/pdf/2406.03711.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jing Qiu, Jiancheng Huang, Xiangdong Zhang, Zeng Lin, Minglei Pan, Zengding Liu, Fen Miao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03711">Pi-fusion: Physics-informed diffusion model for learning fluid dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed deep learning has been developed as a novel paradigm for learning physical dynamics recently. While general physics-informed deep learning methods have shown early promise in learning fluid dynamics, they are difficult to generalize in arbitrary time instants in real-world scenario, where the fluid motion can be considered as a time-variant trajectory involved large-scale particles. Inspired by the advantage of diffusion model in learning the distribution of data, we first propose Pi-fusion, a physics-informed diffusion model for predicting the temporal evolution of velocity and pressure field in fluid dynamics. Physics-informed guidance sampling is proposed in the inference procedure of Pi-fusion to improve the accuracy and interpretability of learning fluid dynamics. Furthermore, we introduce a training strategy based on reciprocal learning to learn the quasiperiodical pattern of fluid motion and thus improve the generalizability of the model. The proposed approach are then evaluated on both synthetic and real-world dataset, by comparing it with state-of-the-art physics-informed deep learning methods. Experimental results show that the proposed approach significantly outperforms existing methods for predicting temporal evolution of velocity and pressure field, confirming its strong generalization by drawing probabilistic inference of forward process and physics-informed guidance sampling. The proposed Pi-fusion can also be generalized in learning other physical dynamics governed by partial differential equations.
<div id='section'>Paperid: <span id='pid'>1517, <a href='https://arxiv.org/pdf/2406.01913.pdf' target='_blank'>https://arxiv.org/pdf/2406.01913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shaorong Zhang, Yuanbin Cheng, Nanpeng Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.01913">Generating Synthetic Net Load Data with Physics-informed Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel physics-informed diffusion model for generating synthetic net load data, addressing the challenges of data scarcity and privacy concerns. The proposed framework embeds physical models within denoising networks, offering a versatile approach that can be readily generalized to unforeseen scenarios. A conditional denoising neural network is designed to jointly train the parameters of the transition kernel of the diffusion model and the parameters of the physics-informed function. Utilizing the real-world smart meter data from Pecan Street, we validate the proposed method and conduct a thorough numerical study comparing its performance with state-of-the-art generative models, including generative adversarial networks, variational autoencoders, normalizing flows, and a well calibrated baseline diffusion model. A comprehensive set of evaluation metrics is used to assess the accuracy and diversity of the generated synthetic net load data. The numerical study results demonstrate that the proposed physics-informed diffusion model outperforms state-of-the-art models across all quantitative metrics, yielding at least 20% improvement.
<div id='section'>Paperid: <span id='pid'>1518, <a href='https://arxiv.org/pdf/2406.00889.pdf' target='_blank'>https://arxiv.org/pdf/2406.00889.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Clement Etienam, Yang Juntao, Oleg Ovcharenko, Issam Said
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00889">Reservoir History Matching of the Norne field with generative exotic priors and a coupled Mixture of Experts -- Physics Informed Neural Operator Forward Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We developed a novel reservoir characterization workflow that addresses reservoir history matching by coupling a physics-informed neural operator (PINO) forward model with a mixture of experts' approach, termed cluster classify regress (CCR). The inverse modelling is achieved via an adaptive Regularized Ensemble Kalman inversion (aREKI) method, ideal for rapid inverse uncertainty quantification during history matching. We parametrize unknown permeability and porosity fields for non-Gaussian posterior measures using a variational convolution autoencoder and a denoising diffusion implicit model (DDIM) exotic priors. The CCR works as a supervised model with the PINO surrogate to replicate nonlinear Peaceman well equations. The CCR's flexibility allows any independent machine-learning algorithm for each stage. The PINO reservoir surrogate's loss function is derived from supervised data loss and losses from the initial conditions and residual of the governing black oil PDE. The PINO-CCR surrogate outputs pressure, water, and gas saturations, along with oil, water, and gas production rates. The methodology was compared to a standard numerical black oil simulator for a waterflooding case on the Norne field, showing similar outputs. This PINO-CCR surrogate was then used in the aREKI history matching workflow, successfully recovering the unknown permeability, porosity and fault multiplier, with simulations up to 6000 times faster than conventional methods. Training the PINO-CCR surrogate on an NVIDIA H100 with 80G memory takes about 5 hours for 100 samples of the Norne field. This workflow is suitable for ensemble-based approaches, where posterior density sampling, given an expensive likelihood evaluation, is desirable for uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>1519, <a href='https://arxiv.org/pdf/2405.20000.pdf' target='_blank'>https://arxiv.org/pdf/2405.20000.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Zhang, Longxiang Jiang, Xinkun Chu, Yong Wen, Luxiong Li, Yonghao Xiao, Liyuan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.20000">Combining physics-informed graph neural network and finite difference for solving forward and inverse spatiotemporal PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The great success of Physics-Informed Neural Networks (PINN) in solving partial differential equations (PDEs) has significantly advanced our simulation and understanding of complex physical systems in science and engineering. However, many PINN-like methods are poorly scalable and are limited to in-sample scenarios. To address these challenges, this work proposes a novel discrete approach termed Physics-Informed Graph Neural Network (PIGNN) to solve forward and inverse nonlinear PDEs. In particular, our approach seamlessly integrates the strength of graph neural networks (GNN), physical equations and finite difference to approximate solutions of physical systems. Our approach is compared with the PINN baseline on three well-known nonlinear PDEs (heat, Burgers and FitzHugh-Nagumo). We demonstrate the excellent performance of the proposed method to work with irregular meshes, longer time steps, arbitrary spatial resolutions, varying initial conditions (ICs) and boundary conditions (BCs) by conducting extensive numerical experiments. Numerical results also illustrate the superiority of our approach in terms of accuracy, time extrapolability, generalizability and scalability. The main advantage of our approach is that models trained in small domains with simple settings have excellent fitting capabilities and can be directly applied to more complex situations in large domains.
<div id='section'>Paperid: <span id='pid'>1520, <a href='https://arxiv.org/pdf/2405.13586.pdf' target='_blank'>https://arxiv.org/pdf/2405.13586.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexis-Raja Brachet, Pierre-Yves Richard, CÃ©line Hudelot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.13586">Bond Graphs for multi-physics informed Neural Networks for multi-variate time series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the trend of hybrid Artificial Intelligence techniques, Physical-Informed Machine Learning has seen a growing interest. It operates mainly by imposing data, learning, or architecture bias with simulation data, Partial Differential Equations, or equivariance and invariance properties. While it has shown great success on tasks involving one physical domain, such as fluid dynamics, existing methods are not adapted to tasks with complex multi-physical and multi-domain phenomena. In addition, it is mainly formulated as an end-to-end learning scheme. To address these challenges, we propose to leverage Bond Graphs, a multi-physics modeling approach, together with Message Passing Graph Neural Networks. We propose a Neural Bond graph Encoder (NBgE) producing multi-physics-informed representations that can be fed into any task-specific model. It provides a unified way to integrate both data and architecture biases in deep learning. Our experiments on two challenging multi-domain physical systems - a Direct Current Motor and the Respiratory System - demonstrate the effectiveness of our approach on a multivariate time-series forecasting task.
<div id='section'>Paperid: <span id='pid'>1521, <a href='https://arxiv.org/pdf/2405.06443.pdf' target='_blank'>https://arxiv.org/pdf/2405.06443.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ibai Ramirez, Joel Pino, David Pardo, Mikel Sanz, Luis del Rio, Alvaro Ortiz, Kateryna Morozovska, Jose I. Aizpurua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.06443">Residual-based Attention Physics-informed Neural Networks for Spatio-Temporal Ageing Assessment of Transformers Operated in Renewable Power Plants</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformers are crucial for reliable and efficient power system operations, particularly in supporting the integration of renewable energy. Effective monitoring of transformer health is critical to maintain grid stability and performance. Thermal insulation ageing is a key transformer failure mode, which is generally tracked by monitoring the hotspot temperature (HST). However, HST measurement is complex, costly, and often estimated from indirect measurements. Existing HST models focus on space-agnostic thermal models, providing worst-case HST estimates. This article introduces a spatio-temporal model for transformer winding temperature and ageing estimation, which leverages physics-based partial differential equations (PDEs) with data-driven Neural Networks (NN) in a Physics Informed Neural Networks (PINNs) configuration to improve prediction accuracy and acquire spatio-temporal resolution. The computational accuracy of the PINN model is improved through the implementation of the Residual-Based Attention (PINN-RBA) scheme that accelerates the PINN model convergence. The PINN-RBA model is benchmarked against self-adaptive attention schemes and classical vanilla PINN configurations. For the first time, PINN based oil temperature predictions are used to estimate spatio-temporal transformer winding temperature values, validated through PDE numerical solution and fiber optic sensor measurements. Furthermore, the spatio-temporal transformer ageing model is inferred, which supports transformer health management decision-making. Results are validated with a distribution transformer operating on a floating photovoltaic power plant.
<div id='section'>Paperid: <span id='pid'>1522, <a href='https://arxiv.org/pdf/2405.03433.pdf' target='_blank'>https://arxiv.org/pdf/2405.03433.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhengqi Zhang, Jing Li, Bin Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.03433">Annealed adaptive importance sampling method in PINNs for solving high dimensional partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as powerful tools for solving a wide range of partial differential equations (PDEs). However, despite their user-friendly interface and broad applicability, PINNs encounter challenges in accurately resolving PDEs, especially when dealing with singular cases that may lead to unsatisfactory local minima. To address these challenges and improve solution accuracy, we propose an innovative approach called Annealed Adaptive Importance Sampling (AAIS) for computing the discretized PDE residuals of the cost functions, inspired by the Expectation Maximization algorithm used in finite mixtures to mimic target density. Our objective is to approximate discretized PDE residuals by strategically sampling additional points in regions with elevated residuals, thus enhancing the effectiveness and accuracy of PINNs. Implemented together with a straightforward resampling strategy within PINNs, our AAIS algorithm demonstrates significant improvements in efficiency across a range of tested PDEs, even with limited training datasets. Moreover, our proposed AAIS-PINN method shows promising capabilities in solving high-dimensional singular PDEs. The adaptive sampling framework introduced here can be integrated into various PINN frameworks.
<div id='section'>Paperid: <span id='pid'>1523, <a href='https://arxiv.org/pdf/2405.03427.pdf' target='_blank'>https://arxiv.org/pdf/2405.03427.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thi Nguyen Khoa Nguyen, Thibault Dairay, RaphaÃ«l Meunier, Christophe Millet, Mathilde Mougeot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.03427">Geometry-aware framework for deep energy method: an application to structural mechanics with hyperelastic materials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have gained considerable interest in diverse engineering domains thanks to their capacity to integrate physical laws into deep learning models. Recently, geometry-aware PINN-based approaches that employ the strong form of underlying physical system equations have been developed with the aim of integrating geometric information into PINNs. Despite ongoing research, the assessment of PINNs in problems with various geometries remains an active area of investigation. In this work, we introduce a novel physics-informed framework named the Geometry-Aware Deep Energy Method (GADEM) for solving structural mechanics problems on different geometries. As the weak form of the physical system equation (or the energy-based approach) has demonstrated clear advantages compared to the strong form for solving solid mechanics problems, GADEM employs the weak form and aims to infer the solution on multiple shapes of geometries. Integrating a geometry-aware framework into an energy-based method results in an effective physics-informed deep learning model in terms of accuracy and computational cost. Different ways to represent the geometric information and to encode the geometric latent vectors are investigated in this work. We introduce a loss function of GADEM which is minimized based on the potential energy of all considered geometries. An adaptive learning method is also employed for the sampling of collocation points to enhance the performance of GADEM. We present some applications of GADEM to solve solid mechanics problems, including a loading simulation of a toy tire involving contact mechanics and large deformation hyperelasticity. The numerical results of this work demonstrate the remarkable capability of GADEM to infer the solution on various and new shapes of geometries using only one trained model.
<div id='section'>Paperid: <span id='pid'>1524, <a href='https://arxiv.org/pdf/2405.01480.pdf' target='_blank'>https://arxiv.org/pdf/2405.01480.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junaid Akhter, Paul David FÃ¤hrmann, Konstantin Sonntag, Sebastian Peitz, Daniel Schwietert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01480">Common pitfalls to avoid while using multiobjective optimization in machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, there has been an increasing interest in the application of multiobjective optimization (MOO) in machine learning (ML). This interest is driven by the numerous real-life situations where multiple objectives must be optimized simultaneously. A key aspect of MOO is the existence of a Pareto set, rather than a single optimal solution, which represents the optimal trade-offs between different objectives. Despite its potential, there is a noticeable lack of satisfactory literature serving as an entry-level guide for ML practitioners aiming to apply MOO effectively. In this paper, our goal is to provide such a resource and highlight pitfalls to avoid. We begin by establishing the groundwork for MOO, focusing on well-known approaches such as the weighted sum (WS) method, alongside more advanced techniques like the multiobjective gradient descent algorithm (MGDA). We critically review existing studies across various ML fields where MOO has been applied and identify challenges that can lead to incorrect interpretations. One of these fields is physics informed neural networks (PINNs), which we use as a guiding example to carefully construct experiments illustrating these pitfalls. By comparing WS and MGDA with one of the most common evolutionary algorithms, NSGA-II, we demonstrate that difficulties can arise regardless of the specific MOO method used. We emphasize the importance of understanding the specific problem, the objective space, and the selected MOO method, while also noting that neglecting factors such as convergence criteria can result in misleading experiments.
<div id='section'>Paperid: <span id='pid'>1525, <a href='https://arxiv.org/pdf/2404.14984.pdf' target='_blank'>https://arxiv.org/pdf/2404.14984.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxuan Chen, Ce Wang, Yuan Hui, Mark Spivack
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14984">Surface profile recovery from electromagnetic field with physics--informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics--informed neural networks (PINN) have shown their potential in solving both direct and inverse problems of partial differential equations. In this paper, we introduce a PINN-based deep learning approach to reconstruct one-dimensional rough surfaces from field data illuminated by an electromagnetic incident wave. In the proposed algorithm, the rough surface is approximated by a neural network, with which the spatial derivatives of surface function can be obtained via automatic differentiation and then the scattered field can be calculated via the method of moments. The neural network is trained by minimizing the loss between the calculated and the observed field data. Furthermore, the proposed method is an unsupervised approach, independent of any surface data, rather only the field data is used. Both TE field (Dirichlet boundary condition) and TM field (Neumann boundary condition) are considered. Two types of field data are used here: full scattered field data and phaseless total field data. The performance of the method is verified by testing with Gaussian-correlated random rough surfaces. Numerical results demonstrate that the PINN-based method can recover rough surfaces with great accuracy and is robust with respect to a wide range of problem regimes.
<div id='section'>Paperid: <span id='pid'>1526, <a href='https://arxiv.org/pdf/2404.14447.pdf' target='_blank'>https://arxiv.org/pdf/2404.14447.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Clement Etienam, Yang Juntao, Issam Said, Oleg Ovcharenko, Kaustubh Tangsali, Pavel Dimitrov, Ken Hester
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14447">A Novel A.I Enhanced Reservoir Characterization with a Combined Mixture of Experts -- NVIDIA Modulus based Physics Informed Neural Operator Forward Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We have developed an advanced workflow for reservoir characterization, effectively addressing the challenges of reservoir history matching through a novel approach. This method integrates a Physics Informed Neural Operator (PINO) as a forward model within a sophisticated Cluster Classify Regress (CCR) framework. The process is enhanced by an adaptive Regularized Ensemble Kalman Inversion (aREKI), optimized for rapid uncertainty quantification in reservoir history matching. This innovative workflow parameterizes unknown permeability and porosity fields, capturing non-Gaussian posterior measures with techniques such as a variational convolution autoencoder and the CCR. Serving as exotic priors and a supervised model, the CCR synergizes with the PINO surrogate to accurately simulate the nonlinear dynamics of Peaceman well equations. The CCR approach allows for flexibility in applying distinct machine learning algorithms across its stages. Updates to the PINO reservoir surrogate are driven by a loss function derived from supervised data, initial conditions, and residuals of governing black oil PDEs. Our integrated model, termed PINO-Res-Sim, outputs crucial parameters including pressures, saturations, and production rates for oil, water, and gas. Validated against traditional simulators through controlled experiments on synthetic reservoirs and the Norne field, the methodology showed remarkable accuracy. Additionally, the PINO-Res-Sim in the aREKI workflow efficiently recovered unknown fields with a computational speedup of 100 to 6000 times faster than conventional methods. The learning phase for PINO-Res-Sim, conducted on an NVIDIA H100, was impressively efficient, compatible with ensemble-based methods for complex computational tasks.
<div id='section'>Paperid: <span id='pid'>1527, <a href='https://arxiv.org/pdf/2403.16391.pdf' target='_blank'>https://arxiv.org/pdf/2403.16391.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hikaru Hoshino, Yorie Nakahira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.16391">Physics-informed RL for Maximal Safety Probability Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate risk quantification and reachability analysis are crucial for safe control and learning, but sampling from rare events, risky states, or long-term trajectories can be prohibitively costly. Motivated by this, we study how to estimate the long-term safety probability of maximally safe actions without sufficient coverage of samples from risky states and long-term trajectories. The use of maximal safety probability in control and learning is expected to avoid conservative behaviors due to over-approximation of risk. Here, we first show that long-term safety probability, which is multiplicative in time, can be converted into additive costs and be solved using standard reinforcement learning methods. We then derive this probability as solutions of partial differential equations (PDEs) and propose Physics-Informed Reinforcement Learning (PIRL) algorithm. The proposed method can learn using sparse rewards because the physics constraints help propagate risk information through neighbors. This suggests that, for the purpose of extracting more information for efficient learning, physics constraints can serve as an alternative to reward shaping. The proposed method can also estimate long-term risk using short-term samples and deduce the risk of unsampled states. This feature is in stark contrast with the unconstrained deep RL that demands sufficient data coverage. These merits of the proposed method are demonstrated in numerical simulation.
<div id='section'>Paperid: <span id='pid'>1528, <a href='https://arxiv.org/pdf/2403.11728.pdf' target='_blank'>https://arxiv.org/pdf/2403.11728.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Johannes Fischer, Kevin RÃ¶sch, Martin Lauer, Christoph Stiller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11728">PITA: Physics-Informed Trajectory Autoencoder</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Validating robotic systems in safety-critical appli-cations requires testing in many scenarios including rare edgecases that are unlikely to occur, requiring to complement real-world testing with testing in simulation. Generative models canbe used to augment real-world datasets with generated data toproduce edge case scenarios by sampling in a learned latentspace. Autoencoders can learn said latent representation for aspecific domain by learning to reconstruct the input data froma lower-dimensional intermediate representation. However, theresulting trajectories are not necessarily physically plausible, butinstead typically contain noise that is not present in the inputtrajectory. To resolve this issue, we propose the novel Physics-Informed Trajectory Autoencoder (PITA) architecture, whichincorporates a physical dynamics model into the loss functionof the autoencoder. This results in smooth trajectories that notonly reconstruct the input trajectory but also adhere to thephysical model. We evaluate PITA on a real-world dataset ofvehicle trajectories and compare its performance to a normalautoencoder and a state-of-the-art action-space autoencoder.
<div id='section'>Paperid: <span id='pid'>1529, <a href='https://arxiv.org/pdf/2403.08589.pdf' target='_blank'>https://arxiv.org/pdf/2403.08589.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gianmarco Guglielmo, Andrea Montessori, Jean-Michel Tucny, Michele La Rocca, Pietro Prestininzi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.08589">Can physical information aid the generalization ability of Neural Networks for hydraulic modeling?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Application of Neural Networks to river hydraulics is fledgling, despite the field suffering from data scarcity, a challenge for machine learning techniques. Consequently, many purely data-driven Neural Networks proved to lack predictive capabilities. In this work, we propose to mitigate such problem by introducing physical information into the training phase. The idea is borrowed from Physics-Informed Neural Networks which have been recently proposed in other contexts. Physics-Informed Neural Networks embed physical information in the form of the residual of the Partial Differential Equations (PDEs) governing the phenomenon and, as such, are conceived as neural solvers, i.e. an alternative to traditional numerical solvers. Such approach is seldom suitable for environmental hydraulics, where epistemic uncertainties are large, and computing residuals of PDEs exhibits difficulties similar to those faced by classical numerical methods. Instead, we envisaged the employment of Neural Networks as neural operators, featuring physical constraints formulated without resorting to PDEs. The proposed novel methodology shares similarities with data augmentation and regularization. We show that incorporating such soft physical information can improve predictive capabilities.
<div id='section'>Paperid: <span id='pid'>1530, <a href='https://arxiv.org/pdf/2403.04576.pdf' target='_blank'>https://arxiv.org/pdf/2403.04576.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Veronika TrÃ¡vnÃ­kovÃ¡, Daniel Wolff, Nico Dirkes, Stefanie Elgeti, Eric von Lieres, Marek Behr
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.04576">A Model Hierarchy for Predicting the Flow in Stirred Tanks with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper explores the potential of Physics-Informed Neural Networks (PINNs) to serve as Reduced Order Models (ROMs) for simulating the flow field within stirred tank reactors (STRs). We solve the two-dimensional stationary Navier-Stokes equations within a geometrically intricate domain and explore methodologies that allow us to integrate additional physical insights into the model. These approaches include imposing the Dirichlet boundary conditions (BCs) strongly and employing domain decomposition (DD), with both overlapping and non-overlapping subdomains. We adapt the Extended Physics-Informed Neural Network (XPINN) approach to solve different sets of equations in distinct subdomains based on the diverse flow characteristics present in each region. Our exploration results in a hierarchy of models spanning various levels of complexity, where the best models exhibit l1 prediction errors of less than 1% for both pressure and velocity. To illustrate the reproducibility of our approach, we track the errors over repeated independent training runs of the best identified model and show its reliability. Subsequently, by incorporating the stirring rate as a parametric input, we develop a fast-to-evaluate model of the flow capable of interpolating across a wide range of Reynolds numbers. Although we exclusively restrict ourselves to STRs in this work, we conclude that the steps taken to obtain the presented model hierarchy can be transferred to other applications.
<div id='section'>Paperid: <span id='pid'>1531, <a href='https://arxiv.org/pdf/2403.03444.pdf' target='_blank'>https://arxiv.org/pdf/2403.03444.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Pensoneault, Xueyu Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.03444">Uncertainty quantification for deeponets with ensemble kalman inversion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, operator learning, particularly the DeepONet, has received much attention for efficiently learning complex mappings between input and output functions across diverse fields. However, in practical scenarios with limited and noisy data, accessing the uncertainty in DeepONet predictions becomes essential, especially in mission-critical or safety-critical applications. Existing methods, either computationally intensive or yielding unsatisfactory uncertainty quantification, leave room for developing efficient and informative uncertainty quantification (UQ) techniques tailored for DeepONets. In this work, we proposed a novel inference approach for efficient UQ for operator learning by harnessing the power of the Ensemble Kalman Inversion (EKI) approach. EKI, known for its derivative-free, noise-robust, and highly parallelizable feature, has demonstrated its advantages for UQ for physics-informed neural networks [28]. Our innovative application of EKI enables us to efficiently train ensembles of DeepONets while obtaining informative uncertainty estimates for the output of interest. We deploy a mini-batch variant of EKI to accommodate larger datasets, mitigating the computational demand due to large datasets during the training stage. Furthermore, we introduce a heuristic method to estimate the artificial dynamics covariance, thereby improving our uncertainty estimates. Finally, we demonstrate the effectiveness and versatility of our proposed methodology across various benchmark problems, showcasing its potential to address the pressing challenges of uncertainty quantification in DeepONets, especially for practical applications with limited and noisy data.
<div id='section'>Paperid: <span id='pid'>1532, <a href='https://arxiv.org/pdf/2403.01692.pdf' target='_blank'>https://arxiv.org/pdf/2403.01692.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shulei Ni, Yisheng Qiu, Yunchun Chen, Zihao Song, Hao Chen, Xuejian Jiang, Huaxi Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01692">PI-AstroDeconv: A Physics-Informed Unsupervised Learning Method for Astronomical Image Deconvolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the imaging process of an astronomical telescope, the deconvolution of its beam or Point Spread Function (PSF) is a crucial task. However, deconvolution presents a classical and challenging inverse computation problem. In scenarios where the beam or PSF is complex or inaccurately measured, such as in interferometric arrays and certain radio telescopes, the resultant blurry images are often challenging to interpret visually or analyze using traditional physical detection methods. We argue that traditional methods frequently lack specific prior knowledge, thereby leading to suboptimal performance. To address this issue and achieve image deconvolution and reconstruction, we propose an unsupervised network architecture that incorporates prior physical information. The network adopts an encoder-decoder structure while leveraging the telescope's PSF as prior knowledge. During network training, we introduced accelerated Fast Fourier Transform (FFT) convolution to enable efficient processing of high-resolution input images and PSFs. We explored various classic regression networks, including autoencoder (AE) and U-Net, and conducted a comprehensive performance evaluation through comparative analysis.
<div id='section'>Paperid: <span id='pid'>1533, <a href='https://arxiv.org/pdf/2403.00177.pdf' target='_blank'>https://arxiv.org/pdf/2403.00177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keying Kuang, Frances Dean, Jack B. Jedlicki, David Ouyang, Anthony Philippakis, David Sontag, Ahmed M. Alaa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.00177">Med-Real2Sim: Non-Invasive Medical Digital Twins using Physics-Informed Self-Supervised Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A digital twin is a virtual replica of a real-world physical phenomena that uses mathematical modeling to characterize and simulate its defining features. By constructing digital twins for disease processes, we can perform in-silico simulations that mimic patients' health conditions and counterfactual outcomes under hypothetical interventions in a virtual setting. This eliminates the need for invasive procedures or uncertain treatment decisions. In this paper, we propose a method to identify digital twin model parameters using only noninvasive patient health data. We approach the digital twin modeling as a composite inverse problem, and observe that its structure resembles pretraining and finetuning in self-supervised learning (SSL). Leveraging this, we introduce a physics-informed SSL algorithm that initially pretrains a neural network on the pretext task of learning a differentiable simulator of a physiological process. Subsequently, the model is trained to reconstruct physiological measurements from noninvasive modalities while being constrained by the physical equations learned in pretraining. We apply our method to identify digital twins of cardiac hemodynamics using noninvasive echocardiogram videos, and demonstrate its utility in unsupervised disease detection and in-silico clinical trials.
<div id='section'>Paperid: <span id='pid'>1534, <a href='https://arxiv.org/pdf/2402.13588.pdf' target='_blank'>https://arxiv.org/pdf/2402.13588.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liqiu Dong, Marta Zagorowska, Tong Liu, Alex Durkin, Mehmet MercangÃ¶z
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.13588">PI-CoF: A Bilevel Optimization Framework for Solving Active Learning Problems using Physics-Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics informed neural networks (PINNs) have recently been proposed as surrogate models for solving process optimization problems. However, in an active learning setting collecting enough data for reliably training PINNs poses a challenge. This study proposes a broadly applicable method for incorporating physics information into existing machine learning (ML) models of any type. The proposed method - referred to as PI-CoF for Physics-Informed Correction Factors - introduces additive or multiplicative correction factors for pointwise inference, which are identified by solving a regularized unconstrained optimization problem for reconciliation of physics information and ML model predictions. When ML models are used in an optimization context, using the proposed approach translates into a bilevel optimization problem, where the reconciliation problem is solved as an inner problem each time before evaluating the objective and constraint functions of the outer problem. The utility of the proposed approach is demonstrated through a numerical example, emphasizing constraint satisfaction in a safe Bayesian optimization (BO) setting. Furthermore, a simulation study is carried out by using PI-CoF for the real-time optimization of a fuel cell system. The results show reduced fuel consumption and better reference tracking performance when using the proposed PI-CoF approach in comparison to a constrained BO algorithm not using physics information.
<div id='section'>Paperid: <span id='pid'>1535, <a href='https://arxiv.org/pdf/2402.13412.pdf' target='_blank'>https://arxiv.org/pdf/2402.13412.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nithin Chalapathi, Yiheng Du, Aditi Krishnapriyan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.13412">Scaling physics-informed hard constraints with mixture-of-experts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Imposing known physical constraints, such as conservation laws, during neural network training introduces an inductive bias that can improve accuracy, reliability, convergence, and data efficiency for modeling physical dynamics. While such constraints can be softly imposed via loss function penalties, recent advancements in differentiable physics and optimization improve performance by incorporating PDE-constrained optimization as individual layers in neural networks. This enables a stricter adherence to physical constraints. However, imposing hard constraints significantly increases computational and memory costs, especially for complex dynamical systems. This is because it requires solving an optimization problem over a large number of points in a mesh, representing spatial and temporal discretizations, which greatly increases the complexity of the constraint. To address this challenge, we develop a scalable approach to enforce hard physical constraints using Mixture-of-Experts (MoE), which can be used with any neural network architecture. Our approach imposes the constraint over smaller decomposed domains, each of which is solved by an "expert" through differentiable optimization. During training, each expert independently performs a localized backpropagation step by leveraging the implicit function theorem; the independence of each expert allows for parallelization across multiple GPUs. Compared to standard differentiable optimization, our scalable approach achieves greater accuracy in the neural PDE solver setting for predicting the dynamics of challenging non-linear systems. We also improve training stability and require significantly less computation time during both training and inference stages.
<div id='section'>Paperid: <span id='pid'>1536, <a href='https://arxiv.org/pdf/2402.10747.pdf' target='_blank'>https://arxiv.org/pdf/2402.10747.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peter PavlÃ­k, Martin VÃ½boh, Anna Bou Ezzeddine, Viera RozinajovÃ¡
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10747">Fully Differentiable Lagrangian Convolutional Neural Network for Physics-Informed Precipitation Nowcasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a convolutional neural network model for precipitation nowcasting that combines data-driven learning with physics-informed domain knowledge. We propose LUPIN, a Lagrangian Double U-Net for Physics-Informed Nowcasting, that draws from existing extrapolation-based nowcasting methods. It consists of a U-Net that dynamically produces mesoscale advection motion fields, a differentiable semi-Lagrangian extrapolation operator, and an advection-free U-Net capturing the growth and decay of precipitation over time. Using our approach, we successfully implement the Lagrangian convolutional neural network for precipitation nowcasting in a fully differentiable and GPU-accelerated manner. This allows for end-to-end training and inference, including the data-driven Lagrangian coordinate system transformation of the data at runtime. We evaluate the model and compare it with other related AI-based models both quantitatively and qualitatively in an extreme event case study. Based on our evaluation, LUPIN matches and even exceeds the performance of the chosen benchmarks, opening the door for other Lagrangian machine learning models.
<div id='section'>Paperid: <span id='pid'>1537, <a href='https://arxiv.org/pdf/2402.10649.pdf' target='_blank'>https://arxiv.org/pdf/2402.10649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kourosh Parand, Aida Pakniyat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.10649">Hermite Neural Network Simulation for Solving the 2D Schrodinger Equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Schrodinger equation is a mathematical equation describing the wave function's behavior in a quantum-mechanical system. It is a partial differential equation that provides valuable insights into the fundamental principles of quantum mechanics. In this paper, the aim was to solve the Schrodinger equation with sufficient accuracy by using a mixture of neural networks with the collocation method base Hermite functions. Initially, the Hermite functions roots were employed as collocation points, enhancing the efficiency of the solution. The Schrodinger equation is defined in an infinite domain, the use of Hermite functions as activation functions resulted in excellent precision. Finally, the proposed method was simulated using MATLAB's Simulink tool. The results were then compared with those obtained using Physics-informed neural networks and the presented method.
<div id='section'>Paperid: <span id='pid'>1538, <a href='https://arxiv.org/pdf/2402.02667.pdf' target='_blank'>https://arxiv.org/pdf/2402.02667.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guangtao Zhang, Jiani Lin, Qijia Zhai, Huiyu Yang, Xujun Chen, Xiaoning Zheng, Ieng Tak Leong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.02667">A Priori Error Estimation of Physics-Informed Neural Networks Solving Allen--Cahn and Cahn--Hilliard Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper aims to analyze errors in the implementation of the Physics-Informed Neural Network (PINN) for solving the Allen--Cahn (AC) and Cahn--Hilliard (CH) partial differential equations (PDEs). The accuracy of PINN is still challenged when dealing with strongly non-linear and higher-order time-varying PDEs. To address this issue, we introduce a stable and bounded self-adaptive weighting scheme known as Residuals-RAE, which ensures fair training and effectively captures the solution. By incorporating this new training loss function, we conduct numerical experiments on 1D and 2D AC and CH systems to validate our theoretical findings. Our theoretical analysis demonstrates that feedforward neural networks with two hidden layers and tanh activation function effectively bound the PINN approximation errors for the solution field, temporal derivative, and nonlinear term of the AC and CH equations by the training loss and number of collocation points.
<div id='section'>Paperid: <span id='pid'>1539, <a href='https://arxiv.org/pdf/2402.00152.pdf' target='_blank'>https://arxiv.org/pdf/2402.00152.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yahong Yang, Juncai He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00152">Deeper or Wider: A Perspective from Optimal Generalization Error with Sobolev Loss</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constructing the architecture of a neural network is a challenging pursuit for the machine learning community, and the dilemma of whether to go deeper or wider remains a persistent question. This paper explores a comparison between deeper neural networks (DeNNs) with a flexible number of layers and wider neural networks (WeNNs) with limited hidden layers, focusing on their optimal generalization error in Sobolev losses. Analytical investigations reveal that the architecture of a neural network can be significantly influenced by various factors, including the number of sample points, parameters within the neural networks, and the regularity of the loss function. Specifically, a higher number of parameters tends to favor WeNNs, while an increased number of sample points and greater regularity in the loss function lean towards the adoption of DeNNs. We ultimately apply this theory to address partial differential equations using deep Ritz and physics-informed neural network (PINN) methods, guiding the design of neural networks.
<div id='section'>Paperid: <span id='pid'>1540, <a href='https://arxiv.org/pdf/2401.11836.pdf' target='_blank'>https://arxiv.org/pdf/2401.11836.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiqing Wang, Kaidi Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.11836">Privacy-Preserving Data Fusion for Traffic State Estimation: A Vertical Federated Learning Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a privacy-preserving data fusion method for traffic state estimation (TSE). Unlike existing works that assume all data sources to be accessible by a single trusted party, we explicitly address data privacy concerns that arise in the collaboration and data sharing between multiple data owners, such as municipal authorities (MAs) and mobility providers (MPs). To this end, we propose a novel vertical federated learning (FL) approach, FedTSE, that enables multiple data owners to collaboratively train and apply a TSE model without having to exchange their private data. To enhance the applicability of the proposed FedTSE in common TSE scenarios with limited availability of ground-truth data, we further propose a privacy-preserving physics-informed FL approach, i.e., FedTSE-PI, that integrates traffic models into FL. Real-world data validation shows that the proposed methods can protect privacy while yielding similar accuracy to the oracle method without privacy considerations.
<div id='section'>Paperid: <span id='pid'>1541, <a href='https://arxiv.org/pdf/2401.11217.pdf' target='_blank'>https://arxiv.org/pdf/2401.11217.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ece S. Koksal, Erdal Aydin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.11217">A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constructing first principles models is a challenging task for nonlinear and complex systems such as a wastewater treatment unit. In recent years, data-driven models are widely used to overcome the complexity. However, they often suffer from issues such as missing, low quality or noisy data. Transfer learning is a solution for this issue where knowledge from another task is transferred to target one to increase the prediction performance. In this work, the objective is increasing the prediction performance of an industrial wastewater treatment plant by transferring the knowledge of (i) an open-source simulation model that captures the underlying physics of the process, albeit with dissimilarities to the target plant, (ii) another industrial plant characterized by noisy and limited data but located in the same refinery, and (iii) the model in (ii) and making the objective function of the training problem physics informed where the physics information derived from the open-source model in (ii). The results have shown that test and validation performance are improved up to 27% and 59%, respectively.
<div id='section'>Paperid: <span id='pid'>1542, <a href='https://arxiv.org/pdf/2401.08684.pdf' target='_blank'>https://arxiv.org/pdf/2401.08684.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saeed Saviz Naeini, Reda Snaiki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08684">A Physics-informed machine learning model for time-dependent wave runup prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wave runup is a critical factor affecting coastal flooding, shoreline changes, and damage to coastal structures. Climate change is also expected to amplify wave runup's impact on coastal areas. Therefore, fast and accurate wave runup estimation is essential for effective coastal engineering design and management. However, predicting the time-dependent wave runup is challenging due to the intrinsic nonlinearities and non-stationarity of the process, even with the use of the most advanced machine learning techniques. In this study, a physics-informed machine learning-based approach is proposed to efficiently and accurately simulate time-series wave runup. The methodology combines the computational efficiency of the Surfbeat (XBSB) mode with the accuracy of the nonhydrostatic (XBNH) mode of the XBeach model. Specifically, a conditional generative adversarial network (cGAN) is used to map the image representation of wave runup from XBSB to the corresponding image from XBNH. These images are generated by first converting wave runup signals into time-frequency scalograms and then transforming them into image representations. The cGAN model achieves improved performance in image-to-image mapping tasks by incorporating physics-based knowledge from XBSB. After training the model, the high-fidelity XBNH-based scalograms can be predicted, which are then employed to reconstruct the time-series wave runup using the inverse wavelet transform. The simulation results underscore the efficiency and robustness of the proposed model in predicting wave runup, suggesting its potential value for applications in risk assessment and management.
<div id='section'>Paperid: <span id='pid'>1543, <a href='https://arxiv.org/pdf/2401.07331.pdf' target='_blank'>https://arxiv.org/pdf/2401.07331.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ehsan Naghavi, Haifeng Wang, Lei Fan, Jenny S. Choy, Ghassan Kassab, Seungik Baek, Lik-Chuan Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.07331">Rapid Estimation of Left Ventricular Contractility with a Physics-Informed Neural Network Inverse Modeling Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-based computer models based on numerical solution of the governing equations generally cannot make rapid predictions, which in turn, limits their applications in the clinic. To address this issue, we developed a physics-informed neural network (PINN) model that encodes the physics of a closed-loop blood circulation system embedding a left ventricle (LV). The PINN model is trained to satisfy a system of ordinary differential equations (ODEs) associated with a lumped parameter description of the circulatory system. The model predictions have a maximum error of less than 5% when compared to those obtained by solving the ODEs numerically. An inverse modeling approach using the PINN model is also developed to rapidly estimate model parameters (in $\sim$ 3 mins) from single-beat LV pressure and volume waveforms. Using synthetic LV pressure and volume waveforms generated by the PINN model with different model parameter values, we show that the inverse modeling approach can recover the corresponding ground truth values, which suggests that the model parameters are unique. The PINN inverse modeling approach is then applied to estimate LV contractility indexed by the end-systolic elastance $E_{es}$ using waveforms acquired from 11 swine models, including waveforms acquired before and after administration of dobutamine (an inotropic agent) in 3 animals. The estimated $E_{es}$ is about 58% to 284% higher for the data associated with dobutamine compared to those without, which implies that this approach can be used to estimate LV contractility using single-beat measurements. The PINN inverse modeling can potentially be used in the clinic to simultaneously estimate LV contractility and other physiological parameters from single-beat measurements.
<div id='section'>Paperid: <span id='pid'>1544, <a href='https://arxiv.org/pdf/2401.04378.pdf' target='_blank'>https://arxiv.org/pdf/2401.04378.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zan Yu, Lianzeng Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04378">Computing the Gerber-Shiu function with interest and a constant dividend barrier by physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a new efficient method for calculating the Gerber-Shiu discounted penalty function. Generally, the Gerber-Shiu function usually satisfies a class of integro-differential equation. We introduce the physics-informed neural networks (PINN) which embed a differential equation into the loss of the neural network using automatic differentiation. In addition, PINN is more free to set boundary conditions and does not rely on the determination of the initial value. This gives us an idea to calculate more general Gerber-Shiu functions. Numerical examples are provided to illustrate the very good performance of our approximation.
<div id='section'>Paperid: <span id='pid'>1545, <a href='https://arxiv.org/pdf/2401.01288.pdf' target='_blank'>https://arxiv.org/pdf/2401.01288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ethan Zhu, Haijian Sun, Mingyue Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01288">Physics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Channel modeling is fundamental in advancing wireless systems and has thus attracted considerable research focus. Recent trends have seen a growing reliance on data-driven techniques to facilitate the modeling process and yield accurate channel predictions. In this work, we first provide a concise overview of data-driven channel modeling methods, highlighting their limitations. Subsequently, we introduce the concept and advantages of physics-informed neural network (PINN)-based modeling and a summary of recent contributions in this area. Our findings demonstrate that PINN-based approaches in channel modeling exhibit promising attributes such as generalizability, interpretability, and robustness. We offer a comprehensive architecture for PINN methodology, designed to inform and inspire future model development. A case-study of our recent work on precise indoor channel prediction with semantic segmentation and deep learning is presented. The study concludes by addressing the challenges faced and suggesting potential research directions in this field.
<div id='section'>Paperid: <span id='pid'>1546, <a href='https://arxiv.org/pdf/2312.17738.pdf' target='_blank'>https://arxiv.org/pdf/2312.17738.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Quang-Ha Ngo, Bang L. H. Nguyen, Tuyen V. Vu, Jianhua Zhang, Tuan Ngo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.17738">Physics-informed Graphical Neural Network for Power System State Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State estimation is highly critical for accurately observing the dynamic behavior of the power grids and minimizing risks from cyber threats. However, existing state estimation methods encounter challenges in accurately capturing power system dynamics, primarily because of limitations in encoding the grid topology and sparse measurements. This paper proposes a physics-informed graphical learning state estimation method to address these limitations by leveraging both domain physical knowledge and a graph neural network (GNN). We employ a GNN architecture that can handle the graph-structured data of power systems more effectively than traditional data-driven methods. The physics-based knowledge is constructed from the branch current formulation, making the approach adaptable to both transmission and distribution systems. The validation results of three IEEE test systems show that the proposed method can achieve lower mean square error more than 20% than the conventional methods.
<div id='section'>Paperid: <span id='pid'>1547, <a href='https://arxiv.org/pdf/2312.13212.pdf' target='_blank'>https://arxiv.org/pdf/2312.13212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Takuya Kurihana, Kyongmin Yeo, Daniela Szwarcman, Bruce Elmegreen, Karthik Mukkavilli, Johannes Schmude, Levente Klein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.13212">A 3D super-resolution of wind fields via physics-informed pixel-wise self-attention generative adversarial network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To mitigate global warming, greenhouse gas sources need to be resolved at a high spatial resolution and monitored in time to ensure the reduction and ultimately elimination of the pollution source. However, the complexity of computation in resolving high-resolution wind fields left the simulations impractical to test different time lengths and model configurations. This study presents a preliminary development of a physics-informed super-resolution (SR) generative adversarial network (GAN) that super-resolves the three-dimensional (3D) low-resolution wind fields by upscaling x9 times. We develop a pixel-wise self-attention (PWA) module that learns 3D weather dynamics via a self-attention computation followed by a 2D convolution. We also employ a loss term that regularizes the self-attention map during pretraining, capturing the vertical convection process from input wind data. The new PWA SR-GAN shows the high-fidelity super-resolved 3D wind data, learns a wind structure at the high-frequency domain, and reduces the computational cost of a high-resolution wind simulation by x89.7 times.
<div id='section'>Paperid: <span id='pid'>1548, <a href='https://arxiv.org/pdf/2312.08650.pdf' target='_blank'>https://arxiv.org/pdf/2312.08650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kawisorn Kamtue, Jose M. F. Moura, Orathai Sangpetch, Paulo Garcia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.08650">PhyOT: Physics-informed object tracking in surveillance cameras</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While deep learning has been very successful in computer vision, real world operating conditions such as lighting variation, background clutter, or occlusion hinder its accuracy across several tasks. Prior work has shown that hybrid models -- combining neural networks and heuristics/algorithms -- can outperform vanilla deep learning for several computer vision tasks, such as classification or tracking. We consider the case of object tracking, and evaluate a hybrid model (PhyOT) that conceptualizes deep neural networks as ``sensors'' in a Kalman filter setup, where prior knowledge, in the form of Newtonian laws of motion, is used to fuse sensor observations and to perform improved estimations. Our experiments combine three neural networks, performing position, indirect velocity and acceleration estimation, respectively, and evaluate such a formulation on two benchmark datasets: a warehouse security camera dataset that we collected and annotated and a traffic camera open dataset. Results suggest that our PhyOT can track objects in extreme conditions that the state-of-the-art deep neural networks fail while its performance in general cases does not degrade significantly from that of existing deep learning approaches. Results also suggest that our PhyOT components are generalizable and transferable.
<div id='section'>Paperid: <span id='pid'>1549, <a href='https://arxiv.org/pdf/2312.06711.pdf' target='_blank'>https://arxiv.org/pdf/2312.06711.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashish Dhiman, Yibei Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.06711">Physics Informed Neural Network for Option Pricing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We apply a physics-informed deep-learning approach the PINN approach to the Black-Scholes equation for pricing American and European options. We test our approach on both simulated as well as real market data, compare it to analytical/numerical benchmarks. Our model is able to accurately capture the price behaviour on simulation data, while also exhibiting reasonable performance for market data. We also experiment with the architecture and learning process of our PINN model to provide more understanding of convergence and stability issues that impact performance.
<div id='section'>Paperid: <span id='pid'>1550, <a href='https://arxiv.org/pdf/2312.05891.pdf' target='_blank'>https://arxiv.org/pdf/2312.05891.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng Chang, Zhouping Xin, Tieyong Zeng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.05891">A conservative hybrid physics-informed neural network method for Maxwell-AmpÃ¨re-Nernst-Planck equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Maxwell-AmpÃ¨re-Nernst-Planck (MANP) equations were recently proposed to model the dynamics of charged particles. In this study, we enhance a numerical algorithm of this system with deep learning tools. The proposed hybrid algorithm provides an automated means to determine a proper approximation for the dummy variables, which can otherwise only be obtained through massive numerical tests. In addition, the original method is validated for 2-dimensional problems. However, when the spatial dimension is one, the original curl-free relaxation component is inapplicable, and the approximation formula for dummy variables, which works well in a 2-dimensional scenario, fails to provide a reasonable output in the 1-dimensional case. The proposed method can be readily generalised to cases with one spatial dimension. Experiments show numerical stability and good convergence to the steady-state solution obtained from Poisson-Boltzmann type equations in the 1-dimensional case. The experiments conducted in the 2-dimensional case indicate that the proposed method preserves the conservation properties.
<div id='section'>Paperid: <span id='pid'>1551, <a href='https://arxiv.org/pdf/2312.03496.pdf' target='_blank'>https://arxiv.org/pdf/2312.03496.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kent-Andre Mardal, Jarle Sogn, Marius Zeinhofer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.03496">Variational Formulations of the Strong Formulation -- Forward and Inverse Modeling using Isogeometric Analysis and Physics-Informed Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recently introduced Physics-Informed Neural Networks (PINNs) have popularized least squares formulations of both forward and inverse problems involving partial differential equations (PDEs) in strong form. We employ both Isogeometric Analysis and Physics-Informed Networks.
<div id='section'>Paperid: <span id='pid'>1552, <a href='https://arxiv.org/pdf/2312.02871.pdf' target='_blank'>https://arxiv.org/pdf/2312.02871.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danyal Rehman, John H. Lienhard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.02871">Attention-enhanced neural differential equations for physics-informed deep learning of ion transport</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Species transport models typically combine partial differential equations (PDEs) with relations from hindered transport theory to quantify electromigrative, convective, and diffusive transport through complex nanoporous systems; however, these formulations are frequently substantial simplifications of the governing dynamics, leading to the poor generalization performance of PDE-based models. Given the growing interest in deep learning methods for the physical sciences, we develop a machine learning-based approach to characterize ion transport across nanoporous membranes. Our proposed framework centers around attention-enhanced neural differential equations that incorporate electroneutrality-based inductive biases to improve generalization performance relative to conventional PDE-based methods. In addition, we study the role of the attention mechanism in illuminating physically-meaningful ion-pairing relationships across diverse mixture compositions. Further, we investigate the importance of pre-training on simulated data from PDE-based models, as well as the performance benefits from hard vs. soft inductive biases. Our results indicate that physics-informed deep learning solutions can outperform their classical PDE-based counterparts and provide promising avenues for modelling complex transport phenomena across diverse applications.
<div id='section'>Paperid: <span id='pid'>1553, <a href='https://arxiv.org/pdf/2311.14931.pdf' target='_blank'>https://arxiv.org/pdf/2311.14931.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wanzhou Lei, Pavlos Protopapas, Joy Parikh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.14931">One-Shot Transfer Learning for Nonlinear ODEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a generalizable approach that combines perturbation method and one-shot transfer learning to solve nonlinear ODEs with a single polynomial term, using Physics-Informed Neural Networks (PINNs). Our method transforms non-linear ODEs into linear ODE systems, trains a PINN across varied conditions, and offers a closed-form solution for new instances within the same non-linear ODE class. We demonstrate the effectiveness of this approach on the Duffing equation and suggest its applicability to similarly structured PDEs and ODE systems.
<div id='section'>Paperid: <span id='pid'>1554, <a href='https://arxiv.org/pdf/2311.14828.pdf' target='_blank'>https://arxiv.org/pdf/2311.14828.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thomas Baldwin-McDonald, Mauricio A. Ãlvarez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.14828">Deep Latent Force Models: ODE-based Process Convolutions for Bayesian Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modelling the behaviour of highly nonlinear dynamical systems with robust uncertainty quantification is a challenging task which typically requires approaches specifically designed to address the problem at hand. We introduce a domain-agnostic model to address this issue termed the deep latent force model (DLFM), a deep Gaussian process with physics-informed kernels at each layer, derived from ordinary differential equations using the framework of process convolutions. Two distinct formulations of the DLFM are presented which utilise weight-space and variational inducing points-based Gaussian process approximations, both of which are amenable to doubly stochastic variational inference. We present empirical evidence of the capability of the DLFM to capture the dynamics present in highly nonlinear real-world multi-output time series data. Additionally, we find that the DLFM is capable of achieving comparable performance to a range of non-physics-informed probabilistic models on benchmark univariate regression tasks. We also empirically assess the negative impact of the inducing points framework on the extrapolation capabilities of LFM-based models.
<div id='section'>Paperid: <span id='pid'>1555, <a href='https://arxiv.org/pdf/2311.14131.pdf' target='_blank'>https://arxiv.org/pdf/2311.14131.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elsa Cardoso-Bihlo, Alex Bihlo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.14131">Exactly conservative physics-informed neural networks and deep operator networks for dynamical systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a method for training exactly conservative physics-informed neural networks and physics-informed deep operator networks for dynamical systems. The method employs a projection-based technique that maps a candidate solution learned by the neural network solver for any given dynamical system possessing at least one first integral onto an invariant manifold. We illustrate that exactly conservative physics-informed neural network solvers and physics-informed deep operator networks for dynamical systems vastly outperform their non-conservative counterparts for several real-world problems from the mathematical sciences.
<div id='section'>Paperid: <span id='pid'>1556, <a href='https://arxiv.org/pdf/2311.09944.pdf' target='_blank'>https://arxiv.org/pdf/2311.09944.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Caterina Millevoi, Damiano Pasetto, Massimiliano Ferronato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.09944">A Physics-Informed Neural Network approach for compartmental epidemiological models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Compartmental models provide simple and efficient tools to analyze the relevant transmission processes during an outbreak, to produce short-term forecasts or transmission scenarios, and to assess the impact of vaccination campaigns. However, their calibration is not straightforward, since many factors contribute to the rapid change of the transmission dynamics during an epidemic. For example, there might be changes in the individual awareness, the imposition of non-pharmacological interventions and the emergence of new variants. As a consequence, model parameters such as the transmission rate are doomed to change in time, making their assessment more challenging. Here, we propose to use Physics-Informed Neural Networks (PINNs) to track the temporal changes in the model parameters and provide an estimate of the model state variables. PINNs recently gained attention in many engineering applications thanks to their ability to consider both the information from data (typically uncertain) and the governing equations of the system. The ability of PINNs to identify unknown model parameters makes them particularly suitable to solve ill-posed inverse problems, such as those arising in the application of epidemiological models. Here, we develop a reduced-split approach for the implementation of PINNs to estimate the temporal changes in the state variables and transmission rate of an epidemic based on the SIR model equation and infectious data. The main idea is to split the training first on the epidemiological data, and then on the residual of the system equations. The proposed method is applied to five synthetic test cases and two real scenarios reproducing the first months of the COVID-19 Italian pandemic. Our results show that the split implementation of PINNs outperforms the standard approach in terms of accuracy (up to one order of magnitude) and computational times (speed up of 20%).
<div id='section'>Paperid: <span id='pid'>1557, <a href='https://arxiv.org/pdf/2311.03746.pdf' target='_blank'>https://arxiv.org/pdf/2311.03746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Deok-Kyu Jang, Hyea Hyun Kim, Kyungsoo Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.03746">Enhanced physics-informed neural networks with domain scaling and residual correction methods for multi-frequency elliptic problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, neural network approximation methods are developed for elliptic partial differential equations with multi-frequency solutions. Neural network work approximation methods have advantages over classical approaches in that they can be applied without much concerns on the form of the differential equations or the shape or dimension of the problem domain. When applied to problems with multi-frequency solutions, the performance and accuracy of neural network approximation methods are strongly affected by the contrast of the high- and low-frequency parts in the solutions. To address this issue, domain scaling and residual correction methods are proposed. The efficiency and accuracy of the proposed methods are demonstrated for multi-frequency model problems.
<div id='section'>Paperid: <span id='pid'>1558, <a href='https://arxiv.org/pdf/2311.01708.pdf' target='_blank'>https://arxiv.org/pdf/2311.01708.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruisong Gao, Min Yang, Jin Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.01708">Physics-Informed Generator-Encoder Adversarial Networks with Latent Space Matching for Stochastic Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a new class of physics-informed neural networks, called Physics-Informed Generator-Encoder Adversarial Networks, to effectively address the challenges posed by forward, inverse, and mixed problems in stochastic differential equations. In these scenarios, while the governing equations are known, the available data consist of only a limited set of snapshots for system parameters. Our model consists of two key components: the generator and the encoder, both updated alternately by gradient descent. In contrast to previous approaches of directly matching the approximated solutions with real snapshots, we employ an indirect matching that operates within the lower-dimensional latent feature space. This method circumvents challenges associated with high-dimensional inputs and complex data distributions, while yielding more accurate solutions compared to existing neural network solvers. In addition, the approach also mitigates the training instability issues encountered in previous adversarial frameworks in an efficient manner. Numerical results provide compelling evidence of the effectiveness of the proposed method in solving different types of stochastic differential equations.
<div id='section'>Paperid: <span id='pid'>1559, <a href='https://arxiv.org/pdf/2310.20308.pdf' target='_blank'>https://arxiv.org/pdf/2310.20308.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kerem Ciftci, Klaus Hackl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.20308">A physics-informed GAN Framework based on Model-free Data-Driven Computational Mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model-free data-driven computational mechanics, first proposed by Kirchdoerfer and Ortiz, replace phenomenological models with numerical simulations based on sample data sets in strain-stress space. In this study, we integrate this paradigm within physics-informed generative adversarial networks (GANs). We enhance the conventional physics-informed neural network framework by implementing the principles of data-driven computational mechanics into GANs. Specifically, the generator is informed by physical constraints, while the discriminator utilizes the closest strain-stress data to discern the authenticity of the generator's output. This combined approach presents a new formalism to harness data-driven mechanics and deep learning to simulate and predict mechanical behaviors.
<div id='section'>Paperid: <span id='pid'>1560, <a href='https://arxiv.org/pdf/2310.17545.pdf' target='_blank'>https://arxiv.org/pdf/2310.17545.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>William Therrien, Olivier Lecompte, Alexandre Girard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.17545">Using Buckingham's $Ï$ Theorem for Multi-System Learning Transfer: a Case-study with 3 Vehicles Sharing a Database</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many advanced driver assistance schemes or autonomous vehicle controllers are based on a motion model of the vehicle behavior, i.e., a function predicting how the vehicle will react to a given control input. Data-driven models, based on experimental or simulated data, are very useful, especially for vehicles difficult to model analytically, for instance, ground vehicles for which the ground-tire interaction is hard to model from first principles. However, learning schemes are limited by the difficulty of collecting large amounts of experimental data or having to rely on high-fidelity simulations. This paper explores the potential of an approach that uses dimensionless numbers based on Buckingham's $Ï$ theorem to improve the efficiency of data for learning models, with the goal of facilitating knowledge sharing between similar systems. A case study using car-like vehicles compares traditional and dimensionless models on simulated and experimental data to validate the benefits of the new dimensionless learning approach. Prediction accuracy improvements with the dimensionless scheme when using a shared database, that is, predicting the motion of a vehicle based on data from various different vehicles was found to be 480\% more accurate for predicting a simple no-slip maneuver based on simulated data and 11\% more accurate to predict a highly dynamic braking maneuver based on experimental data. A modified physics-informed learning scheme with hand-crafted dimensionless features was also shown to increase the improvement to precision gains of 917\% and 28\% respectively. A comparative study also shows that using Buckingham's $Ï$ theorem is a much more effective preprocessing step for this task than principal component analysis (PCA) or simply normalizing the data.
<div id='section'>Paperid: <span id='pid'>1561, <a href='https://arxiv.org/pdf/2310.14948.pdf' target='_blank'>https://arxiv.org/pdf/2310.14948.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marien Chenaud, JosÃ© Alves, FrÃ©dÃ©ric MagoulÃ¨s
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.14948">Physics-Informed Graph Convolutional Networks: Towards a generalized framework for complex geometries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since the seminal work of [9] and their Physics-Informed neural networks (PINNs), many efforts have been conducted towards solving partial differential equations (PDEs) with Deep Learning models. However, some challenges remain, for instance the extension of such models to complex three-dimensional geometries, and a study on how such approaches could be combined to classical numerical solvers. In this work, we justify the use of graph neural networks for these problems, based on the similarity between these architectures and the meshes used in traditional numerical techniques for solving partial differential equations. After proving an issue with the Physics-Informed framework for complex geometries, during the computation of PDE residuals, an alternative procedure is proposed, by combining classical numerical solvers and the Physics-Informed framework. Finally, we propose an implementation of this approach, that we test on a three-dimensional problem on an irregular geometry.
<div id='section'>Paperid: <span id='pid'>1562, <a href='https://arxiv.org/pdf/2310.12846.pdf' target='_blank'>https://arxiv.org/pdf/2310.12846.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiasheng Chen, Juan Tang, Ming Yan, Shuai Lai, Kun Liang, Jianguang Lu, Wenqiang Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.12846">Physical Information Neural Networks for Solving High-index Differential-algebraic Equation Systems Based on Radau Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As is well known, differential algebraic equations (DAEs), which are able to describe dynamic changes and underlying constraints, have been widely applied in engineering fields such as fluid dynamics, multi-body dynamics, mechanical systems and control theory. In practical physical modeling within these domains, the systems often generate high-index DAEs. Classical implicit numerical methods typically result in varying order reduction of numerical accuracy when solving high-index systems.~Recently, the physics-informed neural network (PINN) has gained attention for solving DAE systems. However, it faces challenges like the inability to directly solve high-index systems, lower predictive accuracy, and weaker generalization capabilities. In this paper, we propose a PINN computational framework, combined Radau IIA numerical method with a neural network structure via the attention mechanisms, to directly solve high-index DAEs. Furthermore, we employ a domain decomposition strategy to enhance solution accuracy. We conduct numerical experiments with two classical high-index systems as illustrative examples, investigating how different orders of the Radau IIA method affect the accuracy of neural network solutions. The experimental results demonstrate that the PINN based on a 5th-order Radau IIA method achieves the highest level of system accuracy. Specifically, the absolute errors for all differential variables remains as low as $10^{-6}$, and the absolute errors for algebraic variables is maintained at $10^{-5}$, surpassing the results found in existing literature. Therefore, our method exhibits excellent computational accuracy and strong generalization capabilities, providing a feasible approach for the high-precision solution of larger-scale DAEs with higher indices or challenging high-dimensional partial differential algebraic equation systems.
<div id='section'>Paperid: <span id='pid'>1563, <a href='https://arxiv.org/pdf/2310.11945.pdf' target='_blank'>https://arxiv.org/pdf/2310.11945.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamad Abed El Rahman Hammoud, Edriss S. Titi, Ibrahim Hoteit, Omar Knio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11945">Downscaling Using CDAnet Under Observational and Model Noises: The Rayleigh-Benard Convection Paradigm</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficient downscaling of large ensembles of coarse-scale information is crucial in several applications, such as oceanic and atmospheric modeling. The determining form map is a theoretical lifting function from the low-resolution solution trajectories of a dissipative dynamical system to their corresponding fine-scale counterparts. Recently, a physics-informed deep neural network ("CDAnet") was introduced, providing a surrogate of the determining form map for efficient downscaling. CDAnet was demonstrated to efficiently downscale noise-free coarse-scale data in a deterministic setting. Herein, the performance of well-trained CDAnet models is analyzed in a stochastic setting involving (i) observational noise, (ii) model noise, and (iii) a combination of observational and model noises. The analysis is performed employing the Rayleigh-Benard convection paradigm, under three training conditions, namely, training with perfect, noisy, or downscaled data. Furthermore, the effects of noises, Rayleigh number, and spatial and temporal resolutions of the input coarse-scale information on the downscaled fields are examined. The results suggest that the expected l2-error of CDAnet behaves quadratically in terms of the standard deviations of the observational and model noises. The results also suggest that CDAnet responds to uncertainties similar to the theorized and numerically-validated CDA behavior with an additional error overhead due to CDAnet being a surrogate model of the determining form map.
<div id='section'>Paperid: <span id='pid'>1564, <a href='https://arxiv.org/pdf/2310.11804.pdf' target='_blank'>https://arxiv.org/pdf/2310.11804.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazuya Yokota, Takahiko Kurahashi, Masajiro Abe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11804">Physics-informed neural network for acoustic resonance analysis in a one-dimensional acoustic tube</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study devised a physics-informed neural network (PINN) framework to solve the wave equation for acoustic resonance analysis. The proposed analytical model, ResoNet, minimizes the loss function for periodic solutions and conventional PINN loss functions, thereby effectively using the function approximation capability of neural networks while performing resonance analysis. Additionally, it can be easily applied to inverse problems. The resonance in a one-dimensional acoustic tube, and the effectiveness of the proposed method was validated through the forward and inverse analyses of the wave equation with energy-loss terms. In the forward analysis, the applicability of PINN to the resonance problem was evaluated via comparison with the finite-difference method. The inverse analysis, which included identifying the energy loss term in the wave equation and design optimization of the acoustic tube, was performed with good accuracy.
<div id='section'>Paperid: <span id='pid'>1565, <a href='https://arxiv.org/pdf/2310.06572.pdf' target='_blank'>https://arxiv.org/pdf/2310.06572.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Geoffrey Daniel, Mohamed Bahi Yahiaoui, Claude Comtat, Sebastien Jan, Olga Kochebina, Jean-Marc Martinez, Viktoriya Sergeyeva, Viatcheslav Sharyy, Chi-Hsun Sung, Dominique Yvon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.06572">Deep Learning reconstruction with uncertainty estimation for $Î³$ photon interaction in fast scintillator detectors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This article presents a physics-informed deep learning method for the quantitative estimation of the spatial coordinates of gamma interactions within a monolithic scintillator, with a focus on Positron Emission Tomography (PET) imaging. A Density Neural Network approach is designed to estimate the 2-dimensional gamma photon interaction coordinates in a fast lead tungstate (PbWO4) monolithic scintillator detector. We introduce a custom loss function to estimate the inherent uncertainties associated with the reconstruction process and to incorporate the physical constraints of the detector.
  This unique combination allows for more robust and reliable position estimations and the obtained results demonstrate the effectiveness of the proposed approach and highlights the significant benefits of the uncertainties estimation. We discuss its potential impact on improving PET imaging quality and show how the results can be used to improve the exploitation of the model, to bring benefits to the application and how to evaluate the validity of the given prediction and the associated uncertainties. Importantly, our proposed methodology extends beyond this specific use case, as it can be generalized to other applications beyond PET imaging.
<div id='section'>Paperid: <span id='pid'>1566, <a href='https://arxiv.org/pdf/2310.03745.pdf' target='_blank'>https://arxiv.org/pdf/2310.03745.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vahidullah Tac, Manuel K Rausch, Ilias Bilionis, Francisco Sahli Costabal, Adrian Buganza Tepole
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03745">Generative Hyperelasticity with Physics-Informed Probabilistic Diffusion Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many natural materials exhibit highly complex, nonlinear, anisotropic, and heterogeneous mechanical properties. Recently, it has been demonstrated that data-driven strain energy functions possess the flexibility to capture the behavior of these complex materials with high accuracy while satisfying physics-based constraints. However, most of these approaches disregard the uncertainty in the estimates and the spatial heterogeneity of these materials. In this work, we leverage recent advances in generative models to address these issues. We use as building block neural ordinary equations (NODE) that -- by construction -- create polyconvex strain energy functions, a key property of realistic hyperelastic material models. We combine this approach with probabilistic diffusion models to generate new samples of strain energy functions. This technique allows us to sample a vector of Gaussian white noise and translate it to NODE parameters thereby representing plausible strain energy functions. We extend our approach to spatially correlated diffusion resulting in heterogeneous material properties for arbitrary geometries. We extensively test our method with synthetic and experimental data on biological tissues and run finite element simulations with various degrees of spatial heterogeneity. We believe this approach is a major step forward including uncertainty in predictive, data-driven models of hyperelasticity
<div id='section'>Paperid: <span id='pid'>1567, <a href='https://arxiv.org/pdf/2310.03088.pdf' target='_blank'>https://arxiv.org/pdf/2310.03088.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Solon Falas, Markos Asprou, Charalambos Konstantinou, Maria K. Michael
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.03088">Physics-Informed Neural Networks for Accelerating Power System State Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State estimation is the cornerstone of the power system control center since it provides the operating condition of the system in consecutive time intervals. This work investigates the application of physics-informed neural networks (PINNs) for accelerating power systems state estimation in monitoring the operation of power systems. Traditional state estimation techniques often rely on iterative algorithms that can be computationally intensive, particularly for large-scale power systems. In this paper, a novel approach that leverages the inherent physical knowledge of power systems through the integration of PINNs is proposed. By incorporating physical laws as prior knowledge, the proposed method significantly reduces the computational complexity associated with state estimation while maintaining high accuracy. The proposed method achieves up to 11% increase in accuracy, 75% reduction in standard deviation of results, and 30% faster convergence, as demonstrated by comprehensive experiments on the IEEE 14-bus system.
<div id='section'>Paperid: <span id='pid'>1568, <a href='https://arxiv.org/pdf/2309.10656.pdf' target='_blank'>https://arxiv.org/pdf/2309.10656.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elizabeth J Cross, Timothy J Rogers, Daniel J Pitchforth, Samuel J Gibson, Matthew R Jones
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.10656">A spectrum of physics-informed Gaussian processes for regression in engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the growing availability of sensing and data in general, we remain unable to fully characterise many in-service engineering systems and structures from a purely data-driven approach. The vast data and resources available to capture human activity are unmatched in our engineered world, and, even in cases where data could be referred to as ``big,'' they will rarely hold information across operational windows or life spans. This paper pursues the combination of machine learning technology and physics-based reasoning to enhance our ability to make predictive models with limited data. By explicitly linking the physics-based view of stochastic processes with a data-based regression approach, a spectrum of possible Gaussian process models are introduced that enable the incorporation of different levels of expert knowledge of a system. Examples illustrate how these approaches can significantly reduce reliance on data collection whilst also increasing the interpretability of the model, another important consideration in this context.
<div id='section'>Paperid: <span id='pid'>1569, <a href='https://arxiv.org/pdf/2309.07049.pdf' target='_blank'>https://arxiv.org/pdf/2309.07049.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiran Wang, Suchuan Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.07049">An Extreme Learning Machine-Based Method for Computational PDEs in Higher Dimensions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present two effective methods for solving high-dimensional partial differential equations (PDE) based on randomized neural networks. Motivated by the universal approximation property of this type of networks, both methods extend the extreme learning machine (ELM) approach from low to high dimensions. With the first method the unknown solution field in $d$ dimensions is represented by a randomized feed-forward neural network, in which the hidden-layer parameters are randomly assigned and fixed while the output-layer parameters are trained. The PDE and the boundary/initial conditions, as well as the continuity conditions (for the local variant of the method), are enforced on a set of random interior/boundary collocation points. The resultant linear or nonlinear algebraic system, through its least squares solution, provides the trained values for the network parameters. With the second method the high-dimensional PDE problem is reformulated through a constrained expression based on an Approximate variant of the Theory of Functional Connections (A-TFC), which avoids the exponential growth in the number of terms of TFC as the dimension increases. The free field function in the A-TFC constrained expression is represented by a randomized neural network and is trained by a procedure analogous to the first method. We present ample numerical simulations for a number of high-dimensional linear/nonlinear stationary/dynamic PDEs to demonstrate their performance. These methods can produce accurate solutions to high-dimensional PDEs, in particular with their errors reaching levels not far from the machine accuracy for relatively lower dimensions. Compared with the physics-informed neural network (PINN) method, the current method is both cost-effective and more accurate for high-dimensional PDEs.
<div id='section'>Paperid: <span id='pid'>1570, <a href='https://arxiv.org/pdf/2309.05259.pdf' target='_blank'>https://arxiv.org/pdf/2309.05259.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haohao Qu, Haoxuan Kuang, Jun Li, Linlin You
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.05259">A physics-informed and attention-based graph learning approach for regional electric vehicle charging demand prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Along with the proliferation of electric vehicles (EVs), optimizing the use of EV charging space can significantly alleviate the growing load on intelligent transportation systems. As the foundation to achieve such an optimization, a spatiotemporal method for EV charging demand prediction in urban areas is required. Although several solutions have been proposed by using data-driven deep learning methods, it can be found that these performance-oriented methods may suffer from misinterpretations to correctly handle the reverse relationship between charging demands and prices. To tackle the emerging challenges of training an accurate and interpretable prediction model, this paper proposes a novel approach that enables the integration of graph and temporal attention mechanisms for feature extraction and the usage of physic-informed meta-learning in the model pre-training step for knowledge transfer. Evaluation results on a dataset of 18,013 EV charging piles in Shenzhen, China, show that the proposed approach, named PAG, can achieve state-of-the-art forecasting performance and the ability in understanding the adaptive changes in charging demands caused by price fluctuations.
<div id='section'>Paperid: <span id='pid'>1571, <a href='https://arxiv.org/pdf/2309.04755.pdf' target='_blank'>https://arxiv.org/pdf/2309.04755.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haotian Guan, Jinping Dong, Wei-Ning Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.04755">A Novel Training Framework for Physics-informed Neural Networks: Towards Real-time Applications in Ultrafast Ultrasound Blood Flow Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ultrafast ultrasound blood flow imaging is a state-of-the-art technique for depiction of complex blood flow dynamics in vivo through thousands of full-view image data (or, timestamps) acquired per second. Physics-informed Neural Network (PINN) is one of the most preeminent solvers of the Navier-Stokes equations, widely used as the governing equation of blood flow. However, that current approaches rely on full Navier-Stokes equations is impractical for ultrafast ultrasound. We hereby propose a novel PINN training framework for solving the Navier-Stokes equations. It involves discretizing Navier-Stokes equations into steady state and sequentially solving them with test-time adaptation. The novel training framework is coined as SeqPINN. Upon its success, we propose a parallel training scheme for all timestamps based on averaged constant stochastic gradient descent as initialization. Uncertainty estimation through Stochastic Weight Averaging Gaussian is then used as an indicator of generalizability of the initialization. This algorithm, named SP-PINN, further expedites training of PINN while achieving comparable accuracy with SeqPINN. The performance of SeqPINN and SP-PINN was evaluated through finite-element simulations and in vitro phantoms of single-branch and trifurcate blood vessels. Results show that both algorithms were manyfold faster than the original design of PINN, while respectively achieving Root Mean Square Errors of 0.63 cm/s and 0.81 cm/s on the straight vessel and 1.35 cm/s and 1.63 cm/s on the trifurcate vessel when recovering blood flow velocities. The successful implementation of SeqPINN and SP-PINN open the gate for real-time training of PINN for Navier-Stokes equations and subsequently reliable imaging-based blood flow assessment in clinical practice.
<div id='section'>Paperid: <span id='pid'>1572, <a href='https://arxiv.org/pdf/2308.12864.pdf' target='_blank'>https://arxiv.org/pdf/2308.12864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarah Perez, Philippe Poncet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12864">Auto-weighted Bayesian Physics-Informed Neural Networks and robust estimations for multitask inverse problems in pore-scale imaging of dissolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this article, we present a novel data assimilation strategy in pore-scale imaging and demonstrate that this makes it possible to robustly address reactive inverse problems incorporating Uncertainty Quantification (UQ). Pore-scale modeling of reactive flow offers a valuable opportunity to investigate the evolution of macro-scale properties subject to dynamic processes. Yet, they suffer from imaging limitations arising from the associated X-ray microtomography (X-ray microCT) process, which induces discrepancies in the properties estimates. Assessment of the kinetic parameters also raises challenges, as reactive coefficients are critical parameters that can cover a wide range of values. We account for these two issues and ensure reliable calibration of pore-scale modeling, based on dynamical microCT images, by integrating uncertainty quantification in the workflow.
  The present method is based on a multitasking formulation of reactive inverse problems combining data-driven and physics-informed techniques in calcite dissolution. This allows quantifying morphological uncertainties on the porosity field and estimating reactive parameter ranges through prescribed PDE models with a latent concentration field and dynamical microCT. The data assimilation strategy relies on sequential reinforcement incorporating successively additional PDE constraints. We guarantee robust and unbiased uncertainty quantification by straightforward adaptive weighting of Bayesian Physics-Informed Neural Networks (BPINNs), ensuring reliable micro-porosity changes during geochemical transformations. We demonstrate successful Bayesian Inference in 1D+Time and 2D+Time calcite dissolution based on synthetic microCT images with meaningful posterior distribution on the reactive parameters and dimensionless numbers.
<div id='section'>Paperid: <span id='pid'>1573, <a href='https://arxiv.org/pdf/2308.09956.pdf' target='_blank'>https://arxiv.org/pdf/2308.09956.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiang Xi, Zhuojia Fu, Wenzhi Xu, Mi-An Xue, Jinhai Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09956">FEM-PIKFNNs for underwater acoustic propagation induced by structural vibrations in different ocean environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, a novel hybrid method based on the finite element method (FEM) and physics-informed kernel function neural networks (PIKFNNs) is proposed and applied to the prediction of underwater acoustic propagation induced by structural vibrations in the unbounded ocean, deep ocean and shallow ocean. In the hybrid method, PIKFNNs are a class of improved shallow physics-informed neural networks (PINNs) that replace the activation functions in PINNs with the physics-informed kernel functions (PIKFs), thereby integrating prior physical information into the neural network model. Moreover, this neural network circumvents the step of embedding the governing equations into the loss function in PINNs, and requires only training on boundary data. By using the Green's functions as the PIKFs and the structural-acoustic coupling response information obtained from the FEM as boundary training data, the PIKFNNs can inherently capture the Sommerfeld radiation condition at infinity, which is naturally suitable for predicting ocean acoustic propagation. Numerical experiments demonstrate the accuracy and feasibility of the FEM-PIKFNNs in comparison with the true solutions and finite element results.
<div id='section'>Paperid: <span id='pid'>1574, <a href='https://arxiv.org/pdf/2308.04735.pdf' target='_blank'>https://arxiv.org/pdf/2308.04735.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongho Kim, Yongho Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04735">Going Deeper with Five-point Stencil Convolutions for Reaction-Diffusion Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks have been widely applied to partial differential equations with great success because the physics-informed loss essentially requires no observations or discretization. However, it is difficult to optimize model parameters, and these parameters must be trained for each distinct initial condition. To overcome these challenges in second-order reaction-diffusion type equations, a possible way is to use five-point stencil convolutional neural networks (FCNNs). FCNNs are trained using two consecutive snapshots, where the time step corresponds to the step size of the given snapshots. Thus, the time evolution of FCNNs depends on the time step, and the time step must satisfy its CFL condition to avoid blow-up solutions. In this work, we propose deep FCNNs that have large receptive fields to predict time evolutions with a time step larger than the threshold of the CFL condition. To evaluate our models, we consider the heat, Fisher's, and Allen-Cahn equations with diverse initial conditions. We demonstrate that deep FCNNs retain certain accuracies, in contrast to FDMs that blow up.
<div id='section'>Paperid: <span id='pid'>1575, <a href='https://arxiv.org/pdf/2308.03088.pdf' target='_blank'>https://arxiv.org/pdf/2308.03088.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yong Shang, Fei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.03088">Randomized Neural Networks with Petrov-Galerkin Methods for Solving Linear Elasticity Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop the Randomized Neural Networks with Petrov-Galerkin Methods (RNN-PG methods) to solve linear elasticity problems. RNN-PG methods use Petrov-Galerkin variational framework, where the solution is approximated by randomized neural networks and the test functions are piecewise polynomials. Unlike conventional neural networks, the parameters of the hidden layers of the randomized neural networks are fixed randomly, while the parameters of the output layer are determined by the least square method, which can effectively approximate the solution. We also develop mixed RNN-PG methods for linear elasticity problems, which ensure the symmetry of the stress tensor and avoid locking effects. We compare RNN-PG methods with the finite element method, the mixed discontinuous Galerkin method, and the physics-informed neural network on several examples, and the numerical results demonstrate that RNN-PG methods achieve higher accuracy and efficiency.
<div id='section'>Paperid: <span id='pid'>1576, <a href='https://arxiv.org/pdf/2308.00927.pdf' target='_blank'>https://arxiv.org/pdf/2308.00927.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeremias Garay, Jocelyn Dunstan, Sergio Uribe, Francisco Sahli Costabal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.00927">Physics-informed neural networks for blood flow inverse problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a powerful tool for solving inverse problems, especially in cases where no complete information about the system is known and scatter measurements are available. This is especially useful in hemodynamics since the boundary information is often difficult to model, and high-quality blood flow measurements are generally hard to obtain. In this work, we use the PINNs methodology for estimating reduced-order model parameters and the full velocity field from scatter 2D noisy measurements in the ascending aorta. The results show stable and accurate parameter estimations when using the method with simulated data, while the velocity reconstruction shows dependence on the measurement quality and the flow pattern complexity. The method allows for solving clinical-relevant inverse problems in hemodynamics and complex coupled physical systems.
<div id='section'>Paperid: <span id='pid'>1577, <a href='https://arxiv.org/pdf/2307.10060.pdf' target='_blank'>https://arxiv.org/pdf/2307.10060.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rikhi Bose, Arunabha M. Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.10060">Accurate deep learning sub-grid scale models for large eddy simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present two families of sub-grid scale (SGS) turbulence models developed for large-eddy simulation (LES) purposes. Their development required the formulation of physics-informed robust and efficient Deep Learning (DL) algorithms which, unlike state-of-the-art analytical modeling techniques can produce high-order complex non-linear relations between inputs and outputs. Explicit filtering of data from direct simulations of the canonical channel flow at two friction Reynolds numbers $Re_Ï\approx 395$ and 590 provided accurate data for training and testing. The two sets of models use different network architectures. One of the architectures uses tensor basis neural networks (TBNN) and embeds the simplified analytical model form of the general effective-viscosity hypothesis, thus incorporating the Galilean, rotational and reflectional invariances. The other architecture is that of a relatively simple network, that is able to incorporate the Galilean invariance only. However, this simpler architecture has better feature extraction capacity owing to its ability to establish relations between and extract information from cross-components of the integrity basis tensors and the SGS stresses. Both sets of models are used to predict the SGS stresses for feature datasets generated with different filter widths, and at different Reynolds numbers. It is shown that due to the simpler model's better feature learning capabilities, it outperforms the invariance embedded model in statistical performance metrics. In a priori tests, both sets of models provide similar levels of dissipation and backscatter. Based on the test results, both sets of models should be usable in a posteriori actual LESs.
<div id='section'>Paperid: <span id='pid'>1578, <a href='https://arxiv.org/pdf/2307.09759.pdf' target='_blank'>https://arxiv.org/pdf/2307.09759.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaumudi Joshi, Vukka Snigdha, Arya Kumar Bhattacharya
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.09759">Constructing Extreme Learning Machines with zero Spectral Bias</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The phenomena of Spectral Bias, where the higher frequency components of a function being learnt in a feedforward Artificial Neural Network (ANN) are seen to converge more slowly than the lower frequencies, is observed ubiquitously across ANNs. This has created technology challenges in fields where resolution of higher frequencies is crucial, like in Physics Informed Neural Networks (PINNs). Extreme Learning Machines (ELMs) that obviate an iterative solution process which provides the theoretical basis of Spectral Bias (SB), should in principle be free of the same. This work verifies the reliability of this assumption, and shows that it is incorrect. However, the structure of ELMs makes them naturally amenable to implementation of variants of Fourier Feature Embeddings, which have been shown to mitigate SB in ANNs. This approach is implemented and verified to completely eliminate SB, thus bringing into feasibility the application of ELMs for practical problems like PINNs where resolution of higher frequencies is essential.
<div id='section'>Paperid: <span id='pid'>1579, <a href='https://arxiv.org/pdf/2307.07647.pdf' target='_blank'>https://arxiv.org/pdf/2307.07647.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maciej Sikora, Patryk Krukowski, Anna Paszynska, Maciej Paszynski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.07647">Physics Informed Neural Networks with strong and weak residuals for advection-dominated diffusion problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper deals with the following important research questions. Is it possible to solve challenging advection-dominated diffusion problems in one and two dimensions using Physics Informed Neural Networks (PINN) and Variational Physics Informed Neural Networks (VPINN)? How does it compare to the higher-order and continuity Finite Element Method (FEM)? How to define the loss functions for PINN and VPINN so they converge to the correct solutions? How to select points or test functions for training of PINN and VPINN? We focus on the one-dimensional advection-dominated diffusion problem and the two-dimensional Eriksson-Johnson model problem. We show that the standard Galerkin method for FEM cannot solve this problem. We discuss the stabilization of the advection-dominated diffusion problem with the Petrov-Galerkin (PG) formulation and present the FEM solution obtained with the PG method. We employ PINN and VPINN methods, defining several strong and weak loss functions. We compare the training and solutions of PINN and VPINN methods with higher-order FEM methods.
<div id='section'>Paperid: <span id='pid'>1580, <a href='https://arxiv.org/pdf/2307.01354.pdf' target='_blank'>https://arxiv.org/pdf/2307.01354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Waleed Diab, Omar Chaabi, Shayma Alkobaisi, Abeeb Awotunde, Mohammed Al Kobaisi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.01354">Learning Generic Solutions for Multiphase Transport in Porous Media via the Flux Functions Operator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional numerical schemes for simulating fluid flow and transport in porous media can be computationally expensive. Advances in machine learning for scientific computing have the potential to help speed up the simulation time in many scientific and engineering fields. DeepONet has recently emerged as a powerful tool for accelerating the solution of partial differential equations (PDEs) by learning operators (mapping between function spaces) of PDEs. In this work, we learn the mapping between the space of flux functions of the Buckley-Leverett PDE and the space of solutions (saturations). We use Physics-Informed DeepONets (PI-DeepONets) to achieve this mapping without any paired input-output observations, except for a set of given initial or boundary conditions; ergo, eliminating the expensive data generation process. By leveraging the underlying physical laws via soft penalty constraints during model training, in a manner similar to Physics-Informed Neural Networks (PINNs), and a unique deep neural network architecture, the proposed PI-DeepONet model can predict the solution accurately given any type of flux function (concave, convex, or non-convex) while achieving up to four orders of magnitude improvements in speed over traditional numerical solvers. Moreover, the trained PI-DeepONet model demonstrates excellent generalization qualities, rendering it a promising tool for accelerating the solution of transport problems in porous media.
<div id='section'>Paperid: <span id='pid'>1581, <a href='https://arxiv.org/pdf/2307.00035.pdf' target='_blank'>https://arxiv.org/pdf/2307.00035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guangtao Zhang, Yiting Duan, Guanyu Pan, Qijing Chen, Huiyu Yang, Zhikun Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.00035">Parameter Identification for Partial Differential Equations with Spatiotemporal Varying Coefficients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To comprehend complex systems with multiple states, it is imperative to reveal the identity of these states by system outputs. Nevertheless, the mathematical models describing these systems often exhibit nonlinearity so that render the resolution of the parameter inverse problem from the observed spatiotemporal data a challenging endeavor. Starting from the observed data obtained from such systems, we propose a novel framework that facilitates the investigation of parameter identification for multi-state systems governed by spatiotemporal varying parametric partial differential equations. Our framework consists of two integral components: a constrained self-adaptive physics-informed neural network, encompassing a sub-network, as our methodology for parameter identification, and a finite mixture model approach to detect regions of probable parameter variations. Through our scheme, we can precisely ascertain the unknown varying parameters of the complex multi-state system, thereby accomplishing the inversion of the varying parameters. Furthermore, we have showcased the efficacy of our framework on two numerical cases: the 1D Burgers' equation with time-varying parameters and the 2D wave equation with a space-varying parameter.
<div id='section'>Paperid: <span id='pid'>1582, <a href='https://arxiv.org/pdf/2306.11014.pdf' target='_blank'>https://arxiv.org/pdf/2306.11014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Oliver Hoidn, Aashwin Ananda Mishra, Apurva Mehta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.11014">Physics Constrained Unsupervised Deep Learning for Rapid, High Resolution Scanning Coherent Diffraction Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>By circumventing the resolution limitations of optics, coherent diffractive imaging (CDI) and ptychography are making their way into scientific fields ranging from X-ray imaging to astronomy. Yet, the need for time consuming iterative phase recovery hampers real-time imaging. While supervised deep learning strategies have increased reconstruction speed, they sacrifice image quality. Furthermore, these methods' demand for extensive labeled training data is experimentally burdensome. Here, we propose an unsupervised physics-informed neural network reconstruction method, PtychoPINN, that retains the factor of 100-to-1000 speedup of deep learning-based reconstruction while improving reconstruction quality by combining the diffraction forward map with real-space constraints from overlapping measurements. In particular, PtychoPINN significantly advances generalizability, accuracy (with a typical 10 dB PSNR increase), and linear resolution (2- to 6-fold gain). This blend of performance and speed offers exciting prospects for high-resolution real-time imaging in high-throughput environments such as X-ray free electron lasers (XFELs) and diffraction-limited light sources.
<div id='section'>Paperid: <span id='pid'>1583, <a href='https://arxiv.org/pdf/2306.10335.pdf' target='_blank'>https://arxiv.org/pdf/2306.10335.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mattia Silvestri, Federico Baldo, Eleonora Misino, Michele Lombardi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.10335">An analysis of Universal Differential Equations for data-driven discovery of Ordinary Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the last decade, the scientific community has devolved its attention to the deployment of data-driven approaches in scientific research to provide accurate and reliable analysis of a plethora of phenomena. Most notably, Physics-informed Neural Networks and, more recently, Universal Differential Equations (UDEs) proved to be effective both in system integration and identification. However, there is a lack of an in-depth analysis of the proposed techniques. In this work, we make a contribution by testing the UDE framework in the context of Ordinary Differential Equations (ODEs) discovery. In our analysis, performed on two case studies, we highlight some of the issues arising when combining data-driven approaches and numerical solvers, and we investigate the importance of the data collection process. We believe that our analysis represents a significant contribution in investigating the capabilities and limitations of Physics-informed Machine Learning frameworks.
<div id='section'>Paperid: <span id='pid'>1584, <a href='https://arxiv.org/pdf/2306.09792.pdf' target='_blank'>https://arxiv.org/pdf/2306.09792.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuyang Miao, Haolin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09792">GPINN: Physics-informed Neural Network with Graph Embedding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work proposes a Physics-informed Neural Network framework with Graph Embedding (GPINN) to perform PINN in graph, i.e. topological space instead of traditional Euclidean space, for improved problem-solving efficiency. The method integrates topological data into the neural network's computations, which significantly boosts the performance of the Physics-Informed Neural Network (PINN). The graph embedding technique infuses extra dimensions into the input space to encapsulate the spatial characteristics of a graph while preserving the properties of the original space. The selection of these extra dimensions is guided by the Fiedler vector, offering an optimised pathologic notation of the graph. Two case studies are conducted, which demonstrate significant improvement in the performance of GPINN in comparison to traditional PINN, particularly in its superior ability to capture physical features of the solution.
<div id='section'>Paperid: <span id='pid'>1585, <a href='https://arxiv.org/pdf/2306.08727.pdf' target='_blank'>https://arxiv.org/pdf/2306.08727.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenrui Hao, Qingguo Hong, Xianlin Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.08727">Gauss Newton method for solving variational problems of PDEs with neural network discretizaitons</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The numerical solution of differential equations using machine learning-based approaches has gained significant popularity. Neural network-based discretization has emerged as a powerful tool for solving differential equations by parameterizing a set of functions. Various approaches, such as the deep Ritz method and physics-informed neural networks, have been developed for numerical solutions. Training algorithms, including gradient descent and greedy algorithms, have been proposed to solve the resulting optimization problems. In this paper, we focus on the variational formulation of the problem and propose a Gauss- Newton method for computing the numerical solution. We provide a comprehensive analysis of the superlinear convergence properties of this method, along with a discussion on semi-regular zeros of the vanishing gradient. Numerical examples are presented to demonstrate the efficiency of the proposed Gauss-Newton method.
<div id='section'>Paperid: <span id='pid'>1586, <a href='https://arxiv.org/pdf/2306.07982.pdf' target='_blank'>https://arxiv.org/pdf/2306.07982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lin Qiu, Yanjie Wang, Tian He, Yan Gu, Fajie Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.07982">Adaptive physics-informed neural networks for dynamic thermo-mechanical coupling problems in large-size-ratio functionally graded materials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present the adaptive physics-informed neural networks (PINNs) for resolving three dimensional (3D) dynamic thermo-mechanical coupling problems in large-size-ratio functionally graded materials (FGMs). The physical laws described by coupled governing equations and the constraints imposed by the initial and boundary conditions are leveraged to form the loss function of PINNs by means of the automatic differentiation algorithm, and an adaptive loss balancing scheme is introduced to improve the performance of PINNs. The adaptive PINNs are meshfree and trained on batches of randomly sampled collocation points, which is the key feature and superiority of the approach, since mesh-based methods will encounter difficulties in solving problems with large size ratios. The developed methodology is tested for several 3D thermo-mechanical coupling problems in large-size-ratio FGMs, and the numerical results demonstrate that the adaptive PINNs are effective and reliable for dealing with coupled problems in coating structures with large size ratios up to 109, as well as complex large-size-ratio geometries such as the electrostatic comb, the airplane and the submarine.
<div id='section'>Paperid: <span id='pid'>1587, <a href='https://arxiv.org/pdf/2306.02606.pdf' target='_blank'>https://arxiv.org/pdf/2306.02606.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuojia Fu, Wenzhi Xu, Shuainan Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02606">Physics-Informed Kernel Function Neural Networks for Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposed a novel radial basis function neural network (RBFNN) to solve various partial differential equations (PDEs). In the proposed RBF neural networks, the physics-informed kernel functions (PIKFs), which are derived according to the governing equations of the considered PDEs, are used to be the activation functions instead of the traditional RBFs. Similar to the well-known physics-informed neural networks (PINNs), the proposed physics-informed kernel function neural networks (PIKFNNs) also include the physical information of the considered PDEs in the neural network. The difference is that the PINNs put this physical information in the loss function, and the proposed PIKFNNs put the physical information of the considered governing equations in the activation functions. By using the derived physics-informed kernel functions satisfying the considered governing equations of homogeneous, nonhomogeneous, transient PDEs as the activation functions, only the boundary/initial data are required to train the neural network. Finally, the feasibility and accuracy of the proposed PIKFNNs are validated by several benchmark examples referred to high-wavenumber wave propagation problem, infinite domain problem, nonhomogeneous problem, long-time evolution problem, inverse problem, spatial structural derivative diffusion model, and so on.
<div id='section'>Paperid: <span id='pid'>1588, <a href='https://arxiv.org/pdf/2305.16593.pdf' target='_blank'>https://arxiv.org/pdf/2305.16593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karan Taneja, Xiaolong He, Qizhi He, J. S. Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.16593">A Multi-Resolution Physics-Informed Recurrent Neural Network: Formulation and Application to Musculoskeletal Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents a multi-resolution physics-informed recurrent neural network (MR PI-RNN), for simultaneous prediction of musculoskeletal (MSK) motion and parameter identification of the MSK systems. The MSK application was selected as the model problem due to its challenging nature in mapping the high-frequency surface electromyography (sEMG) signals to the low-frequency body joint motion controlled by the MSK and muscle contraction dynamics. The proposed method utilizes the fast wavelet transform to decompose the mixed frequency input sEMG and output joint motion signals into nested multi-resolution signals. The prediction model is subsequently trained on coarser-scale input-output signals using a gated recurrent unit (GRU), and then the trained parameters are transferred to the next level of training with finer-scale signals. These training processes are repeated recursively under a transfer-learning fashion until the full-scale training (i.e., with unfiltered signals) is achieved, while satisfying the underlying dynamic equilibrium. Numerical examples on recorded subject data demonstrate the effectiveness of the proposed framework in generating a physics-informed forward-dynamics surrogate, which yields higher accuracy in motion predictions of elbow flexion-extension of an MSK system compared to the case with single-scale training. The framework is also capable of identifying muscle parameters that are physiologically consistent with the subject's kinematics data.
<div id='section'>Paperid: <span id='pid'>1589, <a href='https://arxiv.org/pdf/2305.15990.pdf' target='_blank'>https://arxiv.org/pdf/2305.15990.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francesco Brandolin, Matteo Ravasi, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.15990">PINNslope: seismic data interpolation and local slope estimation with physics informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Interpolation of aliased seismic data constitutes a key step in a seismic processing workflow to obtain high quality velocity models and seismic images. Building on the idea of describing seismic wavefields as a superposition of local plane waves, we propose to interpolate seismic data by utilizing a physics informed neural network (PINN). In the proposed framework, two feed-forward neural networks are jointly trained using the local plane wave differential equation as well as the available data as two terms in the objective function: a primary network assisted by positional encoding is tasked with reconstructing the seismic data, whilst an auxiliary, smaller network estimates the associated local slopes. Results on synthetic and field data validate the effectiveness of the proposed method in handling aliased (coarsely sampled) data and data with large gaps. Our method compares favorably against a classic least-squares inversion approach regularized by the local plane-wave equation as well as a PINN-based approach with a single network and pre-computed local slopes. We find that introducing a second network to estimate the local slopes whilst at the same time interpolating the aliased data enhances the overall reconstruction capabilities and convergence behavior of the primary network. Moreover, an additional positional encoding layer embedded as the first layer of the wavefield network confers to the network the ability to converge faster improving the accuracy of the data term.
<div id='section'>Paperid: <span id='pid'>1590, <a href='https://arxiv.org/pdf/2304.12584.pdf' target='_blank'>https://arxiv.org/pdf/2304.12584.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ze-Hao Wang, Long-Kun Shan, Tong-Tian Weng, Tian-Long Chen, Qi-Yu Wang, Xiang-Dong Chen, Zhang-Yang Wang, Guang-Can Guo, Fang-Wen Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.12584">Learning imaging mechanism directly from optical microscopy observations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optical microscopy image plays an important role in scientific research through the direct visualization of the nanoworld, where the imaging mechanism is described as the convolution of the point spread function (PSF) and emitters. Based on a priori knowledge of the PSF or equivalent PSF, it is possible to achieve more precise exploration of the nanoworld. However, it is an outstanding challenge to directly extract the PSF from microscopy images. Here, with the help of self-supervised learning, we propose a physics-informed masked autoencoder (PiMAE) that enables a learnable estimation of the PSF and emitters directly from the raw microscopy images. We demonstrate our method in synthetic data and real-world experiments with significant accuracy and noise robustness. PiMAE outperforms DeepSTORM and the Richardson-Lucy algorithm in synthetic data tasks with an average improvement of 19.6\% and 50.7\% (35 tasks), respectively, as measured by the normalized root mean square error (NRMSE) metric. This is achieved without prior knowledge of the PSF, in contrast to the supervised approach used by DeepSTORM and the known PSF assumption in the Richardson-Lucy algorithm. Our method, PiMAE, provides a feasible scheme for achieving the hidden imaging mechanism in optical microscopy and has the potential to learn hidden mechanisms in many more systems.
<div id='section'>Paperid: <span id='pid'>1591, <a href='https://arxiv.org/pdf/2304.05991.pdf' target='_blank'>https://arxiv.org/pdf/2304.05991.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel S. GusmÃ£o, Andrew J. Medford
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.05991">Maximum-likelihood Estimators in Physics-Informed Neural Networks for High-dimensional Inverse Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have proven a suitable mathematical scaffold for solving inverse ordinary (ODE) and partial differential equations (PDE). Typical inverse PINNs are formulated as soft-constrained multi-objective optimization problems with several hyperparameters. In this work, we demonstrate that inverse PINNs can be framed in terms of maximum-likelihood estimators (MLE) to allow explicit error propagation from interpolation to the physical model space through Taylor expansion, without the need of hyperparameter tuning. We explore its application to high-dimensional coupled ODEs constrained by differential algebraic equations that are common in transient chemical and biological kinetics. Furthermore, we show that singular-value decomposition (SVD) of the ODE coupling matrices (reaction stoichiometry matrix) provides reduced uncorrelated subspaces in which PINNs solutions can be represented and over which residuals can be projected. Finally, SVD bases serve as preconditioners for the inversion of covariance matrices in this hyperparameter-free robust application of MLE to ``kinetics-informed neural networks''.
<div id='section'>Paperid: <span id='pid'>1592, <a href='https://arxiv.org/pdf/2304.04776.pdf' target='_blank'>https://arxiv.org/pdf/2304.04776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Najjar Amiri, Aycan Deniz Vit, Kazim Gorgulu, Emir Salih Magden
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04776">Deep Photonic Networks with Arbitrary and Broadband Functionality</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Growing application space in optical communications, computing, and sensing continues to drive the need for high-performance integrated photonic components. Designing these on-chip systems with complex and application-specific functionality requires beyond what is possible with physical intuition, for which machine learning-based design methods have recently become popular. However, as the expensive computational requirements for physically accurate device simulations last a critical challenge, these methods typically remain limited in scalability and the optical design degrees of freedom they can provide for application-specific and arbitrary photonic integrated circuits. Here, we introduce a highly-scalable, physics-informed framework for the design of on-chip optical systems with arbitrary functionality based on a deep photonic network of custom-designed Mach-Zehnder interferometers. Using this framework, we design ultra-broadband power splitters and a spectral duplexer, each in less than two minutes, and demonstrate state-of-the-art experimental performance with less than 0.66 dB insertion loss and over 120 nm of 1-dB bandwidth for all devices. Our presented framework provides an essential tool with a tractable path towards the systematic design of large-scale photonic systems with custom and broadband power, phase, and dispersion profiles for use in multi-band optical applications including high-throughput communications, quantum information processing, and medical/biological sensing.
<div id='section'>Paperid: <span id='pid'>1593, <a href='https://arxiv.org/pdf/2304.04046.pdf' target='_blank'>https://arxiv.org/pdf/2304.04046.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haiwei Xie, Federica Bellizio, Jochen L. Cremer, Goran Strbac
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04046">Regularised Learning with Selected Physics for Power System Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the increasing system stability issues caused by the technological revolutions of power system equipment, the assessment of the dynamic security of the systems for changing operating conditions (OCs) is nowadays crucial. To address the computational time problem of conventional dynamic security assessment tools, many machine learning (ML) approaches have been proposed and well-studied in this context. However, these learned models only rely on data, and thus miss resourceful information offered by the physical system. To this end, this paper focuses on combining the power system dynamical model together with the conventional ML. Going beyond the classic Physics Informed Neural Networks (PINNs), this paper proposes Selected Physics Informed Neural Networks (SPINNs) to predict the system dynamics for varying OCs. A two-level structure of feed-forward NNs is proposed, where the first NN predicts the generator bus rotor angles (system states) and the second NN learns to adapt to varying OCs. We show a case study on an IEEE-9 bus system that considering selected physics in model training reduces the amount of needed training data. Moreover, the trained model effectively predicted long-term dynamics that were beyond the time scale of the collected training dataset (extrapolation).
<div id='section'>Paperid: <span id='pid'>1594, <a href='https://arxiv.org/pdf/2303.15704.pdf' target='_blank'>https://arxiv.org/pdf/2303.15704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyu Chen, Jianhuan Cen, Qingsong Zou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.15704">Adaptive trajectories sampling for solving PDEs with deep learning methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a new adaptive technique, named adaptive trajectories sampling (ATS), which is used to select training points for the numerical solution of partial differential equations (PDEs) with deep learning methods. The key feature of the ATS is that all training points are adaptively selected from trajectories that are generated according to a PDE-related stochastic process. We incorporate the ATS into three known deep learning solvers for PDEs, namely the adaptive derivative-free-loss method (ATS-DFLM), the adaptive physics-informed neural network method (ATS-PINN), and the adaptive temporal-difference method for forward-backward stochastic differential equations (ATS-FBSTD). Our numerical experiments demonstrate that the ATS remarkably improves the computational accuracy and efficiency of the original deep learning solvers for the PDEs. In particular, for some specific high-dimensional PDEs, the ATS can even improve the accuracy of the PINN by two orders of magnitude.
<div id='section'>Paperid: <span id='pid'>1595, <a href='https://arxiv.org/pdf/2303.15196.pdf' target='_blank'>https://arxiv.org/pdf/2303.15196.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nayara Fonseca, Veronica Guidetti, Will Trojak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.15196">Probing optimisation in physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A novel comparison is presented of the effect of optimiser choice on the accuracy of physics-informed neural networks (PINNs). To give insight into why some optimisers are better, a new approach is proposed that tracks the training trajectory curvature and can be evaluated on the fly at a low computational cost. The linear advection equation is studied for several advective velocities, and we show that the optimiser choice substantially impacts PINNs model performance and accuracy. Furthermore, using the curvature measure, we found a negative correlation between the convergence error and the curvature in the optimiser local reference frame. It is concluded that, in this case, larger local curvature values result in better solutions. Consequently, optimisation of PINNs is made more difficult as minima are in highly curved regions.
<div id='section'>Paperid: <span id='pid'>1596, <a href='https://arxiv.org/pdf/2303.14878.pdf' target='_blank'>https://arxiv.org/pdf/2303.14878.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanlai Chen, Shawn Koohy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.14878">GPT-PINN: Generative Pre-Trained Physics-Informed Neural Networks toward non-intrusive Meta-learning of parametric PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Network (PINN) has proven itself a powerful tool to obtain the numerical solutions of nonlinear partial differential equations (PDEs) leveraging the expressivity of deep neural networks and the computing power of modern heterogeneous hardware. However, its training is still time-consuming, especially in the multi-query and real-time simulation settings, and its parameterization often overly excessive. In this paper, we propose the Generative Pre-Trained PINN (GPT-PINN) to mitigate both challenges in the setting of parametric PDEs. GPT-PINN represents a brand-new meta-learning paradigm for parametric systems. As a network of networks, its outer-/meta-network is hyper-reduced with only one hidden layer having significantly reduced number of neurons. Moreover, its activation function at each hidden neuron is a (full) PINN pre-trained at a judiciously selected system configuration. The meta-network adaptively ``learns'' the parametric dependence of the system and ``grows'' this hidden layer one neuron at a time. In the end, by encompassing a very small number of networks trained at this set of adaptively-selected parameter values, the meta-network is capable of generating surrogate solutions for the parametric system across the entire parameter domain accurately and efficiently.
<div id='section'>Paperid: <span id='pid'>1597, <a href='https://arxiv.org/pdf/2303.14179.pdf' target='_blank'>https://arxiv.org/pdf/2303.14179.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Su Chen, Xianwei Liu, Lei Fu, Suyang Wang, Bin Zhang, Xiaojun Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.14179">Physics Symbolic Learner for Discovering Ground-Motion Models Via NGA-West2 Database</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ground-motion model (GMM) is the basis of many earthquake engineering studies. In this study, a novel physics-informed symbolic learner (PISL) method based on the Nest Generation Attenuation-West2 database is proposed to automatically discover mathematical equation operators as symbols. The sequential threshold ridge regression algorithm is utilized to distill a concise and interpretable explicit characterization of complex systems of ground motions. In addition to the basic variables retrieved from previous GMMs, the current PISL incorporates two a priori physical conditions, namely, distance and amplitude saturation. GMMs developed using the PISL, an empirical regression method (ERM), and an artificial neural network (ANN) are compared in terms of residuals and extrapolation based on obtained data of peak ground acceleration and velocity. The results show that the inter- and intra-event standard deviations of the three methods are similar. The functional form of the PISL is more concise than that of the ERM and ANN. The extrapolation capability of the PISL is more accurate than that of the ANN. The PISL-GMM used in this study provide a new paradigm of regression that considers both physical and data-driven machine learning and can be used to identify the implied physical relationships and prediction equations of ground motion variables in different regions.
<div id='section'>Paperid: <span id='pid'>1598, <a href='https://arxiv.org/pdf/2303.12245.pdf' target='_blank'>https://arxiv.org/pdf/2303.12245.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanxia Qian, Yongchao Zhang, Yunqing Huang, Suchuan Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.12245">Error Analysis of Physics-Informed Neural Networks for Approximating Dynamic PDEs of Second Order in Time</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the approximation of a class of dynamic partial differential equations (PDE) of second order in time by the physics-informed neural network (PINN) approach, and provide an error analysis of PINN for the wave equation, the Sine-Gordon equation and the linear elastodynamic equation. Our analyses show that, with feed-forward neural networks having two hidden layers and the $\tanh$ activation function, the PINN approximation errors for the solution field, its time derivative and its gradient field can be effectively bounded by the training loss and the number of training data points (quadrature points). Our analyses further suggest new forms for the training loss function, which contain certain residuals that are crucial to the error estimate but would be absent from the canonical PINN loss formulation. Adopting these new forms for the loss function leads to a variant PINN algorithm. We present ample numerical experiments with the new PINN algorithm for the wave equation, the Sine-Gordon equation and the linear elastodynamic equation, which show that the method can capture the solution well.
<div id='section'>Paperid: <span id='pid'>1599, <a href='https://arxiv.org/pdf/2303.12164.pdf' target='_blank'>https://arxiv.org/pdf/2303.12164.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kian P. Abdolazizi, Kevin Linka, Christian J. Cyron
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.12164">Viscoelastic Constitutive Artificial Neural Networks (vCANNs) $-$ a framework for data-driven anisotropic nonlinear finite viscoelasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The constitutive behavior of polymeric materials is often modeled by finite linear viscoelastic (FLV) or quasi-linear viscoelastic (QLV) models. These popular models are simplifications that typically cannot accurately capture the nonlinear viscoelastic behavior of materials. For example, the success of attempts to capture strain rate-dependent behavior has been limited so far. To overcome this problem, we introduce viscoelastic Constitutive Artificial Neural Networks (vCANNs), a novel physics-informed machine learning framework for anisotropic nonlinear viscoelasticity at finite strains. vCANNs rely on the concept of generalized Maxwell models enhanced with nonlinear strain (rate)-dependent properties represented by neural networks. The flexibility of vCANNs enables them to automatically identify accurate and sparse constitutive models of a broad range of materials. To test vCANNs, we trained them on stress-strain data from Polyvinyl Butyral, the electro-active polymers VHB 4910 and 4905, and a biological tissue, the rectus abdominis muscle. Different loading conditions were considered, including relaxation tests, cyclic tension-compression tests, and blast loads. We demonstrate that vCANNs can learn to capture the behavior of all these materials accurately and computationally efficiently without human guidance.
<div id='section'>Paperid: <span id='pid'>1600, <a href='https://arxiv.org/pdf/2303.10913.pdf' target='_blank'>https://arxiv.org/pdf/2303.10913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lei Ma, Rong xin Li, Fanhai Zeng, Ling Guo, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.10913">Bi-orthogonal fPINN: A physics-informed neural network method for solving time-dependent stochastic fractional PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fractional partial differential equations (FPDEs) can effectively represent anomalous transport and nonlocal interactions. However, inherent uncertainties arise naturally in real applications due to random forcing or unknown material properties. Mathematical models considering nonlocal interactions with uncertainty quantification can be formulated as stochastic fractional partial differential equations (SFPDEs). There are many challenges in solving SFPDEs numerically, especially for long-time integration since such problems are high-dimensional and nonlocal. Here, we combine the bi-orthogonal (BO) method for representing stochastic processes with physics-informed neural networks (PINNs) for solving partial differential equations to formulate the bi-orthogonal PINN method (BO-fPINN) for solving time-dependent SFPDEs. Specifically, we introduce a deep neural network for the stochastic solution of the time-dependent SFPDEs, and include the BO constraints in the loss function following a weak formulation. Since automatic differentiation is not currently applicable to fractional derivatives, we employ discretization on a grid to to compute the fractional derivatives of the neural network output. The weak formulation loss function of the BO-fPINN method can overcome some drawbacks of the BO methods and thus can be used to solve SFPDEs with eigenvalue crossings. Moreover, the BO-fPINN method can be used for inverse SFPDEs with the same framework and same computational complexity as for forward problems. We demonstrate the effectiveness of the BO-fPINN method for different benchmark problems. The results demonstrate the flexibility and efficiency of the proposed method, especially for inverse problems.
<div id='section'>Paperid: <span id='pid'>1601, <a href='https://arxiv.org/pdf/2303.07647.pdf' target='_blank'>https://arxiv.org/pdf/2303.07647.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanxun Jin, Enrui Zhang, Horacio D. Espinosa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.07647">Recent Advances and Applications of Machine Learning in Experimental Solid Mechanics: A Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For many decades, experimental solid mechanics has played a crucial role in characterizing and understanding the mechanical properties of natural and novel materials. Recent advances in machine learning (ML) provide new opportunities for the field, including experimental design, data analysis, uncertainty quantification, and inverse problems. As the number of papers published in recent years in this emerging field is exploding, it is timely to conduct a comprehensive and up-to-date review of recent ML applications in experimental solid mechanics. Here, we first provide an overview of common ML algorithms and terminologies that are pertinent to this review, with emphasis placed on physics-informed and physics-based ML methods. Then, we provide thorough coverage of recent ML applications in traditional and emerging areas of experimental mechanics, including fracture mechanics, biomechanics, nano- and micro-mechanics, architected materials, and 2D material. Finally, we highlight some current challenges of applying ML to multi-modality and multi-fidelity experimental datasets and propose several future research directions. This review aims to provide valuable insights into the use of ML methods as well as a variety of examples for researchers in solid mechanics to integrate into their experiments.
<div id='section'>Paperid: <span id='pid'>1602, <a href='https://arxiv.org/pdf/2303.07392.pdf' target='_blank'>https://arxiv.org/pdf/2303.07392.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Pensoneault, Xueyu Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.07392">Efficient Bayesian Physics Informed Neural Networks for Inverse Problems via Ensemble Kalman Inversion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Physics Informed Neural Networks (B-PINNs) have gained significant attention for inferring physical parameters and learning the forward solutions for problems based on partial differential equations. However, the overparameterized nature of neural networks poses a computational challenge for high-dimensional posterior inference. Existing inference approaches, such as particle-based or variance inference methods, are either computationally expensive for high-dimensional posterior inference or provide unsatisfactory uncertainty estimates. In this paper, we present a new efficient inference algorithm for B-PINNs that uses Ensemble Kalman Inversion (EKI) for high-dimensional inference tasks. We find that our proposed method can achieve inference results with informative uncertainty estimates comparable to Hamiltonian Monte Carlo (HMC)-based B-PINNs with a much reduced computational cost. These findings suggest that our proposed approach has great potential for uncertainty quantification in physics-informed machine learning for practical applications.
<div id='section'>Paperid: <span id='pid'>1603, <a href='https://arxiv.org/pdf/2303.04594.pdf' target='_blank'>https://arxiv.org/pdf/2303.04594.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danyal Rehman, John H. Lienhard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.04594">Physics-constrained neural differential equations for learning multi-ionic transport</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continuum models for ion transport through polyamide nanopores require solving partial differential equations (PDEs) through complex pore geometries. Resolving spatiotemporal features at this length and time-scale can make solving these equations computationally intractable. In addition, mechanistic models frequently require functional relationships between ion interaction parameters under nano-confinement, which are often too challenging to measure experimentally or know a priori. In this work, we develop the first physics-informed deep learning model to learn ion transport behaviour across polyamide nanopores. The proposed architecture leverages neural differential equations in conjunction with classical closure models as inductive biases directly encoded into the neural framework. The neural differential equations are pre-trained on simulated data from continuum models and fine-tuned on independent experimental data to learn ion rejection behaviour. Gaussian noise augmentations from experimental uncertainty estimates are also introduced into the measured data to improve model generalization. Our approach is compared to other physics-informed deep learning models and shows strong agreement with experimental measurements across all studied datasets.
<div id='section'>Paperid: <span id='pid'>1604, <a href='https://arxiv.org/pdf/2303.01767.pdf' target='_blank'>https://arxiv.org/pdf/2303.01767.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ye Li, Song-Can Chen, Sheng-Jun Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01767">Implicit Stochastic Gradient Descent for Training Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have effectively been demonstrated in solving forward and inverse differential equation problems, but they are still trapped in training failures when the target functions to be approximated exhibit high-frequency or multi-scale features. In this paper, we propose to employ implicit stochastic gradient descent (ISGD) method to train PINNs for improving the stability of training process. We heuristically analyze how ISGD overcome stiffness in the gradient flow dynamics of PINNs, especially for problems with multi-scale solutions. We theoretically prove that for two-layer fully connected neural networks with large hidden nodes, randomly initialized ISGD converges to a globally optimal solution for the quadratic loss function. Empirical results demonstrate that ISGD works well in practice and compares favorably to other gradient-based optimization methods such as SGD and Adam, while can also effectively address the numerical stiffness in training dynamics via gradient descent.
<div id='section'>Paperid: <span id='pid'>1605, <a href='https://arxiv.org/pdf/2302.13696.pdf' target='_blank'>https://arxiv.org/pdf/2302.13696.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hankyul Koh, Joon-hyuk Ko, Wonho Jhe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.13696">Moderate Adaptive Linear Units (MoLU)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the Moderate Adaptive Linear Unit (MoLU), a novel activation function for deep neural networks, defined analytically as: f(x)=x \times (1+tanh(x))/2. MoLU combines mathematical elegance with empirical effectiveness, exhibiting superior performance in terms of prediction accuracy, convergence speed, and computational efficiency. Due to its C-infinity smoothness, i.e. infinite differentiability and analyticity, MoLU is expected to mitigate issues such as vanishing or exploding gradients, making it suitable for a broad range of architectures and applications, including large language models (LLMs), Neural Ordinary Differential Equations (Neural ODEs), Physics-Informed Neural Networks (PINNs), and Convolutional Neural Networks (CNNs). Empirical evaluations show that MoLU consistently achieves faster convergence and improved final accuracy relative to widely used activation functions such as GeLU, SiLU, and Mish. These properties position MoLU as a promising and robust candidate for general-purpose activation across diverse deep learning paradigms.
<div id='section'>Paperid: <span id='pid'>1606, <a href='https://arxiv.org/pdf/2302.13368.pdf' target='_blank'>https://arxiv.org/pdf/2302.13368.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Li, Martin Z. Bazant, Juner Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.13368">Phase-Field DeepONet: Physics-informed deep operator neural network for fast simulations of pattern formation governed by gradient flows of free-energy functionals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in scientific machine learning have shed light on the modeling of pattern-forming systems. However, simulations of real patterns still incur significant computational costs, which could be alleviated by leveraging large image datasets. Physics-informed machine learning and operator learning are two new emerging and promising concepts for this application. Here, we propose "Phase-Field DeepONet", a physics-informed operator neural network framework that predicts the dynamic responses of systems governed by gradient flows of free-energy functionals. Examples used to validate the feasibility and accuracy of the method include the Allen-Cahn and Cahn-Hilliard equations, as special cases of reactive phase-field models for nonequilibrium thermodynamics of chemical mixtures. This is achieved by incorporating the minimizing movement scheme into the framework, which optimizes and controls how the total free energy of a system evolves, instead of solving the governing equations directly. The trained operator neural networks can work as explicit time-steppers that take the current state as the input and output the next state. This could potentially facilitate fast real-time predictions of pattern-forming dynamical systems, such as phase-separating Li-ion batteries, emulsions, colloidal displays, or biological patterns.
<div id='section'>Paperid: <span id='pid'>1607, <a href='https://arxiv.org/pdf/2302.09668.pdf' target='_blank'>https://arxiv.org/pdf/2302.09668.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arunabha M. Roy, Rikhi Bose
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.09668">Physics-aware deep learning framework for linear elasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The paper presents an efficient and robust data-driven deep learning (DL) computational framework developed for linear continuum elasticity problems. The methodology is based on the fundamentals of the Physics Informed Neural Networks (PINNs). For an accurate representation of the field variables, a multi-objective loss function is proposed. It consists of terms corresponding to the residual of the governing partial differential equations (PDE), constitutive relations derived from the governing physics, various boundary conditions, and data-driven physical knowledge fitting terms across randomly selected collocation points in the problem domain. To this end, multiple densely connected independent artificial neural networks (ANNs), each approximating a field variable, are trained to obtain accurate solutions. Several benchmark problems including the Airy solution to elasticity and the Kirchhoff-Love plate problem are solved. Performance in terms of accuracy and robustness illustrates the superiority of the current framework showing excellent agreement with analytical solutions. The present work combines the benefits of the classical methods depending on the physical information available in analytical relations with the superior capabilities of the DL techniques in the data-driven construction of lightweight, yet accurate and robust neural networks. The models developed herein can significantly boost computational speed using minimal network parameters with easy adaptability in different computational platforms.
<div id='section'>Paperid: <span id='pid'>1608, <a href='https://arxiv.org/pdf/2302.08332.pdf' target='_blank'>https://arxiv.org/pdf/2302.08332.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shawn G. Rosofsky, E. A. Huerta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08332">Magnetohydrodynamics with Physics Informed Neural Operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The modeling of multi-scale and multi-physics complex systems typically involves the use of scientific software that can optimally leverage extreme scale computing. Despite major developments in recent years, these simulations continue to be computationally intensive and time consuming. Here we explore the use of AI to accelerate the modeling of complex systems at a fraction of the computational cost of classical methods, and present the first application of physics informed neural operators to model 2D incompressible magnetohydrodynamics simulations. Our AI models incorporate tensor Fourier neural operators as their backbone, which we implemented with the TensorLY package. Our results indicate that physics informed neural operators can accurately capture the physics of magnetohydrodynamics simulations that describe laminar flows with Reynolds numbers $Re\leq250$. We also explore the applicability of our AI surrogates for turbulent flows, and discuss a variety of methodologies that may be incorporated in future work to create AI models that provide a computationally efficient and high fidelity description of magnetohydrodynamics simulations for a broad range of Reynolds numbers. The scientific software developed in this project is released with this manuscript.
<div id='section'>Paperid: <span id='pid'>1609, <a href='https://arxiv.org/pdf/2302.00990.pdf' target='_blank'>https://arxiv.org/pdf/2302.00990.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ece S. Koksal, Erdal Aydin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.00990">Physics Informed Piecewise Linear Neural Networks for Process Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Constructing first-principles models is usually a challenging and time-consuming task due to the complexity of the real-life processes. On the other hand, data-driven modeling, and in particular neural network models often suffer from issues such as overfitting and lack of useful and highquality data. At the same time, embedding trained machine learning models directly into the optimization problems has become an effective and state-of-the-art approach for surrogate optimization, whose performance can be improved by physics-informed training. In this study, it is proposed to upgrade piece-wise linear neural network models with physics informed knowledge for optimization problems with neural network models embedded. In addition to using widely accepted and naturally piece-wise linear rectified linear unit (ReLU) activation functions, this study also suggests piece-wise linear approximations for the hyperbolic tangent activation function to widen the domain. Optimization of three case studies, a blending process, an industrial distillation column and a crude oil column are investigated. For all cases, physics-informed trained neural network based optimal results are closer to global optimality. Finally, associated CPU times for the optimization problems are much shorter than the standard optimization results.
<div id='section'>Paperid: <span id='pid'>1610, <a href='https://arxiv.org/pdf/2302.00100.pdf' target='_blank'>https://arxiv.org/pdf/2302.00100.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Martin Veresko, Ming-Cheng Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.00100">Physics-informed Reduced-Order Learning from the First Principles for Simulation of Quantum Nanostructures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-dimensional direct numerical simulation (DNS) of the SchrÃ¶dinger equation is needed for design and analysis of quantum nanostructures that offer numerous applications in biology, medicine, materials, electronic/photonic devices, etc. In large-scale nanostructures, extensive computational effort needed in DNS may become prohibitive due to the high degrees of freedom (DoF). This study employs a reduced-order learning algorithm, enabled by the first principles, for simulation of the SchrÃ¶dinger equation to achieve high accuracy and efficiency. The proposed simulation methodology is applied to investigate two quantum-dot structures; one operates under external electric field, and the other is influenced by internal potential variation with periodic boundary conditions. The former is similar to typical operations of nanoelectronic devices, and the latter is of interest to simulation and design of nanostructures and materials, such as applications of density functional theory. Using the proposed methodology, a very accurate prediction can be realized with a reduction in the DoF by more than 3 orders of magnitude and in the computational time by 2 orders, compared to DNS. The proposed physics-informed learning methodology is also able to offer an accurate prediction beyond the training conditions, including higher external field and larger internal potential in untrained quantum states.
<div id='section'>Paperid: <span id='pid'>1611, <a href='https://arxiv.org/pdf/2301.13262.pdf' target='_blank'>https://arxiv.org/pdf/2301.13262.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sukirt Thakur, Maziar Raissi, Harsa Mitra, Arezoo Ardekani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.13262">Temporal Consistency Loss for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have been widely used to solve partial differential equations in a forward and inverse manner using deep neural networks. However, training these networks can be challenging for multiscale problems. While statistical methods can be employed to scale the regression loss on data, it is generally challenging to scale the loss terms for equations. This paper proposes a method for scaling the mean squared loss terms in the objective function used to train PINNs. Instead of using automatic differentiation to calculate the temporal derivative, we use backward Euler discretization. This provides us with a scaling term for the equations. In this work, we consider the two and three-dimensional Navier-Stokes equations and determine the kinematic viscosity using the spatio-temporal data on the velocity and pressure fields. We first consider numerical datasets to test our method. We test the sensitivity of our method to the time step size, the number of timesteps, noise in the data, and spatial resolution. Finally, we use the velocity field obtained using Particle Image Velocimetry (PIV) experiments to generate a reference pressure field. We then test our framework using the velocity and reference pressure field.
<div id='section'>Paperid: <span id='pid'>1612, <a href='https://arxiv.org/pdf/2301.07820.pdf' target='_blank'>https://arxiv.org/pdf/2301.07820.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shashank Sule, Richard G. Spencer, Wojciech Czaja
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.07820">On the limits of neural network explainability via descrambling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We characterize the exact solutions to neural network descrambling--a mathematical model for explaining the fully connected layers of trained neural networks (NNs). By reformulating the problem to the minimization of the Brockett function arising in graph matching and complexity theory we show that the principal components of the hidden layer preactivations can be characterized as the optimal explainers or descramblers for the layer weights, leading to descrambled weight matrices. We show that in typical deep learning contexts these descramblers take diverse and interesting forms including (1) matching largest principal components with the lowest frequency modes of the Fourier basis for isotropic hidden data, (2) discovering the semantic development in two-layer linear NNs for signal recovery problems, and (3) explaining CNNs by optimally permuting the neurons. Our numerical experiments indicate that the eigendecompositions of the hidden layer data--now understood as the descramblers--can also reveal the layer's underlying transformation. These results illustrate that the SVD is more directly related to the explainability of NNs than previously thought and offers a promising avenue for discovering interpretable motifs for the hidden action of NNs, especially in contexts of operator learning or physics-informed NNs, where the input/output data has limited human readability.
<div id='section'>Paperid: <span id='pid'>1613, <a href='https://arxiv.org/pdf/2301.07609.pdf' target='_blank'>https://arxiv.org/pdf/2301.07609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Alberts, Ilias Bilionis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.07609">Physics-informed Information Field Theory for Modeling Physical Systems with Uncertainty Quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven approaches coupled with physical knowledge are powerful techniques to model systems. The goal of such models is to efficiently solve for the underlying field by combining measurements with known physical laws. As many systems contain unknown elements, such as missing parameters, noisy data, or incomplete physical laws, this is widely approached as an uncertainty quantification problem. The common techniques to handle all the variables typically depend on the numerical scheme used to approximate the posterior, and it is desirable to have a method which is independent of any such discretization. Information field theory (IFT) provides the tools necessary to perform statistics over fields that are not necessarily Gaussian. We extend IFT to physics-informed IFT (PIFT) by encoding the functional priors with information about the physical laws which describe the field. The posteriors derived from this PIFT remain independent of any numerical scheme and can capture multiple modes, allowing for the solution of problems which are ill-posed. We demonstrate our approach through an analytical example involving the Klein-Gordon equation. We then develop a variant of stochastic gradient Langevin dynamics to draw samples from the joint posterior over the field and model parameters. We apply our method to numerical examples with various degrees of model-form error and to inverse problems involving nonlinear differential equations. As an addendum, the method is equipped with a metric which allows the posterior to automatically quantify model-form uncertainty. Because of this, our numerical experiments show that the method remains robust to even an incorrect representation of the physics given sufficient data. We numerically demonstrate that the method correctly identifies when the physics cannot be trusted, in which case it automatically treats learning the field as a regression problem.
<div id='section'>Paperid: <span id='pid'>1614, <a href='https://arxiv.org/pdf/2301.07528.pdf' target='_blank'>https://arxiv.org/pdf/2301.07528.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soronzonbold Otgonbaatar, Dieter KranzlmÃ¼ller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.07528">Quantum-inspired tensor network for Earth science</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Learning (DL) is one of many successful methodologies to extract informative patterns and insights from ever increasing noisy large-scale datasets (in our case, satellite images). However, DL models consist of a few thousand to millions of training parameters, and these training parameters require tremendous amount of electrical power for extracting informative patterns from noisy large-scale datasets (e.g., computationally expensive). Hence, we employ a quantum-inspired tensor network for compressing trainable parameters of physics-informed neural networks (PINNs) in Earth science. PINNs are DL models penalized by enforcing the law of physics; in particular, the law of physics is embedded in DL models. In addition, we apply tensor decomposition to HyperSpectral Images (HSIs) to improve their spectral resolution. A quantum-inspired tensor network is also the native formulation to efficiently represent and train quantum machine learning models on big datasets on GPU tensor cores. Furthermore, the key contribution of this paper is twofold: (I) we reduced a number of trainable parameters of PINNs by using a quantum-inspired tensor network, and (II) we improved the spectral resolution of remotely-sensed images by employing tensor decomposition. As a benchmark PDE, we solved Burger's equation. As practical satellite data, we employed HSIs of Indian Pine, USA and of Pavia University, Italy.
<div id='section'>Paperid: <span id='pid'>1615, <a href='https://arxiv.org/pdf/2301.02790.pdf' target='_blank'>https://arxiv.org/pdf/2301.02790.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mayank Deshpande, Siddharth Agarwal, Vukka Snigdha, Arya Kumar Bhattacharya
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.02790">Investigations on convergence behaviour of Physics Informed Neural Networks across spectral ranges and derivative orders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An important inference from Neural Tangent Kernel (NTK) theory is the existence of spectral bias (SB), that is, low frequency components of the target function of a fully connected Artificial Neural Network (ANN) being learnt significantly faster than the higher frequencies during training. This is established for Mean Square Error (MSE) loss functions with very low learning rate parameters. Physics Informed Neural Networks (PINNs) are designed to learn the solutions of differential equations (DE) of arbitrary orders; in PINNs the loss functions are obtained as the residues of the conservative form of the DEs and represent the degree of dissatisfaction of the equations. So there has been an open question whether (a) PINNs also exhibit SB and (b) if so, how does this bias vary across the orders of the DEs. In this work, a series of numerical experiments are conducted on simple sinusoidal functions of varying frequencies, compositions and equation orders to investigate these issues. It is firmly established that under normalized conditions, PINNs do exhibit strong spectral bias, and this increases with the order of the differential equation.
<div id='section'>Paperid: <span id='pid'>1616, <a href='https://arxiv.org/pdf/2212.11776.pdf' target='_blank'>https://arxiv.org/pdf/2212.11776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thi Nguyen Khoa Nguyen, Thibault Dairay, RaphaÃ«l Meunier, Christophe Millet, Mathilde Mougeot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.11776">Fixed-budget online adaptive learning for physics-informed neural networks. Towards parameterized problem inference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have gained much attention in various fields of engineering thanks to their capability of incorporating physical laws into the models. PINNs integrate the physical constraints by minimizing the partial differential equations (PDEs) residuals on a set of collocation points. The distribution of these collocation points appears to have a huge impact on the performance of PINNs and the assessment of the sampling methods for these points is still an active topic. In this paper, we propose a Fixed-Budget Online Adaptive Learning (FBOAL) method, which decomposes the domain into sub-domains, for training collocation points based on local maxima and local minima of the PDEs residuals. The effectiveness of FBOAL is demonstrated for non-parameterized and parameterized problems. The comparison with other adaptive sampling methods is also illustrated. The numerical results demonstrate important gains in terms of the accuracy and computational cost of PINNs with FBOAL over the classical PINNs with non-adaptive collocation points. We also apply FBOAL in a complex industrial application involving coupling between mechanical and thermal fields. We show that FBOAL is able to identify the high-gradient locations and even give better predictions for some physical fields than the classical PINNs with collocation points sampled on a pre-adapted finite element mesh built thanks to numerical expert knowledge. From the present study, it is expected that the use of FBOAL will help to improve the conventional numerical solver in the construction of the mesh.
<div id='section'>Paperid: <span id='pid'>1617, <a href='https://arxiv.org/pdf/2212.08989.pdf' target='_blank'>https://arxiv.org/pdf/2212.08989.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Loc Vu-Quoc, Alexander Humer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.08989">Deep learning applied to computational mechanics: A comprehensive review, state of the art, and the classics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Three recent breakthroughs due to AI in arts and science serve as motivation: An award winning digital image, protein folding, fast matrix multiplication. Many recent developments in artificial neural networks, particularly deep learning (DL), applied and relevant to computational mechanics (solid, fluids, finite-element technology) are reviewed in detail. Both hybrid and pure machine learning (ML) methods are discussed. Hybrid methods combine traditional PDE discretizations with ML methods either (1) to help model complex nonlinear constitutive relations, (2) to nonlinearly reduce the model order for efficient simulation (turbulence), or (3) to accelerate the simulation by predicting certain components in the traditional integration methods. Here, methods (1) and (2) relied on Long-Short-Term Memory (LSTM) architecture, with method (3) relying on convolutional neural networks. Pure ML methods to solve (nonlinear) PDEs are represented by Physics-Informed Neural network (PINN) methods, which could be combined with attention mechanism to address discontinuous solutions. Both LSTM and attention architectures, together with modern and generalized classic optimizers to include stochasticity for DL networks, are extensively reviewed. Kernel machines, including Gaussian processes, are provided to sufficient depth for more advanced works such as shallow networks with infinite width. Not only addressing experts, readers are assumed familiar with computational mechanics, but not with DL, whose concepts and applications are built up from the basics, aiming at bringing first-time learners quickly to the forefront of research. History and limitations of AI are recounted and discussed, with particular attention at pointing out misstatements or misconceptions of the classics, even in well-known references. Positioning and pointing control of a large-deformable beam is given as an example.
<div id='section'>Paperid: <span id='pid'>1618, <a href='https://arxiv.org/pdf/2212.08965.pdf' target='_blank'>https://arxiv.org/pdf/2212.08965.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Salah A Faroughi, Ramin Soltanmohammad, Pingki Datta, Seyed Kourosh Mahjour, Shirko Faroughi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.08965">Physics-informed Neural Networks with Periodic Activation Functions for Solute Transport in Heterogeneous Porous Media</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulating solute transport in heterogeneous porous media poses computational challenges due to the high-resolution meshing required for traditional solvers. To overcome these challenges, this study explores a mesh-free method based on deep learning to accelerate solute transport simulation. We employ Physics-informed Neural Networks (PiNN) with a periodic activation function to solve solute transport problems in both homogeneous and heterogeneous porous media governed by the advection-dispersion equation. Unlike traditional neural networks that rely on large training datasets, PiNNs use strong-form mathematical models to constrain the network in the training phase and simultaneously solve for multiple dependent or independent field variables, such as pressure and solute concentration fields. To demonstrate the effectiveness of using PiNNs with a periodic activation function to resolve solute transport in porous media, we construct PiNNs using two activation functions, sin and tanh, for seven case studies, including 1D and 2D scenarios. The accuracy of the PiNNs' predictions is then evaluated using absolute point error and mean square error metrics and compared to the ground truth solutions obtained analytically or numerically. Our results demonstrate that the PiNN with sin activation function, compared to tanh activation function, is up to two orders of magnitude more accurate and up to two times faster to train, especially in heterogeneous porous media. Moreover, PiNN's simultaneous predictions of pressure and concentration fields can reduce computational expenses in terms of inference time by three orders of magnitude compared to FEM simulations for two-dimensional cases.
<div id='section'>Paperid: <span id='pid'>1619, <a href='https://arxiv.org/pdf/2212.07462.pdf' target='_blank'>https://arxiv.org/pdf/2212.07462.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Atiyo Ghosh, Antonio A. Gentile, Mario Dagrada, Chul Lee, Seong-Hyok Kim, Hyukgeun Cha, Yunjun Choi, Brad Kim, Jeong-Il Kye, Vincent E. Elfving
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.07462">Harmonic (Quantum) Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Harmonic functions are abundant in nature, appearing in limiting cases of Maxwell's, Navier-Stokes equations, the heat and the wave equation. Consequently, there are many applications of harmonic functions from industrial process optimisation to robotic path planning and the calculation of first exit times of random walks. Despite their ubiquity and relevance, there have been few attempts to incorporate inductive biases towards harmonic functions in machine learning contexts. In this work, we demonstrate effective means of representing harmonic functions in neural networks and extend such results also to quantum neural networks to demonstrate the generality of our approach. We benchmark our approaches against (quantum) physics-informed neural networks, where we show favourable performance.
<div id='section'>Paperid: <span id='pid'>1620, <a href='https://arxiv.org/pdf/2212.04487.pdf' target='_blank'>https://arxiv.org/pdf/2212.04487.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Francesco Zanetta, Daniele Nerini, Tom Beucler, Mark A. Liniger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.04487">Physics-constrained deep learning postprocessing of temperature and humidity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Weather forecasting centers currently rely on statistical postprocessing methods to minimize forecast error. This improves skill but can lead to predictions that violate physical principles or disregard dependencies between variables, which can be problematic for downstream applications and for the trustworthiness of postprocessing models, especially when they are based on new machine learning approaches. Building on recent advances in physics-informed machine learning, we propose to achieve physical consistency in deep learning-based postprocessing models by integrating meteorological expertise in the form of analytic equations. Applied to the post-processing of surface weather in Switzerland, we find that constraining a neural network to enforce thermodynamic state equations yields physically-consistent predictions of temperature and humidity without compromising performance. Our approach is especially advantageous when data is scarce, and our findings suggest that incorporating domain expertise into postprocessing models allows to optimize weather forecast information while satisfying application-specific requirements.
<div id='section'>Paperid: <span id='pid'>1621, <a href='https://arxiv.org/pdf/2211.12986.pdf' target='_blank'>https://arxiv.org/pdf/2211.12986.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steffen Limmer, Alberto Martinez Alba, Nicola Michailow
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.12986">Physics-informed neural networks for pathloss prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a physics-informed machine learning approach for pathloss prediction. This is achieved by including in the training phase simultaneously (i) physical dependencies between spatial loss field and (ii) measured pathloss values in the field. It is shown that the solution to a proposed learning problem improves generalization and prediction quality with a small number of neural network layers and parameters. The latter leads to fast inference times which are favorable for downstream tasks such as localization. Moreover, the physics-informed formulation allows training and prediction with a small amount of training data which makes it appealing for a wide range of practical pathloss prediction scenarios.
<div id='section'>Paperid: <span id='pid'>1622, <a href='https://arxiv.org/pdf/2211.07377.pdf' target='_blank'>https://arxiv.org/pdf/2211.07377.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Salah A Faroughi, Nikhil Pawar, Celio Fernandes, Maziar Raissi, Subasish Das, Nima K. Kalantari, Seyed Kourosh Mahjour
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.07377">Physics-Guided, Physics-Informed, and Physics-Encoded Neural Networks in Scientific Computing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent breakthroughs in computing power have made it feasible to use machine learning and deep learning to advance scientific computing in many fields, including fluid mechanics, solid mechanics, materials science, etc. Neural networks, in particular, play a central role in this hybridization. Due to their intrinsic architecture, conventional neural networks cannot be successfully trained and scoped when data is sparse, which is the case in many scientific and engineering domains. Nonetheless, neural networks provide a solid foundation to respect physics-driven or knowledge-based constraints during training. Generally speaking, there are three distinct neural network frameworks to enforce the underlying physics: (i) physics-guided neural networks (PgNNs), (ii) physics-informed neural networks (PiNNs), and (iii) physics-encoded neural networks (PeNNs). These methods provide distinct advantages for accelerating the numerical modeling of complex multiscale multi-physics phenomena. In addition, the recent developments in neural operators (NOs) add another dimension to these new simulation paradigms, especially when the real-time prediction of complex multi-physics systems is required. All these models also come with their own unique drawbacks and limitations that call for further fundamental research. This study aims to present a review of the four neural network frameworks (i.e., PgNNs, PiNNs, PeNNs, and NOs) used in scientific computing research. The state-of-the-art architectures and their applications are reviewed, limitations are discussed, and future research opportunities in terms of improving algorithms, considering causalities, expanding applications, and coupling scientific and deep learning solvers are presented. This critical review provides researchers and engineers with a solid starting point to comprehend how to integrate different layers of physics into neural networks.
<div id='section'>Paperid: <span id='pid'>1623, <a href='https://arxiv.org/pdf/2211.06860.pdf' target='_blank'>https://arxiv.org/pdf/2211.06860.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>C G Krishnanunni, Tan Bui-Thanh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.06860">An Adaptive and Stability-Promoting Layerwise Training Approach for Sparse Deep Neural Network Architecture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents a two-stage adaptive framework for progressively developing deep neural network (DNN) architectures that generalize well for a given training data set. In the first stage, a layerwise training approach is adopted where a new layer is added each time and trained independently by freezing parameters in the previous layers. We impose desirable structures on the DNN by employing manifold regularization, sparsity regularization, and physics-informed terms. We introduce a epsilon-delta stability-promoting concept as a desirable property for a learning algorithm and show that employing manifold regularization yields a epsilon-delta stability-promoting algorithm. Further, we also derive the necessary conditions for the trainability of a newly added layer and investigate the training saturation problem. In the second stage of the algorithm (post-processing), a sequence of shallow networks is employed to extract information from the residual produced in the first stage, thereby improving the prediction accuracy. Numerical investigations on prototype regression and classification problems demonstrate that the proposed approach can outperform fully connected DNNs of the same size. Moreover, by equipping the physics-informed neural network (PINN) with the proposed adaptive architecture strategy to solve partial differential equations, we numerically show that adaptive PINNs not only are superior to standard PINNs but also produce interpretable hidden layers with provable stability. We also apply our architecture design strategy to solve inverse problems governed by elliptic partial differential equations.
<div id='section'>Paperid: <span id='pid'>1624, <a href='https://arxiv.org/pdf/2211.01567.pdf' target='_blank'>https://arxiv.org/pdf/2211.01567.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianao Li, Emma Alexander
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.01567">Galaxy Image Deconvolution for Weak Gravitational Lensing with Unrolled Plug-and-Play ADMM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Removing optical and atmospheric blur from galaxy images significantly improves galaxy shape measurements for weak gravitational lensing and galaxy evolution studies. This ill-posed linear inverse problem is usually solved with deconvolution algorithms enhanced by regularisation priors or deep learning. We introduce a so-called "physics-informed deep learning" approach to the Point Spread Function (PSF) deconvolution problem in galaxy surveys. We apply algorithm unrolling and the Plug-and-Play technique to the Alternating Direction Method of Multipliers (ADMM), in which a neural network learns appropriate hyperparameters and denoising priors from simulated galaxy images. We characterise the time-performance trade-off of several methods for galaxies of differing brightness levels as well as our method's robustness to systematic PSF errors and network ablations. We show an improvement in reduced shear ellipticity error of 38.6% (SNR=20)/45.0% (SNR=200) compared to classic methods and 7.4% (SNR=20)/33.2% (SNR=200) compared to modern methods.
<div id='section'>Paperid: <span id='pid'>1625, <a href='https://arxiv.org/pdf/2210.12177.pdf' target='_blank'>https://arxiv.org/pdf/2210.12177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Mavi, A. C. Bekar, E. Haghighat, E. Madenci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.12177">An unsupervised latent/output physics-informed convolutional-LSTM network for solving partial differential equations using peridynamic differential operator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a novel unsupervised convolutional Neural Network (NN) architecture with nonlocal interactions for solving Partial Differential Equations (PDEs). The nonlocal Peridynamic Differential Operator (PDDO) is employed as a convolutional filter for evaluating derivatives the field variable. The NN captures the time-dynamics in smaller latent space through encoder-decoder layers with a Convolutional Long-short Term Memory (ConvLSTM) layer between them. The ConvLSTM architecture is modified by employing a novel activation function to improve the predictive capability of the learning architecture for physics with periodic behavior. The physics is invoked in the form of governing equations at the output of the NN and in the latent (reduced) space. By considering a few benchmark PDEs, we demonstrate the training performance and extrapolation capability of this novel NN architecture by comparing against Physics Informed Neural Networks (PINN) type solvers. It is more capable of extrapolating the solution for future timesteps than the other existing architectures.
<div id='section'>Paperid: <span id='pid'>1626, <a href='https://arxiv.org/pdf/2210.04338.pdf' target='_blank'>https://arxiv.org/pdf/2210.04338.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Suchuan Dong, Yiran Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.04338">A Method for Computing Inverse Parametric PDE Problems with Random-Weight Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a method for computing the inverse parameters and the solution field to inverse parametric PDEs based on randomized neural networks. This extends the local extreme learning machine technique originally developed for forward PDEs to inverse problems. We develop three algorithms for training the neural network to solve the inverse PDE problem. The first algorithm (NLLSQ) determines the inverse parameters and the trainable network parameters all together by the nonlinear least squares method with perturbations (NLLSQ-perturb). The second algorithm (VarPro-F1) eliminates the inverse parameters from the overall problem by variable projection to attain a reduced problem about the trainable network parameters only. It solves the reduced problem first by the NLLSQ-perturb algorithm for the trainable network parameters, and then computes the inverse parameters by the linear least squares method. The third algorithm (VarPro-F2) eliminates the trainable network parameters from the overall problem by variable projection to attain a reduced problem about the inverse parameters only. It solves the reduced problem for the inverse parameters first, and then computes the trainable network parameters afterwards. VarPro-F1 and VarPro-F2 are reciprocal to each other in a sense. The presented method produces accurate results for inverse PDE problems, as shown by the numerical examples herein. For noise-free data, the errors for the inverse parameters and the solution field decrease exponentially as the number of collocation points or the number of trainable network parameters increases, and can reach a level close to the machine accuracy. For noisy data, the accuracy degrades compared with the case of noise-free data, but the method remains quite accurate. The presented method has been compared with the physics-informed neural network method.
<div id='section'>Paperid: <span id='pid'>1627, <a href='https://arxiv.org/pdf/2210.00042.pdf' target='_blank'>https://arxiv.org/pdf/2210.00042.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Divakar Vashisth, Tapan Mukerji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.00042">Direct Estimation of Porosity from Seismic Data using Rock and Wave Physics Informed Neural Networks (RW-PINN)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Petrophysical inversion is an important aspect of reservoir modeling. However due to the lack of a unique and straightforward relationship between seismic traces and rock properties, predicting petrophysical properties directly from seismic data is a complex task. Many studies have attempted to identify the direct end-to-end link using supervised machine learning techniques, but face different challenges such as a lack of large petrophysical training dataset or estimates that may not conform with physics or depositional history of the rocks. We present a rock and wave physics informed neural network (RW-PINN) model that can estimate porosity directly from seismic image traces with no or limited number of wells, with predictions that are consistent with rock physics and geologic knowledge of deposition. As an example, we use the uncemented sand rock physics model and normal-incidence wave physics to guide the learning of RW-PINN to eventually get good estimates of porosities from normal-incidence seismic traces and limited well data. Training RW-PINN with few wells (weakly supervised) helps in tackling the problem of non-uniqueness as different porosity logs can give similar seismic traces. We use weighted normalized root mean square error loss function to train the weakly supervised network and demonstrate the impact of different weights on porosity predictions. The RW-PINN estimated porosities and seismic traces are compared to predictions from a completely supervised model, which gives slightly better porosity estimates but poorly matches the seismic traces, in addition to requiring a large amount of labeled training data. In this paper, we demonstrate the complete workflow for executing petrophysical inversion of seismic data using self-supervised or weakly supervised rock physics informed neural networks.
<div id='section'>Paperid: <span id='pid'>1628, <a href='https://arxiv.org/pdf/2209.11929.pdf' target='_blank'>https://arxiv.org/pdf/2209.11929.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruimeng Hu, Quyuan Lin, Alan Raydan, Sui Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.11929">Higher-Order error estimates for physics-informed neural networks approximating the primitive equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large-scale dynamics of the oceans and the atmosphere are governed by primitive equations (PEs). Due to the nonlinearity and nonlocality, the numerical study of the PEs is generally challenging. Neural networks have been shown to be a promising machine learning tool to tackle this challenge. In this work, we employ physics-informed neural networks (PINNs) to approximate the solutions to the PEs and study the error estimates. We first establish the higher-order regularity for the global solutions to the PEs with either full viscosity and diffusivity, or with only the horizontal ones. Such a result for the case with only the horizontal ones is new and required in the analysis under the PINNs framework. Then we prove the existence of two-layer tanh PINNs of which the corresponding training error can be arbitrarily small by taking the width of PINNs to be sufficiently wide, and the error between the true solution and its approximation can be arbitrarily small provided that the training error is small enough and the sample set is large enough. In particular, all the estimates are a priori, and our analysis includes higher-order (in spatial Sobolev norm) error estimates. Numerical results on prototype systems are presented to further illustrate the advantage of using the $H^s$ norm during the training.
<div id='section'>Paperid: <span id='pid'>1629, <a href='https://arxiv.org/pdf/2209.11355.pdf' target='_blank'>https://arxiv.org/pdf/2209.11355.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Justice Mason, Christine Allen-Blanchette, Nicholas Zolman, Elizabeth Davison, Naomi Leonard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.11355">Learning Interpretable Dynamics from Images of a Freely Rotating 3D Rigid Body</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many real-world settings, image observations of freely rotating 3D rigid bodies, such as satellites, may be available when low-dimensional measurements are not. However, the high-dimensionality of image data precludes the use of classical estimation techniques to learn the dynamics and a lack of interpretability reduces the usefulness of standard deep learning methods. In this work, we present a physics-informed neural network model to estimate and predict 3D rotational dynamics from image sequences. We achieve this using a multi-stage prediction pipeline that maps individual images to a latent representation homeomorphic to $\mathbf{SO}(3)$, computes angular velocities from latent pairs, and predicts future latent states using the Hamiltonian equations of motion with a learned representation of the Hamiltonian. We demonstrate the efficacy of our approach on a new rotating rigid-body dataset with sequences of rotating cubes and rectangular prisms with uniform and non-uniform density.
<div id='section'>Paperid: <span id='pid'>1630, <a href='https://arxiv.org/pdf/2209.07492.pdf' target='_blank'>https://arxiv.org/pdf/2209.07492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sourav Halder, Ethan M. Johnson, Jun Yamasaki, Peter J. Kahrilas, Michael Markl, John E. Pandolfino, Neelesh A. Patankar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.07492">MRI-MECH: Mechanics-informed MRI to estimate esophageal health</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamic magnetic resonance imaging (MRI) is a popular medical imaging technique to generate image sequences of the flow of a contrast material inside tissues and organs. However, its application to imaging bolus movement through the esophagus has only been demonstrated in few feasibility studies and is relatively unexplored. In this work, we present a computational framework called mechanics-informed MRI (MRI-MECH) that enhances that capability thereby increasing the applicability of dynamic MRI for diagnosing esophageal disorders. Pineapple juice was used as the swallowed contrast material for the dynamic MRI and the MRI image sequence was used as input to the MRI-MECH. The MRI-MECH modeled the esophagus as a flexible one-dimensional tube and the elastic tube walls followed a linear tube law. Flow through the esophagus was then governed by one-dimensional mass and momentum conservation equations. These equations were solved using a physics-informed neural network (PINN). The PINN minimized the difference between the measurements from the MRI and model predictions ensuring that the physics of the fluid flow problem was always followed. MRI-MECH calculated the fluid velocity and pressure during esophageal transit and estimated the mechanical health of the esophagus by calculating wall stiffness and active relaxation. Additionally, MRI-MECH predicted missing information about the lower esophageal sphincter during the emptying process, demonstrating its applicability to scenarios with missing data or poor image resolution. In addition to potentially improving clinical decisions based on quantitative estimates of the mechanical health of the esophagus, MRI-MECH can also be enhanced for application to other medical imaging modalities to enhance their functionality as well.
<div id='section'>Paperid: <span id='pid'>1631, <a href='https://arxiv.org/pdf/2209.06257.pdf' target='_blank'>https://arxiv.org/pdf/2209.06257.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liron Simon Keren, Alex Liberzon, Teddy Lazebnik
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.06257">A computational framework for physics-informed symbolic regression with straightforward integration of domain knowledge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Discovering a meaningful symbolic expression that explains experimental data is a fundamental challenge in many scientific fields. We present a novel, open-source computational framework called Scientist-Machine Equation Detector (SciMED), which integrates scientific discipline wisdom in a scientist-in-the-loop approach, with state-of-the-art symbolic regression (SR) methods. SciMED combines a wrapper selection method, that is based on a genetic algorithm, with automatic machine learning and two levels of SR methods. We test SciMED on five configurations of a settling sphere, with and without aerodynamic non-linear drag force, and with excessive noise in the measurements. We show that SciMED is sufficiently robust to discover the correct physically meaningful symbolic expressions from the data, and demonstrate how the integration of domain knowledge enhances its performance. Our results indicate better performance on these tasks than the state-of-the-art SR software packages , even in cases where no knowledge is integrated. Moreover, we demonstrate how SciMED can alert the user about possible missing features, unlike the majority of current SR systems.
<div id='section'>Paperid: <span id='pid'>1632, <a href='https://arxiv.org/pdf/2209.03276.pdf' target='_blank'>https://arxiv.org/pdf/2209.03276.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Danial Amini, Ehsan Haghighat, Ruben Juanes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.03276">Inverse modeling of nonisothermal multiphase poromechanics using physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a solution strategy for parameter identification in multiphase thermo-hydro-mechanical (THM) processes in porous media using physics-informed neural networks (PINNs). We employ a dimensionless form of the THM governing equations that is particularly well suited for the inverse problem, and we leverage the sequential multiphysics PINN solver we developed in previous work. We validate the proposed inverse-modeling approach on multiple benchmark problems, including Terzaghi's isothermal consolidation problem, Barry-Mercer's isothermal injection-production problem, and nonisothermal consolidation of an unsaturated soil layer. We report the excellent performance of the proposed sequential PINN-THM inverse solver, thus paving the way for the application of PINNs to inverse modeling of complex nonlinear multiphysics problems.
<div id='section'>Paperid: <span id='pid'>1633, <a href='https://arxiv.org/pdf/2209.02772.pdf' target='_blank'>https://arxiv.org/pdf/2209.02772.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Kaltenbach, Paris Perdikaris, Phaedon-Stelios Koutsourelakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.02772">Semi-supervised Invertible Neural Operators for Bayesian Inverse Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural Operators offer a powerful, data-driven tool for solving parametric PDEs as they can represent maps between infinite-dimensional function spaces. In this work, we employ physics-informed Neural Operators in the context of high-dimensional, Bayesian inverse problems. Traditional solution strategies necessitate an enormous, and frequently infeasible, number of forward model solves, as well as the computation of parametric derivatives. In order to enable efficient solutions, we extend Deep Operator Networks (DeepONets) by employing a RealNVP architecture which yields an invertible and differentiable map between the parametric input and the branch-net output. This allows us to construct accurate approximations of the full posterior, irrespective of the number of observations and the magnitude of the observation noise, without any need for additional forward solves nor for cumbersome, iterative sampling procedures. We demonstrate the efficacy and accuracy of the proposed methodology in the context of inverse problems for three benchmarks: an anti-derivative equation, reaction-diffusion dynamics and flow through porous media.
<div id='section'>Paperid: <span id='pid'>1634, <a href='https://arxiv.org/pdf/2208.04319.pdf' target='_blank'>https://arxiv.org/pdf/2208.04319.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Longxiang Jiang, Liyuan Wang, Xinkun Chu, Yonghao Xiao, Hao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.04319">PhyGNNet: Solving spatiotemporal PDEs with Physics-informed Graph Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving partial differential equations (PDEs) is an important research means in the fields of physics, biology, and chemistry. As an approximate alternative to numerical methods, PINN has received extensive attention and played an important role in many fields. However, PINN uses a fully connected network as its model, which has limited fitting ability and limited extrapolation ability in both time and space. In this paper, we propose PhyGNNet for solving partial differential equations on the basics of a graph neural network which consists of encoder, processer, and decoder blocks. In particular, we divide the computing area into regular grids, define partial differential operators on the grids, then construct pde loss for the network to optimize to build PhyGNNet model. What's more, we conduct comparative experiments on Burgers equation and heat equation to validate our approach, the results show that our method has better fit ability and extrapolation ability both in time and spatial areas compared with PINN.
<div id='section'>Paperid: <span id='pid'>1635, <a href='https://arxiv.org/pdf/2207.01466.pdf' target='_blank'>https://arxiv.org/pdf/2207.01466.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexandros Kontogiannis, Matthew P. Juniper
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.01466">Physics-informed compressed sensing for PC-MRI: an inverse Navier-Stokes problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We formulate a physics-informed compressed sensing (PICS) method for the reconstruction of velocity fields from noisy and sparse phase-contrast magnetic resonance signals. The method solves an inverse Navier-Stokes boundary value problem, which permits us to jointly reconstruct and segment the velocity field, and at the same time infer hidden quantities such as the hydrodynamic pressure and the wall shear stress. Using a Bayesian framework, we regularize the problem by introducing a priori information about the unknown parameters in the form of Gaussian random fields. This prior information is updated using the Navier-Stokes problem, an energy-based segmentation functional, and by requiring that the reconstruction is consistent with the $k$-space signals. We create an algorithm that solves this reconstruction problem, and test it for noisy and sparse $k$-space signals of the flow through a converging nozzle. We find that the method is capable of reconstructing and segmenting the velocity fields from sparsely-sampled (15% $k$-space coverage), low ($\sim$$10$) signal-to-noise ratio (SNR) signals, and that the reconstructed velocity field compares well with that derived from fully-sampled (100% $k$-space coverage) high ($>40$) SNR signals of the same flow.
<div id='section'>Paperid: <span id='pid'>1636, <a href='https://arxiv.org/pdf/2206.08201.pdf' target='_blank'>https://arxiv.org/pdf/2206.08201.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michail Spitieris, Ingelin Steinsland
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.08201">Learning Physics between Digital Twins with Low-Fidelity Models and Physics-Informed Gaussian Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A digital twin is a computer model that represents an individual, for example, a component, a patient or a process. In many situations, we want to gain knowledge about an individual from its data while incorporating imperfect physical knowledge and also learn from data from other individuals. In this paper, we introduce a fully Bayesian methodology for learning between digital twins in a setting where the physical parameters of each individual are of interest. A model discrepancy term is incorporated in the model formulation of each personalized model to account for the missing physics of the low-fidelity model. To allow sharing of information between individuals, we introduce a Bayesian Hierarchical modelling framework where the individual models are connected through a new level in the hierarchy. Our methodology is demonstrated in two case studies, a toy example previously used in the literature extended to more individuals and a cardiovascular model relevant for the treatment of Hypertension. The case studies show that 1) models not accounting for imperfect physical models are biased and over-confident, 2) the models accounting for imperfect physical models are more uncertain but cover the truth, 3) the models learning between digital twins have less uncertainty than the corresponding independent individual models, but are not over-confident.
<div id='section'>Paperid: <span id='pid'>1637, <a href='https://arxiv.org/pdf/2206.07756.pdf' target='_blank'>https://arxiv.org/pdf/2206.07756.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuheng Liao, Tianju Xue, Jihoon Jeong, Samantha Webster, Kornel Ehmann, Jian Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.07756">Hybrid thermal modeling of additive manufacturing processes using physics-informed neural networks for temperature prediction and parameter identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding the thermal behavior of additive manufacturing (AM) processes is crucial for enhancing the quality control and enabling customized process design. Most purely physics-based computational models suffer from intensive computational costs and the need of calibrating unknown parameters, thus not suitable for online control and iterative design application. Data-driven models taking advantage of the latest developed computational tools can serve as a more efficient surrogate, but they are usually trained over a large amount of simulation data and often fail to effectively use small but high-quality experimental data. In this work, we developed a hybrid physics-based data-driven thermal modeling approach of AM processes using physics-informed neural networks. Specifically, partially observed temperature data measured from an infrared camera is combined with the physics laws to predict full-field temperature history and to discover unknown material and process parameters. In the numerical and experimental examples, the effectiveness of adding auxiliary training data and using the pretrained model on training efficiency and prediction accuracy, as well as the ability to identify unknown parameters with partially observed data, are demonstrated. The results show that the hybrid thermal model can effectively identify unknown parameters and capture the full-field temperature accurately, and thus it has the potential to be used in iterative process design and real-time process control of AM.
<div id='section'>Paperid: <span id='pid'>1638, <a href='https://arxiv.org/pdf/2206.06789.pdf' target='_blank'>https://arxiv.org/pdf/2206.06789.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rabab Haider, Anuradha M. Annaswamy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.06789">Grid-SiPhyR: An end-to-end learning to optimize framework for combinatorial problems in power systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mixed integer problems are ubiquitous in decision making, from discrete device settings and design parameters, unit production, and on/off or yes/no decision in switches, routing, and social networks. Despite their prevalence, classical optimization approaches for combinatorial optimization remain prohibitively slow for fast and accurate decision making in dynamic and safety-critical environments with hard constraints. To address this gap, we propose SiPhyR (pronounced: cipher), a physics-informed machine learning framework for end-to-end learning to optimize for combinatorial problems. SiPhyR employs a novel physics-informed rounding approach to tackle the challenge of combinatorial optimization within a differentiable framework that has certified satisfiability of safety-critical constraints. We demonstrate the effectiveness of SiPhyR on an emerging paradigm for clean energy systems: dynamic reconfiguration, where the topology of the electric grid and power flow are optimized so as to maintain a safe and reliable power grid in the presence of intermittent renewable generation. Offline training of the unsupervised framework on representative load and generation data makes dynamic decision making via the online application of Grid-SiPhyR computationally feasible.
<div id='section'>Paperid: <span id='pid'>1639, <a href='https://arxiv.org/pdf/2206.01495.pdf' target='_blank'>https://arxiv.org/pdf/2206.01495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew R Jones, Timothy J Rogers, Elizabeth J Cross
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.01495">Constraining Gaussian processes for physics-informed acoustic emission mapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The automated localisation of damage in structures is a challenging but critical ingredient in the path towards predictive or condition-based maintenance of high value structures. The use of acoustic emission time of arrival mapping is a promising approach to this challenge, but is severely hindered by the need to collect a dense set of artificial acoustic emission measurements across the structure, resulting in a lengthy and often impractical data acquisition process. In this paper, we consider the use of physics-informed Gaussian processes for learning these maps to alleviate this problem. In the approach, the Gaussian process is constrained to the physical domain such that information relating to the geometry and boundary conditions of the structure are embedded directly into the learning process, returning a model that guarantees that any predictions made satisfy physically-consistent behaviour at the boundary. A number of scenarios that arise when training measurement acquisition is limited, including where training data are sparse, and also of limited coverage over the structure of interest. Using a complex plate-like structure as an experimental case study, we show that our approach significantly reduces the burden of data collection, where it is seen that incorporation of boundary condition knowledge significantly improves predictive accuracy as training observations are reduced, particularly when training measurements are not available across all parts of the structure.
<div id='section'>Paperid: <span id='pid'>1640, <a href='https://arxiv.org/pdf/2205.14439.pdf' target='_blank'>https://arxiv.org/pdf/2205.14439.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Izzatullah, Isa Eren Yildirim, Umair Bin Waheed, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.14439">Laplace HypoPINN: Physics-Informed Neural Network for hypocenter localization and its predictive uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Several techniques have been proposed over the years for automatic hypocenter localization. While those techniques have pros and cons that trade-off computational efficiency and the susceptibility of getting trapped in local minima, an alternate approach is needed that allows robust localization performance and holds the potential to make the elusive goal of real-time microseismic monitoring possible. Physics-informed neural networks (PINNs) have appeared on the scene as a flexible and versatile framework for solving partial differential equations (PDEs) along with the associated initial or boundary conditions. We develop HypoPINN -- a PINN-based inversion framework for hypocenter localization and introduce an approximate Bayesian framework for estimating its predictive uncertainties. This work focuses on predicting the hypocenter locations using HypoPINN and investigates the propagation of uncertainties from the random realizations of HypoPINN's weights and biases using the Laplace approximation. We train HypoPINN to obtain the optimized weights for predicting hypocenter location. Next, we approximate the covariance matrix at the optimized HypoPINN's weights for posterior sampling with the Laplace approximation. The posterior samples represent various realizations of HypoPINN's weights. Finally, we predict the locations of the hypocenter associated with those weights' realizations to investigate the uncertainty propagation that comes from those realisations. We demonstrate the features of this methodology through several numerical examples, including using the Otway velocity model based on the Otway project in Australia.
<div id='section'>Paperid: <span id='pid'>1641, <a href='https://arxiv.org/pdf/2205.09332.pdf' target='_blank'>https://arxiv.org/pdf/2205.09332.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ramansh Sharma, Varun Shankar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.09332">Accelerated Training of Physics-Informed Neural Networks (PINNs) using Meshless Discretizations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a new technique for the accelerated training of physics-informed neural networks (PINNs): discretely-trained PINNs (DT-PINNs). The repeated computation of partial derivative terms in the PINN loss functions via automatic differentiation during training is known to be computationally expensive, especially for higher-order derivatives. DT-PINNs are trained by replacing these exact spatial derivatives with high-order accurate numerical discretizations computed using meshless radial basis function-finite differences (RBF-FD) and applied via sparse-matrix vector multiplication. The use of RBF-FD allows for DT-PINNs to be trained even on point cloud samples placed on irregular domain geometries. Additionally, though traditional PINNs (vanilla-PINNs) are typically stored and trained in 32-bit floating-point (fp32) on the GPU, we show that for DT-PINNs, using fp64 on the GPU leads to significantly faster training times than fp32 vanilla-PINNs with comparable accuracy. We demonstrate the efficiency and accuracy of DT-PINNs via a series of experiments. First, we explore the effect of network depth on both numerical and automatic differentiation of a neural network with random weights and show that RBF-FD approximations of third-order accuracy and above are more efficient while being sufficiently accurate. We then compare the DT-PINNs to vanilla-PINNs on both linear and nonlinear Poisson equations and show that DT-PINNs achieve similar losses with 2-4x faster training times on a consumer GPU. Finally, we also demonstrate that similar results can be obtained for the PINN solution to the heat equation (a space-time problem) by discretizing the spatial derivatives using RBF-FD and using automatic differentiation for the temporal derivative. Our results show that fp64 DT-PINNs offer a superior cost-accuracy profile to fp32 vanilla-PINNs.
<div id='section'>Paperid: <span id='pid'>1642, <a href='https://arxiv.org/pdf/2205.05710.pdf' target='_blank'>https://arxiv.org/pdf/2205.05710.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yue Lu, Gang Mei, Francesco Piccialli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.05710">A Deep Learning Approach for Predicting Two-dimensional Soil Consolidation Using Physics-Informed Neural Networks (PINN)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Soil consolidation is closely related to seepage, stability, and settlement of geotechnical buildings and foundations, and directly affects the use and safety of superstructures. Nowadays, the unidirectional consolidation theory of soils is widely used in certain conditions and approximate calculations. The multi-directional theory of soil consolidation is more reasonable than the unidirectional theory in practical applications, but it is much more complicated in terms of index determination and solution. To address the above problem, in this paper, we propose a deep learning method using physics-informed neural networks (PINN) to predict the excess pore water pressure of two-dimensional soil consolidation. In the proposed method, (1) a fully connected neural network is constructed, (2) the computational domain, partial differential equation (PDE), and constraints are defined to generate data for model training, and (3) the PDE of two-dimensional soil consolidation and the model of the neural network is connected to reduce the loss of the model. The effectiveness of the proposed method is verified by comparison with the numerical solution of PDE for two-dimensional consolidation. Using this method, the excess pore water pressure could be predicted simply and efficiently. In addition, the method was applied to predict the soil excess pore water pressure in the foundation in a real case at Tianjin port, China. The proposed deep learning approach can be used to investigate the large and complex multi-directional soil consolidation.
<div id='section'>Paperid: <span id='pid'>1643, <a href='https://arxiv.org/pdf/2205.03508.pdf' target='_blank'>https://arxiv.org/pdf/2205.03508.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiang Zheng, Xiaoguang Yin, Dongxiao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.03508">Inferring electrochemical performance and parameters of Li-ion batteries based on deep operator networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Li-ion battery is a complex physicochemical system that generally takes applied current as input and terminal voltage as output. The mappings from current to voltage can be described by several kinds of models, such as accurate but inefficient physics-based models, and efficient but sometimes inaccurate equivalent circuit and black-box models. To realize accuracy and efficiency simultaneously in battery modeling, we propose to build a data-driven surrogate for a battery system while incorporating the underlying physics as constraints. In this work, we innovatively treat the functional mapping from current curve to terminal voltage as a composite of operators, which is approximated by the powerful deep operator network (DeepONet). Its learning capability is firstly verified through a predictive test for Li-ion concentration at two electrodes. In this experiment, the physics-informed DeepONet is found to be more robust than the purely data-driven DeepONet, especially in temporal extrapolation scenarios. A composite surrogate is then constructed for mapping current curve and solid diffusivity to terminal voltage with three operator networks, in which two parallel physics-informed DeepONets are firstly used to predict Li-ion concentration at two electrodes, and then based on their surface values, a DeepONet is built to give terminal voltage predictions. Since the surrogate is differentiable anywhere, it is endowed with the ability to learn from data directly, which was validated by using terminal voltage measurements to estimate input parameters. The proposed surrogate built upon operator networks possesses great potential to be applied in on-board scenarios, such as battery management system, since it integrates efficiency and accuracy by incorporating underlying physics, and also leaves an interface for model refinement through a totally differentiable model structure.
<div id='section'>Paperid: <span id='pid'>1644, <a href='https://arxiv.org/pdf/2204.11144.pdf' target='_blank'>https://arxiv.org/pdf/2204.11144.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Zeng, Yash Kothari, Spencer H. Bryngelson, Florian SchÃ¤fer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.11144">Competitive Physics Informed Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks can be trained to solve partial differential equations (PDEs) by using the PDE residual as the loss function. This strategy is called "physics-informed neural networks" (PINNs), but it currently cannot produce high-accuracy solutions, typically attaining about $0.1\%$ relative error. We present an adversarial approach that overcomes this limitation, which we call competitive PINNs (CPINNs). CPINNs train a discriminator that is rewarded for predicting mistakes the PINN makes. The discriminator and PINN participate in a zero-sum game with the exact PDE solution as an optimal strategy. This approach avoids squaring the large condition numbers of PDE discretizations, which is the likely reason for failures of previous attempts to decrease PINN errors even on benign problems. Numerical experiments on a Poisson problem show that CPINNs achieve errors four orders of magnitude smaller than the best-performing PINN. We observe relative errors on the order of single-precision accuracy, consistently decreasing with each epoch. To the authors' knowledge, this is the first time this level of accuracy and convergence behavior has been achieved. Additional experiments on the nonlinear SchrÃ¶dinger, Burgers', and Allen-Cahn equation show that the benefits of CPINNs are not limited to linear problems.
<div id='section'>Paperid: <span id='pid'>1645, <a href='https://arxiv.org/pdf/2204.04348.pdf' target='_blank'>https://arxiv.org/pdf/2204.04348.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anshul Choudhary, Anil Radhakrishnan, John F. Lindner, Sudeshna Sinha, William L. Ditto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.04348">Neuronal diversity can improve machine learning for physics and beyond</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diversity conveys advantages in nature, yet homogeneous neurons typically comprise the layers of artificial neural networks. Here we construct neural networks from neurons that learn their own activation functions, quickly diversify, and subsequently outperform their homogeneous counterparts on image classification and nonlinear regression tasks. Sub-networks instantiate the neurons, which meta-learn especially efficient sets of nonlinear responses. Examples include conventional neural networks classifying digits and forecasting a van der Pol oscillator and physics-informed Hamiltonian neural networks learning HÃ©non-Heiles stellar orbits and the swing of a video recorded pendulum clock. Such \textit{learned diversity} provides examples of dynamical systems selecting diversity over uniformity and elucidates the role of diversity in natural and artificial systems.
<div id='section'>Paperid: <span id='pid'>1646, <a href='https://arxiv.org/pdf/2204.02272.pdf' target='_blank'>https://arxiv.org/pdf/2204.02272.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Teo Deveney, Eike Mueller, Tony Shardlow
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.02272">Deep surrogate accelerated delayed-acceptance HMC for Bayesian inference of spatio-temporal heat fluxes in rotating disc systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a deep learning accelerated methodology to solve PDE-based Bayesian inverse problems with guaranteed accuracy. This is motivated by the ill-posed problem of inferring a spatio-temporal heat-flux parameter known as the Biot number given temperature data, however the methodology is generalisable to other settings. To accelerate Bayesian inference, we develop a novel training scheme that uses data to adaptively train a neural-network surrogate simulating the parametric forward model. By simultaneously identifying an approximate posterior distribution over the Biot number, and weighting a physics-informed training loss according to this, our approach approximates forward and inverse solution together without any need for external solves. Using a random Chebyshev series, we outline how to approximate a Gaussian process prior, and using the surrogate we apply Hamiltonian Monte Carlo (HMC) to sample from the posterior distribution. We derive convergence of the surrogate posterior to the true posterior distribution in the Hellinger metric as our adaptive loss approaches zero. Additionally, we describe how this surrogate-accelerated HMC approach can be combined with traditional PDE solvers in a delayed-acceptance scheme to a-priori control the posterior accuracy. This overcomes a major limitation of deep learning-based surrogate approaches, which do not achieve guaranteed accuracy a-priori due to their non-convex training. Biot number calculations are involved in turbo-machinery design, which is safety critical and highly regulated, therefore it is important that our results have such mathematical guarantees. Our approach achieves fast mixing in high dimensions whilst retaining the convergence guarantees of a traditional PDE solver, and without the burden of evaluating this solver for proposals that are likely to be rejected. Numerical results are given using real and simulated data.
<div id='section'>Paperid: <span id='pid'>1647, <a href='https://arxiv.org/pdf/2203.12634.pdf' target='_blank'>https://arxiv.org/pdf/2203.12634.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shawn G. Rosofsky, Hani Al Majed, E. A. Huerta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.12634">Applications of physics informed neural operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present an end-to-end framework to learn partial differential equations that brings together initial data production, selection of boundary conditions, and the use of physics-informed neural operators to solve partial differential equations that are ubiquitous in the study and modeling of physics phenomena. We first demonstrate that our methods reproduce the accuracy and performance of other neural operators published elsewhere in the literature to learn the 1D wave equation and the 1D Burgers equation. Thereafter, we apply our physics-informed neural operators to learn new types of equations, including the 2D Burgers equation in the scalar, inviscid and vector types. Finally, we show that our approach is also applicable to learn the physics of the 2D linear and nonlinear shallow water equations, which involve three coupled partial differential equations. We release our artificial intelligence surrogates and scientific software to produce initial data and boundary conditions to study a broad range of physically motivated scenarios. We provide the source code, an interactive website to visualize the predictions of our physics informed neural operators, and a tutorial for their use at the Data and Learning Hub for Science.
<div id='section'>Paperid: <span id='pid'>1648, <a href='https://arxiv.org/pdf/2201.06463.pdf' target='_blank'>https://arxiv.org/pdf/2201.06463.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michail Spitieris, Ingelin Steinsland
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.06463">Bayesian Calibration of Imperfect Computer Models using Physics-Informed Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a computational efficient data-driven framework suitable for quantifying the uncertainty in physical parameters and model formulation of computer models, represented by differential equations. We construct physics-informed priors, which are multi-output GP priors that encode the model's structure in the covariance function. This is extended into a fully Bayesian framework that quantifies the uncertainty of physical parameters and model predictions. Since physical models often are imperfect descriptions of the real process, we allow the model to deviate from the observed data by considering a discrepancy function. For inference, Hamiltonian Monte Carlo is used. Further, approximations for big data are developed that reduce the computational complexity from $\mathcal{O}(N^3)$ to $\mathcal{O}(N\cdot m^2),$ where $m \ll N.$ Our approach is demonstrated in simulation and real data case studies where the physics are described by time-dependent ODEs describe (cardiovascular models) and space-time dependent PDEs (heat equation). In the studies, it is shown that our modelling framework can recover the true parameters of the physical models in cases where 1) the reality is more complex than our modelling choice and 2) the data acquisition process is biased while also producing accurate predictions. Furthermore, it is demonstrated that our approach is computationally faster than traditional Bayesian calibration methods.
<div id='section'>Paperid: <span id='pid'>1649, <a href='https://arxiv.org/pdf/2201.01854.pdf' target='_blank'>https://arxiv.org/pdf/2201.01854.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongho Kim, Yongho Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2201.01854">Learning finite difference methods for reaction-diffusion type equations with FCNN</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, Physics-informed neural networks (PINNs) have been widely used to solve partial differential equations alongside numerical methods because PINNs can be trained without observations and deal with continuous-time problems directly. In contrast, optimizing the parameters of such models is difficult, and individual training sessions must be performed to predict the evolutions of each different initial condition. To alleviate the first problem, observed data can be injected directly into the loss function part. To solve the second problem, a network architecture can be built as a framework to learn a finite difference method. In view of the two motivations, we propose Five-point stencil CNNs (FCNNs) containing a five-point stencil kernel and a trainable approximation function for reaction-diffusion type equations including the heat, Fisher's, Allen-Cahn, and other reaction-diffusion equations with trigonometric function terms. We show that FCNNs can learn finite difference schemes using few data and achieve the low relative errors of diverse reaction-diffusion evolutions with unseen initial conditions. Furthermore, we demonstrate that FCNNs can still be trained well even with using noisy data.
<div id='section'>Paperid: <span id='pid'>1650, <a href='https://arxiv.org/pdf/2110.13330.pdf' target='_blank'>https://arxiv.org/pdf/2110.13330.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chandrajit Bajaj, Luke McLennan, Timothy Andeen, Avik Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.13330">Recipes for when Physics Fails: Recovering Robust Learning of Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Neural Networks (PINNs) have been shown to be effective in solving partial differential equations by capturing the physics induced constraints as a part of the training loss function. This paper shows that a PINN can be sensitive to errors in training data and overfit itself in dynamically propagating these errors over the domain of the solution of the PDE. It also shows how physical regularizations based on continuity criteria and conservation laws fail to address this issue and rather introduce problems of their own causing the deep network to converge to a physics-obeying local minimum instead of the global minimum. We introduce Gaussian Process (GP) based smoothing that recovers the performance of a PINN and promises a robust architecture against noise/errors in measurements. Additionally, we illustrate an inexpensive method of quantifying the evolution of uncertainty based on the variance estimation of GPs on boundary data. Robust PINN performance is also shown to be achievable by choice of sparse sets of inducing points based on sparsely induced GPs. We demonstrate the performance of our proposed methods and compare the results from existing benchmark models in literature for time-dependent SchrÃ¶dinger and Burgers' equations.
<div id='section'>Paperid: <span id='pid'>1651, <a href='https://arxiv.org/pdf/2104.00615.pdf' target='_blank'>https://arxiv.org/pdf/2104.00615.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Bihlo, Roman O. Popovych
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2104.00615">Physics-informed neural networks for the shallow-water equations on the sphere</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose the use of physics-informed neural networks for solving the shallow-water equations on the sphere in the meteorological context. Physics-informed neural networks are trained to satisfy the differential equations along with the prescribed initial and boundary data, and thus can be seen as an alternative approach to solving differential equations compared to traditional numerical approaches such as finite difference, finite volume or spectral methods. We discuss the training difficulties of physics-informed neural networks for the shallow-water equations on the sphere and propose a simple multi-model approach to tackle test cases of comparatively long time intervals. Here we train a sequence of neural networks instead of a single neural network for the entire integration interval. We also avoid the use of a boundary value loss by encoding the boundary conditions in a custom neural network layer. We illustrate the abilities of the method by solving the most prominent test cases proposed by Williamson et al. [J. Comput. Phys. 102 (1992), 211-224].
<div id='section'>Paperid: <span id='pid'>1652, <a href='https://arxiv.org/pdf/2510.06355.pdf' target='_blank'>https://arxiv.org/pdf/2510.06355.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kürşat Tekbıyık, Güneş Karabulut Kurt, Antoine Lesage-Landry
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06355">PIKAN: Physics-Inspired Kolmogorov-Arnold Networks for Explainable UAV Channel Modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unmanned aerial vehicle (UAV) communications demand accurate yet interpretable air-to-ground (A2G) channel models that can adapt to nonstationary propagation environments. While deterministic models offer interpretability and deep learning (DL) models provide accuracy, both approaches suffer from either rigidity or a lack of explainability. To bridge this gap, we propose the Physics-Inspired Kolmogorov-Arnold Network (PIKAN) that embeds physical principles (e.g., free-space path loss, two-ray reflections) into the learning process. Unlike physics-informed neural networks (PINNs), PIKAN is more flexible for applying physical information because it introduces them as flexible inductive biases. Thus, it enables a more flexible training process. Experiments on UAV A2G measurement data show that PIKAN achieves comparable accuracy to DL models while providing symbolic and explainable expressions aligned with propagation laws. Remarkably, PIKAN achieves this performance with only 232 parameters, making it up to 37 times lighter than multilayer perceptron (MLP) baselines with thousands of parameters, without sacrificing correlation with measurements and also providing symbolic expressions. These results highlight PIKAN as an efficient, interpretable, and scalable solution for UAV channel modelling in beyond-5G and 6G networks.
<div id='section'>Paperid: <span id='pid'>1653, <a href='https://arxiv.org/pdf/2510.06286.pdf' target='_blank'>https://arxiv.org/pdf/2510.06286.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kim Bente, Roman Marchant, Fabio Ramos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.06286">Mass Conservation on Rails -- Rethinking Physics-Informed Learning of Ice Flow Vector Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To reliably project future sea level rise, ice sheet models require inputs that respect physics. Embedding physical principles like mass conservation into models that interpolate Antarctic ice flow vector fields from sparse & noisy measurements not only promotes physical adherence but can also improve accuracy and robustness. While physics-informed neural networks (PINNs) impose physics as soft penalties, offering flexibility but no physical guarantees, we instead propose divergence-free neural networks (dfNNs), which enforce local mass conservation exactly via a vector calculus trick. Our comparison of dfNNs, PINNs, and unconstrained NNs on ice flux interpolation over Byrd Glacier suggests that "mass conservation on rails" yields more reliable estimates, and that directional guidance, a learning strategy leveraging continent-wide satellite velocity data, boosts performance across models.
<div id='section'>Paperid: <span id='pid'>1654, <a href='https://arxiv.org/pdf/2510.05385.pdf' target='_blank'>https://arxiv.org/pdf/2510.05385.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rohan Arni, Carlos Blanco
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05385">Physics-Informed Neural Networks with Fourier Features and Attention-Driven Decoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are a useful framework for approximating partial differential equation solutions using deep learning methods. In this paper, we propose a principled redesign of the PINNsformer, a Transformer-based PINN architecture. We present the Spectral PINNSformer (S-Pformer), a refinement of encoder-decoder PINNSformers that addresses two key issues; 1. the redundancy (i.e. increased parameter count) of the encoder, and 2. the mitigation of spectral bias. We find that the encoder is unnecessary for capturing spatiotemporal correlations when relying solely on self-attention, thereby reducing parameter count. Further, we integrate Fourier feature embeddings to explicitly mitigate spectral bias, enabling adaptive encoding of multiscale behaviors in the frequency domain. Our model outperforms encoder-decoder PINNSformer architectures across all benchmarks, achieving or outperforming MLP performance while reducing parameter count significantly.
<div id='section'>Paperid: <span id='pid'>1655, <a href='https://arxiv.org/pdf/2510.04591.pdf' target='_blank'>https://arxiv.org/pdf/2510.04591.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junsei Ito, Yasuaki Wasa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04591">Data-Driven Adaptive PID Control Based on Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This article proposes a data-driven PID controller design based on the principle of adaptive gain optimization, leveraging Physics-Informed Neural Networks (PINNs) generated for predictive modeling purposes. The proposed control design method utilizes gradients of the PID gain optimization, achieved through the automatic differentiation of PINNs, to apply model predictive control using a cost function based on tracking error and control inputs. By optimizing PINNs-based PID gains, the method achieves adaptive gain tuning that ensures stability while accounting for system nonlinearities. The proposed method features a systematic framework for integrating PINNs-based models of dynamical control systems into closed-loop control systems, enabling direct application to PID control design. A series of numerical experiments is conducted to demonstrate the effectiveness of the proposed method from the control perspectives based on both time and frequency domains.
<div id='section'>Paperid: <span id='pid'>1656, <a href='https://arxiv.org/pdf/2510.04094.pdf' target='_blank'>https://arxiv.org/pdf/2510.04094.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weikuo Wang, Yue Liao, Huan Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04094">Nyström-Accelerated Primal LS-SVMs: Breaking the $O(an^3)$ Complexity Bottleneck for Scalable ODEs Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A major problem of kernel-based methods (e.g., least squares support vector machines, LS-SVMs) for solving linear/nonlinear ordinary differential equations (ODEs) is the prohibitive $O(an^3)$ ($a=1$ for linear ODEs and 27 for nonlinear ODEs) part of their computational complexity with increasing temporal discretization points $n$. We propose a novel Nyström-accelerated LS-SVMs framework that breaks this bottleneck by reformulating ODEs as primal-space constraints. Specifically, we derive for the first time an explicit Nyström-based mapping and its derivatives from one-dimensional temporal discretization points to a higher $m$-dimensional feature space ($1< m\le n$), enabling the learning process to solve linear/nonlinear equation systems with $m$-dependent complexity. Numerical experiments on sixteen benchmark ODEs demonstrate: 1) $10-6000$ times faster computation than classical LS-SVMs and physics-informed neural networks (PINNs), 2) comparable accuracy to LS-SVMs ($<0.13\%$ relative MAE, RMSE, and $\left \| y-\hat{y} \right \| _{\infty } $difference) while maximum surpassing PINNs by 72\% in RMSE, and 3) scalability to $n=10^4$ time steps with $m=50$ features. This work establishes a new paradigm for efficient kernel-based ODEs learning without significantly sacrificing the accuracy of the solution.
<div id='section'>Paperid: <span id='pid'>1657, <a href='https://arxiv.org/pdf/2510.03416.pdf' target='_blank'>https://arxiv.org/pdf/2510.03416.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ashley Lenau, Dennis Dimiduk, Stephen R. Niezgoda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03416">Training Variation of Physically-Informed Deep Learning Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A successful deep learning network is highly dependent not only on the training dataset, but the training algorithm used to condition the network for a given task. The loss function, dataset, and tuning of hyperparameters all play an essential role in training a network, yet there is not much discussion on the reliability or reproducibility of a training algorithm. With the rise in popularity of physics-informed loss functions, this raises the question of how reliable one's loss function is in conditioning a network to enforce a particular boundary condition. Reporting the model variation is needed to assess a loss function's ability to consistently train a network to obey a given boundary condition, and provides a fairer comparison among different methods. In this work, a Pix2Pix network predicting the stress fields of high elastic contrast composites is used as a case study. Several different loss functions enforcing stress equilibrium are implemented, with each displaying different levels of variation in convergence, accuracy, and enforcing stress equilibrium across many training sessions. Suggested practices in reporting model variation are also shared.
<div id='section'>Paperid: <span id='pid'>1658, <a href='https://arxiv.org/pdf/2510.03305.pdf' target='_blank'>https://arxiv.org/pdf/2510.03305.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tian Zheng, Subashree Venkatasubramanian, Shuolin Li, Amy Braverman, Xinyi Ke, Zhewen Hou, Peter Jin, Samarth Sanjay Agrawal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03305">Machine Learning Workflows in Climate Modeling: Design Patterns and Insights from Case Studies</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning has been increasingly applied in climate modeling on system emulation acceleration, data-driven parameter inference, forecasting, and knowledge discovery, addressing challenges such as physical consistency, multi-scale coupling, data sparsity, robust generalization, and integration with scientific workflows. This paper analyzes a series of case studies from applied machine learning research in climate modeling, with a focus on design choices and workflow structure. Rather than reviewing technical details, we aim to synthesize workflow design patterns across diverse projects in ML-enabled climate modeling: from surrogate modeling, ML parameterization, probabilistic programming, to simulation-based inference, and physics-informed transfer learning. We unpack how these workflows are grounded in physical knowledge, informed by simulation data, and designed to integrate observations. We aim to offer a framework for ensuring rigor in scientific machine learning through more transparent model development, critical evaluation, informed adaptation, and reproducibility, and to contribute to lowering the barrier for interdisciplinary collaboration at the interface of data science and climate modeling.
<div id='section'>Paperid: <span id='pid'>1659, <a href='https://arxiv.org/pdf/2510.01091.pdf' target='_blank'>https://arxiv.org/pdf/2510.01091.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hossein Geshani, Mehrdad Raisee Dehkordi, Masoud Shariat Panahi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.01091">Physics-Informed Machine Learning Approach in Augmenting RANS Models Using DNS Data and DeepInsight Method on FDA Nozzle</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a data-driven framework for turbulence modeling, applied to flow prediction in the FDA nozzle. In this study, the standard RANS equations have been modified using an implicit-explicit hybrid approach. New variables were introduced, and a solver was developed within the OpenFOAM framework, integrating a machine learning module to estimate these variables. The invariant input features were derived based on Hilbert's basis theorem, and the outputs of the machine learning model were obtained through eigenvalue-vector decomposition of the Reynolds stress tensor. Validation was performed using DNS data for turbulent flow in a square channel at various Reynolds numbers. A baseline MLP was first trained at $Re=2900$ and tested at $Re=3500$ to assess its ability to reproduce turbulence anisotropy and secondary flows. To further enhance generalization, three benchmark DNS datasets were transformed into images via the Deep-Insight method, enabling the use of convolutional neural networks. The trained Deep-Insight network demonstrated improved prediction of turbulence structures in the FDA blood nozzle, highlighting the promise of data-driven augmentation in turbulence modeling.
<div id='section'>Paperid: <span id='pid'>1660, <a href='https://arxiv.org/pdf/2510.00442.pdf' target='_blank'>https://arxiv.org/pdf/2510.00442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harbir Antil, Deepanshu Verma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00442">Randomized Matrix Sketching for Neural Network Training and Gradient Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural network training relies on gradient computation through backpropagation, yet memory requirements for storing layer activations present significant scalability challenges. We present the first adaptation of control-theoretic matrix sketching to neural network layer activations, enabling memory-efficient gradient reconstruction in backpropagation. This work builds on recent matrix sketching frameworks for dynamic optimization problems, where similar state trajectory storage challenges motivate sketching techniques. Our approach sketches layer activations using three complementary sketch matrices maintained through exponential moving averages (EMA) with adaptive rank adjustment, automatically balancing memory efficiency against approximation quality. Empirical evaluation on MNIST, CIFAR-10, and physics-informed neural networks demonstrates a controllable accuracy-memory tradeoff. We demonstrate a gradient monitoring application on MNIST showing how sketched activations enable real-time gradient norm tracking with minimal memory overhead. These results establish that sketched activation storage provides a viable path toward memory-efficient neural network training and analysis.
<div id='section'>Paperid: <span id='pid'>1661, <a href='https://arxiv.org/pdf/2509.26113.pdf' target='_blank'>https://arxiv.org/pdf/2509.26113.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Haider Shah, Naveed R. Butt, Asif Ahmad, Muhammad Omer Bin Saeed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.26113">Enhancing PINN Performance Through Lie Symmetry Group</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents intersection of Physics informed neural networks (PINNs) and Lie symmetry group to enhance the accuracy and efficiency of solving partial differential equation (PDEs). Various methods have been developed to solve these equations. A Lie group is an efficient method that can lead to exact solutions for the PDEs that possessing Lie Symmetry. Leveraging the concept of infinitesimal generators from Lie symmetry group in a novel manner within PINN leads to significant improvements in solution of PDEs. In this study three distinct cases are discussed, each showing progressive improvements achieved through Lie symmetry modifications and adaptive techniques. State-of-the-art numerical methods are adopted for comparing the progressive PINN models. Numerical experiments demonstrate the key role of Lie symmetry in enhancing PINNs performance, emphasizing the importance of integrating abstract mathematical concepts into deep learning for addressing complex scientific problems adequately.
<div id='section'>Paperid: <span id='pid'>1662, <a href='https://arxiv.org/pdf/2509.26005.pdf' target='_blank'>https://arxiv.org/pdf/2509.26005.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui-Yang Zhang, Henry B. Moss, Lachlan Astfalck, Edward Cripps, David S. Leslie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.26005">BALLAST: Bayesian Active Learning with Look-ahead Amendment for Sea-drifter Trajectories under Spatio-Temporal Vector Fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a formal active learning methodology for guiding the placement of Lagrangian observers to infer time-dependent vector fields -- a key task in oceanography, marine science, and ocean engineering -- using a physics-informed spatio-temporal Gaussian process surrogate model. The majority of existing placement campaigns either follow standard `space-filling' designs or relatively ad-hoc expert opinions. A key challenge to applying principled active learning in this setting is that Lagrangian observers are continuously advected through the vector field, so they make measurements at different locations and times. It is, therefore, important to consider the likely future trajectories of placed observers to account for the utility of candidate placement locations. To this end, we present BALLAST: Bayesian Active Learning with Look-ahead Amendment for Sea-drifter Trajectories. We observe noticeable benefits of BALLAST-aided sequential observer placement strategies on both synthetic and high-fidelity ocean current models.
<div id='section'>Paperid: <span id='pid'>1663, <a href='https://arxiv.org/pdf/2509.25311.pdf' target='_blank'>https://arxiv.org/pdf/2509.25311.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anirudh Deb, Yaman Sanghavi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25311">Aspects of holographic entanglement using physics-informed-neural-networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We implement physics-informed-neural-networks (PINNs) to compute holographic entanglement entropy and entanglement wedge cross section. This technique allows us to compute these quantities for arbitrary shapes of the subregions in any asymptotically AdS metric. We test our computations against some known results and further demonstrate the utility of PINNs in examples, where it is not straightforward to perform such computations.
<div id='section'>Paperid: <span id='pid'>1664, <a href='https://arxiv.org/pdf/2509.25262.pdf' target='_blank'>https://arxiv.org/pdf/2509.25262.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuandong Li, Runtian Zeng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25262">AW-EL-PINNs: A Multi-Task Learning Physics-Informed Neural Network for Euler-Lagrange Systems in Optimal Control Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents adaptive weighted Euler-Lagrange theorem combined physics-informed neural networks (AW-EL-PINNs) for solving Euler-Lagrange systems in optimal control problems. The framework systematically converts optimal control frameworks into two-point boundary value problems (TPBVPs) while establishing a multi-task learning paradigm through innovative integration of the Euler-Lagrange theorem with deep learning architecture. An adaptive loss weighting mechanism dynamically balances loss function components during training, decreasing tedious manual tuning of weighting the loss functions compared to the conventional physics-informed neural networks (PINNs). Based on six numerical examples, it's clear that AW-EL-PINNs achieve enhanced solution accuracy compared to baseline methods while maintaining stability throughout the optimization process. These results highlight the framework's capability to improve precision and ensure stability in solving Euler-Lagrange systems in optimal control problems, offering potential strategies for problems under physical applications.
<div id='section'>Paperid: <span id='pid'>1665, <a href='https://arxiv.org/pdf/2509.25158.pdf' target='_blank'>https://arxiv.org/pdf/2509.25158.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ehimare Okoyomon, Arbel Yaniv, Christoph Goebel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25158">Physics-Informed Inductive Biases for Voltage Prediction in Distribution Grids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Voltage prediction in distribution grids is a critical yet difficult task for maintaining power system stability. Machine learning approaches, particularly Graph Neural Networks (GNNs), offer significant speedups but suffer from poor generalization when trained on limited or incomplete data. In this work, we systematically investigate the role of inductive biases in improving a model's ability to reliably learn power flow. Specifically, we evaluate three physics-informed strategies: (i) power-flow-constrained loss functions, (ii) complex-valued neural networks, and (iii) residual-based task reformulation. Using the ENGAGE dataset, which spans multiple low- and medium-voltage grid configurations, we conduct controlled experiments to isolate the effect of each inductive bias and assess both standard predictive performance and out-of-distribution generalization. Our study provides practical insights into which model assumptions most effectively guide learning for reliable and efficient voltage prediction in modern distribution networks.
<div id='section'>Paperid: <span id='pid'>1666, <a href='https://arxiv.org/pdf/2509.21405.pdf' target='_blank'>https://arxiv.org/pdf/2509.21405.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nyi Nyi Aung, Neil Muralles, Adrian Stein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21405">Object Identification Under Known Dynamics: A PIRNN Approach for UAV Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work addresses object identification under known dynamics in unmanned aerial vehicle applications, where learning and classification are combined through a physics-informed residual neural network. The proposed framework leverages physics-informed learning for state mapping and state-derivative prediction, while a softmax layer enables multi-class confidence estimation. Quadcopter, fixed-wing, and helicopter aerial vehicles are considered as case studies. The results demonstrate high classification accuracy with reduced training time, offering a promising solution for system identification problems in domains where the underlying dynamics are well understood.
<div id='section'>Paperid: <span id='pid'>1667, <a href='https://arxiv.org/pdf/2509.21393.pdf' target='_blank'>https://arxiv.org/pdf/2509.21393.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi En Chou, Te Hsin Liu, Chao-An Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21393">Impact of Loss Weight and Model Complexity on Physics-Informed Neural Networks for Computational Fluid Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics Informed Neural Networks offer a mesh free framework for solving PDEs but are highly sensitive to loss weight selection. We propose two dimensional analysis based weighting schemes, one based on quantifiable terms, and another also incorporating unquantifiable terms for more balanced training. Benchmarks on heat conduction, convection diffusion, and lid driven cavity flows show that the second scheme consistently improves stability and accuracy over equal weighting. Notably, in high Peclet number convection diffusion, where traditional solvers fail, PINNs with our scheme achieve stable, accurate predictions, highlighting their robustness and generalizability in CFD problems.
<div id='section'>Paperid: <span id='pid'>1668, <a href='https://arxiv.org/pdf/2509.21123.pdf' target='_blank'>https://arxiv.org/pdf/2509.21123.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alessandro Bombini, Alessandro Rosa, Clarissa Buti, Giovanni Passaleva, Lucio Anderlini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21123">Physics Informed Neural Networks for design optimisation of diamond particle detectors for charged particle fast-tracking at high luminosity hadron colliders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Future high-luminosity hadron colliders demand tracking detectors with extreme radiation tolerance, high spatial precision, and sub-nanosecond timing. 3D diamond pixel sensors offer these capabilities due to diamond's radiation hardness and high carrier mobility. Conductive electrodes, produced via femtosecond IR laser pulses, exhibit high resistivity that delays signal propagation. This effect necessitates extending the classical Ramo-Shockley weighting potential formalism. We model the phenomenon through a 3rd-order, 3+1D PDE derived as a quasi-stationary approximation of Maxwell's equations. The PDE is solved numerically and coupled with charge transport simulations for realistic 3D sensor geometries. A Mixture-of-Experts Physics-Informed Neural Network, trained on Spectral Method data, provides a meshless solver to assess timing degradation from electrode resistance.
<div id='section'>Paperid: <span id='pid'>1669, <a href='https://arxiv.org/pdf/2509.19467.pdf' target='_blank'>https://arxiv.org/pdf/2509.19467.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Javier Castro, Benjamin Gess
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.19467">THINNs: Thermodynamically Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are a class of deep learning models aiming to approximate solutions of PDEs by training neural networks to minimize the residual of the equation. Focusing on non-equilibrium fluctuating systems, we propose a physically informed choice of penalization that is consistent with the underlying fluctuation structure, as characterized by a large deviations principle. This approach yields a novel formulation of PINNs in which the penalty term is chosen to penalize improbable deviations, rather than being selected heuristically. The resulting thermodynamically consistent extension of PINNs, termed THINNs, is subsequently analyzed by establishing analytical a posteriori estimates, and providing empirical comparisons to established penalization strategies.
<div id='section'>Paperid: <span id='pid'>1670, <a href='https://arxiv.org/pdf/2509.16114.pdf' target='_blank'>https://arxiv.org/pdf/2509.16114.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yukta Pareek, Abdul Malik Al Mardhouf Al Saadi, Amrita Basak, Satadru Dey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.16114">Real-Time Thermal State Estimation and Forecasting in Laser Powder Bed Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Laser Powder Bed Fusion (L-PBF) is a widely adopted additive manufacturing process for fabricating complex metallic parts layer by layer. Effective thermal management is essential to ensure part quality and structural integrity, as thermal gradients and residual stresses can lead to defects such as warping and cracking. However, existing experimental or computational techniques lack the ability to forecast future temperature distributions in real time, an essential capability for proactive process control. This paper presents a real-time thermal state forecasting framework for L-PBF, based on a physics-informed reduced-order thermal model integrated with a Kalman filtering scheme. The proposed approach efficiently captures inter-layer heat transfer dynamics and enables accurate tracking and forecasting of spatial and temporal temperature evolution. Validation across multiple part geometries using measured data demonstrates that the method reliably estimates and forecasts peak temperatures and cooling trends. By enabling predictive thermal control, this framework offers a practical and computationally efficient solution for thermal management in L-PBF, paving the way toward closed-loop control in L-PBF.
<div id='section'>Paperid: <span id='pid'>1671, <a href='https://arxiv.org/pdf/2509.15029.pdf' target='_blank'>https://arxiv.org/pdf/2509.15029.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hamidreza Razavi, Nele Moelans
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15029">Physics-Informed GCN-LSTM Framework for Long-Term Forecasting of 2D and 3D Microstructure Evolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a physics-informed framework that integrates graph convolutional networks (GCN) with long short-term memory (LSTM) architecture to forecast microstructure evolution over long time horizons in both 2D and 3D with remarkable performance across varied metrics. The proposed framework is composition-aware, trained jointly on datasets with different compositions, and operates in latent graph space, which enables the model to capture compositions and morphological dynamics while remaining computationally efficient. Compressing and encoding phase-field simulation data with convolutional autoencoders and operating in Latent graph space facilitates efficient modeling of microstructural evolution across composition, dimensions, and long-term horizons. The framework captures the spatial and temporal patterns of evolving microstructures while enabling long-range forecasting at reduced computational cost after training.
<div id='section'>Paperid: <span id='pid'>1672, <a href='https://arxiv.org/pdf/2509.15004.pdf' target='_blank'>https://arxiv.org/pdf/2509.15004.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yujia Huang, Xi'an Li ansd Jinran Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15004">Fourier heuristic PINNs to solve the biharmonic equations based on its coupled scheme</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have been widely utilized for solving a range of partial differential equations (PDEs) in various scientific and engineering disciplines. This paper presents a Fourier heuristic-enhanced PINN (termed FCPINN) designed to address a specific class of biharmonic equations with Dirichlet and Navier boundary conditions. The method achieves this by decomposing the high-order equations into two Poisson equations. FCPINN integrates Fourier spectral theory with a reduced-order formulation for high-order PDEs, significantly improving approximation accuracy and reducing computational complexity. This approach is especially beneficial for problems with intricate boundary constraints and high-dimensional inputs. To assess the effectiveness and robustness of the FCPINN algorithm, we conducted several numerical experiments on both linear and nonlinear biharmonic problems across different Euclidean spaces. The results show that FCPINN provides an optimal trade-off between speed and accuracy for high-order PDEs, surpassing the performance of conventional PINN and deep mixed residual method (MIM) approaches, while also maintaining stability and robustness with varying numbers of hidden layer nodes.
<div id='section'>Paperid: <span id='pid'>1673, <a href='https://arxiv.org/pdf/2509.14442.pdf' target='_blank'>https://arxiv.org/pdf/2509.14442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arjun Teh, Wael H. Ali, Joshua Rapp, Hassan Mansour
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14442">Indoor Airflow Imaging Using Physics-Informed Background-Oriented Schlieren Tomography</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a framework for non-invasive volumetric indoor airflow estimation from a single viewpoint using background-oriented schlieren (BOS) measurements and physics-informed reconstruction. Our framework utilizes a light projector that projects a pattern onto a target back-wall and a camera that observes small distortions in the light pattern. While the single-view BOS tomography problem is severely ill-posed, our proposed framework addresses this using: (1) improved ray tracing, (2) a physics-based light rendering approach and loss formulation, and (3) a physics-based regularization using a physics-informed neural network (PINN) to ensure that the reconstructed airflow is consistent with the governing equations for buoyancy-driven flows.
<div id='section'>Paperid: <span id='pid'>1674, <a href='https://arxiv.org/pdf/2509.13952.pdf' target='_blank'>https://arxiv.org/pdf/2509.13952.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amin Lotfalian, Mohammad Reza Banan, Pooyan Broumand
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13952">eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents eXtended Physics-Informed Neural Network (X-PINN), a novel and robust framework for addressing fracture mechanics problems involving multiple cracks in fractured media. To address this, an energy-based loss function, customized integration schemes, and domain decomposition procedures are proposed. Inspired by the Extended Finite Element Method (XFEM), the neural network solution space is enriched with specialized functions that allow crack body discontinuities and singularities at crack tips to be explicitly captured. Furthermore, a structured framework is introduced in which standard and enriched solution components are modeled using distinct neural networks, enabling flexible and effective simulations of complex multiple-crack problems in 1D and 2D domains, with convenient extensibility to 3D problems. Numerical experiments are conducted to validate the effectiveness and robustness of the proposed method.
<div id='section'>Paperid: <span id='pid'>1675, <a href='https://arxiv.org/pdf/2509.13717.pdf' target='_blank'>https://arxiv.org/pdf/2509.13717.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yifan Yu, Cheuk Hin Ho, Yangshuai Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.13717">A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving PDEs, yet existing uncertainty quantification (UQ) approaches for PINNs generally lack rigorous statistical guarantees. In this work, we bridge this gap by introducing a distribution-free conformal prediction (CP) framework for UQ in PINNs. This framework calibrates prediction intervals by constructing nonconformity scores on a calibration set, thereby yielding distribution-free uncertainty estimates with rigorous finite-sample coverage guarantees for PINNs. To handle spatial heteroskedasticity, we further introduce local conformal quantile estimation, enabling spatially adaptive uncertainty bands while preserving theoretical guarantee. Through systematic evaluations on typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz equations) and comprehensive testing across multiple uncertainty metrics, our results demonstrate that the proposed framework achieves reliable calibration and locally adaptive uncertainty intervals, consistently outperforming heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work introduces a general framework that not only enhances calibration and reliability, but also opens new avenues for uncertainty-aware modeling of complex PDE systems.
<div id='section'>Paperid: <span id='pid'>1676, <a href='https://arxiv.org/pdf/2509.12666.pdf' target='_blank'>https://arxiv.org/pdf/2509.12666.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Charuka D. Wickramasinghe, Krishanthi C. Weerasinghe, Pradeep K. Ranaweera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12666">PBPK-iPINNs: Inverse Physics-Informed Neural Networks for Physiologically Based Pharmacokinetic Brain Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) leverage machine learning with differential equations to solve direct and inverse problems, ensuring predictions follow physical laws. Physiologically based pharmacokinetic (PBPK) modeling advances beyond classical compartmental approaches by using a mechanistic, physiology focused framework. A PBPK model is based on a system of ODEs, with each equation representing the mass balance of a drug in a compartment, such as an organ or tissue. These ODEs include parameters that reflect physiological, biochemical, and drug-specific characteristics to simulate how the drug moves through the body. In this paper, we introduce PBPK-iPINN, a method to estimate drug-specific or patient-specific parameters and drug concentration profiles in PBPK brain compartment models using inverse PINNs. We demonstrate that, for the inverse problem to converge to the correct solution, the loss function components (data loss, initial conditions loss, and residual loss) must be appropriately weighted, and parameters (including number of layers, number of neurons, activation functions, learning rate, optimizer, and collocation points) must be carefully tuned. The performance of the PBPK-iPINN approach is then compared with established traditional numerical and statistical methods.
<div id='section'>Paperid: <span id='pid'>1677, <a href='https://arxiv.org/pdf/2509.12522.pdf' target='_blank'>https://arxiv.org/pdf/2509.12522.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Devin Hunter, Chinwendu Enyioha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12522">Hybrid State Estimation of Uncertain Nonlinear Dynamics Using Neural Processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Various neural network architectures are used in many of the state-of-the-art approaches for real-time nonlinear state estimation in dynamical systems. With the ever-increasing incorporation of these data-driven models into the estimation domain, models with reliable margins of error are required -- especially for safety-critical applications. This paper discusses a novel hybrid, data-driven state estimation approach based on the physics-informed attentive neural process (PI-AttNP), a model-informed extension of the attentive neural process (AttNP). We augment this estimation approach with the regression-based split conformal prediction (CP) framework to obtain quantified model uncertainty with probabilistic guarantees. After presenting the algorithm in a generic form, we validate its performance in the task of grey-box state estimation of a simulated under-actuated six-degree-of-freedom quadrotor with multimodal Gaussian sensor noise and several external perturbations typical to quadrotors. Further, we compare outcomes with state-of-the-art data-driven methods, which provide significant evidence of the physics-informed neural process as a viable novel approach for model-driven estimation.
<div id='section'>Paperid: <span id='pid'>1678, <a href='https://arxiv.org/pdf/2509.12483.pdf' target='_blank'>https://arxiv.org/pdf/2509.12483.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Oscar Rincón-Cardeno, Gregorio Pérez Bernal, Silvana Montoya Noguera, Nicolás Guarín-Zapata
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12483">Comparative Analysis of Wave Scattering Numerical Modeling Using the Boundary Element Method and Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Purpose - This study compares the Boundary Element Method (BEM) and Physics-Informed Neural Networks (PINNs) for solving the two-dimensional Helmholtz equation in wave scattering problems. The objective is to evaluate the performance of both methods under the same conditions. Design/methodology/approach - We solve the Helmholtz equation using BEM and PINNs for the same scattering problem. The PINNs are trained by minimizing the residual of the governing equations and boundary conditions, with their configuration determined through hyperparameter optimization, while the BEM is applied using boundary discretization. Both methods are evaluated in terms of solution accuracy, computation time, and generalization capacity. Findings - Numerical experiments were conducted by varying the number of integration points for BEM and the number of layers and neurons per layer for PINNs. Hyperparameter tuning provided further insight into suitable configurations for wave scattering problems. At comparable accuracy, PINNs produced consistent solutions but required training times approximately 42 times longer than BEM. However, once trained, PINNs achieved evaluation times up to 204 times faster. The generalization capacity was also assessed outside the PINN training domain, where the relative error increased from $7.46 \times 10^{-2}$ to 8.22, while BEM maintained a similar error level in the extended region. Originality/value - This work presents a direct comparison between PINNs and BEM for the Helmholtz equation. The analysis provides quantitative data on the performance of both methods, supporting their selection in future research on wave propagation problems and establishing future challenges and directions.
<div id='section'>Paperid: <span id='pid'>1679, <a href='https://arxiv.org/pdf/2509.12271.pdf' target='_blank'>https://arxiv.org/pdf/2509.12271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vijay Kumar, Gautam Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12271">A Variational Physics-Informed Neural Network Framework Using Petrov-Galerkin Method for Solving Singularly Perturbed Boundary Value Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work proposes a Variational Physics-Informed Neural Network (VPINN) framework that integrates the Petrov-Galerkin formulation with deep neural networks (DNNs) for solving one-dimensional singularly perturbed boundary value problems (BVPs) and parabolic partial differential equations (PDEs) involving one or two small parameters. The method adopts a nonlinear approximation in which the trial space is defined by neural network functions, while the test space is constructed from hat functions. The weak formulation is constructed using localized test functions, with interface penalty terms introduced to enhance numerical stability and accurately capture boundary layers. Dirichlet boundary conditions are imposed via hard constraints, and source terms are computed using automatic differentiation. Numerical experiments on benchmark problems demonstrate the effectiveness of the proposed method, showing significantly improved accuracy in both the $L_2$ and maximum norms compared to the standard VPINN approach for one-dimensional singularly perturbed differential equations (SPDEs).
<div id='section'>Paperid: <span id='pid'>1680, <a href='https://arxiv.org/pdf/2509.12226.pdf' target='_blank'>https://arxiv.org/pdf/2509.12226.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aiping Zhong, Baike She, Philip E. Paré
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12226">A Physics-Informed Neural Networks-Based Model Predictive Control Framework for $SIR$ Epidemics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces a physics-informed neural networks (PINNs)-based model predictive control (MPC) framework for susceptible-infected-recovered ($SIR$) spreading models. Existing studies in MPC design for epidemic control often assume either 1) measurable states of the dynamics, where the parameters are learned, or 2) known parameters of the model, where the states are learned. In this work, we address the joint real-time estimation of states and parameters within the MPC framework using only noisy infected states, under the assumption that 1) only the recovery rate is known, or 2) only the basic reproduction number is known. Under the first assumption, we propose MPC-PINNs and two novel PINNs algorithms, all of which are integrated into the MPC framework. First, we introduce MPC-PINNs, which are designed for $SIR$ models with control. We then propose log-scaled PINNs (MPC-LS-PINNs), which incorporate a log-scaled loss function to improve robustness against noise. Next, we present split-integral PINNs (MPC-SI-PINNs), which leverage integral operators and state coupling in the neural network training process to effectively reconstruct the complete epidemic state information. Building upon these methods, we further extend our framework for the second assumption. We establish the necessary conditions and extend our PINNs algorithms, where MPC-SI-PINNs are simplified as split-PINNs (MPC-S-PINNs). By incorporating these algorithms into the MPC framework, we simultaneously estimate the epidemic states and parameters while generating optimal control strategies. Experiment results demonstrate the effectiveness of the proposed methods under different settings.
<div id='section'>Paperid: <span id='pid'>1681, <a href='https://arxiv.org/pdf/2509.11284.pdf' target='_blank'>https://arxiv.org/pdf/2509.11284.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Achmad Ardani Prasha, Clavino Ourizqi Rachmadi, Muhamad Fauzan Ibnu Syahlan, Naufal Rahfi Anugerah, Nanda Garin Raditya, Putri Amelia, Sabrina Laila Mutiara, Hilman Syachr Ramadhan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11284">PINGS: Physics-Informed Neural Network for Fast Generative Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce PINGS (Physics-Informed Neural Network for Fast Generative Sampling), a framework that amortizes diffusion sampling by training a physics-informed network to approximate reverse-time probability-flow dynamics, reducing sampling to a single forward pass (NFE = 1). As a proof of concept, we learn a direct map from a 3D standard normal to a non-Gaussian Gaussian Mixture Model (GMM). PINGS preserves the target's distributional structure (multi-bandwidth kernel $MMD^2 = 1.88 \times 10^{-2}$ with small errors in mean, covariance, skewness, and excess kurtosis) and achieves constant-time generation: $10^4$ samples in $16.54 \pm 0.56$ millisecond on an RTX 3090, versus 468-843 millisecond for DPM-Solver (10/20) and 960 millisecond for DDIM (50) under matched conditions. We also sanity-check the PINN/automatic-differentiation pipeline on a damped harmonic oscillator, obtaining MSEs down to $\mathcal{O}(10^{-5})$. Compared to fast but iterative ODE solvers and direct-map families (Flow, Rectified-Flow, Consistency), PINGS frames generative sampling as a PINN-style residual problem with endpoint anchoring, yielding a white-box, differentiable map with NFE = 1. These proof-of-concept results position PINGS as a promising route to fast, function-based generative sampling with potential extensions to scientific simulation (e.g., fast calorimetry).
<div id='section'>Paperid: <span id='pid'>1682, <a href='https://arxiv.org/pdf/2509.10945.pdf' target='_blank'>https://arxiv.org/pdf/2509.10945.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gautam Singh, Sofia Haider
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10945">Development and Analysis of Chien-Physics-Informed Neural Networks for Singular Perturbation Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this article, we employ Chien-Physics Informed Neural Networks (C-PINNs) to obtain solutions for singularly perturbed convection-diffusion equations, reaction-diffusion equations, and their coupled forms in both one and two-dimensional settings. While PINNs have emerged as a powerful tool for solving various types of differential equations, their application to singular perturbation problems (SPPs) presents significant challenges. These challenges arise because a small perturbation parameter multiplies the highest-order derivatives, leading to sharp gradient changes near the boundary layer. To overcome these difficulties, we apply C-PINNs, a modified version of the standard PINNs framework, which is specifically designed to address singular perturbation problems. Our study shows that C-PINNs provide a more accurate solution for SPPs, demonstrating better performance than conventional methods.
<div id='section'>Paperid: <span id='pid'>1683, <a href='https://arxiv.org/pdf/2509.09611.pdf' target='_blank'>https://arxiv.org/pdf/2509.09611.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haolan Zheng, Yanlai Chen, Jiequn Han, Yue Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.09611">ReBaNO: Reduced Basis Neural Operator Mitigating Generalization Gaps and Achieving Discretization Invariance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel data-lean operator learning algorithm, the Reduced Basis Neural Operator (ReBaNO), to solve a group of PDEs with multiple distinct inputs. Inspired by the Reduced Basis Method and the recently introduced Generative Pre-Trained Physics-Informed Neural Networks, ReBaNO relies on a mathematically rigorous greedy algorithm to build its network structure offline adaptively from the ground up. Knowledge distillation via task-specific activation function allows ReBaNO to have a compact architecture requiring minimal computational cost online while embedding physics. In comparison to state-of-the-art operator learning algorithms such as PCA-Net, DeepONet, FNO, and CNO, numerical results demonstrate that ReBaNO significantly outperforms them in terms of eliminating/shrinking the generalization gap for both in- and out-of-distribution tests and being the only operator learning algorithm achieving strict discretization invariance.
<div id='section'>Paperid: <span id='pid'>1684, <a href='https://arxiv.org/pdf/2509.08872.pdf' target='_blank'>https://arxiv.org/pdf/2509.08872.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felipe Álvarez Barrientos, Tomás Banduc, Isabeau Sirven, Francisco Sahli Costabal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08872">WarpPINN-fibers: improved cardiac strain estimation from cine-MR with physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The contractile motion of the heart is strongly determined by the distribution of the fibers that constitute cardiac tissue. Strain analysis informed with the orientation of fibers allows to describe several pathologies that are typically associated with impaired mechanics of the myocardium, such as cardiovascular disease. Several methods have been developed to estimate strain-derived metrics from traditional imaging techniques. However, the physical models underlying these methods do not include fiber mechanics, restricting their capacity to accurately explain cardiac function. In this work, we introduce WarpPINN-fibers, a physics-informed neural network framework to accurately obtain cardiac motion and strains enhanced by fiber information. We train our neural network to satisfy a hyper-elastic model and promote fiber contraction with the goal to predict the deformation field of the heart from cine magnetic resonance images. For this purpose, we build a loss function composed of three terms: a data-similarity loss between the reference and the warped template images, a regularizer enforcing near-incompressibility of cardiac tissue and a fiber-stretch penalization that controls strain in the direction of synthetically produced fibers. We show that our neural network improves the former WarpPINN model and effectively controls fiber stretch in a synthetic phantom experiment. Then, we demonstrate that WarpPINN-fibers outperforms alternative methodologies in landmark-tracking and strain curve prediction for a cine-MRI benchmark with a cohort of 15 healthy volunteers. We expect that our method will enable a more precise quantification of cardiac strains through accurate deformation fields that are consistent with fiber physiology, without requiring imaging techniques more sophisticated than MRI.
<div id='section'>Paperid: <span id='pid'>1685, <a href='https://arxiv.org/pdf/2509.08607.pdf' target='_blank'>https://arxiv.org/pdf/2509.08607.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pietro Fanti, Dario Izzo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08607">MasconCube: Fast and Accurate Gravity Modeling with an Explicit Representation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The geodesy of irregularly shaped small bodies presents fundamental challenges for gravitational field modeling, particularly as deep space exploration missions increasingly target asteroids and comets. Traditional approaches suffer from critical limitations: spherical harmonics diverge within the Brillouin sphere where spacecraft typically operate, polyhedral models assume unrealistic homogeneous density distributions, and existing machine learning methods like GeodesyNets and Physics-Informed Neural Networks (PINN-GM) require extensive computational resources and training time. This work introduces MasconCubes, a novel self-supervised learning approach that formulates gravity inversion as a direct optimization problem over a regular 3D grid of point masses (mascons). Unlike implicit neural representations, MasconCubes explicitly model mass distributions while leveraging known asteroid shape information to constrain the solution space. Comprehensive evaluation on diverse asteroid models including Bennu, Eros, Itokawa, and synthetic planetesimals demonstrates that MasconCubes achieve superior performance across multiple metrics. Most notably, MasconCubes demonstrate computational efficiency advantages with training times approximately 40 times faster than GeodesyNets while maintaining physical interpretability through explicit mass distributions. These results establish MasconCubes as a promising approach for mission-critical gravitational modeling applications requiring high accuracy, computational efficiency, and physical insight into internal mass distributions of irregular celestial bodies.
<div id='section'>Paperid: <span id='pid'>1686, <a href='https://arxiv.org/pdf/2509.07603.pdf' target='_blank'>https://arxiv.org/pdf/2509.07603.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehdi Bejani, Marco Mauri, Daniele Acconcia, Simone Todaro, Stefano Mariani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07603">Transformer-Based Approach to Optimal Sensor Placement for Structural Health Monitoring of Probe Cards</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents an innovative Transformer-based deep learning strategy for optimizing the placement of sensors aiming at structural health monitoring of semiconductor probe cards. Failures in probe cards, including substrate cracks and loosened screws, would critically affect semiconductor manufacturing yield and reliability. Some failure modes could be detected by equipping a probe card with adequate sensors. Frequency response functions from simulated failure scenarios are adopted within a finite element model of a probe card. A comprehensive dataset, enriched by physics-informed scenario expansion and physics-aware statistical data augmentation, is exploited to train a hybrid Convolutional Neural Network and Transformer model. The model achieves high accuracy (99.83%) in classifying the probe card health states (baseline, loose screw, crack) and an excellent crack detection recall (99.73%). Model robustness is confirmed through a rigorous framework of 3 repetitions of 10-fold stratified cross-validation. The attention mechanism also pinpoints critical sensor locations: an analysis of the attention weights offers actionable insights for designing efficient, cost-effective monitoring systems by optimizing sensor configurations. This research highlights the capability of attention-based deep learning to advance proactive maintenance, enhancing operational reliability and yield in semiconductor manufacturing.
<div id='section'>Paperid: <span id='pid'>1687, <a href='https://arxiv.org/pdf/2509.03370.pdf' target='_blank'>https://arxiv.org/pdf/2509.03370.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akash Malhotra, Nacéra Seghouani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03370">Neural Field Turing Machine: A Differentiable Spatial Computer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce the Neural Field Turing Machine (NFTM), a differentiable architecture that unifies symbolic computation, physical simulation, and perceptual inference within continuous spatial fields. NFTM combines a neural controller, continuous memory field, and movable read/write heads that perform local updates. At each timestep, the controller reads local patches, computes updates via learned rules, and writes them back while updating head positions. This design achieves linear O(N) scaling through fixed-radius neighborhoods while maintaining Turing completeness under bounded error. We demonstrate three example instantiations of NFTM: cellular automata simulation (Rule 110), physics-informed PDE solvers (2D heat equation), and iterative image refinement (CIFAR-10 inpainting). These instantiations learn local update rules that compose into global dynamics, exhibit stable long-horizon rollouts, and generalize beyond training horizons. NFTM provides a unified computational substrate bridging discrete algorithms and continuous field dynamics within a single differentiable framework.
<div id='section'>Paperid: <span id='pid'>1688, <a href='https://arxiv.org/pdf/2509.03036.pdf' target='_blank'>https://arxiv.org/pdf/2509.03036.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bilge Taskin, Wenxiong Xie, Teddy Lazebnik
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03036">Knowledge Integration for Physics-informed Symbolic Regression Using Pre-trained Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Symbolic regression (SR) has emerged as a powerful tool for automated scientific discovery, enabling the derivation of governing equations from experimental data. A growing body of work illustrates the promise of integrating domain knowledge into the SR to improve the discovered equation's generality and usefulness. Physics-informed SR (PiSR) addresses this by incorporating domain knowledge, but current methods often require specialized formulations and manual feature engineering, limiting their adaptability only to domain experts. In this study, we leverage pre-trained Large Language Models (LLMs) to facilitate knowledge integration in PiSR. By harnessing the contextual understanding of LLMs trained on vast scientific literature, we aim to automate the incorporation of domain knowledge, reducing the need for manual intervention and making the process more accessible to a broader range of scientific problems. Namely, the LLM is integrated into the SR's loss function, adding a term of the LLM's evaluation of the SR's produced equation. We extensively evaluate our method using three SR algorithms (DEAP, gplearn, and PySR) and three pre-trained LLMs (Falcon, Mistral, and LLama 2) across three physical dynamics (dropping ball, simple harmonic motion, and electromagnetic wave). The results demonstrate that LLM integration consistently improves the reconstruction of physical dynamics from data, enhancing the robustness of SR models to noise and complexity. We further explore the impact of prompt engineering, finding that more informative prompts significantly improve performance.
<div id='section'>Paperid: <span id='pid'>1689, <a href='https://arxiv.org/pdf/2509.02607.pdf' target='_blank'>https://arxiv.org/pdf/2509.02607.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nisanth Kumar Panneerselvam, Guneet Mummaneni, Emilie Roncali
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02607">Towards Digital Twins for Optimal Radioembolization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Radioembolization is a localized liver cancer treatment that delivers radioactive microspheres (30 micron) to tumors via a catheter inserted in the hepatic arterial tree. The goal is to maximize therapeutic efficacy while minimizing damage to healthy liver tissue. However, optimization is challenging due to complex hepatic artery anatomy, variable blood flow, and uncertainty in microsphere transport. The creation of dynamic, patient-specific digital twins may provide a transformative solution to these challenges. This work outlines a framework for a liver radioembolization digital twin using high-fidelity computational fluid dynamics (CFD) and/or recent physics-informed machine learning approaches. The CFD approach involves microsphere transport calculations in the hepatic arterial tree with individual patient data, which enables personalized treatment planning. Although accurate, traditional CFD is computationally expensive and limits clinical applicability. To accelerate simulations, physics-informed neural networks (PINNs) and their generative extensions play an increasingly important role. PINNs integrate governing equations, such as the Navier-Stokes equations, directly into the neural network training process, enabling mesh-free, data-efficient approximation of blood flow and microsphere transport. Physics-informed generative adversarial networks (PI-GANs), diffusion models (PI-DMs), and transformer-based architectures further enable uncertainty-aware, temporally resolved predictions with reduced computational cost. These AI surrogates not only maintain physical fidelity but also support rapid sampling of diverse flow scenarios, facilitating real-time decision support. Together, CFD and physics-informed AI methods form the foundation of dynamic, patient-specific digital twin to optimize radioembolization planning and ultimately improve clinical outcomes.
<div id='section'>Paperid: <span id='pid'>1690, <a href='https://arxiv.org/pdf/2509.01072.pdf' target='_blank'>https://arxiv.org/pdf/2509.01072.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Idowu Paul Okuwobi, Jingyuan Liu, Jifeng Wan, Jiaojiao Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01072">DRetNet: A Novel Deep Learning Framework for Diabetic Retinopathy Diagnosis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diabetic retinopathy (DR) is a leading cause of blindness worldwide, necessitating early detection to prevent vision loss. Current automated DR detection systems often struggle with poor-quality images, lack interpretability, and insufficient integration of domain-specific knowledge. To address these challenges, we introduce a novel framework that integrates three innovative contributions: (1) Adaptive Retinal Image Enhancement Using Physics-Informed Neural Networks (PINNs): this technique dynamically enhances retinal images by incorporating physical constraints, improving the visibility of critical features such as microaneurysms, hemorrhages, and exudates; (2) Hybrid Feature Fusion Network (HFFN): by combining deep learning embeddings with handcrafted features, HFFN leverages both learned representations and domain-specific knowledge to enhance generalization and accuracy; (3) Multi-Stage Classifier with Uncertainty Quantification: this method breaks down the classification process into logical stages, providing interpretable predictions and confidence scores, thereby improving clinical trust. The proposed framework achieves an accuracy of 92.7%, a precision of 92.5%, a recall of 92.6%, an F1-score of 92.5%, an AUC of 97.8%, a mAP of 0.96, and an MCC of 0.85. Ophthalmologists rated the framework's predictions as highly clinically relevant (4.8/5), highlighting its alignment with real-world diagnostic needs. Qualitative analyses, including Grad-CAM visualizations and uncertainty heatmaps, further enhance the interpretability and trustworthiness of the system. The framework demonstrates robust performance across diverse conditions, including low-quality images, noisy data, and unseen datasets. These features make the proposed framework a promising tool for clinical adoption, enabling more accurate and reliable DR detection in resource-limited settings.
<div id='section'>Paperid: <span id='pid'>1691, <a href='https://arxiv.org/pdf/2509.00808.pdf' target='_blank'>https://arxiv.org/pdf/2509.00808.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Chen, Sanglin Zhao, Baoyu Chen, Mans Gustaf
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.00808">Adaptive Contrast Adjustment Module: A Clinically-Inspired Plug-and-Play Approach for Enhanced Fetal Plane Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fetal ultrasound standard plane classification is essential for reliable prenatal diagnosis but faces inherent challenges, including low tissue contrast, boundary ambiguity, and operator-dependent image quality variations. To overcome these limitations, we propose a plug-and-play adaptive contrast adjustment module (ACAM), whose core design is inspired by the clinical practice of doctors adjusting image contrast to obtain clearer and more discriminative structural information. The module employs a shallow texture-sensitive network to predict clinically plausible contrast parameters, transforms input images into multiple contrast-enhanced views through differentiable mapping, and fuses them within downstream classifiers. Validated on a multi-center dataset of 12,400 images across six anatomical categories, the module consistently improves performance across diverse models, with accuracy of lightweight models increasing by 2.02 percent, accuracy of traditional models increasing by 1.29 percent, and accuracy of state-of-the-art models increasing by 1.15 percent. The innovation of the module lies in its content-aware adaptation capability, replacing random preprocessing with physics-informed transformations that align with sonographer workflows while improving robustness to imaging heterogeneity through multi-view fusion. This approach effectively bridges low-level image features with high-level semantics, establishing a new paradigm for medical image analysis under real-world image quality variations.
<div id='section'>Paperid: <span id='pid'>1692, <a href='https://arxiv.org/pdf/2509.00049.pdf' target='_blank'>https://arxiv.org/pdf/2509.00049.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Nooraiepour, Mohammad Masoudi, Zezhang Song, Helge Hellevang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.00049">Adaptive Physics-Informed Neural Networks with Multi-Category Feature Engineering for Hydrogen Sorption Prediction in Clays, Shales, and Coals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate prediction of hydrogen sorption in clays, shales, and coals is vital for advancing underground hydrogen storage, natural hydrogen exploration, and radioactive waste containment. Traditional experimental methods, while foundational, are time-consuming, error-prone, and limited in capturing geological heterogeneity. This study introduces an adaptive physics-informed neural network (PINN) framework with multi-category feature engineering to enhance hydrogen sorption prediction. The framework integrates classical isotherm models with thermodynamic constraints to ensure physical consistency while leveraging deep learning flexibility. A comprehensive dataset consisting of 155 samples, which includes 50 clays, 60 shales, and 45 coals, was employed, incorporating diverse compositional properties and experimental conditions. Multi-category feature engineering across seven categories captured complex sorption dynamics. The PINN employs deep residual networks with multi-head attention, optimized via adaptive loss functions and Monte Carlo dropout for uncertainty quantification. K-fold cross-validation and hyperparameter optimization achieve significant accuracy (R2 = 0.979, RMSE = 0.045 mol per kg) with 67% faster convergence despite 15-fold increased complexity. The framework demonstrates robust lithology-specific performance across clay minerals (R2 = 0.981), shales (R2 = 0.971), and coals (R2 = 0.978), maintaining 85-91% reliability scores. Interpretability analysis via SHAP, accumulated local effects, and Friedman's H-statistics reveal that hydrogen adsorption capacity dominates predictions, while 86.7% of feature pairs exhibit strong interactions, validating the necessity of non-linear modeling approaches. This adaptive physics-informed framework accelerates site screening and enables risk-informed decision-making through robust uncertainty quantification.
<div id='section'>Paperid: <span id='pid'>1693, <a href='https://arxiv.org/pdf/2508.20440.pdf' target='_blank'>https://arxiv.org/pdf/2508.20440.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xun Yang, Guanqiu Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20440">D3PINNs: A Novel Physics-Informed Neural Network Framework for Staged Solving of Time-Dependent Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a novel framework, Dynamic Domain Decomposition Physics-Informed Neural Networks (D3PINNs), for solving time-dependent partial differential equations (PDEs). In this framework, solutions of time-dependent PDEs are dynamically captured. First, an approximate
  solution is obtained by the Physics-Informed Neural Networks (PINNs) containing the domain decomposition, then the time derivative terms in the PDE will be retained and the other terms associated with the solution will be replaced with the approximate solution. As a result, the PDE reduces to an ordinary differential equations (ODEs). Finally, the time-varying solution will be solved by the classical numerical methods for ODEs. D3PINNs retain the computational efffciency and ffexibility inherent to PINNs and enhance the ability for capturing solutions of time-dependent PDEs. Numerical experiments validate the effectiveness of the proposed methods.
<div id='section'>Paperid: <span id='pid'>1694, <a href='https://arxiv.org/pdf/2508.18954.pdf' target='_blank'>https://arxiv.org/pdf/2508.18954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kyriakos Hjikakou, Juan Diego Cardenas Cartagena, Matthia Sabatelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18954">On the Generalisation of Koopman Representations for Chaotic System Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates the generalisability of Koopman-based representations for chaotic dynamical systems, focusing on their transferability across prediction and control tasks. Using the Lorenz system as a testbed, we propose a three-stage methodology: learning Koopman embeddings through autoencoding, pre-training a transformer on next-state prediction, and fine-tuning for safety-critical control. Our results show that Koopman embeddings outperform both standard and physics-informed PCA baselines, achieving accurate and data-efficient performance. Notably, fixing the pre-trained transformer weights during fine-tuning leads to no performance degradation, indicating that the learned representations capture reusable dynamical structure rather than task-specific patterns. These findings support the use of Koopman embeddings as a foundation for multi-task learning in physics-informed machine learning. A project page is available at https://kikisprdx.github.io/.
<div id='section'>Paperid: <span id='pid'>1695, <a href='https://arxiv.org/pdf/2508.17303.pdf' target='_blank'>https://arxiv.org/pdf/2508.17303.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dhiraj S Kori, Abhinav Chandraker, Syed Abdur Rahman, Punit Rathore, Ankur Chauhan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17303">Physics-informed neural network for fatigue life prediction of irradiated austenitic and ferritic/martensitic steels</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study proposes a Physics-Informed Neural Network (PINN) framework to predict the low-cycle fatigue (LCF) life of irradiated austenitic and ferritic/martensitic (F/M) steels used in nuclear reactors. These materials experience cyclic loading and irradiation at elevated temperatures, causing complex degradation that traditional empirical models fail to capture accurately. The developed PINN model incorporates physical fatigue life constraints into its loss function, improving prediction accuracy and generalizability. Trained on 495 data points, including both irradiated and unirradiated conditions, the model outperforms traditional machine learning models like Random Forest, Gradient Boosting, eXtreme Gradient Boosting, and the conventional Neural Network. SHapley Additive exPlanations analysis identifies strain amplitude, irradiation dose, and testing temperature as dominant features, each inversely correlated with fatigue life, consistent with physical understanding. PINN captures saturation behaviour in fatigue life at higher strain amplitudes in F/M steels. Overall, the PINN framework offers a reliable and interpretable approach for predicting fatigue life in irradiated alloys, enabling informed alloy selection.
<div id='section'>Paperid: <span id='pid'>1696, <a href='https://arxiv.org/pdf/2508.15394.pdf' target='_blank'>https://arxiv.org/pdf/2508.15394.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun Choi, Chang-Ock Lee, Minam Moon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15394">Hybrid Least Squares/Gradient Descent Methods for DeepONets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose an efficient hybrid least squares/gradient descent method to accelerate DeepONet training. Since the output of DeepONet can be viewed as linear with respect to the last layer parameters of the branch network, these parameters can be optimized using a least squares (LS) solve, and the remaining hidden layer parameters are updated by means of gradient descent form. However, building the LS system for all possible combinations of branch and trunk inputs yields a prohibitively large linear problem that is infeasible to solve directly. To address this issue, our method decomposes the large LS system into two smaller, more manageable subproblems $\unicode{x2014}$ one for the branch network and one for the trunk network $\unicode{x2014}$ and solves them separately. This method is generalized to a broader type of $L^2$ loss with a regularization term for the last layer parameters, including the case of unsupervised learning with physics-informed loss.
<div id='section'>Paperid: <span id='pid'>1697, <a href='https://arxiv.org/pdf/2508.14127.pdf' target='_blank'>https://arxiv.org/pdf/2508.14127.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>S. Josyula, Y. Noiman, E. J. Payton, T. Giovannelli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14127">Comparison of derivative-free and gradient-based minimization for multi-objective compositional design of shape memory alloys</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing shape memory alloys (SMAs) that meet performance targets while remaining affordable and sustainable is a complex challenge. In this work, we focus on optimizing SMA compositions to achieve a desired martensitic start temperature (Ms) while minimizing cost. To do this, we use machine learning models as surrogate predictors and apply numerical optimization methods to search for suitable alloy combinations. We trained two types of machine learning models, a tree-based ensemble and a neural network, using a dataset of experimentally characterized alloys and physics-informed features. The tree-based model was used with a derivative-free optimizer (COBYLA), while the neural network, which provides gradient information, was paired with a gradient-based optimizer (TRUST-CONSTR). Our results show that while both models predict Ms with similar accuracy, the optimizer paired with the neural network finds better solutions more consistently. COBYLA often converged to suboptimal results, especially when the starting guess was far from the target. The TRUST-CONSTR method showed more stable behavior and was better at reaching alloy compositions that met both objectives. This study demonstrates a practical approach to exploring new SMA compositions by combining physics-informed data, machine learning models, and optimization algorithms. Although the scale of our dataset is smaller than simulation-based efforts, the use of experimental data improves the reliability of the predictions. The approach can be extended to other materials where design trade-offs must be made with limited data.
<div id='section'>Paperid: <span id='pid'>1698, <a href='https://arxiv.org/pdf/2508.13559.pdf' target='_blank'>https://arxiv.org/pdf/2508.13559.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sukheon Kang, Youngkwon Kim, Jinkyu Yang, Seunghwa Ryu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13559">Physics-Informed Neural Networks for Programmable Origami Metamaterials with Controlled Deployment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Origami-inspired structures provide unprecedented opportunities for creating lightweight, deployable systems with programmable mechanical responses. However, their design remains challenging due to complex nonlinear mechanics, multistability, and the need for precise control of deployment forces. Here, we present a physics-informed neural network (PINN) framework for both forward prediction and inverse design of conical Kresling origami (CKO) without requiring pre-collected training data. By embedding mechanical equilibrium equations directly into the learning process, the model predicts complete energy landscapes with high accuracy while minimizing non-physical artifacts. The inverse design routine specifies both target stable-state heights and separating energy barriers, enabling freeform programming of the entire energy curve. This capability is extended to hierarchical CKO assemblies, where sequential layer-by-layer deployment is achieved through programmed barrier magnitudes. Finite element simulations and experiments on physical prototypes validate the designed deployment sequences and barrier ratios, confirming the robustness of the approach. This work establishes a versatile, data-free route for programming complex mechanical energy landscapes in origami-inspired metamaterials, offering broad potential for deployable aerospace systems, morphing structures, and soft robotic actuators.
<div id='section'>Paperid: <span id='pid'>1699, <a href='https://arxiv.org/pdf/2508.13216.pdf' target='_blank'>https://arxiv.org/pdf/2508.13216.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Santosh Humagain, Toni Schneidereit
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13216">Strategies for training point distributions in physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks approach the approximation of differential equations by directly incorporating their structure and given conditions in a loss function. This enables conditions like, e.g., invariants to be easily added during the modelling phase. In addition, the approach can be considered as mesh free and can be utilised to compute solutions on arbitrary grids after the training phase. Therefore, physics-informed neural networks are emerging as a promising alternative to solving differential equations with methods from numerical mathematics. However, their performance highly depends on a large variety of factors. In this paper, we systematically investigate and evaluate a core component of the approach, namely the training point distribution. We test two ordinary and two partial differential equations with five strategies for training data generation and shallow network architectures, with one and two hidden layers. In addition to common distributions, we introduce sine-based training points, which are motivated by the construction of Chebyshev nodes. The results are challenged by using certain parameter combinations like, e.g., random and fixed-seed weight initialisation for reproducibility. The results show the impact of the training point distributions on the solution accuracy and we find evidence that they are connected to the characteristics of the differential equation.
<div id='section'>Paperid: <span id='pid'>1700, <a href='https://arxiv.org/pdf/2508.11528.pdf' target='_blank'>https://arxiv.org/pdf/2508.11528.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juhi Soni, Markus Lange-Hegermann, Stefan Windmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.11528">Physics-Informed Diffusion Models for Unsupervised Anomaly Detection in Multivariate Time Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose an unsupervised anomaly detection approach based on a physics-informed diffusion model for multivariate time series data. Over the past years, diffusion model has demonstrated its effectiveness in forecasting, imputation, generation, and anomaly detection in the time series domain. In this paper, we present a new approach for learning the physics-dependent temporal distribution of multivariate time series data using a weighted physics-informed loss during diffusion model training. A weighted physics-informed loss is constructed using a static weight schedule. This approach enables a diffusion model to accurately approximate underlying data distribution, which can influence the unsupervised anomaly detection performance. Our experiments on synthetic and real-world datasets show that physics-informed training improves the F1 score in anomaly detection; it generates better data diversity and log-likelihood. Our model outperforms baseline approaches, additionally, it surpasses prior physics-informed work and purely data-driven diffusion models on a synthetic dataset and one real-world dataset while remaining competitive on others.
<div id='section'>Paperid: <span id='pid'>1701, <a href='https://arxiv.org/pdf/2508.08935.pdf' target='_blank'>https://arxiv.org/pdf/2508.08935.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ze Tao, Hanxuan Wang, Fujun Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.08935">LNN-PINN: A Unified Physics-Only Training Framework with Liquid Residual Blocks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have attracted considerable attention for their ability to integrate partial differential equation priors into deep learning frameworks; however, they often exhibit limited predictive accuracy when applied to complex problems. To address this issue, we propose LNN-PINN, a physics-informed neural network framework that incorporates a liquid residual gating architecture while preserving the original physics modeling and optimization pipeline to improve predictive accuracy. The method introduces a lightweight gating mechanism solely within the hidden-layer mapping, keeping the sampling strategy, loss composition, and hyperparameter settings unchanged to ensure that improvements arise purely from architectural refinement. Across four benchmark problems, LNN-PINN consistently reduced RMSE and MAE under identical training conditions, with absolute error plots further confirming its accuracy gains. Moreover, the framework demonstrates strong adaptability and stability across varying dimensions, boundary conditions, and operator characteristics. In summary, LNN-PINN offers a concise and effective architectural enhancement for improving the predictive accuracy of physics-informed neural networks in complex scientific and engineering problems.
<div id='section'>Paperid: <span id='pid'>1702, <a href='https://arxiv.org/pdf/2508.08002.pdf' target='_blank'>https://arxiv.org/pdf/2508.08002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongxin Yu, Yibing Wang, Fengyue Jin, Meng Zhang, Anni Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.08002">A Physics-informed Deep Operator for Real-Time Freeway Traffic State Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traffic state estimation (TSE) falls methodologically into three categories: model-driven, data-driven, and model-data dual-driven. Model-driven TSE relies on macroscopic traffic flow models originated from hydrodynamics. Data-driven TSE leverages historical sensing data and employs statistical models or machine learning methods to infer traffic state. Model-data dual-driven traffic state estimation attempts to harness the strengths of both aspects to achieve more accurate TSE. From the perspective of mathematical operator theory, TSE can be viewed as a type of operator that maps available measurements of inerested traffic state into unmeasured traffic state variables in real time. For the first time this paper proposes to study real-time freeway TSE in the idea of physics-informed deep operator network (PI-DeepONet), which is an operator-oriented architecture embedding traffic flow models based on deep neural networks. The paper has developed an extended architecture from the original PI-DeepONet. The extended architecture is featured with: (1) the acceptance of 2-D data input so as to support CNN-based computations; (2) the introduction of a nonlinear expansion layer, an attention mechanism, and a MIMO mechanism; (3) dedicated neural network design for adaptive identification of traffic flow model parameters. A traffic state estimator built on the basis of this extended PI-DeepONet architecture was evaluated with respect to a short freeway stretch of NGSIM and a large-scale urban expressway in China, along with other four baseline TSE methods. The evaluation results demonstrated that this novel TSE method outperformed the baseline methods with high-precision estimation results of flow and mean speed.
<div id='section'>Paperid: <span id='pid'>1703, <a href='https://arxiv.org/pdf/2508.07546.pdf' target='_blank'>https://arxiv.org/pdf/2508.07546.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Feng Han, Jianguo Wang, Guoliang Peng, Xueting Shi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07546">Physics-informed Multiresolution Wavelet Neural Network Method for Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, a physics-informed multiresolution wavelet neural network (PIMWNN) method is proposed for solving partial differential equations (PDEs). This method uses the multiresolution wavelet neural network (MWNN) to approximate unknown functions, then substituting the MWNN into PDEs and training the MWNN by least-squares algorithm. We apply the proposed method to various problems, including stationary/nonstationary advection, diffusion and advection-diffusion problems, and linear/nonlinear time-dependent problems. Numerical experiments show that the PIMWNN method can achieve higher accuracy and faster speed than Physics Informed Neural Networks (PINNs). Moreover, the PIMWNN method, being mesh-free, can handle different boundary conditions easily and solve the time-dependent problems efficiently. The proposed method is expected to solve the spectral bias problem in network training. These characteristics show the great potential of the PIMWNN method used in the field of numerical solving methods for PDEs.
<div id='section'>Paperid: <span id='pid'>1704, <a href='https://arxiv.org/pdf/2508.04595.pdf' target='_blank'>https://arxiv.org/pdf/2508.04595.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan A. Zak, Christian WeiÃenfels
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.04595">Improved Training Strategies for Physics-Informed Neural Networks using Real Experimental Data in Aluminum Spot Welding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Resistance spot welding is the dominant joining process for the body-in-white in the automotive industry, where the weld nugget diameter is the key quality metric. Its measurement requires destructive testing, limiting the potential for efficient quality control. Physics-informed neural networks were investigated as a promising tool to reconstruct internal process states from experimental data, enabling model-based and non-invasive quality assessment in aluminum spot welding. A major challenge is the integration of real-world data into the network due to competing optimization objectives. To address this, we introduce two novel training strategies. First, experimental losses for dynamic displacement and nugget diameter are progressively included using a fading-in function to prevent excessive optimization conflicts. We also implement a custom learning rate scheduler and early stopping based on a rolling window to counteract premature reduction due to increased loss magnitudes. Second, we introduce a conditional update of temperature-dependent material parameters via a look-up table, activated only after a loss threshold is reached to ensure physically meaningful temperatures. An axially symmetric two-dimensional model was selected to represent the welding process accurately while maintaining computational efficiency. To reduce computational burden, the training strategies and model components were first systematically evaluated in one dimension, enabling controlled analysis of loss design and contact models. The two-dimensional network predicts dynamic displacement and nugget growth within the experimental confidence interval, supports transferring welding stages from steel to aluminum, and demonstrates strong potential for fast, model-based quality control in industrial applications.
<div id='section'>Paperid: <span id='pid'>1705, <a href='https://arxiv.org/pdf/2508.04198.pdf' target='_blank'>https://arxiv.org/pdf/2508.04198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Gao, Hai Zhang, Kai Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.04198">Optimal Design of Broadband Absorbers with Multiple Plasmonic Nanoparticles via Reduced Basis Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we propose a computational framework for the optimal design of broadband absorbing materials composed of plasmonic nanoparticle arrays. This design problem poses several key challenges: (1) the complex multi-particle interactions and high-curvature geometries; (2) the requirement to achieve broadband frequency responses, including resonant regimes; (3) the complexity of shape derivative calculations; and (4) the non-convexity of the optimization landscape. To systematically address these challenges, we employ three sequential strategies. First, we introduce a parameterized integral equation formulation that circumvents traditional shape derivative computations. Second, we develop a shape-adaptive reduced basis method (RBM) that utilizes the eigenfunctions of the Neumann-PoincarÃ© operator for forward problems and their adjoint counterparts for adjoint problems, thereby addressing singularities and accelerating computations. Third, we propose a physics-informed initialization strategy that estimates nanoparticle configurations under weak coupling assumptions, thereby improving the performance of gradient-based optimization algorithms. The method's computational advantages are demonstrated through numerical experiments, which show accurate and efficient designs across various geometric configurations. Furthermore, the framework is flexible and extensible to other material systems and boundary conditions.
<div id='section'>Paperid: <span id='pid'>1706, <a href='https://arxiv.org/pdf/2508.03965.pdf' target='_blank'>https://arxiv.org/pdf/2508.03965.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunhao Zhang, Lin Cheng, Aswin Gnanaskandan, Ameya D. Jagtap
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03965">BubbleONet: A Physics-Informed Neural Operator for High-Frequency Bubble Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces BubbleONet, an operator learning model designed to map pressure profiles from an input function space to corresponding bubble radius responses. BubbleONet is built upon the physics-informed deep operator network (PI-DeepONet) framework, leveraging DeepONet's powerful universal approximation capabilities for operator learning alongside the robust physical fidelity provided by the physics-informed neural networks. To mitigate the inherent spectral bias in deep learning, BubbleONet integrates the Rowdy adaptive activation function, enabling improved representation of high-frequency features. The model is evaluated across various scenarios, including: (1) Rayleigh-Plesset equation based bubble dynamics with a single initial radius, (2) Keller-Miksis equation based bubble dynamics with a single initial radius, and (3) Keller-Miksis equation based bubble dynamics with multiple initial radii. Moreover, the performance of single-step versus two-step training techniques for BubbleONet is investigated. The results demonstrate that BubbleONet serves as a promising surrogate model for simulating bubble dynamics, offering a computationally efficient alternative to traditional numerical solvers.
<div id='section'>Paperid: <span id='pid'>1707, <a href='https://arxiv.org/pdf/2508.03278.pdf' target='_blank'>https://arxiv.org/pdf/2508.03278.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Albertus Denny Handoko, Riko I Made
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03278">Artificial Intelligence and Generative Models for Materials Discovery -- A Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High throughput experimentation tools, machine learning (ML) methods, and open material databases are radically changing the way new materials are discovered. From the experimentally driven approach in the past, we are moving quickly towards the artificial intelligence (AI) driven approach, realizing the 'inverse design' capabilities that allow the discovery of new materials given the desired properties. This review aims to discuss different principles of AI-driven generative models that are applicable for materials discovery, including different materials representations available for this purpose. We will also highlight specific applications of generative models in designing new catalysts, semiconductors, polymers, or crystals while addressing challenges such as data scarcity, computational cost, interpretability, synthesizability, and dataset biases. Emerging approaches to overcome limitations and integrate AI with experimental workflows will be discussed, including multimodal models, physics informed architectures, and closed-loop discovery systems. This review aims to provide insights for researchers aiming to harness AI's transformative potential in accelerating materials discovery for sustainability, healthcare, and energy innovation.
<div id='section'>Paperid: <span id='pid'>1708, <a href='https://arxiv.org/pdf/2508.02537.pdf' target='_blank'>https://arxiv.org/pdf/2508.02537.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xi Chen, Jianchuan Yang, Junjie Zhang, Runnan Yang, Xu Liu, Hong Wang, Tinghui Zheng, Ziyu Ren, Wenqi Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02537">Solved in Unit Domain: JacobiNet for Differentiable Coordinate-Transformed PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks offer a powerful framework for solving PDEs by embedding physical laws into the learning process. However, when applied to domains with irregular boundaries, PINNs often suffer from instability and slow convergence, which stems from (1) inconsistent normalization due to geometric anisotropy, (2) inaccurate boundary enforcements, and (3) imbalanced loss term competition. A common workaround is to map the domain to a regular space. Yet, conventional mapping methods rely on case-specific meshes, define Jacobians at pre-specified fixed nodes, reformulate PDEs via the chain rule-making them incompatible with modern automatic differentiation, tensor-based frameworks. To bridge this gap, we propose JacobiNet, a learning-based coordinate-transformed PINN framework that unifies domain mapping and PDE solving within an end-to-end differentiable architecture. Leveraging lightweight MLPs, JacobiNet learns continuous, differentiable mappings, enables direct Jacobian computation via autograd, shares computation graph with downstream PINNs. Its continuous nature and built-in Jacobian eliminate the need for meshing, explicit Jacobians computation/ storage, and PDE reformulation, while unlocking geometric-editing operations, reducing the mapping cost. Separating physical modeling from geometric complexity, JacobiNet (1) addresses normalization challenges in the original anisotropic coordinates, (2) facilitates hard constraints of boundary conditions, and (3) mitigates the long-standing imbalance among loss terms. Evaluated on various PDEs, JacobiNet reduces the L2 error from 0.11-0.73 to 0.01-0.09. In vessel-like domains with varying shapes, JacobiNet enables millisecond-level mapping inference for unseen geometries, improves prediction accuracy by an average of 3.65*, while delivering over 10* speed up-demonstrating strong generalization, accuracy, and efficiency.
<div id='section'>Paperid: <span id='pid'>1709, <a href='https://arxiv.org/pdf/2508.01951.pdf' target='_blank'>https://arxiv.org/pdf/2508.01951.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dekang Meng, Rabab Haider, Pascal van Hentenryck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.01951">Flow-Aware GNN for Transmission Network Reconfiguration via Substation Breaker Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces OptiGridML, a machine learning framework for discrete topology optimization in power grids. The task involves selecting substation breaker configurations that maximize cross-region power exports, a problem typically formulated as a mixed-integer program (MIP) that is NP-hard and computationally intractable for large networks. OptiGridML replaces repeated MIP solves with a two-stage neural architecture: a line-graph neural network (LGNN) that approximates DC power flows for a given network topology, and a heterogeneous GNN (HeteroGNN) that predicts breaker states under structural and physical constraints. A physics-informed consistency loss connects these components by enforcing Kirchhoff's law on predicted flows. Experiments on synthetic networks with up to 1,000 breakers show that OptiGridML achieves power export improvements of up to 18% over baseline topologies, while reducing inference time from hours to milliseconds. These results demonstrate the potential of structured, flow-aware GNNs for accelerating combinatorial optimization in physical networked systems.
<div id='section'>Paperid: <span id='pid'>1710, <a href='https://arxiv.org/pdf/2508.01314.pdf' target='_blank'>https://arxiv.org/pdf/2508.01314.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vamsi Sai Krishna Malineni, Suresh Rajendran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.01314">Physics-Informed Neural Network Approaches for Sparse Data Flow Reconstruction of Unsteady Flow Around Complex Geometries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The utilization of Deep Neural Networks (DNNs) in physical science and engineering applications has gained traction due to their capacity to learn intricate functions. While large datasets are crucial for training DNN models in fields like computer vision and natural language processing, obtaining such datasets for engineering applications is prohibitively expensive. Physics-Informed Neural Networks (PINNs), a branch of Physics-Informed Machine Learning (PIML), tackle this challenge by embedding physical principles within neural network architectures. PINNs have been extensively explored for solving diverse forward and inverse problems in fluid mechanics. Nonetheless, there is limited research on employing PINNs for flow reconstruction from sparse data under constrained computational resources. Earlier studies were focused on forward problems with well-defined data. The present study attempts to develop models capable of reconstructing the flow field data from sparse datasets mirroring real-world scenarios.
  This study focuses on two cases: (a) two-dimensional (2D) unsteady laminar flow past a circular cylinder and (b) three-dimensional (3D) unsteady turbulent flow past an ultra-large container ship (ULCS). The first case compares the effectiveness of training methods like Standard PINN and Backward Compatible PINN (BC-PINN) and explores the performance enhancements through systematic relaxation of physics constraints and dynamic weighting of loss function components. The second case highlights the capability of PINN-based models to learn underlying physics from sparse data while accurately reconstructing the flow field for a highly turbulent flow.
<div id='section'>Paperid: <span id='pid'>1711, <a href='https://arxiv.org/pdf/2508.00855.pdf' target='_blank'>https://arxiv.org/pdf/2508.00855.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyang Zhang, Feifan Zhang, Weidong Tang, Lei Shi, Tailai Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00855">A Residual Guided strategy with Generative Adversarial Networks in training Physics-Informed Transformer Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nonlinear partial differential equations (PDEs) are pivotal in modeling complex physical systems, yet traditional Physics-Informed Neural Networks (PINNs) often struggle with unresolved residuals in critical spatiotemporal regions and violations of temporal causality. To address these limitations, we propose a novel Residual Guided Training strategy for Physics-Informed Transformer via Generative Adversarial Networks (GAN). Our framework integrates a decoder-only Transformer to inherently capture temporal correlations through autoregressive processing, coupled with a residual-aware GAN that dynamically identifies and prioritizes high-residual regions. By introducing a causal penalty term and an adaptive sampling mechanism, the method enforces temporal causality while refining accuracy in problematic domains. Extensive numerical experiments on the Allen-Cahn, Klein-Gordon, and Navier-Stokes equations demonstrate significant improvements, achieving relative MSE reductions of up to three orders of magnitude compared to baseline methods. This work bridges the gap between deep learning and physics-driven modeling, offering a robust solution for multiscale and time-dependent PDE systems.
<div id='section'>Paperid: <span id='pid'>1712, <a href='https://arxiv.org/pdf/2507.21437.pdf' target='_blank'>https://arxiv.org/pdf/2507.21437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tiantian Sun, Jian Zu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21437">PVD-ONet: A Multi-scale Neural Operator Method for Singularly Perturbed Boundary Layer Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks and Physics-informed DeepONet excel in solving partial differential equations; however, they often fail to converge for singularly perturbed problems. To address this, we propose two novel frameworks, Prandtl-Van Dyke neural network (PVD-Net) and its operator learning extension Prandtl-Van Dyke Deep Operator Network (PVD-ONet), which rely solely on governing equations without data. To address varying task-specific requirements, both PVD-Net and PVD-ONet are developed in two distinct versions, tailored respectively for stability-focused and high-accuracy modeling. The leading-order PVD-Net adopts a two-network architecture combined with Prandtl's matching condition, targeting stability-prioritized scenarios. The high-order PVD-Net employs a five-network design with Van Dyke's matching principle to capture fine-scale boundary layer structures, making it ideal for high-accuracy scenarios. PVD-ONet generalizes PVD-Net to the operator learning setting by assembling multiple DeepONet modules, directly mapping initial conditions to solution operators and enabling instant predictions for an entire family of boundary layer problems without retraining. Numerical experiments on various models show that our proposed methods consistently outperform existing baselines under various error metrics, thereby offering a powerful new approach for multi-scale problems.
<div id='section'>Paperid: <span id='pid'>1713, <a href='https://arxiv.org/pdf/2507.19522.pdf' target='_blank'>https://arxiv.org/pdf/2507.19522.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aarush Gupta, Kendric Hsu, Syna Mathod
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19522">Applications and Manipulations of Physics-Informed Neural Networks in Solving Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mathematical models in neural networks are powerful tools for solving complex differential equations and optimizing their parameters; that is, solving the forward and inverse problems, respectively. A forward problem predicts the output of a network for a given input by optimizing weights and biases. An inverse problem finds equation parameters or coefficients that effectively model the data. A Physics-Informed Neural Network (PINN) can solve both problems. PINNs inject prior analytical information about the data into the cost function to improve model performance outside the training set boundaries. This also allows PINNs to efficiently solve problems with sparse data without overfitting by extrapolating the model to fit larger trends in the data. The prior information we implement is in the form of differential equations. Residuals are the differences between the left-hand and right-hand sides of corresponding differential equations; PINNs minimize these residuals to effectively solve the differential equation and take advantage of prior knowledge. In this way, the solution and parameters are embedded into the loss function and optimized, allowing both the weights of the neural network and the model parameters to be found simultaneously, solving both the forward and inverse problems in the process. In this paper, we will create PINNs with residuals of varying complexity, beginning with linear and quadratic models and then expanding to fit models for the heat equation and other complex differential equations. We will mainly use Python as the computing language, using the PyTorch library to aid us in our research.
<div id='section'>Paperid: <span id='pid'>1714, <a href='https://arxiv.org/pdf/2507.18731.pdf' target='_blank'>https://arxiv.org/pdf/2507.18731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gaijinliu Gangmei, Santu Rana, Bernard Rolfe, Kishalay Mitra, Saswata Bhattacharyya
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18731">Learning coupled Allen-Cahn and Cahn-Hilliard phase-field equations using Physics-informed neural operator(PINO)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Phase-field equations, mostly solved numerically, are known for capturing the mesoscale microstructural evolution of a material. However, such numerical solvers are computationally expensive as it needs to generate fine mesh systems to solve the complex Partial Differential Equations(PDEs) with good accuracy. Therefore, we propose an alternative approach of predicting the microstructural evolution subjected to periodic boundary conditions using Physics informed Neural Operators (PINOs).
  In this study, we have demonstrated the capability of PINO to predict the growth of $Î¸^{\prime}$ precipitates in Al-Cu alloys by learning the operator as well as by solving three coupled physics equations simultaneously. The coupling is of two second-order Allen-Cahn equation and one fourth-order Cahn-Hilliard equation. We also found that using Fourier derivatives(pseudo-spectral method and Fourier extension) instead of Finite Difference Method improved the Cahn-Hilliard equation loss by twelve orders of magnitude. Moreover, since differentiation is equivalent to multiplication in the Fourier domain, unlike Physics informed Neural Networks(PINNs), we can easily compute the fourth derivative of Cahn-Hilliard equation without converting it to coupled second order derivative.
<div id='section'>Paperid: <span id='pid'>1715, <a href='https://arxiv.org/pdf/2507.18206.pdf' target='_blank'>https://arxiv.org/pdf/2507.18206.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arup Kumar Sahoo, Itzik Klein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18206">MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A fundamental requirement for full autonomy in mobile robots is accurate navigation even in situations where satellite navigation or cameras are unavailable. In such practical situations, relying only on inertial sensors will result in navigation solution drift due to the sensors' inherent noise and error terms. One of the emerging solutions to mitigate drift is to maneuver the robot in a snake-like slithering motion to increase the inertial signal-to-noise ratio, allowing the regression of the mobile robot position. In this work, we propose MoRPI-PINN as a physics-informed neural network framework for accurate inertial-based mobile robot navigation. By embedding physical laws and constraints into the training process, MoRPI-PINN is capable of providing an accurate and robust navigation solution. Using real-world experiments, we show accuracy improvements of over 85% compared to other approaches. MoRPI-PINN is a lightweight approach that can be implemented even on edge devices and used in any typical mobile robot application.
<div id='section'>Paperid: <span id='pid'>1716, <a href='https://arxiv.org/pdf/2507.16571.pdf' target='_blank'>https://arxiv.org/pdf/2507.16571.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>G. de RomÃ©mont, F. Renac, F. Chinesta, J. Nunez, D. Gueyffier
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16571">Data-Driven Adaptive Gradient Recovery for Unstructured Finite Volume Computations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel data-driven approach for enhancing gradient reconstruction in unstructured finite volume methods for hyperbolic conservation laws, specifically for the 2D Euler equations. Our approach extends previous structured-grid methodologies to unstructured meshes through a modified DeepONet architecture that incorporates local geometry in the neural network. The architecture employs local mesh topology to ensure rotation invariance, while also ensuring first-order constraint on the learned operator. The training methodology incorporates physics-informed regularization through entropy penalization, total variation diminishing penalization, and parameter regularization to ensure physically consistent solutions, particularly in shock-dominated regions. The model is trained on high-fidelity datasets solutions derived from sine waves and randomized piecewise constant initial conditions with periodic boundary conditions, enabling robust generalization to complex flow configurations or geometries. Validation test cases from the literature, including challenging geometry configuration, demonstrates substantial improvements in accuracy compared to traditional second-order finite volume schemes. The method achieves gains of 20-60% in solution accuracy while enhancing computational efficiency. A convergence study has been conveyed and reveal improved mesh convergence rates compared to the conventional solver. The proposed algorithm is faster and more accurate than the traditional second-order finite volume solver, enabling high-fidelity simulations on coarser grids while preserving the stability and conservation properties essential for hyperbolic conservation laws. This work is a part of a new generation of solvers that are built by combining Machine-Learning (ML) tools with traditional numerical schemes, all while ensuring physical constraint on the results.
<div id='section'>Paperid: <span id='pid'>1717, <a href='https://arxiv.org/pdf/2507.16431.pdf' target='_blank'>https://arxiv.org/pdf/2507.16431.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Ma, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16431">An effective physics-informed neural operator framework for predicting wavefields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving the wave equation is fundamental for geophysical applications. However, numerical solutions of the Helmholtz equation face significant computational and memory challenges. Therefore, we introduce a physics-informed convolutional neural operator (PICNO) to solve the Helmholtz equation efficiently. The PICNO takes both the background wavefield corresponding to a homogeneous medium and the velocity model as input function space, generating the scattered wavefield as the output function space. Our workflow integrates PDE constraints directly into the training process, enabling the neural operator to not only fit the available data but also capture the underlying physics governing wave phenomena. PICNO allows for high-resolution reasonably accurate predictions even with limited training samples, and it demonstrates significant improvements over a purely data-driven convolutional neural operator (CNO), particularly in predicting high-frequency wavefields. These features and improvements are important for waveform inversion down the road.
<div id='section'>Paperid: <span id='pid'>1718, <a href='https://arxiv.org/pdf/2507.16380.pdf' target='_blank'>https://arxiv.org/pdf/2507.16380.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhihan Zeng, Yiqi Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16380">Optimization and generalization analysis for two-layer physics-informed neural networks without over-parametrization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work focuses on the behavior of stochastic gradient descent (SGD) in solving least-squares regression with physics-informed neural networks (PINNs). Past work on this topic has been based on the over-parameterization regime, whose convergence may require the network width to increase vastly with the number of training samples. So, the theory derived from over-parameterization may incur prohibitive computational costs and is far from practical experiments. We perform new optimization and generalization analysis for SGD in training two-layer PINNs, making certain assumptions about the target function to avoid over-parameterization. Given $Îµ>0$, we show that if the network width exceeds a threshold that depends only on $Îµ$ and the problem, then the training loss and expected loss will decrease below $O(Îµ)$.
<div id='section'>Paperid: <span id='pid'>1719, <a href='https://arxiv.org/pdf/2507.16227.pdf' target='_blank'>https://arxiv.org/pdf/2507.16227.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixu Wang, Yuhan Wang, Junfei Ma, Fuyuan Wu, Junchi Yan, Xiaohui Yuan, Zhe Zhang, Jie Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16227">Predictive Hydrodynamic Simulations for Laser Direct-drive Implosion Experiments via Artificial Intelligence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents predictive hydrodynamic simulations empowered by artificial intelligence (AI) for laser driven implosion experiments, taking the double-cone ignition (DCI) scheme as an example. A Transformer-based deep learning model MULTI-Net is established to predict implosion features according to laser waveforms and target radius. A Physics-Informed Decoder (PID) is proposed for high-dimensional sampling, significantly reducing the prediction errors compared to Latin hypercube sampling. Applied to DCI experiments conducted on the SG-II Upgrade facility, the MULTI-Net model is able to predict the implosion dynamics measured by the x-ray streak camera. It is found that an effective laser absorption factor about 65\% is suitable for the one-dimensional simulations of the DCI-R10 experiments. For shot 33, the mean implosion velocity and collided plasma density reached 195 km/s and 117 g/cc, respectively. This study demonstrates a data-driven AI framework that enhances the prediction ability of simulations for complicated laser fusion experiments.
<div id='section'>Paperid: <span id='pid'>1720, <a href='https://arxiv.org/pdf/2507.15455.pdf' target='_blank'>https://arxiv.org/pdf/2507.15455.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hee Jun Yang, Minjung Gim, Yeoneung Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.15455">Solving nonconvex Hamilton--Jacobi--Isaacs equations with PINN-based policy iteration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a mesh-free policy iteration framework that combines classical dynamic programming with physics-informed neural networks (PINNs) to solve high-dimensional, nonconvex Hamilton--Jacobi--Isaacs (HJI) equations arising in stochastic differential games and robust control. The method alternates between solving linear second-order PDEs under fixed feedback policies and updating the controls via pointwise minimax optimization using automatic differentiation. Under standard Lipschitz and uniform ellipticity assumptions, we prove that the value function iterates converge locally uniformly to the unique viscosity solution of the HJI equation. The analysis establishes equi-Lipschitz regularity of the iterates, enabling provable stability and convergence without requiring convexity of the Hamiltonian. Numerical experiments demonstrate the accuracy and scalability of the method. In a two-dimensional stochastic path-planning game with a moving obstacle, our method matches finite-difference benchmarks with relative $L^2$-errors below %10^{-2}%. In five- and ten-dimensional publisher-subscriber differential games with anisotropic noise, the proposed approach consistently outperforms direct PINN solvers, yielding smoother value functions and lower residuals. Our results suggest that integrating PINNs with policy iteration is a practical and theoretically grounded method for solving high-dimensional, nonconvex HJI equations, with potential applications in robotics, finance, and multi-agent reinforcement learning.
<div id='section'>Paperid: <span id='pid'>1721, <a href='https://arxiv.org/pdf/2507.15021.pdf' target='_blank'>https://arxiv.org/pdf/2507.15021.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Soheil Radfar, Faezeh Maghsoodifar, Hamed Moftakhari, Hamid Moradkhani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.15021">Integrating Newton's Laws with deep learning for enhanced physics-informed compound flood modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Coastal communities increasingly face compound floods, where multiple drivers like storm surge, high tide, heavy rainfall, and river discharge occur together or in sequence to produce impacts far greater than any single driver alone. Traditional hydrodynamic models can provide accurate physics-based simulations but require substantial computational resources for real-time applications or risk assessments, while machine learning alternatives often sacrifice physical consistency for speed, producing unrealistic predictions during extreme events. This study addresses these challenges by developing ALPINE (All-in-one Physics Informed Neural Emulator), a physics-informed neural network (PINN) framework to enforce complete shallow water dynamics in compound flood modeling. Unlike previous approaches that implement partial constraints, our framework simultaneously enforces mass conservation and both momentum equations, ensuring full adherence to Newton's laws throughout the prediction process. The model integrates a convolutional encoder-decoder architecture with ConvLSTM temporal processing, trained using a composite loss function that balances data fidelity with physics-based residuals. Using six historical storm events (four for training, one for validation, and one held-out for unseen testing), we observe substantial improvements over baseline neural networks. ALPINE reduces domain-averaged prediction errors and improves model skill metrics for water surface elevation and velocity components. Physics-informed constraints prove most valuable during peak storm intensity, when multiple flood drivers interact and reliable predictions matter most. This approach yields a physically consistent emulator capable of supporting compound-flood forecasting and large-scale risk analyses while preserving physical realism essential for coastal emergency management.
<div id='section'>Paperid: <span id='pid'>1722, <a href='https://arxiv.org/pdf/2507.13542.pdf' target='_blank'>https://arxiv.org/pdf/2507.13542.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Beka Begiashvili, Carlos J. Fernandez-Candel, MatÃ­as PÃ©rez Paredes
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.13542">Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional echocardiographic parameters such as ejection fraction (EF) and global longitudinal strain (GLS) have limitations in the early detection of cardiac dysfunction. EF often remains normal despite underlying pathology, and GLS is influenced by load conditions and vendor variability. There is a growing need for reproducible, interpretable, and operator-independent parameters that capture subtle and global cardiac functional alterations.
  We introduce the Acoustic Index, a novel AI-derived echocardiographic parameter designed to quantify cardiac dysfunction from standard ultrasound views. The model combines Extended Dynamic Mode Decomposition (EDMD) based on Koopman operator theory with a hybrid neural network that incorporates clinical metadata. Spatiotemporal dynamics are extracted from echocardiographic sequences to identify coherent motion patterns. These are weighted via attention mechanisms and fused with clinical data using manifold learning, resulting in a continuous score from 0 (low risk) to 1 (high risk).
  In a prospective cohort of 736 patients, encompassing various cardiac pathologies and normal controls, the Acoustic Index achieved an area under the curve (AUC) of 0.89 in an independent test set. Cross-validation across five folds confirmed the robustness of the model, showing that both sensitivity and specificity exceeded 0.8 when evaluated on independent data. Threshold-based analysis demonstrated stable trade-offs between sensitivity and specificity, with optimal discrimination near this threshold.
  The Acoustic Index represents a physics-informed, interpretable AI biomarker for cardiac function. It shows promise as a scalable, vendor-independent tool for early detection, triage, and longitudinal monitoring. Future directions include external validation, longitudinal studies, and adaptation to disease-specific classifiers.
<div id='section'>Paperid: <span id='pid'>1723, <a href='https://arxiv.org/pdf/2507.13376.pdf' target='_blank'>https://arxiv.org/pdf/2507.13376.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dong Xiao, Zahra Sharif-Khodaei, M. H. Aliabadi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.13376">Physics-guided impact localisation and force estimation in composite plates with uncertainty quantification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-guided approaches offer a promising path toward accurate and generalisable impact identification in composite structures, especially when experimental data are sparse. This paper presents a hybrid framework for impact localisation and force estimation in composite plates, combining a data-driven implementation of First-Order Shear Deformation Theory (FSDT) with machine learning and uncertainty quantification. The structural configuration and material properties are inferred from dispersion relations, while boundary conditions are identified via modal characteristics to construct a low-fidelity but physically consistent FSDT model. This model enables physics-informed data augmentation for extrapolative localisation using supervised learning. Simultaneously, an adaptive regularisation scheme derived from the same model improves the robustness of impact force reconstruction. The framework also accounts for uncertainty by propagating localisation uncertainty through the force estimation process, producing probabilistic outputs. Validation on composite plate experiments confirms the framework's accuracy, robustness, and efficiency in reducing dependence on large training datasets. The proposed method offers a scalable and transferable solution for impact monitoring and structural health management in composite aerostructures.
<div id='section'>Paperid: <span id='pid'>1724, <a href='https://arxiv.org/pdf/2507.12600.pdf' target='_blank'>https://arxiv.org/pdf/2507.12600.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joy Xiaoji Zhang, Jingsen Zhu, Hanyu Chen, Steve Marschner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.12600">HairFormer: Transformer-Based Dynamic Neural Hair Simulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simulating hair dynamics that generalize across arbitrary hairstyles, body shapes, and motions is a critical challenge. Our novel two-stage neural solution is the first to leverage Transformer-based architectures for such a broad generalization. We propose a Transformer-powered static network that predicts static draped shapes for any hairstyle, effectively resolving hair-body penetrations and preserving hair fidelity. Subsequently, a dynamic network with a novel cross-attention mechanism fuses static hair features with kinematic input to generate expressive dynamics and complex secondary motions. This dynamic network also allows for efficient fine-tuning of challenging motion sequences, such as abrupt head movements. Our method offers real-time inference for both static single-frame drapes and dynamic drapes over pose sequences. Our method demonstrates high-fidelity and generalizable dynamic hair across various styles, guided by physics-informed losses, and can resolve penetrations even for complex, unseen long hairstyles, highlighting its broad generalization.
<div id='section'>Paperid: <span id='pid'>1725, <a href='https://arxiv.org/pdf/2507.10983.pdf' target='_blank'>https://arxiv.org/pdf/2507.10983.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Han, Zahra Taheri, Hyunwoong Ko
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.10983">Physics-Informed Neural Networks For Semiconductor Film Deposition: A Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semiconductor manufacturing relies heavily on film deposition processes, such as Chemical Vapor Deposition and Physical Vapor Deposition. These complex processes require precise control to achieve film uniformity, proper adhesion, and desired functionality. Recent advancements in Physics-Informed Neural Networks (PINNs), an innovative machine learning (ML) approach, have shown significant promise in addressing challenges related to process control, quality assurance, and predictive modeling within semiconductor film deposition and other manufacturing domains. This paper provides a comprehensive review of ML applications targeted at semiconductor film deposition processes. Through a thematic analysis, we identify key trends, existing limitations, and research gaps, offering insights into both the advantages and constraints of current methodologies. Our structured analysis aims to highlight the potential integration of these ML techniques to enhance interpretability, accuracy, and robustness in film deposition processes. Additionally, we examine state-of-the-art PINN methods, discussing strategies for embedding physical knowledge, governing laws, and partial differential equations into advanced neural network architectures tailored for semiconductor manufacturing. Based on this detailed review, we propose novel research directions that integrate the strengths of PINNs to significantly advance film deposition processes. The contributions of this study include establishing a clear pathway for future research in integrating physics-informed ML frameworks, addressing existing methodological gaps, and ultimately improving precision, scalability, and operational efficiency within semiconductor manufacturing.
<div id='section'>Paperid: <span id='pid'>1726, <a href='https://arxiv.org/pdf/2507.09766.pdf' target='_blank'>https://arxiv.org/pdf/2507.09766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamadreza Akbari Pour, Ali Ghasemzadeh, MohamadAli Bijarchi, Mohammad Behshad Shafii
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09766">Toward accurate RUL and SOH estimation using reinforced graph-based PINNs enhanced with dynamic weights</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate estimation of Remaining Useful Life (RUL) and State of Health (SOH) is essential for Prognostics and Health Management (PHM) across a wide range of industrial applications. We propose a novel framework -- Reinforced Graph-Based Physics-Informed Neural Networks Enhanced with Dynamic Weights (RGPD) -- that combines physics-based supervision with advanced spatio-temporal learning. Graph Convolutional Recurrent Networks (GCRNs) embed graph-convolutional filters within recurrent units to capture how node representations evolve over time. Graph Attention Convolution (GATConv) leverages a self-attention mechanism to compute learnable, edge-wise attention coefficients, dynamically weighting neighbor contributions for adaptive spatial aggregation. A Soft Actor-Critic (SAC) module is positioned between the Temporal Attention Unit (TAU) and GCRN to further improve the spatio-temporal learning. This module improves attention and prediction accuracy by dynamically scaling hidden representations to minimize noise and highlight informative features. To identify the most relevant physical constraints in each area, Q-learning agents dynamically assign weights to physics-informed loss terms, improving generalization across real-time industrial systems and reducing the need for manual tuning. In both RUL and SOH estimation tasks, the proposed method consistently outperforms state-of-the-art models, demonstrating strong robustness and predictive accuracy across varied degradation patterns across three diverse industrial benchmark datasets.
<div id='section'>Paperid: <span id='pid'>1727, <a href='https://arxiv.org/pdf/2507.09591.pdf' target='_blank'>https://arxiv.org/pdf/2507.09591.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michael Ryan, Mohammad Hassan Baqershahi, Hessamoddin Moshayedi, Elyas Ghafoori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09591">Physics-informed machine learning surrogate for scalable simulation of thermal histories during wire-arc directed energy deposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wire-arc directed energy deposition (DED) has emerged as a promising additive manufacturing (AM) technology for large-scale structural engineering applications. However, the complex thermal dynamics inherent to the process present challenges in ensuring structural integrity and mechanical properties of fabricated thick walls and plates. While finite element method (FEM) simulations have been conventionally employed to predict thermal history during deposition, their computational demand remains prohibitively high for actual large-scale applications. Given the necessity of multiple repetitive simulations for heat management and the determination of an optimal printing strategy, FEM simulation quickly becomes entirely infeasible. Instead, advancements have been made in using trained neural networks as surrogate models for rapid prediction. However, traditional data-driven approaches necessitate large amounts of relevant and verifiable external data, during the training and validation of the neural network. Regarding large-scale wire-arc DED, none of these data sources are readily available in quantities sufficient for an accurate surrogate. The introduction of physics-informed neural networks (PINNs) has opened up an alternative simulation strategy by leveraging the existing physical knowledge of the phenomena with advanced machine learning methods. Despite their theoretical advantages, PINNs have seen limited application in the context of large-scale wire-arc DED for structural engineering. This study investigates the scalability of PINNs, focusing on efficient collocation points sampling, a critical factor controlling both the training time and model performance. Results show PINNs can reduce computational time and effort by up to 98.6%, while maintaining the desired accuracy and offering "super-resolution". Future directions for enhancing PINN performance in metal AM are discussed.
<div id='section'>Paperid: <span id='pid'>1728, <a href='https://arxiv.org/pdf/2507.08118.pdf' target='_blank'>https://arxiv.org/pdf/2507.08118.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hardik Shukla, Manurag Khullar, Vismay Churiwala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08118">PDE-aware Optimizer for Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical constraints into the loss function. However, standard optimizers such as Adam often struggle to balance competing loss terms, particularly in stiff or ill-conditioned systems. In this work, we propose a PDE-aware optimizer that adapts parameter updates based on the variance of per-sample PDE residual gradients. This method addresses gradient misalignment without incurring the heavy computational costs of second-order optimizers such as SOAP. We benchmark the PDE-aware optimizer against Adam and SOAP on 1D Burgers', Allen-Cahn and Korteweg-de Vries(KdV) equations. Across both PDEs, the PDE-aware optimizer achieves smoother convergence and lower absolute errors, particularly in regions with sharp gradients. Our results demonstrate the effectiveness of PDE residual-aware adaptivity in enhancing stability in PINNs training. While promising, further scaling on larger architectures and hardware accelerators remains an important direction for future research.
<div id='section'>Paperid: <span id='pid'>1729, <a href='https://arxiv.org/pdf/2507.06967.pdf' target='_blank'>https://arxiv.org/pdf/2507.06967.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastien Andre-Sloan, Anirbit Mukherjee, Matthew Colbrook
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06967">Noisy PDE Training Requires Bigger PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are increasingly used to approximate solutions of partial differential equations (PDEs), especially in high dimensions. In real-world applications, data samples are noisy, so it is important to know when a predictor can still achieve low empirical risk. However, little is known about the conditions under which a PINN can do so effectively. We prove a lower bound on the size of neural networks required for the supervised PINN empirical risk to fall below the variance of noisy supervision labels. Specifically, if a predictor achieves an empirical risk $O(Î·)$ below $Ï^2$ (variance of supervision data), then necessarily $d_N\log d_N\gtrsim N_s Î·^2$, where $N_s$ is the number of samples and $d_N$ is the number of trainable parameters of the PINN. A similar constraint applies to the fully unsupervised PINN setting when boundary labels are sampled noisily. Consequently, increasing the number of noisy supervision labels alone does not provide a ``free lunch'' in reducing empirical risk. We also show empirically that PINNs can indeed achieve empirical risks below $Ï^2$ under such conditions. As a case study, we investigate PINNs applied to the Hamilton--Jacobi--Bellman (HJB) PDE. Our findings lay the groundwork for quantitatively understanding the parameter requirements for training PINNs in the presence of noise.
<div id='section'>Paperid: <span id='pid'>1730, <a href='https://arxiv.org/pdf/2507.06752.pdf' target='_blank'>https://arxiv.org/pdf/2507.06752.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Heng Wu, Benzhuo Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06752">Mathematical artificial data for operator learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning has emerged as a transformative tool for solving differential equations (DEs), yet prevailing methodologies remain constrained by dual limitations: data-driven methods demand costly labeled datasets while model-driven techniques face efficiency-accuracy trade-offs. We present the Mathematical Artificial Data (MAD) framework, a new paradigm that integrates physical laws with data-driven learning to facilitate large-scale operator discovery. By exploiting DEs' intrinsic mathematical structure to generate physics-embedded analytical solutions and associated synthetic data, MAD fundamentally eliminates dependence on experimental or simulated training data. This enables computationally efficient operator learning across multi-parameter systems while maintaining mathematical rigor. Through numerical demonstrations spanning 2D parametric problems where both the boundary values and source term are functions, we showcase MAD's generalizability and superior efficiency/accuracy across various DE scenarios. This physics-embedded-data-driven framework and its capacity to handle complex parameter spaces gives it the potential to become a universal paradigm for physics-informed machine intelligence in scientific computing.
<div id='section'>Paperid: <span id='pid'>1731, <a href='https://arxiv.org/pdf/2507.05291.pdf' target='_blank'>https://arxiv.org/pdf/2507.05291.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manuel Ricardo Guevara Garban, Yves Chemisky, Ãtienne PruliÃ¨re, MichaÃ«l ClÃ©ment
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05291">Physics-Informed Graph Neural Networks to Reconstruct Local Fields Considering Finite Strain Hyperelasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a physics-informed machine learning framework called P-DivGNN to reconstruct local stress fields at the micro-scale, in the context of multi-scale simulation given a periodic micro-structure mesh and mean, macro-scale, stress values. This method is based in representing a periodic micro-structure as a graph, combined with a message passing graph neural network. We are able to retrieve local stress field distributions, providing average stress values produced by a mean field reduced order model (ROM) or Finite Element (FE) simulation at the macro-scale. The prediction of local stress fields are of utmost importance considering fracture analysis or the definition of local fatigue criteria. Our model incorporates physical constraints during training to constraint local stress field equilibrium state and employs a periodic graph representation to enforce periodic boundary conditions. The benefits of the proposed physics-informed GNN are evaluated considering linear and non linear hyperelastic responses applied to varying geometries. In the non-linear hyperelastic case, the proposed method achieves significant computational speed-ups compared to FE simulation, making it particularly attractive for large-scale applications.
<div id='section'>Paperid: <span id='pid'>1732, <a href='https://arxiv.org/pdf/2507.04153.pdf' target='_blank'>https://arxiv.org/pdf/2507.04153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vasiliy A. Es'kin, Egor V. Ivanov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04153">Physics-informed neural networks and neural operators for a study of EUV electromagnetic wave diffraction from a lithography mask</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) and neural operators (NOs) for solving the problem of diffraction of Extreme Ultraviolet (EUV) electromagnetic waves from a mask are presented. A novel hybrid Waveguide Neural Operator (WGNO) is introduced, which is based on a waveguide method with its most computationally expensive part replaced by a neural network. Numerical experiments on realistic 2D and 3D masks show that the WGNO achieves state-of-the-art accuracy and inference time, providing a highly efficient solution for accelerating the design workflows of lithography masks.
<div id='section'>Paperid: <span id='pid'>1733, <a href='https://arxiv.org/pdf/2507.03853.pdf' target='_blank'>https://arxiv.org/pdf/2507.03853.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Beom Seok Kang, Vignesh C. Bhethanabotla, Amin Tavakoli, Maurice D. Hanisch, William A. Goddard, Anima Anandkumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.03853">OrbitAll: A Unified Quantum Mechanical Representation Deep Learning Framework for All Molecular Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the success of deep learning methods in quantum chemistry, their representational capacity is most often confined to neutral, closed-shell molecules. However, real-world chemical systems often exhibit complex characteristics, including varying charges, spins, and environments. We introduce OrbitAll, a geometry- and physics-informed deep learning framework that can represent all molecular systems with electronic structure information. OrbitAll utilizes spin-polarized orbital features from the underlying quantum mechanical method, and combines it with graph neural networks satisfying SE(3)-equivariance. The resulting framework can represent and process any molecular system with arbitrary charges, spins, and environmental effects. OrbitAll demonstrates superior performance and generalization on predicting charged, open-shell, and solvated molecules, while also robustly extrapolating to molecules significantly larger than the training data by leveraging a physics-informed architecture. OrbitAll achieves chemical accuracy using 10 times fewer training data than competing AI models, with a speedup of approximately $10^3$ - $10^4$ compared to density functional theory.
<div id='section'>Paperid: <span id='pid'>1734, <a href='https://arxiv.org/pdf/2507.01687.pdf' target='_blank'>https://arxiv.org/pdf/2507.01687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georgios Arampatzis, Stylianos Katsarakis, Charalambos Makridakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01687">A generative modeling / Physics-Informed Neural Network approach to random differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The integration of Scientific Machine Learning (SciML) techniques with uncertainty quantification (UQ) represents a rapidly evolving frontier in computational science. This work advances Physics-Informed Neural Networks (PINNs) by incorporating probabilistic frameworks to effectively model uncertainty in complex systems. Our approach enhances the representation of uncertainty in forward problems by combining generative modeling techniques with PINNs. This integration enables in a systematic fashion uncertainty control while maintaining the predictive accuracy of the model. We demonstrate the utility of this method through applications to random differential equations and random partial differential equations (PDEs).
<div id='section'>Paperid: <span id='pid'>1735, <a href='https://arxiv.org/pdf/2507.01047.pdf' target='_blank'>https://arxiv.org/pdf/2507.01047.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Logan A. Burnett, Umme Mahbuba Nabila, Majdi I. Radaideh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.01047">Variational Digital Twins</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While digital twins (DT) hold promise for providing real-time insights into complex energy assets, much of the current literature either does not offer a clear framework for information exchange between the model and the asset, lacks key features needed for real-time implementation, or gives limited attention to model uncertainty. Here, we aim to solve these gaps by proposing a variational digital twin (VDT) framework that augments standard neural architectures with a single Bayesian output layer. This lightweight addition, along with a novel VDT updating algorithm, lets a twin update in seconds on commodity GPUs while producing calibrated uncertainty bounds that can inform experiment design, control algorithms, and model reliability. The VDT is evaluated on four energy-sector problems. For critical-heat-flux prediction, uncertainty-driven active learning reaches R2 = 0.98 using 47 % fewer experiments and one-third the training time of random sampling. A three-year renewable-generation twin maintains R2 > 0.95 for solar output and curbs error growth for volatile wind forecasts via monthly updates that process only one month of data at a time. A nuclear reactor transient cooldown twin reconstructs thermocouple signals with R2 > 0.99 and preserves accuracy after 50 % sensor loss, demonstrating robustness to degraded instrumentation. Finally, a physics-informed Li-ion battery twin, retrained after every ten discharges, lowers voltage mean-squared error by an order of magnitude relative to the best static model while adapting its credible intervals as the cell approaches end-of-life. These results demonstrate that combining modest Bayesian augmentation with efficient update schemes turns conventional surrogates into uncertainty-aware, data-efficient, and computationally tractable DTs, paving the way for dependable models across industrial and scientific energy systems.
<div id='section'>Paperid: <span id='pid'>1736, <a href='https://arxiv.org/pdf/2507.00816.pdf' target='_blank'>https://arxiv.org/pdf/2507.00816.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengyun Wang, Bo Wang, Yifeng Niu, Chang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00816">PI-WAN: A Physics-Informed Wind-Adaptive Network for Quadrotor Dynamics Prediction in Unknown Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate dynamics modeling is essential for quadrotors to achieve precise trajectory tracking in various applications. Traditional physical knowledge-driven modeling methods face substantial limitations in unknown environments characterized by variable payloads, wind disturbances, and external perturbations. On the other hand, data-driven modeling methods suffer from poor generalization when handling out-of-distribution (OoD) data, restricting their effectiveness in unknown scenarios. To address these challenges, we introduce the Physics-Informed Wind-Adaptive Network (PI-WAN), which combines knowledge-driven and data-driven modeling methods by embedding physical constraints directly into the training process for robust quadrotor dynamics learning. Specifically, PI-WAN employs a Temporal Convolutional Network (TCN) architecture that efficiently captures temporal dependencies from historical flight data, while a physics-informed loss function applies physical principles to improve model generalization and robustness across previously unseen conditions. By incorporating real-time prediction results into a model predictive control (MPC) framework, we achieve improvements in closed-loop tracking performance. Comprehensive simulations and real-world flight experiments demonstrate that our approach outperforms baseline methods in terms of prediction accuracy, tracking precision, and robustness to unknown environments.
<div id='section'>Paperid: <span id='pid'>1737, <a href='https://arxiv.org/pdf/2506.23357.pdf' target='_blank'>https://arxiv.org/pdf/2506.23357.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dimitrios C. Rodopoulos, Panos Pantidis, Nikolaos Karathanasopoulos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23357">Variational PINNs with tree-based integration and boundary element data in the modeling of multi-phase architected materials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The current contribution develops a Variational Physics-Informed Neural Network (VPINN)-based framework for the analysis and design of multiphase architected solids. The elaborated VPINN methodology is based on the Petrov-Galerkin approach, with a deep neural network acting as trial function and local polynomials as test functions. For the analysis, a Galerkin Boundary Element Method (GBEM) scheme is developed to generate the mechanical field data, employing solely domain boundary information. The VPINN methodology is complemented by an adaptive, tree-based integration scheme for the evaluation of the weak-form integrals. Different double-phase material architectures are considered, with the VPINNs demonstrating their ability to capture the deformation fields with considerable accuracy. Moreover, the performance enhancement by the incorporation of additional semi-analytical information at auxiliary internal points is analyzed. Tree-based integration schemes are shown to be capable of robustly capturing inner material discontinuities upon substantial computational cost reductions. The results suggest that the proposed VPINN formulation offers comparative advantages in the modeling of multiphase architected materials compared to classical PINN formulations. The analysis paves the way for the development of variational physics-informed computational models for the mechanical analysis of complex architected multiphase materials and structures.
<div id='section'>Paperid: <span id='pid'>1738, <a href='https://arxiv.org/pdf/2506.22437.pdf' target='_blank'>https://arxiv.org/pdf/2506.22437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinxin Sun, Peter Chang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22437">Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate image alignment is essential for monitoring crack evolution in structural health monitoring (SHM), particularly under real-world conditions involving perspective distortion, occlusion, and low contrast. However, traditional feature detectors such as SIFT and SURF, which rely on Gaussian-based scale spaces, tend to suppress high-frequency edges, making them unsuitable for thin crack localization. Lightweight binary alternatives like ORB and BRISK, while computationally efficient, often suffer from poor keypoint repeatability on textured or shadowed surfaces. This study presents a physics-informed alignment framework that adapts the open KAZE architecture to SHM-specific challenges. By utilizing nonlinear anisotropic diffusion to construct a crack-preserving scale space, and integrating RANSAC-based homography estimation, the framework enables accurate geometric correction without the need for training, parameter tuning, or prior calibration. The method is validated on time-lapse images of masonry and concrete acquired via handheld smartphone under varied field conditions, including shadow interference, cropping, oblique viewing angles, and surface clutter. Compared to classical detectors, the proposed framework reduces crack area and spine length errors by up to 70 percent and 90 percent, respectively, while maintaining sub-5 percent alignment error in key metrics. Unsupervised, interpretable, and computationally lightweight, this approach supports scalable deployment via UAVs and mobile platforms. By tailoring nonlinear scale-space modeling to SHM image alignment, this work offers a robust and physically grounded alternative to conventional techniques for tracking real-world crack evolution.
<div id='section'>Paperid: <span id='pid'>1739, <a href='https://arxiv.org/pdf/2506.22413.pdf' target='_blank'>https://arxiv.org/pdf/2506.22413.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arun Govind Neelan, Ferdin Sagai Don Bosco, Naveen Sagar Jarugumalli, Suresh Balaji Vedarethinam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.22413">Physics-Informed Neural Networks: Bridging the Divide Between Conservative and Non-Conservative Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the realm of computational fluid dynamics, traditional numerical methods, which heavily rely on discretization, typically necessitate the formulation of partial differential equations (PDEs) in conservative form to accurately capture shocks and other discontinuities in compressible flows. Conversely, utilizing non-conservative forms often introduces significant errors near these discontinuities or results in smeared shocks. This dependency poses a considerable limitation, particularly as many PDEs encountered in complex physical phenomena, such as multi-phase flows, are inherently non-conservative. This inherent non-conservativity restricts the direct applicability of standard numerical solvers designed for conservative forms. This work aims to thoroughly investigate the sensitivity of Physics-Informed Neural Networks (PINNs) to the choice of PDE formulation (conservative vs. non-conservative) when solving problems involving shocks and discontinuities. We have conducted this investigation across a range of benchmark problems, specifically the Burgers equation and both steady and unsteady Euler equations, to provide a comprehensive understanding of PINNs capabilities in this critical area.
<div id='section'>Paperid: <span id='pid'>1740, <a href='https://arxiv.org/pdf/2506.21952.pdf' target='_blank'>https://arxiv.org/pdf/2506.21952.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangyang Wan, Haotian Wang, Xuhui Yu, Jiageng Chen, Xinyu Fan, Zuyuan He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.21952">Physics-informed network paradigm with data generation and background noise removal for diverse distributed acoustic sensing applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distributed acoustic sensing (DAS) has attracted considerable attention across various fields and artificial intelligence (AI) technology plays an important role in DAS applications to realize event recognition and denoising. Existing AI models require real-world data (RWD), whether labeled or not, for training, which is contradictory to the fact of limited available event data in real-world scenarios. Here, a physics-informed DAS neural network paradigm is proposed, which does not need real-world events data for training. By physically modeling target events and the constraints of real world and DAS system, physical functions are derived to train a generative network for generation of DAS events data. DAS debackground net is trained by using the generated DAS events data to eliminate background noise in DAS data. The effectiveness of the proposed paradigm is verified in event identification application based on a public dataset of DAS spatiotemporal data and in belt conveyor fault monitoring application based on DAS time-frequency data, and achieved comparable or better performance than data-driven networks trained with RWD. Owing to the introduction of physical information and capability of background noise removal, the paradigm demonstrates generalization in same application on different sites. A fault diagnosis accuracy of 91.8% is achieved in belt conveyor field with networks which transferred from simulation test site without any fault events data of test site and field for training. The proposed paradigm is a prospective solution to address significant obstacles of data acquisition and intense noise in practical DAS applications and explore more potential fields for DAS.
<div id='section'>Paperid: <span id='pid'>1741, <a href='https://arxiv.org/pdf/2506.19178.pdf' target='_blank'>https://arxiv.org/pdf/2506.19178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marc-Antoine Coulombe, Maxime Berger, Antoine Lesage-Landry
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19178">Simulation of a closed-loop dc-dc converter using a physics-informed neural network-based model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing reliance on power electronics introduces new challenges requiring detailed time-domain analyses with fast and accurate circuit simulation tools. Currently, commercial time-domain simulation software are mainly relying on physics-based methods to simulate power electronics. Recent work showed that data-driven and physics-informed learning methods can increase simulation speed with limited compromise on accuracy, but many challenges remain before deployment in commercial tools can be possible. In this paper, we propose a physics-informed bidirectional long-short term memory neural network (BiLSTM-PINN) model to simulate the time-domain response of a closed-loop dc-dc boost converter for various operating points, parameters, and perturbations. A physics-informed fully-connected neural network (FCNN) and a BiLSTM are also trained to establish a comparison. The three methods are then compared using step-response tests to assess their performance and limitations in terms of accuracy. The results show that the BiLSTM-PINN and BiLSTM models outperform the FCNN model by more than 9 and 4.5 times, respectively, in terms of median RMSE. Their standard deviation values are more than 2.6 and 1.7 smaller than the FCNN's, making them also more consistent. Those results illustrate that the proposed BiLSTM-PINN is a potential alternative to other physics-based or data-driven methods for power electronics simulations.
<div id='section'>Paperid: <span id='pid'>1742, <a href='https://arxiv.org/pdf/2506.17726.pdf' target='_blank'>https://arxiv.org/pdf/2506.17726.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anirudh Kalyan, Sundararajan Natarajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17726">Numerical simulation of transient heat conduction with moving heat source using Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, the physics informed neural networks (PINNs) is employed for the numerical simulation of heat transfer involving a moving source. To reduce the computational effort, a new training method is proposed that uses a continuous time-stepping through transfer learning. Within this, the time interval is divided into smaller intervals and a single network is initialized. On this single network each time interval is trained with the initial condition for (n+1)th as the solution obtained at nth time increment. Thus, this framework enables the computation of large temporal intervals without increasing the complexity of the network itself. The proposed framework is used to estimate the temperature distribution in a homogeneous medium with a moving heat source. The results from the proposed framework is compared with traditional finite element method and a good agreement is seen.
<div id='section'>Paperid: <span id='pid'>1743, <a href='https://arxiv.org/pdf/2506.13658.pdf' target='_blank'>https://arxiv.org/pdf/2506.13658.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ioannis Christoforos Koune, Alice Cicirello
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13658">Adversarial Disentanglement by Backpropagation with Physics-Informed Variational Autoencoder</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inference and prediction under partial knowledge of a physical system is challenging, particularly when multiple confounding sources influence the measured response. Explicitly accounting for these influences in physics-based models is often infeasible due to epistemic uncertainty, cost, or time constraints, resulting in models that fail to accurately describe the behavior of the system. On the other hand, data-driven machine learning models such as variational autoencoders are not guaranteed to identify a parsimonious representation. As a result, they can suffer from poor generalization performance and reconstruction accuracy in the regime of limited and noisy data. We propose a physics-informed variational autoencoder architecture that combines the interpretability of physics-based models with the flexibility of data-driven models. To promote disentanglement of the known physics and confounding influences, the latent space is partitioned into physically meaningful variables that parametrize a physics-based model, and data-driven variables that capture variability in the domain and class of the physical system. The encoder is coupled with a decoder that integrates physics-based and data-driven components, and constrained by an adversarial training objective that prevents the data-driven components from overriding the known physics, ensuring that the physics-grounded latent variables remain interpretable. We demonstrate that the model is able to disentangle features of the input signal and separate the known physics from confounding influences using supervision in the form of class and domain observables. The model is evaluated on a series of synthetic case studies relevant to engineering structures, demonstrating the feasibility of the proposed approach.
<div id='section'>Paperid: <span id='pid'>1744, <a href='https://arxiv.org/pdf/2506.13369.pdf' target='_blank'>https://arxiv.org/pdf/2506.13369.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sajad Salavatidezfouli, Henrik Karstoft, Alexandros Iosifidis, Mahdi Abkar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13369">Dual guidance: ROM-informed field reconstruction with generative models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a dual-guided framework for reconstructing unsteady incompressible flow fields using sparse observations. The approach combines optimized sensor placement with a physics-informed guided generative model. Sensor locations are selected using mutual information theory applied to a reduced-order model of the flow, enabling efficient identification of high-information observation points with minimal computational cost. These sensors, once selected, provide targeted observations that guide a denoising diffusion probabilistic model conditioned by physical constraints. Extensive experiments on 2D laminar cylinder wake flows demonstrate that under sparse sensing conditions, the structured sensor layouts fail to capture key flow dynamics, yielding high reconstruction errors. In contrast, our optimized sensor placement strategy achieves accurate reconstructions with L2 errors as low as 0.05, even with a limited number of sensors, confirming the effectiveness of the proposed approach in data-limited regimes. When the number of sensors is higher than a threshold, however, both methods perform comparably. Our dual-guided approach bridges reduced order model-based sensor position optimization with modern generative modeling, providing accurate, physics-consistent reconstruction from sparse data for scientific machine-learning problems.
<div id='section'>Paperid: <span id='pid'>1745, <a href='https://arxiv.org/pdf/2506.13222.pdf' target='_blank'>https://arxiv.org/pdf/2506.13222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenyu Xia, Xinlei Huang, Suvash C. Saha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13222">NeuroPhysNet: A FitzHugh-Nagumo-Based Physics-Informed Neural Network Framework for Electroencephalograph (EEG) Analysis and Motor Imagery Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Electroencephalography (EEG) is extensively employed in medical diagnostics and brain-computer interface (BCI) applications due to its non-invasive nature and high temporal resolution. However, EEG analysis faces significant challenges, including noise, nonstationarity, and inter-subject variability, which hinder its clinical utility. Traditional neural networks often lack integration with biophysical knowledge, limiting their interpretability, robustness, and potential for medical translation. To address these limitations, this study introduces NeuroPhysNet, a novel Physics-Informed Neural Network (PINN) framework tailored for EEG signal analysis and motor imagery classification in medical contexts. NeuroPhysNet incorporates the FitzHugh-Nagumo model, embedding neurodynamical principles to constrain predictions and enhance model robustness. Evaluated on the BCIC-IV-2a dataset, the framework achieved superior accuracy and generalization compared to conventional methods, especially in data-limited and cross-subject scenarios, which are common in clinical settings. By effectively integrating biophysical insights with data-driven techniques, NeuroPhysNet not only advances BCI applications but also holds significant promise for enhancing the precision and reliability of clinical diagnostics, such as motor disorder assessments and neurorehabilitation planning.
<div id='section'>Paperid: <span id='pid'>1746, <a href='https://arxiv.org/pdf/2506.12922.pdf' target='_blank'>https://arxiv.org/pdf/2506.12922.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ajeet Singh, Ram Jiwari, Vikram, Ujjwal Saini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.12922">PINNs Algorithmic Framework for Simulation of Nonlinear Burgers' Type Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, a physics-informed neural networks (PINNs) based algorithm is used for simulation of nonlinear 1D and 2D Burgers' type models. This scheme relies on a neural network built to approximate the problem solution and use a trial function that meets the initial data and boundary criteria. First of all, a brief mathematical formulation of the problem and the structure of PINNs, including the neural network architecture, loss construction, and training methodology is described. Finally, the algorithm is demonstrated with five test problems involving variations of the 1D coupled, 2D single and 2D coupled Burgers' models. We compare the PINN-based solutions with exact results to assess accuracy and convergence of the developed algorithm. The results demonstrate that PINNs may faithfully replicate nonlinear PDE solutions and offer competitive performance in terms of inaccuracy and flexibility. This work demonstrates the potential of PINNs as a reliable approach to solving complex time-dependent PDEs.
<div id='section'>Paperid: <span id='pid'>1747, <a href='https://arxiv.org/pdf/2506.11625.pdf' target='_blank'>https://arxiv.org/pdf/2506.11625.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel James Pitchforth, Matthew Rhys Jones, Samuel John Gibson, Elizabeth Jane Cross
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.11625">Physically-informed change-point kernels for structural dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The relative balance between physics and data within any physics-informed machine learner is an important modelling consideration to ensure that the benefits of both physics and data-based approaches are maximised. An over reliance on physical knowledge can be detrimental, particularly when the physics-based component of a model may not accurately represent the true underlying system. An underutilisation of physical knowledge potentially wastes a valuable resource, along with benefits in model interpretability and reduced demand for expensive data collection. Achieving an optimal physics-data balance is a challenging aspect of model design, particularly if the level varies through time; for example, one might have a physical approximation, only valid within particular regimes, or a physical phenomenon may be known to only occur when given conditions are met (e.g. at high temperatures). This paper develops novel, physically-informed, change-point kernels for Gaussian processes, capable of dynamically varying the reliance upon available physical knowledge. A high level of control is granted to a user, allowing for the definition of conditions in which they believe a phenomena should occur and the rate at which the knowledge should be phased in and out of a model. In circumstances where users may be less certain, the switching reliance upon physical knowledge may be automatically learned and recovered from the model in an interpretable and intuitive manner. Variation of the modelled noise based on the physical phenomena occurring is also implemented to provide a more representative capture of uncertainty alongside predictions. The capabilities of the new kernel structures are explored through the use of two engineering case studies: the directional wind loading of a cable-stayed bridge and the prediction of aircraft wing strain during in-flight manoeuvring.
<div id='section'>Paperid: <span id='pid'>1748, <a href='https://arxiv.org/pdf/2506.11395.pdf' target='_blank'>https://arxiv.org/pdf/2506.11395.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefan Schoder, Aneta FurmanovÃ¡, Viktor HruÅ¡ka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.11395">Convergence of physics-informed neural networks modeling time-harmonic wave fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Studying physics-informed neural networks (PINNs) for modeling partial differential equations to solve the acoustic wave field has produced promising results for simple geometries in two-dimensional domains. One option is to compute the time-harmonic wave field using the Helmholtz equation. Compared to existing numerical models, the physics-informed neural networks forward problem has to overcome several topics related to the convergence of the optimization toward the "true" solution. The topics reach from considering the physical dimensionality (from 2D to 3D), the modeling of realistic sources (from a self-similar source to a realistic confined point source), the modeling of sound-hard (Neumann) boundary conditions, and the modeling of the full wave field by considering the complex solution quantities. Within this contribution, we study 3D room acoustic cases at low frequency, varying the source definition and the number of boundary condition sets and using a complex speed of sound model to account for some degree of absorption. We assess the convergence behavior by looking at the loss landscape of the PINN architecture, the $L^2$ error compared to a finite element reference simulation for each network architecture and configuration. The convergence studies showed that at least six training points per wavelength are necessary for accurate training and subsequent predictions of the PINN. The developments are part of an initiative aiming to model the low-frequency behavior of room acoustics, including absorbers.
<div id='section'>Paperid: <span id='pid'>1749, <a href='https://arxiv.org/pdf/2506.11281.pdf' target='_blank'>https://arxiv.org/pdf/2506.11281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Milad Hoseinpour, Vladimir Dvorkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.11281">Constrained Diffusion Models for Synthesizing Representative Power Flow Datasets</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High-quality power flow datasets are essential for training machine learning models in power systems. However, security and privacy concerns restrict access to real-world data, making statistically accurate and physically consistent synthetic datasets a viable alternative. We develop a diffusion model for generating synthetic power flow datasets from real-world power grids that both replicate the statistical properties of the real-world data and ensure AC power flow feasibility. To enforce the constraints, we incorporate gradient guidance based on the power flow constraints to steer diffusion sampling toward feasible samples. For computational efficiency, we further leverage insights from the fast decoupled power flow method and propose a variable decoupling strategy for the training and sampling of the diffusion model. These solutions lead to a physics-informed diffusion model, generating power flow datasets that outperform those from the standard diffusion in terms of feasibility and statistical similarity, as shown in experiments across IEEE benchmark systems.
<div id='section'>Paperid: <span id='pid'>1750, <a href='https://arxiv.org/pdf/2506.07929.pdf' target='_blank'>https://arxiv.org/pdf/2506.07929.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amirreza Yasami, Mohammadali Tofigh, Mahdi Shahbakhti, Charles Robert Koch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.07929">A Generative Physics-Informed Reinforcement Learning-Based Approach for Construction of Representative Drive Cycle</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate driving cycle construction is crucial for vehicle design, fuel economy analysis, and environmental impact assessments. A generative Physics-Informed Expected SARSA-Monte Carlo (PIESMC) approach that constructs representative driving cycles by capturing transient dynamics, acceleration, deceleration, idling, and road grade transitions while ensuring model fidelity is introduced. Leveraging a physics-informed reinforcement learning framework with Monte Carlo sampling, PIESMC delivers efficient cycle construction with reduced computational cost. Experimental evaluations on two real-world datasets demonstrate that PIESMC replicates key kinematic and energy metrics, achieving up to a 57.3% reduction in cumulative kinematic fragment errors compared to the Micro-trip-based (MTB) method and a 10.5% reduction relative to the Markov-chain-based (MCB) method. Moreover, it is nearly an order of magnitude faster than conventional techniques. Analyses of vehicle-specific power distributions and wavelet-transformed frequency content further confirm its ability to reproduce experimental central tendencies and variability.
<div id='section'>Paperid: <span id='pid'>1751, <a href='https://arxiv.org/pdf/2506.06300.pdf' target='_blank'>https://arxiv.org/pdf/2506.06300.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanye Zhou, Zhaokun Wang, Kai Zhou, Hui Tang, Xiaofan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06300">LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a powerful meshless tool for topology optimization, capable of simultaneously determining optimal topologies and physical solutions. However, conventional PINNs rely on density-based topology descriptions, which necessitate manual interpolation and limit their applicability to complex geometries. To address this, we propose Lagrangian topology-conscious PINNs (LT-PINNs), a novel framework for boundary-focused engineering optimization. By parameterizing the control variables of topology boundary curves as learnable parameters, LT-PINNs eliminate the need for manual interpolation and enable precise boundary determination. We further introduce specialized boundary condition loss function and topology loss function to ensure sharp and accurate boundary representations, even for intricate topologies. The accuracy and robustness of LT-PINNs are validated via two types of partial differential equations (PDEs), including elastic equation with Dirichlet boundary conditions and Laplace's equation with Neumann boundary conditions. Furthermore, we demonstrate effectiveness of LT-PINNs on more complex time-dependent and time-independent flow problems without relying on measurement data, and showcase their engineering application potential in flow velocity rearrangement, transforming a uniform upstream velocity into a sine-shaped downstream profile. The results demonstrate (1) LT-PINNs achieve substantial reductions in relative L2 errors compared with the state-of-art density topology-oriented PINNs (DT-PINNs), (2) LT-PINNs can handle arbitrary boundary conditions, making them suitable for a wide range of PDEs, and (3) LT-PINNs can infer clear topology boundaries without manual interpolation, especially for complex topologies.
<div id='section'>Paperid: <span id='pid'>1752, <a href='https://arxiv.org/pdf/2506.05918.pdf' target='_blank'>https://arxiv.org/pdf/2506.05918.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenxuan Huo, Qiang He, Gang Zhu, Weifeng Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.05918">Over-PINNs: Enhancing Physics-Informed Neural Networks via Higher-Order Partial Derivative Overdetermination of PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial differential equations (PDEs) serve as the cornerstone of mathematical physics. In recent years, Physics-Informed Neural Networks (PINNs) have significantly reduced the dependence on large datasets by embedding physical laws directly into the training of neural networks. However, when dealing with complex problems, the accuracy of PINNs still has room for improvement. To address this issue, we introduce the Over-PINNs framework, which leverages automatic differentiation (AD) to generate higher-order auxiliary equations that impose additional physical constraints. These equations are incorporated as extra loss terms in the training process, effectively enhancing the model's ability to capture physical information through an "overdetermined" approach. Numerical results illustrate that this method exhibits strong versatility in solving various types of PDEs. It achieves a significant improvement in solution accuracy without incurring substantial additional computational costs.
<div id='section'>Paperid: <span id='pid'>1753, <a href='https://arxiv.org/pdf/2506.04742.pdf' target='_blank'>https://arxiv.org/pdf/2506.04742.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Oliver G. S. Lundqvist, Fabricio Oliveira
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.04742">Were Residual Penalty and Neural Operators All We Needed for Solving Optimal Control Problems?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks have been used to solve optimal control problems, typically by training neural networks using a combined loss function that considers data, differential equation residuals, and objective costs. We show that including cost functions in the training process is unnecessary, advocating for a simpler architecture and streamlined approach by decoupling the optimal control problem from the training process. Thus, our work shows that a simple neural operator architecture, such as DeepONet, coupled with an unconstrained optimization routine, can solve multiple optimal control problems with a single physics-informed training phase and a subsequent optimization phase. We achieve this by adding a penalty term based on the differential equation residual to the cost function and computing gradients with respect to the control using automatic differentiation through the trained neural operator within an iterative optimization routine. Our results show acceptable accuracy for practical applications and potential computational savings for more complex and higher-dimensional problems.
<div id='section'>Paperid: <span id='pid'>1754, <a href='https://arxiv.org/pdf/2506.02168.pdf' target='_blank'>https://arxiv.org/pdf/2506.02168.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hrushikesh N. Mhaskar, Efstratios Tsoukanis, Ameya D. Jagtap
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02168">An Approximation Theory Perspective on Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A central problem in machine learning is often formulated as follows: Given a dataset $\{(x_j, y_j)\}_{j=1}^M$, which is a sample drawn from an unknown probability distribution, the goal is to construct a functional model $f$ such that $f(x) \approx y$ for any $(x, y)$ drawn from the same distribution. Neural networks and kernel-based methods are commonly employed for this task due to their capacity for fast and parallel computation. The approximation capabilities, or expressive power, of these methods have been extensively studied over the past 35 years. In this paper, we will present examples of key ideas in this area found in the literature. We will discuss emerging trends in machine learning including the role of shallow/deep networks, approximation on manifolds, physics-informed neural surrogates, neural operators, and transformer architectures. Despite function approximation being a fundamental problem in machine learning, approximation theory does not play a central role in the theoretical foundations of the field. One unfortunate consequence of this disconnect is that it is often unclear how well trained models will generalize to unseen or unlabeled data. In this review, we examine some of the shortcomings of the current machine learning framework and explore the reasons for the gap between approximation theory and machine learning practice. We will then introduce our novel research to achieve function approximation on unknown manifolds without the need to learn specific manifold features, such as the eigen-decomposition of the Laplace-Beltrami operator or atlas construction. In many machine learning problems, particularly classification tasks, the labels $y_j$ are drawn from a finite set of values.
<div id='section'>Paperid: <span id='pid'>1755, <a href='https://arxiv.org/pdf/2506.00056.pdf' target='_blank'>https://arxiv.org/pdf/2506.00056.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hugon Lee, Hyeonbin Moon, Junhyeong Lee, Seunghwa RYu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00056">Toward Knowledge-Guided AI for Inverse Design in Manufacturing: A Perspective on Domain, Physics, and Human-AI Synergy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence (AI) is reshaping inverse design in manufacturing, enabling high-performance discovery in materials, products, and processes. However, purely data-driven approaches often struggle in realistic manufacturing settings characterized by sparse data, high-dimensional design spaces, and complex constraints. This perspective proposes an integrated framework built on three complementary pillars: domain knowledge to establish physically meaningful objectives and constraints while removing variables with limited relevance, physics-informed machine learning to enhance generalization under limited or biased data, and large language model-based interfaces to support intuitive, human-centered interaction. Using injection molding as an illustrative example, we demonstrate how these components can operate in practice and conclude by highlighting key challenges for applying such approaches in realistic manufacturing environments.
<div id='section'>Paperid: <span id='pid'>1756, <a href='https://arxiv.org/pdf/2505.22377.pdf' target='_blank'>https://arxiv.org/pdf/2505.22377.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Na Xue, Minghua Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22377">Multiprecision computing for multistage fractional physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fractional physics-informed neural networks (fPINNs) have been successfully introduced in [Pang, Lu and Karniadakis, SIAM J. Sci. Comput. 41 (2019) A2603-A2626], which observe relative errors of $10^{-3} \, \sim \, 10^{-4}$ for the subdiffusion equations. However their high-precision (multiprecision) numerical solution remains challenging, due to the limited regularity of the subdiffusion model caused by the nonlocal operator. To fill in the gap, we present the multistage fPINNs based on traditional multistage PINNs [Wang and Lai, J. Comput. Phys. 504 (2024) 112865]. Numerical experiments show that the relative errors improve to $10^{-7} \, \sim \, 10^{-8}$ for the subdiffusion equations on uniform or nouniform meshes.
<div id='section'>Paperid: <span id='pid'>1757, <a href='https://arxiv.org/pdf/2505.21723.pdf' target='_blank'>https://arxiv.org/pdf/2505.21723.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Skyler Wu, Shihao Yang, S. C. Kou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21723">Are Statistical Methods Obsolete in the Era of Deep Learning?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the era of AI, neural networks have become increasingly popular for modeling, inference, and prediction, largely due to their potential for universal approximation. With the proliferation of such deep learning models, a question arises: are leaner statistical methods still relevant? To shed insight on this question, we employ the mechanistic nonlinear ordinary differential equation (ODE) inverse problem as a testbed, using physics-informed neural network (PINN) as a representative of the deep learning paradigm and manifold-constrained Gaussian process inference (MAGI) as a representative of statistically principled methods. Through case studies involving the SEIR model from epidemiology and the Lorenz model from chaotic dynamics, we demonstrate that statistical methods are far from obsolete, especially when working with sparse and noisy observations. On tasks such as parameter inference and trajectory reconstruction, statistically principled methods consistently achieve lower bias and variance, while using far fewer parameters and requiring less hyperparameter tuning. Statistical methods can also decisively outperform deep learning models on out-of-sample future prediction, where the absence of relevant data often leads overparameterized models astray. Additionally, we find that statistically principled approaches are more robust to accumulation of numerical imprecision and can represent the underlying system more faithful to the true governing ODEs.
<div id='section'>Paperid: <span id='pid'>1758, <a href='https://arxiv.org/pdf/2505.21421.pdf' target='_blank'>https://arxiv.org/pdf/2505.21421.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rami Cassia, Rich Kerswell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21421">A Physics-Augmented GraphGPS Framework for the Reconstruction of 3D Riemann Problems from Sparse Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In compressible fluid flow, reconstructing shocks, discontinuities, rarefactions, and their interactions from sparse measurements is an important inverse problem with practical applications. Moreover, physics-informed machine learning has recently become an increasingly popular approach for performing reconstructions tasks. In this work we explore a machine learning recipe, known as GraphGPS, for reconstructing canonical compressible flows known as 3D Riemann problems from sparse observations, in a physics-informed manner. The GraphGPS framework combines the benefits of positional encodings, local message-passing of graphs, and global contextual awareness, and we explore the latter two components through an ablation study. Furthermore, we modify the aggregation step of message-passing such that it is aware of shocks and discontinuities, resulting in sharper reconstructions of these features. Additionally, we modify message-passing such that information flows strictly from known nodes only, which results in computational savings, better training convergence, and no degradation of reconstruction accuracy. We also show that the GraphGPS framework outperforms numerous machine learning benchmarks.
<div id='section'>Paperid: <span id='pid'>1759, <a href='https://arxiv.org/pdf/2505.20361.pdf' target='_blank'>https://arxiv.org/pdf/2505.20361.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuanxing Wang, Hui Luo, Kai Wang, Guohuai Zhu, Mingxing Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20361">Solving Euler equations with Multiple Discontinuities via Separation-Transfer Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the remarkable progress of physics-informed neural networks (PINNs) in scientific computing, they continue to face challenges when solving hydrodynamic problems with multiple discontinuities. In this work, we propose Separation-Transfer Physics Informed Neural Networks (ST-PINNs) to address such problems. By sequentially resolving discontinuities from strong to weak and leveraging transfer learning during training, ST-PINNs significantly reduce the problem complexity and enhance solution accuracy. To the best of our knowledge, this is the first study to apply a PINNs-based approach to the two-dimensional unsteady planar shock refraction problem, offering new insights into the application of PINNs to complex shock-interface interactions. Numerical experiments demonstrate that ST-PINNs more accurately capture sharp discontinuities and substantially reduce solution errors in hydrodynamic problems involving multiple discontinuities.
<div id='section'>Paperid: <span id='pid'>1760, <a href='https://arxiv.org/pdf/2505.15329.pdf' target='_blank'>https://arxiv.org/pdf/2505.15329.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anqiao Ouyang, Hongyi Ke, Qi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.15329">Fourier-Invertible Neural Encoder (FINE) for Homogeneous Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Invertible neural architectures have recently attracted attention for their compactness, interpretability, and information-preserving properties. In this work, we propose the Fourier-Invertible Neural Encoder (FINE), which combines invertible monotonic activation functions with reversible filter structures, and could be extended using Invertible ResNets. This architecture is examined in learning low-dimensional representations of one-dimensional nonlinear wave interactions and exact circular translation symmetry. Dimensionality is preserved across layers, except for a Fourier truncation step in the latent space, which enables dimensionality reduction while maintaining shift equivariance and interpretability. Our results demonstrate that FINE significantly outperforms classical linear methods such as Discrete Fourier Transformation (DFT) and Proper Orthogonal Decomposition (POD), and achieves reconstruction accuracy better than conventional deep autoencoders with convolutional layers (CNN) - while using substantially smaller models and offering superior physical interpretability. These findings suggest that invertible single-neuron networks, when combined with spectral truncation, offer a promising framework for learning compact and interpretable representations of physics datasets, and symmetry-aware representation learning in physics-informed machine learning.
<div id='section'>Paperid: <span id='pid'>1761, <a href='https://arxiv.org/pdf/2505.13501.pdf' target='_blank'>https://arxiv.org/pdf/2505.13501.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zequn He, Celia Reina
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13501">SPIEDiff: robust learning of long-time macroscopic dynamics from short-time particle simulations with quantified epistemic uncertainty</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The data-driven discovery of long-time macroscopic dynamics and thermodynamics of dissipative systems with particle fidelity is hampered by significant obstacles. These include the strong time-scale limitations inherent to particle simulations, the non-uniqueness of the thermodynamic potentials and operators from given macroscopic dynamics, and the need for efficient uncertainty quantification. This paper introduces Statistical-Physics Informed Epistemic Diffusion Models (SPIEDiff), a machine learning framework designed to overcome these limitations in the context of purely dissipative systems by leveraging statistical physics, conditional diffusion models, and epinets. We evaluate the proposed framework on stochastic Arrhenius particle processes and demonstrate that SPIEDiff can accurately uncover both thermodynamics and kinetics, while enabling reliable long-time macroscopic predictions using only short-time particle simulation data. SPIEDiff can deliver accurate predictions with quantified uncertainty in minutes, drastically reducing the computational demand compared to direct particle simulations, which would take days or years in the examples considered. Overall, SPIEDiff offers a robust and trustworthy pathway for the data-driven discovery of thermodynamic models.
<div id='section'>Paperid: <span id='pid'>1762, <a href='https://arxiv.org/pdf/2505.12557.pdf' target='_blank'>https://arxiv.org/pdf/2505.12557.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinmeng Luan, Kazuya Yokota, Gary Scavone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12557">Acoustic Field Reconstruction in Tubes via Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the application of Physics-Informed Neural Networks (PINNs) to inverse problems in acoustic tube analysis, focusing on reconstructing acoustic fields from noisy and limited observation data. Specifically, we address scenarios where the radiation model is unknown, and pressure data is only available at the tube's radiation end. A PINNs framework is proposed to reconstruct the acoustic field, along with the PINN Fine-Tuning Method (PINN-FTM) and a traditional optimization method (TOM) for predicting radiation model coefficients. The results demonstrate that PINNs can effectively reconstruct the tube's acoustic field under noisy conditions, even with unknown radiation parameters. PINN-FTM outperforms TOM by delivering balanced and reliable predictions and exhibiting robust noise-tolerance capabilities.
<div id='section'>Paperid: <span id='pid'>1763, <a href='https://arxiv.org/pdf/2505.12360.pdf' target='_blank'>https://arxiv.org/pdf/2505.12360.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siwen Zhang, Xizeng Zhao, Zhengzhi Deng, Zhaoyuan Huang, Gang Tao, Nuo Xu, Zhouteng Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12360">LaPON: A Lagrange's-mean-value-theorem-inspired operator network for solving PDEs and its application on NSE</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accelerating the solution of nonlinear partial differential equations (PDEs) while maintaining accuracy at coarse spatiotemporal resolution remains a key challenge in scientific computing. Physics-informed machine learning (ML) methods such as Physics-Informed Neural Networks (PINNs) introduce prior knowledge through loss functions to ensure physical consistency, but their "soft constraints" are usually not strictly satisfied. Here, we propose LaPON, an operator network inspired by the Lagrange's mean value theorem, which embeds prior knowledge directly into the neural network architecture instead of the loss function, making the neural network naturally satisfy the given constraints. This is a hybrid framework that combines neural operators with traditional numerical methods, where neural operators are used to compensate for the effect of discretization errors on the analytical scale in under-resolution simulations. As evaluated on turbulence problem modeled by the Navier-Stokes equations (NSE), the multiple time step extrapolation accuracy and stability of LaPON exceed the direct numerical simulation baseline at 8x coarser grids and 8x larger time steps, while achieving a vorticity correlation of more than 0.98 with the ground truth. It is worth noting that the model can be well generalized to unseen flow states, such as turbulence with different forcing, without retraining. In addition, with the same training data, LaPON's comprehensive metrics on the out-of-distribution test set are at least approximately twice as good as two popular ML baseline methods. By combining numerical computing with machine learning, LaPON provides a scalable and reliable solution for high-fidelity fluid dynamics simulation, showing the potential for wide application in fields such as weather forecasting and engineering design.
<div id='section'>Paperid: <span id='pid'>1764, <a href='https://arxiv.org/pdf/2505.11682.pdf' target='_blank'>https://arxiv.org/pdf/2505.11682.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ananyae Kumar Bhartari, Vinayak Vinayak, Vivek B Shenoy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11682">Mollifier Layers: Enabling Efficient High-Order Derivatives in Inverse PDE Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Parameter estimation in inverse problems involving partial differential equations (PDEs) underpins modeling across scientific disciplines, especially when parameters vary in space or time. Physics-informed Machine Learning (PhiML) integrates PDE constraints into deep learning, but prevailing approaches depend on recursive automatic differentiation (autodiff), which produces inaccurate high-order derivatives, inflates memory usage, and underperforms in noisy settings. We propose Mollifier Layers, a lightweight, architecture-agnostic module that replaces autodiff with convolutional operations using analytically defined mollifiers. This reframing of derivative computation as smoothing integration enables efficient, noise-robust estimation of high-order derivatives directly from network outputs. Mollifier Layers attach at the output layer and require no architectural modifications. We compare them with three distinct architectures and benchmark performance across first-, second-, and fourth-order PDEs -- including Langevin dynamics, heat diffusion, and reaction-diffusion systems -- observing significant improvements in memory efficiency, training time and accuracy for parameter recovery across tasks. To demonstrate practical relevance, we apply Mollifier Layers to infer spatially varying epigenetic reaction rates from super-resolution chromatin imaging data -- a real-world inverse problem with biomedical significance. Our results establish Mollifier Layers as an efficient and scalable tool for physics-constrained learning.
<div id='section'>Paperid: <span id='pid'>1765, <a href='https://arxiv.org/pdf/2505.11638.pdf' target='_blank'>https://arxiv.org/pdf/2505.11638.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan Bioli, Carlo Marcati, Giancarlo Sangalli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11638">Accelerating Natural Gradient Descent for PINNs with Randomized Numerical Linear Algebra</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Natural Gradient Descent (NGD) has emerged as a promising optimization algorithm for training neural network-based solvers for partial differential equations (PDEs), such as Physics-Informed Neural Networks (PINNs). However, its practical use is often limited by the high computational cost of solving linear systems involving the Gramian matrix. While matrix-free NGD methods based on the conjugate gradient (CG) method avoid explicit matrix inversion, the ill-conditioning of the Gramian significantly slows the convergence of CG. In this work, we extend matrix-free NGD to broader classes of problems than previously considered and propose the use of Randomized NystrÃ¶m preconditioning to accelerate convergence of the inner CG solver. The resulting algorithm demonstrates substantial performance improvements over existing NGD-based methods on a range of PDE problems discretized using neural networks.
<div id='section'>Paperid: <span id='pid'>1766, <a href='https://arxiv.org/pdf/2505.10919.pdf' target='_blank'>https://arxiv.org/pdf/2505.10919.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luca Menicali, Andrew Grace, David H. Richter, Stefano Castruccio
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.10919">A Physics-Informed Convolutional Long Short Term Memory Statistical Model for Fluid Thermodynamics Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fluid thermodynamics underpins atmospheric dynamics, climate science, industrial applications, and energy systems. However, direct numerical simulations (DNS) of such systems are computationally prohibitive. To address this, we present a novel physics-informed spatio-temporal surrogate model for Rayleigh-BÃ©nard convection (RBC), a canonical example of convective fluid flow. Our approach combines convolutional neural networks for spatial feature extraction with an innovative recurrent architecture inspired by large language models, comprising a context builder and a sequence generator to capture temporal dynamics. Inference is penalized with respect to the governing partial differential equations to ensure physical interpretability. Given the sensitivity of turbulent convection to initial conditions, we quantify uncertainty using a conformal prediction framework. This model replicates key features of RBC dynamics while significantly reducing computational cost, offering a scalable alternative to DNS for long-term simulations.
<div id='section'>Paperid: <span id='pid'>1767, <a href='https://arxiv.org/pdf/2505.10393.pdf' target='_blank'>https://arxiv.org/pdf/2505.10393.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Agustin Medina, Marcelo Arlego, Carlos A. Lamas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.10393">Uncovering Magnetic Phases with Synthetic Data and Physics-Informed Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate the efficient learning of magnetic phases using artificial neural networks trained on synthetic data, combining computational simplicity with physics-informed strategies. Focusing on the diluted Ising model, which lacks an exact analytical solution, we explore two complementary approaches: a supervised classification using simple dense neural networks, and an unsupervised detection of phase transitions using convolutional autoencoders trained solely on idealized spin configurations.
  To enhance model performance, we incorporate two key forms of physics-informed guidance. First, we exploit architectural biases which preferentially amplify features related to symmetry breaking. Second, we include training configurations that explicitly break $\mathbb{Z}_2$ symmetry, reinforcing the network's ability to detect ordered phases. These mechanisms, acting in tandem, increase the network's sensitivity to phase structure even in the absence of explicit labels. We validate the machine learning predictions through comparison with direct numerical estimates of critical temperatures and percolation thresholds.
  Our results show that synthetic, structured, and computationally efficient training schemes can reveal physically meaningful phase boundaries, even in complex systems. This framework offers a low-cost and robust alternative to conventional methods, with potential applications in broader condensed matter and statistical physics contexts.
<div id='section'>Paperid: <span id='pid'>1768, <a href='https://arxiv.org/pdf/2505.09977.pdf' target='_blank'>https://arxiv.org/pdf/2505.09977.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiyuan Chen, Ajay Annamareddy, Ying-Fei Li, Dane Morgan, Bu Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.09977">Physical regularized Hierarchical Generative Model for Metallic Glass Structural Generation and Energy Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Disordered materials such as glasses, unlike crystals, lack long range atomic order and have no periodic unit cells, yielding a high dimensional configuration space with widely varying properties. The complexity not only increases computational costs for atomistic simulations but also makes it difficult for generative AI models to deliver accurate property predictions and realistic structure generation. In this work, we introduce GlassVAE, a hierarchical graph variational autoencoder that uses graph representations to learn compact, rotation, translation, and permutation invariant embeddings of atomic configurations. The resulting structured latent space not only enables efficient generation of novel, physically plausible structures but also supports exploration of the glass energy landscape. To enforce structural realism and physical fidelity, we augment GlassVAE with two physics informed regularizers, a radial distribution function (RDF) loss that captures characteristic short and medium range ordering and an energy regression loss that reflects the broad configurational energetics. Both theoretical analysis and experimental results highlight the critical impact of these regularizers. By encoding high dimensional atomistic data into a compact latent vector and decoding it into structures with accurate energy predictions, GlassVAE provides a fast, physics aware path for modeling and designing disordered materials.
<div id='section'>Paperid: <span id='pid'>1769, <a href='https://arxiv.org/pdf/2505.07765.pdf' target='_blank'>https://arxiv.org/pdf/2505.07765.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihan Shao, Konstantin Pieper, Xiaochuan Tian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07765">Solving Nonlinear PDEs with Sparse Radial Basis Function Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel framework for solving nonlinear PDEs using sparse radial basis function (RBF) networks. Sparsity-promoting regularization is employed to prevent over-parameterization and reduce redundant features. This work is motivated by longstanding challenges in traditional RBF collocation methods, along with the limitations of physics-informed neural networks (PINNs) and Gaussian process (GP) approaches, aiming to blend their respective strengths in a unified framework. The theoretical foundation of our approach lies in the function space of Reproducing Kernel Banach Spaces (RKBS) induced by one-hidden-layer neural networks of possibly infinite width. We prove a representer theorem showing that the sparse optimization problem in the RKBS admits a finite solution and establishes error bounds that offer a foundation for generalizing classical numerical analysis. The algorithmic framework is based on a three-phase algorithm to maintain computational efficiency through adaptive feature selection, second-order optimization, and pruning of inactive neurons. Numerical experiments demonstrate the effectiveness of our method and highlight cases where it offers notable advantages over GP approaches. This work opens new directions for adaptive PDE solvers grounded in rigorous analysis with efficient, learning-inspired implementation.
<div id='section'>Paperid: <span id='pid'>1770, <a href='https://arxiv.org/pdf/2505.06459.pdf' target='_blank'>https://arxiv.org/pdf/2505.06459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pablo Flores, Olga Graf, Pavlos Protopapas, Karim Pichara
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06459">Improved Uncertainty Quantification in Physics-Informed Neural Networks Using Error Bounds and Solution Bundles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have been widely used to obtain solutions to various physical phenomena modeled as Differential Equations. As PINNs are not naturally equipped with mechanisms for Uncertainty Quantification, some work has been done to quantify the different uncertainties that arise when dealing with PINNs. In this paper, we use a two-step procedure to train Bayesian Neural Networks that provide uncertainties over the solutions to differential equation systems provided by PINNs. We use available error bounds over PINNs to formulate a heteroscedastic variance that improves the uncertainty estimation. Furthermore, we solve forward problems and utilize the obtained uncertainties when doing parameter estimation in inverse problems in cosmology.
<div id='section'>Paperid: <span id='pid'>1771, <a href='https://arxiv.org/pdf/2505.06275.pdf' target='_blank'>https://arxiv.org/pdf/2505.06275.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuzhou Zhu, Zheng Zhang, Ruyi Zhang, Liang Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06275">SinBasis Networks: Matrix-Equivalent Feature Extraction for Wave-Like Optical Spectrograms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wave-like images-from attosecond streaking spectrograms to optical spectra, audio mel-spectrograms and periodic video frames-encode critical harmonic structures that elude conventional feature extractors. We propose a unified, matrix-equivalent framework that reinterprets convolution and attention as linear transforms on flattened inputs, revealing filter weights as basis vectors spanning latent feature subspaces. To infuse spectral priors we apply elementwise $\sin(\cdot)$ mappings to each weight matrix. Embedding these transforms into CNN, ViT and Capsule architectures yields Sin-Basis Networks with heightened sensitivity to periodic motifs and built-in invariance to spatial shifts. Experiments on a diverse collection of wave-like image datasets-including 80,000 synthetic attosecond streaking spectrograms, thousands of Raman, photoluminescence and FTIR spectra, mel-spectrograms from AudioSet and cycle-pattern frames from Kinetics-demonstrate substantial gains in reconstruction accuracy, translational robustness and zero-shot cross-domain transfer. Theoretical analysis via matrix isomorphism and Mercer-kernel truncation quantifies how sinusoidal reparametrization enriches expressivity while preserving stability in data-scarce regimes. Sin-Basis Networks thus offer a lightweight, physics-informed approach to deep learning across all wave-form imaging modalities.
<div id='section'>Paperid: <span id='pid'>1772, <a href='https://arxiv.org/pdf/2505.03806.pdf' target='_blank'>https://arxiv.org/pdf/2505.03806.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehran Mazandarani, Marzieh Najariyan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03806">Perception-Informed Neural Networks: Beyond Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This article introduces Perception-Informed Neural Networks (PrINNs), a framework designed to incorporate perception-based information into neural networks, addressing both systems with known and unknown physics laws or differential equations. Moreover, PrINNs extend the concept of Physics-Informed Neural Networks (PINNs) and their variants, offering a platform for the integration of diverse forms of perception precisiation, including singular, probability distribution, possibility distribution, interval, and fuzzy graph. In fact, PrINNs allow neural networks to model dynamical systems by integrating expert knowledge and perception-based information through loss functions, enabling the creation of modern data-driven models. Some of the key contributions include Mixture of Experts Informed Neural Networks (MOEINNs), which combine heterogeneous expert knowledge into the network, and Transformed-Knowledge Informed Neural Networks (TKINNs), which facilitate the incorporation of meta-information for enhanced model performance. Additionally, Fuzzy-Informed Neural Networks (FINNs) as a modern class of fuzzy deep neural networks leverage fuzzy logic constraints within a deep learning architecture, allowing online training without pre-training and eliminating the need for defuzzification. PrINNs represent a significant step forward in bridging the gap between traditional physics-based modeling and modern data-driven approaches, enabling neural networks to learn from both structured physics laws and flexible perception-based rules. This approach empowers neural networks to operate in uncertain environments, model complex systems, and discover new forms of differential equations, making PrINNs a powerful tool for advancing computational science and engineering.
<div id='section'>Paperid: <span id='pid'>1773, <a href='https://arxiv.org/pdf/2505.02258.pdf' target='_blank'>https://arxiv.org/pdf/2505.02258.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Emir Esenov, Olof Hjortstam, Yuriy Serdyuk, Thomas HammarstrÃ¶m, Christian HÃ¤ger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02258">Inverse Modeling of Dielectric Response in Time Domain using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dielectric response (DR) of insulating materials is key input information for designing electrical insulation systems and defining safe operating conditions of various HV devices. In dielectric materials, different polarization and conduction processes occur at different time scales, making it challenging to physically interpret raw measured data. To analyze DR measurement results, equivalent circuit models (ECMs) are commonly used, reducing the complexity of the physical system to a number of circuit elements that capture the dominant response. This paper examines the use of physics-informed neural networks (PINNs) for inverse modeling of DR in time domain using parallel RC circuits. To assess their performance, we test PINNs on synthetic data generated from analytical solutions of corresponding ECMs, incorporating Gaussian noise to simulate measurement errors. Our results show that PINNs are highly effective at solving well-conditioned inverse problems, accurately estimating up to five unknown RC parameters with minimal requirements on neural network size, training duration, and hyperparameter tuning. Furthermore, we extend the ECMs to incorporate temperature dependence and demonstrate that PINNs can accurately recover embedded, nonlinear temperature functions from noisy DR data sampled at different temperatures. This case study in modeling DR in time domain presents a solution with wide-ranging potential applications in disciplines relying on ECMs, utilizing the latest technology in machine learning for scientific computation.
<div id='section'>Paperid: <span id='pid'>1774, <a href='https://arxiv.org/pdf/2505.01569.pdf' target='_blank'>https://arxiv.org/pdf/2505.01569.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thomas Beckers, Leonardo Colombo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.01569">Physics-informed Learning for Passivity-based Tracking Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Passivity-based control ensures system stability by leveraging dissipative properties and is widely applied in electrical and mechanical systems. Port-Hamiltonian systems (PHS), in particular, are well-suited for interconnection and damping assignment passivity-based control (IDA-PBC) due to their structured, energy-centric modeling approach. However, current IDA-PBC faces two key challenges: (i) it requires precise system knowledge, which is often unavailable due to model uncertainties, and (ii) it is typically limited to set-point control. To address these limitations, we propose a data-driven tracking control approach based on a physics-informed model, namely Gaussian process Port-Hamiltonian systems, along with the modified matching equation. By leveraging the Bayesian nature of the model, we establish probabilistic stability and passivity guarantees. A simulation demonstrates the effectiveness of our approach.
<div id='section'>Paperid: <span id='pid'>1775, <a href='https://arxiv.org/pdf/2505.01078.pdf' target='_blank'>https://arxiv.org/pdf/2505.01078.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sungje Park, Stephen Tu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.01078">Integration Matters for Learning PDEs with Backwards SDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Backward stochastic differential equation (BSDE)-based deep learning methods provide an alternative to Physics-Informed Neural Networks (PINNs) for solving high-dimensional partial differential equations (PDEs), offering algorithmic advantages in settings such as stochastic optimal control, where the PDEs of interest are tied to an underlying dynamical system. However, existing BSDE-based solvers have empirically been shown to underperform relative to PINNs in the literature. In this paper, we identify the root cause of this performance gap as a discretization bias introduced by the standard Euler-Maruyama (EM) integration scheme applied to short-horizon self-consistency BSDE losses, which shifts the optimization landscape off target. We find that this bias cannot be satisfactorily addressed through finer step sizes or longer self-consistency horizons. To properly handle this issue, we propose a Stratonovich-based BSDE formulation, which we implement with stochastic Heun integration. We show that our proposed approach completely eliminates the bias issues faced by EM integration. Furthermore, our empirical results show that our Heun-based BSDE method consistently outperforms EM-based variants and achieves competitive results with PINNs across multiple high-dimensional benchmarks. Our findings highlight the critical role of integration schemes in BSDE-based PDE solvers, an algorithmic detail that has received little attention thus far in the literature.
<div id='section'>Paperid: <span id='pid'>1776, <a href='https://arxiv.org/pdf/2504.21328.pdf' target='_blank'>https://arxiv.org/pdf/2504.21328.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yao-Hsuan Tsai, Hsiao-Tung Juan, Pao-Hsiung Chiu, Chao-An Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.21328">Multi-level datasets training method in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks have emerged as a promising methodology for solving PDEs, gaining significant attention in computer science and various physics-related fields. Despite being demonstrated the ability to incorporate the physics of laws for versatile applications, PINNs still struggle with the challenging problems which are stiff to be solved and/or have high-frequency components in the solutions, resulting in accuracy and convergence issues. It may not only increase computational costs, but also lead to accuracy loss or solution divergence. In this study, an alternative approach is proposed to mitigate the above-mentioned problems. Inspired by the multi-grid method in CFD community, the underlying idea of the current approach is to efficiently remove different frequency errors via training with different levels of training samples, resulting in a simpler way to improve the training accuracy without spending time in fine-tuning of neural network structures, loss weights as well as hyperparameters. To demonstrate the efficacy of current approach, we first investigate canonical 1D ODE with high-frequency component and 2D convection-diffusion equation with V-cycle training strategy. Finally, the current method is employed for the classical benchmark problem of steady Lid-driven cavity flows at different Reynolds numbers, to investigate the applicability and efficacy for the problem involved multiple modes of high and low frequency. By virtue of various training sequence modes, improvement through predictions lead to 30% to 60% accuracy improvement. We also investigate the synergies between current method and transfer learning techniques for more challenging problems (i.e., higher Re). From the present results, it also revealed that the current framework can produce good predictions even for the case of Re=5000, demonstrating the ability to solve complex high-frequency PDEs.
<div id='section'>Paperid: <span id='pid'>1777, <a href='https://arxiv.org/pdf/2504.21155.pdf' target='_blank'>https://arxiv.org/pdf/2504.21155.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fauzan Nazranda Rizqan, Matthew Hole, Charles Gretton
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.21155">Evaluation and Verification of Physics-Informed Neural Models of the Grad-Shafranov Equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Our contributions are motivated by fusion reactors that rely on maintaining magnetohydrodynamic (MHD) equilibrium, where the balance between plasma pressure and confining magnetic fields is required for stable operation. In axisymmetric tokamak reactors in particular, and under the assumption of toroidal symmetry, this equilibrium can be mathematically modelled using the Grad-Shafranov Equation (GSE). Recent works have demonstrated the potential of using Physics-Informed Neural Networks (PINNs) to model the GSE. Existing studies did not examine realistic scenarios in which a single network generalizes to a variety of boundary conditions. Addressing that limitation, we evaluate a PINN architecture that incorporates boundary points as network inputs. Additionally, we compare PINN model accuracy and inference speeds with a Fourier Neural Operator (FNO) model. Finding the PINN model to be the most performant, and accurate in our setting, we use the network verification tool Marabou to perform a range of verification tasks. Although we find some discrepancies between evaluations of the networks natively in PyTorch, compared to via Marabou, we are able to demonstrate useful and practical verification workflows. Our study is the first investigation of verification of such networks.
<div id='section'>Paperid: <span id='pid'>1778, <a href='https://arxiv.org/pdf/2504.18091.pdf' target='_blank'>https://arxiv.org/pdf/2504.18091.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shota Deguchi, Mitsuteru Asai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.18091">Reliable and Efficient Inverse Analysis using Physics-Informed Neural Networks with Distance Functions and Adaptive Weight Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks have attracted significant attention in scientific machine learning for their capability to solve forward and inverse problems governed by partial differential equations. However, the accuracy of PINN solutions is often limited by the treatment of boundary conditions. Conventional penalty-based methods, which incorporate boundary conditions as penalty terms in the loss function, cannot guarantee exact satisfaction of the given boundary conditions and are highly sensitive to the choice of penalty parameters. This paper demonstrates that distance functions, specifically R-functions, can be leveraged to enforce boundary conditions, overcoming these limitations. R-functions provide normalized distance fields, enabling accurate representation of boundary geometries, including non-convex domains, and facilitating various types of boundary conditions. We extend this distance function-based boundary condition imposition method to inverse problems using PINNs and introduce an adaptive weight tuning technique to ensure reliable and efficient inverse analysis. We demonstrate the efficacy of the method through several numerical experiments. Numerical results show that the proposed method solves inverse problems more accurately and efficiently than penalty-based methods, even in the presence of complex non-convex geometries. This approach offers a reliable and efficient framework for inverse analysis using PINNs, with potential applications across a wide range of engineering problems.
<div id='section'>Paperid: <span id='pid'>1779, <a href='https://arxiv.org/pdf/2504.17945.pdf' target='_blank'>https://arxiv.org/pdf/2504.17945.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bastien C. Baluyot, Marta Varela, Chen Qin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.17945">Spectral Bias Correction in PINNs for Myocardial Image Registration of Pathological Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate myocardial image registration is essential for cardiac strain analysis and disease diagnosis. However, spectral bias in neural networks impedes modeling high-frequency deformations, producing inaccurate, biomechanically implausible results, particularly in pathological data. This paper addresses spectral bias in physics-informed neural networks (PINNs) by integrating Fourier Feature mappings and introducing modulation strategies into a PINN framework. Experiments on two distinct datasets demonstrate that the proposed methods enhance the PINN's ability to capture complex, high-frequency deformations in cardiomyopathies, achieving superior registration accuracy while maintaining biomechanical plausibility - thus providing a foundation for scalable cardiac image registration and generalization across multiple patients and pathologies.
<div id='section'>Paperid: <span id='pid'>1780, <a href='https://arxiv.org/pdf/2504.14156.pdf' target='_blank'>https://arxiv.org/pdf/2504.14156.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdelali Sajia, Bilal Benzimoun, Pawan Khatiwada, Guogan Zhao, Xiao-Feng Qian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.14156">Breaking the Diffraction Barrier for Passive Sources: Parameter-Decoupled Superresolution Assisted by Physics-Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a parameter-decoupled superresolution framework for estimating sub-wavelength separations of passive two-point sources without requiring prior knowledge or control of the source. Our theoretical foundation circumvents the need to estimate multiple challenging parameters such as partial coherence, brightness imbalance, random relative phase, and photon statistics. A physics-informed machine learning (ML) model (trained with a standard desktop workstation), synergistically integrating this theory, further addresses practical imperfections including background noise, photon loss, and centroid/orientation misalignment. The integrated parameter-decoupling superresolution method achieves resolution 14 and more times below the diffraction limit (corresponding to ~ 13.5 nm in optical microscopy) on experimentally generated realistic images with >82% fidelity, performance rivaling state-of-the-art techniques for actively controllable sources. Critically, our method's robustness against source parameter variability and source-independent noises enables potential applications in realistic scenarios where source control is infeasible, such as astrophysical imaging, live-cell microscopy, and quantum metrology. This work bridges a critical gap between theoretical superresolution limits and practical implementations for passive systems.
<div id='section'>Paperid: <span id='pid'>1781, <a href='https://arxiv.org/pdf/2504.13797.pdf' target='_blank'>https://arxiv.org/pdf/2504.13797.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Wang, Shujie Liu, Shuai Lv, Gengshuo Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.13797">Meta-Learning and Knowledge Discovery based Physics-Informed Neural Network for Remaining Useful Life Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the remaining useful life (RUL) of rotating machinery is critical for industrial safety and maintenance, but existing methods struggle with scarce target-domain data and unclear degradation dynamics. We propose a Meta-Learning and Knowledge Discovery-based Physics-Informed Neural Network (MKDPINN) to address these challenges. The method first maps noisy sensor data to a low-dimensional hidden state space via a Hidden State Mapper (HSM). A Physics-Guided Regulator (PGR) then learns unknown nonlinear PDEs governing degradation evolution, embedding these physical constraints into the PINN framework. This integrates data-driven and physics-based approaches. The framework uses meta-learning, optimizing across source-domain meta-tasks to enable few-shot adaptation to new target tasks. Experiments on industrial data and the C-MAPSS benchmark show MKDPINN outperforms baselines in generalization and accuracy, proving its effectiveness for RUL prediction under data scarcity
<div id='section'>Paperid: <span id='pid'>1782, <a href='https://arxiv.org/pdf/2504.11140.pdf' target='_blank'>https://arxiv.org/pdf/2504.11140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qing Li, Jingrun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11140">An Unsupervised Network Architecture Search Method for Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving partial differential equations (PDEs) has been indispensable in scientific and engineering applications. Recently, deep learning methods have been widely used to solve high-dimensional problems, one of which is the physics-informed neural network (PINN). Typically, a deep learning method has three main components: a neural network, a loss function, and an optimizer. While the construction of the loss function is rooted in the definition of solution space, how to choose a optimal neural network is somewhat ad hoc, leaving much room for improvement. In the framework of PINN, we propose an unsupervised network architecture search method for solving PDEs, termed PINN-DARTS, which applies the differentiable architecture search (DARTS) to find the optimal network architecture structure in a given set of neural networks. In this set, the number of layers and the number of neurons in each layer can change. In the searching phase, both network and architecture parameters are updated simultaneously, so the running time is close to that of PINN with a pre-determined network structure. Unlike available works, our approach is unsupervised and purely based on the PDE residual without any prior usage of solutions. PINN-DARTS outputs the optimal network structure as well as the associated numerical solution. The performance of PINN-DARTS is verified on several benchmark PDEs, including elliptic, parabolic, wave, and Burgers' equations. Compared to traditional architecture search methods, PINN-DARTS achieves significantly higher architectural accuracy. Another interesting observation is that both the solution complexity and the PDE type have a prominent impact on the optimal network architecture. Our study suggests that architectures with uneven widths from layer to layer may have superior performance across different solution complexities and different PDE types.
<div id='section'>Paperid: <span id='pid'>1783, <a href='https://arxiv.org/pdf/2504.10395.pdf' target='_blank'>https://arxiv.org/pdf/2504.10395.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ragini Bal Mahesh, Ronny HÃ¤nsch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.10395">Better Coherence, Better Height: Fusing Physical Models and Deep Learning for Forest Height Estimation from Interferometric SAR Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating forest height from Synthetic Aperture Radar (SAR) images often relies on traditional physical models, which, while interpretable and data-efficient, can struggle with generalization. In contrast, Deep Learning (DL) approaches lack physical insight. To address this, we propose CoHNet - an end-to-end framework that combines the best of both worlds: DL optimized with physics-informed constraints. We leverage a pre-trained neural surrogate model to enforce physical plausibility through a unique training loss. Our experiments show that this approach not only improves forest height estimation accuracy but also produces meaningful features that enhance the reliability of predictions.
<div id='section'>Paperid: <span id='pid'>1784, <a href='https://arxiv.org/pdf/2504.07802.pdf' target='_blank'>https://arxiv.org/pdf/2504.07802.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Max Beffert, Andreas Zell
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.07802">Cable Optimization and Drag Estimation for Tether-Powered Multirotor UAVs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The flight time of multirotor unmanned aerial vehicles (UAVs) is typically constrained by their high power consumption. Tethered power systems present a viable solution to extend flight times while maintaining the advantages of multirotor UAVs, such as hover capability and agility. This paper addresses the critical aspect of cable selection for tether-powered multirotor UAVs, considering both hover and forward flight. Existing research often overlooks the trade-offs between cable mass, power losses, and system constraints. We propose a novel methodology to optimize cable selection, accounting for thrust requirements and power efficiency across various flight conditions. The approach combines physics-informed modeling with system identification to combine hover and forward flight dynamics, incorporating factors such as motor efficiency, tether resistance, and aerodynamic drag. This work provides an intuitive and practical framework for optimizing tethered UAV designs, ensuring efficient power transmission and flight performance. Thus allowing for better, safer, and more efficient tethered drones.
<div id='section'>Paperid: <span id='pid'>1785, <a href='https://arxiv.org/pdf/2504.05282.pdf' target='_blank'>https://arxiv.org/pdf/2504.05282.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ramachandran Anantharaman, Carlos Gonzalez Rojas, Luna Artemis van Leeuwen, Leyla Ãzkan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.05282">Estimation of Heat Transfer Coefficient in Heat Exchangers from closed-loop data using Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Heat exchangers (HEXs) play a central role in process industries for thermal energy transfer. Fouling, the gradual accumulation of solids on heat transfer surfaces, causes a time-varying decrease in the overall heat transfer coefficient (U(t)), significantly impacting the efficiency of heat transfer. Good estimation and modeling of fouling (the heat transfer coefficient) will lead to better fouling mitigation strategies. This study investigates the identifiability of the time-varying $U(t)$ in HEXs from closed-loop operational data, without external excitation of reference signals or knowledge of the controller parameters. We establish that while the complete system model cannot be identified under these given constraints, the time-varying heat transfer coefficient $U(t)$ remains identifiable. Further, we propose a neural network based architecture, called (Per-PINN), for estimation and modeling the heat transfer coefficient from the closed-loop system data. This Per-PINN model is shown to perform better than the existing Physics-Informed Neural Networks (PINN) based models for inverse parameter learning as it inherently fixes the underlying physical equations and learns only the time-varying parameter U(t).
<div id='section'>Paperid: <span id='pid'>1786, <a href='https://arxiv.org/pdf/2504.05248.pdf' target='_blank'>https://arxiv.org/pdf/2504.05248.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marius AlmanstÃ¶tter, Roman Vetter, Dagmar Iber
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.05248">PINNverse: Accurate parameter estimation in differential equations from noisy data with constrained physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Parameter estimation for differential equations from measured data is an inverse problem prevalent across quantitative sciences. Physics-Informed Neural Networks (PINNs) have emerged as effective tools for solving such problems, especially with sparse measurements and incomplete system information. However, PINNs face convergence issues, stability problems, overfitting, and complex loss function design. Here we introduce PINNverse, a training paradigm that addresses these limitations by reformulating the learning process as a constrained differential optimization problem. This approach achieves a dynamic balance between data loss and differential equation residual loss during training while preventing overfitting. PINNverse combines the advantages of PINNs with the Modified Differential Method of Multipliers to enable convergence on any point on the Pareto front. We demonstrate robust and accurate parameter estimation from noisy data in four classical ODE and PDE models from physics and biology. Our method enables accurate parameter inference also when the forward problem is expensive to solve.
<div id='section'>Paperid: <span id='pid'>1787, <a href='https://arxiv.org/pdf/2504.03914.pdf' target='_blank'>https://arxiv.org/pdf/2504.03914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Luo, Florian SchÃ¤fer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03914">Optimal Krylov On Average</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose an adaptive randomized truncation estimator for Krylov subspace methods that optimizes the trade-off between the solution variance and the computational cost, while remaining unbiased. The estimator solves a constrained optimization problem to compute the truncation probabilities on the fly, with minimal computational overhead. The problem has a closed-form solution when the improvement of the deterministic algorithm satisfies a diminishing returns property. We prove that obtaining the optimal adaptive truncation distribution is impossible in the general case. Without the diminishing return condition, our estimator provides a suboptimal but still unbiased solution. We present experimental results in GP hyperparameter training and competitive physics-informed neural networks problem to demonstrate the effectiveness of our approach.
<div id='section'>Paperid: <span id='pid'>1788, <a href='https://arxiv.org/pdf/2504.03469.pdf' target='_blank'>https://arxiv.org/pdf/2504.03469.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zisheng Yao, Yuhe Zhang, Zhe Hu, Robert KlÃ¶fkorn, Tobias Ritschel, Pablo Villanueva-Perez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.03469">Physics-informed 4D X-ray image reconstruction from ultra-sparse spatiotemporal data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The unprecedented X-ray flux density provided by modern X-ray sources offers new spatiotemporal possibilities for X-ray imaging of fast dynamic processes. Approaches to exploit such possibilities often result in either i) a limited number of projections or spatial information due to limited scanning speed, as in time-resolved tomography, or ii) a limited number of time points, as in stroboscopic imaging, making the reconstruction problem ill-posed and unlikely to be solved by classical reconstruction approaches. 4D reconstruction from such data requires sample priors, which can be included via deep learning (DL). State-of-the-art 4D reconstruction methods for X-ray imaging combine the power of AI and the physics of X-ray propagation to tackle the challenge of sparse views. However, most approaches do not constrain the physics of the studied process, i.e., a full physical model. Here we present 4D physics-informed optimized neural implicit X-ray imaging (4D-PIONIX), a novel physics-informed 4D X-ray image reconstruction method combining the full physical model and a state-of-the-art DL-based reconstruction method for 4D X-ray imaging from sparse views. We demonstrate and evaluate the potential of our approach by retrieving 4D information from ultra-sparse spatiotemporal acquisitions of simulated binary droplet collisions, a relevant fluid dynamic process. We envision that this work will open new spatiotemporal possibilities for various 4D X-ray imaging modalities, such as time-resolved X-ray tomography and more novel sparse acquisition approaches like X-ray multi-projection imaging, which will pave the way for investigations of various rapid 4D dynamics, such as fluid dynamics and composite testing.
<div id='section'>Paperid: <span id='pid'>1789, <a href='https://arxiv.org/pdf/2504.02283.pdf' target='_blank'>https://arxiv.org/pdf/2504.02283.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Le Minh Long Nguyen, Edric Ong, Matthew Eng, Yuhao Zhang, Hiu Yung Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02283">Ga$_2$O$_3$ TCAD Mobility Parameter Calibration using Simulation Augmented Machine Learning with Physics Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we demonstrate the possibility of performing automatic Technology Computer-Aided-Design (TCAD) parameter calibration using machine learning, verified with experimental data. The machine only needs to be trained by TCAD data. Schottky Barrier Diode (SBD) fabricated with emerging ultra-wide-bandgap material, Gallium Oxide (Ga$_2$O$_3$), is measured and its current-voltage (IV) is used for Ga$_2$O$_3$ Philips Unified Mobility (PhuMob) model parameters, effective anode workfunction, and ambient temperature extraction (7 parameters). A machine comprised of an autoencoder (AE) and a neural network (NN) (AE-NN) is used. Ga$_2$O$_3$ PhuMob parameters are extracted from the noisy experimental curves. TCAD simulation with the extracted parameters shows that the quality of the parameters is as good as an expert's calibration at the pre-turned-on regime but not in the on-state regime. By using a simple physics-informed neural network (PINN) (AE-PINN), the machine performs as well as the human expert in all regimes.
<div id='section'>Paperid: <span id='pid'>1790, <a href='https://arxiv.org/pdf/2504.01532.pdf' target='_blank'>https://arxiv.org/pdf/2504.01532.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kuei-Jan Chu, Nozomi Akashi, Akihiro Yamamoto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01532">Incorporating Coupling Knowledge into Echo State Networks for Learning Spatiotemporally Chaotic Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning methods have shown promise in learning chaotic dynamical systems, enabling model-free short-term prediction and attractor reconstruction. However, when applied to large-scale, spatiotemporally chaotic systems, purely data-driven machine learning methods often suffer from inefficiencies, as they require a large learning model size and a massive amount of training data to achieve acceptable performance. To address this challenge, we incorporate the spatial coupling structure of the target system as an inductive bias in the network design. Specifically, we introduce physics-guided clustered echo state networks, leveraging the efficiency of the echo state networks as a base model. Experimental results on benchmark chaotic systems demonstrate that our physics-informed method outperforms existing echo state network models in learning the target chaotic systems. Additionally, we numerically demonstrate that leveraging coupling knowledge into ESN models can enhance their robustness to variations of training and target system conditions. We further show that our proposed model remains effective even when the coupling knowledge is imperfect or extracted directly from time series data. We believe this approach has the potential to enhance other machine-learning methods.
<div id='section'>Paperid: <span id='pid'>1791, <a href='https://arxiv.org/pdf/2504.01169.pdf' target='_blank'>https://arxiv.org/pdf/2504.01169.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>VÃ­ctor Ramos-Osuna, Alberto DÃ­az-Ãlvarez, RaÃºl Lara-Cabrera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01169">Efficient n-body simulations using physics informed graph neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel approach for accelerating n-body simulations by integrating a physics-informed graph neural networks (GNN) with traditional numerical methods. Our method implements a leapfrog-based simulation engine to generate datasets from diverse astrophysical scenarios which are then transformed into graph representations. A custom-designed GNN is trained to predict particle accelerations with high precision. Experiments, conducted on 60 training and 6 testing simulations spanning from 3 to 500 bodies over 1000 time steps, demonstrate that the proposed model achieves extremely low prediction errors-loss values while maintaining robust long-term stability, with accumulated errors in position, velocity, and acceleration remaining insignificant. Furthermore, our method yields a modest speedup of approximately 17% over conventional simulation techniques. These results indicate that the integration of deep learning with traditional physical simulation methods offers a promising pathway to significantly enhance computational efficiency without compromising accuracy.
<div id='section'>Paperid: <span id='pid'>1792, <a href='https://arxiv.org/pdf/2504.00746.pdf' target='_blank'>https://arxiv.org/pdf/2504.00746.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Zieglmeier, Mathias Hudoba de Badyn, Narada D. Warakagoda, Thomas R. Krogstad, Paal Engelstad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.00746">Semi-Data-Driven Model Predictive Control: A Physics-Informed Data-Driven Control Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-enabled predictive control (DeePC) has emerged as a powerful technique to control complex systems without the need for extensive modeling efforts. However, relying solely on offline collected data trajectories to represent the system dynamics introduces certain drawbacks. Therefore, we present a novel semi-data-driven model predictive control (SD-MPC) framework that combines (limited) model information with DeePC to address a range of these drawbacks, including sensitivity to noisy data and a lack of robustness. In this work, we focus on the performance of DeePC in operating regimes not captured by the offline collected data trajectories and demonstrate how incorporating an underlying parametric model can counteract this issue. SD-MPC exhibits equivalent closed-loop performance as DeePC for deterministic linear time-invariant systems. Simulations demonstrate the general control performance of the proposed SD-MPC for both a linear time-invariant system and a nonlinear system modeled as a linear parameter-varying system. These results provide numerical evidence of the enhanced robustness of SD-MPC over classical DeePC.
<div id='section'>Paperid: <span id='pid'>1793, <a href='https://arxiv.org/pdf/2504.00249.pdf' target='_blank'>https://arxiv.org/pdf/2504.00249.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rory Clements, James Ellis, Geoff Hassall, Simon Horsley, Gavin Tabor
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.00249">Plane-Wave Decomposition and Randomised Training; a Novel Path to Generalised PINNs for SHM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce a formulation of Physics-Informed Neural Networks (PINNs), based on learning the form of the Fourier decomposition, and a training methodology based on a spread of randomly chosen boundary conditions. By training in this way we produce a PINN that generalises; after training it can be used to correctly predict the solution for an arbitrary set of boundary conditions and interpolate this solution between the samples that spanned the training domain. We demonstrate for a toy system of two coupled oscillators that this gives the PINN formulation genuine predictive capability owing to an effective reduction of the training to evaluation times ratio due to this decoupling of the solution from specific boundary conditions.
<div id='section'>Paperid: <span id='pid'>1794, <a href='https://arxiv.org/pdf/2503.24074.pdf' target='_blank'>https://arxiv.org/pdf/2503.24074.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongzheng Zhu, Weizheng Chen, Jian Deng, Xin Bian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.24074">Physics-informed neural networks for hidden boundary detection and flow field reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Simultaneously detecting hidden solid boundaries and reconstructing flow fields from sparse observations poses a significant inverse challenge in fluid mechanics. This study presents a physics-informed neural network (PINN) framework designed to infer the presence, shape, and motion of static or moving solid boundaries within a flow field. By integrating a body fraction parameter into the governing equations, the model enforces no-slip/no-penetration boundary conditions in solid regions while preserving conservation laws of fluid dynamics. Using partial flow field data, the method simultaneously reconstructs the unknown flow field and infers the body fraction distribution, thereby revealing solid boundaries. The framework is validated across diverse scenarios, including incompressible Navier-Stokes and compressible Euler flows, such as steady flow past a fixed cylinder, an inline oscillating cylinder, and subsonic flow over an airfoil. The results demonstrate accurate detection of hidden boundaries, reconstruction of missing flow data, and estimation of trajectories and velocities of a moving body. Further analysis examines the effects of data sparsity, velocity-only measurements, and noise on inference accuracy. The proposed method exhibits robustness and versatility, highlighting its potential for applications when only limited experimental or numerical data are available.
<div id='section'>Paperid: <span id='pid'>1795, <a href='https://arxiv.org/pdf/2503.23396.pdf' target='_blank'>https://arxiv.org/pdf/2503.23396.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianhua Zhang, Yansong He, Hao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.23396">Physics-Informed Adaptive Deep Koopman Operator Modeling for Autonomous Vehicle Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Koopman operator has been recognized as an ongoing data-driven modeling method for vehicle dynamics which lifts the original state space into a high-dimensional linear state space. The deep neural networks (DNNs) are verified to be useful for the approximation of Koopman operator. To further improve the accuracy of Koopman operator approximation, this paper introduces a physical loss function term from the concept of physics-informed neural networks (PINNs), i.e., the acceleration loss between neural network output and sensor measurements, to improve the efficiency of network learning and its interpretability. Moreover, we utilize the sliding window least squares (SWLS) to update the system matrix and input matrix online in the lifted space, therefore enabling the deep Koopman operator to adapt to the rapid dynamics of autonomous vehicles in real events. The data collection and validation are conducted on CarSim/Simlink co-simulation platform. With comparison to other physics-based and data-driven approaches on various scenarios, the results reveal that the acceleration loss-informed network refines the accuracy of Koopman operator approximation and renders it with inherent generalization, and the SWLS enforces the deep Koopman operator's capability to cope with changes in vehicle parameters, road conditions, and rapid maneuvers. This indicates the proposed physics-informed adaptive deep Koopman operator is a performant and efficient data-driven modeling tool.
<div id='section'>Paperid: <span id='pid'>1796, <a href='https://arxiv.org/pdf/2503.23289.pdf' target='_blank'>https://arxiv.org/pdf/2503.23289.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zuyu Xu, Bin Lv
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.23289">Enhancing Physics-Informed Neural Networks with a Hybrid Parallel Kolmogorov-Arnold and MLP Architecture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks have emerged as powerful tools for modeling complex physical systems, yet balancing high accuracy with computational efficiency remains a critical challenge in their convergence behavior. In this work, we propose the Hybrid Parallel Kolmogorov-Arnold Network (KAN) and Multi-Layer Perceptron (MLP) Physics-Informed Neural Network (HPKM-PINN), a novel architecture that synergistically integrates parallelized KAN and MLP branches within a unified PINN framework. The HPKM-PINN introduces a scaling factor Î¾, to optimally balance the complementary strengths of KAN's interpretable function approximation and MLP's nonlinear feature learning, thereby enhancing predictive performance through a weighted fusion of their outputs. Through systematic numerical evaluations, we elucidate the impact of the scaling factor Î¾ on the model's performance in both function approximation and partial differential equation (PDE) solving tasks. Benchmark experiments across canonical PDEs, such as the Poisson and Advection equations, demonstrate that HPKM-PINN achieves a marked decrease in loss values (reducing relative error by two orders of magnitude) compared to standalone KAN or MLP models. Furthermore, the framework exhibits numerical stability and robustness when applied to various physical systems. These findings highlight the HPKM-PINN's ability to leverage KAN's interpretability and MLP's expressivity, positioning it as a versatile and scalable tool for solving complex PDE-driven problems in computational science and engineering.
<div id='section'>Paperid: <span id='pid'>1797, <a href='https://arxiv.org/pdf/2503.22386.pdf' target='_blank'>https://arxiv.org/pdf/2503.22386.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>S M Sivalingam, V Govindaraj, A. S. Hendy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22386">Spectral coefficient learning physics informed neural network for time-dependent fractional parametric differential problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The study of parametric differential equations plays a crucial role in weather forecasting and epidemiological modeling. These phenomena are better represented using fractional derivatives due to their inherent memory or hereditary effects. This paper introduces a novel scientific machine learning approach for solving parametric time-fractional differential equations by combining traditional spectral methods with neural networks. Instead of relying on automatic differentiation techniques, commonly used in traditional Physics-Informed Neural Networks (PINNs), we propose a more efficient global discretization method based on Legendre polynomials. This approach eliminates the need to simulate the parametric fractional differential equations across multiple parameter values. By applying the Legendre-Galerkin weak formulation to the differential equation, we construct a loss function for training the neural network. The trial solutions are represented as linear combinations of Legendre polynomials, with the coefficients learned by the neural network. The convergence of this method is theoretically established, and the theoretical results are validated through numerical experiments on several well-known differential equations.
<div id='section'>Paperid: <span id='pid'>1798, <a href='https://arxiv.org/pdf/2503.21529.pdf' target='_blank'>https://arxiv.org/pdf/2503.21529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhay Kumar, Dushyant Sharma, Mayukha Pal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.21529">Physics-Informed Neural Network-Based Control for Grid-Forming Converter's Stability Under Overload Conditions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Grid-forming converters (GFCs) are crucial for frequency and voltage stability in modern power systems. However, their performance under overload conditions remains a challenge. This paper highlights the limitations of existing approaches in managing DC source saturation and AC current limits, emphasizing the need for improved control strategies to ensure system stability. This paper proposes a control strategy based on a physics-informed neural network (PINN) to improve GFC performance under overloaded conditions, effectively preventing switch failures and mitigating DC source saturation. This approach outperforms conventional methods by maintaining stable voltage and frequency, even under significant load increase where traditional droop control alone proves inadequate. The post-disturbance operating point of GFCs remains unchanged using PINN-based control with an improvement of 0.245 Hz in frequency and 0.03 p.u. in active power when compared to an already existing current limitation strategy. Additionally, it reduces peak voltage deviations during transients by 24.14\%, lowers the rate of change of frequency (ROCOF) from 0.02 Hz/s to 0.005 Hz/s, and improves the rate of change of voltage (ROCOV), keeping both within acceptable limits. These improvements significantly enhance system resilience, especially in inertia-less power networks.
<div id='section'>Paperid: <span id='pid'>1799, <a href='https://arxiv.org/pdf/2503.18849.pdf' target='_blank'>https://arxiv.org/pdf/2503.18849.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan Chuprov, Denis Derkach, Dmitry Efremenko, Aleksei Kychkin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18849">Application of Physics-Informed Neural Networks for Solving the Inverse Advection-Diffusion Problem to Localize Pollution Sources</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates the application of Physics-Informed Neural Networks (PINNs) for solving the inverse advection-diffusion problem to localize pollution sources. The study focuses on optimizing neural network architectures to accurately model pollutant dispersion dynamics under diverse conditions, including scenarios with weak and strong winds and multiple pollution sources. Various PINN configurations are evaluated, showing the strong dependence of solution accuracy on hyperparameter selection. Recommendations for efficient PINN configurations are provided based on these comparisons. The approach is tested across multiple scenarios and validated using real-world data that accounts for atmospheric variability. The results demonstrate that the proposed methodology achieves high accuracy in source localization, showcasing the stability and potential of PINNs for addressing environmental monitoring and pollution management challenges under complex weather conditions.
<div id='section'>Paperid: <span id='pid'>1800, <a href='https://arxiv.org/pdf/2503.18181.pdf' target='_blank'>https://arxiv.org/pdf/2503.18181.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edgar Torres, Jonathan Schiefer, Mathias Niepert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18181">Adaptive Physics-informed Neural Networks: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a promising approach to solving partial differential equations (PDEs) using neural networks, particularly in data-scarce scenarios, due to their unsupervised training capability. However, limitations related to convergence and the need for re-optimization with each change in PDE parameters hinder their widespread adoption across scientific and engineering applications. This survey reviews existing research that addresses these limitations through transfer learning and meta-learning. The covered methods improve the training efficiency, allowing faster adaptation to new PDEs with fewer data and computational resources. While traditional numerical methods solve systems of differential equations directly, neural networks learn solutions implicitly by adjusting their parameters. One notable advantage of neural networks is their ability to abstract away from specific problem domains, allowing them to retain, discard, or adapt learned representations to efficiently address similar problems. By exploring the application of these techniques to PINNs, this survey identifies promising directions for future research to facilitate the broader adoption of PINNs in a wide range of scientific and engineering applications.
<div id='section'>Paperid: <span id='pid'>1801, <a href='https://arxiv.org/pdf/2503.17704.pdf' target='_blank'>https://arxiv.org/pdf/2503.17704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liang Jiang, Yuzhou Cheng, Kun Luo, Jianren Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17704">PT-PINNs: A Parametric Engineering Turbulence Solver based on Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) demonstrate promising potential in parameterized engineering turbulence optimization problems but face challenges, such as high data requirements and low computational accuracy when applied to engineering turbulence problems. This study proposes a framework that enhances the ability of PINNs to solve parametric turbulence problems without training datasets from experiments or CFD-Parametric Turbulence PINNs (PT-PINNs)). Two key methods are introduced to improve the accuracy and robustness of this framework. The first is a soft constraint method for turbulent viscosity calculation. The second is a pre-training method based on the conservation of flow rate in the flow field. The effectiveness of PT-PINNs is validated using a three-dimensional backward-facing step (BFS) turbulence problem with two varying parameters (Re = 3000-200000, ER = 1.1-1.5). PT-PINNs produce predictions that closely match experimental data and computational fluid dynamics (CFD) results across various conditions. Moreover, PT-PINNs offer a computational efficiency advantage over traditional CFD methods. The total time required to construct the parametric BFS turbulence model is 39 hours, one-sixteenth of the time required by traditional numerical methods. The inference time for a single-condition prediction is just 40 seconds-only 0.5% of a single CFD computation. These findings highlight the potential of PT-PINNs for future applications in engineering turbulence optimization problems.
<div id='section'>Paperid: <span id='pid'>1802, <a href='https://arxiv.org/pdf/2503.17430.pdf' target='_blank'>https://arxiv.org/pdf/2503.17430.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shun-Cai Zhao, Yi-Meng Huang, Yi-Fan Yang, Zi-Ran Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17430">Multi-timescale time encoding for CNN prediction of Fenna-Matthews-Olson energy-transfer dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning simulations of open quantum dynamics often rely on recursive predictors that accumulate error. We develop a non-recursive convolutional neural networks (CNNs) that maps system parameters and a redundant time encoding directly to excitation-energy-transfer populations in the Fenna-Matthews-Olson complex. The encoding-modified logistic plus $\tanh$ functions-normalizes time and resolves fast, transitional, and quasi-steady regimes, while physics-informed labels enforce population conservation and inter-site consistency. Trained only on $0\sim 7 ps$ reference trajectories generated with a Lindblad model in QuTiP, the network accurately predicts $0\sim100 ps$ dynamics across a range of reorganization energies, bath rates, and temperatures. Beyond $20 ps$, the absolute relative error remains below 0.05, demonstrating stable long-time extrapolation. By avoiding step-by-step recursion, the method suppresses error accumulation and generalizes across timescales. These results show that redundant time encoding enables data-efficient inference of long-time quantum dissipative dynamics in realistic pigment-protein complexes, and may aid the data-driven design of light-harvesting materials.
<div id='section'>Paperid: <span id='pid'>1803, <a href='https://arxiv.org/pdf/2503.17402.pdf' target='_blank'>https://arxiv.org/pdf/2503.17402.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Oscar L. Cruz-GonzÃ¡lez, ValÃ©rie Deplano, Badih Ghattas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17402">Enhanced Vascular Flow Simulations in Aortic Aneurysm via Physics-Informed Neural Networks and Deep Operator Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the limited accuracy of 4D Magnetic Resonance Imaging (MRI) in identifying hemodynamics in cardiovascular diseases, the challenges in obtaining patient-specific flow boundary conditions, and the computationally demanding and time-consuming nature of Computational Fluid Dynamics (CFD) simulations, it is crucial to explore new data assimilation algorithms that offer possible alternatives to these limitations. In the present work, we study Physics-Informed Neural Networks (PINNs), Deep Operator Networks (DeepONets), and their Physics-Informed extensions (PI-DeepONets) in predicting vascular flow simulations in the context of a 3D Abdominal Aortic Aneurysm (AAA) idealized model. PINN is a technique that combines deep neural networks with the fundamental principles of physics, incorporating the physics laws, which are given as partial differential equations, directly into loss functions used during the training process. On the other hand, DeepONet is designed to learn nonlinear operators from data and is particularly useful in studying parametric partial differential equations (PDEs), e.g., families of PDEs with different source terms, boundary conditions, or initial conditions. Here, we adapt the approaches to address the particular use case of AAA by integrating the 3D Navier-Stokes equations (NSE) as the physical laws governing fluid dynamics. In addition, we follow best practices to enhance the capabilities of the models by effectively capturing the underlying physics of the problem under study. The advantages and limitations of each approach are highlighted through a series of relevant application cases. We validate our results by comparing them with CFD simulations for benchmark datasets, demonstrating good agreements and emphasizing those cases where improvements in computational efficiency are observed.
<div id='section'>Paperid: <span id='pid'>1804, <a href='https://arxiv.org/pdf/2503.16323.pdf' target='_blank'>https://arxiv.org/pdf/2503.16323.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peter Sharpe, R. John Hansman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.16323">NeuralFoil: An Airfoil Aerodynamics Analysis Tool Using Physics-Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>NeuralFoil is an open-source Python-based tool for rapid aerodynamics analysis of airfoils, similar in purpose to XFoil. Speedups ranging from 8x to 1,000x over XFoil are demonstrated, after controlling for equivalent accuracy. NeuralFoil computes both global and local quantities (lift, drag, velocity distribution, etc.) over a broad input space, including: an 18-dimensional space of airfoil shapes, possibly including control deflections; a 360 degree range of angles of attack; Reynolds numbers from $10^2$ to $10^{10}$; subsonic flows up to the transonic drag rise; and with varying turbulence parameters. Results match those of XFoil closely: the mean relative error of drag is 0.37% on simple cases, and remains as low as 2.0% on a test dataset with numerous post-stall and transitional cases. NeuralFoil facilitates gradient-based design optimization, due to its $C^\infty$-continuous solutions, automatic-differentiation-compatibility, and bounded computational cost without non-convergence issues.
  NeuralFoil is a hybrid of physics-informed machine learning techniques and analytical models. Here, physics information includes symmetries that are structurally embedded into the model architecture, feature engineering using domain knowledge, and guaranteed extrapolation to known limit cases. This work also introduces a new approach for surrogate model uncertainty quantification that enables robust design optimization.
  This work discusses the methodology and performance of NeuralFoil with several case studies, including a practical airfoil design optimization study including both aerodynamic and non-aerodynamic constraints. Here, NeuralFoil optimization is able to produce airfoils nearly identical in performance and shape to expert-designed airfoils within seconds; these computationally-optimized airfoils provide a useful starting point for further expert refinement.
<div id='section'>Paperid: <span id='pid'>1805, <a href='https://arxiv.org/pdf/2503.14342.pdf' target='_blank'>https://arxiv.org/pdf/2503.14342.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kinga Anna Wozniak, Stephen Mulligan, Jan Kieseler, Markus Klute, Francois Fleuret, Tobias Golling
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14342">End-to-End Optimal Detector Design with Mutual Information Surrogates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel approach for end-to-end black-box optimization of high energy physics (HEP) detectors using local deep learning (DL) surrogates. These surrogates approximate a scalar objective function that encapsulates the complex interplay of particle-matter interactions and physics analysis goals. In addition to a standard reconstruction-based metric commonly used in the field, we investigate the information-theoretic metric of mutual information. Unlike traditional methods, mutual information is inherently task-agnostic, offering a broader optimization paradigm that is less constrained by predefined targets. We demonstrate the effectiveness of our method in a realistic physics analysis scenario: optimizing the thicknesses of calorimeter detector layers based on simulated particle interactions. The surrogate model learns to approximate objective gradients, enabling efficient optimization with respect to energy resolution. Our findings reveal three key insights: (1) end-to-end black-box optimization using local surrogates is a practical and compelling approach for detector design, providing direct optimization of detector parameters in alignment with physics analysis goals; (2) mutual information-based optimization yields design choices that closely match those from state-of-the-art physics-informed methods, indicating that these approaches operate near optimality and reinforcing their reliability in HEP detector design; and (3) information-theoretic methods provide a powerful, generalizable framework for optimizing scientific instruments. By reframing the optimization process through an information-theoretic lens rather than domain-specific heuristics, mutual information enables the exploration of new avenues for discovery beyond conventional approaches.
<div id='section'>Paperid: <span id='pid'>1806, <a href='https://arxiv.org/pdf/2503.14222.pdf' target='_blank'>https://arxiv.org/pdf/2503.14222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Katayoun Eshkofti, Matthieu Barreau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14222">Vanishing Stacked-Residual PINN for State Reconstruction of Hyperbolic Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In a more connected world, modeling multi-agent systems with hyperbolic partial differential equations (PDEs) offers a compact, physics-consistent description of collective dynamics. However, classical control tools need adaptation for these complex systems. Physics-informed neural networks (PINNs) provide a powerful framework to fix this issue by inferring solutions to PDEs by embedding governing equations into the neural network. A major limitation of original PINNs is their inability to capture steep gradients and discontinuities in hyperbolic PDEs. To tackle this problem, we propose a stacked residual PINN method enhanced with a vanishing viscosity mechanism. Initially, a basic PINN with a small viscosity coefficient provides a stable, low-fidelity solution. Residual correction blocks with learnable scaling parameters then iteratively refine this solution, progressively decreasing the viscosity coefficient to transition from parabolic to hyperbolic PDEs. Applying this method to traffic state reconstruction improved results by an order of magnitude in relative $\mathcal{L}^2$ error, demonstrating its potential to accurately estimate solutions where original PINNs struggle with instability and low fidelity.
<div id='section'>Paperid: <span id='pid'>1807, <a href='https://arxiv.org/pdf/2503.10708.pdf' target='_blank'>https://arxiv.org/pdf/2503.10708.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bikram Das, Rupchand Sutradhar, D C Dalal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.10708">Exploration of Hepatitis B Virus Infection Dynamics through Physics-Informed Deep Learning Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate forecasting of viral disease outbreaks is crucial for guiding public health responses and preventing widespread loss of life. In recent years, Physics-Informed Neural Networks (PINNs) have emerged as a promising framework that can capture the intricate dynamics of viral infection and reliably predict its future progression. However, despite notable advances, the application of PINNs in disease modeling remains limited. Standard PINNs are effective in simulating disease dynamics through forward modeling but often face challenges in estimating key biological parameters from sparse or noisy experimental data when applied in an inverse framework. To overcome these limitations, a recent extension known as Disease Informed Neural Networks (DINNs) has emerged, offering a more robust approach to parameter estimation tasks. In this work, we apply this DINNs technique on a recently proposed hepatitis B virus (HBV) infection dynamics model to predict infection transmission within the liver. This model consists of four compartments: uninfected and infected hepatocytes, rcDNA-containing capsids, and free viruses. Leveraging the power of DINNs, we study the impacts of (i) variations in parameter range, (ii) experimental noise in data, (iii) sample sizes, (iv) network architecture and (v) learning rate. We employ this methodology in experimental data collected from nine HBV-infected chimpanzees and observe that it reliably estimates the model parameters. DINNs can capture infection dynamics and predict their future progression even when data of some compartments of the system are missing. Additionally, it identifies the influential model parameters that determine whether the HBV infection is cleared or persists within the host.
<div id='section'>Paperid: <span id='pid'>1808, <a href='https://arxiv.org/pdf/2503.07619.pdf' target='_blank'>https://arxiv.org/pdf/2503.07619.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jamie Holber, Krishna Garikipati
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.07619">Physics- and data-driven Active Learning of neural network representations for free energy functions of materials from statistical mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate free energy representations are crucial for understanding phase dynamics in materials. We employ a scale-bridging approach to incorporate atomistic information into our free energy model by training a neural network on DFT-informed Monte Carlo data. To optimize sampling in the high-dimensional Monte Carlo space, we present an Active Learning framework that integrates space-filling sampling, uncertainty-based sampling, and physics-informed sampling. Additionally, our approach includes methods such as hyperparameter tuning, dynamic sampling, and novelty enforcement. These strategies can be combined to reduce MSE,either globally or in targeted regions of interest,while minimizing the number of required data points. The framework introduced here is broadly applicable to Monte Carlo sampling of a range of materials systems.
<div id='section'>Paperid: <span id='pid'>1809, <a href='https://arxiv.org/pdf/2503.06995.pdf' target='_blank'>https://arxiv.org/pdf/2503.06995.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haolin Li, Yikang Chai, Bailin Lv, Lecheng Ruan, Hang Zhao, Ye Zhao, Jianwen Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.06995">Physics-informed Neural Network Predictive Control for Quadruped Locomotion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study introduces a unified control framework that addresses the challenge of precise quadruped locomotion with unknown payloads, named as online payload identification-based physics-informed neural network predictive control (OPI-PINNPC). By integrating online payload identification with physics-informed neural networks (PINNs), our approach embeds identified mass parameters directly into the neural network's loss function, ensuring physical consistency while adapting to changing load conditions. The physics-constrained neural representation serves as an efficient surrogate model within our nonlinear model predictive controller, enabling real-time optimization despite the complex dynamics of legged locomotion. Experimental validation on our quadruped robot platform demonstrates 35% improvement in position and orientation tracking accuracy across diverse payload conditions (25-100 kg), with substantially faster convergence compared to previous adaptive control methods. Our framework provides a adaptive solution for maintaining locomotion performance under variable payload conditions without sacrificing computational efficiency.
<div id='section'>Paperid: <span id='pid'>1810, <a href='https://arxiv.org/pdf/2503.00420.pdf' target='_blank'>https://arxiv.org/pdf/2503.00420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedram Asef, Christopher Vagg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00420">A physics-informed Bayesian optimization method for rapid development of electrical machines</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advanced slot and winding designs are imperative to create future high performance electrical machines (EM). As a result, the development of methods to design and improve slot filling factor (SFF) has attracted considerable research. Recent developments in manufacturing processes, such as additive manufacturing and alternative materials, has also highlighted a need for novel high-fidelity design techniques to develop high performance complex geometries and topologies. This study therefore introduces a novel physics-informed machine learning (PIML) design optimization process for improving SFF in traction electrical machines used in electric vehicles. A maximum entropy sampling algorithm (MESA) is used to seed a physics-informed Bayesian optimization (PIBO) algorithm, where the target function and its approximations are produced by Gaussian processes (GP)s. The proposed PIBO-MESA is coupled with a 2D finite element model (FEM) to perform a GP-based surrogate and provide the first demonstration of the optimal combination of complex design variables for an electrical machine. Significant computational gains were achieved using the new PIBO-MESA approach, which is 45% faster than existing stochastic methods, such as the non-dominated sorting genetic algorithm II (NSGA-II). The FEM results confirm that the new design optimization process and keystone shaped wires lead to a higher SFF (i.e. by 20%) and electromagnetic improvements (e.g. maximum torque by 12%) with similar resistivity. The newly developed PIBO-MESA design optimization process therefore presents significant benefits in the design of high-performance electric machines, with reduced development time and costs.
<div id='section'>Paperid: <span id='pid'>1811, <a href='https://arxiv.org/pdf/2503.00317.pdf' target='_blank'>https://arxiv.org/pdf/2503.00317.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhaoxi Jiang, Fei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00317">DeepONet Augmented by Randomized Neural Networks for Efficient Operator Learning in PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep operator networks (DeepONets) represent a powerful class of data-driven methods for operator learning, demonstrating strong approximation capabilities for a wide range of linear and nonlinear operators. They have shown promising performance in learning operators that govern partial differential equations (PDEs), including diffusion-reaction systems and Burgers' equations. However, the accuracy of DeepONets is often constrained by computational limitations and optimization challenges inherent in training deep neural networks. Furthermore, the computational cost associated with training these networks is typically very high. To address these challenges, we leverage randomized neural networks (RaNNs), in which the parameters of the hidden layers remain fixed following random initialization. RaNNs compute the output layer parameters using the least-squares method, significantly reducing training time and mitigating optimization errors. In this work, we integrate DeepONets with RaNNs to propose RaNN-DeepONets, a hybrid architecture designed to balance accuracy and efficiency. Furthermore, to mitigate the need for extensive data preparation, we introduce the concept of physics-informed RaNN-DeepONets. Instead of relying on data generated through other time-consuming numerical methods, we incorporate PDE information directly into the training process. We evaluate the proposed model on three benchmark PDE problems: diffusion-reaction dynamics, Burgers' equation, and the Darcy flow problem. Through these tests, we assess its ability to learn nonlinear operators with varying input types. When compared to the standard DeepONet framework, RaNN-DeepONets achieves comparable accuracy while reducing computational costs by orders of magnitude. These results highlight the potential of RaNN-DeepONets as an efficient alternative for operator learning in PDE-based systems.
<div id='section'>Paperid: <span id='pid'>1812, <a href='https://arxiv.org/pdf/2502.17597.pdf' target='_blank'>https://arxiv.org/pdf/2502.17597.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>M. P. Bento, H. B. CÃ¢mara, J. F. Seabra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.17597">Unraveling particle dark matter with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We parametrically solve the Boltzmann equations governing freeze-in dark matter (DM) in alternative cosmologies with Physics-Informed Neural Networks (PINNs), a mesh-free method. Through inverse PINNs, using a single DM experimental point -- observed relic density -- we determine the physical attributes of the theory, namely power-law cosmologies, inspired by braneworld scenarios, and particle interaction cross sections. The expansion of the Universe in such alternative cosmologies has been parameterized through a switch-like function reproducing the Hubble law at later times. Without loss of generality, we model more realistically this transition with a smooth function. We predict a distinct pair-wise relationship between power-law exponent and particle interactions: for a given cosmology with negative (positive) exponent, smaller (larger) cross sections are required to reproduce the data. Lastly, via Bayesian methods, we quantify the epistemic uncertainty of theoretical parameters found in inverse problems.
<div id='section'>Paperid: <span id='pid'>1813, <a href='https://arxiv.org/pdf/2502.17452.pdf' target='_blank'>https://arxiv.org/pdf/2502.17452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saikat Dey, Ayan Mallik
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.17452">Physics Informed Neural Network Estimated Circuit Parameter Adaptive Modulation of DAB</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This article presents the development, implementation, and validation of a loss-optimized and circuit parameter-sensitive TPS modulation scheme for a dual-active-bridge DC-DC converter. The proposed approach dynamically adjusts control parameters based on circuit parameters estimated using a physics-informed neural network.
<div id='section'>Paperid: <span id='pid'>1814, <a href='https://arxiv.org/pdf/2502.15755.pdf' target='_blank'>https://arxiv.org/pdf/2502.15755.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Matilde Valente, Tiago C. Dias, Vasco Guerra, Rodrigo Ventura
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.15755">Physics-consistent machine learning: output projection onto physical manifolds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven machine learning models often require extensive datasets, which can be costly or inaccessible, and their predictions may fail to comply with established physical laws. Current approaches for incorporating physical priors mitigate these issues by penalizing deviations from known physical laws, as in physics-informed neural networks, or by designing architectures that automatically satisfy specific invariants. However, penalization approaches do not guarantee compliance with physical constraints for unseen inputs, and invariant-based methods lack flexibility and generality. We propose a novel physics-consistent machine learning method that directly enforces compliance with physical principles by projecting model outputs onto the manifold defined by these laws. This procedure ensures that predictions inherently adhere to the chosen physical constraints, improving reliability and interpretability. Our method is demonstrated on two systems: a spring-mass system and a low-temperature reactive plasma. Compared to purely data-driven models, our approach significantly reduces errors in physical law compliance, enhances predictive accuracy of physical quantities, and outperforms alternatives when working with simpler models or limited datasets. The proposed projection-based technique is versatile and can function independently or in conjunction with existing physics-informed neural networks, offering a powerful, general, and scalable solution for developing fast and reliable surrogate models of complex physical systems, particularly in resource-constrained scenarios.
<div id='section'>Paperid: <span id='pid'>1815, <a href='https://arxiv.org/pdf/2502.12161.pdf' target='_blank'>https://arxiv.org/pdf/2502.12161.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhang Ying, Wen Congcong, Sornette Didier, Zhan Chengxiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.12161">Integrating Artificial Intelligence and Geophysical Insights for Earthquake Forecasting: A Cross-Disciplinary Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Earthquake forecasting remains a significant scientific challenge, with current methods falling short of achieving the performance necessary for meaningful societal benefits. Traditional models, primarily based on past seismicity and geomechanical data, struggle to capture the complexity of seismic patterns and often overlook valuable non-seismic precursors such as geophysical, geochemical, and atmospheric anomalies. The integration of such diverse data sources into forecasting models, combined with advancements in AI technologies, offers a promising path forward. AI methods, particularly deep learning, excel at processing complex, large-scale datasets, identifying subtle patterns, and handling multidimensional relationships, making them well-suited for overcoming the limitations of conventional approaches.
  This review highlights the importance of combining AI with geophysical knowledge to create robust, physics-informed forecasting models. It explores current AI methods, input data types, loss functions, and practical considerations for model development, offering guidance to both geophysicists and AI researchers. While many AI-based studies oversimplify earthquake prediction, neglecting critical features such as data imbalance and spatio-temporal clustering, the integration of specialized geophysical insights into AI models can address these shortcomings.
  We emphasize the importance of interdisciplinary collaboration, urging geophysicists to experiment with AI architectures thoughtfully and encouraging AI experts to deepen their understanding of seismology. By bridging these disciplines, we can develop more accurate, reliable, and societally impactful earthquake forecasting tools.
<div id='section'>Paperid: <span id='pid'>1816, <a href='https://arxiv.org/pdf/2502.11942.pdf' target='_blank'>https://arxiv.org/pdf/2502.11942.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nanxi Chen, Chuanjie Cui, Rujin Ma, Airong Chen, Sifan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.11942">Sharp-PINNs: staggered hard-constrained physics-informed neural networks for phase field modelling of corrosion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks have shown significant potential in solving partial differential equations (PDEs) across diverse scientific fields. However, their performance often deteriorates when addressing PDEs with intricate and strongly coupled solutions. In this work, we present a novel Sharp-PINN framework to tackle complex phase field corrosion problems. Instead of minimizing all governing PDE residuals simultaneously, the Sharp-PINNs introduce a staggered training scheme that alternately minimizes the residuals of Allen-Cahn and Cahn-Hilliard equations, which govern the corrosion system. To further enhance its efficiency and accuracy, we design an advanced neural network architecture that integrates random Fourier features as coordinate embeddings, employs a modified multi-layer perceptron as the primary backbone, and enforces hard constraints in the output layer. This framework is benchmarked through simulations of corrosion problems with multiple pits, where the staggered training scheme and network architecture significantly improve both the efficiency and accuracy of PINNs. Moreover, in three-dimensional cases, our approach is 5-10 times faster than traditional finite element methods while maintaining competitive accuracy, demonstrating its potential for real-world engineering applications in corrosion prediction.
<div id='section'>Paperid: <span id='pid'>1817, <a href='https://arxiv.org/pdf/2502.10949.pdf' target='_blank'>https://arxiv.org/pdf/2502.10949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Suchuan Dong, Naxian Ni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.10949">Learning the Exact Time Integration Algorithm for Initial Value Problems by Randomized Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a method leveraging extreme learning machine (ELM) type randomized neural networks (NNs) for learning the exact time integration algorithm for initial value problems (IVPs). The exact time integration algorithm for non-autonomous systems can be represented by an algorithmic function in higher dimensions, which satisfies an associated system of partial differential equations with corresponding boundary conditions. Our method learns the algorithmic function by solving this associated system using ELM with a physics informed approach. The trained ELM network serves as the learned algorithm and can be used to solve the IVP with arbitrary initial data or step sizes from some domain. When the right hand side of the non-autonomous system exhibits a periodicity with respect to any of its arguments, while the solution itself to the problem is not periodic, we show that the algorithmic function is either periodic, or when it is not, satisfies a well-defined relation for different periods. This property can greatly simplify the algorithm learning in many problems. We consider explicit and implicit NN formulations, leading to explicit or implicit time integration algorithms, and discuss how to train the ELM network by the nonlinear least squares method. Extensive numerical experiments with benchmark problems, including non-stiff, stiff and chaotic systems, show that the learned NN algorithm produces highly accurate solutions in long-time simulations, with its time-marching errors decreasing nearly exponentially with increasing degrees of freedom in the neural network. We compare extensively the computational performance (accuracy vs.~cost) between the current NN algorithm and the leading traditional time integration algorithms. The learned NN algorithm is computationally competitive, markedly outperforming the traditional algorithms in many problems.
<div id='section'>Paperid: <span id='pid'>1818, <a href='https://arxiv.org/pdf/2502.05044.pdf' target='_blank'>https://arxiv.org/pdf/2502.05044.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Denis Korolev, Tim Schmidt, Dinesh K. Natarajan, Stefano Cassola, David May, Miro Duhovic, Michael HintermÃ¼ller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.05044">Hybrid machine learning based scale bridging framework for permeability prediction of fibrous structures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study introduces a hybrid machine learning-based scale-bridging framework for predicting the permeability of fibrous textile structures. By addressing the computational challenges inherent to multiscale modeling, the proposed approach evaluates the efficiency and accuracy of different scale-bridging methodologies combining traditional surrogate models and even integrating physics-informed neural networks (PINNs) with numerical solvers, enabling accurate permeability predictions across micro- and mesoscales. Four methodologies were evaluated: Single Scale Method (SSM), Simple Upscaling Method (SUM), Scale-Bridging Method (SBM), and Fully Resolved Model (FRM). SSM, the simplest method, neglects microscale permeability and exhibited permeability values deviating by up to 150\% of the FRM model, which was taken as ground truth at an equivalent lower fiber volume content. SUM improved predictions by considering uniform microscale permeability, yielding closer values under similar conditions, but still lacked structural variability. The SBM method, incorporating segment-based microscale permeability assignments, showed significant enhancements, achieving almost equivalent values while maintaining computational efficiency and modeling runtimes of ~45 minutes per simulation. In contrast, FRM, which provides the highest fidelity by fully resolving microscale and mesoscale geometries, required up to 270 times more computational time than SSM, with model files exceeding 300 GB. Additionally, a hybrid dual-scale solver incorporating PINNs has been developed and shows the potential to overcome generalization errors and the problem of data scarcity of the data-driven surrogate approaches. The hybrid framework advances permeability modelling by balancing computational cost and prediction reliability, laying the foundation for further applications in fibrous composite manufacturing.
<div id='section'>Paperid: <span id='pid'>1819, <a href='https://arxiv.org/pdf/2502.01820.pdf' target='_blank'>https://arxiv.org/pdf/2502.01820.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hesameddin Safari, Henning Wessels
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.01820">Physics-Informed Surrogates for Temperature Prediction of Multi-Tracks in Laser Powder Bed Fusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling plays a critical role in additive manufacturing (AM), enabling a deeper understanding of underlying processes. Parametric solutions for such models are of great importance, enabling the optimization of production processes and considerable cost reductions. However, the complexity of the problem and diversity of spatio-temporal scales involved in the process pose significant challenges for traditional numerical methods. Surrogate models offer a powerful alternative by accelerating simulations and facilitating real-time monitoring and control. The present study presents an operator learning approach that relies on the deep operator network (DeepONet) and physics-informed neural networks (PINN) to predict the three-dimensional temperature distribution during melting and consolidation in laser powder bed fusion (LPBF). Parametric solutions for both single-track and multi-track scenarios with respect to tool path are obtained. To address the challenges in obtaining parametric solutions for multi-track scenarios using DeepONet architecture, a sequential PINN approach is proposed to efficiently manage the increased training complexity inherent in those scenarios. The accuracy and consistency of the model are verified against finite-difference computations. The developed surrogate allows us to efficiently analyze the effect of scanning paths and laser parameters on the thermal history.
<div id='section'>Paperid: <span id='pid'>1820, <a href='https://arxiv.org/pdf/2502.00280.pdf' target='_blank'>https://arxiv.org/pdf/2502.00280.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan Daniel Meshir, Abel Palafox, Edgar Alejandro Guerrero
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00280">On the study of frequency control and spectral bias in Wavelet-Based Kolmogorov Arnold networks: A path to physics-informed KANs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spectral bias, the tendency of neural networks to prioritize learning low-frequency components of functions during the initial training stages, poses a significant challenge when approximating solutions with high-frequency details. This issue is particularly pronounced in physics-informed neural networks (PINNs), widely used to solve differential equations that describe physical phenomena. In the literature, contributions such as Wavelet Kolmogorov Arnold Networks (Wav-KANs) have demonstrated promising results in capturing both low- and high-frequency components. Similarly, Fourier features (FF) are often employed to address this challenge. However, the theoretical foundations of Wav-KANs, particularly the relationship between the frequency of the mother wavelet and spectral bias, remain underexplored. A more in-depth understanding of how Wav-KANs manage high-frequency terms could offer valuable insights for addressing oscillatory phenomena encountered in parabolic, elliptic, and hyperbolic differential equations. In this work, we analyze the eigenvalues of the neural tangent kernel (NTK) of Wav-KANs to enhance their ability to converge on high-frequency components, effectively mitigating spectral bias. Our theoretical findings are validated through numerical experiments, where we also discuss the limitations of traditional approaches, such as standard PINNs and Fourier features, in addressing multi-frequency problems.
<div id='section'>Paperid: <span id='pid'>1821, <a href='https://arxiv.org/pdf/2502.00194.pdf' target='_blank'>https://arxiv.org/pdf/2502.00194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Althaf Shajihan, Kirill Mechitov, Girish Chowdhary, Billie F. Spencer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.00194">Physics-Informed Neural Network based Damage Identification for Truss Railroad Bridges</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Railroad bridges are a crucial component of the U.S. freight rail system, which moves over 40 percent of the nation's freight and plays a critical role in the economy. However, aging bridge infrastructure and increasing train traffic pose significant safety hazards and risk service disruptions. The U.S. rail network includes over 100,000 railroad bridges, averaging one every 1.4 miles of track, with steel bridges comprising over 50% of the network's total bridge length. Early identification and assessment of damage in these bridges remain challenging tasks. This study proposes a physics-informed neural network (PINN) based approach for damage identification in steel truss railroad bridges. The proposed approach employs an unsupervised learning approach, eliminating the need for large datasets typically required by supervised methods. The approach utilizes train wheel load data and bridge response during train crossing events as inputs for damage identification. The PINN model explicitly incorporates the governing differential equations of the linear time-varying (LTV) bridge-train system. Herein, this model employs a recurrent neural network (RNN) based architecture incorporating a custom Runge-Kutta (RK) integrator cell, designed for gradient-based learning. The proposed approach updates the bridge finite element model while also quantifying damage severity and localizing the affected structural members. A case study on the Calumet Bridge in Chicago, Illinois, with simulated damage scenarios, is used to demonstrate the model's effectiveness in identifying damage while maintaining low false-positive rates. Furthermore, the damage identification pipeline is designed to seamlessly integrate prior knowledge from inspections and drone surveys, also enabling context-aware updating and assessment of bridge's condition.
<div id='section'>Paperid: <span id='pid'>1822, <a href='https://arxiv.org/pdf/2501.18078.pdf' target='_blank'>https://arxiv.org/pdf/2501.18078.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karthik Reddy Lyathakula, Aseem Muhammad, Sevki Cesmeci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18078">Statistical Design of Thermal Protection System Using Physics-Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Thermal protection systems (TPS) of space vehicles are designed computationally rather than experimentally. They are validated using ground experiments, but all aspects of the flight cannot be replicated on ground. This ground-to-flight mapping introduces uncertainties which need to be accounted for while designing any thermal protection system. Thus, precise computational models along with uncertainty quantification in the models are required to design the TPS. The focus of this study is to estimate the thermal material parameters of TPS based on the target reliability requirements using statistical methods. To perform uncertainty quantification (UQ) of a system, a simulated model of the system needs to be solved many times on statistical samples, increasing the computational time and cost of the overall process. A physics-informed neural network (PINN) model is used in the analysis instead of traditional physics based numerical solutions. The accuracy of PINN is comparable to that of the numerical solution. To find the parameter distribution, sampling of the parameter space is performed using Sequential Monte- Carlo (SMC) method. The sampling method is efficient as it generates samples based on the target distribution in parallel and it also generates diverse samples for proper UQ. Combining the use of both PINN predictive model and SMC sampling, the framework can approximate the parameter distributions that satisfy the TPS design reliability constraints. The framework achieved remarkable increases in the speed of performing the reliability analysis of the TPS. This reliability analysis can be used for design optimization of the TPS based on risk analysis along with other systems of the vehicle.
<div id='section'>Paperid: <span id='pid'>1823, <a href='https://arxiv.org/pdf/2501.16867.pdf' target='_blank'>https://arxiv.org/pdf/2501.16867.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vijay Kuberan, Sateesh Gedupudi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16867">Empirical modeling and hybrid machine learning framework for nucleate pool boiling on microchannel structured surfaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Micro-structured surfaces influence nucleation characteristics and bubble dynamics besides increasing the heat transfer surface area, thus enabling efficient nucleate boiling heat transfer. Modeling the pool boiling heat transfer characteristics of these surfaces under varied conditions is essential in diverse applications. A new empirical correlation for nucleate boiling on microchannel structured surfaces has been proposed with the data collected from various experiments in previous studies since the existing correlations are limited by their accuracy and narrow operating ranges. This study also examines various Machine Learning (ML) algorithms and Deep Neural Networks (DNN) on the microchannel structured surfaces dataset to predict the nucleate pool boiling Heat Transfer Coefficient (HTC). With the aim to integrate both the ML and domain knowledge, a Physics-Informed Machine Learning Aided Framework (PIMLAF) is proposed. The proposed correlation in this study is employed as the prior physics-based model for PIMLAF, and a DNN is employed to model the residuals of the prior model. This hybrid framework achieved the best performance in comparison to the other ML models and DNNs. This framework is able to generalize well for different datasets because the proposed correlation provides the baseline knowledge of the boiling behavior. Also, SHAP interpretation analysis identifies the critical parameters impacting the model predictions and their effect on HTC prediction. This analysis further makes the model more robust and reliable.
  Keywords: Pool boiling, Microchannels, Heat transfer coefficient, Correlation analysis, Machine learning, Deep neural network, Physics-informed machine learning aided framework, SHAP analysis
<div id='section'>Paperid: <span id='pid'>1824, <a href='https://arxiv.org/pdf/2501.16362.pdf' target='_blank'>https://arxiv.org/pdf/2501.16362.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoyun Xing, Kaiyan Jin, Guice Yao, Jin Zhao, Dichu Xu, Dongsheng Wen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.16362">A novel Trunk Branch-net PINN for flow and heat transfer prediction in porous medium</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A novel Trunk-Branch (TB)-net physics-informed neural network (PINN) architecture is developed, which is a PINN-based method incorporating trunk and branch nets to capture both global and local features. The aim is to solve four main classes of problems: forward flow problem, forward heat transfer problem, inverse heat transfer problem, and transfer learning problem within the porous medium, which are notoriously complex that could not be handled by origin PINN. In the proposed TB-net PINN architecture, a Fully-connected Neural Network (FNN) is used as the trunk net, followed by separated FNNs as the branch nets with respect to outputs, and automatic differentiation is performed for partial derivatives of outputs with respect to inputs by considering various physical loss. The effectiveness and flexibility of the novel TB-net PINN architecture is demonstrated through a collection of forward problems, and transfer learning validates the feasibility of resource reuse. Combining with the superiority over traditional numerical methods in solving inverse problems, the proposed TB-net PINN shows its great potential for practical engineering applications.
<div id='section'>Paperid: <span id='pid'>1825, <a href='https://arxiv.org/pdf/2501.14709.pdf' target='_blank'>https://arxiv.org/pdf/2501.14709.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zaheer Ahmad, Junaid Shabeer, Usman Saleem, Tahir Qadeer, Abdul Sami, Zahira El Khalidi, Saad Mehmood
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.14709">Enhanced Confocal Laser Scanning Microscopy with Adaptive Physics Informed Deep Autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a physics-informed deep learning framework to address common limitations in Confocal Laser Scanning Microscopy (CLSM), such as diffraction limited resolution, noise, and undersampling due to low laser power conditions. The optical system's point spread function (PSF) and common CLSM image degradation mechanisms namely photon shot noise, dark current noise, motion blur, speckle noise, and undersampling were modeled and were directly included into model architecture. The model reconstructs high fidelity images from heavily noisy inputs by using convolutional and transposed convolutional layers. Following the advances in compressed sensing, our approach significantly reduces data acquisition requirements without compromising image resolution. The proposed method was extensively evaluated on simulated CLSM images of diverse structures, including lipid droplets, neuronal networks, and fibrillar systems. Comparisons with traditional deconvolution algorithms such as Richardson-Lucy (RL), non-negative least squares (NNLS), and other methods like Total Variation (TV) regularization, Wiener filtering, and Wavelet denoising demonstrate the superiority of the network in restoring fine structural details with high fidelity. Assessment metrics like Structural Similarity Index (SSIM) and Peak Signal to Noise Ratio (PSNR), underlines that the AdaptivePhysicsAutoencoder achieved robust image enhancement across diverse CLSM conditions, helping faster acquisition, reduced photodamage, and reliable performance in low light and sparse sampling scenarios holding promise for applications in live cell imaging, dynamic biological studies, and high throughput material characterization.
<div id='section'>Paperid: <span id='pid'>1826, <a href='https://arxiv.org/pdf/2501.14107.pdf' target='_blank'>https://arxiv.org/pdf/2501.14107.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianhong Chen, Shihao Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.14107">EFiGP: Eigen-Fourier Physics-Informed Gaussian Process for Inference of Dynamic Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Parameter estimation and trajectory reconstruction for data-driven dynamical systems governed by ordinary differential equations (ODEs) are essential tasks in fields such as biology, engineering, and physics. These inverse problems -- estimating ODE parameters from observational data -- are particularly challenging when the data are noisy, sparse, and the dynamics are nonlinear. We propose the Eigen-Fourier Physics-Informed Gaussian Process (EFiGP), an algorithm that integrates Fourier transformation and eigen-decomposition into a physics-informed Gaussian Process framework. This approach eliminates the need for numerical integration, significantly enhancing computational efficiency and accuracy. Built on a principled Bayesian framework, EFiGP incorporates the ODE system through probabilistic conditioning, enforcing governing equations in the Fourier domain while truncating high-frequency terms to achieve denoising and computational savings. The use of eigen-decomposition further simplifies Gaussian Process covariance operations, enabling efficient recovery of trajectories and parameters even in dense-grid settings. We validate the practical effectiveness of EFiGP on three benchmark examples, demonstrating its potential for reliable and interpretable modeling of complex dynamical systems while addressing key challenges in trajectory recovery and computational cost.
<div id='section'>Paperid: <span id='pid'>1827, <a href='https://arxiv.org/pdf/2501.12145.pdf' target='_blank'>https://arxiv.org/pdf/2501.12145.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>T. De Ryck, S. Mishra, Y. Shang, F. Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.12145">Approximation Theory and Applications of Randomized Neural Networks for Solving High-Dimensional PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present approximation results and numerical experiments for the use of randomized neural networks within physics-informed extreme learning machines to efficiently solve high-dimensional PDEs, demonstrating both high accuracy and low computational cost. Specifically, we prove that RaNNs can approximate certain classes of functions, including Sobolev functions, in the $H^2$-norm at dimension-independent convergence rates, thereby alleviating the curse of dimensionality. Numerical experiments are provided for the high-dimensional heat equation, the Black-Scholes model, and the Heston model, demonstrating the accuracy and efficiency of randomized neural networks.
<div id='section'>Paperid: <span id='pid'>1828, <a href='https://arxiv.org/pdf/2501.10684.pdf' target='_blank'>https://arxiv.org/pdf/2501.10684.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amogh Raj, Carol Eunice Gudumotou, Sakol Bun, Keerthana Srinivasa, Arash Sarshar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.10684">Deep Operator Networks for Bayesian Parameter Estimation in PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel framework combining Deep Operator Networks (DeepONets) with Physics-Informed Neural Networks (PINNs) to solve partial differential equations (PDEs) and estimate their unknown parameters. By integrating data-driven learning with physical constraints, our method achieves robust and accurate solutions across diverse scenarios. Bayesian training is implemented through variational inference, allowing for comprehensive uncertainty quantification for both aleatoric and epistemic uncertainties. This ensures reliable predictions and parameter estimates even in noisy conditions or when some of the physical equations governing the problem are missing. The framework demonstrates its efficacy in solving forward and inverse problems, including the 1D unsteady heat equation and 2D reaction-diffusion equations, as well as regression tasks with sparse, noisy observations. This approach provides a computationally efficient and generalizable method for addressing uncertainty quantification in PDE surrogate modeling.
<div id='section'>Paperid: <span id='pid'>1829, <a href='https://arxiv.org/pdf/2501.07809.pdf' target='_blank'>https://arxiv.org/pdf/2501.07809.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daehee Cho, Hyeonmin Yun, Jaeyong Lee, Mikyoung Lim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.07809">Conformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs): learning neural networks for designing neutral inclusions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We focus on designing and solving the neutral inclusion problem via neural networks. The neutral inclusion problem has a long history in the theory of composite materials, and it is exceedingly challenging to identify the precise condition that precipitates a general-shaped inclusion into a neutral inclusion. Physics-informed neural networks (PINNs) have recently become a highly successful approach to addressing both forward and inverse problems associated with partial differential equations. We found that traditional PINNs perform inadequately when applied to the inverse problem of designing neutral inclusions with arbitrary shapes. In this study, we introduce a novel approach, Conformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs), which integrates complex analysis techniques into PINNs. This method exhibits strong performance in solving forward-inverse problems to construct neutral inclusions of arbitrary shapes in two dimensions, where the imperfect interface condition on the inclusion's boundary is modeled by training neural networks. Notably, we mathematically prove that training with a single linear field is sufficient to achieve neutrality for untrained linear fields in arbitrary directions, given a minor assumption. We demonstrate that CoCo-PINNs offer enhanced performances in terms of credibility, consistency, and stability.
<div id='section'>Paperid: <span id='pid'>1830, <a href='https://arxiv.org/pdf/2501.06335.pdf' target='_blank'>https://arxiv.org/pdf/2501.06335.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlos AndrÃ©s Elorza Casas, Luis A. Ricardez-Sandoval, Joshua L. Pulsipher
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06335">A Comparison of Strategies to Embed Physics-Informed Neural Networks in Nonlinear Model Predictive Control Formulations Solved via Direct Transcription</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study aims to benchmark candidate strategies for embedding neural network (NN) surrogates in nonlinear model predictive control (NMPC) formulations that are subject to systems described with partial differential equations and that are solved via direct transcription (i.e., simultaneous methods). This study focuses on the use of physics-informed NNs and physics-informed convolutional NNs as the internal (surrogate) models within the NMPC formulation. One strategy embeds NN models as explicit algebraic constraints, leveraging the automatic differentiation (AD) of an algebraic modelling language (AML) to evaluate the derivatives. Alternatively, the solver can be provided with derivatives computed external to the AML via the AD routines of the machine learning environment the NN is trained in. The three numerical experiments considered in this work reveal that replacing mechanistic models with NN surrogates may not always offer computational advantages when smooth activation functions are used in conjunction with a local nonlinear solver (e.g., Ipopt), even with highly nonlinear systems. Moreover, in this context, the external function evaluation of the NN surrogates often outperforms the embedding strategies that rely on explicit algebraic constraints, likely due to the difficulty in initializing the auxiliary variables and constraints introduced by explicit algebraic reformulations.
<div id='section'>Paperid: <span id='pid'>1831, <a href='https://arxiv.org/pdf/2501.04013.pdf' target='_blank'>https://arxiv.org/pdf/2501.04013.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Avetik Arakelyan, Rafayel Barkhudaryan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.04013">Convergence of Physics-Informed Neural Networks for Fully Nonlinear PDE's</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The present work is focused on exploring convergence of Physics-informed Neural Networks (PINNs) when applied to a specific class of second-order fully nonlinear Partial Differential Equations (PDEs). It is well-known that as the number of data grows, PINNs generate a sequence of minimizers which correspond to a sequence of neural networks. We show that such sequence converges to a unique viscosity solution of a certain class of second-order fully nonlinear PDE's, provided the latter satisfies the comparison principle in the viscosity sense.
<div id='section'>Paperid: <span id='pid'>1832, <a href='https://arxiv.org/pdf/2412.21132.pdf' target='_blank'>https://arxiv.org/pdf/2412.21132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>A. Tollardo, F. Cadini, M. Giglio, L. Lomazzi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.21132">DeepF-fNet: a physics-informed neural network for vibration isolation optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Structural optimization is essential for designing safe, efficient, and durable components with minimal material usage. Traditional methods for vibration control often rely on active systems to mitigate unpredictable vibrations, which may lead to resonance and potential structural failure. However, these methods face significant challenges when addressing the nonlinear inverse eigenvalue problems required for optimizing structures subjected to a wide range of frequencies. As a result, no existing approach has effectively addressed the need for real-time vibration suppression within this context, particularly in high-performance environments such as automotive noise, vibration and harshness, where computational efficiency is crucial.
  This study introduces DeepF-fNet, a novel neural network framework designed to replace traditional active systems in vibration-based structural optimization. Leveraging DeepONets within the context of physics-informed neural networks, DeepF-fNet integrates both data and the governing physical laws. This enables rapid identification of optimal parameters to suppress critical vibrations at specific frequencies, offering a more efficient and real-time alternative to conventional methods.
  The proposed framework is validated through a case study involving a locally resonant metamaterial used to isolate structures from user-defined frequency ranges. The results demonstrate that DeepF-fNet outperforms traditional genetic algorithms in terms of computational speed while achieving comparable results, making it a promising tool for vibration-sensitive applications. By replacing active systems with machine learning techniques, DeepF-fNet paves the way for more efficient and cost-effective structural optimization in real-world scenarios.
<div id='section'>Paperid: <span id='pid'>1833, <a href='https://arxiv.org/pdf/2412.20575.pdf' target='_blank'>https://arxiv.org/pdf/2412.20575.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georgios Akrivis, Charalambos G. Makridakis, Costas Smaragdakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20575">Runge-Kutta Physics Informed Neural Networks: Formulation and Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper we consider time-dependent PDEs discretized by a special class of Physics Informed Neural Networks whose design is based on the framework of Runge--Kutta and related time-Galerkin discretizations. The primary motivation for using such methods is that alternative time-discrete schemes not only enable higher-order approximations but also have a crucial impact on the qualitative behavior of the discrete solutions. The design of the methods follows a novel training approach based on two key principles: (a) the discrete loss is designed using a time-discrete framework, and (b) the final loss formulation incorporates Runge--Kutta or time-Galerkin discretization in a carefully structured manner. We then demonstrate that the resulting methods inherit the stability properties of the Runge--Kutta or time-Galerkin schemes, and furthermore, their computational behavior aligns with that of the original time discrete method used in their formulation. In our analysis, we focus on linear parabolic equations, demonstrating both the stability of the methods and the convergence of the discrete minimizers to solutions of the underlying evolution PDE. An important novel aspect of our work is the derivation of maximal regularity (MR) estimates for B-stable Runge--Kutta schemes and both continuous and discontinuous Galerkin time discretizations. This allows us to provide new energy-based proofs for maximal regularity estimates previously established by KovÃ¡cs, Li, and Lubich, now in the Hilbert space setting and with the flexibility of variable time steps.
<div id='section'>Paperid: <span id='pid'>1834, <a href='https://arxiv.org/pdf/2412.18344.pdf' target='_blank'>https://arxiv.org/pdf/2412.18344.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aneesh Panchal, Kirti Beniwal, Vivek Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.18344">Predator Prey Scavenger Model using Holling's Functional Response of Type III and Physics-Informed Deep Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nonlinear mathematical models introduce the relation between various physical and biological interactions present in nature. One of the most famous models is the Lotka-Volterra model which defined the interaction between predator and prey species present in nature. However, predators, scavengers, and prey populations coexist in a natural system where scavengers can additionally rely on the dead bodies of predators present in the system. Keeping this in mind, the formulation and simulation of the predator prey scavenger model is introduced in this paper. For the predation response, respective prey species are assumed to have Holling's functional response of type III. The proposed model is tested for various simulations and is found to be showing satisfactory results in different scenarios. After simulations, the American forest dataset is taken for parameter estimation which imitates the real-world case. For parameter estimation, a physics-informed deep neural network is used with the Adam backpropagation method which prevents the avalanche effect in trainable parameters updation. For neural networks, mean square error and physics-informed informed error are considered. After the neural network, the hence-found parameters are fine-tuned using the Broyden-Fletcher-Goldfarb-Shanno algorithm. Finally, the hence-found parameters using a natural dataset are tested for stability using Jacobian stability analysis. Future research work includes minimization of error induced by parameters, bifurcation analysis, and sensitivity analysis of the parameters.
<div id='section'>Paperid: <span id='pid'>1835, <a href='https://arxiv.org/pdf/2412.17827.pdf' target='_blank'>https://arxiv.org/pdf/2412.17827.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Xuanxuan, Zhang Yangming, Chen Haofeng, Ma Gang, Wang Xiaojie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.17827">CPFI-EIT: A CNN-PINN Framework for Full-Inverse Electrical Impedance Tomography on Non-Smooth Conductivity Distributions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a hybrid learning framework that combines convolutional neural networks (CNNs) and physics-informed neural networks (PINNs) to address the challenging problem of full-inverse electrical impedance tomography (EIT). EIT is a noninvasive imaging technique that reconstructs the spatial distribution of internal conductivity based on boundary voltage measurements from injected currents. This method has applications across medical imaging, multiphase flow detection, and tactile sensing. However, solving EIT involves a nonlinear partial differential equation (PDE) derived from Maxwell's equations, posing significant computational challenges as an ill-posed inverse problem. Existing PINN approaches primarily address semi-inverse EIT, assuming full access to internal potential data, which limits practical applications in realistic, full-inverse scenarios. Our framework employs a forward CNN-based supervised network to map differential boundary voltage measurements to a discrete potential distribution under fixed Neumann boundary conditions, while an inverse PINN-based unsupervised network enforces PDE constraints for conductivity reconstruction. Instead of traditional automatic differentiation, we introduce discrete numerical differentiation to bridge the forward and inverse networks, effectively decoupling them, enhancing modularity, and reducing computational demands. We validate our framework under realistic conditions, using a 16-electrode setup and rigorous testing on complex conductivity distributions with sharp boundaries, without Gaussian smoothing. This approach demonstrates robust flexibility and improved applicability in full-inverse EIT, establishing a practical solution for real-world imaging challenges.
<div id='section'>Paperid: <span id='pid'>1836, <a href='https://arxiv.org/pdf/2412.14683.pdf' target='_blank'>https://arxiv.org/pdf/2412.14683.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Jesser, Kai Krycki, Ryan G. McClarren, Martin Frank
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.14683">Numerical Robustness of PINNs for Multiscale Transport Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We investigate the numerical solution of multiscale transport equations using Physics Informed Neural Networks (PINNs) with ReLU activation functions. Therefore, we study the analogy between PINNs and Least-Squares Finite Elements (LSFE) which lies in the shared approach to reformulate the PDE solution as a minimization of a quadratic functional. We prove that in the diffusive regime, the correct limit is not reached, in agreement with known results for first-order LSFE. A diffusive scaling is introduced that can be applied to overcome this, again in full agreement with theoretical results for LSFE. We provide numerical results in the case of slab geometry that support our theoretical findings.
<div id='section'>Paperid: <span id='pid'>1837, <a href='https://arxiv.org/pdf/2412.14132.pdf' target='_blank'>https://arxiv.org/pdf/2412.14132.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hugo Gangloff, Nicolas Jouvin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.14132">jinns: a JAX Library for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>jinns is an open-source Python library for physics-informed neural networks, built to tackle both forward and inverse problems, as well as meta-model learning. Rooted in the JAX ecosystem, it provides a versatile framework for efficiently prototyping real-problems, while easily allowing extensions to specific needs. Furthermore, the implementation leverages existing popular JAX libraries such as equinox and optax for model definition and optimisation, bringing a sense of familiarity to the user. Many models are available as baselines, and the documentation provides reference implementations of different use-cases along with step-by-step tutorials for extensions to specific needs. The code is available on Gitlab https://gitlab.com/mia_jinns/jinns.
<div id='section'>Paperid: <span id='pid'>1838, <a href='https://arxiv.org/pdf/2412.10782.pdf' target='_blank'>https://arxiv.org/pdf/2412.10782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nilo Schwencke, Cyril Furtlehner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.10782">ANaGRAM: A Natural Gradient Relative to Adapted Model for efficient PINNs learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the recent years, Physics Informed Neural Networks (PINNs) have received strong interest as a method to solve PDE driven systems, in particular for data assimilation purpose. This method is still in its infancy, with many shortcomings and failures that remain not properly understood. In this paper we propose a natural gradient approach to PINNs which contributes to speed-up and improve the accuracy of the training. Based on an in depth analysis of the differential geometric structures of the problem, we come up with two distinct contributions: (i) a new natural gradient algorithm that scales as $\min(P^2S, S^2P)$, where $P$ is the number of parameters, and $S$ the batch size; (ii) a mathematically principled reformulation of the PINNs problem that allows the extension of natural gradient to it, with proved connections to Green's function theory.
<div id='section'>Paperid: <span id='pid'>1839, <a href='https://arxiv.org/pdf/2412.06842.pdf' target='_blank'>https://arxiv.org/pdf/2412.06842.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arturo Rodriguez, Ashesh Chattopadhyay, Piyush Kumar, Luis F. Rodriguez, Vinod Kumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.06842">Partition of Unity Physics-Informed Neural Networks (POU-PINNs): An Unsupervised Framework for Physics-Informed Domain Decomposition and Mixtures of Experts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) commonly address ill-posed inverse problems by uncovering unknown physics. This study presents a novel unsupervised learning framework that identifies spatial subdomains with specific governing physics. It uses the partition of unity networks (POUs) to divide the space into subdomains, assigning unique nonlinear model parameters to each, which are integrated into the physics model. A vital feature of this method is a physics residual-based loss function that detects variations in physical properties without requiring labeled data. This approach enables the discovery of spatial decompositions and nonlinear parameters in partial differential equations (PDEs), optimizing the solution space by dividing it into subdomains and improving accuracy. Its effectiveness is demonstrated through applications in porous media thermal ablation and ice-sheet modeling, showcasing its potential for tackling real-world physics challenges.
<div id='section'>Paperid: <span id='pid'>1840, <a href='https://arxiv.org/pdf/2412.05525.pdf' target='_blank'>https://arxiv.org/pdf/2412.05525.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>H. Sababha, A. Elmaradny, H. Taha, M. Daqaq
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.05525">A Variational Computational-based Framework for Unsteady Incompressible Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advancements in computational fluid mechanics have largely relied on Newtonian frameworks, particularly through the direct simulation of Navier-Stokes equations. In this work, we propose an alternative computational framework that employs variational methods, specifically by leveraging the principle of minimum pressure gradient, which turns the fluid mechanics problem into a minimization problem whose solution can be used to predict the flow field in unsteady incompressible viscous flows.
  This method exhibits two particulary intriguing properties. First, it circumvents the chronic issues of pressure-velocity coupling in incompressible flows, which often dominates the computational cost in computational fluid dynamics (CFD). Second, this method eliminates the reliance on unphysical assumptions at the outflow boundary, addressing another longstanding challenge in CFD.
  We apply this framework to three benchmark examples across a range of Reynolds numbers: (i) unsteady flow field in a lid-driven cavity, (ii) Poiseuille flow, and (iii) flow past a circular cylinder. The minimization framework is carried out using a physics-informed neural network (PINN), which integrates the underlying physical principles directly into the training of the model. The results from the proposed method are validated against high-fidelity CFD simulations, showing an excellent agreement. Comparison of the proposed variational method to the conventional method, wherein PINNs is directly applied to solve Navier-Stokes Equations, reveals that the proposed method outperforms conventional PINNs in terms of both convergence rate and time, demonstrating its potential for solving complex fluid mechanics problems.
<div id='section'>Paperid: <span id='pid'>1841, <a href='https://arxiv.org/pdf/2412.03609.pdf' target='_blank'>https://arxiv.org/pdf/2412.03609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Biqi Chen, Ying Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.03609">Online Physics-Informed Dynamic Mode Decomposition: Theory and Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamic Mode Decomposition (DMD) has received increasing research attention due to its capability to analyze and model complex dynamical systems. However, it faces challenges in computational efficiency, noise sensitivity, and difficulty adhering to physical laws, which negatively affect its performance. Addressing these issues, we present Online Physics-informed DMD (OPIDMD), a novel adaptation of DMD into a convex optimization framework. This approach not only ensures convergence to a unique global optimum, but also enhances the efficiency and accuracy of modeling dynamical systems in an online setting. Leveraging the Bayesian DMD framework, we propose a probabilistic interpretation of Physics-informed DMD (piDMD), examining the impact of physical constraints on the DMD linear operator. Further, we implement online proximal gradient descent and formulate specific algorithms to tackle problems with different physical constraints, enabling real-time solutions across various scenarios. Compared with existing algorithms such as Exact DMD, Online DMD, and piDMD, OPIDMD achieves the best prediction performance in short-term forecasting, e.g. an $R^2$ value of 0.991 for noisy Lorenz system. The proposed method employs a time-varying linear operator, offering a promising solution for the real-time simulation and control of complex dynamical systems.
<div id='section'>Paperid: <span id='pid'>1842, <a href='https://arxiv.org/pdf/2412.00225.pdf' target='_blank'>https://arxiv.org/pdf/2412.00225.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michail Koumpanakis, Ricardo Vilalta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.00225">Meta-learning Loss Functions of Parametric Partial Differential Equations Using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a new way to learn Physics-Informed Neural Network loss functions using Generalized Additive Models. We apply our method by meta-learning parametric partial differential equations, PDEs, on Burger's and 2D Heat Equations. The goal is to learn a new loss function for each parametric PDE using meta-learning. The derived loss function replaces the traditional data loss, allowing us to learn each parametric PDE more efficiently, improving the meta-learner's performance and convergence.
<div id='section'>Paperid: <span id='pid'>1843, <a href='https://arxiv.org/pdf/2411.13848.pdf' target='_blank'>https://arxiv.org/pdf/2411.13848.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Augusto T. Chantada, Pavlos Protopapas, Luca Gomez Bachar, Susana J. Landau, Claudia G. ScÃ³ccola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.13848">Exact and approximate error bounds for physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The use of neural networks to solve differential equations, as an alternative to traditional numerical solvers, has increased recently. However, error bounds for the obtained solutions have only been developed for certain equations. In this work, we report important progress in calculating error bounds of physics-informed neural networks (PINNs) solutions of nonlinear first-order ODEs. We give a general expression that describes the error of the solution that the PINN-based method provides for a nonlinear first-order ODE. In addition, we propose a technique to calculate an approximate bound for the general case and an exact bound for a particular case. The error bounds are computed using only the residual information and the equation structure. We apply the proposed methods to particular cases and show that they can successfully provide error bounds without relying on the numerical solution.
<div id='section'>Paperid: <span id='pid'>1844, <a href='https://arxiv.org/pdf/2411.11497.pdf' target='_blank'>https://arxiv.org/pdf/2411.11497.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Saad Zia, Ashiq Anjum, Lu Liu, Anthony Conway, Anasol Pena Rios
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11497">Physics Encoded Blocks in Residual Neural Network Architectures for Digital Twin Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics Informed Machine Learning has emerged as a popular approach for modeling and simulation in digital twins, enabling the generation of accurate models of processes and behaviors in real-world systems. However, existing methods either rely on simple loss regularizations that offer limited physics integration or employ highly specialized architectures that are difficult to generalize across diverse physical systems. This paper presents a generic approach based on a novel physics-encoded residual neural network (PERNN) architecture that seamlessly combines data-driven and physics-based analytical models to overcome these limitations. Our method integrates differentiable physics blocks-implementing mathematical operators from physics-based models with feed-forward learning blocks, while intermediate residual blocks ensure stable gradient flow during training. Consequently, the model naturally adheres to the underlying physical principles even when prior physics knowledge is incomplete, thereby improving generalizability with low data requirements and reduced model complexity. We investigate our approach in two application domains. The first is a steering model for autonomous vehicles in a simulation environment, and the second is a digital twin for climate modeling using an ordinary differential equation (ODE)-based model of Net Ecosystem Exchange (NEE) to enable gap-filling in flux tower data. In both cases, our method outperforms conventional neural network approaches as well as state-of-the-art Physics Informed Machine Learning methods.
<div id='section'>Paperid: <span id='pid'>1845, <a href='https://arxiv.org/pdf/2411.11276.pdf' target='_blank'>https://arxiv.org/pdf/2411.11276.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yeping Wang, Shihao Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.11276">Coupled Integral PINN for conservation law</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Physics-Informed Neural Network (PINN) is an innovative approach to solve a diverse array of partial differential equations (PDEs) leveraging the power of neural networks. This is achieved by minimizing the residual loss associated with the explicit physical information, usually coupled with data derived from initial and boundary conditions. However, a challenge arises in the context of nonlinear conservation laws where derivatives are undefined at shocks, leading to solutions that deviate from the true physical phenomena. To solve this issue, the physical solution must be extracted from the weak formulation of the PDE and is typically further bounded by entropy conditions. Within the numerical framework, finite volume methods (FVM) are employed to address conservation laws. These methods resolve the integral form of conservation laws and delineate the shock characteristics. Inspired by the principles underlying FVM, this paper introduces a novel Coupled Integrated PINN methodology that involves fitting the integral solutions of equations using additional neural networks. This technique not only augments the conventional PINN's capability in modeling shock waves, but also eliminates the need for spatial and temporal discretization. As such, it bypasses the complexities of numerical integration and reconstruction associated with non-convex fluxes. Finally, we show that the proposed new Integrated PINN performs well in conservative law and outperforms the vanilla PINN when tackle the challenging shock problems using examples of Burger's equation, Buckley-Leverett Equation and Euler System.
<div id='section'>Paperid: <span id='pid'>1846, <a href='https://arxiv.org/pdf/2411.10064.pdf' target='_blank'>https://arxiv.org/pdf/2411.10064.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David Shulman, Itai Dattner
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.10064">Adaptive Physics-Guided Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces an adaptive physics-guided neural network (APGNN) framework for predicting quality attributes from image data by integrating physical laws into deep learning models. The APGNN adaptively balances data-driven and physics-informed predictions, enhancing model accuracy and robustness across different environments. Our approach is evaluated on both synthetic and real-world datasets, with comparisons to conventional data-driven models such as ResNet. For the synthetic data, 2D domains were generated using three distinct governing equations: the diffusion equation, the advection-diffusion equation, and the Poisson equation. Non-linear transformations were applied to these domains to emulate complex physical processes in image form.
  In real-world experiments, the APGNN consistently demonstrated superior performance in the diverse thermal image dataset. On the cucumber dataset, characterized by low material diversity and controlled conditions, APGNN and PGNN showed similar performance, both outperforming the data-driven ResNet. However, in the more complex thermal dataset, particularly for outdoor materials with higher environmental variability, APGNN outperformed both PGNN and ResNet by dynamically adjusting its reliance on physics-based versus data-driven insights. This adaptability allowed APGNN to maintain robust performance across structured, low-variability settings and more heterogeneous scenarios. These findings underscore the potential of adaptive physics-guided learning to integrate physical constraints effectively, even in challenging real-world contexts with diverse environmental conditions.
<div id='section'>Paperid: <span id='pid'>1847, <a href='https://arxiv.org/pdf/2411.09915.pdf' target='_blank'>https://arxiv.org/pdf/2411.09915.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zheng Liu, Yuan Jiang, Yumeng Li, Pingfeng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.09915">Physics-informed Machine Learning for Battery Pack Thermal Management</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the popularity of electric vehicles, the demand for lithium-ion batteries is increasing. Temperature significantly influences the performance and safety of batteries. Battery thermal management systems can effectively control the temperature of batteries; therefore, the performance and safety can be ensured. However, the development process of battery thermal management systems is time-consuming and costly due to the extensive training dataset needed by data-driven models requiring enormous computational costs for finite element analysis. Therefore, a new approach to constructing surrogate models is needed in the era of AI. Physics-informed machine learning enforces the physical laws in surrogate models, making it the perfect candidate for estimating battery pack temperature distribution. In this study, we first developed a 21700 battery pack indirect liquid cooling system with cold plates on the top and bottom with thermal paste surrounding the battery cells. Then, the simplified finite element model was built based on experiment results. Due to the high coolant flow rate, the cold plates can be considered as constant temperature boundaries, while battery cells are the heat sources. The physics-informed convolutional neural network served as a surrogate model to estimate the temperature distribution of the battery pack. The loss function was constructed considering the heat conduction equation based on the finite difference method. The physics-informed loss function helped the convergence of the training process with less data. As a result, the physics-informed convolutional neural network showed more than 15 percents improvement in accuracy compared to the data-driven method with the same training data.
<div id='section'>Paperid: <span id='pid'>1848, <a href='https://arxiv.org/pdf/2411.09728.pdf' target='_blank'>https://arxiv.org/pdf/2411.09728.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bozhou Zhuang, Sashank Rana, Brandon Jones, Danny Smyl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.09728">Physics-informed neural networks (PINNs) for numerical model error approximation and superresolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Numerical modeling errors are unavoidable in finite element analysis. The presence of model errors inherently reflects both model accuracy and uncertainty. To date there have been few methods for explicitly quantifying errors at points of interest (e.g. at finite element nodes). The lack of explicit model error approximators has been addressed recently with the emergence of machine learning (ML), which closes the loop between numerical model features/solutions and explicit model error approximations. In this paper, we propose physics-informed neural networks (PINNs) for simultaneous numerical model error approximation and superresolution. To test our approach, numerical data was generated using finite element simulations on a two-dimensional elastic plate with a central opening. Four- and eight-node quadrilateral elements were used in the discretization to represent the reduced-order and higher-order models, respectively. It was found that the developed PINNs effectively predict model errors in both x and y displacement fields with small differences between predictions and ground truth. Our findings demonstrate that the integration of physics-informed loss functions enables neural networks (NNs) to surpass a purely data-driven approach for approximating model errors.
<div id='section'>Paperid: <span id='pid'>1849, <a href='https://arxiv.org/pdf/2411.09704.pdf' target='_blank'>https://arxiv.org/pdf/2411.09704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fardous Hasan, Hazrat Ali, Hasan Asyari Arief
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.09704">From Mesh to Neural Nets: A Multi-Method Evaluation of Physics-Informed Neural Networks and Galerkin Finite Element Method for Solving Nonlinear Convection-Reaction-Diffusion Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Non-linear convection-reaction-diffusion (CRD) partial differential equations (PDEs) are crucial for modeling complex phenomena in fields such as biology, ecology, population dynamics, physics, and engineering. Numerical approximation of these non-linear systems is essential due to the challenges of obtaining exact solutions. Traditionally, the Galerkin finite element method (GFEM) has been the standard computational tool for solving these PDEs. With the advancements in machine learning, Physics-Informed Neural Network (PINN) has emerged as a promising alternative for approximating non-linear PDEs.
  In this study, we compare the performance of PINN and GFEM by solving four distinct one-dimensional CRD problems with varying initial and boundary conditions and evaluate the performance of PINN over GFEM. This evaluation metrics includes error estimates, and visual representations of the solutions, supported by statistical methods such as the root mean squared error (RMSE), the standard deviation of error, the the Wilcoxon Signed-Rank Test and the coefficient of variation (CV) test.
  Our findings reveal that while both methods achieve solutions close to the analytical results, PINN demonstrate superior accuracy and efficiency. PINN achieved significantly lower RMSE values and smaller standard deviations for Burgers' equation, Fisher's equation, and Newell-Whitehead-Segel equation, indicating higher accuracy and greater consistency. While GFEM shows slightly better accuracy for the Burgers-Huxley equation, its performance was less consistent over time. In contrast, PINN exhibit more reliable and robust performance, highlighting their potential as a cutting-edge approach for solving non-linear PDEs.
<div id='section'>Paperid: <span id='pid'>1850, <a href='https://arxiv.org/pdf/2411.08760.pdf' target='_blank'>https://arxiv.org/pdf/2411.08760.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mustafa KÃ¼tÃ¼k, Hamdullah YÃ¼cel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08760">Energy Dissipation Preserving Physics Informed Neural Network for Allen-Cahn Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates a numerical solution of Allen-Cahn equation with constant and degenerate mobility, with polynomial and logarithmic energy functionals, with deterministic and random initial functions, and with advective term in one, two, and three spatial dimensions, based on the physics-informed neural network (PINN). To improve the learning capacity of the PINN, we incorporate the energy dissipation property of the Allen-Cahn equation as a penalty term into the loss function of the network. To facilitate the learning process of random initials, we employ a continuous analogue of the initial random condition by utilizing the Fourier series expansion. Adaptive methods from traditional numerical analysis are also integrated to enhance the effectiveness of the proposed PINN. Numerical results indicate a consistent decrease in the discrete energy, while also revealing phenomena such as phase separation and metastability.
<div id='section'>Paperid: <span id='pid'>1851, <a href='https://arxiv.org/pdf/2411.07918.pdf' target='_blank'>https://arxiv.org/pdf/2411.07918.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christopher Hahne, Omar Rodriguez-Nunez, ÃlÃ©a Gros, ThÃ©otim Lucas, Ekkehard Hewer, Tatiana Novikova, Theoni Maragkou, Philippe Schucht, Richard McKinley
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.07918">Physically Consistent Image Augmentation for Deep Learning in Mueller Matrix Polarimetry</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mueller matrix polarimetry captures essential information about polarized light interactions with a sample, presenting unique challenges for data augmentation in deep learning due to its distinct structure. While augmentations are an effective and affordable way to enhance dataset diversity and reduce overfitting, standard transformations like rotations and flips do not preserve the polarization properties in Mueller matrix images. To this end, we introduce a versatile simulation framework that applies physically consistent rotations and flips to Mueller matrices, tailored to maintain polarization fidelity. Our experimental results across multiple datasets reveal that conventional augmentations can lead to falsified results when applied to polarimetric data, underscoring the necessity of our physics-based approach. In our experiments, we first compare our polarization-specific augmentations against real-world captures to validate their physical consistency. We then apply these augmentations in a semantic segmentation task, achieving substantial improvements in model generalization and performance. This study underscores the necessity of physics-informed data augmentation for polarimetric imaging in deep learning (DL), paving the way for broader adoption and more robust applications across diverse research in the field. In particular, our framework unlocks the potential of DL models for polarimetric datasets with limited sample sizes. Our code implementation is available at github.com/hahnec/polar_augment.
<div id='section'>Paperid: <span id='pid'>1852, <a href='https://arxiv.org/pdf/2410.22796.pdf' target='_blank'>https://arxiv.org/pdf/2410.22796.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Viggo Moro, Luiz F. O. Chamon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.22796">Solving Differential Equations with Constrained Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>(Partial) differential equations (PDEs) are fundamental tools for describing natural phenomena, making their solution crucial in science and engineering. While traditional methods, such as the finite element method, provide reliable solutions, their accuracy is often tied to the use of computationally intensive fine meshes. Moreover, they do not naturally account for measurements or prior solutions, and any change in the problem parameters requires results to be fully recomputed. Neural network-based approaches, such as physics-informed neural networks and neural operators, offer a mesh-free alternative by directly fitting those models to the PDE solution. They can also integrate prior knowledge and tackle entire families of PDEs by simply aggregating additional training losses. Nevertheless, they are highly sensitive to hyperparameters such as collocation points and the weights associated with each loss. This paper addresses these challenges by developing a science-constrained learning (SCL) framework. It demonstrates that finding a (weak) solution of a PDE is equivalent to solving a constrained learning problem with worst-case losses. This explains the limitations of previous methods that minimize the expected value of aggregated losses. SCL also organically integrates structural constraints (e.g., invariances) and (partial) measurements or known solutions. The resulting constrained learning problems can be tackled using a practical algorithm that yields accurate solutions across a variety of PDEs, neural network architectures, and prior knowledge levels without extensive hyperparameter tuning and sometimes even at a lower computational cost.
<div id='section'>Paperid: <span id='pid'>1853, <a href='https://arxiv.org/pdf/2410.20203.pdf' target='_blank'>https://arxiv.org/pdf/2410.20203.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xutun Wang, Yuchen Zhang, Zidong Li, Haocheng Wen, Bing Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20203">Physics-informed Shadowgraph Network: An End-to-end Density Field Reconstruction Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a novel approach for quantificationally reconstructing density fields from shadowgraph images using physics-informed neural networks
<div id='section'>Paperid: <span id='pid'>1854, <a href='https://arxiv.org/pdf/2410.20186.pdf' target='_blank'>https://arxiv.org/pdf/2410.20186.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiqiao Meng, Ying Zhou, Qinghua Zheng, Bingxu Liao, Mushi Chang, Tianshu Zhang, Abderrahim Djerrad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.20186">SeisGPT: A Physics-Informed Data-Driven Large Model for Real-Time Seismic Response Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting the dynamic responses of building structures under seismic loads is essential for ensuring structural safety and minimizing potential damage. This critical aspect of structural analysis allows engineers to evaluate how structures perform under various loading conditions, facilitating informed design and safety decisions. Traditional methods, which rely on complex finite element models often struggle with balancing computational efficiency and accuracy. To address this challenge, we introduce SeisGPT, a data-driven, large physics-informed model that leverages deep neural networks based on the Generative Pre-trained Transformer (GPT) architecture. SeisGPT is designed to predict, in real-time the dynamic behavior of building structures under seismic forces. Trained on a diverse corpus of seismic data and structural engineering principles, it instantly generates predictive responses, including displacement, acceleration, and inter-story drift, with high accuracy and computational efficiency. Its adaptability across various building typologies and seismic intensities makes this framework a valuable tool for designing robust structures and assessing seismic risk. Through comprehensive validation, this approach exhibits superior performance, offering engineers and researchers a powerful tool for assessing seismic response and informing resilient design strategies. This innovative framework represents a significant advancement in seismic engineering practice, with potential applications in mitigating seismic hazards and enhancing structural resilience.
<div id='section'>Paperid: <span id='pid'>1855, <a href='https://arxiv.org/pdf/2410.14270.pdf' target='_blank'>https://arxiv.org/pdf/2410.14270.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Uttam Suman, Mariya Mamajiwala, Mukul Saxena, Ankit Tyagi, Debasish Roy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14270">FINDER: Stochastic Mirroring of Noisy Quasi-Newton Search and Deep Network Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Our proposal is on a new stochastic optimizer for non-convex and possibly non-smooth objective functions typically defined over large dimensional design spaces. Towards this, we have tried to bridge noise-assisted global search and faster local convergence, the latter being the characteristic feature of a Newton-like search. Our specific scheme -- acronymed FINDER (Filtering Informed Newton-like and Derivative-free Evolutionary Recursion), exploits the nonlinear stochastic filtering equations to arrive at a derivative-free update that has resemblance with the Newton search employing the inverse Hessian of the objective function. Following certain simplifications of the update to enable a linear scaling with dimension and a few other enhancements, we apply FINDER to a range of problems, starting with some IEEE benchmark objective functions to a couple of archetypal data-driven problems in deep networks to certain cases of physics-informed deep networks. The performance of the new method vis-Ã¡-vis the well-known Adam and a few others bears evidence to its promise and potentialities for large dimensional optimization problems of practical interest.
<div id='section'>Paperid: <span id='pid'>1856, <a href='https://arxiv.org/pdf/2410.13295.pdf' target='_blank'>https://arxiv.org/pdf/2410.13295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingda Lu, Zitian Ao, Chao Wang, Sudhakar Prasad, Raymond H. Chan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13295">PiLocNet: Physics-informed neural network on 3D localization with rotating point spread function</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For the 3D localization problem using point spread function (PSF) engineering, we propose a novel enhancement of our previously introduced localization neural network, LocNet. The improved network is a physics-informed neural network (PINN) that we call PiLocNet. Previous works on the localization problem may be categorized separately into model-based optimization and neural network approaches. Our PiLocNet combines the unique strengths of both approaches by incorporating forward-model-based information into the network via a data-fitting loss term that constrains the neural network to yield results that are physically sensible. We additionally incorporate certain regularization terms from the variational method, which further improves the robustness of the network in the presence of image noise, as we show for the Poisson and Gaussian noise models. This framework accords interpretability to the neural network, and the results we obtain show its superiority. Although the paper focuses on the use of single-lobe rotating PSF to encode the full 3D source location, we expect the method to be widely applicable to other PSFs and imaging problems that are constrained by known forward processes.
<div id='section'>Paperid: <span id='pid'>1857, <a href='https://arxiv.org/pdf/2410.06523.pdf' target='_blank'>https://arxiv.org/pdf/2410.06523.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sejin Kim, Kyung Kiu Kim, Yunseok Seo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06523">Phase Diagram from Nonlinear Interaction between Superconducting Order and Density: Toward Data-Based Holographic Superconductor</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We address an inverse problem in modeling holographic superconductors. We focus our research on the critical temperature behavior depicted by experiments. We use a physics-informed neural network method to find a mass function $M(F^2)$, which is necessary to understand phase transition behavior. This mass function describes a nonlinear interaction between superconducting order and charge carrier density. We introduce positional embedding layers to improve the learning process in our algorithm, and the Adam optimization is used to predict the critical temperature data via holographic calculation with appropriate accuracy. Consideration of the positional embedding layers is motivated by the transformer model of natural-language processing in the artificial intelligence (AI) field. We obtain holographic models that reproduce borderlines of the normal and superconducting phases provided by actual data. Our work is the first holographic attempt to match phase transition data quantitatively obtained from experiments. Also, the present work offers a new methodology for data-based holographic models.
<div id='section'>Paperid: <span id='pid'>1858, <a href='https://arxiv.org/pdf/2410.04299.pdf' target='_blank'>https://arxiv.org/pdf/2410.04299.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Caitlin Ho, Andrea Arnold
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04299">Integrating Physics-Informed Deep Learning and Numerical Methods for Robust Dynamics Discovery and Parameter Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Incorporating a priori physics knowledge into machine learning leads to more robust and interpretable algorithms. In this work, we combine deep learning techniques and classic numerical methods for differential equations to solve two challenging problems in dynamical systems theory: dynamics discovery and parameter estimation. Results demonstrate the effectiveness of the proposed approaches on a suite of test problems exhibiting oscillatory and chaotic dynamics. When comparing the performance of various numerical schemes, such as the Runge-Kutta and linear multistep families of methods, we observe promising results in predicting the system dynamics and estimating physical parameters, given appropriate choices of spatial and temporal discretization schemes and numerical method orders.
<div id='section'>Paperid: <span id='pid'>1859, <a href='https://arxiv.org/pdf/2410.04167.pdf' target='_blank'>https://arxiv.org/pdf/2410.04167.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stavros Kassinos, Alessio Alexiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04167">Beyond Language: Applying MLX Transformers to Engineering Physics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformer Neural Networks are driving an explosion of activity and discovery in the field of Large Language Models (LLMs). In contrast, there have been only a few attempts to apply Transformers in engineering physics. Aiming to offer an easy entry point to physics-centric Transformers, we introduce a physics-informed Transformer model for solving the heat conduction problem in a 2D plate with Dirichlet boundary conditions. The model is implemented in the machine learning framework MLX and leverages the unified memory of Apple M-series processors. The use of MLX means that the models can be trained and perform predictions efficiently on personal machines with only modest memory requirements. To train, validate and test the Transformer model we solve the 2D heat conduction problem using central finite differences. Each finite difference solution in these sets is initialized with four random Dirichlet boundary conditions, a uniform but random internal temperature distribution and a randomly selected thermal diffusivity. Validation is performed in-line during training to monitor against over-fitting. The excellent performance of the trained model is demonstrated by predicting the evolution of the temperature field to steady state for the unseen test set of conditions.
<div id='section'>Paperid: <span id='pid'>1860, <a href='https://arxiv.org/pdf/2410.01599.pdf' target='_blank'>https://arxiv.org/pdf/2410.01599.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tirtho S. Saha, Alexander Heinlein, Cordula Reisch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.01599">Towards Model Discovery Using Domain Decomposition and PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We enhance machine learning algorithms for learning model parameters in complex systems represented by ordinary differential equations (ODEs) with domain decomposition methods. The study evaluates the performance of two approaches, namely (vanilla) Physics-Informed Neural Networks (PINNs) and Finite Basis Physics-Informed Neural Networks (FBPINNs), in learning the dynamics of test models with a quasi-stationary longtime behavior. We test the approaches for data sets in different dynamical regions and with varying noise level. As results, we find a better performance for the FBPINN approach compared to the vanilla PINN approach, even in cases with data from only a quasi-stationary time domain with few dynamics.
<div id='section'>Paperid: <span id='pid'>1861, <a href='https://arxiv.org/pdf/2410.00422.pdf' target='_blank'>https://arxiv.org/pdf/2410.00422.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sai Ganga, Ziya Uddin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.00422">Exploring Physics-Informed Neural Networks: From Fundamentals to Applications in Complex Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have emerged as a versatile and widely applicable concept across various science and engineering domains over the past decade. This article offers a comprehensive overview of the fundamentals of PINNs, tracing their evolution, modifications, and various variants. It explores the impact of different parameters on PINNs and the optimization algorithms involved. The review also delves into the theoretical advancements related to the convergence, consistency, and stability of numerical solutions using PINNs, while highlighting the current state of the art. Given their ability to address equations involving complex physics, the article discusses various applications of PINNs, with a particular focus on their utility in computational fluid dynamics problems. Additionally, it identifies current gaps in the research and outlines future directions for the continued development of PINNs.
<div id='section'>Paperid: <span id='pid'>1862, <a href='https://arxiv.org/pdf/2409.19647.pdf' target='_blank'>https://arxiv.org/pdf/2409.19647.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shiming Fang, Kaiyan Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19647">Fine-Tuning Hybrid Physics-Informed Neural Networks for Vehicle Dynamics Model Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate dynamic modeling is critical for autonomous racing vehicles, especially during high-speed and agile maneuvers where precise motion prediction is essential for safety. Traditional parameter estimation methods face limitations such as reliance on initial guesses, labor-intensive fitting procedures, and complex testing setups. On the other hand, purely data-driven machine learning methods struggle to capture inherent physical constraints and typically require large datasets for optimal performance. To address these challenges, this paper introduces the Fine-Tuning Hybrid Dynamics (FTHD) method, which integrates supervised and unsupervised Physics-Informed Neural Networks (PINNs), combining physics-based modeling with data-driven techniques. FTHD fine-tunes a pre-trained Deep Dynamics Model (DDM) using a smaller training dataset, delivering superior performance compared to state-of-the-art methods such as the Deep Pacejka Model (DPM) and outperforming the original DDM. Furthermore, an Extended Kalman Filter (EKF) is embedded within FTHD (EKF-FTHD) to effectively manage noisy real-world data, ensuring accurate denoising while preserving the vehicle's essential physical characteristics. The proposed FTHD framework is validated through scaled simulations using the BayesRace Physics-based Simulator and full-scale real-world experiments from the Indy Autonomous Challenge. Results demonstrate that the hybrid approach significantly improves parameter estimation accuracy, even with reduced data, and outperforms existing models. EKF-FTHD enhances robustness by denoising real-world data while maintaining physical insights, representing a notable advancement in vehicle dynamics modeling for high-speed autonomous racing.
<div id='section'>Paperid: <span id='pid'>1863, <a href='https://arxiv.org/pdf/2409.16008.pdf' target='_blank'>https://arxiv.org/pdf/2409.16008.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Santiago Sanchez-Escalonilla, Samuele Zoboli, Bayu Jayawardhana
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.16008">Robust Neural IDA-PBC: passivity-based stabilization under approximations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we restructure the Neural Interconnection and Damping Assignment - Passivity Based Control (Neural IDA-PBC) design methodology, and we formally analyze its closed-loop properties. Neural IDA-PBC redefines the IDA-PBC design approach as an optimization problem by building on the framework of Physics Informed Neural Networks (PINNs). However, the closed-loop stability and robustness properties under Neural IDA-PBC remain unexplored. To address the issue, we study the behavior of classical IDA-PBC under approximations. Our theoretical analysis allows deriving conditions for practical and asymptotic stability of the desired equilibrium point. Moreover, it extends the Neural IDA-PBC applicability to port-Hamiltonian systems where the matching conditions cannot be solved exactly. Our renewed optimization-based design introduces three significant aspects: i) it involves a novel optimization objective including stability and robustness constraints issued from our theoretical analysis; ii) it employs separate Neural Networks (NNs), which can be structured to reduce the search space to relevant functions; iii) it does not require knowledge about the port-Hamiltonian formulation of the system's model. Our methodology is validated with simulations on three standard benchmarks: a double pendulum, a nonlinear mass-spring-damper and a cartpole. Notably, classical IDA-PBC designs cannot be analytically derived for the latter.
<div id='section'>Paperid: <span id='pid'>1864, <a href='https://arxiv.org/pdf/2409.15872.pdf' target='_blank'>https://arxiv.org/pdf/2409.15872.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabrine Chebbi, Joseph Muthui Wacira, Makram Hamouda, Bubacarr Bah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.15872">Physics-informed neural networks for Timoshenko system with Thermoelasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The main focus of this paper is to analyze the behavior of a numerical solution of the Timoshenko system coupled with Thermoelasticity and incorporating second sound effects. In order to address this target, we employ the Physics-Informed Neural Networks (PINNs) framework to derive an approximate solution for the system. Our investigation delves into the extent to which this approximate solution can accurately capture the asymptotic behavior of the discrete energy, contingent upon the stability number $Ï$. Interestingly, the PINNs overcome the major difficulties encountered while using the standard numerical methods.
<div id='section'>Paperid: <span id='pid'>1865, <a href='https://arxiv.org/pdf/2409.14035.pdf' target='_blank'>https://arxiv.org/pdf/2409.14035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michal Byra, Piotr Jarosik, Piotr Karwat, Ziemowit Klimonda, Marcin Lewandowski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.14035">Implicit Neural Representations for Speed-of-Sound Estimation in Ultrasound</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate estimation of the speed-of-sound (SoS) is important for ultrasound (US) image reconstruction techniques and tissue characterization. Various approaches have been proposed to calculate SoS, ranging from tomography-inspired algorithms like CUTE to convolutional networks, and more recently, physics-informed optimization frameworks based on differentiable beamforming. In this work, we utilize implicit neural representations (INRs) for SoS estimation in US. INRs are a type of neural network architecture that encodes continuous functions, such as images or physical quantities, through the weights of a network. Implicit networks may overcome the current limitations of SoS estimation techniques, which mainly arise from the use of non-adaptable and oversimplified physical models of tissue. Moreover, convolutional networks for SoS estimation, usually trained using simulated data, often fail when applied to real tissues due to out-of-distribution and data-shift issues. In contrast, implicit networks do not require extensive training datasets since each implicit network is optimized for an individual data case. This adaptability makes them suitable for processing US data collected from varied tissues and across different imaging protocols.
  We evaluated the proposed SoS estimation method based on INRs using data collected from a tissue-mimicking phantom containing four cylindrical inclusions, with SoS values ranging from 1480 m/s to 1600 m/s. The inclusions were immersed in a material with an SoS value of 1540 m/s. In experiments, the proposed method achieved strong performance, clearly demonstrating the usefulness of implicit networks for quantitative US applications.
<div id='section'>Paperid: <span id='pid'>1866, <a href='https://arxiv.org/pdf/2409.13241.pdf' target='_blank'>https://arxiv.org/pdf/2409.13241.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Omar LeÃ³n, VÃ­ctor Rivera, Angel VÃ¡zquez-PatiÃ±o, Jacinto Ulloa, Esteban Samaniego
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13241">Exploring energy minimization to model strain localization as a strong discontinuity using Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We explore the possibilities of using energy minimization for the numerical modeling of strain localization in solids as a sharp discontinuity in the displacement field. For this purpose, we consider (regularized) strong discontinuity kinematics in elastoplastic solids. The corresponding mathematical model is discretized using Artificial Neural Networks (ANNs), aiming to predict both the magnitude and location of the displacement jump from energy minimization, $\textit{i.e.}$, within a variational setting. The architecture takes care of the kinematics, while the loss function takes care of the variational statement of the boundary value problem. The main idea behind this approach is to solve both the equilibrium problem and the location of the localization band by means of trainable parameters in the ANN. As a proof of concept, we show through both 1D and 2D numerical examples that the computational modeling of strain localization for elastoplastic solids using energy minimization is feasible.
<div id='section'>Paperid: <span id='pid'>1867, <a href='https://arxiv.org/pdf/2409.12998.pdf' target='_blank'>https://arxiv.org/pdf/2409.12998.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nazanin Ahmadi Daryakenari, Shupeng Wang, George Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.12998">CMINNs: Compartment Model Informed Neural Networks -- Unlocking Drug Dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of pharmacokinetics and pharmacodynamics (PKPD) modeling, which plays a pivotal role in the drug development process, traditional models frequently encounter difficulties in fully encapsulating the complexities of drug absorption, distribution, and their impact on targets. Although multi-compartment models are frequently utilized to elucidate intricate drug dynamics, they can also be overly complex. To generalize modeling while maintaining simplicity, we propose an innovative approach that enhances PK and integrated PK-PD modeling by incorporating fractional calculus or time-varying parameter(s), combined with constant or piecewise constant parameters. These approaches effectively model anomalous diffusion, thereby capturing drug trapping and escape rates in heterogeneous tissues, which is a prevalent phenomenon in drug dynamics. Furthermore, this method provides insight into the dynamics of drug in cancer in multi-dose administrations. Our methodology employs a Physics-Informed Neural Network (PINN) and fractional Physics-Informed Neural Networks (fPINNs), integrating ordinary differential equations (ODEs) with integer/fractional derivative order from compartmental modeling with neural networks. This integration optimizes parameter estimation for variables that are time-variant, constant, piecewise constant, or related to the fractional derivative order. The results demonstrate that this methodology offers a robust framework that not only markedly enhances the model's depiction of drug absorption rates and distributed delayed responses but also unlocks different drug-effect dynamics, providing new insights into absorption rates, anomalous diffusion, drug resistance, peristance and pharmacokinetic tolerance, all within a system of just two (fractional) ODEs with explainable results.
<div id='section'>Paperid: <span id='pid'>1868, <a href='https://arxiv.org/pdf/2409.11847.pdf' target='_blank'>https://arxiv.org/pdf/2409.11847.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Himanshu Pandey, Anshima Singh, Ratikanta Behera
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11847">An efficient wavelet-based physics-informed neural networks for singularly perturbed problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are a class of deep learning models that utilize physics in the form of differential equations to address complex problems, including ones that may involve limited data availability. However, tackling solutions of differential equations with rapid oscillations, steep gradients, or singular behavior becomes challenging for PINNs. Considering these challenges, we designed an efficient wavelet-based PINNs (W-PINNs) model to address this class of differential equations. Here, we represent the solution in wavelet space using a family of smooth-compactly supported wavelets. This framework represents the solution of a differential equation with significantly fewer degrees of freedom while still retaining the dynamics of complex physical phenomena. The architecture allows the training process to search for a solution within the wavelet space, making the process faster and more accurate. Further, the proposed model does not rely on automatic differentiations for derivatives involved in differential equations and does not require any prior information regarding the behavior of the solution, such as the location of abrupt features. Thus, through a strategic fusion of wavelets with PINNs, W-PINNs excel at capturing localized nonlinear information, making them well-suited for problems showing abrupt behavior in certain regions, such as singularly perturbed and multiscale problems. The efficiency and accuracy of the proposed neural network model are demonstrated in various 1D and 2D test problems, i.e., the FitzHugh-Nagumo (FHN) model, the Helmholtz equation, the Maxwell's equation, lid-driven cavity flow, and the Allen-Cahn equation, along with other highly singularly perturbed nonlinear differential equations. The proposed model significantly improves with traditional PINNs, recently developed wavelet-based PINNs, and other state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>1869, <a href='https://arxiv.org/pdf/2409.11138.pdf' target='_blank'>https://arxiv.org/pdf/2409.11138.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harsh Choudhary, Chandan Gupta, Vyacheslav kungrutsev, Melvin Leok, Georgios Korpas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11138">Learning Generalized Hamiltonians using fully Symplectic Mappings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many important physical systems can be described as the evolution of a Hamiltonian system, which has the important property of being conservative, that is, energy is conserved throughout the evolution. Physics Informed Neural Networks and in particular Hamiltonian Neural Networks have emerged as a mechanism to incorporate structural inductive bias into the NN model. By ensuring physical invariances are conserved, the models exhibit significantly better sample complexity and out-of-distribution accuracy than standard NNs. Learning the Hamiltonian as a function of its canonical variables, typically position and velocity, from sample observations of the system thus becomes a critical task in system identification and long-term prediction of system behavior. However, to truly preserve the long-run physical conservation properties of Hamiltonian systems, one must use symplectic integrators for a forward pass of the system's simulation. While symplectic schemes have been used in the literature, they are thus far limited to situations when they reduce to explicit algorithms, which include the case of separable Hamiltonians or augmented non-separable Hamiltonians. We extend it to generalized non-separable Hamiltonians, and noting the self-adjoint property of symplectic integrators, we bypass computationally intensive backpropagation through an ODE solver. We show that the method is robust to noise and provides a good approximation of the system Hamiltonian when the state variables are sampled from a noisy observation. In the numerical results, we show the performance of the method concerning Hamiltonian reconstruction and conservation, indicating its particular advantage for non-separable systems.
<div id='section'>Paperid: <span id='pid'>1870, <a href='https://arxiv.org/pdf/2409.10910.pdf' target='_blank'>https://arxiv.org/pdf/2409.10910.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shivprasad Kathane, Shyamprasad Karagadde
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10910">A Physics Informed Neural Network (PINN) Methodology for Coupled Moving Boundary PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Network (PINN) is a novel multi-task learning framework useful for solving physical problems modeled using differential equations (DEs) by integrating the knowledge of physics and known constraints into the components of deep learning. A large class of physical problems in materials science and mechanics involve moving boundaries, where interface flux balance conditions are to be satisfied while solving DEs. Examples of such systems include free surface flows, shock propagation, solidification of pure and alloy systems etc. While recent research works have explored applicability of PINNs for an uncoupled system (such as solidification of pure system), the present work reports a PINN-based approach to solve coupled systems involving multiple governing parameters (energy and species, along with multiple interface balance equations). This methodology employs an architecture consisting of a separate network for each variable with a separate treatment of each phase, a training strategy which alternates between temporal learning and adaptive loss weighting, and a scheme which progressively reduces the optimisation space. While solving the benchmark problem of binary alloy solidification, it is distinctly successful at capturing the complex composition profile, which has a characteristic discontinuity at the interface and the resulting predictions align well with the analytical solutions. The procedure can be generalised for solving other transient multiphysics problems especially in the low-data regime and in cases where measurements can reveal new physics.
<div id='section'>Paperid: <span id='pid'>1871, <a href='https://arxiv.org/pdf/2409.10777.pdf' target='_blank'>https://arxiv.org/pdf/2409.10777.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoran Cheng, Sen Na
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10777">Physics-Informed Neural Networks with Trust-Region Sequential Quadratic Programming</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) represent a significant advancement in Scientific Machine Learning (SciML), which integrate physical domain knowledge into an empirical loss function as soft constraints and apply existing machine learning methods to train the model. However, recent research has noted that PINNs may fail to learn relatively complex Partial Differential Equations (PDEs). This paper addresses the failure modes of PINNs by introducing a novel, hard-constrained deep learning method -- trust-region Sequential Quadratic Programming (trSQP-PINN). In contrast to directly training the penalized soft-constrained loss as in PINNs, our method performs a linear-quadratic approximation of the hard-constrained loss, while leveraging the soft-constrained loss to adaptively adjust the trust-region radius. We only trust our model approximations and make updates within the trust region, and such an updating manner can overcome the ill-conditioning issue of PINNs. We also address the computational bottleneck of second-order SQP methods by employing quasi-Newton updates for second-order information, and importantly, we introduce a simple pretraining step to further enhance training efficiency of our method. We demonstrate the effectiveness of trSQP-PINN through extensive experiments. Compared to existing hard-constrained methods for PINNs, such as penalty methods and augmented Lagrangian methods, trSQP-PINN significantly improves the accuracy of the learned PDE solutions, achieving up to 1-3 orders of magnitude lower errors. Additionally, our pretraining step is generally effective for other hard-constrained methods, and experiments have shown the robustness of our method against both problem-specific parameters and algorithm tuning parameters.
<div id='section'>Paperid: <span id='pid'>1872, <a href='https://arxiv.org/pdf/2409.10388.pdf' target='_blank'>https://arxiv.org/pdf/2409.10388.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahyar Jahani-nasab, Mohamad Ali Bijarchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10388">Revising the Structure of Recurrent Neural Networks to Eliminate Numerical Derivatives in Forming Physics Informed Loss Terms with Respect to Time</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving unsteady partial differential equations (PDEs) using recurrent neural networks (RNNs) typically requires numerical derivatives between each block of the RNN to form the physics informed loss function. However, this introduces the complexities of numerical derivatives into the training process of these models. In this study, we propose modifying the structure of the traditional RNN to enable the prediction of each block over a time interval, making it possible to calculate the derivative of the output with respect to time using the backpropagation algorithm. To achieve this, the time intervals of these blocks are overlapped, defining a mutual loss function between them. Additionally, the employment of conditional hidden states enables us to achieve a unique solution for each block. The forget factor is utilized to control the influence of the conditional hidden state on the prediction of the subsequent block. This new model, termed the Mutual Interval RNN (MI-RNN), is applied to solve three different benchmarks: the Burgers equation, unsteady heat conduction in an irregular domain, and the Green vortex problem. Our results demonstrate that MI-RNN can find the exact solution more accurately compared to existing RNN models. For instance, in the second problem, MI-RNN achieved one order of magnitude less relative error compared to the RNN model with numerical derivatives.
<div id='section'>Paperid: <span id='pid'>1873, <a href='https://arxiv.org/pdf/2409.08832.pdf' target='_blank'>https://arxiv.org/pdf/2409.08832.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahman Ejaz, Varchas Gopalaswamy, Riccardo Betti, Aarne Lees, Christopher Kanan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08832">Can Kans (re)discover predictive models for Direct-Drive Laser Fusion?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The domain of laser fusion presents a unique and challenging predictive modeling application landscape for machine learning methods due to high problem complexity and limited training data. Data-driven approaches utilizing prescribed functional forms, inductive biases and physics-informed learning (PIL) schemes have been successful in the past for achieving desired generalization ability and model interpretation that aligns with physics expectations. In complex multi-physics application domains, however, it is not always obvious how architectural biases or discriminative penalties can be formulated. In this work, focusing on nuclear fusion energy using high powered lasers, we present the use of Kolmogorov-Arnold Networks (KANs) as an alternative to PIL for developing a new type of data-driven predictive model which is able to achieve high prediction accuracy and physics interpretability. A KAN based model, a MLP with PIL, and a baseline MLP model are compared in generalization ability and interpretation with a domain expert-derived symbolic regression model. Through empirical studies in this high physics complexity domain, we show that KANs can potentially provide benefits when developing predictive models for data-starved physics applications.
<div id='section'>Paperid: <span id='pid'>1874, <a href='https://arxiv.org/pdf/2409.08063.pdf' target='_blank'>https://arxiv.org/pdf/2409.08063.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabio Musco, Andrea Barth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08063">Deep learning methods for stochastic Galerkin approximations of elliptic random PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work considers stochastic Galerkin approximations of linear elliptic partial differential equations (PDEs) with stochastic forcing terms and stochastic diffusion coefficients, that cannot be bounded uniformly away from zero and infinity. A traditional numerical method for solving the resulting high-dimensional coupled system of PDEs is replaced by deep learning techniques. In order to achieve this, physics-informed neural networks (PINNs), which typically operate on the strong residual of the PDE and can therefore be applied in a wide range of settings, are considered. As a second approach, the Deep Ritz method, which is a neural network that minimizes the Ritz energy functional to find the weak solution, is employed. While the second approach only works in special cases, it overcomes the necessity of testing in variational problems while maintaining mathematical rigor and ensuring the existence of a unique solution. Furthermore, the residual is of a lower differentiation order, reducing the training cost considerably. The efficiency of the method is demonstrated on several model problems.
<div id='section'>Paperid: <span id='pid'>1875, <a href='https://arxiv.org/pdf/2409.07671.pdf' target='_blank'>https://arxiv.org/pdf/2409.07671.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiajing Guan, Howard Elman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.07671">Transformed Physics-Informed Neural Networks for The Convection-Diffusion Equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Singularly perturbed problems are known to have solutions with steep boundary layers that are hard to resolve numerically. Traditional numerical methods, such as Finite Difference Methods (FDMs), require a refined mesh to obtain stable and accurate solutions. As Physics-Informed Neural Networks (PINNs) have been shown to successfully approximate solutions to differential equations from various fields, it is natural to examine their performance on singularly perturbed problems. The convection-diffusion equation is a representative example of such a class of problems, and we consider the use of PINNs to produce numerical solutions of this equation. We study two ways to use PINNS: as a method for correcting oscillatory discrete solutions obtained using FDMs, and as a method for modifying reduced solutions of unperturbed problems. For both methods, we also examine the use of input transformation to enhance accuracy, and we explain the behavior of input transformations analytically, with the help of neural tangent kernels.
<div id='section'>Paperid: <span id='pid'>1876, <a href='https://arxiv.org/pdf/2409.07028.pdf' target='_blank'>https://arxiv.org/pdf/2409.07028.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>John Mango, Ronald Katende
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.07028">Adaptive Error-Bounded Hierarchical Matrices for Efficient Neural Network Compression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a dynamic, error-bounded hierarchical matrix (H-matrix) compression method tailored for Physics-Informed Neural Networks (PINNs). The proposed approach reduces the computational complexity and memory demands of large-scale physics-based models while preserving the essential properties of the Neural Tangent Kernel (NTK). By adaptively refining hierarchical matrix approximations based on local error estimates, our method ensures efficient training and robust model performance. Empirical results demonstrate that this technique outperforms traditional compression methods, such as Singular Value Decomposition (SVD), pruning, and quantization, by maintaining high accuracy and improving generalization capabilities. Additionally, the dynamic H-matrix method enhances inference speed, making it suitable for real-time applications. This approach offers a scalable and efficient solution for deploying PINNs in complex scientific and engineering domains, bridging the gap between computational feasibility and real-world applicability.
<div id='section'>Paperid: <span id='pid'>1877, <a href='https://arxiv.org/pdf/2409.01914.pdf' target='_blank'>https://arxiv.org/pdf/2409.01914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Filippo Aglietti, Francesco Della Santa, Andrea Piano, Virginia Aglietti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01914">GradINN: Gradient Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose Gradient Informed Neural Networks (GradINNs), a methodology inspired by Physics Informed Neural Networks (PINNs) that can be used to efficiently approximate a wide range of physical systems for which the underlying governing equations are completely unknown or cannot be defined, a condition that is often met in complex engineering problems. GradINNs leverage prior beliefs about a system's gradient to constrain the predicted function's gradient across all input dimensions. This is achieved using two neural networks: one modeling the target function and an auxiliary network expressing prior beliefs, e.g., smoothness. A customized loss function enables training the first network while enforcing gradient constraints derived from the auxiliary network. We demonstrate the advantages of GradINNs, particularly in low-data regimes, on diverse problems spanning non time-dependent systems (Friedman function, Stokes Flow) and time-dependent systems (Lotka-Volterra, Burger's equation). Experimental results showcase strong performance compared to standard neural networks and PINN-like approaches across all tested scenarios.
<div id='section'>Paperid: <span id='pid'>1878, <a href='https://arxiv.org/pdf/2409.01744.pdf' target='_blank'>https://arxiv.org/pdf/2409.01744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jithu J Athalathil, Bhargav Vaidya, Sayan Kundu, Vishal Upendran, Mark C. M. Cheung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01744">Surface Flux Transport Modeling using Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Studying the magnetic field properties on the solar surface is crucial for understanding the solar and heliospheric activities, which in turn shape space weather in the solar system. Surface Flux Transport (SFT) modeling helps us to simulate and analyse the transport and evolution of magnetic flux on the solar surface, providing valuable insights into the mechanisms responsible for solar activity. In this work, we demonstrate the use of machine learning techniques in solving magnetic flux transport, making it accurate. We have developed a novel Physics-Informed Neural Networks (PINN)-based model to study the evolution of Bipolar Magnetic Regions (BMRs) using SFT in one-dimensional azimuthally averaged and also in two-dimensions. We demonstrate the efficiency and computational feasibility of our PINN-based model by comparing its performance and accuracy with that of a numerical model implemented using the Runge-Kutta Implicit-Explicit (RK-IMEX) scheme. The mesh-independent PINN method can be used to reproduce the observed polar magnetic field with better flux conservation. This advancement is important for accurately reproducing observed polar magnetic fields, thereby providing insights into the strength of future solar cycles. This work paves the way for more efficient and accurate simulations of solar magnetic flux transport and showcases the applicability of PINN in solving advection-diffusion equations with a particular focus on heliophysics.
<div id='section'>Paperid: <span id='pid'>1879, <a href='https://arxiv.org/pdf/2409.00956.pdf' target='_blank'>https://arxiv.org/pdf/2409.00956.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Boda Li, Shichao Zhou, Qinwei Ma, Shaopeng Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.00956">Physics-Informed Neural Network Based Digital Image Correlation Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Digital Image Correlation (DIC) is a key technique in experimental mechanics for full-field deformation measurement, traditionally relying on subset matching to determine displacement fields. However, selecting optimal parameters like shape functions and subset size can be challenging in non-uniform deformation scenarios. Recent deep learning-based DIC approaches, both supervised and unsupervised, use neural networks to map speckle images to deformation fields, offering precise measurements without manual tuning. However, these methods require complex network architectures to extract speckle image features, which does not guarantee solution accuracy This paper introduces PINN-DIC, a novel DIC method based on Physics-Informed Neural Networks (PINNs). Unlike traditional approaches, PINN-DIC uses a simple fully connected neural network that takes the coordinate domain as input and outputs the displacement field. By integrating the DIC governing equation into the loss function, PINN-DIC directly extracts the displacement field from reference and deformed speckle images through iterative optimization. Evaluations on simulated and real experiments demonstrate that PINN-DIC maintains the accuracy of deep learning-based DIC in non-uniform fields while offering three distinct advantages: 1) enhanced precision with a simpler network by directly fitting the displacement field from coordinates, 2) effective handling of irregular boundary displacement fields with minimal parameter adjustments, and 3) easy integration with other neural network-based mechanical analysis methods for comprehensive DIC result analysis.
<div id='section'>Paperid: <span id='pid'>1880, <a href='https://arxiv.org/pdf/2409.00651.pdf' target='_blank'>https://arxiv.org/pdf/2409.00651.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lujie Yin, Xing Lv
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.00651">Adapting Physics-Informed Neural Networks for Bifurcation Detection in Ecological Migration Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we explore the application of Physics-Informed Neural Networks (PINNs) to the analysis of bifurcation phenomena in ecological migration models. By integrating the fundamental principles of diffusion-advection-reaction equations with deep learning techniques, we address the complexities of species migration dynamics, particularly focusing on the detection and analysis of Hopf bifurcations. Traditional numerical methods for solving partial differential equations (PDEs) often involve intricate calculations and extensive computational resources, which can be restrictive in high-dimensional problems. In contrast, PINNs offer a more flexible and efficient alternative, bypassing the need for grid discretization and allowing for mesh-free solutions. Our approach leverages the DeepXDE framework, which enhances the computational efficiency and applicability of PINNs in solving high-dimensional PDEs. We validate our results against conventional methods and demonstrate that PINNs not only provide accurate bifurcation predictions but also offer deeper insights into the underlying dynamics of diffusion processes. Despite these advantages, the study also identifies challenges such as the high computational costs and the sensitivity of PINN performance to network architecture and hyperparameter settings. Future work will focus on optimizing these algorithms and expanding their application to other complex systems involving bifurcations. The findings from this research have significant implications for the modeling and analysis of ecological systems, providing a powerful tool for predicting and understanding complex dynamical behaviors.
<div id='section'>Paperid: <span id='pid'>1881, <a href='https://arxiv.org/pdf/2408.17271.pdf' target='_blank'>https://arxiv.org/pdf/2408.17271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander New, Marisel VillafaÃ±e-Delgado, Charles Shugert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.17271">Equation identification for fluid flows via physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific machine learning (SciML) methods such as physics-informed neural networks (PINNs) are used to estimate parameters of interest from governing equations and small quantities of data. However, there has been little work in assessing how well PINNs perform for inverse problems across wide ranges of governing equations across the mathematical sciences. We present a new and challenging benchmark problem for inverse PINNs based on a parametric sweep of the 2D Burgers' equation with rotational flow. We show that a novel strategy that alternates between first- and second-order optimization proves superior to typical first-order strategies for estimating parameters. In addition, we propose a novel data-driven method to characterize PINN effectiveness in the inverse setting. PINNs' physics-informed regularization enables them to leverage small quantities of data more efficiently than the data-driven baseline. However, both PINNs and the baseline can fail to recover parameters for highly inviscid flows, motivating the need for further development of PINN methods.
<div id='section'>Paperid: <span id='pid'>1882, <a href='https://arxiv.org/pdf/2408.16969.pdf' target='_blank'>https://arxiv.org/pdf/2408.16969.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanwen Bi, Thushara D. Abhayapala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16969">Point Neuron Learning: A New Physics-Informed Neural Network Architecture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning and neural networks have advanced numerous research domains, but challenges such as large training data requirements and inconsistent model performance hinder their application in certain scientific problems. To overcome these challenges, researchers have investigated integrating physics principles into machine learning models, mainly through: (i) physics-guided loss functions, generally termed as physics-informed neural networks, and (ii) physics-guided architectural design. While both approaches have demonstrated success across multiple scientific disciplines, they have limitations including being trapped to a local minimum, poor interpretability, and restricted generalizability. This paper proposes a new physics-informed neural network (PINN) architecture that combines the strengths of both approaches by embedding the fundamental solution of the wave equation into the network architecture, enabling the learned model to strictly satisfy the wave equation. The proposed point neuron learning method can model an arbitrary sound field based on microphone observations without any dataset. Compared to other PINN methods, our approach directly processes complex numbers and offers better interpretability and generalizability. We evaluate the versatility of the proposed architecture by a sound field reconstruction problem in a reverberant environment. Results indicate that the point neuron method outperforms two competing methods and can efficiently handle noisy environments with sparse microphone observations.
<div id='section'>Paperid: <span id='pid'>1883, <a href='https://arxiv.org/pdf/2408.16626.pdf' target='_blank'>https://arxiv.org/pdf/2408.16626.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yankun Hong, Harshit Bansal, Karen Veroy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16626">A Score-based Generative Solver for PDE-constrained Inverse Problems with Complex Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the field of inverse estimation for systems modeled by partial differential equations (PDEs), challenges arise when estimating high- (or even infinite-) dimensional parameters. Typically, the ill-posed nature of such problems necessitates leveraging prior information to achieve well-posedness. In most existing inverse solvers, the prior distribution is assumed to be of either Gaussian or Laplace form which, in many practical scenarios, is an oversimplification. In case the prior is complex and the likelihood model is computationally expensive (e.g., due to expensive forward models), drawing the sample from such posteriors can be computationally intractable, especially when the unknown parameter is high-dimensional. In this work, to sample efficiently, we propose a score-based diffusion model, which combines a score-based generative sampling tool with a noising and denoising process driven by stochastic differential equations. This tool is used for iterative sample generation in accordance with the posterior distribution, while simultaneously learning and leveraging the underlying information and constraints inherent in the given complex prior. A time-varying time schedule is proposed to adapt the method for posterior sampling. To expedite the simulation of non-parameterized PDEs and enhance the generalization capacity, we introduce a physics-informed convolutional neural network (CNN) surrogate for the forward model. Finally, numerical experiments, including a hyper-elastic problem and a multi-scale mechanics problem, demonstrate the efficacy of the proposed approach. In particular, the score-based diffusion model, coupled with the physics-informed CNN surrogate, effectively learns geometrical features from provided prior samples, yielding better inverse estimation results compared to the state-of-the-art techniques.
<div id='section'>Paperid: <span id='pid'>1884, <a href='https://arxiv.org/pdf/2408.14502.pdf' target='_blank'>https://arxiv.org/pdf/2408.14502.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sam Varghese, Rahul Anand, Gaurav Paliwal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14502">Physics-Informed Neural Network for Concrete Manufacturing Process Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Concrete manufacturing projects are one of the most common ones for consulting agencies. Because of the highly non-linear dependency of input materials like ash, water, cement, superplastic, etc; with the resultant strength of concrete, it gets difficult for machine learning models to successfully capture this relation and perform cost optimizations. This paper highlights how PINNs (Physics Informed Neural Networks) can be useful in the given situation. This state-of-the-art model shall also get compared with traditional models like Linear Regression, Random Forest, Gradient Boosting, and Deep Neural Network. Results of the research highlights how well PINNs performed even with reduced dataset, thus resolving one of the biggest issues of limited data availability for ML models. On an average, PINN got the loss value reduced by 26.3% even with 40% lesser data compared to the Deep Neural Network. In addition to predicting strength of the concrete given the quantity of raw materials, the paper also highlights the use of heuristic optimization method like Particle Swarm Optimization (PSO) in predicting quantity of raw materials required to manufacture concrete of given strength with least cost.
<div id='section'>Paperid: <span id='pid'>1885, <a href='https://arxiv.org/pdf/2408.14407.pdf' target='_blank'>https://arxiv.org/pdf/2408.14407.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Benjamin D. Shaffer, Jeremy R. Vorenberg, M. Ani Hsieh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14407">Spectrally Informed Learning of Fluid Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and efficient fluid flow models are essential for applications relating to many physical phenomena including geophysical, aerodynamic, and biological systems. While these flows may exhibit rich and multiscale dynamics, in many cases underlying low-rank structures exist which describe the bulk of the motion. These structures tend to be spatially large and temporally slow, and may contain most of the energy in a given flow. The extraction and parsimonious representation of these low-rank dynamics from high-dimensional data is a key challenge. Inspired by the success of physics-informed machine learning methods, we propose a spectrally-informed approach to extract low-rank models of fluid flows by leveraging known spectral properties in the learning process. We incorporate this knowledge by imposing regularizations on the learned dynamics, which bias the training process towards learning low-frequency structures with corresponding higher power. We demonstrate the effectiveness of this method to improve prediction and produce learned models which better match the underlying spectral properties of prototypical fluid flows.
<div id='section'>Paperid: <span id='pid'>1886, <a href='https://arxiv.org/pdf/2408.11485.pdf' target='_blank'>https://arxiv.org/pdf/2408.11485.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leila Taghizadeh, Ansgar JÃ¼ngel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11485">Bayesian inversion for the identification of the doping profile in unipolar semiconductor devices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A rigorous Bayesian formulation of the inverse doping profile problem in infinite dimensions for a stationary linearized unipolar drift-diffusion model for semiconductor devices is given. The goal is to estimate the posterior probability distribution of the doping profile and to compute its posterior mean. This allows for the reconstruction of the doping profile from voltage-current measurements. The well-posedness of the Bayesian inverse problem is shown by proving boundedness and continuity properties of the semiconductor model with respect to the unknown parameter. A preconditioned Crank-Nicolson Markov chain Monte-Carlo method for the Bayesian estimation of the doping profile, using a physics-informed prior model, is proposed. The numerical results for a two-dimensional diode illustrate the efficiency of the proposed approach.
<div id='section'>Paperid: <span id='pid'>1887, <a href='https://arxiv.org/pdf/2408.11077.pdf' target='_blank'>https://arxiv.org/pdf/2408.11077.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kai-liang Lu, Yu-meng Su, Zhuo Bi, Cheng Qiu, Wen-jun Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11077">Characteristic Performance Study on Solving Oscillator ODEs via Soft-constrained Physics-informed Neural Network with Small Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper compared physics-informed neural network (PINN), conventional neural network (NN) and traditional numerical discretization methods on solving differential equations (DEs) through literature investigation and experimental validation. We focused on the soft-constrained PINN approach and formalized its mathematical framework and computational flow for solving Ordinary DEs and Partial DEs (ODEs/PDEs). The working mechanism and its accuracy and efficiency were experimentally verified by solving typical linear and non-linear oscillator ODEs. We demonstrate that the DeepXDE-based implementation of PINN is not only light code and efficient in training, but also flexible across CPU/GPU platforms. PINN greatly reduces the need for labeled data: when the nonlinearity of the ODE is weak, a very small amount of supervised training data plus a few unsupervised collocation points are sufficient to predict the solution; in the minimalist case, only one or two training points (with initial values) are needed for first- or second-order ODEs, respectively. We also find that, with the aid of collocation points and the use of physical information, PINN has the ability to extrapolate data outside the time domain of the training set, and especially is robust to noisy data, thus with enhanced generalization capabilities. Training is accelerated when the gains obtained along with the reduction in the amount of data outweigh the delay caused by the increase in the loss function terms. The soft-constrained PINN can easily impose a physical law (e.g., conservation of energy) constraint by adding a regularization term to the total loss function, thus improving the solution performance to ODEs that obey this physical law. Furthermore, PINN can also be used for stiff ODEs, PDEs, and other types of DEs, and is becoming a favorable catalyst for the era of Digital Twins.
<div id='section'>Paperid: <span id='pid'>1888, <a href='https://arxiv.org/pdf/2408.10011.pdf' target='_blank'>https://arxiv.org/pdf/2408.10011.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jason Matthews, Alex Bihlo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.10011">PinnDE: Physics-Informed Neural Networks for Solving Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years the study of deep learning for solving differential equations has grown substantially. The use of physics-informed neural networks (PINNs) and deep operator networks (DeepONets) have emerged as two of the most useful approaches in approximating differential equation solutions using machine learning. Here, we introduce PinnDE, an open-source Python library for solving differential equations with both PINNs and DeepONets. We give a brief review of both PINNs and DeepONets, introduce PinnDE along with the structure and usage of the package, and present worked examples to show PinnDE's effectiveness in approximating solutions of systems of differential equations with both PINNs and DeepONets.
<div id='section'>Paperid: <span id='pid'>1889, <a href='https://arxiv.org/pdf/2408.05172.pdf' target='_blank'>https://arxiv.org/pdf/2408.05172.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Josef DanÄk, Jan PospÃ­Å¡il
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.05172">Challenges in automatic differentiation and numerical integration in physics-informed neural networks modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we numerically examine the precision challenges that emerge in automatic differentiation and numerical integration in various tasks now tackled by physics-informed neural networks (PINNs). Specifically, we illustrate how ill-posed problems or inaccurately computed functions can cause serious precision issues in differentiation and integration. A major difficulty lies in detecting these problems. A simple large-scale view of the function or good-looking loss functions or convergence results may not reveal any potential errors, and the resulting outcomes are often mistakenly considered correct. To address this, it is critical to determine whether standard double-precision arithmetic suffices or if higher precision is necessary. Three problematic use-cases for solving differential equations using PINNs are analysed in detail. For the case requiring numerical integration, we also evaluate several numerical quadrature methods and suggest particular numerical analysis steps to choose the most suitable method.
<div id='section'>Paperid: <span id='pid'>1890, <a href='https://arxiv.org/pdf/2408.04690.pdf' target='_blank'>https://arxiv.org/pdf/2408.04690.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Milad Panahi, Giovanni Michele Porta, Monica Riva, Alberto Guadagnini
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.04690">Modelling parametric uncertainty in PDEs models via Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We provide an approach enabling one to employ physics-informed neural networks (PINNs) for uncertainty quantification. Our approach is applicable to systems where observations are scarce (or even lacking), these being typical situations associated with subsurface water bodies. Our novel physics-informed neural network under uncertainty (PINN-UU) integrates the space-time domain across which processes take place and uncertain parameter spaces within a unique computational domain. PINN-UU is then trained to satisfy the relevant physical principles (e.g., mass conservation) in the defined input domain. We employ a stage training approach via transfer learning to accommodate high-dimensional solution spaces. We demonstrate the effectiveness of PINN-UU in a scenario associated with reactive transport in porous media, showcasing its reliability, efficiency, and applicability to sensitivity analysis. PINN-UU emerges as a promising tool for robust uncertainty quantification, with broad applicability to groundwater systems. As such, it can be considered as a valuable alternative to traditional methods such as multi-realization Monte Carlo simulations based on direct solvers or black-box surrogate models.
<div id='section'>Paperid: <span id='pid'>1891, <a href='https://arxiv.org/pdf/2408.00084.pdf' target='_blank'>https://arxiv.org/pdf/2408.00084.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David DahlbÃ¼dding, Karan Molaverdikhani, Barbara Ercolano, Tommaso Grassi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.00084">Approximating Rayleigh Scattering in Exoplanetary Atmospheres using Physics-informed Neural Networks (PINNs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This research introduces an innovative application of physics-informed neural networks (PINNs) to tackle the intricate challenges of radiative transfer (RT) modeling in exoplanetary atmospheres, with a special focus on efficiently handling scattering phenomena. Traditional RT models often simplify scattering as absorption, leading to inaccuracies. Our approach utilizes PINNs, noted for their ability to incorporate the governing differential equations of RT directly into their loss function, thus offering a more precise yet potentially fast modeling technique. The core of our method involves the development of a parameterized PINN tailored for a modified RT equation, enhancing its adaptability to various atmospheric scenarios. We focus on RT in transiting exoplanet atmospheres using a simplified 1D isothermal model with pressure-dependent coefficients for absorption and Rayleigh scattering. In scenarios of pure absorption, the PINN demonstrates its effectiveness in predicting transmission spectra for diverse absorption profiles. For Rayleigh scattering, the network successfully computes the RT equation, addressing both direct and diffuse stellar light components. While our preliminary results with simplified models are promising, indicating the potential of PINNs in improving RT calculations, we acknowledge the errors stemming from our approximations as well as the challenges in applying this technique to more complex atmospheric conditions. Specifically, extending our approach to atmospheres with intricate temperature-pressure profiles and varying scattering properties, such as those introduced by clouds and hazes, remains a significant area for future development.
<div id='section'>Paperid: <span id='pid'>1892, <a href='https://arxiv.org/pdf/2407.20669.pdf' target='_blank'>https://arxiv.org/pdf/2407.20669.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lorenzo Brevi, Antonio Mandarino, Enrico Prati
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.20669">A Tutorial on the Use of Physics-Informed Neural Networks to Compute the Spectrum of Quantum Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantum many-body systems are of great interest for many research areas, including physics, biology and chemistry. However, their simulation is extremely challenging, due to the exponential growth of the Hilbert space with the system size, making it exceedingly difficult to parameterize the wave functions of large systems by using exact methods. Neural networks and machine learning in general are a way to face this challenge. For instance, methods like Tensor networks and Neural Quantum States are being investigated as promising tools to obtain the wave function of a quantum mechanical system. In this tutorial, we focus on a particularly promising class of deep learning algorithms. We explain how to construct a Physics-Informed Neural Network (PINN) able to solve the SchrÃ¶dinger equation for a given potential, by finding its eigenvalues and eigenfunctions. This technique is unsupervised, and utilizes a novel computational method in a manner that is barely explored. PINNs are a deep learning method that exploits Automatic Differentiation to solve Integro-Differential Equations in a mesh-free way. We show how to find both the ground and the excited states. The method discovers the states progressively by starting from the ground state. We explain how to introduce inductive biases in the loss to exploit further knowledge of the physical system. Such additional constraints allow for a faster and more accurate convergence. This technique can then be enhanced by a smart choice of collocation points in order to take advantage of the mesh-free nature of the PINN. The methods are made explicit by applying them to the infinite potential well and the particle in a ring, a challenging problem to be learned by an Artificial Intelligence agent due to the presence of complex-valued eigenfunctions and degenerate states.
<div id='section'>Paperid: <span id='pid'>1893, <a href='https://arxiv.org/pdf/2407.20155.pdf' target='_blank'>https://arxiv.org/pdf/2407.20155.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaopei Jiao, Fansheng Xiong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.20155">GsPINN: A novel fast Green kernel solver based on symmetric Physics-Informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ever since deep learning was introduced in the calculation of partial differential equation (PDE), there has been a lot of interests on real time response of system where the kernel function plays an important role. As a popular tool in recent years, physics-informed neural networks (PINNs) was proposed to perform a mesh-free, semi-supervised learning with high flexibility. This paper explores the integration of Lie symmetry groups with deep learning techniques to enhance the numerical solutions of fundamental solution in PDE. We propose a novel approach that combines the strengths of PINN and Lie group theory to address the computational inefficiencies in traditional methods. By incorporating the linearized symmetric condition (LSC) derived from Lie symmetries into PINNs, we introduce a new type of residual loss with lower order of derivative needed to calculate. This integration allows for significant reductions in computational costs and improvements in solution precision. Numerical simulation shows that our method can achieve up to a 50\% reduction in training time while maintaining good accuracy. Additionally, we provide a general theoretical framework to identify invariant infinitesimal generators for arbitrary Cauchy problems. This unsupervised algorithm does not require prior numerical solutions, making it both practical and efficient for various applications. Our contributions demonstrate the potential of combining symmetry analysis with deep learning to advance the field of scientific machine learning.
<div id='section'>Paperid: <span id='pid'>1894, <a href='https://arxiv.org/pdf/2407.19074.pdf' target='_blank'>https://arxiv.org/pdf/2407.19074.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao-Xuan Chen, Pin Zhang, Hai-Sui Yu, Zhen-Yu Yin, Brian Sheil
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.19074">Parsimonious Universal Function Approximator for Elastic and Elasto-Plastic Cavity Expansion Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cavity expansion is a canonical problem in geotechnics, which can be described by partial differential equations (PDEs) and ordinary differential equations (ODEs). This study explores the potential of using a new solver, a physics-informed neural network (PINN), to calculate the stress field in an expanded cavity in the elastic and elasto-plastic regimes. Whilst PINNs have emerged as an effective universal function approximator for deriving the solutions of a wide range of governing PDEs/ODEs, their ability to solve elasto-plastic problems remains uncertain. A novel parsimonious loss function is first proposed to balance the simplicity and accuracy of PINN. The proposed method is applied to diverse material behaviours in the cavity expansion problem including isotropic, anisotropic elastic media, and elastic-perfectly plastic media with Tresca and Mohr-Coulomb yield criteria. The results indicate that the use of a parsimonious prior information-based loss function is highly beneficial to deriving the approximate solutions of complex PDEs with high accuracy. The present method allows for accurate derivation of solutions for both elastic and plastic mechanical responses of an expanded cavity. It also provides insights into how PINNs can be further advanced to solve more complex problems in geotechnical practice.
<div id='section'>Paperid: <span id='pid'>1895, <a href='https://arxiv.org/pdf/2407.14051.pdf' target='_blank'>https://arxiv.org/pdf/2407.14051.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jihahm Yoo, Haesung Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14051">Robust error estimates of PINN in one-dimensional boundary value problems for linear elliptic equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we study physics-informed neural networks (PINN) to approximate solutions to one-dimensional boundary value problems for linear elliptic equations and establish robust error estimates of PINN regardless of the quantities of the coefficients. In particular, we rigorously demonstrate the existence and uniqueness of solutions using the Sobolev space theory based on a variational approach. Deriving $L^2$-contraction estimates, we show that the error, defined as the mean square of the differences between the true solution and our trial function at the sample points, is dominated by the training loss. Furthermore, we show that as the quantities of the coefficients for the differential equation increase, the error-to-loss ratio rapidly decreases. Our theoretical and experimental results confirm the robustness of the error regardless of the quantities of the coefficients.
<div id='section'>Paperid: <span id='pid'>1896, <a href='https://arxiv.org/pdf/2407.11346.pdf' target='_blank'>https://arxiv.org/pdf/2407.11346.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luyang Zhao, Qian Shao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.11346">DEDEM: Discontinuity Embedded Deep Energy Method for solving fracture mechanics problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have aroused great attention for its ability to address forward and inverse problems of partial differential equations. However, approximating discontinuous functions by neural networks poses a considerable challenge, which results in high computational demands and low accuracy to solve fracture mechanics problems within standard PINNs framework. In this paper, we present a novel method called Discontinuity Embedded Deep Energy Method (DEDEM) for modeling fracture mechanics problems. In this method, interfaces and internal boundaries with weak/strong discontinuities are represented by discontinuous functions constructed by signed distance functions, then the representations are embedded to the input of the neural network so that specific discontinuous features can be imposed to the neural network solution. Results demonstrate that DEDEM can accurately model the mechanical behaviors of cracks on a large variety of fracture problems. Besides, it is also found that DEDEM achieves significantly higher computational efficiency and accuracy than the existing methods based on domain decomposition techniques.
<div id='section'>Paperid: <span id='pid'>1897, <a href='https://arxiv.org/pdf/2407.10988.pdf' target='_blank'>https://arxiv.org/pdf/2407.10988.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Heng Zhang, Yun-Ling He, Dong Liu, Qin Hang, He-Min Yao, Di Xiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.10988">Residual resampling-based physics-informed neural network for neutron diffusion equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The neutron diffusion equation plays a pivotal role in the analysis of nuclear reactors. Nevertheless, employing the Physics-Informed Neural Network (PINN) method for its solution entails certain limitations. Traditional PINN approaches often utilize fully connected network (FCN) architecture, which is susceptible to overfitting, training instability, and gradient vanishing issues as the network depth increases. These challenges result in accuracy bottlenecks in the solution. In response to these issues, the Residual-based Resample Physics-Informed Neural Network(R2-PINN) is proposed, which proposes an improved PINN architecture that replaces the FCN with a Convolutional Neural Network with a shortcut(S-CNN), incorporating skip connections to facilitate gradient propagation between network layers. Additionally, the incorporation of the Residual Adaptive Resampling (RAR) mechanism dynamically increases sampling points, enhancing the spatial representation capabilities and overall predictive accuracy of the model. The experimental results illustrate that our approach significantly improves the model's convergence capability, achieving high-precision predictions of physical fields. In comparison to traditional FCN-based PINN methods, R2-PINN effectively overcomes the limitations inherent in current methods, providing more accurate and robust solutions for neutron diffusion equations.
<div id='section'>Paperid: <span id='pid'>1898, <a href='https://arxiv.org/pdf/2407.10836.pdf' target='_blank'>https://arxiv.org/pdf/2407.10836.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Zhou, Y. F. Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.10836">Data-Guided Physics-Informed Neural Networks for Solving Inverse Problems in Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) represent a significant advancement in scientific machine learning by integrating fundamental physical laws into their architecture through loss functions. PINNs have been successfully applied to solve various forward and inverse problems in partial differential equations (PDEs). However, a notable challenge can emerge during the early training stages when solving inverse problems. Specifically, data losses remain high while PDE residual losses are minimized rapidly, thereby exacerbating the imbalance between loss terms and impeding the overall efficiency of PINNs. To address this challenge, this study proposes a novel framework termed data-guided physics-informed neural networks (DG-PINNs). The DG-PINNs framework is structured into two distinct phases: a pre-training phase and a fine-tuning phase. In the pre-training phase, a loss function with only the data loss is minimized in a neural network. In the fine-tuning phase, a composite loss function, which consists of the data loss, PDE residual loss, and, if available, initial and boundary condition losses, is minimized in the same neural network. Notably, the pre-training phase ensures that the data loss is already at a low value before the fine-tuning phase commences. This approach enables the fine-tuning phase to converge to a minimal composite loss function with fewer iterations compared to existing PINNs. To validate the effectiveness, noise-robustness, and efficiency of DG-PINNs, extensive numerical investigations are conducted on inverse problems related to several classical PDEs, including the heat equation, wave equation, Euler--Bernoulli beam equation, and Navier--Stokes equation. The numerical results demonstrate that DG-PINNs can accurately solve these inverse problems and exhibit robustness against noise in training data.
<div id='section'>Paperid: <span id='pid'>1899, <a href='https://arxiv.org/pdf/2407.10761.pdf' target='_blank'>https://arxiv.org/pdf/2407.10761.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahul Sharma, Maziar Raissi, Y. B. Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.10761">Physics-Informed Machine Learning for Smart Additive Manufacturing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Compared to physics-based computational manufacturing, data-driven models such as machine learning (ML) are alternative approaches to achieve smart manufacturing. However, the data-driven ML's "black box" nature has presented a challenge to interpreting its outcomes. On the other hand, governing physical laws are not effectively utilized to develop data-efficient ML algorithms. To leverage the advantages of ML and physical laws of advanced manufacturing, this paper focuses on the development of a physics-informed machine learning (PIML) model by integrating neural networks and physical laws to improve model accuracy, transparency, and generalization with case studies in laser metal deposition (LMD).
<div id='section'>Paperid: <span id='pid'>1900, <a href='https://arxiv.org/pdf/2407.10654.pdf' target='_blank'>https://arxiv.org/pdf/2407.10654.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marco Berardi, Fabio Difonzo, Matteo Icardi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.10654">Inverse Physics-Informed Neural Networks for transport models in porous materials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINN) are a machine learning tool that can be used to solve direct and inverse problems related to models described by Partial Differential Equations. This paper proposes an adaptive inverse PINN applied to different transport models, from diffusion to advection-diffusion-reaction problems. Once a suitable PINN is established to solve the forward problem, the transport parameters are added as trainable parameters. We find that, for the inverse problem to converge to the correct solution, the different components of the loss function (data misfit, initial conditions, boundary conditions and residual of the transport equation) need to be weighted adaptively as a function of the training iteration (epoch). Similarly, gradients of trainable parameters are scaled at each epoch accordingly. Several examples are presented for different test cases to support our PINN architecture and its scalability and robustness.
<div id='section'>Paperid: <span id='pid'>1901, <a href='https://arxiv.org/pdf/2407.03239.pdf' target='_blank'>https://arxiv.org/pdf/2407.03239.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rui Li, Mikhail Kudryashev, Artur Yakimovich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.03239">Solving the inverse problem of microscopy deconvolution with a residual Beylkin-Coifman-Rokhlin neural network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Optic deconvolution in light microscopy (LM) refers to recovering the object details from images, revealing the ground truth of samples. Traditional explicit methods in LM rely on the point spread function (PSF) during image acquisition. Yet, these approaches often fall short due to inaccurate PSF models and noise artifacts, hampering the overall restoration quality. In this paper, we approached the optic deconvolution as an inverse problem. Motivated by the nonstandard-form compression scheme introduced by Beylkin, Coifman, and Rokhlin (BCR), we proposed an innovative physics-informed neural network Multi-Stage Residual-BCR Net (m-rBCR) to approximate the optic deconvolution. We validated the m-rBCR model on four microscopy datasets - two simulated microscopy datasets from ImageNet and BioSR, real dSTORM microscopy images, and real widefield microscopy images. In contrast to the explicit deconvolution methods (e.g. Richardson-Lucy) and other state-of-the-art NN models (U-Net, DDPM, CARE, DnCNN, ESRGAN, RCAN, Noise2Noise, MPRNet, and MIMO-U-Net), the m-rBCR model demonstrates superior performance to other candidates by PSNR and SSIM in two real microscopy datasets and the simulated BioSR dataset. In the simulated ImageNet dataset, m-rBCR ranks the second-best place (right after MIMO-U-Net). With the backbone from the optical physics, m-rBCR exploits the trainable parameters with better performances (from ~30 times fewer than the benchmark MIMO-U-Net to ~210 times than ESRGAN). This enables m-rBCR to achieve a shorter runtime (from ~3 times faster than MIMO-U-Net to ~300 times faster than DDPM). To summarize, by leveraging physics constraints our model reduced potentially redundant parameters significantly in expertise-oriented NN candidates and achieved high efficiency with superior performance.
<div id='section'>Paperid: <span id='pid'>1902, <a href='https://arxiv.org/pdf/2406.14808.pdf' target='_blank'>https://arxiv.org/pdf/2406.14808.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Sun, Debarghya Mukherjee, Yves Atchade
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14808">On the estimation rate of Bayesian PINN for inverse problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Solving partial differential equations (PDEs) and their inverse problems using Physics-informed neural networks (PINNs) is a rapidly growing approach in the physics and machine learning community. Although several architectures exist for PINNs that work remarkably in practice, our theoretical understanding of their performances is somewhat limited. In this work, we study the behavior of a Bayesian PINN estimator of the solution of a PDE from $n$ independent noisy measurement of the solution. We focus on a class of equations that are linear in their parameters (with unknown coefficients $Î¸_\star$). We show that when the partial differential equation admits a classical solution (say $u_\star$), differentiable to order $Î²$, the mean square error of the Bayesian posterior mean is at least of order $n^{-2Î²/(2Î²+ d)}$. Furthermore, we establish a convergence rate of the linear coefficients of $Î¸_\star$ depending on the order of the underlying differential operator. Last but not least, our theoretical results are validated through extensive simulations.
<div id='section'>Paperid: <span id='pid'>1903, <a href='https://arxiv.org/pdf/2406.14591.pdf' target='_blank'>https://arxiv.org/pdf/2406.14591.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Konstantinos Vogiatzoglou, Costas Papadimitriou, Vasilis Bontozoglou, Konstantinos Ampountolas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14591">Physics-informed neural networks for parameter learning of wildfire spreading</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wildland fires pose a terrifying natural hazard, underscoring the urgent need to develop data-driven and physics-informed digital twins for wildfire prevention, monitoring, intervention, and response. In this direction of research, this work introduces a physics-informed neural network (PiNN) designed to learn the unknown parameters of an interpretable wildfire spreading model. The considered modeling approach integrates fundamental physical laws articulated by key model parameters essential for capturing the complex behavior of wildfires. The proposed machine learning framework leverages the theory of artificial neural networks with the physical constraints governing wildfire dynamics, including the first principles of mass and energy conservation. Training of the PiNN for physics-informed parameter identification is realized using synthetic data on the spatiotemporal evolution of one- and two-dimensional firefronts, derived from a high-fidelity simulator, as well as empirical data (ground surface thermal images) from the Troy Fire that occurred on June 19, 2002, in California. The parameter learning results demonstrate the predictive ability of the proposed PiNN in uncovering the unknown coefficients of the wildfire model in one- and two-dimensional fire spreading scenarios as well as the Troy Fire. Additionally, this methodology exhibits robustness by identifying the same parameters even in the presence of noisy data. By integrating this PiNN approach into a comprehensive framework, the envisioned physics-informed digital twin will enhance intelligent wildfire management and risk assessment, providing a powerful tool for proactive and reactive strategies.
<div id='section'>Paperid: <span id='pid'>1904, <a href='https://arxiv.org/pdf/2406.11917.pdf' target='_blank'>https://arxiv.org/pdf/2406.11917.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao He, Hongmei Shi, Ruixin Li, Jianbo Li, ZuJun Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11917">Modulated differentiable STFT and balanced spectrum metric for freight train wheelset bearing cross-machine transfer monitoring under speed fluctuations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The service conditions of wheelset bearings has a direct impact on the safe operation of railway heavy haul freight trains as the key components. However, speed fluctuation of the trains and few fault samples are the two main problems that restrict the accuracy of bearing fault diagnosis. Therefore, a cross-machine transfer diagnosis (pyDSN) network coupled with interpretable modulated differentiable short-time Fourier transform (STFT) and physics-informed balanced spectrum quality metric is proposed to learn domain-invariant and discriminative features under time-varying speeds. Firstly, due to insufficiency in extracting extract frequency components of time-varying speed signals using fixed windows, a modulated differentiable STFT (MDSTFT) that is interpretable with STFT-informed theoretical support, is proposed to extract the robust time-frequency spectrum (TFS). During training process, multiple windows with different lengths dynamically change. Also, in addition to the classification metric and domain discrepancy metric, we creatively introduce a third kind of metric, referred to as the physics-informed metric, to enhance transferable TFS. A physics-informed balanced spectrum quality (BSQ) regularization loss is devised to guide an optimization direction for MDSTFT and model. With it, not only can model acquire high-quality TFS, but also a physics-restricted domain adaptation network can be also acquired, making it learn real-world physics knowledge, ultimately diminish the domain discrepancy across different datasets. The experiment is conducted in the scenario of migrating from the laboratory datasets to the freight train dataset, indicating that the hybrid-driven pyDSN outperforms existing methods and has practical value.
<div id='section'>Paperid: <span id='pid'>1905, <a href='https://arxiv.org/pdf/2406.10534.pdf' target='_blank'>https://arxiv.org/pdf/2406.10534.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiye Zou, Tianyu Li, Lin Lu, Jingyu Wang, Shufan Zou, Laiping Zhang, Xiaogang Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10534">Finite-difference-informed graph network for solving steady-state incompressible flows on block-structured grids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in deep learning have enabled physics-informed neural networks to solve partial differential equations. Numerical differentiation using the finite-difference (FD) method is efficient in physics-constrained designs, even in parameterized settings. In traditional computational fluid dynamics(CFD), body-fitted block-structured grids are often employed for complex flow cases when obtaining FD solutions. However, convolution operators in convolutional neural networks for FD are typically limited to single-block grids. To address this issue, \blueText{graphs and graph networks are used} to learn flow representations across multi-block-structured grids. \blueText{A graph convolution-based FD method (GC-FDM) is proposed} to train graph networks in a label-free physics-constrained manner, enabling differentiable FD operations on unstructured graph outputs. To demonstrate model performance from single- to multi-block-structured grids, \blueText{the parameterized steady incompressible Navier-Stokes equations are solved} for a lid-driven cavity flow and the flows around single and double circular cylinder configurations. When compared to a CFD solver under various boundary conditions, the proposed method achieves a relative error in velocity field predictions on the order of $10^{-3}$. Furthermore, the proposed method reduces training costs by approximately 20\% compared to a physics-informed neural network. \blueText{To} further verify the effectiveness of GC-FDM in multi-block processing, \blueText{a 30P30N airfoil geometry is considered} and the \blueText{predicted} results are reasonable compared with those given by CFD. \blueText{Finally, the applicability of GC-FDM to three-dimensional (3D) case is tested using a 3D cavity geometry.
<div id='section'>Paperid: <span id='pid'>1906, <a href='https://arxiv.org/pdf/2406.06287.pdf' target='_blank'>https://arxiv.org/pdf/2406.06287.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Seungchan Ko, Sang Hyeon Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.06287">VS-PINN: A fast and efficient training of physics-informed neural networks using variable-scaling methods for solving PDEs with stiff behavior</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have recently emerged as a promising way to compute the solutions of partial differential equations (PDEs) using deep neural networks. However, despite their significant success in various fields, it remains unclear in many aspects how to effectively train PINNs if the solutions of PDEs exhibit stiff behaviors or high frequencies. In this paper, we propose a new method for training PINNs using variable-scaling techniques. This method is simple and it can be applied to a wide range of problems including PDEs with rapidly-varying solutions. Throughout various numerical experiments, we will demonstrate the effectiveness of the proposed method for these problems and confirm that it can significantly improve the training efficiency and performance of PINNs. Furthermore, based on the analysis of the neural tangent kernel (NTK), we will provide theoretical evidence for this phenomenon and show that our methods can indeed improve the performance of PINNs.
<div id='section'>Paperid: <span id='pid'>1907, <a href='https://arxiv.org/pdf/2406.02014.pdf' target='_blank'>https://arxiv.org/pdf/2406.02014.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wanli Ma, Xuegang Tang, Jin Gu, Ying Wang, Yuling Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02014">Understanding Auditory Evoked Brain Signal via Physics-informed Embedding Network with Multi-Task Transformer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the fields of brain-computer interaction and cognitive neuroscience, effective decoding of auditory signals from task-based functional magnetic resonance imaging (fMRI) is key to understanding how the brain processes complex auditory information. Although existing methods have enhanced decoding capabilities, limitations remain in information utilization and model representation. To overcome these challenges, we propose an innovative multi-task learning model, Physics-informed Embedding Network with Multi-Task Transformer (PEMT-Net), which enhances decoding performance through physics-informed embedding and deep learning techniques. PEMT-Net consists of two principal components: feature augmentation and classification. For feature augmentation, we propose a novel approach by creating neural embedding graphs via node embedding, utilizing random walks to simulate the physical diffusion of neural information. This method captures both local and non-local information overflow and proposes a position encoding based on relative physical coordinates. In the classification segment, we propose adaptive embedding fusion to maximally capture linear and non-linear characteristics. Furthermore, we propose an innovative parameter-sharing mechanism to optimize the retention and learning of extracted features. Experiments on a specific dataset demonstrate PEMT-Net's significant performance in multi-task auditory signal decoding, surpassing existing methods and offering new insights into the brain's mechanisms for processing complex auditory information.
<div id='section'>Paperid: <span id='pid'>1908, <a href='https://arxiv.org/pdf/2405.16770.pdf' target='_blank'>https://arxiv.org/pdf/2405.16770.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxiang Gao, Soheil Kolouri, Ravindra Duddu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16770">Physics informed cell representations for variational formulation of multiscale problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the rapid advancement of graphical processing units, Physics-Informed Neural Networks (PINNs) are emerging as a promising tool for solving partial differential equations (PDEs). However, PINNs are not well suited for solving PDEs with multiscale features, particularly suffering from slow convergence and poor accuracy. To address this limitation of PINNs, this article proposes physics-informed cell representations for resolving multiscale Poisson problems using a model architecture consisting of multilevel multiresolution grids coupled with a multilayer perceptron (MLP). The grid parameters (i.e., the level-dependent feature vectors) and the MLP parameters (i.e., the weights and biases) are determined using gradient-descent based optimization. The variational (weak) form based loss function accelerates computation by allowing the linear interpolation of feature vectors within grid cells. This cell-based MLP model also facilitates the use of a decoupled training scheme for Dirichlet boundary conditions and a parameter-sharing scheme for periodic boundary conditions, delivering superior accuracy compared to conventional PINNs. Furthermore, the numerical examples highlight improved speed and accuracy in solving PDEs with nonlinear or high-frequency boundary conditions and provide insights into hyperparameter selection. In essence, by cell-based MLP model along with the parallel tiny-cuda-nn library, our implementation improves convergence speed and numerical accuracy.
<div id='section'>Paperid: <span id='pid'>1909, <a href='https://arxiv.org/pdf/2405.11383.pdf' target='_blank'>https://arxiv.org/pdf/2405.11383.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kun Qian, Mohamed Kheir
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.11383">Investigating KAN-Based Physics-Informed Neural Networks for EMI/EMC Simulations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The main objective of this paper is to investigate the feasibility of employing Physics-Informed Neural Networks (PINNs) techniques, in particular KolmogorovArnold Networks (KANs), for facilitating Electromagnetic Interference (EMI) simulations. It introduces some common EM problem formulations and how they can be solved using AI-driven solutions instead of lengthy and complex full-wave numerical simulations. This research may open new horizons for green EMI simulation workflows with less energy consumption and feasible computational capacity.
<div id='section'>Paperid: <span id='pid'>1910, <a href='https://arxiv.org/pdf/2405.08690.pdf' target='_blank'>https://arxiv.org/pdf/2405.08690.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiumei Huang, Qiao Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08690">Double-activation neural network for solving parabolic equations with time delay</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents the double-activation neural network (DANN), a novel network architecture designed for solving parabolic equations with time delay. In DANN, each neuron is equipped with two activation functions to augment the network's nonlinear expressive capacity. Additionally, a new parameter is introduced for the construction of the quadratic terms in one of two activation functions, which further enhances the network's ability to capture complex nonlinear relationships. To address the issue of low fitting accuracy caused by the discontinuity of solution's derivative, a piecewise fitting approach is proposed by dividing the global solving domain into several subdomains. The convergence of the loss function is proven. Numerical results are presented to demonstrate the superior accuracy and faster convergence of DANN compared to the traditional physics-informed neural network (PINN).
<div id='section'>Paperid: <span id='pid'>1911, <a href='https://arxiv.org/pdf/2405.05371.pdf' target='_blank'>https://arxiv.org/pdf/2405.05371.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michel Nohra, Steven Dufour
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.05371">Coupling of the Finite Element Method with Physics Informed Neural Networks for the Multi-Fluid Flow Problem</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-fluid flows are found in various industrial processes, including metal injection molding and 3D printing. The accuracy of multi-fluid flow modeling is determined by how well interfaces and capillary forces are represented. In this paper, the multi-fluid flow problem is discretized using a combination of a Physics-Informed Neural Network (PINN) with a finite element discretization. To determine the best PINN formulation, a comparative study is conducted using a manufactured solution. We compare interface reinitialization methods to determine the most suitable approach for our discretization strategy. We devise a neural network architecture that better handles complex free surface topologies. Finally, the coupled numerical strategy is used to model a rising bubble problem.
<div id='section'>Paperid: <span id='pid'>1912, <a href='https://arxiv.org/pdf/2405.04230.pdf' target='_blank'>https://arxiv.org/pdf/2405.04230.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jorge F. UrbÃ¡n, Petros Stefanou, JosÃ© A. Pons
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.04230">Unveiling the optimization process of Physics Informed Neural Networks: How accurate and competitive can PINNs be?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the potential accuracy boundaries of physics-informed neural networks, contrasting their approach with previous similar works and traditional numerical methods. We find that selecting improved optimization algorithms significantly enhances the accuracy of the results. Simple modifications to the loss function may also improve precision, offering an additional avenue for enhancement. Despite optimization algorithms having a greater impact on convergence than adjustments to the loss function, practical considerations often favor tweaking the latter due to ease of implementation. On a global scale, the integration of an enhanced optimizer and a marginally adjusted loss function enables a reduction in the loss function by several orders of magnitude across diverse physical problems. Consequently, our results obtained using compact networks (typically comprising 2 or 3 layers of 20-30 neurons) achieve accuracies comparable to finite difference schemes employing thousands of grid points. This study encourages the continued advancement of PINNs and associated optimization techniques for broader applications across various fields.
<div id='section'>Paperid: <span id='pid'>1913, <a href='https://arxiv.org/pdf/2405.00217.pdf' target='_blank'>https://arxiv.org/pdf/2405.00217.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shupeng Wang, George Em Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.00217">GMC-PINNs: A new general Monte Carlo PINNs method for solving fractional partial differential equations on irregular domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have been widely used for solving partial differential equations (PDEs) of different types, including fractional PDEs (fPDES) [29]. Herein, we propose a new general (quasi) Monte Carlo PINN for solving fPDEs on irregular domains. Specifically, instead of approximating fractional derivatives by Monte Carlo approximations of integrals as was done previously in [31], we use a more general Monte Carlo approximation method to solve different fPDEs, which is valid for fractional differentiation under any definition. Moreover, based on the ensemble probability density function, the generated nodes are all located in denser regions near the target point where we perform the differentiation. This has an unexpected connection with known finite difference methods on non-equidistant or nested grids, and hence our method inherits their advantages. At the same time, the generated nodes exhibit a block-like dense distribution, leading to a good computational efficiency of this approach. We present the framework for using this algorithm and apply it to several examples. Our results demonstrate the effectiveness of GMC-PINNs in dealing with irregular domain problems and show a higher computational efficiency compared to the original fPINN method. We also include comparisons with the Monte Carlo fPINN [31]. Finally, we use examples to demonstrate the effectiveness of the method in dealing with fuzzy boundary location problems, and then use the method to solve the coupled 3D fractional Bloch-Torrey equation defined in the ventricular domain of the human brain, and compare the results with classical numerical methods.
<div id='section'>Paperid: <span id='pid'>1914, <a href='https://arxiv.org/pdf/2405.00166.pdf' target='_blank'>https://arxiv.org/pdf/2405.00166.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Imran Nasim, Adam Nasim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.00166">Discovering intrinsic multi-compartment pharmacometric models using Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pharmacometric models are pivotal across drug discovery and development, playing a decisive role in determining the progression of candidate molecules. However, the derivation of mathematical equations governing the system is a labor-intensive trial-and-error process, often constrained by tight timelines. In this study, we introduce PKINNs, a novel purely data-driven pharmacokinetic-informed neural network model. PKINNs efficiently discovers and models intrinsic multi-compartment-based pharmacometric structures, reliably forecasting their derivatives. The resulting models are both interpretable and explainable through Symbolic Regression methods. Our computational framework demonstrates the potential for closed-form model discovery in pharmacometric applications, addressing the labor-intensive nature of traditional model derivation. With the increasing availability of large datasets, this framework holds the potential to significantly enhance model-informed drug discovery.
<div id='section'>Paperid: <span id='pid'>1915, <a href='https://arxiv.org/pdf/2404.18054.pdf' target='_blank'>https://arxiv.org/pdf/2404.18054.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huang Qiumei, Ma Jiaxuan, Xu Zhen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.18054">Mass-preserving Spatio-temporal adaptive PINN for Cahn-Hilliard equations with strong nonlinearity and singularity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As one kind important phase field equations, Cahn-Hilliard equations contain spatial high order derivatives, strong nonlinearities, and even singularities. When using the physics informed neural network (PINN) to simulate the long time evolution, it is necessary to decompose the time domain to capture the transition of solutions in different time. Moreover, the baseline PINN can't maintain the mass conservation property for the equations. We propose a mass-preserving spatio-temporal adaptive PINN. This method adaptively dividing the time domain according to the rate of energy decrease, and solves the Cahn-Hilliard equation in each time step using an independent neural network. To improve the prediction accuracy, spatial adaptive sampling is employed in the subdomain to select points with large residual value and add them to the training samples. Additionally, a mass constraint is added to the loss function to compensate the mass degradation problem of the PINN method in solving the Cahn-Hilliard equations. The mass-preserving spatio-temporal adaptive PINN is employed to solve a series of numerical examples. These include the Cahn-Hilliard equations with different bulk potentials, the three dimensional Cahn-Hilliard equation with singularities, and the set of Cahn-Hilliard equations. The numerical results demonstrate the effectiveness of the proposed algorithm.
<div id='section'>Paperid: <span id='pid'>1916, <a href='https://arxiv.org/pdf/2404.17174.pdf' target='_blank'>https://arxiv.org/pdf/2404.17174.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Constantin-Daniel Nicolae, Sara Sameer, Nathan Sun, Karena Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17174">Optimizing Cycle Life Prediction of Lithium-ion Batteries via a Physics-Informed Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately measuring the cycle lifetime of commercial lithium-ion batteries is crucial for performance and technology development. We introduce a novel hybrid approach combining a physics-based equation with a self-attention model to predict the cycle lifetimes of commercial lithium iron phosphate graphite cells via early-cycle data. After fitting capacity loss curves to this physics-based equation, we then use a self-attention layer to reconstruct entire battery capacity loss curves. Our model exhibits comparable performances to existing models while predicting more information: the entire capacity loss curve instead of cycle life. This provides more robustness and interpretability: our model does not need to be retrained for a different notion of end-of-life and is backed by physical intuition.
<div id='section'>Paperid: <span id='pid'>1917, <a href='https://arxiv.org/pdf/2404.16347.pdf' target='_blank'>https://arxiv.org/pdf/2404.16347.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shivam Bhargava, Nagaiah Chamakuri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.16347">Enhancing Arterial Blood Flow Simulations through Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study introduces a computational approach leveraging Physics-Informed Neural Networks (PINNs) for the efficient computation of arterial blood flows, particularly focusing on solving the incompressible Navier-Stokes equations by using the domain decomposition technique. Unlike conventional computational fluid dynamics methods, PINNs offer advantages by eliminating the need for discretized meshes and enabling the direct solution of partial differential equations (PDEs). In this paper, we propose the weighted Extended Physics-Informed Neural Networks (WXPINNs) and weighted Conservative Physics-Informed Neural Networks (WCPINNs), tailored for detailed hemodynamic simulations based on generalized space-time domain decomposition techniques. The inclusion of multiple neural networks enhances the representation capacity of the weighted PINN methods. Furthermore, the weighted PINNs can be efficiently trained in parallel computing frameworks by employing separate neural networks for each sub-domain. We show that PINNs simulation results circumvent backflow instabilities, underscoring a notable advantage of employing PINNs over traditional numerical methods to solve such complex blood flow models. They naturally address such challenges within their formulations. The presented numerical results demonstrate that the proposed weighted PINNs outperform traditional PINNs settings, where sub-PINNs are applied to each subdomain separately. This study contributes to the integration of deep learning methodologies with fluid mechanics, paving the way for accurate and efficient high-fidelity simulations in biomedical applications, particularly in modeling arterial blood flow.
<div id='section'>Paperid: <span id='pid'>1918, <a href='https://arxiv.org/pdf/2404.12544.pdf' target='_blank'>https://arxiv.org/pdf/2404.12544.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohsen Zaker Esteghamati, Brennan Bean, Henry V. Burton, M. Z. Naser
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.12544">Beyond development: Challenges in deploying machine learning models for structural engineering applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML)-based solutions are rapidly changing the landscape of many fields, including structural engineering. Despite their promising performance, these approaches are usually only demonstrated as proof-of-concept in structural engineering, and are rarely deployed for real-world applications. This paper aims to illustrate the challenges of developing ML models suitable for deployment through two illustrative examples. Among various pitfalls, the presented discussion focuses on model overfitting and underspecification, training data representativeness, variable omission bias, and cross-validation. The results highlight the importance of implementing rigorous model validation techniques through adaptive sampling, careful physics-informed feature selection, and considerations of both model complexity and generalizability.
<div id='section'>Paperid: <span id='pid'>1919, <a href='https://arxiv.org/pdf/2404.09794.pdf' target='_blank'>https://arxiv.org/pdf/2404.09794.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>W. DÃ¶rfler, M. Elasmi, T. Laufer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.09794">Taper-based scattering formulation of the Helmholtz equation to improve the training process of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work addresses the scattering problem of an incident wave at a junction connecting two semi-infinite waveguides, which we intend to solve using Physics-Informed Neural Networks (PINNs). As with other deep learning-based approaches, PINNs are known to suffer from a spectral bias and from the hyperbolic nature of the Helmholtz equation. This makes the training process challenging, especially for higher wave numbers. We show an example where these limitations are present. In order to improve the learning capability of our model, we suggest an equivalent formulation of the Helmholtz Boundary Value Problem (BVP) that is based on splitting the total wave into a tapered continuation of the incoming wave and a remaining scattered wave. This allows the introduction of an inhomogeneity in the BVP, leveraging the information transmitted during back-propagation, thus, enhancing and accelerating the training process of our PINN model. The presented numerical illustrations are in accordance with the expected behavior, paving the way to a possible alternative approach to predicting scattering problems using PINNs.
<div id='section'>Paperid: <span id='pid'>1920, <a href='https://arxiv.org/pdf/2404.01163.pdf' target='_blank'>https://arxiv.org/pdf/2404.01163.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nan Zhou, Zheng Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.01163">Capturing Shock Waves by Relaxation Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we put forward a neural network framework to solve the nonlinear hyperbolic systems. This framework, named relaxation neural networks(RelaxNN), is a simple and scalable extension of physics-informed neural networks(PINN). It is shown later that a typical PINN framework struggles to handle shock waves that arise in hyperbolic systems' solutions. This ultimately results in the failure of optimization that is based on gradient descent in the training process. Relaxation systems provide a smooth asymptotic to the discontinuity solution, under the expectation that macroscopic problems can be solved from a microscopic perspective. Based on relaxation systems, the RelaxNN framework alleviates the conflict of losses in the training process of the PINN framework. In addition to the remarkable results demonstrated in numerical simulations, most of the acceleration techniques and improvement strategies aimed at the standard PINN framework can also be applied to the RelaxNN framework.
<div id='section'>Paperid: <span id='pid'>1921, <a href='https://arxiv.org/pdf/2404.01122.pdf' target='_blank'>https://arxiv.org/pdf/2404.01122.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ajay Devda, Akshay Sunil, Murthy R, B Deepthi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.01122">Enhanced Precision in Rainfall Forecasting for Mumbai: Utilizing Physics Informed ConvLSTM2D Models for Finer Spatial and Temporal Resolution</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Forecasting rainfall in tropical areas is challenging due to complex atmospheric behaviour, elevated humidity levels, and the common presence of convective rain events. In the Indian context, the difficulty is further exacerbated because of the monsoon intra seasonal oscillations, which introduce significant variability in rainfall patterns over short periods. Earlier investigations into rainfall prediction leveraged numerical weather prediction methods, along with statistical and deep learning approaches. This study introduces deep learning spatial model aimed at enhancing rainfall prediction accuracy on a finer scale. In this study, we hypothesize that integrating physical understanding improves the precipitation prediction skill of deep learning models with high precision for finer spatial scales, such as cities. To test this hypothesis, we introduce a physics informed ConvLSTM2D model to predict precipitation 6hr and 12hr ahead for Mumbai, India. We utilize ERA5 reanalysis data select predictor variables, across various geopotential levels. The ConvLSTM2D model was trained on the target variable precipitation for 4 different grids representing different spatial grid locations of Mumbai. Thus, the use of the ConvLSTM2D model for rainfall prediction, utilizing physics informed data from specific grids with limited spatial information, reflects current advancements in meteorological research that emphasize both efficiency and localized precision.
<div id='section'>Paperid: <span id='pid'>1922, <a href='https://arxiv.org/pdf/2403.19736.pdf' target='_blank'>https://arxiv.org/pdf/2403.19736.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jacob Varey, Jessica D. Ruprecht, Michael Tierney, Ryan Sullenberger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.19736">Physics-Informed Neural Networks for Satellite State Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Space Domain Awareness (SDA) community routinely tracks satellites in orbit by fitting an orbital state to observations made by the Space Surveillance Network (SSN). In order to fit such orbits, an accurate model of the forces that are acting on the satellite is required. Over the past several decades, high-quality, physics-based models have been developed for satellite state estimation and propagation. These models are exceedingly good at estimating and propagating orbital states for non-maneuvering satellites; however, there are several classes of anomalous accelerations that a satellite might experience which are not well-modeled, such as satellites that use low-thrust electric propulsion to modify their orbit. Physics-Informed Neural Networks (PINNs) are a valuable tool for these classes of satellites as they combine physics models with Deep Neural Networks (DNNs), which are highly expressive and versatile function approximators. By combining a physics model with a DNN, the machine learning model need not learn astrodynamics, which results in more efficient and effective utilization of machine learning resources. This paper details the application of PINNs to estimate the orbital state and a continuous, low-amplitude anomalous acceleration profile for satellites. The PINN is trained to learn the unknown acceleration by minimizing the mean square error of observations. We evaluate the performance of pure physics models with PINNs in terms of their observation residuals and their propagation accuracy beyond the fit span of the observations. For a two-day simulation of a GEO satellite using an unmodeled acceleration profile on the order of $10^{-8} \text{ km/s}^2$, the PINN outperformed the best-fit physics model by orders of magnitude for both observation residuals (123 arcsec vs 1.00 arcsec) as well as propagation accuracy (3860 km vs 164 km after five days).
<div id='section'>Paperid: <span id='pid'>1923, <a href='https://arxiv.org/pdf/2403.18371.pdf' target='_blank'>https://arxiv.org/pdf/2403.18371.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Victor Daniel Reyes Dreke, Ygor Pereira Marca, Maurice Roes, Mircea Lazar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18371">Multivariable control of modular multilevel converters with convergence and safety guarantees</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Well-designed current control is a key factor in ensuring the efficient and safe operation of modular multilevel converters (MMCs). Even though this control problem involves multiple control objectives, conventional current control schemes are comprised of independently designed decoupled controllers, e.g., proportional-integral (PI) or proportional-resonant (PR). Due to the bilinearity of the MMC dynamics, tuning PI and PR controllers so that good performance and constraint satisfaction are guaranteed is quite challenging. This challenge becomes more relevant in an AC/AC MMC configuration due to the complexity of tracking the single-phase sinusoidal components of the MMC output. In this paper, we propose a method to design a multivariable controller, i.e., a static feedback gain, to regulate the MMC currents. We use a physics-informed transformation to model the MMC dynamics linearly and synthesise the proposed controller. We use this linear model to formulate a linear matrix inequality that computes a feedback gain that guarantees safe and effective operation, including (i) limited tracking error, (ii) stability, and (iii) meeting all constraints. To test the efficacy of our method, we examine its performance in a direct AC/AC MMC simulated in Simulink/PLECS and in a scaled-down AC/AC MMC prototype to investigate the ultra-fast charging of electric vehicles.
<div id='section'>Paperid: <span id='pid'>1924, <a href='https://arxiv.org/pdf/2403.10682.pdf' target='_blank'>https://arxiv.org/pdf/2403.10682.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarah I. Allec, Xiaonan Lu, Daniel R. Cassar, Xuan T. Nguyen, Vinay I. Hegde, Thiruvillamalai Mahadevan, Miroslava Peterson, Jincheng Du, Brian J. Riley, John D. Vienna, James E. Saal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10682">Evaluation of GlassNet for physics-informed machine learning of glass stability and glass-forming ability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Glasses form the basis of many modern applications and also hold great potential for future medical and environmental applications. However, their structural complexity and large composition space make design and optimization challenging for certain applications. Of particular importance for glass processing is an estimate of a given composition's glass-forming ability (GFA). However, there remain many open questions regarding the physical mechanisms of glass formation, especially in oxide glasses. It is apparent that a proxy for GFA would be highly useful in glass processing and design, but identifying such a surrogate property has proven itself to be difficult. Here, we explore the application of an open-source pre-trained NN model, GlassNet, that can predict the characteristic temperatures necessary to compute glass stability (GS) and assess the feasibility of using these physics-informed ML (PIML)-predicted GS parameters to estimate GFA. In doing so, we track the uncertainties at each step of the computation - from the original ML prediction errors, to the compounding of errors during GS estimation, and finally to the final estimation of GFA. While GlassNet exhibits reasonable accuracy on all individual properties, we observe a large compounding of error in the combination of these individual predictions for the prediction of GS, finding that random forest models offer similar accuracy to GlassNet. We also breakdown the ML performance on different glass families and find that the error in GS prediction is correlated with the error in crystallization peak temperature prediction. Lastly, we utilize this finding to assess the relationship between top-performing GS parameters and GFA for two ternary glass systems: sodium borosilicate and sodium iron phosphate glasses. We conclude that to obtain true ML predictive capability of GFA, significantly more data needs to be collected.
<div id='section'>Paperid: <span id='pid'>1925, <a href='https://arxiv.org/pdf/2403.09961.pdf' target='_blank'>https://arxiv.org/pdf/2403.09961.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad J. Aljubran, Roland N. Horne
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.09961">Thermal Earth Model for the Conterminous United States Using an Interpolative Physics-Informed Graph Neural Network (InterPIGNN)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a data-driven spatial interpolation algorithm based on physics-informed graph neural networks used to develop national temperature-at-depth maps for the conterminous United States. The model was trained to approximately satisfy the three-dimensional heat conduction law by simultaneously predicting subsurface temperature, surface heat flow, and rock thermal conductivity. In addition to bottomhole temperature measurements, we incorporated other physical quantities as model inputs, such as depth, geographic coordinates, elevation, sediment thickness, magnetic anomaly, gravity anomaly, gamma-ray flux of radioactive elements, seismicity, and electric conductivity. We constructed surface heat flow, and temperature and thermal conductivity predictions for depths of 0-7 km at an interval of 1 km with spatial resolution of 18 km$^2$ per grid cell. Our model showed superior temperature, surface heat flow and thermal conductivity mean absolute errors of 4.8Â° C, 5.817 mW/m$^2$ and 0.022 W/(C-m)$, respectively. The predictions were visualized in two-dimensional spatial maps across the modeled depths. This thorough modeling of the Earth's thermal processes is crucial to understanding subsurface phenomena and exploiting natural underground resources.
<div id='section'>Paperid: <span id='pid'>1926, <a href='https://arxiv.org/pdf/2403.09758.pdf' target='_blank'>https://arxiv.org/pdf/2403.09758.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shaghayegh Z. Ashtiani, Mohammad Sarabian, Kaveh Laksari, Hessam Babaee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.09758">Reconstructing Blood Flow in Data-Poor Regimes: A Vasculature Network Kernel for Gaussian Process Regression</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Blood flow reconstruction in the vasculature is important for many clinical applications. However, in clinical settings, the available data are often quite limited. For instance, Transcranial Doppler ultrasound (TCD) is a noninvasive clinical tool that is commonly used in the clinical settings to measure blood velocity waveform at several locations on brain's vasculature. This amount of data is grossly insufficient for training machine learning surrogate models, such as deep neural networks or Gaussian process regression. In this work, we propose a Gaussian process regression approach based on physics-informed kernels, enabling near-real-time reconstruction of blood flow in data-poor regimes. We introduce a novel methodology to reconstruct the kernel within the vascular network, which is a non-Euclidean space. The proposed kernel encodes both spatiotemporal and vessel-to-vessel correlations, thus enabling blood flow reconstruction in vessels that lack direct measurements. We demonstrate that any prediction made with the proposed kernel satisfies the conservation of mass principle. The kernel is constructed by running stochastic one-dimensional blood flow simulations, where the stochasticity captures the epistemic uncertainties, such as lack of knowledge about boundary conditions and uncertainties in vasculature geometries. We demonstrate the performance of the model on three test cases, namely, a simple Y-shaped bifurcation, abdominal aorta, and the Circle of Willis in the brain.
<div id='section'>Paperid: <span id='pid'>1927, <a href='https://arxiv.org/pdf/2403.08569.pdf' target='_blank'>https://arxiv.org/pdf/2403.08569.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Hu, Sidi Wu, Guoxiong Cai, Na Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.08569">A Physics-driven GraphSAGE Method for Physical Process Simulations Described by Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have successfully addressed various computational physics problems based on partial differential equations (PDEs). However, while tackling issues related to irregularities like singularities and oscillations, trained solutions usually suffer low accuracy. In addition, most current works only offer the trained solution for predetermined input parameters. If any change occurs in input parameters, transfer learning or retraining is required, and traditional numerical techniques also need an independent simulation. In this work, a physics-driven GraphSAGE approach (PD-GraphSAGE) based on the Galerkin method and piecewise polynomial nodal basis functions is presented to solve computational problems governed by irregular PDEs and to develop parametric PDE surrogate models. This approach employs graph representations of physical domains, thereby reducing the demands for evaluated points due to local refinement. A distance-related edge feature and a feature mapping strategy are devised to help training and convergence for singularity and oscillation situations, respectively. The merits of the proposed method are demonstrated through a couple of cases. Moreover, the robust PDE surrogate model for heat conduction problems parameterized by the Gaussian random field source is successfully established, which not only provides the solution accurately but is several times faster than the finite element method in our experiments.
<div id='section'>Paperid: <span id='pid'>1928, <a href='https://arxiv.org/pdf/2403.08448.pdf' target='_blank'>https://arxiv.org/pdf/2403.08448.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiarui Wang, Mahyar Fazlyab
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.08448">Actor-Critic Physics-informed Neural Lyapunov Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Designing control policies for stabilization tasks with provable guarantees is a long-standing problem in nonlinear control. A crucial performance metric is the size of the resulting region of attraction, which essentially serves as a robustness "margin" of the closed-loop system against uncertainties. In this paper, we propose a new method to train a stabilizing neural network controller along with its corresponding Lyapunov certificate, aiming to maximize the resulting region of attraction while respecting the actuation constraints. Crucial to our approach is the use of Zubov's Partial Differential Equation (PDE), which precisely characterizes the true region of attraction of a given control policy. Our framework follows an actor-critic pattern where we alternate between improving the control policy (actor) and learning a Zubov function (critic). Finally, we compute the largest certifiable region of attraction by invoking an SMT solver after the training procedure. Our numerical experiments on several design problems show consistent and significant improvements in the size of the resulting region of attraction.
<div id='section'>Paperid: <span id='pid'>1929, <a href='https://arxiv.org/pdf/2403.07925.pdf' target='_blank'>https://arxiv.org/pdf/2403.07925.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David C. Williams, Neil Inala
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.07925">Physics-informed generative model for drug-like molecule conformers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a diffusion-based, generative model for conformer generation. Our model is focused on the reproduction of bonded structure and is constructed from the associated terms traditionally found in classical force fields to ensure a physically relevant representation. Techniques in deep learning are used to infer atom typing and geometric parameters from a training set. Conformer sampling is achieved by taking advantage of recent advancements in diffusion-based generation. By training on large, synthetic data sets of diverse, drug-like molecules optimized with the semiempirical GFN2-xTB method, high accuracy is achieved for bonded parameters, exceeding that of conventional, knowledge-based methods. Results are also compared to experimental structures from the Protein Databank (PDB) and Cambridge Structural Database (CSD).
<div id='section'>Paperid: <span id='pid'>1930, <a href='https://arxiv.org/pdf/2403.07507.pdf' target='_blank'>https://arxiv.org/pdf/2403.07507.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Philip W. Livermore, Leyuan Wu, Longwei Chen, Sjoerd A. L. de Ridder
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.07507">Reconstructions of Jupiter's magnetic field using physics informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Magnetic sounding using data collected from the Juno mission can be used to provide constraints on Jupiter's interior. However, inwards continuation of reconstructions assuming zero electrical conductivity and a representation in spherical harmonics are limited by the enhancement of noise at small scales. Here we describe new reconstructions of Jupiter's internal magnetic field based on physics-informed neural networks and either the first 33 (PINN33) or the first 50 (PINN50) of Juno's orbits. The method can resolve local structures, and allows for weak ambient electrical currents. Our models are not hampered by noise amplification at depth, and offer a much clearer picture of the interior structure. We estimate that the dynamo boundary is at a fractional radius of 0.8. At this depth, the magnetic field is arranged into longitudinal bands, and strong local features such as the great blue spot appear to be rooted in neighbouring structures of oppositely signed flux.
<div id='section'>Paperid: <span id='pid'>1931, <a href='https://arxiv.org/pdf/2403.04883.pdf' target='_blank'>https://arxiv.org/pdf/2403.04883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyuan Xing, Efstathios G. Charalampidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.04883">Learning Traveling Solitary Waves Using Separable Gaussian Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we apply a machine-learning approach to learn traveling solitary waves across various families of partial differential equations (PDEs). Our approach integrates a novel interpretable neural network (NN) architecture, called Separable Gaussian Neural Networks (SGNN) into the framework of Physics-Informed Neural Networks (PINNs). Unlike the traditional PINNs that treat spatial and temporal data as independent inputs, the present method leverages wave characteristics to transform data into the so-called co-traveling wave frame. This adaptation effectively addresses the issue of propagation failure in PINNs when applied to large computational domains. Here, the SGNN architecture demonstrates robust approximation capabilities for single-peakon, multi-peakon, and stationary solutions within the (1+1)-dimensional, $b$-family of PDEs. In addition, we expand our investigations, and explore not only peakon solutions in the $ab$-family but also compacton solutions in (2+1)-dimensional, Rosenau-Hyman family of PDEs. A comparative analysis with MLP reveals that SGNN achieves comparable accuracy with fewer than a tenth of the neurons, underscoring its efficiency and potential for broader application in solving complex nonlinear PDEs.
<div id='section'>Paperid: <span id='pid'>1932, <a href='https://arxiv.org/pdf/2403.03223.pdf' target='_blank'>https://arxiv.org/pdf/2403.03223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pratanu Roy, Stephen Castonguay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.03223">Exact Enforcement of Temporal Continuity in Sequential Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The use of deep learning methods in scientific computing represents a potential paradigm shift in engineering problem solving. One of the most prominent developments is Physics-Informed Neural Networks (PINNs), in which neural networks are trained to satisfy partial differential equations (PDEs). While this method shows promise, the standard version has been shown to struggle in accurately predicting the dynamic behavior of time-dependent problems. To address this challenge, methods have been proposed that decompose the time domain into multiple segments, employing a distinct neural network in each segment and directly incorporating continuity between them in the loss function of the minimization problem. In this work we introduce a method to exactly enforce continuity between successive time segments via a solution ansatz. This hard constrained sequential PINN (HCS-PINN) method is simple to implement and eliminates the need for any loss terms associated with temporal continuity. The method is tested for a number of benchmark problems involving both linear and non-linear PDEs. Examples include various first order time dependent problems in which traditional PINNs struggle, namely advection, Allen-Cahn, and Korteweg-de Vries equations. Furthermore, second and third order time-dependent problems are demonstrated via wave and Jerky dynamics examples, respectively. Notably, the Jerky dynamics problem is chaotic, making the problem especially sensitive to temporal accuracy. The numerical experiments conducted with the proposed method demonstrated superior convergence and accuracy over both traditional PINNs and the soft-constrained counterparts.
<div id='section'>Paperid: <span id='pid'>1933, <a href='https://arxiv.org/pdf/2402.15592.pdf' target='_blank'>https://arxiv.org/pdf/2402.15592.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Jiao, Wantao Jia, Weiqiu Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.15592">Solving a class of stochastic optimal control problems by physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The aim of this work is to develop a deep learning method for solving high-dimensional stochastic control problems based on the Hamilton--Jacobi--Bellman (HJB) equation and physics-informed learning. Our approach is to parameterize the feedback control and the value function using a decoupled neural network with multiple outputs. We train this network by using a loss function with penalty terms that enforce the HJB equation along the sampled trajectories generated by the controlled system. More significantly, numerical results on various applications are carried out to demonstrate that the proposed approach is efficient and applicable.
<div id='section'>Paperid: <span id='pid'>1934, <a href='https://arxiv.org/pdf/2402.14049.pdf' target='_blank'>https://arxiv.org/pdf/2402.14049.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guiye Li, Guofeng Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.14049">Generative Adversarial Models for Extreme Geospatial Downscaling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Addressing the challenges of climate change requires accurate and high-resolution mapping of geospatial data, especially climate and weather variables. However, many existing geospatial datasets, such as the gridded outputs of the state-of-the-art numerical climate models (e.g., general circulation models), are only available at very coarse spatial resolutions due to the model complexity and extremely high computational demand. Deep-learning-based methods, particularly generative adversarial networks (GANs) and their variants, have proved effective for refining natural images and have shown great promise in improving geospatial datasets. This paper describes a conditional GAN-based stochastic geospatial downscaling method that can accommodates very high scaling factors. Compared to most existing methods, the method can generate high-resolution accurate climate datasets from very low-resolution inputs. More importantly, the method explicitly considers the uncertainty inherent to the downscaling process that tends to be ignored in existing methods. Given an input, the method can produce a multitude of plausible high-resolution samples instead of one single deterministic result. These samples allow for an empirical exploration and inferences of model uncertainty and robustness. With a case study of gridded climate datasets (wind velocity and solar irradiance), we demonstrate the performances of the framework in downscaling tasks with large scaling factors (up to $64\times$) and highlight the advantages of the framework with a comprehensive comparison with commonly used and most recent downscaling methods, including area-to-point (ATP) kriging, deep image prior (DIP), enhanced super-resolution generative adversarial networks (ESRGAN), physics-informed resolution-enhancing GAN (PhIRE GAN), and an efficient diffusion model for remote sensing image super-resolution (EDiffSR).
<div id='section'>Paperid: <span id='pid'>1935, <a href='https://arxiv.org/pdf/2402.13911.pdf' target='_blank'>https://arxiv.org/pdf/2402.13911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mostafa Esmaeilzadeh, Melika Amirzadeh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.13911">Replication Study: Enhancing Hydrological Modeling with Physics-Guided Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current hydrological modeling methods combine data-driven Machine Learning (ML) algorithms and traditional physics-based models to address their respective limitations incorrect parameter estimates from rigid physics-based models and the neglect of physical process constraints by ML algorithms. Despite the accuracy of ML in outcome prediction, the integration of scientific knowledge is crucial for reliable predictions. This study introduces a Physics Informed Machine Learning (PIML) model, which merges the process understanding of conceptual hydrological models with the predictive efficiency of ML algorithms. Applied to the Anandapur sub-catchment, the PIML model demonstrates superior performance in forecasting monthly streamflow and actual evapotranspiration over both standalone conceptual models and ML algorithms, ensuring physical consistency of the outputs. This study replicates the methodologies of Bhasme, P., Vagadiya, J., & Bhatia, U. (2022) from their pivotal work on Physics Informed Machine Learning for hydrological processes, utilizing their shared code and datasets to further explore the predictive capabilities in hydrological modeling.
<div id='section'>Paperid: <span id='pid'>1936, <a href='https://arxiv.org/pdf/2402.06261.pdf' target='_blank'>https://arxiv.org/pdf/2402.06261.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marco Baldan, Paolo Di Barba
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.06261">Energy-based PINNs for solving coupled field problems: concepts and application to the multi-objective optimal design of an induction heater</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are neural networks (NNs) that directly encode model equations, like Partial Differential Equations (PDEs), in the network itself. While most of the PINN algorithms in the literature minimize the local residual of the governing equations, there are energy-based approaches that take a different path by minimizing the variational energy of the model. We show that in the case of the steady thermal equation weakly coupled to magnetic equation, the energy-based approach displays multiple advantages compared to the standard residual-based PINN: it is more computationally efficient, it requires a lower order of derivatives to compute, and it involves less hyperparameters. The analyzed benchmark problems are the single- and multi-objective optimal design of an inductor for the controlled heating of a graphite plate. The optimized device is designed involving a multi-physics problem: a time-harmonic magnetic problem and a steady thermal problem. For the former, a deep neural network solving the direct problem is supervisedly trained on Finite Element Analysis (FEA) data. In turn, the solution of the latter relies on a hypernetwork that takes as input the inductor geometry parameters and outputs the model weights of an energy-based PINN (or ePINN). Eventually, the ePINN predicts the temperature field within the graphite plate.
<div id='section'>Paperid: <span id='pid'>1937, <a href='https://arxiv.org/pdf/2402.05281.pdf' target='_blank'>https://arxiv.org/pdf/2402.05281.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tanmoy Mondal, Ricardo Mendoza, Lucas Drumetz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.05281">Physics Informed and Data Driven Simulation of Underwater Images via Residual Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In general, underwater images suffer from color distortion and low contrast, because light is attenuated and backscattered as it propagates through water (differently depending on wavelength and on the properties of the water body). An existing simple degradation model (similar to atmospheric image "hazing" effects), though helpful, is not sufficient to properly represent the underwater image degradation because there are unaccounted for and non-measurable factors e.g. scattering of light due to turbidity of water, reflective characteristics of turbid medium etc. We propose a deep learning-based architecture to automatically simulate the underwater effects where only a dehazing-like image formation equation is known to the network, and the additional degradation due to the other unknown factors if inferred in a data-driven way. We only use RGB images (because in real-time scenario depth image is not available) to estimate the depth image. For testing, we have proposed (due to the lack of real underwater image datasets) a complex image formation model/equation to manually generate images that resemble real underwater images (used as ground truth). However, only the classical image formation equation (the one used for image dehazing) is informed to the network. This mimics the fact that in a real scenario, the physics are never completely known and only simplified models are known. Thanks to the ground truth, generated by a complex image formation equation, we could successfully perform a qualitative and quantitative evaluation of proposed technique, compared to other purely data driven approaches
<div id='section'>Paperid: <span id='pid'>1938, <a href='https://arxiv.org/pdf/2402.03864.pdf' target='_blank'>https://arxiv.org/pdf/2402.03864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrea Bonfanti, Giuseppe Bruno, Cristina Cipriani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03864">The Challenges of the Nonlinear Regime for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Neural Tangent Kernel (NTK) viewpoint is widely employed to analyze the training dynamics of overparameterized Physics-Informed Neural Networks (PINNs). However, unlike the case of linear Partial Differential Equations (PDEs), we show how the NTK perspective falls short in the nonlinear scenario. Specifically, we establish that the NTK yields a random matrix at initialization that is not constant during training, contrary to conventional belief. Another significant difference from the linear regime is that, even in the idealistic infinite-width limit, the Hessian does not vanish and hence it cannot be disregarded during training. This motivates the adoption of second-order optimization methods. We explore the convergence guarantees of such methods in both linear and nonlinear cases, addressing challenges such as spectral bias and slow convergence. Every theoretical result is supported by numerical examples with both linear and nonlinear PDEs, and we highlight the benefits of second-order methods in benchmark test cases.
<div id='section'>Paperid: <span id='pid'>1939, <a href='https://arxiv.org/pdf/2402.03153.pdf' target='_blank'>https://arxiv.org/pdf/2402.03153.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>M. Naderibeni, M. J. T. Reinders, L. Wu, D. M. J. Tax
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03153">Learning solutions of parametric Navier-Stokes with physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We leverage Physics-Informed Neural Networks (PINNs) to learn solution functions of parametric Navier-Stokes Equations (NSE). Our proposed approach results in a feasible optimization problem setup that bypasses PINNs' limitations in converging to solutions of highly nonlinear parametric-PDEs like NSE. We consider the parameter(s) of interest as inputs of PINNs along with spatio-temporal coordinates, and train PINNs on generated numerical solutions of parametric-PDES for instances of the parameters. We perform experiments on the classical 2D flow past cylinder problem aiming to learn velocities and pressure functions over a range of Reynolds numbers as parameter of interest. Provision of training data from generated numerical simulations allows for interpolation of the solution functions for a range of parameters. Therefore, we compare PINNs with unconstrained conventional Neural Networks (NN) on this problem setup to investigate the effectiveness of considering the PDEs regularization in the loss function. We show that our proposed approach results in optimizing PINN models that learn the solution functions while making sure that flow predictions are in line with conservational laws of mass and momentum. Our results show that PINN results in accurate prediction of gradients compared to NN model, this is clearly visible in predicted vorticity fields given that none of these models were trained on vorticity labels.
<div id='section'>Paperid: <span id='pid'>1940, <a href='https://arxiv.org/pdf/2402.01768.pdf' target='_blank'>https://arxiv.org/pdf/2402.01768.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xujia Huang, Fajie Wang, Benrong Zhang, Hanqing Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01768">Enriched Physics-informed Neural Networks for Dynamic Poisson-Nernst-Planck Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a meshless deep learning algorithm, enriched physics-informed neural networks (EPINNs), to solve dynamic Poisson-Nernst-Planck (PNP) equations with strong coupling and nonlinear characteristics. The EPINNs takes the traditional physics-informed neural networks as the foundation framework, and adds the adaptive loss weight to balance the loss functions, which automatically assigns the weights of losses by updating the parameters in each iteration based on the maximum likelihood estimate. The resampling strategy is employed in the EPINNs to accelerate the convergence of loss function. Meanwhile, the GPU parallel computing technique is adopted to accelerate the solving process. Four examples are provided to demonstrate the validity and effectiveness of the proposed method. Numerical results indicate that the new method has better applicability than traditional numerical methods in solving such coupled nonlinear systems. More importantly, the EPINNs is more accurate, stable, and fast than the traditional physics-informed neural networks. This work provides a simple and high-performance numerical tool for addressing PNPs with arbitrary boundary shapes and boundary conditions.
<div id='section'>Paperid: <span id='pid'>1941, <a href='https://arxiv.org/pdf/2402.00435.pdf' target='_blank'>https://arxiv.org/pdf/2402.00435.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicola Rares Franco, Simone Brugiapaglia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.00435">A practical existence theorem for reduced order models based on convolutional autoencoders</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, deep learning has gained increasing popularity in the fields of Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM), providing domain practitioners with new powerful data-driven techniques such as Physics-Informed Neural Networks (PINNs), Neural Operators, Deep Operator Networks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context, deep autoencoders based on Convolutional Neural Networks (CNNs) have proven extremely effective, outperforming established techniques, such as the reduced basis method, when dealing with complex nonlinear problems. However, despite the empirical success of CNN-based autoencoders, there are only a few theoretical results supporting these architectures, usually stated in the form of universal approximation theorems. In particular, although the existing literature provides users with guidelines for designing convolutional autoencoders, the subsequent challenge of learning the latent features has been barely investigated. Furthermore, many practical questions remain unanswered, e.g., the number of snapshots needed for convergence or the neural network training strategy. In this work, using recent techniques from sparse high-dimensional function approximation, we fill some of these gaps by providing a new practical existence theorem for CNN-based autoencoders when the parameter-to-solution map is holomorphic. This regularity assumption arises in many relevant classes of parametric PDEs, such as the parametric diffusion equation, for which we discuss an explicit application of our general theory.
<div id='section'>Paperid: <span id='pid'>1942, <a href='https://arxiv.org/pdf/2401.17424.pdf' target='_blank'>https://arxiv.org/pdf/2401.17424.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sajad Abbar, Meng-Ru Wu, Zewei Xiong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.17424">Application of Neural Networks for the Reconstruction of Supernova Neutrino Energy Spectra Following Fast Neutrino Flavor Conversions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neutrinos can undergo fast flavor conversions (FFCs) within extremely dense astrophysical environments such as core-collapse supernovae (CCSNe) and neutron star mergers (NSMs). In this study, we explore FFCs in a \emph{multi-energy} neutrino gas, revealing that when the FFC growth rate significantly exceeds that of the vacuum Hamiltonian, all neutrinos (regardless of energy) share a common survival probability dictated by the energy-integrated neutrino spectrum. We then employ physics-informed neural networks (PINNs) to predict the asymptotic outcomes of FFCs within such a multi-energy neutrino gas. These predictions are based on the first two moments of neutrino angular distributions for each energy bin, typically available in state-of-the-art CCSN and NSM simulations. Our PINNs achieve errors as low as $\lesssim6\%$ and $\lesssim 18\%$ for predicting the number of neutrinos in the electron channel and the relative absolute error in the neutrino moments, respectively.
<div id='section'>Paperid: <span id='pid'>1943, <a href='https://arxiv.org/pdf/2401.16645.pdf' target='_blank'>https://arxiv.org/pdf/2401.16645.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Joel Hayford, Jacob Goldman-Wetzler, Eric Wang, Lu Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.16645">Speeding up and reducing memory usage for scientific machine learning via mixed precision</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific machine learning (SciML) has emerged as a versatile approach to address complex computational science and engineering problems. Within this field, physics-informed neural networks (PINNs) and deep operator networks (DeepONets) stand out as the leading techniques for solving partial differential equations by incorporating both physical equations and experimental data. However, training PINNs and DeepONets requires significant computational resources, including long computational times and large amounts of memory. In search of computational efficiency, training neural networks using half precision (float16) rather than the conventional single (float32) or double (float64) precision has gained substantial interest, given the inherent benefits of reduced computational time and memory consumed. However, we find that float16 cannot be applied to SciML methods, because of gradient divergence at the start of training, weight updates going to zero, and the inability to converge to a local minima. To overcome these limitations, we explore mixed precision, which is an approach that combines the float16 and float32 numerical formats to reduce memory usage and increase computational speed. Our experiments showcase that mixed precision training not only substantially decreases training times and memory demands but also maintains model accuracy. We also reinforce our empirical observations with a theoretical analysis. The research has broad implications for SciML in various computational applications.
<div id='section'>Paperid: <span id='pid'>1944, <a href='https://arxiv.org/pdf/2401.12806.pdf' target='_blank'>https://arxiv.org/pdf/2401.12806.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanzhi Liu, Ruifan Wu, Ying Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.12806">Binary structured physics-informed neural networks for solving equations with rapidly changing solutions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs), rooted in deep learning, have emerged as a promising approach for solving partial differential equations (PDEs). By embedding the physical information described by PDEs into feedforward neural networks, PINNs are trained as surrogate models to approximate solutions without the need for label data. Nevertheless, even though PINNs have shown remarkable performance, they can face difficulties, especially when dealing with equations featuring rapidly changing solutions. These difficulties encompass slow convergence, susceptibility to becoming trapped in local minima, and reduced solution accuracy. To address these issues, we propose a binary structured physics-informed neural network (BsPINN) framework, which employs binary structured neural network (BsNN) as the neural network component. By leveraging a binary structure that reduces inter-neuron connections compared to fully connected neural networks, BsPINNs excel in capturing the local features of solutions more effectively and efficiently. These features are particularly crucial for learning the rapidly changing in the nature of solutions. In a series of numerical experiments solving Burgers equation, Euler equation, Helmholtz equation, and high-dimension Poisson equation, BsPINNs exhibit superior convergence speed and heightened accuracy compared to PINNs. From these experiments, we discover that BsPINNs resolve the issues caused by increased hidden layers in PINNs resulting in over-smoothing, and prevent the decline in accuracy due to non-smoothness of PDEs solutions.
<div id='section'>Paperid: <span id='pid'>1945, <a href='https://arxiv.org/pdf/2401.12489.pdf' target='_blank'>https://arxiv.org/pdf/2401.12489.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xin Feng, Yi Jiang, Jia-Xian Qin, Lai-Ping Zhang, Xiao-Gang Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.12489">Unsupervised Learning Method for the Wave Equation Based on Finite Difference Residual Constraints Loss</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The wave equation is an important physical partial differential equation, and in recent years, deep learning has shown promise in accelerating or replacing traditional numerical methods for solving it. However, existing deep learning methods suffer from high data acquisition costs, low training efficiency, and insufficient generalization capability for boundary conditions. To address these issues, this paper proposes an unsupervised learning method for the wave equation based on finite difference residual constraints. We construct a novel finite difference residual constraint based on structured grids and finite difference methods, as well as an unsupervised training strategy, enabling convolutional neural networks to train without data and predict the forward propagation process of waves. Experimental results show that finite difference residual constraints have advantages over physics-informed neural networks (PINNs) type physical information constraints, such as easier fitting, lower computational costs, and stronger source term generalization capability, making our method more efficient in training and potent in application.
<div id='section'>Paperid: <span id='pid'>1946, <a href='https://arxiv.org/pdf/2401.12435.pdf' target='_blank'>https://arxiv.org/pdf/2401.12435.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiayi Xie, Hongfeng Li, Jin Cheng, Qingrui Cai, Hanbo Tan, Lingyun Zu, Xiaobo Qu, Hongbin Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.12435">Quantitative Analysis of Molecular Transport in the Extracellular Space Using Physics-Informed Neural Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The brain extracellular space (ECS), an irregular, extremely tortuous nanoscale space located between cells or between cells and blood vessels, is crucial for nerve cell survival. It plays a pivotal role in high-level brain functions such as memory, emotion, and sensation. However, the specific form of molecular transport within the ECS remain elusive. To address this challenge, this paper proposes a novel approach to quantitatively analyze the molecular transport within the ECS by solving an inverse problem derived from the advection-diffusion equation (ADE) using a physics-informed neural network (PINN). PINN provides a streamlined solution to the ADE without the need for intricate mathematical formulations or grid settings. Additionally, the optimization of PINN facilitates the automatic computation of the diffusion coefficient governing long-term molecule transport and the velocity of molecules driven by advection. Consequently, the proposed method allows for the quantitative analysis and identification of the specific pattern of molecular transport within the ECS through the calculation of the Peclet number. Experimental validation on two datasets of magnetic resonance images (MRIs) captured at different time points showcases the effectiveness of the proposed method. Notably, our simulations reveal identical molecular transport patterns between datasets representing rats with tracer injected into the same brain region. These findings highlight the potential of PINN as a promising tool for comprehensively exploring molecular transport within the ECS.
<div id='section'>Paperid: <span id='pid'>1947, <a href='https://arxiv.org/pdf/2401.11860.pdf' target='_blank'>https://arxiv.org/pdf/2401.11860.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuandi Wu, Brett Sicard, Stephen Andrew Gadsden
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.11860">A Review of Physics-Informed Machine Learning Methods with Applications to Condition Monitoring and Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study presents a comprehensive overview of PIML techniques in the context of condition monitoring. The central concept driving PIML is the incorporation of known physical laws and constraints into machine learning algorithms, enabling them to learn from available data while remaining consistent with physical principles. Through fusing domain knowledge with data-driven learning, PIML methods offer enhanced accuracy and interpretability in comparison to purely data-driven approaches. In this comprehensive survey, detailed examinations are performed with regard to the methodology by which known physical principles are integrated within machine learning frameworks, as well as their suitability for specific tasks within condition monitoring. Incorporation of physical knowledge into the ML model may be realized in a variety of methods, with each having its unique advantages and drawbacks. The distinct advantages and limitations of each methodology for the integration of physics within data-driven models are detailed, considering factors such as computational efficiency, model interpretability, and generalizability to different systems in condition monitoring and fault detection. Several case studies and works of literature utilizing this emerging concept are presented to demonstrate the efficacy of PIML in condition monitoring applications. From the literature reviewed, the versatility and potential of PIML in condition monitoring may be demonstrated. Novel PIML methods offer an innovative solution for addressing the complexities of condition monitoring and associated challenges. This comprehensive survey helps form the foundation for future work in the field. As the technology continues to advance, PIML is expected to play a crucial role in enhancing maintenance strategies, system reliability, and overall operational efficiency in engineering systems.
<div id='section'>Paperid: <span id='pid'>1948, <a href='https://arxiv.org/pdf/2401.11488.pdf' target='_blank'>https://arxiv.org/pdf/2401.11488.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wilhelm KirchgÃ¤ssner, Nikolas FÃ¶rster, Till Piepenbrock, Oliver Schweins, Oliver Wallscheid
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.11488">HARDCORE: H-field and power loss estimation for arbitrary waveforms with residual, dilated convolutional neural networks in ferrite cores</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The MagNet Challenge 2023 calls upon competitors to develop data-driven models for the material-specific, waveform-agnostic estimation of steady-state power losses in toroidal ferrite cores. The following HARDCORE (H-field and power loss estimation for Arbitrary waveforms with Residual, Dilated convolutional neural networks in ferrite COREs) approach shows that a residual convolutional neural network with physics-informed extensions can serve this task efficiently when trained on observational data beforehand. One key solution element is an intermediate model layer which first reconstructs the bh curve and then estimates the power losses based on the curve's area rendering the proposed topology physically interpretable. In addition, emphasis was placed on expert-based feature engineering and information-rich inputs in order to enable a lean model architecture. A model is trained from scratch for each material, while the topology remains the same. A Pareto-style trade-off between model size and estimation accuracy is demonstrated, which yields an optimum at as low as 1755 parameters and down to below 8\,\% for the 95-th percentile of the relative error for the worst-case material with sufficient samples.
<div id='section'>Paperid: <span id='pid'>1949, <a href='https://arxiv.org/pdf/2401.07489.pdf' target='_blank'>https://arxiv.org/pdf/2401.07489.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hussam Alhussein, Mohammed Daqaq
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.07489">The Principle of Minimum Pressure Gradient: An Alternative Basis for Physics-Informed Learning of Incompressible Fluid Mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in the application of physics-informed learning into the field of fluid mechanics have been predominantly grounded in the Newtonian framework, primarly leveraging Navier-Stokes Equation or one of its various derivative to train a neural network. Here, we propose an alternative approach based on variational methods. The proposed approach uses the principle of minimum pressure gradient combined with the continuity constraint to train a neural network and predict the flow field in incompressible fluids. We describe the underlying principles of the proposed approach, then use a demonstrative example to illustrate its implementation and show that it reduces the computational time per training epoch when compared to the conventional approach.
<div id='section'>Paperid: <span id='pid'>1950, <a href='https://arxiv.org/pdf/2401.07379.pdf' target='_blank'>https://arxiv.org/pdf/2401.07379.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maria Mircea, Diego Garlaschelli, Stefan Semrau
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.07379">Inference of dynamical gene regulatory networks from single-cell data with physics informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One of the main goals of developmental biology is to reveal the gene regulatory networks (GRNs) underlying the robust differentiation of multipotent progenitors into precisely specified cell types. Most existing methods to infer GRNs from experimental data have limited predictive power as the inferred GRNs merely reflect gene expression similarity or correlation. Here, we demonstrate, how physics-informed neural networks (PINNs) can be used to infer the parameters of predictive, dynamical GRNs that provide mechanistic understanding of biological processes. Specifically we study GRNs that exhibit bifurcation behavior and can therefore model cell differentiation. We show that PINNs outperform regular feed-forward neural networks on the parameter inference task and analyze two relevant experimental scenarios: 1. a system with cell communication for which gene expression trajectories are available and 2. snapshot measurements of a cell population in which cell communication is absent. Our analysis will inform the design of future experiments to be analyzed with PINNs and provides a starting point to explore this powerful class of neural network models further.
<div id='section'>Paperid: <span id='pid'>1951, <a href='https://arxiv.org/pdf/2401.02810.pdf' target='_blank'>https://arxiv.org/pdf/2401.02810.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdul Hannan Mustajab, Hao Lyu, Zarghaam Rizvi, Frank Wuttke
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02810">Physics-Informed Neural Networks for High-Frequency and Multi-Scale Problems using Transfer Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural network (PINN) is a data-driven solver for partial and ordinary differential equations(ODEs/PDEs). It provides a unified framework to address both forward and inverse problems. However, the complexity of the objective function often leads to training failures. This issue is particularly prominent when solving high-frequency and multi-scale problems. We proposed using transfer learning to boost the robustness and convergence of training PINN, starting training from low-frequency problems and gradually approaching high-frequency problems. Through two case studies, we discovered that transfer learning can effectively train PINN to approximate solutions from low-frequency problems to high-frequency problems without increasing network parameters. Furthermore, it requires fewer data points and less training time. We elaborately described our training strategy, including optimizer selection, and suggested guidelines for using transfer learning to train neural networks for solving more complex problems.
<div id='section'>Paperid: <span id='pid'>1952, <a href='https://arxiv.org/pdf/2312.15175.pdf' target='_blank'>https://arxiv.org/pdf/2312.15175.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vijay Kag, Venkatesh Gopinath
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.15175">Physics-informed neural network for modeling dynamic linear elasticity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we present the physics-informed neural network (PINN) model applied particularly to dynamic problems in solid mechanics. We focus on forward and inverse problems. Particularly, we show how a PINN model can be used efficiently for material identification in a dynamic setting. In this work, we assume linear continuum elasticity. We show results for two-dimensional (2D) plane strain problem and then we proceed to apply the same techniques for a three-dimensional (3D) problem. As for the training data we use the solution based on the finite element method. We rigorously show that PINN models are accurate, robust and computationally efficient, especially as a surrogate model for material identification problems. Also, we employ state-of-the-art techniques from the PINN literature which are an improvement to the vanilla implementation of PINN. Based on our results, we believe that the framework we have developed can be readily adapted to computational platforms for solving multiple dynamic problems in solid mechanics.
<div id='section'>Paperid: <span id='pid'>1953, <a href='https://arxiv.org/pdf/2312.14975.pdf' target='_blank'>https://arxiv.org/pdf/2312.14975.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Josh Dees, Antoine Jacquier, Sylvain Laizet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.14975">Unsupervised Random Quantum Networks for PDEs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Classical Physics-informed neural networks (PINNs) approximate solutions to PDEs with the help of deep neural networks trained to satisfy the differential operator and the relevant boundary conditions. We revisit this idea in the quantum computing realm, using parameterised random quantum circuits as trial solutions. We further adapt recent PINN-based techniques to our quantum setting, in particular Gaussian smoothing. Our analysis concentrates on the Poisson, the Heat and the Hamilton-Jacobi-Bellman equations, which are ubiquitous in most areas of science. On the theoretical side, we develop a complexity analysis of this approach, and show numerically that random quantum networks can outperform more traditional quantum networks as well as random classical networks.
<div id='section'>Paperid: <span id='pid'>1954, <a href='https://arxiv.org/pdf/2312.13584.pdf' target='_blank'>https://arxiv.org/pdf/2312.13584.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harsha Vardhan Tetali, Joel B. Harley, Benjamin D. Haeffele
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.13584">Wave Physics-informed Matrix Factorizations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the recent success of representation learning methods, which includes deep learning as a special case, there has been considerable interest in developing techniques that incorporate known physical constraints into the learned representation. As one example, in many applications that involve a signal propagating through physical media (e.g., optics, acoustics, fluid dynamics, etc), it is known that the dynamics of the signal must satisfy constraints imposed by the wave equation. Here we propose a matrix factorization technique that decomposes such signals into a sum of components, where each component is regularized to ensure that it {nearly} satisfies wave equation constraints. Although our proposed formulation is non-convex, we prove that our model can be efficiently solved to global optimality. Through this line of work we establish theoretical connections between wave-informed learning and filtering theory in signal processing. We further demonstrate the application of this work on modal analysis problems commonly arising in structural diagnostics and prognostics.
<div id='section'>Paperid: <span id='pid'>1955, <a href='https://arxiv.org/pdf/2312.11316.pdf' target='_blank'>https://arxiv.org/pdf/2312.11316.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabio Vito Difonzo, Luciano Lopez, Sabrina Francesca Pellegrino
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.11316">Physics Informed Neural Networks for an Inverse Problem in Peridynamic Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning is a powerful tool for solving data driven differential problems and has come out to have successful applications in solving direct and inverse problems described by PDEs, even in presence of integral terms. In this paper, we propose to apply radial basis functions (RBFs) as activation functions in suitably designed Physics Informed Neural Networks (PINNs) to solve the inverse problem of computing the peridynamic kernel in the nonlocal formulation of classical wave equation, resulting in what we call RBF-iPINN. We show that the selection of an RBF is necessary to achieve meaningful solutions, that agree with the physical expectations carried by the data. We support our results with numerical examples and experiments, comparing the solution obtained with the proposed RBF-iPINN to the exact solutions.
<div id='section'>Paperid: <span id='pid'>1956, <a href='https://arxiv.org/pdf/2312.10257.pdf' target='_blank'>https://arxiv.org/pdf/2312.10257.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>John Martin, Hanspeter Schaub
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.10257">The Physics-Informed Neural Network Gravity Model: Generation III</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific machine learning and the advent of the Physics-Informed Neural Network (PINN) have shown high potential in their ability to solve complex differential equations. One example is the use of PINNs to solve the gravity field modeling problem -- learning convenient representations of the gravitational potential from position and acceleration data. These PINN gravity models, or PINN-GMs, have demonstrated advantages in model compactness, robustness to noise, and sample efficiency when compared to popular alternatives; however, further investigation has revealed various failure modes for these and other machine learning gravity models which this manuscript aims to address. Specifically, this paper introduces the third generation Physics-Informed Neural Network Gravity Model (PINN-GM-III) which includes design changes that solve the problems of feature divergence, bias towards low-altitude samples, numerical instability, and extrapolation error. Six evaluation metrics are proposed to expose these past pitfalls and illustrate the PINN-GM-III's robustness to them. This study concludes by evaluating the PINN-GM-III modeling accuracy on a heterogeneous density asteroid, and comparing its performance to other analytic and machine learning gravity models.
<div id='section'>Paperid: <span id='pid'>1957, <a href='https://arxiv.org/pdf/2312.09403.pdf' target='_blank'>https://arxiv.org/pdf/2312.09403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cody Rucker, Brittany A. Erickson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.09403">Physics-Informed Deep Learning of Rate-and-State Fault Friction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Direct observations of earthquake nucleation and propagation are few and yet the next decade will likely see an unprecedented increase in indirect, surface observations that must be integrated into modeling efforts. Machine learning (ML) excels in the presence of large data and is an actively growing field in seismology. However, not all ML methods incorporate rigorous physics, and purely data-driven models can predict physically unrealistic outcomes due to observational bias or extrapolation. Our work focuses on the recently emergent Physics-Informed Neural Network (PINN), which seamlessly integrates data while ensuring that model outcomes satisfy rigorous physical constraints. In this work we develop a multi-network PINN for both the forward problem as well as for direct inversion of nonlinear fault friction parameters, constrained by the physics of motion in the solid Earth, which have direct implications for assessing seismic hazard. We present the computational PINN framework for strike-slip faults in 1D and 2D subject to rate-and-state friction. Initial and boundary conditions define the data on which the PINN is trained. While the PINN is capable of approximating the solution to the governing equations to low-errors, our primary interest lies in the network's capacity to infer friction parameters during the training loop. We find that the network for the parameter inversion at the fault performs much better than the network for material displacements to which it is coupled. Additional training iterations and model tuning resolves this discrepancy, enabling a robust surrogate model for solving both forward and inverse problems relevant to seismic faulting.
<div id='section'>Paperid: <span id='pid'>1958, <a href='https://arxiv.org/pdf/2312.09215.pdf' target='_blank'>https://arxiv.org/pdf/2312.09215.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abhishek Setty, Rasul Abdusalamov, Felix Motzoi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.09215">Self-Adaptive Physics-Informed Quantum Machine Learning for Solving Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Chebyshev polynomials have shown significant promise as an efficient tool for both classical and quantum neural networks to solve linear and nonlinear differential equations. In this work, we adapt and generalize this framework in a quantum machine learning setting for a variety of problems, including the 2D Poisson's equation, second-order linear differential equation, system of differential equations, nonlinear Duffing and Riccati equation. In particular, we propose in the quantum setting a modified Self-Adaptive Physics-Informed Neural Network (SAPINN) approach, where self-adaptive weights are applied to problems with multi-objective loss functions. We further explore capturing correlations in our loss function using a quantum-correlated measurement, resulting in improved accuracy for initial value problems. We analyse also the use of entangling layers and their impact on the solution accuracy for second-order differential equations. The results indicate a promising approach to the near-term evaluation of differential equations on quantum devices.
<div id='section'>Paperid: <span id='pid'>1959, <a href='https://arxiv.org/pdf/2311.18539.pdf' target='_blank'>https://arxiv.org/pdf/2311.18539.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moses Ike, Kandy Phan, Anwesh Badapanda, Matthew Landen, Keaton Sadoski, Wanda Guo, Asfahan Shah, Saman Zonouz, Wenke Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18539">Bridging Both Worlds in Semantics and Time: Domain Knowledge Based Analysis and Correlation of Industrial Process Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern industrial control systems (ICS) attacks infect supervisory control and data acquisition (SCADA) hosts to stealthily alter industrial processes, causing damage. To detect attacks with low false alarms, recent work detects attacks in both SCADA and process data. Unfortunately, this led to the same problem - disjointed (false) alerts, due to the semantic and time gap in SCADA and process behavior, i.e., SCADA execution does not map to process dynamics nor evolve at similar time scales. We propose BRIDGE to analyze and correlate SCADA and industrial process attacks using domain knowledge to bridge their unique semantic and time evolution. This enables operators to tie malicious SCADA operations to their adverse process effects, which reduces false alarms and improves attack understanding. BRIDGE (i) identifies process constraints violations in SCADA by measuring actuation dependencies in SCADA process-control, and (ii) detects malicious SCADA effects in processes via a physics-informed neural network that embeds generic knowledge of inertial process dynamics. BRIDGE then dynamically aligns both analysis (i and ii) in a time-window that adjusts their time evolution based on process inertial delays. We applied BRIDGE to 11 diverse real-world industrial processes, and adaptive attacks inspired by past events. BRIDGE correlated 98.3% of attacks with 0.8% false positives (FP), compared to 78.3% detection accuracy and 13.7% FP of recent work.
<div id='section'>Paperid: <span id='pid'>1960, <a href='https://arxiv.org/pdf/2311.13491.pdf' target='_blank'>https://arxiv.org/pdf/2311.13491.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Byoungchan Jang, Alan A. Kaptanoglu, Rahul Gaur, Shaowu Pan, Matt Landreman, William Dorland
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13491">Grad-Shafranov equilibria via data-free physics informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A large number of magnetohydrodynamic (MHD) equilibrium calculations are often required for uncertainty quantification, optimization, and real-time diagnostic information, making MHD equilibrium codes vital to the field of plasma physics. In this paper, we explore a method for solving the Grad-Shafranov equation by using Physics-Informed Neural Networks (PINNs). For PINNs, we optimize neural networks by directly minimizing the residual of the PDE as a loss function. We show that PINNs can accurately and effectively solve the Grad-Shafranov equation with several different boundary conditions. We also explore the parameter space by varying the size of the model, the learning rate, and boundary conditions to map various trade-offs such as between reconstruction error and computational speed. Additionally, we introduce a parameterized PINN framework, expanding the input space to include variables such as pressure, aspect ratio, elongation, and triangularity in order to handle a broader range of plasma scenarios within a single network. Parametrized PINNs could be used in future work to solve inverse problems such as shape optimization.
<div id='section'>Paperid: <span id='pid'>1961, <a href='https://arxiv.org/pdf/2311.06580.pdf' target='_blank'>https://arxiv.org/pdf/2311.06580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huynh T. T. Tran, Hieu T. Nguyen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.06580">Modeling Power Systems Dynamics with Symbolic Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, scientific machine learning, particularly physic-informed neural networks (PINNs), has introduced new innovative methods to understanding the differential equations that describe power system dynamics, providing a more efficient alternative to traditional methods. However, using a single neural network to capture patterns of all variables requires a large enough size of networks, leading to a long time of training and still high computational costs. In this paper, we utilize the interfacing of PINNs with symbolic techniques to construct multiple single-output neural networks by taking the loss function apart and integrating it over the relevant domain. Also, we reweigh the factors of the components in the loss function to improve the performance of the network for instability systems. Our results show that the symbolic PINNs provide higher accuracy with significantly fewer parameters and faster training time. By using the adaptive weight method, the symbolic PINNs can avoid the vanishing gradient problem and numerical instability.
<div id='section'>Paperid: <span id='pid'>1962, <a href='https://arxiv.org/pdf/2311.06483.pdf' target='_blank'>https://arxiv.org/pdf/2311.06483.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amanda A Howard, Sarah H Murphy, Shady E Ahmed, Panos Stinis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.06483">Stacked networks improve physics-informed training: applications to neural networks and deep operator networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks and operator networks have shown promise for effectively solving equations modeling physical systems. However, these networks can be difficult or impossible to train accurately for some systems of equations. We present a novel multifidelity framework for stacking physics-informed neural networks and operator networks that facilitates training. We successively build a chain of networks, where the output at one step can act as a low-fidelity input for training the next step, gradually increasing the expressivity of the learned model. The equations imposed at each step of the iterative process can be the same or different (akin to simulated annealing). The iterative (stacking) nature of the proposed method allows us to progressively learn features of a solution that are hard to learn directly. Through benchmark problems including a nonlinear pendulum, the wave equation, and the viscous Burgers equation, we show how stacking can be used to improve the accuracy and reduce the required size of physics-informed neural networks and operator networks.
<div id='section'>Paperid: <span id='pid'>1963, <a href='https://arxiv.org/pdf/2311.04511.pdf' target='_blank'>https://arxiv.org/pdf/2311.04511.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amir H. Khodabakhsh, Seid H. Pourtakdoust
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.04511">Solution of FPK Equation for Stochastic Dynamics Subjected to Additive Gaussian Noise via Deep Learning Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Fokker-Plank-Kolmogorov (FPK) equation is an idealized model representing many stochastic systems commonly encountered in the analysis of stochastic structures as well as many other applications. Its solution thus provides an invaluable insight into the performance of many engineering systems. Despite its great importance, the solution of the FPK equation is still extremely challenging. For systems of practical significance, the FPK equation is usually high dimensional, rendering most of the numerical methods ineffective. In this respect, the present work introduces the FPK-DP Net as a physics-informed network that encodes the physical insights, i.e. the governing constrained differential equations emanated out of physical laws, into a deep neural network. FPK-DP Net is a mesh-free learning method that can solve the density evolution of stochastic dynamics subjected to additive white Gaussian noise without any prior simulation data and can be used as an efficient surrogate model afterward. FPK-DP Net uses the dimension-reduced FPK equation. Therefore, it can be used to address high-dimensional practical problems as well. To demonstrate the potential applicability of the proposed framework, and to study its accuracy and efficacy, numerical implementations on five different benchmark problems are investigated.
<div id='section'>Paperid: <span id='pid'>1964, <a href='https://arxiv.org/pdf/2310.18268.pdf' target='_blank'>https://arxiv.org/pdf/2310.18268.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Felipe A. Lopes, Vasit Sagan, Flavio Esposito
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18268">PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monitoring plantations is crucial for crop management and producing healthy harvests. Unmanned Aerial Vehicles (UAVs) have been used to collect multispectral images that aid in this monitoring. However, given the number of hectares to be monitored and the limitations of flight, plant disease signals become visually clear only in the later stages of plant growth and only if the disease has spread throughout a significant portion of the plantation. This limited amount of relevant data hampers the prediction models, as the algorithms struggle to generalize patterns with unbalanced or unrealistic augmented datasets effectively. To address this issue, we propose PlantPlotGAN, a physics-informed generative model capable of creating synthetic multispectral plot images with realistic vegetation indices. These indices served as a proxy for disease detection and were used to evaluate if our model could help increase the accuracy of prediction models. The results demonstrate that the synthetic imagery generated from PlantPlotGAN outperforms state-of-the-art methods regarding the FrÃ©chet inception distance. Moreover, prediction models achieve higher accuracy metrics when trained with synthetic and original imagery for earlier plant disease detection compared to the training processes based solely on real imagery.
<div id='section'>Paperid: <span id='pid'>1965, <a href='https://arxiv.org/pdf/2310.15343.pdf' target='_blank'>https://arxiv.org/pdf/2310.15343.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>VitÃ³ria Biesek, Pedro Henrique de Almeida Konzen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.15343">Burgers' pinns with implicit euler transfer learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Burgers equation is a well-established test case in the computational modeling of several phenomena such as fluid dynamics, gas dynamics, shock theory, cosmology, and others. In this work, we present the application of Physics-Informed Neural Networks (PINNs) with an implicit Euler transfer learning approach to solve the Burgers equation. The proposed approach consists in seeking a time-discrete solution by a sequence of Artificial Neural Networks (ANNs). At each time step, the previous ANN transfers its knowledge to the next network model, which learns the current time solution by minimizing a loss function based on the implicit Euler approximation of the Burgers equation. The approach is tested for two benchmark problems: the first with an exact solution and the other with an alternative analytical solution. In comparison to the usual PINN models, the proposed approach has the advantage of requiring smaller neural network architectures with similar accurate results and potentially decreasing computational costs.
<div id='section'>Paperid: <span id='pid'>1966, <a href='https://arxiv.org/pdf/2310.10970.pdf' target='_blank'>https://arxiv.org/pdf/2310.10970.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruixian Liu, Peter Gerstoft
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.10970">Deep Learning based Spatially Dependent Acoustical Properties Recovery</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The physics-informed neural network (PINN) is capable of recovering partial differential equation (PDE) coefficients that remain constant throughout the spatial domain directly from physical measurements. In this work, we propose a spatially dependent physics-informed neural network (SD-PINN), which enables the recovery of coefficients in spatially-dependent PDEs using a single neural network, eliminating the requirement for domain-specific physical expertise. We apply the SD-PINN to spatially-dependent wave equation coefficients recovery to reveal the spatial distribution of acoustical properties in the inhomogeneous medium. The proposed method exhibits robustness to noise owing to the incorporation of a loss function for the physical constraint that the assumed PDE must be satisfied. For the coefficients recovery of spatially two-dimensional PDEs, we store the PDE coefficients at all locations in the 2D region of interest into a matrix and incorporate the low-rank assumption for such a matrix to recover the coefficients at locations without available measurements.
<div id='section'>Paperid: <span id='pid'>1967, <a href='https://arxiv.org/pdf/2310.08109.pdf' target='_blank'>https://arxiv.org/pdf/2310.08109.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gerard T. Schuster, Shihang Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08109">Overview of Physics-Informed Machine Learning Inversion of Geophysical Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We review four types of algorithms for physics-informed machine learning (PIML) inversion of geophysical data. The unifying equation is given by the joint objective function $Îµ$:
  \begin{eqnarray} Îµ^{||-PIML}&=&Î»_1 \overbrace{||{\bf W}^{ML}({\bf H}_{\bf w} {\bf d}^{obs}-{\bf m})||^2}^{NN} + Î»_2 \overbrace{{||{\bf W}^{FWI}({\bf L} {\bf m}-{\bf d}^{obs})||^2}}^{FWI} ~+ \nonumber\\ \nonumber\\ && + ~~Regularizer, \label{PIML.eq120} \end{eqnarray}where the optimal model ${\bf m}^*$ and weights $\bf w^*$ minimize $Îµ$. Here, The matrix weights are given by the boldface symbol $\bf W$, and full waveform inversion (FWI) is typically computed using a finite-difference solution of the wave equation, where $\bf L$ represents the forward modeling operation of the wave equation as a function of the model $\bf m$. Also, a fully-connected neural network (NN) is used to compute the model ${\bf H_w}{\bf d}^{obs} \approx \bf m$ from the observed input data ${\bf d}^{obs}$. The selection of weights $Î»_i$ and the NN operations determine one of four different PIML algorithms.
  PIML offers potential advantages over standard FWI through its enhanced ability to avoid local minima and the option to locally train the inversion operator, minimizing the requirement for extensive training data for global applicability. However, the effectiveness of PIML relies on the similarity between the test and trained data. Nevertheless, a possible strategy to overcome this limitation involves initial pretraining of a PIML architecture with data from a broader region, followed by fine-tuning for specific data-a method reminiscent of the way large language models are pretrained and adapted for various tasks.
<div id='section'>Paperid: <span id='pid'>1968, <a href='https://arxiv.org/pdf/2310.04213.pdf' target='_blank'>https://arxiv.org/pdf/2310.04213.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Agnes M. Nakiganda, Spyros Chatzivasileiadis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.04213">Graph Neural Networks for Fast Contingency Analysis of Power Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The successful integration of machine learning models into decision support tools for grid operation hinges on effectively capturing the topological changes in daily operations. Frequent grid reconfigurations and N-k security analyses have to be conducted to ensure a reliable and secure power grid, leading to a vast combinatorial space of possible topologies and operating states. This combinatorial complexity, which increases with grid size, poses a significant computational challenge for traditional solvers. In this paper, we combine Physics-Informed Neural Networks with graph-aware neural network architectures, i.e., a Guided-Dropout (GD) and an Edge-Varying Graph Neural Network (GNN) architecture to learn the set points for a grid that considers all probable single-line reconfigurations (all critical N-1 scenarios) and subsequently apply the trained models to N-k scenarios. We demonstrate how incorporating the underlying physical equations for the network equations within the training procedure of the GD and the GNN architectures performs with N-1, N-2, and N-3 case studies. Using the AC Power Flow as a guiding application, we test our methods on the 6-bus, 24-bus, 57-bus, and 118-bus systems. We find that GNN not only achieves the task of contingency screening with satisfactory accuracy but does this up to 400 times faster than the Newton-Raphson power flow solver. Moreover, our results provide a comparison of the GD and GNN models in terms of accuracy and computational speed and provide recommendations on their adoption for contingency analysis of power systems.
<div id='section'>Paperid: <span id='pid'>1969, <a href='https://arxiv.org/pdf/2310.01649.pdf' target='_blank'>https://arxiv.org/pdf/2310.01649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>KaiChieh Lo, Daniel Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.01649">On Training Derivative-Constrained Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We refer to the setting where the (partial) derivatives of a neural network's (NN's) predictions with respect to its inputs are used as additional training signal as a derivative-constrained (DC) NN. This situation is common in physics-informed settings in the natural sciences. We propose an integrated RELU (IReLU) activation function to improve training of DC NNs. We also investigate denormalization and label rescaling to help stabilize DC training. We evaluate our methods on physics-informed settings including quantum chemistry and Scientific Machine Learning (SciML) tasks. We demonstrate that existing architectures with IReLU activations combined with denormalization and label rescaling better incorporate training signal provided by derivative constraints.
<div id='section'>Paperid: <span id='pid'>1970, <a href='https://arxiv.org/pdf/2310.00728.pdf' target='_blank'>https://arxiv.org/pdf/2310.00728.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jules Authier, Rabab Haider, Anuradha Annaswamy, Florian Dorfler
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.00728">Physics-Informed Graph Neural Network for Dynamic Reconfiguration of Power Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To maintain a reliable grid we need fast decision-making algorithms for complex problems like Dynamic Reconfiguration (DyR). DyR optimizes distribution grid switch settings in real-time to minimize grid losses and dispatches resources to supply loads with available generation. DyR is a mixed-integer problem and can be computationally intractable to solve for large grids and at fast timescales. We propose GraPhyR, a Physics-Informed Graph Neural Network (GNNs) framework tailored for DyR. We incorporate essential operational and connectivity constraints directly within the GNN framework and train it end-to-end. Our results show that GraPhyR is able to learn to optimize the DyR task.
<div id='section'>Paperid: <span id='pid'>1971, <a href='https://arxiv.org/pdf/2310.00172.pdf' target='_blank'>https://arxiv.org/pdf/2310.00172.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pasquale Ambrosio, Salvatore Cuomo, Mariapia De Rosa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.00172">A physics-informed deep learning approach for solving strongly degenerate parabolic problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, Scientific Machine Learning (SciML) methods for solving partial differential equations (PDEs) have gained increasing popularity. Within such a paradigm, Physics-Informed Neural Networks (PINNs) are novel deep learning frameworks for solving initial-boundary value problems involving nonlinear PDEs. Recently, PINNs have shown promising results in several application fields. Motivated by applications to gas filtration problems, here we present and evaluate a PINN-based approach to predict solutions to strongly degenerate parabolic problems with asymptotic structure of Laplacian type. To the best of our knowledge, this is one of the first papers demonstrating the efficacy of the PINN framework for solving such kind of problems. In particular, we estimate an appropriate approximation error for some test problems whose analytical solutions are fortunately known. The numerical experiments discussed include two and three-dimensional spatial domains, emphasizing the effectiveness of this approach in predicting accurate solutions.
<div id='section'>Paperid: <span id='pid'>1972, <a href='https://arxiv.org/pdf/2309.17343.pdf' target='_blank'>https://arxiv.org/pdf/2309.17343.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng Zheng, Guangyuan Zhao, Peter T. C. So
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.17343">Neural Lithography: Close the Design-to-Manufacturing Gap in Computational Optics with a 'Real2Sim' Learned Photolithography Simulator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce neural lithography to address the 'design-to-manufacturing' gap in computational optics. Computational optics with large design degrees of freedom enable advanced functionalities and performance beyond traditional optics. However, the existing design approaches often overlook the numerical modeling of the manufacturing process, which can result in significant performance deviation between the design and the fabricated optics. To bridge this gap, we, for the first time, propose a fully differentiable design framework that integrates a pre-trained photolithography simulator into the model-based optical design loop. Leveraging a blend of physics-informed modeling and data-driven training using experimentally collected datasets, our photolithography simulator serves as a regularizer on fabrication feasibility during design, compensating for structure discrepancies introduced in the lithography process. We demonstrate the effectiveness of our approach through two typical tasks in computational optics, where we design and fabricate a holographic optical element (HOE) and a multi-level diffractive lens (MDL) using a two-photon lithography system, showcasing improved optical performance on the task-specific metrics.
<div id='section'>Paperid: <span id='pid'>1973, <a href='https://arxiv.org/pdf/2309.16729.pdf' target='_blank'>https://arxiv.org/pdf/2309.16729.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sidney Besnard, FrÃ©dÃ©ric Jurie, Jalal M. Fadili
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16729">SimPINNs: Simulation-Driven Physics-Informed Neural Networks for Enhanced Performance in Nonlinear Inverse Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel approach to solve inverse problems by leveraging deep learning techniques. The objective is to infer unknown parameters that govern a physical system based on observed data. We focus on scenarios where the underlying forward model demonstrates pronounced nonlinear behaviour, and where the dimensionality of the unknown parameter space is substantially smaller than that of the observations. Our proposed method builds upon physics-informed neural networks (PINNs) trained with a hybrid loss function that combines observed data with simulated data generated by a known (approximate) physical model. Experimental results on an orbit restitution problem demonstrate that our approach surpasses the performance of standard PINNs, providing improved accuracy and robustness.
<div id='section'>Paperid: <span id='pid'>1974, <a href='https://arxiv.org/pdf/2309.16725.pdf' target='_blank'>https://arxiv.org/pdf/2309.16725.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hussam Alhussein, Mohammed Khasawneh, Mohammed F. Daqaq
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16725">Physics-Informed Solution of The Stationary Fokker-Plank Equation for a Class of Nonlinear Dynamical Systems: An Evaluation Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Fokker-Planck (FP) equation is a linear partial differential equation which governs the temporal and spatial evolution of the probability density function (PDF) associated with the response of stochastic dynamical systems. An exact analytical solution of the FP equation is only available for a limited subset of dynamical systems. Semi-analytical methods are available for larger, yet still a small subset of systems, while traditional computational methods; e.g. Finite Elements and Finite Difference require dividing the computational domain into a grid of discrete points, which incurs significant computational costs for high-dimensional systems. Physics-informed learning offers a potentially powerful alternative to traditional computational schemes. To evaluate its potential, we present a data-free, physics-informed neural network (PINN) framework to solve the FP equation for a class of nonlinear stochastic dynamical systems. In particular, through several examples concerning the stochastic response of the Duffing, Van der Pol, and the Duffing-Van der Pol oscillators, we assess the ability and accuracy of the PINN framework in $i)$ predicting the PDF under the combined effect of additive and multiplicative noise, $ii)$ capturing P-bifurcations of the PDF, and $iii)$ effectively treating high-dimensional systems. Through comparisons with Monte-Carlo simulations and the available literature, we show that PINN can effectively address all of the afore-described points. We also demonstrate that the computational time associated with the PINN solution can be substantially reduced by using transfer learning.
<div id='section'>Paperid: <span id='pid'>1975, <a href='https://arxiv.org/pdf/2309.16579.pdf' target='_blank'>https://arxiv.org/pdf/2309.16579.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Georg Kordowich, Johann Jaeger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16579">A Physics Informed Machine Learning Method for Power System Model Parameter Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a gradient descent based optimization method that relies on automatic differentiation for the computation of gradients. The method uses tools and techniques originally developed in the field of artificial neural networks and applies them to power system simulations. It can be used as a one-shot physics informed machine learning approach for the identification of uncertain power system simulation parameters. Additionally, it can optimize parameters with respect to a desired system behavior. The paper focuses on presenting the theoretical background and showing exemplary use-cases for both parameter identification and optimization using a single machine infinite busbar system. The results imply a generic applicability for a wide range of problems.
<div id='section'>Paperid: <span id='pid'>1976, <a href='https://arxiv.org/pdf/2309.16391.pdf' target='_blank'>https://arxiv.org/pdf/2309.16391.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Flavio Figueiredo, JosÃ© Geraldo Fernandes, Jackson Silva, Renato M. AssunÃ§Ã£o
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16391">2-Cats: 2D Copula Approximating Transforms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Copulas are powerful statistical tools for capturing dependencies across data dimensions. Applying Copulas involves estimating independent marginals, a straightforward task, followed by the much more challenging task of determining a single copulating function, $C$, that links these marginals. For bivariate data, a copula takes the form of a two-increasing function $C: (u,v)\in \mathbb{I}^2 \rightarrow \mathbb{I}$, where $\mathbb{I} = [0, 1]$. This paper proposes 2-Cats, a Neural Network (NN) model that learns two-dimensional Copulas without relying on specific Copula families (e.g., Archimedean). Furthermore, via both theoretical properties of the model and a Lagrangian training approach, we show that 2-Cats meets the desiderata of Copula properties. Moreover, inspired by the literature on Physics-Informed Neural Networks and Sobolev Training, we further extend our training strategy to learn not only the output of a Copula but also its derivatives. Our proposed method exhibits superior performance compared to the state-of-the-art across various datasets while respecting (provably for most and approximately for a single other) properties of C.
<div id='section'>Paperid: <span id='pid'>1977, <a href='https://arxiv.org/pdf/2309.10788.pdf' target='_blank'>https://arxiv.org/pdf/2309.10788.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehdi Jabbari Zideh, Paroma Chatterjee, Anurag K. Srivastava
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.10788">Physics-Informed Machine Learning for Data Anomaly Detection, Classification, Localization, and Mitigation: A Review, Challenges, and Path Forward</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advancements in digital automation for smart grids have led to the installation of measurement devices like phasor measurement units (PMUs), micro-PMUs ($Î¼$-PMUs), and smart meters. However, a large amount of data collected by these devices brings several challenges as control room operators need to use this data with models to make confident decisions for reliable and resilient operation of the cyber-power systems. Machine-learning (ML) based tools can provide a reliable interpretation of the deluge of data obtained from the field. For the decision-makers to ensure reliable network operation under all operating conditions, these tools need to identify solutions that are feasible and satisfy the system constraints, while being efficient, trustworthy, and interpretable. This resulted in the increasing popularity of physics-informed machine learning (PIML) approaches, as these methods overcome challenges that model-based or data-driven ML methods face in silos. This work aims at the following: a) review existing strategies and techniques for incorporating underlying physical principles of the power grid into different types of ML approaches (supervised/semi-supervised learning, unsupervised learning, and reinforcement learning (RL)); b) explore the existing works on PIML methods for anomaly detection, classification, localization, and mitigation in power transmission and distribution systems, c) discuss improvements in existing methods through consideration of potential challenges while also addressing the limitations to make them suitable for real-world applications.
<div id='section'>Paperid: <span id='pid'>1978, <a href='https://arxiv.org/pdf/2309.06628.pdf' target='_blank'>https://arxiv.org/pdf/2309.06628.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Atticus Beachy, Harok Bae, Jose Camberos, Ramana Grandhi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.06628">Epistemic Modeling Uncertainty of Rapid Neural Network Ensembles for Adaptive Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Emulator embedded neural networks, which are a type of physics informed neural network, leverage multi-fidelity data sources for efficient design exploration of aerospace engineering systems. Multiple realizations of the neural network models are trained with different random initializations. The ensemble of model realizations is used to assess epistemic modeling uncertainty caused due to lack of training samples. This uncertainty estimation is crucial information for successful goal-oriented adaptive learning in an aerospace system design exploration. However, the costs of training the ensemble models often become prohibitive and pose a computational challenge, especially when the models are not trained in parallel during adaptive learning. In this work, a new type of emulator embedded neural network is presented using the rapid neural network paradigm. Unlike the conventional neural network training that optimizes the weights and biases of all the network layers by using gradient-based backpropagation, rapid neural network training adjusts only the last layer connection weights by applying a linear regression technique. It is found that the proposed emulator embedded neural network trains near-instantaneously, typically without loss of prediction accuracy. The proposed method is demonstrated on multiple analytical examples, as well as an aerospace flight parameter study of a generic hypersonic vehicle.
<div id='section'>Paperid: <span id='pid'>1979, <a href='https://arxiv.org/pdf/2309.02935.pdf' target='_blank'>https://arxiv.org/pdf/2309.02935.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivo Daniel, Andrea Cominola
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02935">Estimating irregular water demands with physics-informed machine learning to inform leakage detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Leakages in drinking water distribution networks pose significant challenges to water utilities, leading to infrastructure failure, operational disruptions, environmental hazards, property damage, and economic losses. The timely identification and accurate localisation of such leakages is paramount for utilities to mitigate these unwanted effects. However, implementation of algorithms for leakage detection is limited in practice by requirements of either hydraulic models or large amounts of training data. Physics-informed machine learning can utilise hydraulic information thereby circumventing both limitations. In this work, we present a physics-informed machine learning algorithm that analyses pressure data and therefrom estimates unknown irregular water demands via a fully connected neural network, ultimately leveraging the Bernoulli equation and effectively linearising the leakage detection problem. Our algorithm is tested on data from the L-Town benchmark network, and results indicate a good capability for estimating most irregular demands, with R2 larger than 0.8. Identification results for leakages under the presence of irregular demands could be improved by a factor of 5.3 for abrupt leaks and a factor of 3.0 for incipient leaks when compared the results disregarding irregular demands.
<div id='section'>Paperid: <span id='pid'>1980, <a href='https://arxiv.org/pdf/2309.02589.pdf' target='_blank'>https://arxiv.org/pdf/2309.02589.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steven Zhou, Xiaojing Ye
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02589">Approximating High-Dimensional Minimal Surfaces with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we compute numerical approximations of the minimal surfaces, an essential type of Partial Differential Equation (PDE), in higher dimensions. Classical methods cannot handle it in this case because of the Curse of Dimensionality, where the computational cost of these methods increases exponentially fast in response to higher problem dimensions, far beyond the computing capacity of any modern supercomputers. Only in the past few years have machine learning researchers been able to mitigate this problem. The solution method chosen here is a model known as a Physics-Informed Neural Network (PINN) which trains a deep neural network (DNN) to solve the minimal surface PDE. It can be scaled up into higher dimensions and trained relatively quickly even on a laptop with no GPU. Due to the inability to view the high-dimension output, our data is presented as snippets of a higher-dimension shape with enough fixed axes so that it is viewable with 3-D graphs. Not only will the functionality of this method be tested, but we will also explore potential limitations in the method's performance.
<div id='section'>Paperid: <span id='pid'>1981, <a href='https://arxiv.org/pdf/2308.16089.pdf' target='_blank'>https://arxiv.org/pdf/2308.16089.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ujjal Kr Dutta, Aldo Lipani, Chuan Wang, Yukun Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16089">Application of Zone Method based Physics-Informed Neural Networks in Reheating Furnaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation Industries (FIs) constitute glass, metals, cement, ceramics, bulk chemicals, paper, steel, etc. and provide crucial, foundational materials for a diverse set of economically relevant industries: automobiles, machinery, construction, household appliances, chemicals, etc. Reheating furnaces within the manufacturing chain of FIs are energy-intensive. Accurate and real-time prediction of underlying temperatures in reheating furnaces has the potential to reduce the overall heating time, thereby controlling the energy consumption for achieving the Net-Zero goals in FIs. In this paper, we cast this prediction as a regression task and explore neural networks due to their inherent capability of being effective and efficient, given adequate data. However, due to the infeasibility of achieving good-quality real data in scenarios like reheating furnaces, classical Hottel's zone method based computational model has been used to generate data for model training. To further enhance the Out-Of-Distribution generalization capability of the trained model, we propose a Physics-Informed Neural Network (PINN) by incorporating prior physical knowledge using a set of novel Energy-Balance regularizers.
<div id='section'>Paperid: <span id='pid'>1982, <a href='https://arxiv.org/pdf/2308.15640.pdf' target='_blank'>https://arxiv.org/pdf/2308.15640.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyuan Song, Hanxun Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.15640">Identifying Constitutive Parameters for Complex Hyperelastic Materials using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Identifying constitutive parameters in engineering and biological materials, particularly those with intricate geometries and mechanical behaviors, remains a longstanding challenge. The recent advent of Physics-Informed Neural Networks (PINNs) offers promising solutions, but current frameworks are often limited to basic constitutive laws and encounter practical constraints when combined with experimental data. In this paper, we introduce a robust PINN-based framework designed to identify material parameters for soft materials, specifically those exhibiting complex constitutive behaviors, under large deformation in plane stress conditions. Distinctively, our model emphasizes training PINNs with multi-modal synthetic experimental datasets consisting of full-field deformation and loading history, ensuring algorithm robustness even with noisy data. Our results reveal that the PINNs framework can accurately identify constitutive parameters of the incompressible Arruda-Boyce model for samples with intricate geometries, maintaining an error below 5%, even with an experimental noise level of 5%. We believe our framework provides a robust modulus identification approach for complex solids, especially for those with geometrical and constitutive complexity.
<div id='section'>Paperid: <span id='pid'>1983, <a href='https://arxiv.org/pdf/2308.14958.pdf' target='_blank'>https://arxiv.org/pdf/2308.14958.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ismael Ben-Yelun, Ahmet Oguzhan Yuksel, Fehmi Cirak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.14958">Robust topology optimisation of lattice structures with spatially correlated uncertainties</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The uncertainties in material and other properties of structures are usually spatially correlated. We introduce an efficient technique for representing and processing spatially correlated random fields in robust topology optimisation of lattice structures. Robust optimisation considers the statistics of the structural response to obtain a design whose performance is less sensitive to the specific realisation of the random field. We represent Gaussian random fields on lattices by leveraging the established link between random fields and stochastic partial differential equations (SPDEs). It is known that the precision matrix, i.e. the inverse of the covariance matrix, of a random field with MatÃ©rn covariance is equal to the finite element stiffness matrix of a possibly fractional PDE with a second-order elliptic operator. We consider the discretisation of the PDE on the lattice to obtain a random field which, by design, considers its geometry and connectivity. The so-obtained random field can be interpreted as a physics-informed prior by the hypothesis that the elliptic SPDE models the physical processes occurring during manufacturing, like heat and mass diffusion. Although the proposed approach is general, we demonstrate its application to lattices modelled as pin-jointed trusses with uncertainties in member Young's moduli. We consider as a cost function the weighted sum of the expectation and standard deviation of the structural compliance. To compute the expectation and standard deviation and their gradients with respect to member cross-sections we use a first-order Taylor series approximation. The cost function and its gradient are computed using only sparse matrix operations. We demonstrate the efficiency of the proposed approach using several lattice examples with isotropic, anisotropic and non-stationary random fields and up to eighty thousand random and optimisation variables.
<div id='section'>Paperid: <span id='pid'>1984, <a href='https://arxiv.org/pdf/2308.13993.pdf' target='_blank'>https://arxiv.org/pdf/2308.13993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinhong Feng, Yongzhi Zhang, Rui Xiong, Chun Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.13993">Comprehensive performance comparison among different types of features in data-driven battery state of health estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Battery state of health (SOH), which informs the maximal available capacity of the battery, is a key indicator of battery aging failure. Accurately estimating battery SOH is a vital function of the battery management system that remains to be addressed. In this study, a physics-informed Gaussian process regression (GPR) model is developed for battery SOH estimation, with the performance being systematically compared with that of different types of features and machine learning (ML) methods. The method performance is validated based on 58826 cycling data units of 118 cells. Experimental results show that the physics-driven ML generally estimates more accurate SOH than other non-physical features under different scenarios. The physical features-based GPR predicts battery SOH with the errors being less than 1.1% based on 10 to 20 mins' relaxation data. And the high robustness and generalization capability of the methodology is also validated against different ratios of training and test data under unseen conditions. Results also highlight the more effective capability of knowledge transfer between different types of batteries with the physical features and GPR. This study demonstrates the excellence of physical features in indicating the state evolution of complex systems, and the improved indication performance of these features by combining a suitable ML method.
<div id='section'>Paperid: <span id='pid'>1985, <a href='https://arxiv.org/pdf/2308.13222.pdf' target='_blank'>https://arxiv.org/pdf/2308.13222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Krzysztof M. Graczyk, Kornel Witkowski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.13222">Bayesian Reasoning for Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present the application of the physics-informed neural network (PINN) approach in Bayesian formulation. We have adopted the Bayesian neural network framework to obtain posterior densities from Laplace approximation. For each model or fit, the evidence is computed, which is a measure that classifies the hypothesis. The optimal solution is the one with the highest value of evidence. We have proposed a modification of the Bayesian algorithm to obtain hyperparameters of the model. We have shown that within the Bayesian framework, one can obtain the relative weights between the boundary and equation contributions to the total loss. Presented method leads to predictions comparable to those obtained by sampling from the posterior distribution within the Hybrid Monte Carlo algorithm (HMC). We have solved heat, wave, and Burger's equations, and the results obtained are in agreement with the exact solutions, demonstrating the effectiveness of our approach. In Burger's equation problem, we have demonstrated that the framework can combine information from differential equations and potential measurements. All solutions are provided with uncertainties (induced by the model's parameter dependence) computed within the Bayesian framework.
<div id='section'>Paperid: <span id='pid'>1986, <a href='https://arxiv.org/pdf/2308.12716.pdf' target='_blank'>https://arxiv.org/pdf/2308.12716.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>T. Sahin, M. von Danwitz, A. Popp
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12716">Solving Forward and Inverse Problems of Contact Mechanics using Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper explores the ability of physics-informed neural networks (PINNs) to solve forward and inverse problems of contact mechanics for small deformation elasticity. We deploy PINNs in a mixed-variable formulation enhanced by output transformation to enforce Dirichlet and Neumann boundary conditions as hard constraints. Inequality constraints of contact problems, namely Karush-Kuhn-Tucker (KKT) type conditions, are enforced as soft constraints by incorporating them into the loss function during network training. To formulate the loss function contribution of KKT constraints, existing approaches applied to elastoplasticity problems are investigated and we explore a nonlinear complementarity problem (NCP) function, namely Fischer-Burmeister, which possesses advantageous characteristics in terms of optimization. Based on the Hertzian contact problem, we show that PINNs can serve as pure partial differential equation (PDE) solver, as data-enhanced forward model, as inverse solver for parameter identification, and as fast-to-evaluate surrogate model. Furthermore, we demonstrate the importance of choosing proper hyperparameters, e.g. loss weights, and a combination of Adam and L-BFGS-B optimizers aiming for better results in terms of accuracy and training time.
<div id='section'>Paperid: <span id='pid'>1987, <a href='https://arxiv.org/pdf/2308.12621.pdf' target='_blank'>https://arxiv.org/pdf/2308.12621.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinqi Zhang, Jihao Shi, Junjie Li, Xinyan Huang, Fu Xiao, Qiliang Wang, Asif Sohail Usmani, Guoming Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12621">Hydrogen jet diffusion modeling by using physics-informed graph neural network and sparsely-distributed sensor data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficient modeling of jet diffusion during accidental release is critical for operation and maintenance management of hydrogen facilities. Deep learning has proven effective for concentration prediction in gas jet diffusion scenarios. Nonetheless, its reliance on extensive simulations as training data and its potential disregard for physical laws limit its applicability to unseen accidental scenarios. Recently, physics-informed neural networks (PINNs) have emerged to reconstruct spatial information by using data from sparsely-distributed sensors which are easily collected in real-world applications. However, prevailing approaches use the fully-connected neural network as the backbone without considering the spatial dependency of sensor data, which reduces the accuracy of concentration prediction. This study introduces the physics-informed graph deep learning approach (Physic_GNN) for efficient and accurate hydrogen jet diffusion prediction by using sparsely-distributed sensor data. Graph neural network (GNN) is used to model the spatial dependency of such sensor data by using graph nodes at which governing equations describing the physical law of hydrogen jet diffusion are immediately solved. The computed residuals are then applied to constrain the training process. Public experimental data of hydrogen jet is used to compare the accuracy and efficiency between our proposed approach Physic_GNN and state-of-the-art PINN. The results demonstrate our Physic_GNN exhibits higher accuracy and physical consistency of centerline concentration prediction given sparse concentration compared to PINN and more efficient compared to OpenFOAM. The proposed approach enables accurate and robust real-time spatial consequence reconstruction and underlying physical mechanisms analysis by using sparse sensor data.
<div id='section'>Paperid: <span id='pid'>1988, <a href='https://arxiv.org/pdf/2308.12299.pdf' target='_blank'>https://arxiv.org/pdf/2308.12299.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xing-Yu Ma, Shaogang Hao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12299">Inverse Lithography Physics-informed Deep Neural Level Set for Mask Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As the feature size of integrated circuits continues to decrease, optical proximity correction (OPC) has emerged as a crucial resolution enhancement technology for ensuring high printability in the lithography process. Recently, level set-based inverse lithography technology (ILT) has drawn considerable attention as a promising OPC solution, showcasing its powerful pattern fidelity, especially in advanced process. However, massive computational time consumption of ILT limits its applicability to mainly correcting partial layers and hotspot regions. Deep learning (DL) methods have shown great potential in accelerating ILT. However, lack of domain knowledge of inverse lithography limits the ability of DL-based algorithms in process window (PW) enhancement and etc. In this paper, we propose an inverse lithography physics-informed deep neural level set (ILDLS) approach for mask optimization. This approach utilizes level set based-ILT as a layer within the DL framework and iteratively conducts mask prediction and correction to significantly enhance printability and PW in comparison with results from pure DL and ILT. With this approach, computation time is reduced by a few orders of magnitude versus ILT. By gearing up DL with knowledge of inverse lithography physics, ILDLS provides a new and efficient mask optimization solution.
<div id='section'>Paperid: <span id='pid'>1989, <a href='https://arxiv.org/pdf/2308.11133.pdf' target='_blank'>https://arxiv.org/pdf/2308.11133.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Sevcovic, Cyril Izuchukwu Udeani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.11133">Learning the solution operator of a nonlinear parabolic equation using physics informed deep operator network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study focuses on addressing the challenges of solving analytically intractable differential equations that arise in scientific and engineering fields such as Hamilton-Jacobi-Bellman. Traditional numerical methods and neural network approaches for solving such equations often require independent simulation or retraining when the underlying parameters change. To overcome this, this study employs a physics-informed DeepONet (PI-DeepONet) to approximate the solution operator of a nonlinear parabolic equation. PI-DeepONet integrates known physics into a deep neural network, which learns the solution of the PDE.
<div id='section'>Paperid: <span id='pid'>1990, <a href='https://arxiv.org/pdf/2308.09571.pdf' target='_blank'>https://arxiv.org/pdf/2308.09571.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Monika Nagy-Huber, Volker Roth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09571">Physics-Informed Boundary Integral Networks (PIBI-Nets): A Data-Driven Approach for Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial differential equations (PDEs) are widely used to describe relevant phenomena in dynamical systems. In real-world applications, we commonly need to combine formal PDE models with (potentially noisy) observations. This is especially relevant in settings where we lack information about boundary or initial conditions, or where we need to identify unknown model parameters. In recent years, Physics-Informed Neural Networks (PINNs) have become a popular tool for this kind of problems. In high-dimensional settings, however, PINNs often suffer from computational problems because they usually require dense collocation points over the entire computational domain. To address this problem, we present Physics-Informed Boundary Integral Networks (PIBI-Nets) as a data-driven approach for solving PDEs in one dimension less than the original problem space. PIBI-Nets only require points at the computational domain boundary, while still achieving highly accurate results. Moreover, PIBI-Nets clearly outperform PINNs in several practical settings. Exploiting elementary properties of fundamental solutions of linear differential operators, we present a principled and simple way to handle point sources in inverse problems. We demonstrate the excellent performance of PIBI- Nets for the Laplace and Poisson equations, both on artificial datasets and within a real-world application concerning the reconstruction of groundwater flows.
<div id='section'>Paperid: <span id='pid'>1991, <a href='https://arxiv.org/pdf/2308.08873.pdf' target='_blank'>https://arxiv.org/pdf/2308.08873.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahyar Jahaninasab, Mohamad Ali Bijarchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08873">Enhancing Convergence Speed with Feature-Enforcing Physics-Informed Neural Networks: Utilizing Boundary Conditions as Prior Knowledge for Faster Convergence</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study introduces an accelerated training method for Vanilla Physics-Informed-Neural-Networks (PINN) addressing three factors that imbalance the loss function: initial weight state of a neural network, domain to boundary points ratio, and loss weighting factor. We propose a novel two-stage training method. During the initial stage, we create a unique loss function using a subset of boundary conditions and partial differential equation terms. Furthermore, we introduce preprocessing procedures that aim to decrease the variance during initialization and choose domain points according to the initial weight state of various neural networks. The second phase resembles Vanilla-PINN training, but a portion of the random weights are substituted with weights from the first phase. This implies that the neural network's structure is designed to prioritize the boundary conditions, subsequently affecting the overall convergence. Three benchmarks are utilized: two-dimensional flow over a cylinder, an inverse problem of inlet velocity determination, and the Burger equation. It is found that incorporating weights generated in the first training phase into the structure of a neural network neutralizes the effects of imbalance factors. For instance, in the first benchmark, as a result of our process, the second phase of training is balanced across a wide range of ratios and is not affected by the initial state of weights, while the Vanilla-PINN failed to converge in most cases. Lastly, the initial training process not only eliminates the need for hyperparameter tuning to balance the loss function, but it also outperforms the Vanilla-PINN in terms of speed.
<div id='section'>Paperid: <span id='pid'>1992, <a href='https://arxiv.org/pdf/2308.08655.pdf' target='_blank'>https://arxiv.org/pdf/2308.08655.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Faisal Nissar Malik, James Ricles, Masoud Yari, Malik Arsala Nissar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08655">Physics Informed Recurrent Neural Networks for Seismic Response Evaluation of Nonlinear Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamic response evaluation in structural engineering is the process of determining the response of a structure, such as member forces, node displacements, etc when subjected to dynamic loads such as earthquakes, wind, or impact. This is an important aspect of structural analysis, as it enables engineers to assess structural performance under extreme loading conditions and make informed decisions about the design and safety of the structure. Conventional methods for dynamic response evaluation involve numerical simulations using finite element analysis (FEA), where the structure is modeled using finite elements, and the equations of motion are solved numerically. Although effective, this approach can be computationally intensive and may not be suitable for real-time applications. To address these limitations, recent advancements in machine learning, specifically artificial neural networks, have been applied to dynamic response evaluation in structural engineering. These techniques leverage large data sets and sophisticated algorithms to learn the complex relationship between inputs and outputs, making them ideal for such problems. In this paper, a novel approach is proposed for evaluating the dynamic response of multi-degree-of-freedom (MDOF) systems using physics-informed recurrent neural networks. The focus of this paper is to evaluate the seismic (earthquake) response of nonlinear structures. The predicted response will be compared to state-of-the-art methods such as FEA to assess the efficacy of the physics-informed RNN model.
<div id='section'>Paperid: <span id='pid'>1993, <a href='https://arxiv.org/pdf/2308.08179.pdf' target='_blank'>https://arxiv.org/pdf/2308.08179.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qinghui Nie, Jishun Ou, Haiyang Zhang, Jiawei Lu, Shen Li, Haotian Shi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08179">A Robust Integrated Multi-Strategy Bus Control System via Deep Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An efficient urban bus control system has the potential to significantly reduce travel delays and streamline the allocation of transportation resources, thereby offering enhanced and user-friendly transit services to passengers. However, bus operation efficiency can be impacted by bus bunching. This problem is notably exacerbated when the bus system operates along a signalized corridor with unpredictable travel demand. To mitigate this challenge, we introduce a multi-strategy fusion approach for the longitudinal control of connected and automated buses. The approach is driven by a physics-informed deep reinforcement learning (DRL) algorithm and takes into account a variety of traffic conditions along urban signalized corridors. Taking advantage of connected and autonomous vehicle (CAV) technology, the proposed approach can leverage real-time information regarding bus operating conditions and road traffic environment. By integrating the aforementioned information into the DRL-based bus control framework, our designed physics-informed DRL state fusion approach and reward function efficiently embed prior physics and leverage the merits of equilibrium and consensus concepts from control theory. This integration enables the framework to learn and adapt multiple control strategies to effectively manage complex traffic conditions and fluctuating passenger demands. Three control variables, i.e., dwell time at stops, speed between stations, and signal priority, are formulated to minimize travel duration and ensure bus stability with the aim of avoiding bus bunching. We present simulation results to validate the effectiveness of the proposed approach, underlining its superior performance when subjected to sensitivity analysis, specifically considering factors such as traffic volume, desired speed, and traffic signal conditions.
<div id='section'>Paperid: <span id='pid'>1994, <a href='https://arxiv.org/pdf/2308.08010.pdf' target='_blank'>https://arxiv.org/pdf/2308.08010.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sayantan Auddy, Ramit Dey, Neal J. Turner, Shantanu Basu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08010">GRINN: A Physics-Informed Neural Network for solving hydrodynamic systems in the presence of self-gravity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modeling self-gravitating gas flows is essential to answering many fundamental questions in astrophysics. This spans many topics including planet-forming disks, star-forming clouds, galaxy formation, and the development of large-scale structures in the Universe. However, the nonlinear interaction between gravity and fluid dynamics offers a formidable challenge to solving the resulting time-dependent partial differential equations (PDEs) in three dimensions (3D). By leveraging the universal approximation capabilities of a neural network within a mesh-free framework, physics informed neural networks (PINNs) offer a new way of addressing this challenge. We introduce the gravity-informed neural network (GRINN), a PINN-based code, to simulate 3D self-gravitating hydrodynamic systems. Here, we specifically study gravitational instability and wave propagation in an isothermal gas. Our results match a linear analytic solution to within 1\% in the linear regime and a conventional grid code solution to within 5\% as the disturbance grows into the nonlinear regime. We find that the computation time of the GRINN does not scale with the number of dimensions. This is in contrast to the scaling of the grid-based code for the hydrodynamic and self-gravity calculations as the number of dimensions is increased. Our results show that the GRINN computation time is longer than the grid code in one- and two- dimensional calculations but is an order of magnitude lesser than the grid code in 3D with similar accuracy. Physics-informed neural networks like GRINN thus show promise for advancing our ability to model 3D astrophysical flows.
<div id='section'>Paperid: <span id='pid'>1995, <a href='https://arxiv.org/pdf/2308.07441.pdf' target='_blank'>https://arxiv.org/pdf/2308.07441.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lianfa Li, Roxana Khalili, Frederick Lurmann, Nathan Pavlovic, Jun Wu, Yan Xu, Yisi Liu, Karl O'Sharkey, Beate Ritz, Luke Oman, Meredith Franklin, Theresa Bastain, Shohreh F. Farzan, Carrie Breton, Rima Habre
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.07441">Physics-Informed Deep Learning to Reduce the Bias in Joint Prediction of Nitrogen Oxides</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Atmospheric nitrogen oxides (NOx) primarily from fuel combustion have recognized acute and chronic health and environmental effects. Machine learning (ML) methods have significantly enhanced our capacity to predict NOx concentrations at ground-level with high spatiotemporal resolution but may suffer from high estimation bias since they lack physical and chemical knowledge about air pollution dynamics. Chemical transport models (CTMs) leverage this knowledge; however, accurate predictions of ground-level concentrations typically necessitate extensive post-calibration. Here, we present a physics-informed deep learning framework that encodes advection-diffusion mechanisms and fluid dynamics constraints to jointly predict NO2 and NOx and reduce ML model bias by 21-42%. Our approach captures fine-scale transport of NO2 and NOx, generates robust spatial extrapolation, and provides explicit uncertainty estimation. The framework fuses knowledge-driven physicochemical principles of CTMs with the predictive power of ML for air quality exposure, health, and policy applications. Our approach offers significant improvements over purely data-driven ML methods and has unprecedented bias reduction in joint NO2 and NOx prediction.
<div id='section'>Paperid: <span id='pid'>1996, <a href='https://arxiv.org/pdf/2308.06447.pdf' target='_blank'>https://arxiv.org/pdf/2308.06447.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Milad Ramezankhani, Abbas S. Milani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06447">A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have gained popularity in solving nonlinear partial differential equations (PDEs) via integrating physical laws into the training of neural networks, making them superior in many scientific and engineering applications. However, conventional PINNs still fall short in accurately approximating the solution of complex systems with strong nonlinearity, especially in long temporal domains. Besides, since PINNs are designed to approximate a specific realization of a given PDE system, they lack the necessary generalizability to efficiently adapt to new system configurations. This entails computationally expensive re-training from scratch for any new change in the system. To address these shortfalls, in this work a novel sequential meta-transfer (SMT) learning framework is proposed, offering a unified solution for both fast training and efficient adaptation of PINNs in highly nonlinear systems with long temporal domains. Specifically, the framework decomposes PDE's time domain into smaller time segments to create "easier" PDE problems for PINNs training. Then for each time interval, a meta-learner is assigned and trained to achieve an optimal initial state for rapid adaptation to a range of related tasks. Transfer learning principles are then leveraged across time intervals to further reduce the computational cost.Through a composites autoclave processing case study, it is shown that SMT is clearly able to enhance the adaptability of PINNs while significantly reducing computational cost, by a factor of 100.
<div id='section'>Paperid: <span id='pid'>1997, <a href='https://arxiv.org/pdf/2308.05423.pdf' target='_blank'>https://arxiv.org/pdf/2308.05423.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dimitrios Gazoulis, Ioannis Gkanis, Charalambos G. Makridakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.05423">On the Stability and Convergence of Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics Informed Neural Networks is a numerical method which uses neural networks to approximate solutions of partial differential equations. It has received a lot of attention and is currently used in numerous physical and engineering problems. The mathematical understanding of these methods is limited, and in particular, it seems that, a consistent notion of stability is missing. Towards addressing this issue we consider model problems of partial differential equations, namely linear elliptic and parabolic PDEs. Motivated by tools of nonlinear calculus of variations we systematically show that coercivity of the energies and associated compactness provide a consistent framework for stability. For time discrete training we show that if these properties fail to hold then methods may become unstable. Furthermore, using tools of $Î$- convergence we provide new convergence results for weak solutions by only requiring that the neural network spaces are chosen to have suitable approximation properties. While our analysis is motivated by neural network-based approximation spaces, the framework developed here is applicable to any class of discrete functions satisfying the relevant approximation properties, and hence may serve as a foundation for the broader study of variational nonlinear PDE solvers.
<div id='section'>Paperid: <span id='pid'>1998, <a href='https://arxiv.org/pdf/2308.04501.pdf' target='_blank'>https://arxiv.org/pdf/2308.04501.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhihui Li, Francesco Montomoli, Sanjiv Sharma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04501">Investigation of Compressor Cascade Flow Using Physics- Informed Neural Networks with Adaptive Learning Strategy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we utilize the emerging Physics Informed Neural Networks (PINNs) approach for the first time to predict the flow field of a compressor cascade. Different from conventional training methods, a new adaptive learning strategy that mitigates gradient imbalance through incorporating adaptive weights in conjunction with dynamically adjusting learning rate is used during the training process to improve the convergence of PINNs. The performance of PINNs is assessed here by solving both the forward and inverse problems. In the forward problem, by encapsulating the physical relations among relevant variables, PINNs demonstrate their effectiveness in accurately forecasting the compressor's flow field. PINNs also show obvious advantages over the traditional CFD approaches, particularly in scenarios lacking complete boundary conditions, as is often the case in inverse engineering problems. PINNs successfully reconstruct the flow field of the compressor cascade solely based on partial velocity vectors and near-wall pressure information. Furthermore, PINNs show robust performance in the environment of various levels of aleatory uncertainties stemming from labeled data. This research provides evidence that PINNs can offer turbomachinery designers an additional and promising option alongside the current dominant CFD methods.
<div id='section'>Paperid: <span id='pid'>1999, <a href='https://arxiv.org/pdf/2308.04457.pdf' target='_blank'>https://arxiv.org/pdf/2308.04457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abdeldjalil Latrach, Mohamed Lamine Malki, Misael Morales, Mohamed Mehana, Minou Rabiei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04457">A Critical Review of Physics-Informed Machine Learning Applications in Subsurface Energy Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning has emerged as a powerful tool in various fields, including computer vision, natural language processing, and speech recognition. It can unravel hidden patterns within large data sets and reveal unparalleled insights, revolutionizing many industries and disciplines. However, machine and deep learning models lack interpretability and limited domain-specific knowledge, especially in applications such as physics and engineering. Alternatively, physics-informed machine learning (PIML) techniques integrate physics principles into data-driven models. By combining deep learning with domain knowledge, PIML improves the generalization of the model, abidance by the governing physical laws, and interpretability. This paper comprehensively reviews PIML applications related to subsurface energy systems, mainly in the oil and gas industry. The review highlights the successful utilization of PIML for tasks such as seismic applications, reservoir simulation, hydrocarbons production forecasting, and intelligent decision-making in the exploration and production stages. Additionally, it demonstrates PIML's capabilities to revolutionize the oil and gas industry and other emerging areas of interest, such as carbon and hydrogen storage; and geothermal systems by providing more accurate and reliable predictions for resource management and operational efficiency.
<div id='section'>Paperid: <span id='pid'>2000, <a href='https://arxiv.org/pdf/2307.09740.pdf' target='_blank'>https://arxiv.org/pdf/2307.09740.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiqi Xing, Yu Liu, Dayou Lu, Xinchen Zou, Xuming He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.09740">A Physics-Informed Data-Driven Fault Location Method for Transmission Lines Using Single-Ended Measurements with Field Data Validation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data driven transmission line fault location methods have the potential to more accurately locate faults by extracting fault information from available data. However, most of the data driven fault location methods in the literature are not validated by field data for the following reasons. On one hand, the available field data during faults are very limited for one specific transmission line, and using field data for training is close to impossible. On the other hand, if simulation data are utilized for training, the mismatch between the simulation system and the practical system will cause fault location errors. To this end, this paper proposes a physics-informed data-driven fault location method. The data from a practical fault event are first analyzed to extract the ranges of system and fault parameters such as equivalent source impedances, loading conditions, fault inception angles (FIA) and fault resistances. Afterwards, the simulation system is constructed with the ranges of parameters, to generate data for training. This procedure merges the gap between simulation and practical power systems, and at the same time considers the uncertainty of system and fault parameters in practice. The proposed data-driven method does not require system parameters, only requires instantaneous voltage and current measurements at the local terminal, with a low sampling rate of several kHz and a short fault time window of half a cycle before and after the fault occurs. Numerical experiments and field data experiments clearly validate the advantages of the proposed method over existing data driven methods.
<div id='section'>Paperid: <span id='pid'>2001, <a href='https://arxiv.org/pdf/2306.13116.pdf' target='_blank'>https://arxiv.org/pdf/2306.13116.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minh Triet Chau, JoÃ£o Lucas de Sousa Almeida, Elie Alhajjar, Alberto Costa Nogueira Junior
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.13116">A Machine Learning Pressure Emulator for Hydrogen Embrittlement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A recent alternative for hydrogen transportation as a mixture with natural gas is blending it into natural gas pipelines. However, hydrogen embrittlement of material is a major concern for scientists and gas installation designers to avoid process failures. In this paper, we propose a physics-informed machine learning model to predict the gas pressure on the pipes' inner wall. Despite its high-fidelity results, the current PDE-based simulators are time- and computationally-demanding. Using simulation data, we train an ML model to predict the pressure on the pipelines' inner walls, which is a first step for pipeline system surveillance. We found that the physics-based method outperformed the purely data-driven method and satisfy the physical constraints of the gas flow system.
<div id='section'>Paperid: <span id='pid'>2002, <a href='https://arxiv.org/pdf/2306.11682.pdf' target='_blank'>https://arxiv.org/pdf/2306.11682.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhao Nie, Eric Zelikman, Andea Scott, Quentin Paletta, Adam Brandt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.11682">SkyGPT: Probabilistic Short-term Solar Forecasting Using Synthetic Sky Videos from Physics-constrained VideoGPT</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, deep learning-based solar forecasting using all-sky images has emerged as a promising approach for alleviating uncertainty in PV power generation. However, the stochastic nature of cloud movement remains a major challenge for accurate and reliable solar forecasting. With the recent advances in generative artificial intelligence, the synthesis of visually plausible yet diversified sky videos has potential for aiding in forecasts. In this study, we introduce \emph{SkyGPT}, a physics-informed stochastic video prediction model that is able to generate multiple possible future images of the sky with diverse cloud motion patterns, by using past sky image sequences as input. Extensive experiments and comparison with benchmark video prediction models demonstrate the effectiveness of the proposed model in capturing cloud dynamics and generating future sky images with high realism and diversity. Furthermore, we feed the generated future sky images from the video prediction models for 15-minute-ahead probabilistic solar forecasting for a 30-kW roof-top PV system, and compare it with an end-to-end deep learning baseline model SUNSET and a smart persistence model. Better PV output prediction reliability and sharpness is observed by using the predicted sky images generated with SkyGPT compared with other benchmark models, achieving a continuous ranked probability score (CRPS) of 2.81 (13\% better than SUNSET and 23\% better than smart persistence) and a Winkler score of 26.70 for the test set. Although an arbitrary number of futures can be generated from a historical sky image sequence, the results suggest that 10 future scenarios is a good choice that balances probabilistic solar forecasting performance and computational cost.
<div id='section'>Paperid: <span id='pid'>2003, <a href='https://arxiv.org/pdf/2306.09621.pdf' target='_blank'>https://arxiv.org/pdf/2306.09621.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Po-Han Hou, Sung-Chi Hsieh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09621">Regression-based Physics Informed Neural Networks (Reg-PINNs) for Magnetopause Tracking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Previous research in the scientific field has utilized statistical empirical models and machine learning to address fitting challenges. While empirical models have the advantage of numerical generalization, they often sacrifice accuracy. However, conventional machine learning methods can achieve high precision but may lack the desired generalization. The article introduces a Regression-based Physics-Informed Neural Networks (Reg-PINNs), which embeds physics-inspired empirical models into the neural network's loss function, thereby combining the benefits of generalization and high accuracy. The study validates the proposed method using the magnetopause boundary location as the target and explores the feasibility of methods including Shue et al. [1998], a data overfitting model, a fully-connected networks, Reg-PINNs with Shue's model, and Reg-PINNs with the overfitting model. Compared to Shue's model, this technique achieves approximately a 30% reduction in RMSE, presenting a proof-of-concept improved solution for the scientific community.
<div id='section'>Paperid: <span id='pid'>2004, <a href='https://arxiv.org/pdf/2306.09478.pdf' target='_blank'>https://arxiv.org/pdf/2306.09478.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lukas Fesser, Luca D'Amico-Wong, Richard Qiu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.09478">Understanding and Mitigating Extrapolation Failures in Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Neural Networks (PINNs) have recently gained popularity due to their effective approximation of partial differential equations (PDEs) using deep neural networks (DNNs). However, their out of domain behavior is not well understood, with previous work speculating that the presence of high frequency components in the solution function might be to blame for poor extrapolation performance. In this paper, we study the extrapolation behavior of PINNs on a representative set of PDEs of different types, including high-dimensional PDEs. We find that failure to extrapolate is not caused by high frequencies in the solution function, but rather by shifts in the support of the Fourier spectrum over time. We term these spectral shifts and quantify them by introducing a Weighted Wasserstein-Fourier distance (WWF). We show that the WWF can be used to predict PINN extrapolation performance, and that in the absence of significant spectral shifts, PINN predictions stay close to the true solution even in extrapolation. Finally, we propose a transfer learning-based strategy to mitigate the effects of larger spectral shifts, which decreases extrapolation errors by up to 82%.
<div id='section'>Paperid: <span id='pid'>2005, <a href='https://arxiv.org/pdf/2306.02150.pdf' target='_blank'>https://arxiv.org/pdf/2306.02150.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kairui Hao, Ilias Bilionis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02150">An information field theory approach to Bayesian state and parameter estimation in dynamical systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Dynamical system state estimation and parameter calibration problems are ubiquitous across science and engineering. Bayesian approaches to the problem are the gold standard as they allow for the quantification of uncertainties and enable the seamless fusion of different experimental modalities. When the dynamics are discrete and stochastic, one may employ powerful techniques such as Kalman, particle, or variational filters. Practitioners commonly apply these methods to continuous-time, deterministic dynamical systems after discretizing the dynamics and introducing fictitious transition probabilities. However, approaches based on time-discretization suffer from the curse of dimensionality since the number of random variables grows linearly with the number of time-steps. Furthermore, the introduction of fictitious transition probabilities is an unsatisfactory solution because it increases the number of model parameters and may lead to inference bias. To address these drawbacks, the objective of this paper is to develop a scalable Bayesian approach to state and parameter estimation suitable for continuous-time, deterministic dynamical systems. Our methodology builds upon information field theory. Specifically, we construct a physics-informed prior probability measure on the function space of system responses so that functions that satisfy the physics are more likely. This prior allows us to quantify model form errors. We connect the system's response to observations through a probabilistic model of the measurement process. The joint posterior over the system responses and all parameters is given by Bayes' rule. To approximate the intractable posterior, we develop a stochastic variational inference algorithm. In summary, the developed methodology offers a powerful framework for Bayesian estimation in dynamical systems.
<div id='section'>Paperid: <span id='pid'>2006, <a href='https://arxiv.org/pdf/2306.01204.pdf' target='_blank'>https://arxiv.org/pdf/2306.01204.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Kamali, Kaveh Laksari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.01204">Physics-informed UNets for Discovering Hidden Elasticity in Heterogeneous Materials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Soft biological tissues often have complex mechanical properties due to variation in structural components. In this paper, we develop a novel UNet-based neural network model for inversion in elasticity (El-UNet) to infer the spatial distributions of mechanical parameters from strain maps as input images, normal stress boundary conditions, and domain physics information. We show superior performance, both in terms of accuracy and computational cost, by El-UNet compared to fully-connected physics-informed neural networks in estimating unknown parameters and stress distributions for isotropic linear elasticity. We characterize different variations of El-UNet and propose a self-adaptive spatial loss weighting approach. To validate our inversion models, we performed various finite-element simulations of isotropic domains with heterogenous distributions of material parameters to generate synthetic data. El-UNet is faster and more accurate than the fully-connected physics-informed implementation in resolving the distribution of unknown fields. Among the tested models, the self-adaptive spatially weighted models had the most accurate reconstructions in equal computation times. The learned spatial weighting distribution visibly corresponded to regions that the unweighted models were resolving inaccurately. Our work demonstrates a computationally efficient inversion algorithm for elasticity imaging using convolutional neural networks and presents a potential fast framework for three-dimensional inverse elasticity problems that have proven unachievable through previously proposed methods.
<div id='section'>Paperid: <span id='pid'>2007, <a href='https://arxiv.org/pdf/2305.12817.pdf' target='_blank'>https://arxiv.org/pdf/2305.12817.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Reyna Quita, Yu-Shuo Chen, Hsin-Yi Lee Alex C. Hu, John M. Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.12817">Conservative Physics-Informed Neural Networks for Non-Conservative Hyperbolic Conservation Laws Near Critical States</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, a modified version of conservative Physics-informed Neural Networks (cPINN for short) is provided to construct the weak solutions of Riemann problem for the hyperbolic scalar conservation laws in non-conservative form. To demonstrate the results, we use the model of generalized Buckley-Leverett equation (GBL equation for short) with discontinuous porosity in porous media. By inventing a new unknown, the GBL equation is transformed into a two-by-two resonant hyperbolic conservation laws in conservative form. The modified method of cPINN is invented to overcome the difficulties due to the discontinuity of the porosity and the appearance of the critical states (near vacuum) in the Riemann data. We experiment with our idea by using a deep learning algorithm to solve the GBL equation in both conservative and non-conservative forms, as well as the cases of critical and non-critical states. This method provides a combination of two different neural networks and corresponding loss functions, one is for the two-by-two resonant hyperbolic system, and the other is for the scalar conservation law with a discontinuous perturbation term in the non-convex flux. The technique of re-scaling to the unknowns is adopted to avoid the oscillation of the Riemann solutions in the cases of critical Riemann data. The solutions constructed by the modified cPINN match the exact solutions constructed by the theoretical analysis for hyperbolic conservation laws. In addition, the solutions are identical in both conservative and non-conservative cases. Finally, we compare the performance of the modified cPINN with numerical method called WENO5. Whereas WENO5 struggles with the highly oscillation of approximate solutions for the Riemann problems of GBL equation in non-conservative form, cPINN works admirably.
<div id='section'>Paperid: <span id='pid'>2008, <a href='https://arxiv.org/pdf/2305.12570.pdf' target='_blank'>https://arxiv.org/pdf/2305.12570.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luuk Jacobs, Stefano Mandija, Hongyan Liu, Cornelis A. T. van den Berg, Alessandro Sbrizzi, Matteo Maspero
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.12570">Generalizable synthetic MRI with physics-informed convolutional networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we develop a physics-informed deep learning-based method to synthesize multiple brain magnetic resonance imaging (MRI) contrasts from a single five-minute acquisition and investigate its ability to generalize to arbitrary contrasts to accelerate neuroimaging protocols. A dataset of fifty-five subjects acquired with a standard MRI protocol and a five-minute transient-state sequence was used to develop a physics-informed deep learning-based method. The model, based on a generative adversarial network, maps data acquired from the five-minute scan to "effective" quantitative parameter maps, here named q*-maps, by using its generated PD, T1, and T2 values in a signal model to synthesize four standard contrasts (proton density-weighted, T1-weighted, T2-weighted, and T2-weighted fluid-attenuated inversion recovery), from which losses are computed. The q*-maps are compared to literature values and the synthetic contrasts are compared to an end-to-end deep learning-based method proposed by literature. The generalizability of the proposed method is investigated for five volunteers by synthesizing three non-standard contrasts unseen during training and comparing these to respective ground truth acquisitions via contrast-to-noise ratio and quantitative assessment. The physics-informed method was able to match the high-quality synthMRI of the end-to-end method for the four standard contrasts, with mean \pm standard deviation structural similarity metrics above 0.75 \pm 0.08 and peak signal-to-noise ratios above 22.4 \pm 1.9 and 22.6 \pm 2.1. Additionally, the physics-informed method provided retrospective contrast adjustment, with visually similar signal contrast and comparable contrast-to-noise ratios to the ground truth acquisitions for three sequences unused for model training, demonstrating its generalizability and potential application to accelerate neuroimaging protocols.
<div id='section'>Paperid: <span id='pid'>2009, <a href='https://arxiv.org/pdf/2305.07671.pdf' target='_blank'>https://arxiv.org/pdf/2305.07671.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad H. Taufik, Tariq Alkhalifah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.07671">LatentPINNs: Generative physics-informed neural networks via a latent representation learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are promising to replace conventional partial differential equation (PDE) solvers by offering more accurate and flexible PDE solutions. However, they are hampered by the relatively slow convergence and the need to perform additional, potentially expensive, training for different PDE parameters. To solve this limitation, we introduce latentPINN, a framework that utilizes latent representations of the PDE parameters as additional (to the coordinates) inputs into PINNs and allows for training over the distribution of these parameters. Motivated by the recent progress on generative models, we promote the use of latent diffusion models to learn compressed latent representations of the PDE parameters distribution and act as input parameters to NN functional solutions. We use a two-stage training scheme in which the first stage, we learn the latent representations for the distribution of PDE parameters. In the second stage, we train a physics-informed neural network over inputs given by randomly drawn samples from the coordinate space within the solution domain and samples from the learned latent representation of the PDE parameters. We test the approach on a class of level set equations given by the nonlinear Eikonal equation. We specifically share results corresponding to three different sets of Eikonal parameters (velocity models). The proposed method performs well on new phase velocity models without the need for any additional training.
<div id='section'>Paperid: <span id='pid'>2010, <a href='https://arxiv.org/pdf/2305.06802.pdf' target='_blank'>https://arxiv.org/pdf/2305.06802.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Liam Harcombe, Quanling Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.06802">Physics-Informed Neural Networks for Discovering Localised Eigenstates in Disordered Media</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The SchrÃ¶dinger equation with random potentials is a fundamental model for understanding the behaviour of particles in disordered systems. Disordered media are characterised by complex potentials that lead to the localisation of wavefunctions, also called Anderson localisation. These wavefunctions may have similar scales of eigenenergies which poses difficulty in their discovery. It has been a longstanding challenge due to the high computational cost and complexity of solving the SchrÃ¶dinger equation. Recently, machine-learning tools have been adopted to tackle these challenges. In this paper, based upon recent advances in machine learning, we present a novel approach for discovering localised eigenstates in disordered media using physics-informed neural networks (PINNs). We focus on the spectral approximation of Hamiltonians in one dimension with potentials that are randomly generated according to the Bernoulli, normal, and uniform distributions. We introduce a novel feature to the loss function that exploits known physical phenomena occurring in these regions to scan across the domain and successfully discover these eigenstates, regardless of the similarity of their eigenenergies. We present various examples to demonstrate the performance of the proposed approach and compare it with isogeometric analysis.
<div id='section'>Paperid: <span id='pid'>2011, <a href='https://arxiv.org/pdf/2305.03774.pdf' target='_blank'>https://arxiv.org/pdf/2305.03774.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Surya T. Sathujoda, Soham M. Sheth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.03774">Physics-Informed Localized Learning for Advection-Diffusion-Reaction Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The global push to advance Carbon Capture and Sequestration initiatives and green energy solutions, such as geothermal, have thrust new demands upon the current state-of-the-art subsurface fluid simulators. The requirement to be able to simulate a large order of reservoir states simultaneously, in a short period of time, has opened the door of opportunity for the application of machine learning techniques for surrogate modelling. We propose a novel physics-informed and boundary condition-aware Localized Learning method which extends the Embed-to-Control (E2C) and Embed-to-Control and Observe (E2CO) models to learn local representations of global state variables in an Advection-Diffusion Reaction system. Trained on reservoir simulation data, we show that our model is able to predict future states of the system, for a given set of controls, to a great deal of accuracy with only a fraction of the available information. It hence reduces training times significantly compared to the original E2C and E2CO models, lending to its benefit in application to optimal control problems.
<div id='section'>Paperid: <span id='pid'>2012, <a href='https://arxiv.org/pdf/2305.01539.pdf' target='_blank'>https://arxiv.org/pdf/2305.01539.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shivam Barwey, Venkat Raman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.01539">Jacobian-Scaled K-means Clustering for Physics-Informed Segmentation of Reacting Flows</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces Jacobian-scaled K-means (JSK-means) clustering, which is a physics-informed clustering strategy centered on the K-means framework. The method allows for the injection of underlying physical knowledge into the clustering procedure through a distance function modification: instead of leveraging conventional Euclidean distance vectors, the JSK-means procedure operates on distance vectors scaled by matrices obtained from dynamical system Jacobians evaluated at the cluster centroids. The goal of this work is to show how the JSK-means algorithm -- without modifying the input dataset -- produces clusters that capture regions of dynamical similarity, in that the clusters are redistributed towards high-sensitivity regions in phase space and are described by similarity in the source terms of samples instead of the samples themselves. The algorithm is demonstrated on a complex reacting flow simulation dataset (a channel detonation configuration), where the dynamics in the thermochemical composition space are known through the highly nonlinear and stiff Arrhenius-based chemical source terms. Interpretations of cluster partitions in both physical space and composition space reveal how JSK-means shifts clusters produced by standard K-means towards regions of high chemical sensitivity (e.g., towards regions of peak heat release rate near the detonation reaction zone). The findings presented here illustrate the benefits of utilizing Jacobian-scaled distances in clustering techniques, and the JSK-means method in particular displays promising potential for improving former partition-based modeling strategies in reacting flow (and other multi-physics) applications.
<div id='section'>Paperid: <span id='pid'>2013, <a href='https://arxiv.org/pdf/2304.13205.pdf' target='_blank'>https://arxiv.org/pdf/2304.13205.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simin Shekarpaz, Fanhai Zeng, George Karniadakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.13205">Splitting physics-informed neural networks for inferring the dynamics of integer- and fractional-order neuron models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a new approach for solving forward systems of differential equations using a combination of splitting methods and physics-informed neural networks (PINNs). The proposed method, splitting PINN, effectively addresses the challenge of applying PINNs to forward dynamical systems and demonstrates improved accuracy through its application to neuron models. Specifically, we apply operator splitting to decompose the original neuron model into sub-problems that are then solved using PINNs. Moreover, we develop an $L^1$ scheme for discretizing fractional derivatives in fractional neuron models, leading to improved accuracy and efficiency. The results of this study highlight the potential of splitting PINNs in solving both integer- and fractional-order neuron models, as well as other similar systems in computational science and engineering.
<div id='section'>Paperid: <span id='pid'>2014, <a href='https://arxiv.org/pdf/2304.12586.pdf' target='_blank'>https://arxiv.org/pdf/2304.12586.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adam Rupe, Karthik Kashinath, Nalini Kumar, James P. Crutchfield
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.12586">Unsupervised Discovery of Extreme Weather Events Using Universal Representations of Emergent Organization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spontaneous self-organization is ubiquitous in systems far from thermodynamic equilibrium. While organized structures that emerge dominate transport properties, universal representations that identify and describe these key objects remain elusive. Here, we introduce a theoretically-grounded framework for describing emergent organization that, via data-driven algorithms, is constructive in practice. Its building blocks are spacetime lightcones that embody how information propagates across a system through local interactions. We show that predictive equivalence classes of lightcones -- local causal states -- capture organized behaviors and coherent structures in complex spatiotemporal systems. Employing an unsupervised physics-informed machine learning algorithm and a high-performance computing implementation, we demonstrate automatically discovering coherent structures in two real world domain science problems. We show that local causal states identify vortices and track their power-law decay behavior in two-dimensional fluid turbulence. We then show how to detect and track familiar extreme weather events -- hurricanes and atmospheric rivers -- and discover other novel coherent structures associated with precipitation extremes in high-resolution climate data at the grid-cell level.
<div id='section'>Paperid: <span id='pid'>2015, <a href='https://arxiv.org/pdf/2304.12177.pdf' target='_blank'>https://arxiv.org/pdf/2304.12177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maximilian Pierzyna, Rudolf Saathof, Sukanta Basu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.12177">Î -ML: A dimensional analysis-based machine learning parameterization of optical turbulence in the atmospheric surface layer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Turbulent fluctuations of the atmospheric refraction index, so-called optical turbulence, can significantly distort propagating laser beams. Therefore, modeling the strength of these fluctuations ($C_n^2$) is highly relevant for the successful development and deployment of future free-space optical communication links. In this letter, we propose a physics-informed machine learning (ML) methodology, $Î $-ML, based on dimensional analysis and gradient boosting to estimate $C_n^2$. Through a systematic feature importance analysis, we identify the normalized variance of potential temperature as the dominating feature for predicting $C_n^2$. For statistical robustness, we train an ensemble of models which yields high performance on the out-of-sample data of $R^2=0.958\pm0.001$.
<div id='section'>Paperid: <span id='pid'>2016, <a href='https://arxiv.org/pdf/2304.11702.pdf' target='_blank'>https://arxiv.org/pdf/2304.11702.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Xiong, Olga Fink, Jian Zhou, Yizhong Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.11702">Controlled physics-informed data generation for deep learning-based remaining useful life prediction under unseen operation conditions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Limited availability of representative time-to-failure (TTF) trajectories either limits the performance of deep learning (DL)-based approaches on remaining useful life (RUL) prediction in practice or even precludes their application. Generating synthetic data that is physically plausible is a promising way to tackle this challenge. In this study, a novel hybrid framework combining the controlled physics-informed data generation approach with a deep learning-based prediction model for prognostics is proposed. In the proposed framework, a new controlled physics-informed generative adversarial network (CPI-GAN) is developed to generate synthetic degradation trajectories that are physically interpretable and diverse. Five basic physics constraints are proposed as the controllable settings in the generator. A physics-informed loss function with penalty is designed as the regularization term, which ensures that the changing trend of system health state recorded in the synthetic data is consistent with the underlying physical laws. Then, the generated synthetic data is used as input of the DL-based prediction model to obtain the RUL estimations. The proposed framework is evaluated based on new Commercial Modular Aero-Propulsion System Simulation (N-CMAPSS), a turbofan engine prognostics dataset where a limited avail-ability of TTF trajectories is assumed. The experimental results demonstrate that the proposed framework is able to generate synthetic TTF trajectories that are consistent with underlying degradation trends. The generated trajectories enable to significantly improve the accuracy of RUL predictions.
<div id='section'>Paperid: <span id='pid'>2017, <a href='https://arxiv.org/pdf/2303.14090.pdf' target='_blank'>https://arxiv.org/pdf/2303.14090.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenyu Dai, Ben Moews, Ricardo Vilalta, Romeel Dave
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.14090">Physics-informed neural networks in the recreation of hydrodynamic simulations from dark matter</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks have emerged as a coherent framework for building predictive models that combine statistical patterns with domain knowledge. The underlying notion is to enrich the optimization loss function with known relationships to constrain the space of possible solutions. Hydrodynamic simulations are a core constituent of modern cosmology, while the required computations are both expensive and time-consuming. At the same time, the comparatively fast simulation of dark matter requires fewer resources, which has led to the emergence of machine learning algorithms for baryon inpainting as an active area of research; here, recreating the scatter found in hydrodynamic simulations is an ongoing challenge. This paper presents the first application of physics-informed neural networks to baryon inpainting by combining advances in neural network architectures with physical constraints, injecting theory on baryon conversion efficiency into the model loss function. We also introduce a punitive prediction comparison based on the Kullback-Leibler divergence, which enforces scatter reproduction. By simultaneously extracting the complete set of baryonic properties for the Simba suite of cosmological simulations, our results demonstrate improved accuracy of baryonic predictions based on dark matter halo properties, successful recovery of the fundamental metallicity relation, and retrieve scatter that traces the target simulation's distribution.
<div id='section'>Paperid: <span id='pid'>2018, <a href='https://arxiv.org/pdf/2303.09280.pdf' target='_blank'>https://arxiv.org/pdf/2303.09280.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saviz Mowlavi, Ken Kamrin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.09280">Detecting hidden structures from a static loading experiment: topology optimization meets physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most noninvasive imaging techniques utilize electromagnetic or acoustic waves originating from multiple locations and directions to identify hidden geometrical structures. Surprisingly, it is also possible to image hidden voids and inclusions buried within an object using a single static thermal or mechanical loading experiment by observing the response of the exposed surface of the body, but this problem is challenging to invert. Although physics-informed neural networks (PINNs) have shown promise as a simple-yet-powerful tool for problem inversion, they have not yet been applied to imaging problems with a priori unknown topology. Here, we introduce a topology optimization framework based on PINNs that identifies concealed geometries using exposed surface data from a single loading experiment, without prior knowledge of the number or types of shapes. We allow for arbitrary solution topology by representing the geometry using a material density field combined with a novel eikonal regularization technique. We validate our framework by detecting the number, locations, and shapes of hidden voids and inclusions in many example cases, in both 2D and 3D, and we demonstrate the method's robustness to noise and sparsity in the data. Our methodology opens a pathway for PINNs to solve geometry optimization problems in engineering.
<div id='section'>Paperid: <span id='pid'>2019, <a href='https://arxiv.org/pdf/2303.03181.pdf' target='_blank'>https://arxiv.org/pdf/2303.03181.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>S Chandra Mouli, Muhammad Ashraful Alam, Bruno Ribeiro
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.03181">MetaPhysiCa: OOD Robustness in Physics-informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A fundamental challenge in physics-informed machine learning (PIML) is the design of robust PIML methods for out-of-distribution (OOD) forecasting tasks. These OOD tasks require learning-to-learn from observations of the same (ODE) dynamical system with different unknown ODE parameters, and demand accurate forecasts even under out-of-support initial conditions and out-of-support ODE parameters. In this work we propose a solution for such tasks, which we define as a meta-learning procedure for causal structure discovery (including invariant risk minimization). Using three different OOD tasks, we empirically observe that the proposed approach significantly outperforms existing state-of-the-art PIML and deep learning methods.
<div id='section'>Paperid: <span id='pid'>2020, <a href='https://arxiv.org/pdf/2303.00474.pdf' target='_blank'>https://arxiv.org/pdf/2303.00474.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kemal Koysuren, Ahmet Faruk Keles, Melih Cakmakci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.00474">Online Parameter Estimation using Physics-Informed Deep Learning for Vehicle Stability Algorithms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed deep learning is a popular trend in the modeling and control of dynamical systems. This paper presents a novel method for rapid online identification of vehicle cornering stiffness coefficient, a crucial parameter in vehicle stability control models and control algorithms. The new method enables designers to rapidly identify the vehicle front and rear cornering stiffness parameters so that the controller reference gains can be re-adjusted under varying road and vehicle conditions to improve the reference tracking performance of the control system during operation. The proposed method based on vehicle model-based deep learning is compared to other alternatives such as traditional neural network training and identification, and Pacejka model estimation with regression. Our initial findings show that, in comparison to these classical methods, high fidelity estimations can be done with much smaller data sets simple enough to be obtained from a lane-changing or vehicle overtake maneuver. In order to conduct experiments, and collect sensor data, a custom-built 1:8 scaled test vehicle platform is used real-time wireless networking capabilities. The proposed method is applicable to predict derived vehicle parameters such as the understeering coefficient so it can be used in parallel with conventional MIMO controllers. Our $H_{\infty}$ yaw rate regulation controller test results show that the reference gains updated with the proposed online estimation method improve the tracking performance in both simulations and vehicle experiments.
<div id='section'>Paperid: <span id='pid'>2021, <a href='https://arxiv.org/pdf/2303.00437.pdf' target='_blank'>https://arxiv.org/pdf/2303.00437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adriano Mele, Alfredo Pironti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.00437">Assessing the Finite-Time Stability of Nonlinear Systems by means of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, the problem of assessing the Finite-Time Stability (FTS) property for general nonlinear systems is considered. First, some necessary and sufficient conditions that guarantee the FTS of general nonlinear systems are provided; such conditions are expressed in terms of the existence of a suitable Lyapunov-like function. Connections of the main theoretical result of given in this article with the typical conditions based on Linear Matrix Inequalities (LMI) that are used for Linear Time-Varying (LTV) systems are discussed. An extension to the case of discrete time systems is also provided. Then, we propose a method to verify the obtained conditions for a very broad class of nonlinear systems. The proposed technique leverages the capability of neural networks to serve as universal function approximators to obtain the Lyapunov-like function. The network training data are generated by enforcing the conditions defining such function in a (large) set of collocation points, as in the case of Physics-Informed Neural Networks. To illustrate the effectiveness of the proposed approach, some numerical examples are proposed and discussed. The technique proposed in this paper allows to obtain the required Lyapunov-like function in closed form. This has the twofold advantage of a) providing a practical way to verify the considered FTS property for a very general class of systems, with an unprecedented flexibility in the FTS context, and b) paving the way to control applications based on Lyapunov methods in the framework of Finite-Time Stability and Control.
<div id='section'>Paperid: <span id='pid'>2022, <a href='https://arxiv.org/pdf/2302.12260.pdf' target='_blank'>https://arxiv.org/pdf/2302.12260.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hubert Baty, Leo Baty
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12260">Solving differential equations using physics informed deep learning: a hand-on tutorial with benchmark tests</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We revisit the original approach of using deep learning and neural networks to solve differential equations by incorporating the knowledge of the equation. This is done by adding a dedicated term to the loss function during the optimization procedure in the training process. The so-called physics-informed neural networks (PINNs) are tested on a variety of academic ordinary differential equations in order to highlight the benefits and drawbacks of this approach with respect to standard integration methods. We focus on the possibility to use the least possible amount of data into the training process. The principles of PINNs for solving differential equations by enforcing physical laws via penalizing terms are reviewed. A tutorial on a simple equation model illustrates how to put into practice the method for ordinary differential equations. Benchmark tests show that a very small amount of training data is sufficient to predict the solution when the non linearity of the problem is weak. However, this is not the case in strongly non linear problems where a priori knowledge of training data over some partial or the whole time integration interval is necessary.
<div id='section'>Paperid: <span id='pid'>2023, <a href='https://arxiv.org/pdf/2302.11061.pdf' target='_blank'>https://arxiv.org/pdf/2302.11061.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis Espath, Pouria Behnoudfar, Raul Tempone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.11061">Physics-informed Spectral Learning: the Discrete Helmholtz--Hodge Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we further develop the Physics-informed Spectral Learning (PiSL) by Espath et al. \cite{Esp21} based on a discrete $L^2$ projection to solve the discrete Hodge--Helmholtz decomposition from sparse data. Within this physics-informed statistical learning framework, we adaptively build a sparse set of Fourier basis functions with corresponding coefficients by solving a sequence of minimization problems where the set of basis functions is augmented greedily at each optimization problem. Moreover, our PiSL computational framework enjoys spectral (exponential) convergence. We regularize the minimization problems with the seminorm of the fractional Sobolev space in a Tikhonov fashion. In the Fourier setting, the divergence- and curl-free constraints become a finite set of linear algebraic equations. The proposed computational framework combines supervised and unsupervised learning techniques in that we use data concomitantly with the projection onto divergence- and curl-free spaces. We assess the capabilities of our method in various numerical examples including the `Storm of the Century' with satellite data from 1993.
<div id='section'>Paperid: <span id='pid'>2024, <a href='https://arxiv.org/pdf/2302.08035.pdf' target='_blank'>https://arxiv.org/pdf/2302.08035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhiping Mao, Xuhui Meng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08035">Physics-informed neural networks with residual/gradient-based adaptive sampling methods for solving PDEs with sharp solutions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider solving the forward and inverse PDEs which have sharp solutions using physics-informed neural networks (PINNs) in this work. In particular, to better capture the sharpness of the solution, we propose adaptive sampling methods (ASMs) based on the residual and the gradient of the solution. We first present a residual only based ASM algorithm denoted by ASM I. In this approach, we first train the neural network by using a small number of residual points and divide the computational domain into a certain number of sub-domains, we then add new residual points in the sub-domain which has the largest mean absolute value of the residual, and those points which have largest absolute values of the residual in this sub-domain will be added as new residual points. We further develop a second type of ASM algorithm (denoted by ASM II) based on both the residual and the gradient of the solution due to the fact that only the residual may be not able to efficiently capture the sharpness of the solution. The procedure of ASM II is almost the same as that of ASM I except that in ASM II, we add new residual points which not only have large residual but also large gradient. To demonstrate the effectiveness of the present methods, we employ both ASM I and ASM II to solve a number of PDEs, including Burger equation, compressible Euler equation, Poisson equation over an L-shape domain as well as high-dimensional Poisson equation. It has been shown from the numerical results that the sharp solutions can be well approximated by using either ASM I or ASM II algorithm, and both methods deliver much more accurate solution than original PINNs with the same number of residual points. Moreover, the ASM II algorithm has better performance in terms of accuracy, efficiency and stability compared with the ASM I algorithm.
<div id='section'>Paperid: <span id='pid'>2025, <a href='https://arxiv.org/pdf/2302.07557.pdf' target='_blank'>https://arxiv.org/pdf/2302.07557.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrea Bonfanti, Roberto Santana, Marco Ellero, Babak Gholami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.07557">On the Generalization of PINNs outside the training domain and the Hyperparameters influencing it</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are Neural Network architectures trained to emulate solutions of differential equations without the necessity of solution data. They are currently ubiquitous in the scientific literature due to their flexible and promising settings. However, very little of the available research provides practical studies that aim for a better quantitative understanding of such architecture and its functioning. In this paper, we perform an empirical analysis of the behavior of PINN predictions outside their training domain. The primary goal is to investigate the scenarios in which a PINN can provide consistent predictions outside the training area. Thereinafter, we assess whether the algorithmic setup of PINNs can influence their potential for generalization and showcase the respective effect on the prediction. The results obtained in this study returns insightful and at times counterintuitive perspectives which can be highly relevant for architectures which combines PINNs with domain decomposition and/or adaptive training strategies.
<div id='section'>Paperid: <span id='pid'>2026, <a href='https://arxiv.org/pdf/2302.07405.pdf' target='_blank'>https://arxiv.org/pdf/2302.07405.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmed Rebai, Louay Boukhris, Radhi Toujani, Ahmed Gueddiche, Fayad Ali Banna, Fares Souissi, Ahmed Lasram, Elyes Ben Rayana, Hatem Zaag
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.07405">Unsupervised physics-informed neural network in reaction-diffusion biology models (Ulcerative colitis and Crohn's disease cases) A preliminary study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose to explore the potential of physics-informed neural networks (PINNs) in solving a class of partial differential equations (PDEs) used to model the propagation of chronic inflammatory bowel diseases, such as Crohn's disease and ulcerative colitis. An unsupervised approach was privileged during the deep neural network training. Given the complexity of the underlying biological system, characterized by intricate feedback loops and limited availability of high-quality data, the aim of this study is to explore the potential of PINNs in solving PDEs. In addition to providing this exploratory assessment, we also aim to emphasize the principles of reproducibility and transparency in our approach, with a specific focus on ensuring the robustness and generalizability through the use of artificial intelligence. We will quantify the relevance of the PINN method with several linear and non-linear PDEs in relation to biology. However, it is important to note that the final solution is dependent on the initial conditions, chosen boundary conditions, and neural network architectures.
<div id='section'>Paperid: <span id='pid'>2027, <a href='https://arxiv.org/pdf/2302.05322.pdf' target='_blank'>https://arxiv.org/pdf/2302.05322.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuval Zelig, Shai Dekel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05322">Numerical Methods For PDEs Over Manifolds Using Spectral Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce an approach for solving PDEs over manifolds using physics informed neural networks whose architecture aligns with spectral methods. The networks are trained to take in as input samples of an initial condition, a time stamp and point(s) on the manifold and then output the solution's value at the given time and point(s). We provide proofs of our method for the heat equation on the interval and examples of unique network architectures that are adapted to nonlinear equations on the sphere and the torus. We also show that our spectral-inspired neural network architectures outperform the standard physics informed architectures. Our extensive experimental results include generalization studies where the testing dataset of initial conditions is randomly sampled from a significantly larger space than the training set.
<div id='section'>Paperid: <span id='pid'>2028, <a href='https://arxiv.org/pdf/2302.01810.pdf' target='_blank'>https://arxiv.org/pdf/2302.01810.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fabian Heldmann, Sarah Berkhahn, Matthias Ehrhardt, Kathrin Klamroth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.01810">PINN Training using Biobjective Optimization: The Trade-off between Data Loss and Residual Loss</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics informed neural networks (PINNs) have proven to be an efficient tool to represent problems for which measured data are available and for which the dynamics in the data are expected to follow some physical laws. In this paper, we suggest a multiobjective perspective on the training of PINNs by treating the data loss and the residual loss as two individual objective functions in a truly biobjective optimization approach. As a showcase example, we consider COVID-19 predictions in Germany and built an extended susceptibles-infected-recovered (SIR) model with additionally considered leaky-vaccinated and hospitalized populations (SVIHR model) to model the transition rates and to predict future infections. SIR-type models are expressed by systems of ordinary differential equations (ODEs). We investigate the suitability of the generated PINN for COVID-19 predictions and compare the resulting predicted curves with those obtained by applying the method of non-standard finite differences to the system of ODEs and initial data. The approach is applicable to various systems of ODEs that define dynamical regimes. Those regimes do not need to be SIR-type models, and the corresponding underlying data sets do not have to be associated with COVID-19.
<div id='section'>Paperid: <span id='pid'>2029, <a href='https://arxiv.org/pdf/2301.12118.pdf' target='_blank'>https://arxiv.org/pdf/2301.12118.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddharth Nand, Yuecheng Cai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12118">Physics-informed Neural Network: The Effect of Reparameterization in Solving Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Differential equations are used to model and predict the behaviour of complex systems in a wide range of fields, and the ability to solve them is an important asset for understanding and predicting the behaviour of these systems. Complicated physics mostly involves difficult differential equations, which are hard to solve analytically. In recent years, physics-informed neural networks have been shown to perform very well in solving systems with various differential equations. The main ways to approximate differential equations are through penalty function and reparameterization. Most researchers use penalty functions rather than reparameterization due to the complexity of implementing reparameterization. In this study, we quantitatively compare physics-informed neural network models with and without reparameterization using the approximation error. The performance of reparameterization is demonstrated based on two benchmark mechanical engineering problems, a one-dimensional bar problem and a two-dimensional bending beam problem. Our results show that when dealing with complex differential equations, applying reparameterization results in a lower approximation error.
<div id='section'>Paperid: <span id='pid'>2030, <a href='https://arxiv.org/pdf/2301.07824.pdf' target='_blank'>https://arxiv.org/pdf/2301.07824.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marlon Sproesser Mathias, Wesley Pereira de Almeida, Marcel Rodrigues de Barros, Jefferson Fialho Coelho, Lucas Palmiro de Freitas, Felipe Marino Moreno, Caio Fabricio Deberaldini Netto, Fabio Gagliardi Cozman, Anna Helena Reali Costa, Eduardo Aoun Tannuri, Edson Satoshi Gomi, Marcelo Dottori
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.07824">Augmenting a Physics-Informed Neural Network for the 2D Burgers Equation by Addition of Solution Data Points</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We implement a Physics-Informed Neural Network (PINN) for solving the two-dimensional Burgers equations. This type of model can be trained with no previous knowledge of the solution; instead, it relies on evaluating the governing equations of the system in points of the physical domain. It is also possible to use points with a known solution during training. In this paper, we compare PINNs trained with different amounts of governing equation evaluation points and known solution points. Comparing models that were trained purely with known solution points to those that have also used the governing equations, we observe an improvement in the overall observance of the underlying physics in the latter. We also investigate how changing the number of each type of point affects the resulting models differently. Finally, we argue that the addition of the governing equations during training may provide a way to improve the overall performance of the model without relying on additional data, which is especially important for situations where the number of known solution points is limited.
<div id='section'>Paperid: <span id='pid'>2031, <a href='https://arxiv.org/pdf/2301.00776.pdf' target='_blank'>https://arxiv.org/pdf/2301.00776.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pengfei Wen, Zhi-Sheng Ye, Yong Li, Shaowei Chen, Pu Xie, Shuai Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.00776">Physics-Informed Neural Networks for Prognostics and Health Management of Lithium-Ion Batteries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For Prognostics and Health Management (PHM) of Lithium-ion (Li-ion) batteries, many models have been established to characterize their degradation process. The existing empirical or physical models can reveal important information regarding the degradation dynamics. However, there are no general and flexible methods to fuse the information represented by those models. Physics-Informed Neural Network (PINN) is an efficient tool to fuse empirical or physical dynamic models with data-driven models. To take full advantage of various information sources, we propose a model fusion scheme based on PINN. It is implemented by developing a semi-empirical semi-physical Partial Differential Equation (PDE) to model the degradation dynamics of Li-ion batteries. When there is little prior knowledge about the dynamics, we leverage the data-driven Deep Hidden Physics Model (DeepHPM) to discover the underlying governing dynamic models. The uncovered dynamics information is then fused with that mined by the surrogate neural network in the PINN framework. Moreover, an uncertainty-based adaptive weighting method is employed to balance the multiple learning tasks when training the PINN. The proposed methods are verified on a public dataset of Li-ion Phosphate (LFP)/graphite batteries.
<div id='section'>Paperid: <span id='pid'>2032, <a href='https://arxiv.org/pdf/2301.00106.pdf' target='_blank'>https://arxiv.org/pdf/2301.00106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Greeshma Krishna, Malavika S Nair, Pramod P Nair, Anil Lal S
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.00106">Physics-informed Neural Networks approach to solve the Blasius function</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning techniques with neural networks have been used effectively in computational fluid dynamics (CFD) to obtain solutions to nonlinear differential equations. This paper presents a physics-informed neural network (PINN) approach to solve the Blasius function. This method eliminates the process of changing the non-linear differential equation to an initial value problem. Also, it tackles the convergence issue arising in the conventional series solution. It is seen that this method produces results that are at par with the numerical and conventional methods. The solution is extended to the negative axis to show that PINNs capture the singularity of the function at $Î·=-5.69$
<div id='section'>Paperid: <span id='pid'>2033, <a href='https://arxiv.org/pdf/2212.13531.pdf' target='_blank'>https://arxiv.org/pdf/2212.13531.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arnav Gangal, Luis Kim, Sean P. Carney
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.13531">Physics informed neural networks for elliptic equations with oscillatory differential operators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics informed neural network (PINN) based solution methods for differential equations have recently shown success in a variety of scientific computing applications. Several authors have reported difficulties, however, when using PINNs to solve equations with multiscale features. The objective of the present work is to illustrate and explain the difficulty of using standard PINNs for the particular case of divergence-form elliptic partial differential equations (PDEs) with oscillatory coefficients present in the differential operator. We show that if the coefficient in the elliptic operator $a^Îµ(x)$ is of the form $a(x/Îµ)$ for a 1-periodic coercive function $a(\cdot)$, then the Frobenius norm of the neural tangent kernel (NTK) matrix associated to the loss function grows as $1/Îµ^2$. This implies that as the separation of scales in the problem increases, training the neural network with gradient descent based methods to achieve an accurate approximation of the solution to the PDE becomes increasingly difficult. Numerical examples illustrate the stiffness of the optimization problem.
<div id='section'>Paperid: <span id='pid'>2034, <a href='https://arxiv.org/pdf/2212.02179.pdf' target='_blank'>https://arxiv.org/pdf/2212.02179.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adithya Ramesh, Balaraman Ravindran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.02179">Physics-Informed Model-Based Reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We apply reinforcement learning (RL) to robotics tasks. One of the drawbacks of traditional RL algorithms has been their poor sample efficiency. One approach to improve the sample efficiency is model-based RL. In our model-based RL algorithm, we learn a model of the environment, essentially its transition dynamics and reward function, use it to generate imaginary trajectories and backpropagate through them to update the policy, exploiting the differentiability of the model. Intuitively, learning more accurate models should lead to better model-based RL performance. Recently, there has been growing interest in developing better deep neural network based dynamics models for physical systems, by utilizing the structure of the underlying physics. We focus on robotic systems undergoing rigid body motion without contacts. We compare two versions of our model-based RL algorithm, one which uses a standard deep neural network based dynamics model and the other which uses a much more accurate, physics-informed neural network based dynamics model. We show that, in model-based RL, model accuracy mainly matters in environments that are sensitive to initial conditions, where numerical errors accumulate fast. In these environments, the physics-informed version of our algorithm achieves significantly better average-return and sample efficiency. In environments that are not sensitive to initial conditions, both versions of our algorithm achieve similar average-return, while the physics-informed version achieves better sample efficiency. We also show that, in challenging environments, physics-informed model-based RL achieves better average-return than state-of-the-art model-free RL algorithms such as Soft Actor-Critic, as it computes the policy-gradient analytically, while the latter estimates it through sampling.
<div id='section'>Paperid: <span id='pid'>2035, <a href='https://arxiv.org/pdf/2211.09715.pdf' target='_blank'>https://arxiv.org/pdf/2211.09715.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>MickaÃ«l Delcey, Yoann Cheny, SÃ©bastien Kiesgen de Richter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.09715">Physics-informed neural networks for gravity currents reconstruction from limited data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The present work investigates the use of physics-informed neural networks (PINNs) for the 3D reconstruction of unsteady gravity currents from limited data. In the PINN context, the flow fields are reconstructed by training a neural network whose objective function penalizes the mismatch between the network predictions and the observed data and embeds the underlying equations using automatic differentiation. This study relies on a high-fidelity numerical experiment of the canonical lock-exchange configuration. This allows us to benchmark quantitatively the PINNs reconstruction capabilities on several training databases that mimic state-of-the-art experimental measurement techniques for density and velocity. Notably, spatially averaged density measurements by light attenuation technique (LAT) are employed for the training procedure. An optimal experimental setup for flow reconstruction by PINNs is proposed according to two criteria : the implementation complexity and the accuracy of the inferred fields.
<div id='section'>Paperid: <span id='pid'>2036, <a href='https://arxiv.org/pdf/2211.01021.pdf' target='_blank'>https://arxiv.org/pdf/2211.01021.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yilan Qin, Jiayu Ma, Mingle Jiang, Chuanfei Dong, Haiyang Fu, Liang Wang, Wenjie Cheng, Yaqiu Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.01021">Data-driven modeling of Landau damping by physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Kinetic approaches are generally accurate in dealing with microscale plasma physics problems but are computationally expensive for large-scale or multiscale systems. One of the long-standing problems in plasma physics is the integration of kinetic physics into fluid models, which is often achieved through sophisticated analytical closure terms. In this paper, we successfully construct a multi-moment fluid model with an implicit fluid closure included in the neural network using machine learning. The multi-moment fluid model is trained with a small fraction of sparsely sampled data from kinetic simulations of Landau damping, using the physics-informed neural network (PINN) and the gradient-enhanced physics-informed neural network (gPINN). The multi-moment fluid model constructed using either PINN or gPINN reproduces the time evolution of the electric field energy, including its damping rate, and the plasma dynamics from the kinetic simulations. In addition, we introduce a variant of the gPINN architecture, namely, gPINN$p$ to capture the Landau damping process. Instead of including the gradients of all the equation residuals, gPINN$p$ only adds the gradient of the pressure equation residual as one additional constraint. Among the three approaches, the gPINN$p$-constructed multi-moment fluid model offers the most accurate results. This work sheds light on the accurate and efficient modeling of large-scale systems, which can be extended to complex multiscale laboratory, space, and astrophysical plasma physics problems.
<div id='section'>Paperid: <span id='pid'>2037, <a href='https://arxiv.org/pdf/2210.14795.pdf' target='_blank'>https://arxiv.org/pdf/2210.14795.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>S. Berrone, C. Canuto, M. Pintore, N. Sukumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.14795">Enforcing Dirichlet boundary conditions in physics-informed neural networks and variational physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present and compare four methods to enforce Dirichlet boundary conditions in Physics-Informed Neural Networks (PINNs) and Variational Physics-Informed Neural Networks (VPINNs). Such conditions are usually imposed by adding penalization terms in the loss function and properly choosing the corresponding scaling coefficients; however, in practice, this requires an expensive tuning phase. We show through several numerical tests that modifying the output of the neural network to exactly match the prescribed values leads to more efficient and accurate solvers. The best results are achieved by exactly enforcing the Dirichlet boundary conditions by means of an approximate distance function. We also show that variationally imposing the Dirichlet boundary conditions via Nitsche's method leads to suboptimal solvers.
<div id='section'>Paperid: <span id='pid'>2038, <a href='https://arxiv.org/pdf/2210.14320.pdf' target='_blank'>https://arxiv.org/pdf/2210.14320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rini J. Gladstone, Mohammad A. Nabian, N. Sukumar, Ankit Srivastava, Hadi Meidani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.14320">FO-PINNs: A First-Order formulation for Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) are a class of deep learning neural networks that learn the response of a physical system without any simulation data, and only by incorporating the governing partial differential equations (PDEs) in their loss function. While PINNs are successfully used for solving forward and inverse problems, their accuracy decreases significantly for parameterized systems. PINNs also have a soft implementation of boundary conditions resulting in boundary conditions not being exactly imposed everywhere on the boundary. With these challenges at hand, we present first-order physics-informed neural networks (FO-PINNs). These are PINNs that are trained using a first-order formulation of the PDE loss function. We show that, compared to standard PINNs, FO-PINNs offer significantly higher accuracy in solving parameterized systems, and reduce time-per-iteration by removing the extra backpropagations needed to compute the second or higher-order derivatives. Additionally, FO-PINNs can enable exact imposition of boundary conditions using approximate distance functions, which pose challenges when applied on high-order PDEs. Through three examples, we demonstrate the advantages of FO-PINNs over standard PINNs in terms of accuracy and training speedup.
<div id='section'>Paperid: <span id='pid'>2039, <a href='https://arxiv.org/pdf/2210.13900.pdf' target='_blank'>https://arxiv.org/pdf/2210.13900.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hamed Saidaoui, Luis Espath, RÃ¡ul Tempone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.13900">Deep NURBS -- Admissible Physics-informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we propose a new numerical scheme for physics-informed neural networks (PINNs) that enables precise and inexpensive solution for partial differential equations (PDEs) in case of arbitrary geometries while strictly enforcing Dirichlet boundary conditions. The proposed approach combines admissible NURBS parametrizations required to define the physical domain and the Dirichlet boundary conditions with a PINN solver. The fundamental boundary conditions are automatically satisfied in this novel Deep NURBS framework. We verified our new approach using two-dimensional elliptic PDEs when considering arbitrary geometries, including non-Lipschitz domains. Compared to the classical PINN solver, the Deep NURBS estimator has a remarkably high convergence rate for all the studied problems. Moreover, a desirable accuracy was realized for most of the studied PDEs using only one hidden layer of neural networks. This novel approach is considered to pave the way for more effective solutions for high-dimensional problems by allowing for more realistic physics-informed statistical learning to solve PDE-based variational problems.
<div id='section'>Paperid: <span id='pid'>2040, <a href='https://arxiv.org/pdf/2210.13212.pdf' target='_blank'>https://arxiv.org/pdf/2210.13212.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weilong Guan, Kaihan Yang, Yinsheng Chen, Zhong Guan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.13212">A Dimension-Augmented Physics-Informed Neural Network (DaPINN) with High Level Accuracy and Efficiency</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) have been widely applied in different fields due to their effectiveness in solving partial differential equations (PDEs). However, the accuracy and efficiency of PINNs need to be considerably improved for scientific and commercial use. To address this issue, we systematically propose a novel dimension-augmented physics-informed neural network (DaPINN), which simultaneously and significantly improves the accuracy and efficiency of the PINN. In the DaPINN model, we introduce inductive bias in the neural network to enhance network generalizability by adding a special regularization term to the loss function. Furthermore, we manipulate the network input dimension by inserting additional sample features and incorporating the expanded dimensionality in the loss function. Moreover, we verify the effectiveness of power series augmentation, Fourier series augmentation and replica augmentation, in both forward and backward problems. In most experiments, the error of DaPINN is 1$\sim$2 orders of magnitude lower than that of PINN. The results show that the DaPINN outperforms the original PINN in terms of both accuracy and efficiency with a reduced dependence on the number of sample points. We also discuss the complexity of the DaPINN and its compatibility with other methods.
<div id='section'>Paperid: <span id='pid'>2041, <a href='https://arxiv.org/pdf/2210.00222.pdf' target='_blank'>https://arxiv.org/pdf/2210.00222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenhao Ding, Qing He, Hanghang Tong, Qingjing Wang, Ping Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.00222">Solving Coupled Differential Equation Groups Using PINO-CDE</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a fundamental mathmatical tool in many engineering disciplines, coupled differential equation groups are being widely used to model complex structures containing multiple physical quantities. Engineers constantly adjust structural parameters at the design stage, which requires a highly efficient solver. The rise of deep learning technologies has offered new perspectives on this task. Unfortunately, existing black-box models suffer from poor accuracy and robustness, while the advanced methodologies of single-output operator regression cannot deal with multiple quantities simultaneously. To address these challenges, we propose PINO-CDE, a deep learning framework for solving coupled differential equation groups (CDEs) along with an equation normalization algorithm for performance enhancing. Based on the theory of physics-informed neural operator (PINO), PINO-CDE uses a single network for all quantities in a CDEs, instead of training dozens, or even hundreds of networks as in the existing literature. We demonstrate the flexibility and feasibility of PINO-CDE for one toy example and two engineering applications: vehicle-track coupled dynamics (VTCD) and reliability assessment for a four-storey building (uncertainty propagation). The performance of VTCD indicates that PINO-CDE outperforms existing software and deep learning-based methods in terms of efficiency and precision, respectively. For the uncertainty propagation task, PINO-CDE provides higher-resolution results in less than a quarter of the time incurred when using the probability density evolution method (PDEM). This framework integrates engineering dynamics and deep learning technologies and may reveal a new concept for CDEs solving and uncertainty propagation.
<div id='section'>Paperid: <span id='pid'>2042, <a href='https://arxiv.org/pdf/2209.12433.pdf' target='_blank'>https://arxiv.org/pdf/2209.12433.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Norihiro Oyama, Noriko N. Ishizaki, Satoshi Koide, Hiroaki Yoshida
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.12433">Deep generative model super-resolves spatially correlated multiregional climate data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Super-resolving the coarse outputs of global climate simulations, termed downscaling, is crucial in making political and social decisions on systems requiring long-term climate change projections. Existing fast super-resolution techniques, however, have yet to preserve the spatially correlated nature of climatological data, which is particularly important when we address systems with spatial expanse, such as the development of transportation infrastructure. Herein, we show an adversarial network-based machine learning enables us to correctly reconstruct the inter-regional spatial correlations in downscaling with high magnification of up to fifty while maintaining pixel-wise statistical consistency. Direct comparison with the measured meteorological data of temperature and precipitation distributions reveals that integrating climatologically important physical information improves the downscaling performance, which prompts us to call this approach $Ï$SRGAN (Physics Informed Super-Resolution Generative Adversarial Network). The proposed method has a potential application to the inter-regionally consistent assessment of the climate change impact. Additionally, we present the outcomes of another variant of the deep generative model-based downscaling approach in which the low-resolution precipitation field is substituted with the pressure field, referred to as $Ï$SRGAN (Precipitation Source Inaccessible SRGAN). Remarkably, this method demonstrates unexpectedly good downscaling performance for the precipitation field.
<div id='section'>Paperid: <span id='pid'>2043, <a href='https://arxiv.org/pdf/2209.07802.pdf' target='_blank'>https://arxiv.org/pdf/2209.07802.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jose M. G. Vilar, Leonor Saiz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.07802">Dynamics-informed deconvolutional neural networks for super-resolution identification of regime changes in epidemiological time series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inferring the timing and amplitude of perturbations in epidemiological systems from their stochastically spread low-resolution outcomes is as relevant as challenging. It is a requirement for current approaches to overcome the need to know the details of the perturbations to proceed with the analyses. However, the general problem of connecting epidemiological curves with the underlying incidence lacks the highly effective methodology present in other inverse problems, such as super-resolution and dehazing from computer vision. Here, we develop an unsupervised physics-informed convolutional neural network approach in reverse to connect death records with incidence that allows the identification of regime changes at single-day resolution. Applied to COVID-19 data with proper regularization and model-selection criteria, the approach can identify the implementation and removal of lockdowns and other nonpharmaceutical interventions with 0.93-day accuracy over the time span of a year.
<div id='section'>Paperid: <span id='pid'>2044, <a href='https://arxiv.org/pdf/2207.07705.pdf' target='_blank'>https://arxiv.org/pdf/2207.07705.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zachary Burns, Zhaowei Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.07705">Untrained, physics-informed neural networks for structured illumination microscopy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years there has been great interest in using deep neural networks (DNN) for super-resolution image reconstruction including for structured illumination microscopy (SIM). While these methods have shown very promising results, they all rely on data-driven, supervised training strategies that need a large number of ground truth images, which is experimentally difficult to realize. For SIM imaging, there exists a need for a flexible, general, and open-source reconstruction method that can be readily adapted to different forms of structured illumination. We demonstrate that we can combine a deep neural network with the forward model of the structured illumination process to reconstruct sub-diffraction images without training data. The resulting physics-informed neural network (PINN) can be optimized on a single set of diffraction limited sub-images and thus doesn't require any training set. We show with simulated and experimental data that this PINN can be applied to a wide variety of SIM methods by simply changing the known illumination patterns used in the loss function and can achieve resolution improvements that match well with theoretical expectations.
<div id='section'>Paperid: <span id='pid'>2045, <a href='https://arxiv.org/pdf/2206.03439.pdf' target='_blank'>https://arxiv.org/pdf/2206.03439.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Senbao Jiang, Xiaofan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.03439">Solving Non-local Fokker-Planck Equations by Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PiNNs) recently emerged as a powerful solver for a large class of partial differential equations under various initial and boundary conditions. In this paper, we propose trapz-PiNNs, physics-informed neural networks incorporated with a modified trapezoidal rule recently developed for accurately evaluating fractional laplacian and solve the space-fractional Fokker-Planck equations in 2D and 3D. We describe the modified trapezoidal rule in detail and verify the second-order accuracy. We demonstrate trapz-PiNNs have high expressive power through predicting solution with low $\mathcal{L}^2$ relative error on a variety of numerical examples. We also use local metrics such as pointwise absolute and relative errors to analyze where could be further improved. We present an effective method for improving performance of trapz-PiNN on local metrics, provided that physical observations of high-fidelity simulation of the true solution are available. Besides the usual advantages of the deep learning solvers such as adaptivity and mesh-independence, the trapz-PiNN is able to solve PDEs with fractional laplacian with arbitrary $Î±\in (0,2)$ and specializes on rectangular domain. It also has potential to be generalized into higher dimensions.
<div id='section'>Paperid: <span id='pid'>2046, <a href='https://arxiv.org/pdf/2205.09114.pdf' target='_blank'>https://arxiv.org/pdf/2205.09114.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amilson R. Fritsch, Shangjie Guo, Sophia M. Koh, I. B. Spielman, Justyna P. Zwolak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.09114">Dark solitons in Bose-Einstein condensates: a dataset for many-body physics research</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We establish a dataset of over $1.6\times10^4$ experimental images of Bose--Einstein condensates containing solitonic excitations to enable machine learning (ML) for many-body physics research. About $33~\%$ of this dataset has manually assigned and carefully curated labels. The remainder is automatically labeled using SolDet -- an implementation of a physics-informed ML data analysis framework -- consisting of a convolutional-neural-network-based classifier and OD as well as a statistically motivated physics-informed classifier and a quality metric. This technical note constitutes the definitive reference of the dataset, providing an opportunity for the data science community to develop more sophisticated analysis tools, to further understand nonlinear many-body physics, and even advance cold atom experiments.
<div id='section'>Paperid: <span id='pid'>2047, <a href='https://arxiv.org/pdf/2204.13474.pdf' target='_blank'>https://arxiv.org/pdf/2204.13474.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Riccardo Morandin, Jonas Nicodemus, Benjamin Unger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.13474">Port-Hamiltonian Dynamic Mode Decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel physics-informed system identification method to construct a passive linear time-invariant system. In more detail, for a given quadratic energy functional, measurements of the input, state, and output of a system in the time domain, we find a realization that approximates the data well while guaranteeing that the energy functional satisfies a dissipation inequality. To this end, we use the framework of port-Hamiltonian (pH) systems and modify the dynamic mode decomposition, respectively operator inference, to be feasible for continuous-time pH systems. We propose an iterative numerical method to solve the corresponding least-squares minimization problem. We construct an effective initialization of the algorithm by studying the least-squares problem in a weighted norm, for which we present the analytical minimum-norm solution. The efficiency of the proposed method is demonstrated with several numerical examples.
<div id='section'>Paperid: <span id='pid'>2048, <a href='https://arxiv.org/pdf/2203.08802.pdf' target='_blank'>https://arxiv.org/pdf/2203.08802.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>E. J. R. Coutinho, M. Dall'Aqua, L. McClenny, M. Zhong, U. Braga-Neto, E. Gildin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.08802">Physics-Informed Neural Networks with Adaptive Localized Artificial Viscosity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed Neural Network (PINN) is a promising tool that has been applied in a variety of physical phenomena described by partial differential equations (PDE). However, it has been observed that PINNs are difficult to train in certain "stiff" problems, which include various nonlinear hyperbolic PDEs that display shocks in their solutions. Recent studies added a diffusion term to the PDE, and an artificial viscosity (AV) value was manually tuned to allow PINNs to solve these problems. In this paper, we propose three approaches to address this problem, none of which rely on an a priori definition of the artificial viscosity value. The first method learns a global AV value, whereas the other two learn localized AV values around the shocks, by means of a parametrized AV map or a residual-based AV map. We applied the proposed methods to the inviscid Burgers equation and the Buckley-Leverett equation, the latter being a classical problem in Petroleum Engineering. The results show that the proposed methods are able to learn both a small AV value and the accurate shock location and improve the approximation error over a nonadaptive global AV alternative method.
<div id='section'>Paperid: <span id='pid'>2049, <a href='https://arxiv.org/pdf/2202.11342.pdf' target='_blank'>https://arxiv.org/pdf/2202.11342.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alban Gossard, Pierre Weiss
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.11342">Training Adaptive Reconstruction Networks for Blind Inverse Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural networks allow solving many ill-posed inverse problems with unprecedented performance. Physics informed approaches already progressively replace carefully hand-crafted reconstruction algorithms in real applications. However, these networks suffer from a major defect: when trained on a given forward operator, they do not generalize well to a different one. The aim of this paper is twofold. First, we show through various applications that training the network with a family of forward operators allows solving the adaptivity problem without compromising the reconstruction quality significantly.Second, we illustrate that this training procedure allows tackling challenging blind inverse problems.Our experiments include partial Fourier sampling problems arising in magnetic resonance imaging (MRI) with sensitivity estimation and off-resonance effects, computerized tomography (CT) with a tilted geometry  and image deblurring with Fresnel diffraction kernels.
<div id='section'>Paperid: <span id='pid'>2050, <a href='https://arxiv.org/pdf/2112.14707.pdf' target='_blank'>https://arxiv.org/pdf/2112.14707.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanfeng Zhai, Timothy Sands
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2112.14707">Controlling Chaos in Van Der Pol Dynamics Using Signal-Encoded Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Controlling nonlinear dynamics is a long-standing problem in engineering. Harnessing known physical information to accelerate or constrain stochastic learning pursues a new paradigm of scientific machine learning. By linearizing nonlinear systems, traditional control methods cannot learn nonlinear features from chaotic data for use in control. Here, we introduce Physics-Informed Deep Operator Control (PIDOC), and by encoding the control signal and initial position into the losses of a physics-informed neural network (PINN), the nonlinear system is forced to exhibit the desired trajectory given the control signal. PIDOC receives signals as physics commands and learns from the chaotic data output from the nonlinear van der Pol system, where the output of the PINN is the control. Applied to a benchmark problem, PIDOC successfully implements control with higher stochasticity for higher-order terms. PIDOC has also been proven to be capable of converging to different desired trajectories based on case studies. Initial positions slightly affect the control accuracy at the beginning stage yet do not change the overall control quality. For highly nonlinear systems, PIDOC is not able to execute control with high accuracy compared with the benchmark problem. The depth and width of the neural network structure do not greatly change the convergence of PIDOC based on case studies of van der Pol systems with low and high nonlinearities. Surprisingly, enlarging the control signal does not help to improve the control quality. The proposed framework can potentially be applied to many nonlinear systems for nonlinear controls.
<div id='section'>Paperid: <span id='pid'>2051, <a href='https://arxiv.org/pdf/2111.04684.pdf' target='_blank'>https://arxiv.org/pdf/2111.04684.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daihui Lu, Ivan C. Christov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2111.04684">Physics-informed neural networks for understanding shear migration of particles in viscous flow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We harness the physics-informed neural network (PINN) approach to extend the utility of phenomenological models for particle migration in shear flow. Specifically, we propose to constrain the neural network training via a model for the physics of shear-induced particle migration in suspensions. Then, we train the PINN against experimental data from the literature, showing that this approach provides both better fidelity to the experiments, and a novel understanding of the relative roles of the hypothesized migration fluxes. We first verify the PINN approach for solving the inverse problem of radial particle migration in a non-Brownian suspension in an annular Couette flow. In this classical case, the PINN yields the same value (as reported in the literature) for the ratio of the two parameters of the empirical model. Next, we apply the PINN approach to analyze experiments on particle migration in both non-Brownian and Brownian suspensions in Poiseuille slot flow, for which a definitive calibration of the phenomenological migration model has been lacking. Using the PINN approach, we identify the unknown/empirical parameters in the physical model through the inverse solver capability of PINNs. Specifically, the values are significantly different from those for the Couette cell, highlighting an inconsistency in the literature that uses the latter value for Poiseuille flow. Importantly, the PINN results also show that the inferred values of the empirical model's parameters vary with the shear PÃ©clet number and the particle bulk volume fraction of the suspension, instead of being constant as assumed in some previous literature.
<div id='section'>Paperid: <span id='pid'>2052, <a href='https://arxiv.org/pdf/2110.09813.pdf' target='_blank'>https://arxiv.org/pdf/2110.09813.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rafael Bischof, Michael Kraus
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2110.09813">Multi-Objective Loss Balancing for Physics-Informed Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINN) are algorithms from deep learning leveraging physical laws by including partial differential equations together with a respective set of boundary and initial conditions as penalty terms into their loss function. In this work, we observe the significant role of correctly weighting the combination of multiple competitive loss functions for training PINNs effectively. To this end, we implement and evaluate different methods aiming at balancing the contributions of multiple terms of the PINNs loss function and their gradients. After reviewing of three existing loss scaling approaches (Learning Rate Annealing, GradNorm and SoftAdapt), we propose a novel self-adaptive loss balancing scheme for PINNs named \emph{ReLoBRaLo} (Relative Loss Balancing with Random Lookback). We extensively evaluate the performance of the aforementioned balancing schemes by solving both forward as well as inverse problems on three benchmark PDEs for PINNs: Burgers' equation, Kirchhoff's plate bending equation and Helmholtz's equation. The results show that ReLoBRaLo is able to consistently outperform the baseline of existing scaling methods in terms of accuracy, while also inducing significantly less computational overhead.
<div id='section'>Paperid: <span id='pid'>2053, <a href='https://arxiv.org/pdf/2107.07871.pdf' target='_blank'>https://arxiv.org/pdf/2107.07871.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ben Moseley, Andrew Markham, Tarje Nissen-Meyer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2107.07871">Finite Basis Physics-Informed Neural Networks (FBPINNs): a scalable domain decomposition approach for solving differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, physics-informed neural networks (PINNs) have offered a powerful new paradigm for solving problems relating to differential equations. Compared to classical numerical methods PINNs have several advantages, for example their ability to provide mesh-free solutions of differential equations and their ability to carry out forward and inverse modelling within the same optimisation problem. Whilst promising, a key limitation to date is that PINNs have struggled to accurately and efficiently solve problems with large domains and/or multi-scale solutions, which is crucial for their real-world application. Multiple significant and related factors contribute to this issue, including the increasing complexity of the underlying PINN optimisation problem as the problem size grows and the spectral bias of neural networks. In this work we propose a new, scalable approach for solving large problems relating to differential equations called Finite Basis PINNs (FBPINNs). FBPINNs are inspired by classical finite element methods, where the solution of the differential equation is expressed as the sum of a finite set of basis functions with compact support. In FBPINNs neural networks are used to learn these basis functions, which are defined over small, overlapping subdomains. FBINNs are designed to address the spectral bias of neural networks by using separate input normalisation over each subdomain, and reduce the complexity of the underlying optimisation problem by using many smaller neural networks in a parallel divide-and-conquer approach. Our numerical experiments show that FBPINNs are effective in solving both small and larger, multi-scale problems, outperforming standard PINNs in both accuracy and computational resources required, potentially paving the way to the application of PINNs on large, real-world problems.
<div id='section'>Paperid: <span id='pid'>2054, <a href='https://arxiv.org/pdf/2010.00399.pdf' target='_blank'>https://arxiv.org/pdf/2010.00399.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Julian Rice, Wenwei Xu, Andrew August
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2010.00399">Analyzing Koopman approaches to physics-informed machine learning for long-term sea-surface temperature forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurately predicting sea-surface temperature weeks to months into the future is an important step toward long term weather forecasting. Standard atmosphere-ocean coupled numerical models provide accurate sea-surface forecasts on the scale of a few days to a few weeks, but many important weather systems require greater foresight. In this paper we propose machine-learning approaches sea-surface temperature forecasting that are accurate on the scale of dozens of weeks. Our approach is based in Koopman operator theory, a useful tool for dynamical systems modelling. With this approach, we predict sea surface temperature in the Gulf of Mexico up to 180 days into the future based on a present image of thermal conditions and three years of historical training data. We evaluate the combination of a basic Koopman method with a convolutional autoencoder, and a newly proposed "consistent Koopman" method, in various permutations. We show that the Koopman approach consistently outperforms baselines, and we discuss the utility of our additional assumptions and methods in this sea-surface temperature domain.
<div id='section'>Paperid: <span id='pid'>2055, <a href='https://arxiv.org/pdf/2009.04544.pdf' target='_blank'>https://arxiv.org/pdf/2009.04544.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Levi McClenny, Ulisses Braga-Neto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2009.04544">Self-Adaptive Physics-Informed Neural Networks using a Soft Attention Mechanism</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged recently as a promising application of deep neural networks to the numerical solution of nonlinear partial differential equations (PDEs). However, it has been recognized that adaptive procedures are needed to force the neural network to fit accurately the stubborn spots in the solution of "stiff" PDEs. In this paper, we propose a fundamentally new way to train PINNs adaptively, where the adaptation weights are fully trainable and applied to each training point individually, so the neural network learns autonomously which regions of the solution are difficult and is forced to focus on them. The self-adaptation weights specify a soft multiplicative soft attention mask, which is reminiscent of similar mechanisms used in computer vision. The basic idea behind these SA-PINNs is to make the weights increase as the corresponding losses increase, which is accomplished by training the network to simultaneously minimize the losses and maximize the weights. In addition, we show how to build a continuous map of self-adaptive weights using Gaussian Process regression, which allows the use of stochastic gradient descent in problems where conventional gradient descent is not enough to produce accurate solutions. Finally, we derive the Neural Tangent Kernel matrix for SA-PINNs and use it to obtain a heuristic understanding of the effect of the self-adaptive weights on the dynamics of training in the limiting case of infinitely-wide PINNs, which suggests that SA-PINNs work by producing a smooth equalization of the eigenvalues of the NTK matrix corresponding to the different loss terms. In numerical experiments with several linear and nonlinear benchmark problems, the SA-PINN outperformed other state-of-the-art PINN algorithm in L2 error, while using a smaller number of training epochs.
<div id='section'>Paperid: <span id='pid'>2056, <a href='https://arxiv.org/pdf/2510.08295.pdf' target='_blank'>https://arxiv.org/pdf/2510.08295.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tsuyoshi Okita
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.08295">Bridging the Physics-Data Gap with FNO-Guided Conditional Flow Matching: Designing Inductive Bias through Hierarchical Physical Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conventional time-series generation often ignores domain-specific physical constraints, limiting statistical and physical consistency. We propose a hierarchical framework that embeds the inherent hierarchy of physical laws-conservation, dynamics, boundary, and empirical relations-directly into deep generative models, introducing a new paradigm of physics-informed inductive bias. Our method combines Fourier Neural Operators (FNOs) for learning physical operators with Conditional Flow Matching (CFM) for probabilistic generation, integrated via time-dependent hierarchical constraints and FNO-guided corrections. Experiments on harmonic oscillators, human activity recognition, and lithium-ion battery degradation show 16.3% higher generation quality, 46% fewer physics violations, and 18.5% improved predictive accuracy over baselines.
<div id='section'>Paperid: <span id='pid'>2057, <a href='https://arxiv.org/pdf/2510.05183.pdf' target='_blank'>https://arxiv.org/pdf/2510.05183.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiacheng Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05183">Aneurysm Growth Time Series Reconstruction Using Physics-informed Autoencoder</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Arterial aneurysm (Fig.1) is a bulb-shape local expansion of human arteries, the rupture of which is a leading cause of morbidity and mortality in US. Therefore, the prediction of arterial aneurysm rupture is of great significance for aneurysm management and treatment selection. The prediction of aneurysm rupture depends on the analysis of the time series of aneurysm growth history. However, due to the long time scale of aneurysm growth, the time series of aneurysm growth is not always accessible. We here proposed a method to reconstruct the aneurysm growth time series directly from patient parameters. The prediction is based on data pairs of [patient parameters, patient aneurysm growth time history]. To obtain the mapping from patient parameters to patient aneurysm growth time history, we first apply autoencoder to obtain a compact representation of the time series for each patient. Then a mapping is learned from patient parameters to the corresponding compact representation of time series via a five-layer neural network. Moving average and convolutional output layer are implemented to explicitly taking account the time dependency of the time series. Apart from that, we also propose to use prior knowledge about the mechanism of aneurysm growth to improve the time series reconstruction results. The prior physics-based knowledge is incorporated as constraints for the optimization problem associated with autoencoder. The model can handle both algebraic and differential constraints. Our results show that including physical model information about the data will not significantly improve the time series reconstruction results if the training data is error-free. However, in the case of training data with noise and bias error, incorporating physical model constraints can significantly improve the predicted time series.
<div id='section'>Paperid: <span id='pid'>2058, <a href='https://arxiv.org/pdf/2510.04264.pdf' target='_blank'>https://arxiv.org/pdf/2510.04264.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohamed Shamseldein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04264">A Hybrid GNN-IZR Framework for Fast and Empirically Robust AC Power Flow Analysis in Radial Distribution Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Alternating Current Power Flow (ACPF) problem forces a trade-off between the speed of data-driven models and the reliability of analytical solvers. This paper introduces a hybrid framework that synergizes a Graph Neural Network (GNN) with the Implicit Z-Bus Recursive (IZR) method, a robust, non-iterative solver for radial distribution networks. The framework employs a physics-informed GNN for rapid initial predictions and invokes the IZR solver as a failsafe for stressed cases identified by a two-stage trigger. A failure is defined as any solution with a maximum power mismatch exceeding 0.1 p.u., a significant operational deviation. On a challenging test set of 7,500 stressed scenarios for the IEEE 33-bus system, the GNN-only model failed on 13.11 % of cases. In contrast, the hybrid framework identified all potential failures, delegating them to the IZR solver to achieve a 0.00 % failure rate, empirically matching the 100 % success rate of the analytical solver on this specific test set. An expanded ablation study confirms that both physics-informed training and Z-bus sensitivity features are critical, collaboratively reducing the GNN's failure rate from 98.72 % (data-only) to 13.11 %. The hybrid approach demonstrates a pragmatic path to achieving the empirical reliability of an analytical solver while leveraging GNN speed, enabling a significant increase in the number of scenarios analyzable in near real-time.
<div id='section'>Paperid: <span id='pid'>2059, <a href='https://arxiv.org/pdf/2510.03278.pdf' target='_blank'>https://arxiv.org/pdf/2510.03278.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Filip Landgren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03278">Quantifying constraint hierarchies in Bayesian PINNs via per-constraint Hessian decomposition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian physics-informed neural networks (B-PINNs) merge data with governing equations to solve differential equations under uncertainty. However, interpreting uncertainty and overconfidence in B-PINNs requires care due to the poorly understood effects the physical constraints have on the network; overconfidence could reflect warranted precision, enforced by the constraints, rather than miscalibration. Motivated by the need to further clarify how individual physical constraints shape these networks, we introduce a scalable, matrix-free Laplace framework that decomposes the posterior Hessian into contributions from each constraint and provides metrics to quantify their relative influence on the loss landscape. Applied to the Van der Pol equation, our method tracks how constraints sculpt the network's geometry and shows, directly through the Hessian, how changing a single loss weight non-trivially redistributes curvature and effective dominance across the others.
<div id='section'>Paperid: <span id='pid'>2060, <a href='https://arxiv.org/pdf/2510.02551.pdf' target='_blank'>https://arxiv.org/pdf/2510.02551.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edward Finkelstein
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.02551">Deducing Closed-Form Expressions for Bright-Solitons in Strongly Magnetized Plasmas with Physics Informed Symbolic Regression (PISR)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel approach to finding analytical approximations for bright-soliton solutions in strongly magnetized plasmas. We leverage Physics-Informed Symbolic Regression (PISR) to discover closed-form expressions for the vector potential and number density profiles, governed by a reduced-order model derived from Maxwell-fluid equations. The PISR framework combines symbolic regression with physics-based constraints, boundary conditions, and available simulation data to guide the search for solutions. We demonstrate the effectiveness of the approach by rediscovering approximate solutions consistent with previously published numerical results, showcasing the potential of PISR for reducing simulation costs of reduced-order models in plasma physics.
<div id='section'>Paperid: <span id='pid'>2061, <a href='https://arxiv.org/pdf/2509.24327.pdf' target='_blank'>https://arxiv.org/pdf/2509.24327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hai Siong Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24327">Inferring Cosmological Parameters with Evidential Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We examine the use of a novel variant of Physics-Informed Neural Networks to predict cosmological parameters from recent supernovae and baryon acoustic oscillations (BAO) datasets. Our machine learning framework generates uncertainty estimates for target variables and the inferred unknown parameters of the underlying PDE descriptions. Built upon a hybrid of the principles of Evidential Deep Learning, Physics-Informed Neural Networks, Bayesian Neural Networks and Gaussian Processes, our model enables learning of the posterior distribution of the unknown PDE parameters through standard gradient-descent based training. We apply our model to an up-to-date BAO dataset (Bousis et al. 2024) calibrated with the CMB-inferred sound horizon, and the Pantheon$+$ Sne Ia distances (Scolnic et al. 2018), examining the relative effectiveness and mutual consistency among the standard $Λ$CDM, $w$CDM and $Λ_s$CDM models. Unlike previous results arising from the standard approach of minimizing an appropriate $χ^2$ function, the posterior distributions for parameters in various models trained purely on Pantheon$+$ data were found to be largely contained within the $2σ$ contours of their counterparts trained on BAO data. Their posterior medians for $h_0$ were within about $2σ$ of one another, indicating that our machine learning-guided approach provides a different measure of the Hubble tension.
<div id='section'>Paperid: <span id='pid'>2062, <a href='https://arxiv.org/pdf/2509.22760.pdf' target='_blank'>https://arxiv.org/pdf/2509.22760.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Achraf Zinihi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.22760">Identifying Memory Effects in Epidemics via a Fractional SEIRD Model and Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a physics-informed neural network (PINN) framework for parameter estimation in fractional-order SEIRD epidemic models. By embedding the Caputo fractional derivative into the network residuals via the L1 discretization scheme, our method simultaneously reconstructs epidemic trajectories and infers both epidemiological parameters and the fractional memory order $α$. The fractional formulation extends classical integer-order models by capturing long-range memory effects in disease progression, incubation, and recovery. Our framework learns the fractional memory order $α$ as a trainable parameter while simultaneously estimating the epidemiological rates $(β, σ, γ, μ)$. A composite loss combining data misfit, physics residuals, and initial conditions, with constraints on positivity and population conservation, ensures both accuracy and biological consistency. Tests on synthetic Mpox data confirm reliable recovery of $α$ and parameters under noise, while applications to COVID-19 show that optimal $α\in (0, 1]$ captures memory effects and improves predictive performance over the classical SEIRD model. This work establishes PINNs as a robust tool for learning memory effects in epidemic dynamics, with implications for forecasting, control strategies, and the analysis of non-Markovian epidemic processes.
<div id='section'>Paperid: <span id='pid'>2063, <a href='https://arxiv.org/pdf/2509.21751.pdf' target='_blank'>https://arxiv.org/pdf/2509.21751.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jaemin Oh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21751">Reparameterizing 4DVAR with neural fields</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Four-dimensional variational data assimilation (4DVAR) is a cornerstone of numerical weather prediction, but its cost function is difficult to optimize and computationally intensive. We propose a neural field-based reformulation in which the full spatiotemporal state is represented as a continuous function parameterized by a neural network. This reparameterization removes the time-sequential dependency of classical 4DVAR, enabling parallel-in-time optimization in parameter space. Physical constraints are incorporated directly through a physics-informed loss, simplifying implementation and reducing computational cost. We evaluate the method on the two-dimensional incompressible Navier--Stokes equations with Kolmogorov forcing. Compared to a baseline 4DVAR implementation, the neural reparameterized variants produce more stable initial condition estimates without spurious oscillations. Notably, unlike most machine learning-based approaches, our framework does not require access to ground-truth states or reanalysis data, broadening its applicability to settings with limited reference information.
<div id='section'>Paperid: <span id='pid'>2064, <a href='https://arxiv.org/pdf/2509.18744.pdf' target='_blank'>https://arxiv.org/pdf/2509.18744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuqing Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18744">Theory of periodic convolutional neural network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel convolutional neural network architecture, termed the \emph{periodic CNN}, which incorporates periodic boundary conditions into the convolutional layers. Our main theoretical contribution is a rigorous approximation theorem: periodic CNNs can approximate ridge functions depending on $d-1$ linear variables in a $d$-dimensional input space, while such approximation is impossible in lower-dimensional ridge settings ($d-2$ or fewer variables). This result establishes a sharp characterization of the expressive power of periodic CNNs. Beyond the theory, our findings suggest that periodic CNNs are particularly well-suited for problems where data naturally admits a ridge-like structure of high intrinsic dimension, such as image analysis on wrapped domains, physics-informed learning, and materials science. The work thus both expands the mathematical foundation of CNN approximation theory and highlights a class of architectures with surprising and practically relevant approximation capabilities.
<div id='section'>Paperid: <span id='pid'>2065, <a href='https://arxiv.org/pdf/2509.12253.pdf' target='_blank'>https://arxiv.org/pdf/2509.12253.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Riyaadh Gani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.12253">Physics-Informed Neural Networks vs. Physics Models for Non-Invasive Glucose Monitoring: A Comparative Study Under Realistic Synthetic Conditions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Non-invasive glucose monitors often fail outside the lab because existing datasets ignore hardware noise, environmental drift, and person-to-person physiology. We introduce the first ultra-realistic near-infrared (NIR) simulator that injects 12-bit ADC quantisation, +/-0.1% LED ageing, photodiode dark noise, 15-45 C temperature, 30-90% relative humidity, contact-pressure variation, Fitzpatrick I-VI melanin, and diurnal glucose excursions (dawn phenomenon). Using this platform (rho glucose-NIR = 0.21), we benchmark six methods: Enhanced Beer-Lambert (physics-engineered ridge regression), three physics-informed neural networks (PINNs), a selective radiative-transfer PINN, and a shallow DNN. Beer-Lambert achieves 13.6 mg/dL RMSE, 95.8% Clarke-A and 93.8% +/-15% accuracy with only 56 parameters and 0.01 ms inference, outperforming the best PINN (14.6 mg/dL) and the SDNN baseline (35.1 mg/dL). Results overturn the assumption that deeper PINNs dominate and supply an open, end-to-end reference stack for rapid prototyping of embedded optical glucose sensors.
<div id='section'>Paperid: <span id='pid'>2066, <a href='https://arxiv.org/pdf/2509.11911.pdf' target='_blank'>https://arxiv.org/pdf/2509.11911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Antonin Sulc
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.11911">Quantum Noise Tomography with Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Characterizing the environmental interactions of quantum systems is a critical bottleneck in the development of robust quantum technologies. Traditional tomographic methods are often data-intensive and struggle with scalability. In this work, we introduce a novel framework for performing Lindblad tomography using Physics-Informed Neural Networks (PINNs). By embedding the Lindblad master equation directly into the neural network's loss function, our approach simultaneously learns the quantum state's evolution and infers the underlying dissipation parameters from sparse, time-series measurement data. Our results show that PINNs can reconstruct both the system dynamics and the functional form of unknown noise parameters, presenting a sample-efficient and scalable solution for quantum device characterization. Ultimately, our method produces a fully-differentiable digital twin of a noisy quantum system by learning its governing master equation.
<div id='section'>Paperid: <span id='pid'>2067, <a href='https://arxiv.org/pdf/2509.10565.pdf' target='_blank'>https://arxiv.org/pdf/2509.10565.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aryan Gupta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.10565">Assessing the Limits of Graph Neural Networks for Vapor-Liquid Equilibrium Prediction: A Cryogenic Mixture Case Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate and fast thermophysical models are needed to embed vapor-liquid equilibrium (VLE) calculations in design, optimization, and control loops for cryogenic mixtures. This study asks whether a structure-aware graph neural network (GNN; DimeNet++) trained on GERG-2008/CoolProp data can act as a practical surrogate for an equation of state (EoS). We generate a ternary dataset over 90-200 K and pressures to 100 bar, curate it with a 15% density filter (reducing 5,200 states to 1,516), and pair each state with a lightweight molecular-dynamics snapshot to supply structural features. The model is trained in two stages; pretraining on residual Helmholtz energy followed by pressure fine-tuning with a stability penalty; and evaluated via single-phase interpolation tests, solver-free derivative-quality diagnostics, an audited VLE driver, and a latency benchmark. Within its regime, the GNN interpolates single-phase properties reasonably well; however, the VLE driver accepts no GNN equilibria on tested binaries (all plotted VLE points are CoolProp fallback or the solver fails), and diagnostic probes reveal jagged P(V|T) paths and thermal-stability flags concentrated in dense/cold regions, indicating insufficient derivative smoothness/consistency for robust equilibrium solving. An end-to-end timing comparison shows no single-phase speed advantage relative to CoolProp (tens of milliseconds vs sub-millisecond). We conclude that, as configured, the surrogate in this study is not solver-ready for VLE and offers no runtime benefit; its value is methodological, delineating failure modes and pointing to remedies such as physics-informed training signals and targeted coverage near phase boundaries.
<div id='section'>Paperid: <span id='pid'>2068, <a href='https://arxiv.org/pdf/2509.05886.pdf' target='_blank'>https://arxiv.org/pdf/2509.05886.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Reza Pirayeshshirazinezhad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.05886">SPINN: An Optimal Self-Supervised Physics-Informed Neural Network Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A surrogate model is developed to predict the convective heat transfer coefficient of liquid sodium (Na) flow within rectangular miniature heat sinks. Initially, kernel-based machine learning techniques and shallow neural network are applied to a dataset with 87 Nusselt numbers for liquid sodium in rectangular miniature heat sinks. Subsequently, a self-supervised physics-informed neural network and transfer learning approach are used to increase the estimation performance. In the self-supervised physics-informed neural network, an additional layer determines the weight the of physics in the loss function to balance data and physics based on their uncertainty for a better estimation. For transfer learning, a shallow neural network trained on water is adapted for use with Na. Validation results show that the self-supervised physics-informed neural network successfully estimate the heat transfer rates of Na with an error margin of approximately +8%. Using only physics for regression, the error remains between 5% to 10%. Other machine learning methods specify the prediction mostly within +8%. High-fidelity modeling of turbulent forced convection of liquid metals using computational fluid dynamics (CFD) is both time-consuming and computationally expensive. Therefore, machine learning based models offer a powerful alternative tool for the design and optimization of liquid-metal-cooled miniature heat sinks.
<div id='section'>Paperid: <span id='pid'>2069, <a href='https://arxiv.org/pdf/2509.01963.pdf' target='_blank'>https://arxiv.org/pdf/2509.01963.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Naval Shah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01963">Computational Fluid Dynamics Optimization of F1 Front Wing using Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In response to recent FIA regulations reducing Formula 1 team wind tunnel hours (from 320 hours for last-place teams to 200 hours for championship leaders) and strict budget caps of 135 million USD per year, more efficient aerodynamic development tools are needed by teams. Conventional computational fluid dynamics (CFD) simulations, though offering high fidelity results, require large computational resources with typical simulation durations of 8-24 hours per configuration analysis. This article proposes a Physics-Informed Neural Network (PINN) for the fast prediction of Formula 1 front wing aerodynamic coefficients. The suggested methodology combines CFD simulation data from SimScale with first principles of fluid dynamics through a hybrid loss function that constrains both data fidelity and physical adherence based on Navier-Stokes equations. Training on force and moment data from 12 aerodynamic features, the PINN model records coefficient of determination (R-squared) values of 0.968 for drag coefficient and 0.981 for lift coefficient prediction while lowering computational time. The physics-informed framework guarantees that predictions remain adherent to fundamental aerodynamic principles, offering F1 teams an efficient tool for the fast exploration of design space within regulatory constraints.
<div id='section'>Paperid: <span id='pid'>2070, <a href='https://arxiv.org/pdf/2508.12996.pdf' target='_blank'>https://arxiv.org/pdf/2508.12996.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stavros C. Kassinos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12996">Kourkoutas-Beta: A Sunspike-Driven Adam Optimizer with Desert Flair</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformer neural networks are increasingly used for physics-based problems. In data-driven PDE surrogates, training samples from varying boundary and initial conditions can cause erratic losses and spiky gradients; in physics-informed neural networks (PINNs), stiff composite losses amplify this effect.
  We introduce Kourkoutas-Beta, an Adam-style optimizer where the fixed second-moment discount beta2 is replaced by a layer-wise dynamic value driven by a bounded ``sunspike'' ratio: the current pooled gradient norm divided by an exponential moving average (EMA) of past norms, squashed to the interval [0,1). Spikes lower beta2 toward beta2_min; calm phases keep it near beta2_max. Options include leaky-AMSGrad (decay), trust-region clipping (max_ratio), adaptive tiny terms, and several bias-correction modes ``none'', ``beta2max'', ``exact'). With all features off and bias_correction=``none'', the method is exactly Adam.
  We test on four settings: (i) a Transformer PDE surrogate (Heat2D), (ii) a 3D PINN for heat conduction (Heat3D), (iii) a lightweight MLX synthetic task with jitter and rare-trigger bursts, and (iv) a character-level Transformer on 30 MB of enwik8 (small-enwik8). Kourkoutas-Beta improves stability and final loss versus fixed-beta2 Adam. On small-enwik8 it lowers bits-per-character by about 38% vs Adam-0.95 and about 58% vs Adam-0.999 over 10 seeds, with smaller variance. The method remains drop-in, with runtime overhead comparable to Adam in testbeds A-C and within single-digit percent in testbed D. It preserves Adam-style convergence guarantees while improving robustness under spiky gradients.
<div id='section'>Paperid: <span id='pid'>2071, <a href='https://arxiv.org/pdf/2508.12314.pdf' target='_blank'>https://arxiv.org/pdf/2508.12314.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chiranjit Mitra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12314">Synchronization Dynamics of Heterogeneous, Collaborative Multi-Agent AI Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel interdisciplinary framework that bridges synchronization theory and multi-agent AI systems by adapting the Kuramoto model to describe the collective dynamics of heterogeneous AI agents engaged in complex task execution. By representing AI agents as coupled oscillators with both phase and amplitude dynamics, our model captures essential aspects of agent specialization, influence, and communication within networked systems. We introduce an order parameter to quantify the degree of coordination and synchronization, providing insights into how coupling strength, agent diversity, and network topology impact emergent collective behavior. Furthermore, we formalize a detailed correspondence between Chain-of-Thought prompting in AI reasoning and synchronization phenomena, unifying human-like iterative problem solving with emergent group intelligence. Through extensive simulations on all-to-all and deterministic scale-free networks, we demonstrate that increased coupling promotes robust synchronization despite heterogeneous agent capabilities, reflecting realistic collaborative AI scenarios. Our physics-informed approach establishes a rigorous mathematical foundation for designing, analyzing, and optimizing scalable, adaptive, and interpretable multi-agent AI systems. This work opens pathways for principled orchestration of agentic AI and lays the groundwork for future incorporation of learning dynamics and adaptive network architectures to further enhance system resilience and efficiency.
<div id='section'>Paperid: <span id='pid'>2072, <a href='https://arxiv.org/pdf/2508.05921.pdf' target='_blank'>https://arxiv.org/pdf/2508.05921.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddharth Rout
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05921">Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accuracy in neural PDE solvers often breaks down not because of limited expressivity, but due to poor optimisation caused by ill-conditioning, especially in multi-fidelity and stiff problems. We study this issue in Physics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural PDE solvers, and show that asymptotic components in governing equations can produce highly ill-conditioned activation matrices, severely limiting convergence. We introduce Shifted Gaussian Encoding, a simple yet effective activation filtering step that increases matrix rank and expressivity while preserving convexity. Our method extends the solvable range of Peclet numbers in steady advection-diffusion equations by over two orders of magnitude, achieves up to six orders lower error on multi-frequency function learning, and fits high-fidelity image vectors more accurately and faster than deep networks with over a million parameters. This work highlights that conditioning, not depth, is often the bottleneck in scientific neural solvers and that simple architectural changes can unlock substantial gains.
<div id='section'>Paperid: <span id='pid'>2073, <a href='https://arxiv.org/pdf/2508.04590.pdf' target='_blank'>https://arxiv.org/pdf/2508.04590.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mizuka Komatsu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.04590">Algebraically Observable Physics-Informed Neural Network and its Application to Epidemiological Modelling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Network (PINN) is a deep learning framework that integrates the governing equations underlying data into a loss function. In this study, we consider the problem of estimating state variables and parameters in epidemiological models governed by ordinary differential equations using PINNs. In practice, not all trajectory data corresponding to the population described by models can be measured. Learning PINNs to estimate the unmeasured state variables and epidemiological parameters using partial measurements is challenging.
  Accordingly, we introduce the concept of algebraic observability of the state variables. Specifically, we propose augmenting the unmeasured data based on algebraic observability analysis. The validity of the proposed method is demonstrated through numerical experiments under three scenarios in the context of epidemiological modelling. Specifically, given noisy and partial measurements, the accuracy of unmeasured states and parameter estimation of the proposed method is shown to be higher than that of the conventional methods. The proposed method is also shown to be effective in practical scenarios, such as when the data corresponding to certain variables cannot be reconstructed from the measurements.
<div id='section'>Paperid: <span id='pid'>2074, <a href='https://arxiv.org/pdf/2507.12468.pdf' target='_blank'>https://arxiv.org/pdf/2507.12468.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Mohammad-Djafari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.12468">Digital Twins in Industrial Applications: Concepts, Mathematical Modeling, and Use Cases</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Digital Twins (DTs) are virtual representations of physical systems synchronized in real time through Internet of Things (IoT) sensors and computational models. In industrial applications, DTs enable predictive maintenance, fault diagnosis, and process optimization. This paper explores the mathematical foundations of DTs, hybrid modeling techniques, including Physics Informed Neural Networks (PINNs), and their implementation in industrial scenarios. We present key applications, computational tools, and future research directions.
<div id='section'>Paperid: <span id='pid'>2075, <a href='https://arxiv.org/pdf/2507.12218.pdf' target='_blank'>https://arxiv.org/pdf/2507.12218.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomohisa Okazaki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.12218">Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many physical systems are described by partial differential equations (PDEs), and solving these equations and estimating their coefficients or boundary conditions (BCs) from observational data play a crucial role in understanding the associated phenomena. Recently, a machine learning approach known as physics-informed neural network, which solves PDEs using neural networks by minimizing the sum of residuals from the PDEs, BCs, and data, has gained significant attention in the scientific community. In this study, we investigate a physics-informed linear model (PILM) that uses linear combinations of basis functions to represent solutions, thereby enabling an analytical representation of optimal solutions. The PILM was formulated and verified for illustrative forward and inverse problems including cases with uncertain BCs. Furthermore, the PILM was applied to estimate crustal strain rates using geodetic data. Specifically, physical regularization that enforces elastic equilibrium on the velocity fields was compared with mathematical regularization that imposes smoothness constraints. From a Bayesian perspective, mathematical regularization exhibited superior performance. The PILM provides an analytically solvable framework applicable to linear forward and inverse problems, underdetermined systems, and physical regularization.
<div id='section'>Paperid: <span id='pid'>2076, <a href='https://arxiv.org/pdf/2507.11799.pdf' target='_blank'>https://arxiv.org/pdf/2507.11799.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shin-ichi Ito
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11799">Fragment size density estimator for shrinkage-induced fracture based on a physics-informed neural network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a neural network (NN)-based solver for an integro-differential equation that models shrinkage-induced fragmentation. The proposed method directly maps input parameters to the corresponding probability density function without numerically solving the governing equation, thereby significantly reducing computational costs. Specifically, it enables efficient evaluation of the density function in Monte Carlo simulations while maintaining accuracy comparable to or even exceeding that of conventional finite difference schemes. Validatation on synthetic data demonstrates both the method's computational efficiency and predictive reliability. This study establishes a foundation for the data-driven inverse analysis of fragmentation and suggests the potential for extending the framework beyond pre-specified model structures.
<div id='section'>Paperid: <span id='pid'>2077, <a href='https://arxiv.org/pdf/2507.09733.pdf' target='_blank'>https://arxiv.org/pdf/2507.09733.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bradley Camburn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09733">Universal Physics Simulation: A Foundational Diffusion Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present the first foundational AI model for universal physics simulation that learns physical laws directly from boundary-condition data without requiring a priori equation encoding. Traditional physics-informed neural networks (PINNs) and finite-difference methods necessitate explicit mathematical formulation of governing equations, fundamentally limiting their generalizability and discovery potential. Our sketch-guided diffusion transformer approach reimagines computational physics by treating simulation as a conditional generation problem, where spatial boundary conditions guide the synthesis of physically accurate steady-state solutions.
  By leveraging enhanced diffusion transformer architectures with novel spatial relationship encoding, our model achieves direct boundary-to-equilibrium mapping and is generalizable to diverse physics domains. Unlike sequential time-stepping methods that accumulate errors over iterations, our approach bypasses temporal integration entirely, directly generating steady-state solutions with SSIM > 0.8 while maintaining sub-pixel boundary accuracy. Our data-informed approach enables physics discovery through learned representations analyzable via Layer-wise Relevance Propagation (LRP), revealing emergent physical relationships without predetermined mathematical constraints. This work represents a paradigm shift from AI-accelerated physics to AI-discovered physics, establishing the first truly universal physics simulation framework.
<div id='section'>Paperid: <span id='pid'>2078, <a href='https://arxiv.org/pdf/2507.08906.pdf' target='_blank'>https://arxiv.org/pdf/2507.08906.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nathan DoumÃ¨che
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08906">Physics-informed machine learning: A mathematical framework with applications to time series forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed machine learning (PIML) is an emerging framework that integrates physical knowledge into machine learning models. This physical prior often takes the form of a partial differential equation (PDE) system that the regression function must satisfy. In the first part of this dissertation, we analyze the statistical properties of PIML methods. In particular, we study the properties of physics-informed neural networks (PINNs) in terms of approximation, consistency, overfitting, and convergence. We then show how PIML problems can be framed as kernel methods, making it possible to apply the tools of kernel ridge regression to better understand their behavior. In addition, we use this kernel formulation to develop novel physics-informed algorithms and implement them efficiently on GPUs. The second part explores industrial applications in forecasting energy signals during atypical periods. We present results from the Smarter Mobility challenge on electric vehicle charging occupancy and examine the impact of mobility on electricity demand. Finally, we introduce a physics-constrained framework for designing and enforcing constraints in time series, applying it to load forecasting and tourism forecasting in various countries.
<div id='section'>Paperid: <span id='pid'>2079, <a href='https://arxiv.org/pdf/2507.04940.pdf' target='_blank'>https://arxiv.org/pdf/2507.04940.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haesung Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04940">Notes on $L^2$-estimates in linear elliptic equations with general coefficients</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper establishes an explicit $L^2$-estimate for weak solutions $u$ to linear elliptic equations in divergence form with general coefficients and external source term $f$, stating that the $L^2$-norm of $u$ over $U$ is bounded by a constant multiple of the $L^2$-norm of $f$ over $U$. In contrast to classical approaches based on compactness arguments, the proposed method, which employs a divergence-free transformation method, provides a computable and explicit constant $C>0$. The $L^2$-estimate remains robust even when there is no zero-order term, and the analysis further demonstrates that the constant $C>0$ decreases as the diffusion coefficient or the zero-order term increases. These quantitative results provide a rigorous foundation for applications such as a posteriori error estimates in Physics-Informed Neural Networks (PINNs), where explicit error bounds are essential.
<div id='section'>Paperid: <span id='pid'>2080, <a href='https://arxiv.org/pdf/2506.23505.pdf' target='_blank'>https://arxiv.org/pdf/2506.23505.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tinh Nguyen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23505">Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Underwater object detection is crucial for autonomous navigation, environmental monitoring, and marine exploration, but it is severely hampered by light attenuation, turbidity, and occlusion. Current methods balance accuracy and computational efficiency, but they have trouble deploying in real-time under low visibility conditions. Through the integration of physics-informed augmentation techniques with the YOLOv12 architecture, this study advances underwater detection. With Residual ELAN blocks to preserve structural features in turbid waters and Area Attention to maintain large receptive fields for occluded objects while reducing computational complexity. Underwater optical properties are addressed by domain-specific augmentations such as turbulence adaptive blurring, biologically grounded occlusion simulation, and spectral HSV transformations for color distortion. Extensive tests on four difficult datasets show state-of-the-art performance, with Brackish data registering 98.30% mAP at 142 FPS. YOLOv12 improves occlusion robustness by 18.9%, small-object recall by 22.4%, and detection precision by up to 7.94% compared to previous models. The crucial role of augmentation strategy is validated by ablation studies. This work offers a precise and effective solution for conservation and underwater robotics applications.
<div id='section'>Paperid: <span id='pid'>2081, <a href='https://arxiv.org/pdf/2506.20181.pdf' target='_blank'>https://arxiv.org/pdf/2506.20181.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ronald Katende
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.20181">Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a principled framework for discovering causal structure in partial differential equations (PDEs) using physics-informed neural networks and counterfactual perturbations. Unlike classical residual minimization or sparse regression methods, our approach quantifies operator-level necessity through functional interventions on the governing dynamics. We introduce causal sensitivity indices and structural deviation metrics to assess the influence of candidate differential operators within neural surrogates. Theoretically, we prove exact recovery of the causal operator support under restricted isometry or mutual coherence conditions, with residual bounds guaranteeing identifiability. Empirically, we validate the framework on both synthetic and real-world datasets across climate dynamics, tumor diffusion, and ocean flows. Our method consistently recovers governing operators even under noise, redundancy, and data scarcity, outperforming standard PINNs and DeepONets in structural fidelity. This work positions causal PDE discovery as a tractable and interpretable inference task grounded in structural causal models and variational residual analysis.
<div id='section'>Paperid: <span id='pid'>2082, <a href='https://arxiv.org/pdf/2506.13554.pdf' target='_blank'>https://arxiv.org/pdf/2506.13554.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ronald Katende
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.13554">Non-Asymptotic Stability and Consistency Guarantees for Physics-Informed Neural Networks via Coercive Operator Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a unified theoretical framework for analyzing the stability and consistency of Physics-Informed Neural Networks (PINNs), grounded in operator coercivity, variational formulations, and non-asymptotic perturbation theory. PINNs approximate solutions to partial differential equations (PDEs) by minimizing residual losses over sampled collocation and boundary points. We formalize both operator-level and variational notions of consistency, proving that residual minimization in Sobolev norms leads to convergence in energy and uniform norms under mild regularity. Deterministic stability bounds quantify how bounded perturbations to the network outputs propagate through the full composite loss, while probabilistic concentration results via McDiarmid's inequality yield sample complexity guarantees for residual-based generalization. A unified generalization bound links residual consistency, projection error, and perturbation sensitivity. Empirical results on elliptic, parabolic, and nonlinear PDEs confirm the predictive accuracy of our theoretical bounds across regimes. The framework identifies key structural principles, such as operator coercivity, activation smoothness, and sampling admissibility, that underlie robust and generalizable PINN training, offering principled guidance for the design and analysis of PDE-informed learning systems.
<div id='section'>Paperid: <span id='pid'>2083, <a href='https://arxiv.org/pdf/2506.09679.pdf' target='_blank'>https://arxiv.org/pdf/2506.09679.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Gracyk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.09679">Geometric flow regularization in latent spaces for smooth dynamics with the efficient variations of curvature</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We design strategies in nonlinear geometric analysis to temper the effects of adversarial learning for sufficiently smooth data of numerical method-type dynamics in encoder-decoder methods, variational and deterministic, through the use of geometric flow regularization. We augment latent spaces with geometric flows to control structure. Our techniques rely on adaptations of curvature and Ricci flow. We invent new geometric flows or discover them neurally and non-parametrically. All of our flows are solved using physics-informed learning. Traditional geometric meaning is traded for computing ability, but we maintain key geometric invariants, the primary of which are maintained, intrinsically-low structure, canonicity or a lack of irregularity, nontriviality due to sufficient lower bounds on curvature, and distortion of volume element, that develop quality in the inference stage. Our primary contributions are fourfold. We develop a loss based on Gaussian curvature using closed path circulation integration for surfaces, bypassing automatic differentiation of the Christoffel symbols through use of Stokes' theorem. We invent a new parametric flow derived from a linear version of the Gauss equation and a Riemannian decomposition for a custom tensor defined with a normal Hessian and Weyl tensor proxies. We develop two strategies based on time differentiation of functionals, one with a special case of scalar curvature for conformally-changed metrics, and another with harmonic maps, their energy, and induced metrics. Our methods, while diminished analytically, maintain overall integral latent structure. We showcase that curvature flows and the formulation of geometric structure in intermediary encoded settings enhance learning and overall zero-shot and adversarial fidelity.
<div id='section'>Paperid: <span id='pid'>2084, <a href='https://arxiv.org/pdf/2506.08036.pdf' target='_blank'>https://arxiv.org/pdf/2506.08036.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rahul Bhadani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.08036">Followerstopper Revisited: Phase-space Lagrangian Controller for Traffic Decongestion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper revisits Followerstopper, a phase-space-based control system that had demonstrated its ability to mitigate emergent traffic jams due to stop-and-go traffic during rush hour in the mixed-autonomy setting. Followerstopper was deployed on an autonomous vehicle. The controller attenuates the emanant traffic waves by regulating its velocity according to the relative distance and velocity of the leader car. While regulating the velocity, the controller also prevents the collision of the ego vehicle with the lead vehicle within the range specified by the controller's design parameter. The controller design is based on a configurable quadratic curve on relative distance-relative velocity phase-space that allows the transition of the regulated velocity from (i) no modification of input, (ii) decelerating to match the leader's velocity (iii) braking to avoid any imminent collision. In this paper, we explore the phase-space properties of Followerstopper and provide a detailed description of a nonlinear control law that regulates the reference input to Followerstopper within the physics-informed boundaries. We also provide a new discussion on the nominal control law that regulates the reference speed to Followerstopper to avoid unrealistic and unsafe acceleration.
<div id='section'>Paperid: <span id='pid'>2085, <a href='https://arxiv.org/pdf/2506.06308.pdf' target='_blank'>https://arxiv.org/pdf/2506.06308.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Adoubi Vincent De Paul Adombi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06308">Scientific machine learning in Hydrology: a unified perspective</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific machine learning (SciML) provides a structured approach to integrating physical knowledge into data-driven modeling, offering significant potential for advancing hydrological research. In recent years, multiple methodological families have emerged, including physics-informed machine learning, physics-guided machine learning, hybrid physics-machine learning, and data-driven physics discovery. Within each of these families, a proliferation of heterogeneous approaches has developed independently, often without conceptual coordination. This fragmentation complicates the assessment of methodological novelty and makes it difficult to identify where meaningful advances can still be made in the absence of a unified conceptual framework. This review, the first focused overview of SciML in hydrology, addresses these limitations by proposing a unified methodological framework for each SciML family, bringing together representative contributions into a coherent structure that fosters conceptual clarity and supports cumulative progress in hydrological modeling. Finally, we highlight the limitations and future opportunities of each unified family to guide systematic research in hydrology, where these methods remain underutilized.
<div id='section'>Paperid: <span id='pid'>2086, <a href='https://arxiv.org/pdf/2506.03161.pdf' target='_blank'>https://arxiv.org/pdf/2506.03161.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mira Nuthakki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.03161">Safety-Prioritized, Reinforcement Learning-Enabled Traffic Flow Optimization in a 3D City-Wide Simulation Environment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traffic congestion and collisions represent significant economic, environmental, and social challenges worldwide. Traditional traffic management approaches have shown limited success in addressing these complex, dynamic problems. To address the current research gaps, three potential tools are developed: a comprehensive 3D city-wide simulation environment that integrates both macroscopic and microscopic traffic dynamics; a collision model; and a reinforcement learning framework with custom reward functions prioritizing safety over efficiency. Unity game engine-based simulation is used for direct collision modeling. A custom reward enabled reinforcement learning method, proximal policy optimization (PPO) model, yields substantial improvements over baseline results, reducing the number of serious collisions, number of vehicle-vehicle collisions, and total distance travelled by over 3 times the baseline values. The model also improves fuel efficiency by 39% and reduces carbon emissions by 88%. Results establish feasibility for city-wide 3D traffic simulation applications incorporating the vision-zero safety principles of the Department of Transportation, including physics-informed, adaptable, realistic collision modeling, as well as appropriate reward modeling for real-world traffic signal light control towards reducing collisions, optimizing traffic flow and reducing greenhouse emissions.
<div id='section'>Paperid: <span id='pid'>2087, <a href='https://arxiv.org/pdf/2506.00951.pdf' target='_blank'>https://arxiv.org/pdf/2506.00951.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuyang Xiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00951">Physics-Informed Neural Networks for the Relativistic Burgers Equation in the Exterior of a Schwarzschild Black Hole</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a Physics-Informed Neural Networks(PINN) to solve a relativistic Burgers equation in the exterior domain of a Schwarzschild black hole. Our main contribution is a PINN architecture that is able to simulate shock wave formations in such curved spacetime, by training a shock-aware network block and introducing a Godunov-inspired residuals in the loss function. We validate our method with numerical experiments with different kinds of initial conditions. We show its ability to reproduce both smooth and discontinuous solutions in the context of general relativity.
<div id='section'>Paperid: <span id='pid'>2088, <a href='https://arxiv.org/pdf/2505.18169.pdf' target='_blank'>https://arxiv.org/pdf/2505.18169.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nischal Mandal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18169">Interpretable Multi-Task PINN for Emotion Recognition and EDA Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding and predicting human emotional and physiological states using wearable sensors has important applications in stress monitoring, mental health assessment, and affective computing. This study presents a novel Multi-Task Physics-Informed Neural Network (PINN) that performs Electrodermal Activity (EDA) prediction and emotion classification simultaneously, using the publicly available WESAD dataset. The model integrates psychological self-report features (PANAS and SAM) with a physics-inspired differential equation representing EDA dynamics, enforcing biophysically grounded constraints through a custom loss function. This loss combines EDA regression, emotion classification, and a physics residual term for improved interpretability.
  The architecture supports dual outputs for both tasks and is trained under a unified multi-task framework. Evaluated using 5-fold cross-validation, the model achieves an average EDA RMSE of 0.0362, Pearson correlation of 0.9919, and F1-score of 94.08 percent. These results outperform classical models such as SVR and XGBoost, as well as ablated variants like emotion-only and EDA-only models.
  In addition, the learned physical parameters including decay rate (alpha_0), emotional sensitivity (beta), and time scaling (gamma) are interpretable and stable across folds, aligning with known principles of human physiology. This work is the first to introduce a multi-task PINN framework for wearable emotion recognition, offering improved performance, generalizability, and model transparency. The proposed system provides a foundation for future interpretable and multimodal applications in healthcare and human-computer interaction.
<div id='section'>Paperid: <span id='pid'>2089, <a href='https://arxiv.org/pdf/2505.07222.pdf' target='_blank'>https://arxiv.org/pdf/2505.07222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nima Dehghani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07222">Compression, Regularity, Randomness and Emergent Structure: Rethinking Physical Complexity in the Data-Driven Era</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Complexity science offers a wide range of measures for quantifying unpredictability, structure, and information. Yet, a systematic conceptual organization of these measures is still missing.
  We present a unified framework that locates statistical, algorithmic, and dynamical measures along three axes (regularity, randomness, and complexity) and situates them in a common conceptual space. We map statistical, algorithmic, and dynamical measures into this conceptual space, discussing their computational accessibility and approximability.
  This taxonomy reveals the deep challenges posed by uncomputability and highlights the emergence of modern data-driven methods (including autoencoders, latent dynamical models, symbolic regression, and physics-informed neural networks) as pragmatic approximations to classical complexity ideals. Latent spaces emerge as operational arenas where regularity extraction, noise management, and structured compression converge, bridging theoretical foundations with practical modeling in high-dimensional systems.
  We close by outlining implications for physics-informed AI and AI-guided discovery in complex physical systems, arguing that classical questions of complexity remain central to next-generation scientific modeling.
<div id='section'>Paperid: <span id='pid'>2090, <a href='https://arxiv.org/pdf/2505.01819.pdf' target='_blank'>https://arxiv.org/pdf/2505.01819.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ze Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.01819">An LSTM-PINN Hybrid Method to the specific problem of population forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning has emerged as a powerful tool in scientific modeling, particularly for complex dynamical systems; however, accurately capturing age-structured population dynamics under policy-driven fertility changes remains a significant challenge due to the lack of effective integration between domain knowledge and long-term temporal dependencies. To address this issue, we propose two physics-informed deep learning frameworks--PINN and LSTM-PINN--that incorporate policy-aware fertility functions into a transport-reaction partial differential equation to simulate population evolution from 2024 to 2054. The standard PINN model enforces the governing equation and boundary conditions via collocation-based training, enabling accurate learning of underlying population dynamics and ensuring stable convergence. Building on this, the LSTM-PINN framework integrates sequential memory mechanisms to effectively capture long-range dependencies in the age-time domain, achieving robust training performance across multiple loss components. Simulation results under three distinct fertility policy scenarios-the Three-child policy, the Universal two-child policy, and the Separate two-child policy--demonstrate the models' ability to reflect policy-sensitive demographic shifts and highlight the effectiveness of integrating domain knowledge into data-driven forecasting. This study provides a novel and extensible framework for modeling age-structured population dynamics under policy interventions, offering valuable insights for data-informed demographic forecasting and long-term policy planning in the face of emerging population challenges.
<div id='section'>Paperid: <span id='pid'>2091, <a href='https://arxiv.org/pdf/2504.12949.pdf' target='_blank'>https://arxiv.org/pdf/2504.12949.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenao Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.12949">RL-PINNs: Reinforcement Learning-Driven Adaptive Sampling for Efficient Training of PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs). However, their performance heavily relies on the strategy used to select training points. Conventional adaptive sampling methods, such as residual-based refinement, often require multi-round sampling and repeated retraining of PINNs, leading to computational inefficiency due to redundant points and costly gradient computations-particularly in high-dimensional or high-order derivative scenarios. To address these limitations, we propose RL-PINNs, a reinforcement learning(RL)-driven adaptive sampling framework that enables efficient training with only a single round of sampling. Our approach formulates adaptive sampling as a Markov decision process, where an RL agent dynamically selects optimal training points by maximizing a long-term utility metric. Critically, we replace gradient-dependent residual metrics with a computationally efficient function variation as the reward signal, eliminating the overhead of derivative calculations. Furthermore, we employ a delayed reward mechanism to prioritize long-term training stability over short-term gains. Extensive experiments across diverse PDE benchmarks, including low-regular, nonlinear, high-dimensional, and high-order problems, demonstrate that RL-PINNs significantly outperforms existing residual-driven adaptive methods in accuracy. Notably, RL-PINNs achieve this with negligible sampling overhead, making them scalable to high-dimensional and high-order problems.
<div id='section'>Paperid: <span id='pid'>2092, <a href='https://arxiv.org/pdf/2503.17368.pdf' target='_blank'>https://arxiv.org/pdf/2503.17368.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Romain Lacombe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.17368">Non-Canonical Crosslinks Confound Evolutionary Protein Structure Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evolution-based protein structure prediction models have achieved breakthrough success in recent years. However, they struggle to generalize beyond evolutionary priors and on sequences lacking rich homologous data. Here we present a novel, out-of-domain benchmark based on sactipeptides, a rare class of ribosomally synthesized and post-translationally modified peptides (RiPPs) characterized by sulfur-to-$Î±$-carbon thioether bridges creating cross-links between cysteine residues and backbone. We evaluate recent models on predicting conformations compatible with these cross-links bridges for the 10 known sactipeptides with elucidated post-translational modifications. Crucially, the structures of 5 of them have not yet been experimentally resolved. This makes the task a challenging problem for evolution-based models, which we find exhibit limited performance (0.0% to 19.2% GDT-TS on sulfur-to-$Î±$-carbon distance). Our results point at the need for physics-informed models to sustain progress in biomolecular structure prediction.
<div id='section'>Paperid: <span id='pid'>2093, <a href='https://arxiv.org/pdf/2503.06436.pdf' target='_blank'>https://arxiv.org/pdf/2503.06436.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fan Meng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.06436">Physics-Informed Residual Neural Ordinary Differential Equations for Enhanced Tropical Cyclone Intensity Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate tropical cyclone (TC) intensity prediction is crucial for mitigating storm hazards, yet its complex dynamics pose challenges to traditional methods. Here, we introduce a Physics-Informed Residual Neural Ordinary Differential Equation (PIR-NODE) model to precisely forecast TC intensity evolution. This model leverages the powerful non-linear fitting capabilities of deep learning, integrates residual connections to enhance model depth and training stability, and explicitly models the continuous temporal evolution of TC intensity using Neural ODEs. Experimental results in the SHIPS dataset demonstrate that the PIR-NODE model achieves a significant improvement in 24-hour intensity prediction accuracy compared to traditional statistical models and benchmark deep learning methods, with a 25. 2\% reduction in the root mean square error (RMSE) and a 19.5\% increase in R-square (R2) relative to a baseline of neural network. Crucially, the residual structure effectively preserves initial state information, and the model exhibits robust generalization capabilities. This study details the PIR-NODE model architecture, physics-informed integration strategies, and comprehensive experimental validation, revealing the substantial potential of deep learning techniques in predicting complex geophysical systems and laying the foundation for future refined TC forecasting research.
<div id='section'>Paperid: <span id='pid'>2094, <a href='https://arxiv.org/pdf/2502.13827.pdf' target='_blank'>https://arxiv.org/pdf/2502.13827.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Mohammad-Djafari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.13827">Bayesian Physics Informed Neural Networks for Linear Inverse problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inverse problems arise almost everywhere in science and engineering where we need to infer on a quantity from indirect observation. The cases of medical, biomedical, and industrial imaging systems are the typical examples. A very high overview of classification of the inverse problems method can be: i) Analytical, ii) Regularization, and iii) Bayesian inference methods. Even if there are straight links between them, we can say that the Bayesian inference based methods are the most powerful, as they give the possibility of accounting for prior knowledge and can account for errors and uncertainties in general. One of the main limitations stay in computational costs in particular for high dimensional imaging systems. Neural Networks (NN), and in particular Deep NNs (DNN), have been considered as a way to push farther this limit. Physics Informed Neural Networks (PINN) concept integrates physical laws with deep learning techniques to enhance the speed, accuracy and efficiency of the above mentioned problems.
  In this work, a new Bayesian framework for the concept of PINN (BPINN) is presented and discussed which includes the deterministic one if we use the Maximum A Posteriori (MAP) estimation framework. We consider two cases of supervised and unsupervised for training step, obtain the expressions of the posterior probability of the unknown variables, and deduce the posterior laws of the NN's parameters. We also discuss about the challenges of implementation of these methods in real applications.
<div id='section'>Paperid: <span id='pid'>2095, <a href='https://arxiv.org/pdf/2502.07425.pdf' target='_blank'>https://arxiv.org/pdf/2502.07425.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keon Vin Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07425">Towards a Foundation Model for Physics-Informed Neural Networks: Multi-PDE Learning with Active Sampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical laws into neural network training. However, traditional PINN models are typically designed for single PDEs, limiting their generalizability across different physical systems. In this work, we explore the potential of a foundation PINN model capable of solving multiple PDEs within a unified architecture. We investigate the efficacy of a single PINN framework trained on four distinct PDEs-the Simple Harmonic Oscillator (SHO), the 1D Heat Equation, the 1D Wave Equation, and the 2D Laplace Equation, demonstrating its ability to learn diverse physical dynamics.
  To enhance sample efficiency, we incorporate Active Learning (AL) using Monte Carlo (MC) Dropout-based uncertainty estimation, selecting the most informative training samples iteratively. We evaluate different active learning strategies, comparing models trained on 10%, 20%, 30%, 40%, and 50% of the full dataset, and analyze their impact on solution accuracy. Our results indicate that targeted uncertainty sampling significantly improves performance with fewer training samples, leading to efficient learning across multiple PDEs.
  This work highlights the feasibility of a generalizable PINN-based foundation model, capable of adapting to different physics-based problems without redesigning network architectures. Our findings suggest that multi-PDE PINNs with active learning can serve as an effective approach for reducing computational costs while maintaining high accuracy in physics-based deep learning applications.
<div id='section'>Paperid: <span id='pid'>2096, <a href='https://arxiv.org/pdf/2502.03963.pdf' target='_blank'>https://arxiv.org/pdf/2502.03963.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Keon Vin Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03963">AL-PINN: Active Learning-Driven Physics-Informed Neural Networks for Efficient Sample Selection in Solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a promising approach for solving Partial Differential Equations (PDEs) by incorporating physical constraints into deep learning models. However, standard PINNs often require a large number of training samples to achieve high accuracy, leading to increased computational costs. To address this issue, we propose Active Learning-Driven PINNs (AL-PINN), which integrates Uncertainty Quantification (UQ) and Active Learning (AL) strategies to optimize sample selection dynamically.
  AL-PINN utilizes Monte Carlo Dropout to estimate epistemic uncertainty in the model predictions, enabling the adaptive selection of high-uncertainty regions for additional training. This approach significantly enhances learning efficiency by focusing computational resources on the most informative data points. We evaluate AL-PINN on benchmark PDE problems with known analytical solutions and real-world WeatherBench climate data. Our results demonstrate that AL-PINN achieves comparable or superior accuracy compared to traditional PINNs while reducing the number of required training samples.
  The proposed framework is particularly beneficial for scientific and engineering applications where data collection is expensive or limited, such as climate modeling, medical simulations, and material science. Our findings highlight the potential of active learning in accelerating PINN-based PDE solvers while maintaining high accuracy and computational efficiency.
<div id='section'>Paperid: <span id='pid'>2097, <a href='https://arxiv.org/pdf/2501.10825.pdf' target='_blank'>https://arxiv.org/pdf/2501.10825.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Karthik Reddy Lyathakula
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.10825">Statistical Design of Thermal Protection System Using Physics-Informed Machine learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Estimating the material properties of thermal protection films is crucial for their effective design and application, particularly in high-temperature environments. This work presents a novel approach to determine the properties using uncertainty quantification simulations. We quantify uncertainty in the material properties for effective insulation by proposing a Bayesian distribution for them. Sampling from this distribution is performed using Monte Carlo simulations, which require repeatedly solving the predictive thermal model. To address the computational inefficiency of conventional numerical simulations, we develop a parametric Physics-Informed Neural Network (PINN) to solve the heat transfer problem. The proposed PINN significantly reduces computational time while maintaining accuracy, as verified against traditional numerical solutions. Additionally, we used the Sequential Monte Carlo (SMC) method to enable vectorized and parallel computations, further enhancing computational speedup. Our results demonstrate that integrating MCMC with PINN decreases computational time substantially compared to using standard numerical methods. Moreover, combining the SMC method with PINN yields multifold computational speedup, making this approach highly effective for the rapid and accurate estimation of material properties.
<div id='section'>Paperid: <span id='pid'>2098, <a href='https://arxiv.org/pdf/2501.04305.pdf' target='_blank'>https://arxiv.org/pdf/2501.04305.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Scheinker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.04305">Physics-Informed Super-Resolution Diffusion for 6D Phase Space Diagnostics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adaptive physics-informed super-resolution diffusion is developed for non-invasive virtual diagnostics of the 6D phase space density of charged particle beams. An adaptive variational autoencoder (VAE) embeds initial beam condition images and scalar measurements to a low-dimensional latent space from which a 326 pixel 6D tensor representation of the beam's 6D phase space density is generated. Projecting from a 6D tensor generates physically consistent 2D projections. Physics-guided super-resolution diffusion transforms low-resolution images of the 6D density to high resolution 256x256 pixel images. Un-supervised adaptive latent space tuning enables tracking of time-varying beams without knowledge of time-varying initial conditions. The method is demonstrated with experimental data and multi-particle simulations at the HiRES UED. The general approach is applicable to a wide range of complex dynamic systems evolving in high-dimensional phase space. The method is shown to be robust to distribution shift without re-training.
<div id='section'>Paperid: <span id='pid'>2099, <a href='https://arxiv.org/pdf/2501.03254.pdf' target='_blank'>https://arxiv.org/pdf/2501.03254.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akshansh Mishra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.03254">Advanced Displacement Magnitude Prediction in Multi-Material Architected Lattice Structure Beams Using Physics Informed Neural Network Architecture</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes an innovative method for predicting deformation in architected lattice structures that combines Physics-Informed Neural Networks (PINNs) with finite element analysis. A thorough study was carried out on FCC-based lattice beams utilizing five different materials (Structural Steel, AA6061, AA7075, Ti6Al4V, and Inconel 718) under varied edge loads (1000-10000 N). The PINN model blends data-driven learning with physics-based limitations via a proprietary loss function, resulting in much higher prediction accuracy than linear regression. PINN outperforms linear regression, achieving greater R-square (0.7923 vs 0.5686) and lower error metrics (MSE: 0.00017417 vs 0.00036187). Among the materials examined, AA6061 had the highest displacement sensitivity (0.1014 mm at maximum load), while Inconel718 had better structural stability.
<div id='section'>Paperid: <span id='pid'>2100, <a href='https://arxiv.org/pdf/2501.00288.pdf' target='_blank'>https://arxiv.org/pdf/2501.00288.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chunyang Liao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.00288">Solving Partial Differential Equations with Random Feature Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning based partial differential equations (PDEs) solvers have received great attention in recent years. Most progress in this area has been driven by deep neural networks such as physics-informed neural networks (PINNs) and kernel method. In this paper, we introduce a random feature based framework toward efficiently solving PDEs. Random feature method was originally proposed to approximate large-scale kernel machines and can be viewed as a shallow neural network as well. We provide an error analysis for our proposed method along with comprehensive numerical results on several PDE benchmarks. In contrast to the state-of-the-art solvers that face challenges with a large number of collocation points, our proposed method reduces the computational complexity. Moreover, the implementation of our method is simple and does not require additional computational resources. Due to the theoretical guarantee and advantages in computation, our approach is proven to be efficient for solving PDEs.
<div id='section'>Paperid: <span id='pid'>2101, <a href='https://arxiv.org/pdf/2412.18564.pdf' target='_blank'>https://arxiv.org/pdf/2412.18564.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Apurba Sarker
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.18564">Efficient Aircraft Design Optimization Using Multi-Fidelity Models and Multi-fidelity Physics Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Aircraft design optimization traditionally relies on computationally expensive simulation techniques such as Finite Element Method (FEM) and Finite Volume Method (FVM), which, while accurate, can significantly slow down the design iteration process. The challenge lies in reducing the computational complexity while maintaining high accuracy for quick evaluations of multiple design alternatives. This research explores advanced methods, including surrogate models, reduced-order models (ROM), and multi-fidelity machine learning techniques, to achieve more efficient aircraft design evaluations. Specifically, the study investigates the application of Multi-fidelity Physics-Informed Neural Networks (MPINN) and autoencoders for manifold alignment, alongside the potential of Generative Adversarial Networks (GANs) for refining design geometries. Through a proof-of-concept task, the research demonstrates the ability to predict high-fidelity results from low-fidelity simulations, offering a path toward faster and more cost effective aircraft design iterations.
<div id='section'>Paperid: <span id='pid'>2102, <a href='https://arxiv.org/pdf/2412.15079.pdf' target='_blank'>https://arxiv.org/pdf/2412.15079.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunli Shao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.15079">A Traffic Adapative Physics-informed Learning Control for Energy Savings of Connected and Automated Vehicles</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model predictive control has emerged as an effective approach for real-time optimal control of connected and automated vehicles. However, nonlinear dynamics of vehicle and traffic systems make accurate modeling and real-time optimization challenging. Learning-based control offer a promising alternative, as they adapt to environment without requiring an explicit model. For learning control framework, an augmented state space system design is necessary since optimal control depends on both the ego vehicle's state and predicted states of other vehicles. This work develops a traffic adaptive augmented state space system that allows the control strategy to intelligently adapt to varying traffic conditions. This design ensures that while different vehicle trajectories alter initial conditions, the system dynamics remain independent of specific trajectories. Additionally, a physics-informed learning control framework is presented that combines value function from Bellman's equation with derivative of value functions from Pontryagin's Maximum Principle into a unified loss function. This method aims to reduce required training data and time while enhancing robustness and efficiency. The proposed control framework is applied to car-following scenarios in real-world data calibrated simulation environments. The results show that this learning control approach alleviates real-time computational requirements while achieving car-following behaviors comparable to model-based methods, resulting in 9% energy savings in scenarios not previously seen in training dataset.
<div id='section'>Paperid: <span id='pid'>2103, <a href='https://arxiv.org/pdf/2412.11526.pdf' target='_blank'>https://arxiv.org/pdf/2412.11526.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohsen Rashki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.11526">Probabilities-Informed Machine Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning (ML) has emerged as a powerful tool for tackling complex regression and classification tasks, yet its success often hinges on the quality of training data. This study introduces an ML paradigm inspired by domain knowledge of the structure of output function, akin to physics-informed ML, but rooted in probabilistic principles rather than physical laws. The proposed approach integrates the probabilistic structure of the target variable (such as its cumulative distribution function) into the training process. This probabilistic information is obtained from historical data or estimated using structural reliability methods during experimental design. By embedding domain-specific probabilistic insights into the learning process, the technique enhances model accuracy and mitigates risks of overfitting and underfitting. Applications in regression, image denoising, and classification demonstrate the approach's effectiveness in addressing real-world problems.
<div id='section'>Paperid: <span id='pid'>2104, <a href='https://arxiv.org/pdf/2412.02222.pdf' target='_blank'>https://arxiv.org/pdf/2412.02222.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Advait Chandorkar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02222">Deep learning approach for predicting the replicator equation in evolutionary game theory</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a physics-informed deep learning approach for predicting the replicator equation, allowing accurate forecasting of population dynamics. This methodological innovation allows us to derive governing differential or difference equations for systems that lack explicit mathematical models. We used the SINDy model first introduced by Fasel, Kaiser, Kutz, Brunton, and Brunt 2016a to get the replicator equation, which will significantly advance our understanding of evolutionary biology, economic systems, and social dynamics. By refining predictive models across multiple disciplines, including ecology, social structures, and moral behaviours, our work offers new insights into the complex interplay of variables shaping evolutionary outcomes in dynamic systems
<div id='section'>Paperid: <span id='pid'>2105, <a href='https://arxiv.org/pdf/2411.10483.pdf' target='_blank'>https://arxiv.org/pdf/2411.10483.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Reyhaneh Taj
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.10483">Physics-Informed Neural Networks for Electrical Circuit Analysis: Applications in Dielectric Material Modeling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific machine learning (SciML) represents a significant advancement in integrating machine learning (ML) with scientific methodologies. At the forefront of this development are Physics-Informed Neural Networks (PINNs), which offer a promising approach by incorporating physical laws directly into the learning process, thereby reducing the need for extensive datasets. However, when data is limited or the system becomes more complex, PINNs can face challenges, such as instability and difficulty in accurately fitting the training data. In this article, we explore the capabilities and limitations of the DeepXDE framework, a tool specifically designed for implementing PINNs, in addressing both forward and inverse problems related to dielectric properties. Using RC circuit models to represent dielectric materials in HVDC systems, we demonstrate the effectiveness of PINNs in analyzing and improving system performance. Additionally, we show that applying a logarithmic transformation to the current (ln(I)) significantly enhances the stability and accuracy of PINN predictions, especially in challenging scenarios with sparse data or complex models. In inverse mode, however, we faced challenges in estimating key system parameters, such as resistance and capacitance, in more complex scenarios with longer time domains. This highlights the potential for future work in improving PINNs through transformations or other methods to enhance performance in inverse problems. This article provides pedagogical insights for those looking to use PINNs in both forward and inverse modes, particularly within the DeepXDE framework.
<div id='section'>Paperid: <span id='pid'>2106, <a href='https://arxiv.org/pdf/2411.02177.pdf' target='_blank'>https://arxiv.org/pdf/2411.02177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rodrigo Carmo Terin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.02177">Physics-informed neural networks viewpoint for solving the Dyson-Schwinger equations of quantum electrodynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) are employed to solve the Dyson--Schwinger equations of quantum electrodynamics (QED) in Euclidean space, with a focus on the non-perturbative generation of the fermion's dynamical mass function in the Landau gauge. By inserting the integral equation directly into the loss function, our PINN framework enables a single neural network to learn a continuous and differentiable representation of the mass function over a spectrum of momenta. Also, we benchmark our approach against a traditional numerical algorithm showing the main differences among them. Our novel strategy, which is expected to be extended to other quantum field theories, is the first step towards forefront applications of machine learning in high-level theoretical physics.
<div id='section'>Paperid: <span id='pid'>2107, <a href='https://arxiv.org/pdf/2410.18593.pdf' target='_blank'>https://arxiv.org/pdf/2410.18593.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinrui Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.18593">Differential Informed Auto-Encoder</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this article, an encoder was trained to obtain the inner structure of the original data by obtain a differential equations. A decoder was trained to resample the original data domain, to generate new data that obey the differential structure of the original data using the physics-informed neural network.
<div id='section'>Paperid: <span id='pid'>2108, <a href='https://arxiv.org/pdf/2410.14760.pdf' target='_blank'>https://arxiv.org/pdf/2410.14760.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vasileios Vatellis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14760">Advancing Physics Data Analysis through Machine Learning and Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In an era increasingly focused on green computing and explainable AI, revisiting traditional approaches in theoretical and phenomenological particle physics is paramount. This project evaluates various machine learning (ML) algorithms-including Nearest Neighbors, Decision Trees, Random Forest, AdaBoost, Naive Bayes, Quadratic Discriminant Analysis (QDA), and XGBoost-alongside standard neural networks and a novel Physics-Informed Neural Network (PINN) for physics data analysis. We apply these techniques to a binary classification task that distinguishes the experimental viability of simulated scenarios based on Higgs observables and essential parameters. Through this comprehensive analysis, we aim to showcase the capabilities and computational efficiency of each model in binary classification tasks, thereby contributing to the ongoing discourse on integrating ML and Deep Neural Networks (DNNs) into physics research. In this study, XGBoost emerged as the preferred choice among the evaluated machine learning algorithms for its speed and effectiveness, especially in the initial stages of computation with limited datasets. However, while standard Neural Networks and Physics-Informed Neural Networks (PINNs) demonstrated superior performance in terms of accuracy and adherence to physical laws, they require more computational time. These findings underscore the trade-offs between computational efficiency and model sophistication.
<div id='section'>Paperid: <span id='pid'>2109, <a href='https://arxiv.org/pdf/2410.14134.pdf' target='_blank'>https://arxiv.org/pdf/2410.14134.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sidi Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14134">Fine-Tuning DeepONets to Enhance Physics-informed Neural Networks for solving Partial Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as powerful tools for solving partial differential equations (PDEs). However, training PINNs from scratch is often computationally intensive and time-consuming. To address this problem, we propose a parameter-efficient approach that fine-tunes pre-trained DeepONet models within the PINN framework (FTO-PINN), enabling more efficient meshless PDE solving. Specifically, we freeze the weights of the pre-trained DeepONet model and fine-tune the output of the branch net by incorporating a small number of new trainable parameters, which can be quickly determined using least-squares techniques. Additionally, we introduce trunk net expansions and low-rank adaptation strategies to further enhance the performance of FTO-PINN. The effectiveness of our proposed method is demonstrated through a series of numerical experiments across various types of PDEs. FTO-PINN significantly reduces the training time of vanilla PINNs while maintaining comparable accuracy, and outperforms DeepONet, which is pre-trained on general function data, in both fidelity and generalization capabilities.
<div id='section'>Paperid: <span id='pid'>2110, <a href='https://arxiv.org/pdf/2410.10137.pdf' target='_blank'>https://arxiv.org/pdf/2410.10137.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Gracyk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10137">Variational autoencoders with latent high-dimensional steady geometric flows for dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop Riemannian approaches to variational autoencoders (VAEs) for PDE-type ambient data with regularizing geometric latent dynamics, which we refer to as VAE-DLM, or VAEs with dynamical latent manifolds. We redevelop the VAE framework such that manifold geometries, subject to our geometric flow, embedded in Euclidean space are learned in the intermediary latent space developed by encoders and decoders. By tailoring the geometric flow in which the latent space evolves, we induce latent geometric properties of our choosing, which are reflected in empirical performance. We reformulate the traditional evidence lower bound (ELBO) loss with a considerate choice of prior. We develop a linear geometric flow with a steady-state regularizing term. This flow requires only automatic differentiation of one time derivative, and can be solved in moderately high dimensions in a physics-informed approach, allowing more expressive latent representations. We discuss how this flow can be formulated as a gradient flow, and maintains entropy away from metric singularity. This, along with an eigenvalue penalization condition, helps ensure the manifold is sufficiently large in measure, nondegenerate, and a canonical geometry, which contribute to a robust representation. Our methods focus on the modified multi-layer perceptron architecture with tanh activations for the manifold encoder-decoder. We demonstrate, on our datasets of interest, our methods perform at least as well as the traditional VAE, and oftentimes better. Our methods can outperform this and a VAE endowed with our proposed architecture, frequently reducing out-of-distribution (OOD) error between 15% to 35% on select datasets. We highlight our method on ambient PDEs whose solutions maintain minimal variation in late times. We provide empirical justification towards how we can improve robust learning for external dynamics with VAEs.
<div id='section'>Paperid: <span id='pid'>2111, <a href='https://arxiv.org/pdf/2410.07527.pdf' target='_blank'>https://arxiv.org/pdf/2410.07527.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vineet Jagadeesan Nair
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07527">Enhanced physics-informed neural networks (PINNs) for high-order power grid dynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop improved physics-informed neural networks (PINNs) for high-order and high-dimensional power system models described by nonlinear ordinary differential equations. We propose some novel enhancements to improve PINN training and accuracy and also implement several other recently proposed ideas from the literature. We successfully apply these to study the transient dynamics of synchronous generators. We also make progress towards applying PINNs to advanced inverter models. Such enhanced PINNs can allow us to accelerate high-fidelity simulations needed to ensure a stable and reliable renewables-rich future grid.
<div id='section'>Paperid: <span id='pid'>2112, <a href='https://arxiv.org/pdf/2410.04344.pdf' target='_blank'>https://arxiv.org/pdf/2410.04344.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yahong Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04344">DeepONet for Solving Nonlinear Partial Differential Equations with Physics-Informed Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we investigate the use of operator learning, specifically DeepONet, for solving nonlinear partial differential equations (PDEs). Unlike conventional function learning methods that require training separate neural networks for each PDE, operator learning enables generalization across different PDEs without retraining. This study examines the performance of DeepONet in physics-informed training, focusing on two key aspects: (1) the approximation capabilities of deep branch and trunk networks, and (2) the generalization error in Sobolev norms. Our results demonstrate that deep branch networks provide substantial performance improvements, while trunk networks achieve optimal results when kept relatively simple. Furthermore, we derive a bound on the generalization error of DeepONet for solving nonlinear PDEs by analyzing the Rademacher complexity of its derivatives in terms of pseudo-dimension. This work bridges a critical theoretical gap by delivering rigorous error estimates. This paper fills a theoretical gap by providing error estimations for a wide range of physics-informed machine learning models and applications.
<div id='section'>Paperid: <span id='pid'>2113, <a href='https://arxiv.org/pdf/2410.04344.pdf' target='_blank'>https://arxiv.org/pdf/2410.04344.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yahong Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04344">DeepONet for Solving Nonlinear Partial Differential Equations with Physics-Informed Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we investigate the applications of operator learning, specifically DeepONet, for solving nonlinear partial differential equations (PDEs). Unlike conventional function learning methods that require training separate neural networks for each PDE, operator learning enables generalization across different PDEs without retraining. This study examines the performance of DeepONet in physics-informed training, focusing on two key aspects: (1) the approximation capabilities of deep branch and trunk networks, and (2) the generalization error in Sobolev norms. Our results show that complex branch networks provide substantial performance gains, while trunk networks are most effective when kept relatively simple. Furthermore, we derive a bound on the generalization error of DeepONet for solving nonlinear PDEs by analyzing the Rademacher complexity of its derivatives in terms of pseudo-dimension. This work bridges a critical theoretical gap by delivering rigorous error estimates. This paper fills a theoretical gap by providing error estimates for a wide range of physics-informed machine learning models and applications.
<div id='section'>Paperid: <span id='pid'>2114, <a href='https://arxiv.org/pdf/2410.04114.pdf' target='_blank'>https://arxiv.org/pdf/2410.04114.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Amirmahdi Jafari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04114">Transport-Embedded Neural Architecture: Redefining the Landscape of physics aware neural models in fluid mechanics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces a new neural model which follows the transport equation by design. A physical problem, the Taylor-Green vortex, defined on a bi-periodic domain, is used as a benchmark to evaluate the performance of both the standard physics-informed neural network and our model (transport-embedded neural network). Results exhibit that while the standard physics-informed neural network fails to predict the solution accurately and merely returns the initial condition for the entire time span, our model successfully captures the temporal changes in the physics, particularly for high Reynolds numbers of the flow. Additionally, the ability of our model to prevent false minima can pave the way for addressing multiphysics problems, which are more prone to false minima, and help them accurately predict complex physics.
<div id='section'>Paperid: <span id='pid'>2115, <a href='https://arxiv.org/pdf/2409.18397.pdf' target='_blank'>https://arxiv.org/pdf/2409.18397.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomohisa Okazaki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.18397">Scientific Machine Learning Seismology</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scientific machine learning (SciML) is an interdisciplinary research field that integrates machine learning, particularly deep learning, with physics theory to understand and predict complex natural phenomena. By incorporating physical knowledge, SciML reduces the dependency on observational data, which is often limited in the natural sciences. In this article, the fundamental concepts of SciML, its applications in seismology, and prospects are described. Specifically, two popular methods are mainly discussed: physics-informed neural networks (PINNs) and neural operators (NOs). PINNs can address both forward and inverse problems by incorporating governing laws into the loss functions. The use of PINNs is expanding into areas such as simultaneous solutions of differential equations, inference in underdetermined systems, and regularization based on physics. These research directions would broaden the scope of deep learning in natural sciences. NOs are models designed for operator learning, which deals with relationships between infinite-dimensional spaces. NOs show promise in modeling the time evolution of complex systems based on observational or simulation data. Since large amounts of data are often required, combining NOs with physics-informed learning holds significant potential. Finally, SciML is considered from a broader perspective beyond deep learning: statistical (or mathematical) frameworks that integrate observational data with physical principles to model natural phenomena. In seismology, mathematically rigorous Bayesian statistics has been developed over the past decades, whereas more flexible and scalable deep learning has only emerged recently. Both approaches can be considered as part of SciML in a broad sense. Theoretical and practical insights in both directions would advance SciML methodologies and thereby deepen our understanding of earthquake phenomena.
<div id='section'>Paperid: <span id='pid'>2116, <a href='https://arxiv.org/pdf/2409.16214.pdf' target='_blank'>https://arxiv.org/pdf/2409.16214.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arman Asgharpoor Golroudbari
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.16214">TE-PINN: Quaternion-Based Orientation Estimation using Transformer-Enhanced Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a Transformer-Enhanced Physics-Informed Neural Network (TE-PINN) designed for accurate quaternion-based orientation estimation in high-dynamic environments, particularly within the field of robotics. By integrating transformer networks with physics-informed learning, our approach innovatively captures temporal dependencies in sensor data while enforcing the fundamental physical laws governing rotational motion. TE-PINN leverages a multi-head attention mechanism to handle sequential data from inertial sensors, such as accelerometers and gyroscopes, ensuring temporal consistency. Simultaneously, the model embeds quaternion kinematics and rigid body dynamics into the learning process, aligning the network's predictions with mechanical principles like Euler's laws of motion. The physics-informed loss function incorporates the dynamics of angular velocity and external forces, enhancing the network's ability to generalize in complex scenarios. Our experimental evaluation demonstrates that TE-PINN consistently outperforms traditional methods such as Extended Kalman Filters (EKF) and LSTM-based estimators, particularly in scenarios characterized by high angular velocities and noisy sensor data. The results show a significant reduction in mean quaternion error and improved gyroscope bias estimation compared to the state-of-the-art. An ablation study further isolates the contributions of both the transformer architecture and the physics-informed constraints, highlighting the synergistic effect of both components in improving model performance. The proposed model achieves real-time performance on embedded systems typical of mobile robots, offering a scalable and efficient solution for orientation estimation in autonomous systems.
<div id='section'>Paperid: <span id='pid'>2117, <a href='https://arxiv.org/pdf/2409.06649.pdf' target='_blank'>https://arxiv.org/pdf/2409.06649.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Afzal Aghaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06649">KANtrol: A Physics-Informed Kolmogorov-Arnold Network Framework for Solving Multi-Dimensional and Fractional Optimal Control Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we introduce the KANtrol framework, which utilizes Kolmogorov-Arnold Networks (KANs) to solve optimal control problems involving continuous time variables. We explain how Gaussian quadrature can be employed to approximate the integral parts within the problem, particularly for integro-differential state equations. We also demonstrate how automatic differentiation is utilized to compute exact derivatives for integer-order dynamics, while for fractional derivatives of non-integer order, we employ matrix-vector product discretization within the KAN framework. We tackle multi-dimensional problems, including the optimal control of a 2D heat partial differential equation. The results of our simulations, which cover both forward and parameter identification problems, show that the KANtrol framework outperforms classical MLPs in terms of accuracy and efficiency.
<div id='section'>Paperid: <span id='pid'>2118, <a href='https://arxiv.org/pdf/2409.05030.pdf' target='_blank'>https://arxiv.org/pdf/2409.05030.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ronald Katende
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.05030">Unified theoretical guarantees for stability, consistency, and convergence in neural PDE solvers from non-IID data to physics-informed networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We establish a unified theoretical framework addressing the stability, consistency, and convergence of neural networks under realistic training conditions, specifically, in the presence of non-IID data, geometric constraints, and embedded physical laws. For standard supervised learning with dependent data, we derive uniform stability bounds for gradient-based methods using mixing coefficients and dynamic learning rates. In federated learning with heterogeneous data and non-Euclidean parameter spaces, we quantify model inconsistency via curvature-aware aggregation and information-theoretic divergence. For Physics-Informed Neural Networks (PINNs), we rigorously prove perturbation stability, residual consistency, Sobolev convergence, energy stability for conservation laws, and convergence under adaptive multi-domain refinements. Each result is grounded in variational analysis, compactness arguments, and universal approximation theorems in Sobolev spaces. Our theoretical guarantees are validated across parabolic, elliptic, and hyperbolic PDEs, confirming that residual minimization aligns with physical solution accuracy. This work offers a mathematically principled basis for designing robust, generalizable, and physically coherent neural architectures across diverse learning environments.
<div id='section'>Paperid: <span id='pid'>2119, <a href='https://arxiv.org/pdf/2409.03507.pdf' target='_blank'>https://arxiv.org/pdf/2409.03507.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Afzal Aghaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03507">A Physics-Informed Machine Learning Approach for Solving Distributed Order Fractional Differential Equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces a novel methodology for solving distributed-order fractional differential equations using a physics-informed machine learning framework. The core of this approach involves extending the support vector regression (SVR) algorithm to approximate the unknown solutions of the governing equations during the training phase. By embedding the distributed-order functional equation into the SVR framework, we incorporate physical laws directly into the learning process. To further enhance computational efficiency, Gegenbauer orthogonal polynomials are employed as the kernel function, capitalizing on their fractional differentiation properties to streamline the problem formulation. Finally, the resulting optimization problem of SVR is addressed either as a quadratic programming problem or as a positive definite system in its dual form. The effectiveness of the proposed approach is validated through a series of numerical experiments on Caputo-based distributed-order fractional differential equations, encompassing both ordinary and partial derivatives.
<div id='section'>Paperid: <span id='pid'>2120, <a href='https://arxiv.org/pdf/2409.01293.pdf' target='_blank'>https://arxiv.org/pdf/2409.01293.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Skyler Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01293">Extracting Signal out of Chaos: Advancements on MAGI for Bayesian Analysis of Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work builds off the manifold-constrained Gaussian process inference (MAGI) method for Bayesian parameter inference and trajectory reconstruction of ODE-based dynamical systems, focusing primarily on sparse and noisy data conditions. First, we introduce Pilot MAGI (pMAGI), a novel methodological upgrade on the base MAGI method that confers significantly-improved numerical stability, parameter inference, and trajectory reconstruction. Second, we demonstrate, for the first time to our knowledge, how one can combine MAGI-based methods with dynamical systems theory to provide probabilistic classifications of whether a system is stable or chaotic. Third, we demonstrate how pMAGI performs favorably in many settings against much more computationally-expensive and overparameterized methods. Fourth, we introduce Pilot MAGI Sequential Prediction (PMSP), a novel method building upon pMAGI that allows one to predict the trajectory of ODE-based dynamical systems multiple time steps into the future, given only sparse and noisy observations. We show that PMSP can output accurate future predictions even on chaotic dynamical systems and significantly outperform PINN-based methods. Overall, we contribute to the literature two novel methods, pMAGI and PMSP, that serve as Bayesian, uncertainty-quantified competitors to the Physics-Informed Neural Network.
<div id='section'>Paperid: <span id='pid'>2121, <a href='https://arxiv.org/pdf/2407.21642.pdf' target='_blank'>https://arxiv.org/pdf/2407.21642.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Turinici
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.21642">Regime-Aware Time Weighting for Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel method to handle the time dimension when Physics-Informed Neural Networks (PINNs) are used to solve time-dependent differential equations; our proposal focuses on how time sampling and weighting strategies affect solution quality. While previous methods proposed heuristic time-weighting schemes, our approach is grounded in theoretical insights derived from the Lyapunov exponents, which quantify the sensitivity of solutions to perturbations over time. This principled methodology automatically adjusts weights based on the stability regime of the system -- whether chaotic, periodic, or stable. Numerical experiments on challenging benchmarks, including the chaotic Lorenz system and the Burgers' equation, demonstrate the effectiveness and robustness of the proposed method. Compared to existing techniques, our approach offers improved convergence and accuracy without requiring additional hyperparameter tuning. The findings underline the importance of incorporating causality and dynamical system behavior into PINN training strategies, providing a robust framework for solving time-dependent problems with enhanced reliability.
<div id='section'>Paperid: <span id='pid'>2122, <a href='https://arxiv.org/pdf/2407.20026.pdf' target='_blank'>https://arxiv.org/pdf/2407.20026.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gaoyuan Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.20026">JAX-SSO: Differentiable Finite Element Analysis Solver for Structural Optimization and Seamless Integration with Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Differentiable numerical simulations of physical systems have gained rising attention in the past few years with the development of automatic differentiation tools. This paper presents JAX-SSO, a differentiable finite element analysis solver built with JAX, Google's high-performance computing library, to assist efficient structural design in the built environment. With the adjoint method and automatic differentiation feature, JAX-SSO can efficiently evaluate gradients of physical quantities in an automatic way, enabling accurate sensitivity calculation in structural optimization problems. Written in Python and JAX, JAX-SSO is naturally within the machine learning ecosystem so it can be seamlessly integrated with neural networks to train machine learning models with inclusion of physics. Moreover, JAX-SSO supports GPU acceleration to further boost finite element analysis. Several examples are presented to showcase the capabilities and efficiency of JAX-SSO: i) shape optimization of grid-shells and continuous shells; ii) size (thickness) optimization of continuous shells; iii) simultaneous shape and topology optimization of continuous shells; and iv) training of physics-informed neural networks for structural optimization. We believe that JAX-SSO can facilitate research related to differentiable physics and machine learning to further address problems in structural and architectural design.
<div id='section'>Paperid: <span id='pid'>2123, <a href='https://arxiv.org/pdf/2407.18798.pdf' target='_blank'>https://arxiv.org/pdf/2407.18798.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abiodun Finbarrs Oketunji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.18798">Predicting 3D Rigid Body Dynamics with Deep Residual Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the application of deep residual networks for predicting the dynamics of interacting three-dimensional rigid bodies. We present a framework combining a 3D physics simulator implemented in C++ with a deep learning model constructed using PyTorch. The simulator generates training data encompassing linear and angular motion, elastic collisions, fluid friction, gravitational effects, and damping. Our deep residual network, consisting of an input layer, multiple residual blocks, and an output layer, is designed to handle the complexities of 3D dynamics. We evaluate the network's performance using a datasetof 10,000 simulated scenarios, each involving 3-5 interacting rigid bodies. The model achieves a mean squared error of 0.015 for position predictions and 0.022 for orientation predictions, representing a 25% improvement over baseline methods. Our results demonstrate the network's ability to capture intricate physical interactions, with particular success in predicting elastic collisions and rotational dynamics. This work significantly contributes to physics-informed machine learning by showcasing the immense potential of deep residual networks in modeling complex 3D physical systems. We discuss our approach's limitations and propose future directions for improving generalization to more diverse object shapes and materials.
<div id='section'>Paperid: <span id='pid'>2124, <a href='https://arxiv.org/pdf/2407.12598.pdf' target='_blank'>https://arxiv.org/pdf/2407.12598.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mizuka Komatsu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.12598">Estimate Epidemiological Parameters given Partial Observations based on Algebraically Observable PINNs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this study, we considered the problem of estimating epidemiological parameters based on physics-informed neural networks (PINNs). In practice, not all trajectory data corresponding to the population estimated by epidemic models can be obtained, and some observed trajectories are noisy. Learning PINNs to estimate unknown epidemiological parameters using such partial observations is challenging. Accordingly, we introduce the concept of algebraic observability into PINNs. The validity of the proposed PINN, named as an algebraically observable PINNs, in terms of estimation parameters and prediction of unobserved variables, is demonstrated through numerical experiments.
<div id='section'>Paperid: <span id='pid'>2125, <a href='https://arxiv.org/pdf/2406.07456.pdf' target='_blank'>https://arxiv.org/pdf/2406.07456.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alireza Afzal Aghaei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.07456">fKAN: Fractional Kolmogorov-Arnold Networks with trainable Jacobi basis functions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in neural network design have given rise to the development of Kolmogorov-Arnold Networks (KANs), which enhance speed, interpretability, and precision. This paper presents the Fractional Kolmogorov-Arnold Network (fKAN), a novel neural network architecture that incorporates the distinctive attributes of KANs with a trainable adaptive fractional-orthogonal Jacobi function as its basis function. By leveraging the unique mathematical properties of fractional Jacobi functions, including simple derivative formulas, non-polynomial behavior, and activity for both positive and negative input values, this approach ensures efficient learning and enhanced accuracy. The proposed architecture is evaluated across a range of tasks in deep learning and physics-informed deep learning. Precision is tested on synthetic regression data, image classification, image denoising, and sentiment analysis. Additionally, the performance is measured on various differential equations, including ordinary, partial, and fractional delay differential equations. The results demonstrate that integrating fractional Jacobi functions into KANs significantly improves training speed and performance across diverse fields and applications.
<div id='section'>Paperid: <span id='pid'>2126, <a href='https://arxiv.org/pdf/2406.00276.pdf' target='_blank'>https://arxiv.org/pdf/2406.00276.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shengyu Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00276">Machine Learning-Assisted Sustainable Remanufacturing, Reusing and Recycling for Lithium-ion Batteries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The sustainable utilization of lithium-ion batteries (LIBs) is crucial to the global energy transition and carbon neutrality, yet data scarcity and heterogeneity remain major barriers across remanufacturing, reusing, and recycling. This dissertation develops a machine learning assisted framework to address these challenges throughout the battery lifecycle. A physics informed quality control model predicts long-term degradation from limited early-cycle data, while a generative learning based residual value assessment method enables rapid and accurate evaluation of retired batteries under random conditions. A federated learning strategy achieves privacy preserving and high precision cathode material sorting, supporting efficient recycling. Furthermore, a unified diagnostics and prognostics framework based on correlation alignment enhances adaptability across tasks such as state of health estimation, state of charge estimation, and remaining useful life prediction under varied testing protocols. Collectively, these contributions advance sustainable battery management by integrating physics, data generation, privacy preserving collaboration, and adaptive learning, offering methodological innovations to promote circular economy and global carbon neutrality.
<div id='section'>Paperid: <span id='pid'>2127, <a href='https://arxiv.org/pdf/2405.05987.pdf' target='_blank'>https://arxiv.org/pdf/2405.05987.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alice Cicirello
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.05987">Physics-Enhanced Machine Learning: a position paper for dynamical systems investigations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This position paper takes a broad look at Physics-Enhanced Machine Learning (PEML) -- also known as Scientific Machine Learning -- with particular focus to those PEML strategies developed to tackle dynamical systems' challenges. The need to go beyond Machine Learning (ML) strategies is driven by: (i) limited volume of informative data, (ii) avoiding accurate-but-wrong predictions; (iii) dealing with uncertainties; (iv) providing Explainable and Interpretable inferences. A general definition of PEML is provided by considering four physics and domain knowledge biases, and three broad groups of PEML approaches are discussed: physics-guided, physics-encoded and physics-informed. The advantages and challenges in developing PEML strategies for guiding high-consequence decision making in engineering applications involving complex dynamical systems, are presented.
<div id='section'>Paperid: <span id='pid'>2128, <a href='https://arxiv.org/pdf/2405.02063.pdf' target='_blank'>https://arxiv.org/pdf/2405.02063.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>David J. Schodt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.02063">Few-sample Variational Inference of Bayesian Neural Networks with Arbitrary Nonlinearities</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Bayesian Neural Networks (BNNs) extend traditional neural networks to provide uncertainties associated with their outputs. On the forward pass through a BNN, predictions (and their uncertainties) are made either by Monte Carlo sampling network weights from the learned posterior or by analytically propagating statistical moments through the network. Though flexible, Monte Carlo sampling is computationally expensive and can be infeasible or impractical under resource constraints or for large networks. While moment propagation can ameliorate the computational costs of BNN inference, it can be difficult or impossible for networks with arbitrary nonlinearities, thereby restricting the possible set of network layers permitted with such a scheme. In this work, we demonstrate a simple yet effective approach for propagating statistical moments through arbitrary nonlinearities with only 3 deterministic samples, enabling few-sample variational inference of BNNs without restricting the set of network layers used. Furthermore, we leverage this approach to demonstrate a novel nonlinear activation function that we use to inject physics-informed prior information into output nodes of a BNN.
<div id='section'>Paperid: <span id='pid'>2129, <a href='https://arxiv.org/pdf/2404.18780.pdf' target='_blank'>https://arxiv.org/pdf/2404.18780.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Turinici
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.18780">Optimal time sampling in physics-informed neural networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINN) is a extremely powerful paradigm used to solve equations encountered in scientific computing applications. An important part of the procedure is the minimization of the equation residual which includes, when the equation is time-dependent, a time sampling. It was argued in the literature that the sampling need not be uniform but should overweight initial time instants, but no rigorous explanation was provided for this choice. In the present work we take some prototypical examples and, under standard hypothesis concerning the neural network convergence, we show that the optimal time sampling follows a (truncated) exponential distribution. In particular we explain when is best to use uniform time sampling and when one should not. The findings are illustrated with numerical examples on linear equation, Burgers' equation and the Lorenz system.
<div id='section'>Paperid: <span id='pid'>2130, <a href='https://arxiv.org/pdf/2404.13909.pdf' target='_blank'>https://arxiv.org/pdf/2404.13909.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yared W. Bekele
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.13909">Physics-informed neural networks with curriculum training for poroelastic flow and deformation processes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a highly active research topic across multiple disciplines in science and engineering, including computational geomechanics. PINNs offer a promising approach in different applications where faster, near real-time or real-time numerical prediction is required. Examples of such areas in geomechanics include geotechnical design optimization, digital twins of geo-structures and stability prediction of monitored slopes. But there remain challenges in training of PINNs, especially for problems with high spatial and temporal complexity. In this paper, we study how the training of PINNs can be improved by using an idealized poroelasticity problem as a demonstration example. A curriculum training strategy is employed where the PINN model is trained gradually by dividing the training data into intervals along the temporal dimension. We find that the PINN model with curriculum training takes nearly half the time required for training compared to conventional training over the whole solution domain. For the particular example here, the quality of the predicted solution was found to be good in both training approaches, but it is anticipated that the curriculum training approach has the potential to offer a better prediction capability for more complex problems, a subject for further research.
<div id='section'>Paperid: <span id='pid'>2131, <a href='https://arxiv.org/pdf/2402.11701.pdf' target='_blank'>https://arxiv.org/pdf/2402.11701.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Roberto C. Alamino
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.11701">Explaining the Machine Learning Solution of the Ising Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As powerful as machine learning (ML) techniques are in solving problems involving data with large dimensionality, explaining the results from the fitted parameters remains a challenging task of utmost importance, especially in physics applications. This work shows how this can be accomplished for the ferromagnetic Ising model, the main target of several ML studies in statistical physics. Here it is demonstrated that the successful unsupervised identification of the phases and order parameter by principal component analysis, a common method in those studies, detects that the magnetization per spin has its greatest variation with the temperature, the actual control parameter of the phase transition. Then, by using a neural network (NN) without hidden layers (the simplest possible) and informed by the symmetry of the Hamiltonian, an explanation is provided for the strategy used in finding the supervised learning solution for the critical temperature of the model's continuous phase transition. This allows the prediction of the minimal extension of the NN to solve the problem when the symmetry is not known, which becomes also explainable. These results pave the way to a physics-informed explainable generalized framework, enabling the extraction of physical laws and principles from the parameters of the models.
<div id='section'>Paperid: <span id='pid'>2132, <a href='https://arxiv.org/pdf/2401.15661.pdf' target='_blank'>https://arxiv.org/pdf/2401.15661.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefano Markidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.15661">Brain-Inspired Physics-Informed Neural Networks: Bare-Minimum Neural Architectures for PDE Solvers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving partial differential equations~(PDEs) in various scientific and engineering domains. However, traditional PINN architectures typically rely on large, fully connected multilayer perceptrons~(MLPs), lacking the sparsity and modularity inherent in many traditional numerical solvers. An unsolved and critical question for PINN is: What is the minimum PINN complexity regarding nodes, layers, and connections needed to provide acceptable performance? To address this question, this study investigates a novel approach by merging established PINN methodologies with brain-inspired neural network techniques. We use Brain-Inspired Modular Training~(BIMT), leveraging concepts such as locality, sparsity, and modularity inspired by the organization of the brain. With brain-inspired PINN, we demonstrate the evolution of PINN architectures from large, fully connected structures to bare-minimum, compact MLP architectures, often consisting of a few neural units!
  Moreover, using brain-inspired PINN, we showcase the spectral bias phenomenon occurring on the PINN architectures: bare-minimum architectures solving problems with high-frequency components require more neural units than PINN solving low-frequency problems. Finally, we derive basic PINN building blocks through BIMT training on simple problems akin to convolutional and attention modules in deep neural networks, enabling the construction of modular PINN architectures. Our experiments show that brain-inspired PINN training leads to PINN architectures that minimize the computing and memory resources yet provide accurate results.
<div id='section'>Paperid: <span id='pid'>2133, <a href='https://arxiv.org/pdf/2401.14591.pdf' target='_blank'>https://arxiv.org/pdf/2401.14591.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Gracyk
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.14591">Ricci flow regularization in latent spaces for the forward learning of partial differential equations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a manifold-based machine learning encoder-decoder method for learning dynamics in time, notably partial differential equations (PDEs), in which the manifold latent space evolves according to Ricci flow. This can be accomplished by parameterizing the latent manifold stage and subsequently simulating Ricci flow in a physics-informed setting, matching manifold quantities so that Ricci flow is empirically achieved. We emphasize dynamics that admit low-dimensional representations. With our method, the manifold, induced by the metric, is discerned through the training procedure, while the latent evolution due to Ricci flow provides an accommodating representation. By use of this flow, we sustain a canonical manifold latent representation for all values in the ambient PDE time interval continuum. We showcase that the Ricci flow facilitates qualities such as learning for out-of-distribution data and adversarial robustness on select PDE data. Moreover, we provide a thorough expansion of our methods in regard to special cases which allow higher-dimensional representations, such as Ricci flow on the hypersphere and neural discovery of non-parametric geometric flows with entropic strategies from Ricci flow theory.
<div id='section'>Paperid: <span id='pid'>2134, <a href='https://arxiv.org/pdf/2401.03534.pdf' target='_blank'>https://arxiv.org/pdf/2401.03534.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hamza Alsharif
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.03534">Physics-informed Neural Networks for Encoding Dynamics in Real Physical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This dissertation investigates physics-informed neural networks (PINNs) as candidate models for encoding governing equations, and assesses their performance on experimental data from two different systems. The first system is a simple nonlinear pendulum, and the second is 2D heat diffusion across the surface of a metal block. We show that for the pendulum system the PINNs outperformed equivalent uninformed neural networks (NNs) in the ideal data case, with accuracy improvements of 18x and 6x for 10 linearly-spaced and 10 uniformly-distributed random training points respectively. In similar test cases with real data collected from an experiment, PINNs outperformed NNs with 9.3x and 9.1x accuracy improvements for 67 linearly-spaced and uniformly-distributed random points respectively. For the 2D heat diffusion, we show that both PINNs and NNs do not fare very well in reconstructing the heating regime due to difficulties in optimizing the network parameters over a large domain in both time and space. We highlight that data denoising and smoothing, reducing the size of the optimization problem, and using LBFGS as the optimizer are all ways to improve the accuracy of the predicted solution for both PINNs and NNs. Additionally, we address the viability of deploying physics-informed models within physical systems, and we choose FPGAs as the compute substrate for deployment. In light of this, we perform our experiments using a PYNQ-Z1 FPGA and identify issues related to time-coherent sensing and spatial data alignment. We discuss the insights gained from this work and list future work items based on the proposed architecture for the system that our methods work to develop.
<div id='section'>Paperid: <span id='pid'>2135, <a href='https://arxiv.org/pdf/2312.00003.pdf' target='_blank'>https://arxiv.org/pdf/2312.00003.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akshansh Mishra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00003">Transport Equation based Physics Informed Neural Network to predict the Yield Strength of Architected Materials</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this research, the application of the Physics-Informed Neural Network (PINN) model is explored to solve transport equation-based Partial Differential Equations (PDEs). The primary objective is to analyze the impact of different activation functions incorporated within the PINN model on its predictive performance, specifically assessing the Mean Squared Error (MSE) and Mean Absolute Error (MAE). The dataset used in the study consists of a varied set of input parameters related to strut diameter, unit cell size, and the corresponding yield stress values. Through this investigation the aim is to understand the effectiveness of the PINN model and the significance of choosing appropriate activation functions for solving complex PDEs in real-world applications. The outcomes suggest that the choice of activation function may have minimal influence on the model's predictive accuracy for this particular problem. The PINN model showcases exceptional generalization capabilities, indicating its capacity to avoid overfitting with the provided dataset. The research underscores the importance of striking a balance between performance and computational efficiency while selecting an activation function for specific real-world applications. These valuable findings contribute to advancing the understanding and potential adoption of PINN as an effective tool for solving challenging PDEs in diverse scientific and engineering domains.
<div id='section'>Paperid: <span id='pid'>2136, <a href='https://arxiv.org/pdf/2311.15940.pdf' target='_blank'>https://arxiv.org/pdf/2311.15940.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel Burbulla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.15940">Physics-informed neural networks for transformed geometries and manifolds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed neural networks (PINNs) effectively embed physical principles into machine learning, but often struggle with complex or alternating geometries. We propose a novel method for integrating geometric transformations within PINNs to robustly accommodate geometric variations. Our method incorporates a diffeomorphism as a mapping of a reference domain and adapts the derivative computation of the physics-informed loss function. This generalizes the applicability of PINNs not only to smoothly deformed domains, but also to lower-dimensional manifolds and allows for direct shape optimization while training the network. We demonstrate the effectivity of our approach on several problems: (i) Eikonal equation on Archimedean spiral, (ii) Poisson problem on surface manifold, (iii) Incompressible Stokes flow in deformed tube, and (iv) Shape optimization with Laplace operator. Through these examples, we demonstrate the enhanced flexibility over traditional PINNs, especially under geometric variations. The proposed framework presents an outlook for training deep neural operators over parametrized geometries, paving the way for advanced modeling with PDEs on complex geometries in science and engineering.
<div id='section'>Paperid: <span id='pid'>2137, <a href='https://arxiv.org/pdf/2310.15875.pdf' target='_blank'>https://arxiv.org/pdf/2310.15875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ju Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.15875">Data-Driven Modeling and Analysis of Transmission Error in Harmonic Drive Systems: Nonlinear Dynamics, Error Modeling, and Compensation Techniques</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Harmonic drive systems (HDS) are high-precision robotic transmissions featuring compact size and high gear ratios. However, issues like kinematic transmission errors hamper their precision performance. This article focuses on data-driven modeling and analysis of an HDS to improve kinematic error compensation. The background introduces HDS mechanics, nonlinear attributes, and modeling approaches from literature. The HDS dynamics are derived using Lagrange equations. Experiments under aggressive conditions provide training data exhibiting deterministic patterns. Various linear and nonlinear models have been developed. The best-performing model, based on a nonlinear neural network, achieves over 98\% accuracy for one-step predictions on both the training and validation data sets. A phenomenological model separates the kinematic error into a periodic pure part and flexible part. Apart from implementation of estimated transmission error injection compensation, novel compensation mechanisms policies for the kinematic error are analyzed and proposed, including nonlinear model predictive control and frequency loop-shaping. The feedback loop is analyzed to select the controller for vibration mitigation. Main contributions include the nonlinear dynamics derivation, data-driven nonlinear modeling of flexible kinematic errors, repeatable experiment design, and proposed novel compensation mechanism and policies. Future work involves using physics-informed neural networks, sensitivity analysis, full life-cycle monitoring, and extracting physical laws directly from data.
<div id='section'>Paperid: <span id='pid'>2138, <a href='https://arxiv.org/pdf/2310.02548.pdf' target='_blank'>https://arxiv.org/pdf/2310.02548.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Barschkis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02548">Exact and soft boundary conditions in Physics-Informed Neural Networks for the Variable Coefficient Poisson equation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Boundary conditions (BCs) are a key component in every Physics-Informed Neural Network (PINN). By defining the solution to partial differential equations (PDEs) along domain boundaries, BCs constrain the underlying boundary value problem (BVP) that a PINN tries to approximate. Without them, unique PDE solutions may not exist and finding approximations with PINNs would be a challenging, if not impossible task. This study examines how soft loss-based and exact distance function-based BC imposition approaches differ when applied in PINNs. The well known variable coefficient Poisson equation serves as the target PDE for all PINN models trained in this work. Besides comparing BC imposition approaches, the goal of this work is to also provide resources on how to implement these PINNs in practice. To this end, Keras models with Tensorflow backend as well as a Python notebook with code examples and step-by-step explanations on how to build soft/exact BC PINNs are published alongside this review.
<div id='section'>Paperid: <span id='pid'>2139, <a href='https://arxiv.org/pdf/2309.06838.pdf' target='_blank'>https://arxiv.org/pdf/2309.06838.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Akshansh Mishra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.06838">Supervised Machine Learning and Physics based Machine Learning approach for prediction of peak temperature distribution in Additive Friction Stir Deposition of Aluminium Alloy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Additive friction stir deposition (AFSD) is a novel solid-state additive manufacturing technique that circumvents issues of porosity, cracking, and properties anisotropy that plague traditional powder bed fusion and directed energy deposition approaches. However, correlations between process parameters, thermal profiles, and resulting microstructure in AFSD remain poorly understood. This hinders process optimization for properties. This work employs a framework combining supervised machine learning (SML) and physics-informed neural networks (PINNs) to predict peak temperature distribution in AFSD from process parameters. Eight regression algorithms were implemented for SML modeling, while four PINNs leveraged governing equations for transport, wave propagation, heat transfer, and quantum mechanics. Across multiple statistical measures, ensemble techniques like gradient boosting proved superior for SML, with lowest MSE of 165.78. The integrated ML approach was also applied to classify deposition quality from process factors, with logistic regression delivering robust accuracy. By fusing data-driven learning and fundamental physics, this dual methodology provides comprehensive insights into tailoring microstructure through thermal management in AFSD. The work demonstrates the power of bridging statistical and physics-based modeling for elucidating AM process-property relationships.
<div id='section'>Paperid: <span id='pid'>2140, <a href='https://arxiv.org/pdf/2308.03763.pdf' target='_blank'>https://arxiv.org/pdf/2308.03763.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vedanta Thapar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.03763">Applications of Machine Learning to Modelling and Analysing Dynamical Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We explore the use of Physics Informed Neural Networks to analyse nonlinear Hamiltonian Dynamical Systems with a first integral of motion. In this work, we propose an architecture which combines existing Hamiltonian Neural Network structures into Adaptable Symplectic Recurrent Neural Networks which preserve Hamilton's equations as well as the symplectic structure of phase space while predicting dynamics for the entire parameter space. This architecture is found to significantly outperform previously proposed neural networks when predicting Hamiltonian dynamics especially in potentials which contain multiple parameters. We demonstrate its robustness using the nonlinear Henon-Heiles potential under chaotic, quasiperiodic and periodic conditions.
  The second problem we tackle is whether we can use the high dimensional nonlinear capabilities of neural networks to predict the dynamics of a Hamiltonian system given only partial information of the same. Hence we attempt to take advantage of Long Short Term Memory networks to implement Takens' embedding theorem and construct a delay embedding of the system followed by mapping the topologically invariant attractor to the true form. This architecture is then layered with Adaptable Symplectic nets to allow for predictions which preserve the structure of Hamilton's equations. We show that this method works efficiently for single parameter potentials and provides accurate predictions even over long periods of time.
<div id='section'>Paperid: <span id='pid'>2141, <a href='https://arxiv.org/pdf/2307.07302.pdf' target='_blank'>https://arxiv.org/pdf/2307.07302.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hubert Baty
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.07302">Solving higher-order Lane-Emden-Fowler type equations using physics-informed neural networks: benchmark tests comparing soft and hard constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, numerical methods using Physics-Informed Neural Networks (PINNs) are presented with the aim to solve higher-order ordinary differential equations (ODEs). Indeed, this deep-learning technique is successfully applied for solving different classes of singular ODEs, namely the well known second-order Lane-Emden equations, third order-order Emden-Fowler equations, and fourth-order Lane-Emden-Fowler equations. Two variants of PINNs technique are considered and compared. First, a minimization procedure is used to constrain the total loss function of the neural network, in which the equation residual is considered with some weight to form a physics-based loss and added to the training data loss that contains the initial/boundary conditions. Second, a specific choice of trial solutions ensuring these conditions as hard constraints is done in order to satisfy the differential equation, contrary to the first variant based on training data where the constraints appear as soft ones. Advantages and drawbacks of PINNs variants are highlighted.
<div id='section'>Paperid: <span id='pid'>2142, <a href='https://arxiv.org/pdf/2307.04121.pdf' target='_blank'>https://arxiv.org/pdf/2307.04121.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rajat Arora
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.04121">A Deep Learning Framework for Solving Hyperbolic Partial Differential Equations: Part I</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics informed neural networks (PINNs) have emerged as a powerful tool to provide robust and accurate approximations of solutions to partial differential equations (PDEs). However, PINNs face serious difficulties and challenges when trying to approximate PDEs with dominant hyperbolic character. This research focuses on the development of a physics informed deep learning framework to approximate solutions to nonlinear PDEs that can develop shocks or discontinuities without any a-priori knowledge of the solution or the location of the discontinuities. The work takes motivation from finite element method that solves for solution values at nodes in the discretized domain and use these nodal values to obtain a globally defined solution field. Built on the rigorous mathematical foundations of the discontinuous Galerkin method, the framework naturally handles imposition of boundary conditions (Neumann/Dirichlet), entropy conditions, and regularity requirements. Several numerical experiments and validation with analytical solutions demonstrate the accuracy, robustness, and effectiveness of the proposed framework.
<div id='section'>Paperid: <span id='pid'>2143, <a href='https://arxiv.org/pdf/2305.01653.pdf' target='_blank'>https://arxiv.org/pdf/2305.01653.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Sahimi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.01653">Physics-Informed and Data-Driven Discovery of Governing Equations for Complex Phenomena in Heterogeneous Media</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rapid evolution of sensor technology, advances in instrumentation, and progress in devising data-acquisition softwares/hardwares are providing vast amounts of data for various complex phenomena, ranging from those in atomospheric environment, to large-scale porous formations, and biological systems. The tremendous increase in the speed of scientific computing has also made it possible to emulate diverse high-dimensional, multiscale and multiphysics phenomena that contain elements of stochasticity, and to generate large volumes of numerical data for them in heterogeneous systems. The difficulty is, however, that often the governing equations for such phenomena are not known. A prime example is flow, transport, and deformation processes in macroscopically-heterogeneous materials and geomedia. In other cases, the governing equations are only partially known, in the sense that they either contain various coefficients that must be evaluated based on data, or that they require constitutive relations, such as the relationship between the stress tensor and the velocity gradients for non-Newtonian fluids in the momentum conservation equation, in order for them to be useful to the modeling. Several classes of approaches are emerging to address such problems that are based on machine learning, symbolic regression, the Mori-Zwanzig projection operator formulation, sparse identification of nonlinear dynamics, data assimilation, and stochastic optimization and analysis, or a combination of two or more of such approaches. This Perspective describes the latest developments in this highly important area, and discusses possible future directions.
<div id='section'>Paperid: <span id='pid'>2144, <a href='https://arxiv.org/pdf/2304.11488.pdf' target='_blank'>https://arxiv.org/pdf/2304.11488.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazuo Yonekura
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.11488">Physics-guided generative adversarial network to learn physical models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This short note describes the concept of guided training of deep neural networks (DNNs) to learn physically reasonable solutions. DNNs are being widely used to predict phenomena in physics and mechanics. One of the issues of DNNs is that their output does not always satisfy physical equations. One approach to consider physical equations is adding a residual of equations into the loss function; this is called physics-informed neural network (PINN). One feature of PINNs is that the physical equations and corresponding residual must be implemented as part of a neural network model. In addition, the residual does not always converge to a small value. The proposed model is a physics-guided generative adversarial network (PG-GAN) that uses a GAN architecture in which physical equations are used to judge whether the neural network's output is consistent with physics. The proposed method was applied to a simple problem to assess its potential usability.
<div id='section'>Paperid: <span id='pid'>2145, <a href='https://arxiv.org/pdf/2303.07127.pdf' target='_blank'>https://arxiv.org/pdf/2303.07127.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alex Bihlo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.07127">Improving physics-informed neural networks with meta-learned optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We show that the error achievable using physics-informed neural networks for solving systems of differential equations can be substantially reduced when these networks are trained using meta-learned optimization methods rather than to using fixed, hand-crafted optimizers as traditionally done. We choose a learnable optimization method based on a shallow multi-layer perceptron that is meta-trained for specific classes of differential equations. We illustrate meta-trained optimizers for several equations of practical relevance in mathematical physics, including the linear advection equation, Poisson's equation, the Korteweg--de Vries equation and Burgers' equation. We also illustrate that meta-learned optimizers exhibit transfer learning abilities, in that a meta-trained optimizer on one differential equation can also be successfully deployed on another differential equation.
<div id='section'>Paperid: <span id='pid'>2146, <a href='https://arxiv.org/pdf/2303.02890.pdf' target='_blank'>https://arxiv.org/pdf/2303.02890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Edward Small
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02890">An Analysis of Physics-Informed Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Whilst the partial differential equations that govern the dynamics of our world have been studied in great depth for centuries, solving them for complex, high-dimensional conditions and domains still presents an incredibly large mathematical and computational challenge. Analytical methods can be cumbersome to utilise, and numerical methods can lead to errors and inaccuracies. On top of this, sometimes we lack the information or knowledge to pose the problem well enough to apply these kinds of methods. Here, we present a new approach to approximating the solution to physical systems - physics-informed neural networks. The concept of artificial neural networks is introduced, the objective function is defined, and optimisation strategies are discussed. The partial differential equation is then included as a constraint in the loss function for the optimisation problem, giving the network access to knowledge of the dynamics of the physical system it is modelling. Some intuitive examples are displayed, and more complex applications are considered to showcase the power of physics informed neural networks, such as in seismic imaging. Solution error is analysed, and suggestions are made to improve convergence and/or solution precision. Problems and limitations are also touched upon in the conclusions, as well as some thoughts as to where physics informed neural networks are most useful, and where they could go next.
<div id='section'>Paperid: <span id='pid'>2147, <a href='https://arxiv.org/pdf/2302.10448.pdf' target='_blank'>https://arxiv.org/pdf/2302.10448.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuhui Meng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.10448">Variational inference in neural functional prior using normalizing flows: Application to differential equation and operator learning problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-informed deep learning have recently emerged as an effective tool for leveraging both observational data and available physical laws. Physics-informed neural networks (PINNs) and deep operator networks (DeepONets) are two such models. The former encodes the physical laws via the automatic differentiation, while the latter learns the hidden physics from data. Generally, the noisy and limited observational data as well as the overparameterization in neural networks (NNs) result in uncertainty in predictions from deep learning models. In [1], a Bayesian framework based on the {Generative Adversarial Networks} (GAN) has been proposed as a unified model to quantify uncertainties in predictions of PINNs as well as DeepONets. Specifically, the proposed approach in [1] has two stages: (1) prior learning, and (2) posterior estimation. At the first stage, the GANs are employed to learn a functional prior either from a prescribed function distribution, e.g., Gaussian process, or from historical data and available physics. At the second stage, the Hamiltonian Monte Carlo (HMC) method is utilized to estimate the posterior in the latent space of GANs. However, the vanilla HMC does not support the mini-batch training, which limits its applications in problems with big data. In the present work, we propose to use the normalizing flow (NF) models in the context of variational inference, which naturally enables the minibatch training, as the alternative to HMC for posterior estimation in the latent space of GANs. A series of numerical experiments, including a nonlinear differential equation problem and a 100-dimensional Darcy problem, are conducted to demonstrate that NF with full-/mini-batch training are able to achieve similar accuracy as the ``gold rule'' HMC.
<div id='section'>Paperid: <span id='pid'>2148, <a href='https://arxiv.org/pdf/2301.11316.pdf' target='_blank'>https://arxiv.org/pdf/2301.11316.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maziar Raissi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.11316">Open Problems in Applied Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work formulates the machine learning mechanism as a bi-level optimization problem. The inner level optimization loop entails minimizing a properly chosen loss function evaluated on the training data. This is nothing but the well-studied training process in pursuit of optimal model parameters. The outer level optimization loop is less well-studied and involves maximizing a properly chosen performance metric evaluated on the validation data. This is what we call the "iteration process", pursuing optimal model hyper-parameters. Among many other degrees of freedom, this process entails model engineering (e.g., neural network architecture design) and management, experiment tracking, dataset versioning and augmentation. The iteration process could be automated via Automatic Machine Learning (AutoML) or left to the intuitions of machine learning students, engineers, and researchers. Regardless of the route we take, there is a need to reduce the computational cost of the iteration step and as a direct consequence reduce the carbon footprint of developing artificial intelligence algorithms. Despite the clean and unified mathematical formulation of the iteration step as a bi-level optimization problem, its solutions are case specific and complex. This work will consider such cases while increasing the level of complexity from supervised learning to semi-supervised, self-supervised, unsupervised, few-shot, federated, reinforcement, and physics-informed learning. As a consequence of this exercise, this proposal surfaces a plethora of open problems in the field, many of which can be addressed in parallel.
<div id='section'>Paperid: <span id='pid'>2149, <a href='https://arxiv.org/pdf/2301.04793.pdf' target='_blank'>https://arxiv.org/pdf/2301.04793.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siddharth Rout
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.04793">PINN for Dynamical Partial Differential Equations is Not Training Deeper Networks Rather Learning Advection and Time Variance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The concepts and techniques of physics-informed neural networks (PINNs) is studied and limitations are identified to make it efficient to approximate dynamical equations. Potential working research domains are explored for increasing the robustness of this technique for the solvability of partial differential equations. It is identified that PINNs potentially fails to stronger advection and longer time duration. Also, optimization function and constraint posing needs to be smarter. Even a shallow network is good for a lot of problems while powerful deeper network fails. Reservoir computing based recurrent neural network architecture is recommended to solve dynamical problems.
<div id='section'>Paperid: <span id='pid'>2150, <a href='https://arxiv.org/pdf/2212.14012.pdf' target='_blank'>https://arxiv.org/pdf/2212.14012.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ulisses Braga-Neto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.14012">Characteristics-Informed Neural Networks for Forward and Inverse Hyperbolic Problems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose characteristics-informed neural networks (CINN), a simple and efficient machine learning approach for solving forward and inverse problems involving hyperbolic PDEs. Like physics-informed neural networks (PINN), CINN is a meshless machine learning solver with universal approximation capabilities. Unlike PINN, which enforces a PDE softly via a multi-part loss function, CINN encodes the characteristics of the PDE in a general-purpose deep neural network by adding a characteristic layer. This neural network is trained with the usual MSE data-fitting regression loss and does not require residual losses on collocation points. This leads to faster training and can avoid well-known pathologies of gradient descent optimization of multi-part PINN loss functions. This paper focuses on linear transport phenomena, in which case it is shown that, if the characteristic ODEs can be solved exactly, then the output of a CINN is an exact solution of the PDE, even at initialization, preventing the occurrence of non-physical solutions. In addition, a CINN can also be trained with soft penalty constraints that enforce, for example, periodic or Neumman boundary conditions, without losing the property that the output satisfies the PDE automatically. We also propose an architecture that extends the CINN approach to linear hyperbolic systems of PDEs. All CINN architectures proposed here can be trained end-to-end from sample data using standard deep learning software. Experiments with the simple advection equation, a stiff periodic advection equation, and an acoustics problem where data from one field is used to predict the other, unseen field, indicate that CINN is able to improve on the accuracy of the baseline PINN, in some cases by a considerable margin, while also being significantly faster to train and avoiding non-physical solutions. An extension to nonlinear PDEs is also briefly discussed.
<div id='section'>Paperid: <span id='pid'>2151, <a href='https://arxiv.org/pdf/2210.12104.pdf' target='_blank'>https://arxiv.org/pdf/2210.12104.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Simon Letzgus
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.12104">XAI for transparent wind turbine power curve models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate wind turbine power curve models, which translate ambient conditions into turbine power output, are crucial for wind energy to scale and fulfill its proposed role in the global energy transition. While machine learning (ML) methods have shown significant advantages over parametric, physics-informed approaches, they are often criticised for being opaque 'black boxes', which hinders their application in practice. We apply Shapley values, a popular explainable artificial intelligence (XAI) method, and the latest findings from XAI for regression models, to uncover the strategies ML models have learned from operational wind turbine data. Our findings reveal that the trend towards ever larger model architectures, driven by a focus on test set performance, can result in physically implausible model strategies. Therefore, we call for a more prominent role of XAI methods in model selection. Moreover, we propose a practical approach to utilize explanations for root cause analysis in the context of wind turbine performance monitoring. This can help to reduce downtime and increase the utilization of turbines in the field.
<div id='section'>Paperid: <span id='pid'>2152, <a href='https://arxiv.org/pdf/2210.09081.pdf' target='_blank'>https://arxiv.org/pdf/2210.09081.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Giulia Bertaglia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.09081">Asymptotic-Preserving Neural Networks for hyperbolic systems with diffusive scaling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the rapid advance of Machine Learning techniques and the deep increase of availability of scientific data, data-driven approaches have started to become progressively popular across science, causing a fundamental shift in the scientific method after proving to be powerful tools with a direct impact in many areas of society. Nevertheless, when attempting to analyze dynamics of complex multiscale systems, the usage of standard Deep Neural Networks (DNNs) and even standard Physics-Informed Neural Networks (PINNs) may lead to incorrect inferences and predictions, due to the presence of small scales leading to reduced or simplified models in the system that have to be applied consistently during the learning process. In this Chapter, we will address these issues in light of recent results obtained in the development of Asymptotic-Preserving Neural Networks (APNNs) for hyperbolic models with diffusive scaling. Several numerical tests show how APNNs provide considerably better results with respect to the different scales of the problem when compared with standard DNNs and PINNs, especially when analyzing scenarios in which only little and scattered information is available.
<div id='section'>Paperid: <span id='pid'>2153, <a href='https://arxiv.org/pdf/2209.14754.pdf' target='_blank'>https://arxiv.org/pdf/2209.14754.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Stefano Markidis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.14754">On Physics-Informed Neural Networks for Quantum Computers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Physics-Informed Neural Networks (PINN) emerged as a powerful tool for solving scientific computing problems, ranging from the solution of Partial Differential Equations to data assimilation tasks. One of the advantages of using PINN is to leverage the usage of Machine Learning computational frameworks relying on the combined usage of CPUs and co-processors, such as accelerators, to achieve maximum performance. This work investigates the design, implementation, and performance of PINNs, using the Quantum Processing Unit (QPU) co-processor. We design a simple Quantum PINN to solve the one-dimensional Poisson problem using a Continuous Variable (CV) quantum computing framework. We discuss the impact of different optimizers, PINN residual formulation, and quantum neural network depth on the quantum PINN accuracy. We show that the optimizer exploration of the training landscape in the case of quantum PINN is not as effective as in classical PINN, and basic Stochastic Gradient Descent (SGD) optimizers outperform adaptive and high-order optimizers. Finally, we highlight the difference in methods and algorithms between quantum and classical PINNs and outline future research challenges for quantum PINN development.
<div id='section'>Paperid: <span id='pid'>2154, <a href='https://arxiv.org/pdf/2209.10707.pdf' target='_blank'>https://arxiv.org/pdf/2209.10707.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Houman Owhadi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.10707">Gaussian Process Hydrodynamics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a Gaussian Process (GP) approach (Gaussian Process Hydrodynamics, GPH) for approximating the solution of the Euler and Navier-Stokes equations. As in Smoothed Particle Hydrodynamics (SPH), GPH is a Lagrangian particle-based approach involving the tracking of a finite number of particles transported by the flow. However, these particles do not represent mollified particles of matter but carry discrete/partial information about the continuous flow. Closure is achieved by placing a divergence-free GP prior $Î¾$ on the velocity field and conditioning on vorticity at particle locations. Known physics (e.g., the Richardson cascade and velocity-increments power laws) is incorporated into the GP prior through physics-informed additive kernels. This approach allows us to coarse-grain turbulence in a statistical manner rather than a deterministic one. By enforcing incompressibility and fluid/structure boundary conditions through the selection of the kernel, GPH requires much fewer particles than SPH. Since GPH has a natural probabilistic interpretation, numerical results come with uncertainty estimates enabling their incorporation into a UQ pipeline and the adding/removing of particles (quantas of information) in an adapted manner. The proposed approach is amenable to analysis, it inherits the complexity of state-of-the-art solvers for dense kernel matrices, and it leads to a natural definition of turbulence as information loss. Numerical experiments support the importance of selecting physics-informed kernels and illustrate the major impact of such kernels on accuracy and stability. Since the proposed approach has a Bayesian interpretation, it naturally enables data assimilation and making predictions and estimations based on mixing simulation data with experimental data.
<div id='section'>Paperid: <span id='pid'>2155, <a href='https://arxiv.org/pdf/2209.09988.pdf' target='_blank'>https://arxiv.org/pdf/2209.09988.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shamsulhaq Basir
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.09988">Investigating and Mitigating Failure Modes in Physics-informed Neural Networks (PINNs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper explores the difficulties in solving partial differential equations (PDEs) using physics-informed neural networks (PINNs). PINNs use physics as a regularization term in the objective function. However, a drawback of this approach is the requirement for manual hyperparameter tuning, making it impractical in the absence of validation data or prior knowledge of the solution. Our investigations of the loss landscapes and backpropagated gradients in the presence of physics reveal that existing methods produce non-convex loss landscapes that are hard to navigate. Our findings demonstrate that high-order PDEs contaminate backpropagated gradients and hinder convergence. To address these challenges, we introduce a novel method that bypasses the calculation of high-order derivative operators and mitigates the contamination of backpropagated gradients. Consequently, we reduce the dimension of the search space and make learning PDEs with non-smooth solutions feasible. Our method also provides a mechanism to focus on complex regions of the domain. Besides, we present a dual unconstrained formulation based on Lagrange multiplier method to enforce equality constraints on the model's prediction, with adaptive and independent learning rates inspired by adaptive subgradient methods. We apply our approach to solve various linear and non-linear PDEs.
